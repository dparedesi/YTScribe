---
video_id: Z_21fo3BmEc
video_url: https://www.youtube.com/watch?v=Z_21fo3BmEc
is_generated: False
is_translatable: True
---

Hi and thank you for joining this session. Many organizations are using Amazon to host their container-based applications. One of their key requirements is being able to roll out new versions in a safe and resilient way, and what this means is they want to be able to deploy these versions without downtime, and also they want to be able to roll back to the older version if any issue was discovered. In this session we are going to talk about we are going to talk about the different deployment strategies that you can use with Amazon ECS to implement safe and resilient deployment pipelines, and we're going to see these different strategies and how you can use them to address these resilient these resiliency requirements. My name is Islam Makcoub. I work as a containers, uh, I work as a solutions architect at AWS and I'm also a containers SME. This is the agenda for today. We are going to start with a quick overview for deployments and then we'll talk about the rolling up the deployment strategy. We'll talk about the blue-green deployment strategy, and then we'll end the session with a few key takeaways. So first, a quick overview for deployments. Services are defined through a combination of a task definition and service configurations. The task definition captures details about the container image that you want to run as part of your service, things like container image, URL, networking configurations, environment variables. When you create a service for the first time, The task definition along with service configurations are combined to create this Service Revision 1. And then if you want to deploy a new version, what you do is you create a new task definition. And this new task definition again the same thing. It is combined with the service configuration and this becomes your service revision too. The process that takes you from service revision 1 to service revision 2 is persisted and tracked in an object called service deployment, and this object or resource contains information like the progress of the deployment. It contains source revision, source service revision information, and target service revision information as well. Now let's get into the rolling update deployment strategy and see how it works. So if you want to deploy your new version without any downtime, one of the approaches that you can use is gradual replacement of your tasks that are running the old version with newer tasks that are running the new version. And this is what we call the rolling update deployment strategy. There are two key parameters that you need to configure for this to work properly. These are the minimum health percent. And this represents a lower bound on the number of tasks that you can have during this deployment. This is really important for your service availability. You don't want to be running with a lower number of tasks than what you need to serve your customers. The other percent parameter is a maximum percent, and this represents the upper bound of the number of tasks that you can have under the service. These two parameters allow you to strike the right balance for you between availability, speed of the deployment, and cost also during the deployment. The way it works is, as you see here, we are starting with all the tasks, running the old version, and then we are starting gradually to add new tasks, running the new version. And terminating the old ones that are running the old version until you get to a state where all the tasks running under the service are running the new version. Let's see how this is working, how this works in action. I'm going to use this application. This is a sample retail application. It consists of 5 services, all running on the service, and 4 back-end services, the order, the checkout, the cart, and the catalog. All of these are like services and they are backed by managed services for databases and for managed queues as well. So we'll take this scenario now we want to deploy a new version of the UI service. We want to make sure that this happens without a downtime. So we'll use the rolling update deployment strategy for that. Let's first check um the, the UI service. So we'll go to the cluster. Under the cluster, there are a bunch of services, we'll get to that shortly. We go to the service. And here you see that this service is exposed through a load balancer and also all the tasks are registered under one target group. You see here's the name of the target group. If you go to the deployment section. You will note that rolling up the deployment strategy is being used. And now let's see, let's push a change. We're going to change the background. Let's push it and see how we progress through the pipeline. First, the source code checked out, the container images built and pushed to, and then we get to the deployment stage, and here we are creating a new task definition and updating the service to point to this new task definition. We'll jump to the console and see how this is progressing on ECS. So you see the task, the deployment status is in progress, and here you see there are new tasks being added, but these tasks are referring to the new task definition. More tasks are getting added, and at the right hand side we have the browser connected to the listener of the service, and it will start showing the new background and this means the traffic is going now to the new tasks. After some time, you will note that the old tasks are getting deregistered and terminated. This is how we do the rolling update deployment strategy. This is how it works, and you can see it is completed with downtime. OK, so one thing here is if you wanted to roll back to the previous version, it may take a little bit of time because you will have to reprovision again these tasks that will run the old version. If you want to roll back quickly, then one of the strategies that you may want to implement is the blue-green deployment strategy, and what this entails is you are going to have two parallel environments the blue environment and the green environment. The blue is the old version, the green is the new version, and then you switch from the blue to the green. And the blue is still kept alive, and if things are not working as expected, you can roll back again to the blue environment. Let's see how this works in. So here the very first stage is you are starting with your original set of tasks that are running the old version. And then we get into the scaling stage. At the scaling stage, we are provisioning the green environment, and these are the tasks running the new version. Still, your traffic is entirely served by the old or the original set of tasks, the blue ones. Then we get into the test traffic shift stage. With blue-green, you have this ability to segregate production traffic from test traffic. So if you are talking about a service which is exposed using an application load balancer, what you can do is you define an additional listener. You create an additional listener. This becomes your test listener, and this can be used for testing this new version before shifting the actual traffic or before changing the production listener to point to this new version. At this test traffic shift, traffic shift stage, what you do, what is happening under the hood by the deployment controller is the test listener is changed to route the traffic to the new version or the green environment. Then in the production traffic shift stage, the production traffic or the production listener is changed to point to this new green environment or the new tasks. And then we get to the big time stage. At this stage, the two environments are kept. Still, the traffic is served by the green or the new environment, but the blue environment is still there. If any issue got discovered, you can roll back to this or you can reroute the traffic back to the blue environment. And you have the ability to define how long this stage will last for. Once the peak time lapses, then we get into the clean up stage, and at this stage, the blue environment is terminated, and you just have the green, and the green again becomes a new blue the next time you deploy. Let's see how this works. So the scenario we'll take here is you are deploying a change in the service. This time we want to be able to roll back quickly if things didn't go well. So at the beginning we need to change the service to use the blue-green deployment strategy. So we'll go to the service, click update service. And here we'll go to the deployment options section. And select the blue-green strategy. You need to configure the big time. This is again just a reminder. This is how long you want the blue environment to be kept in case you want it to roll back. And after he said that in the load balancing section we will provide a role, so the way the way the deployment controller shifts the traffic between the blue and green is by changing the listener rules. So it needs to have the IM permissions to do that. And here we're we're giving it the IM role with the required permissions. After you do that, you, you select the production listener, you select the production listener rule, and again the same thing for the test listener and the test listener rule. For blue-green, we are keeping these two environments, the blue and the green, so we need two target groups rather than just 11 for each. So we need to provide the details of the additional target group here. And then that's it. We update the service. This will trigger a deployment, and once this deployment is completed, the blue-green deployment strategy is in effect. We'll push another change to see how this will work with the blue-green strategy again, very similar steps, but when it here at the deployment. Stage we have at the right hand side like two browser windows. One is connected to the production listener. This is the one at the top, and another one is connected to the test listener, and this is the one at the bottom. Now we are progressing through different stages. At this point we are at the scale-up stage, and here we are creating the green environment. We're creating the new tasks that will be running the new version. You will notice that the number of tasks is doubling because we have now 2 environments. And then we get into the test traffic shift stage and here we are changing the rule for the test listener to route to the new tasks and you see the new black background is showing up in the lower right window which is connected to the test listener. Then we get into the production traffic shift stage, and here the production lesson is being changed to route the traffic to the new tasks. Then we get into the big time stage, and here the two environments are just kept. All the traffic is going to the new environment or the green, but the blue is still there. So we can roll back quickly. Let's say we are unhappy with this version for any reason, so we would like to roll back. As I said, this should be quick, so because the blue environment is still there, we click on the rollback. And then the deployment status will reflect that the rollback as requested. And then we'll go again to the production traffic shifts, and here we are changing the listener, the production listener again to reroute the traffic to the blue environment or the old tasks, and you see the yellowish background is coming back again. And the same thing will happen for the test listeners, so we're going to change it back to 0.2 the old environment and then we get into the cleanup stage, and here we're just deleting the new task that was created as part of this deployment and then we're back to just 3 tasks. So so. The new environment is completely deleted. OK, um, Now let's say you want to customize this deployment workflow a little bit. Imagine that you want to run some automated testing, automated testing before you actually shift the production traffic. Or if you imagine that you would like to add a manual approval step or manual verification step, you want to hold the deployment after the test traffic shift, so you do this testing and then proceed. One thing that you can use to achieve that is the life cycle hooks. Life cycle hooks are lambda functions that can be invoked at these different points of the deployment workflow, and these life cycle hooks are expected to return either in progress or success or fail. If it's then in progress, the deployment is on hold at this stage, and it keeps calling it again after a configured number of seconds. And it keeps calling it until it returns either success or failure. If it returns success, the deployment will progress to the next stage. If it fails, a rollback will be requested. Let's take one of the one of the scenarios that I mentioned is implementing a manual approval workflow. Let's see how this can be implemented with life cycle looks. So we will create a lambda function. This lambda function will be configured as a hook for the post-test traffic shift stage. And this lambda function will initially put the state of the deployment, set the state of the deployment as pending, and will save this state in an S3 bucket. And then a notification will be sent through SNS to a reviewer because this is invoked at the post-test traffic shift stage. The new version is already available under the test listener for someone to verify. Once they look into it, verify it, and if they are happy with it, they can go to this state and change it from pending to approved, and then the next time the life cycle hook is invoked, it will check the status, it will find it approved, it will return success. That is one of these cases for the life cycle looks. Let's see how this would work in action. In this case, again, we'll do change in the service, but this time we want to stop the deployment process at the post-test traffic shift so we can do some manual verifications. OK, so first we'll add the life cycle hook, so we'll go again to the service. And here we are going to update the service. In the life cycle hook section, we are going to select the lambda functions that we created with the logic I just explained. After you select the lambda function, you need to provide an I roll to the deployment controller that can invoke this lambda function. So here we select this roll. And then we need to select the life cycle stage that we need this hook to be invoked at. In this case it will be the post-test traffic shift stage. Now that is done, let's push and change in the UI service and see how this works. So again, we'll change the the background one more time. It will go through the same CICD pipeline that we have seen before and um we'll go through the deployment stage now. We will jump to the ECS console. It will progress through the different stages that I. Talked about again the same browser window setup. The top is connected to the production. The bottom is connected to test listener. We are at the scale up stage, so the new version is being provisioned. And now we are at the test traffic shift stage, so the test listener will be changed to route to the new version, and you see the background at the lower bottom is changed. Then we get to the post-test traffic shift stage. Now our life cycle hook will be invoked, and a notification will be sent based on the logic that we have in the lambda function. The user will or the reviewer will test this new version on the test listener, and based on the results of this verification, they can either approve or reject. In this case they will approve. So what this will do is it will set the deployment state or the approval state to approved in the S3 packet, and then when the hook is invoked, it will return success and this will make the workflow progress to the production traffic shift stage and you see the new background is now showing under the production listener. We get to the big time stage, we're not rolling back. We'll just wait for it to lapse and then we get to the clean up stage. We delete the old version and the deployment is succeeded. Has succeeded. OK, now I would like to discuss with you a few key takeaways. The first of these is with there are different deployment strategies that are available to you. One of these is, of course, the rolling updates that we discussed, the blue-green that we discussed as well, and there are additional strategies like Linear and Canary that are variants of the blue-green strategy. And the main benefit you get with the blue-green deployment strategy is this reduced risk. You have these two environments maintained during the deployment, allowing you to roll back if any issue is discovered. There are some trade-offs between the rolling update and the blue-green. With the rolling update, the total capacity utilized during the deployment can be lower, but the drawback you get with that is rollback can be a bit slower. However, with the blue-green deployment strategy, you are using more capacity because you have these two parallel environments, the blue and green, but you get this quick rollback. Now a call to action for you. These are some additional resources about Blue green. Feel free to explore these resources afterwards. Uh, I will just leave the slide for a couple of seconds for you to take a photo. OK, and we have two sessions about Blue-Green happening today. The first of these is a breakout session here in Mandalay Bay. This is starting at 1:30. So if you wanted to know more about Blue-Green, please join this session. The other one is a workshop. This is happening at 4 p.m. at MGM, and in this workshop you are actually going to build the demo that we have showed to you, and you're going to even add more features to what we just explained. OK, that's all that I wanted to cover. Thank you. Thank you very much for your time.