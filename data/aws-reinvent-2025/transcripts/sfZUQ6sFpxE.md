---
video_id: sfZUQ6sFpxE
video_url: https://www.youtube.com/watch?v=sfZUQ6sFpxE
is_generated: False
is_translatable: True
---

My name's Tim. I'm a senior principal engineer at Aurora, and welcome to Dat 441, where we're gonna talk about Amazon Aurora and its innovations this year. So, we've given this talk, um, every year for quite a few years now, but this year it's gonna be a little bit different for two reasons. The first one is, if you've seen one of these talks before, I'm not the normal guy, I'm not Grant. Um, but also, secondly, it's because Aurora turned 10 this year. So, uh, if you're not up to speed with that, then that means, yes, thank you, congratulations Aurora, uh, that, that cake was delicious, even from the other side of the world. Um, so what it means is that, uh, we did this live streaming event and we went back, so you could watch this live stream, still at the QR code if you'd like. You can hear from some people who we still have working for us for those 10 years and see a bunch of cool demos and stuff, so I really encourage you to check out that live stream. But if you haven't seen this talk before, I just wanna orient ourselves a little bit. So what is Amazon Aurora? So, Aurora is a cloud native relational database that combines the speed and availability of high-end commercial databases with the simplicity and cost-effectiveness of open source. So it's fully managed, fully compatible with MySQL and Postgress, respectively. It's got a whole bunch of tools that allows us to plug into Servalless, machine learning applications, because it's compatible, it means that your applications don't need to change in order to use Aurora. Um, and it means that all your extensions work for postgress and things like that as well. So the most recent addition to the Aurora family has been this third engine called Aurora DSQL, Distributed SQL. So this talk's not gonna focus deeply on DSQL, we will talk about it a little bit towards the end. So if you're interested in DSQL, I'll put some other talks up at the end which you'll be, um, Should be going to have a look at as well. OK, so I'm an engineer, right, so this is a technical talk, so I need to get a little bit technical. We'll talk about the architecture of Aurora first, because this underpins a whole bunch of what we're gonna talk about today, and I think it's a bit cool, so, if you're not interested, too bad, you've gotta listen to me geek out anyway. Um, so here we've got a common picture that you'll see a bunch of times today, 3 availability zones. Now at the bottom there, we have Aurora storage. Storage is really what makes Aurora special. So you can see the first thing is that big blue box covers all three availability zones, so we have 3 availability zones storage out of the box with Aurora, no questions asked. We have a bunch of yellow boxes, they're the storage nodes, there's normally a lot more than 9 of those things. And we have your application, 2 application nodes running in 2 different AZs, they're talking to one read-write node here, and they're talking directly to the storage. And that storage, what are we writing to that? We're writing uh log records, database log records. So they're the instructions to change a piece of data that a database would normally write. And the storage, special part about it is it understands how to turn those log records into database pages. So that means that there's no checkpoints like a traditional database, there's no full page writes, there's no double write buffers, there's no log archival. All those kind of problems that you'd normally hit with traditional databases, they don't happen here. You can also see some of my cool color coding there. There's 6 copies of each piece of data written across 6 of those storage nodes, every time you write once, we get 6 copies across 3 AZ, that comes out of the box too. We write those log records, but we read back database pages, so that's because the storage can turn those log records into pages. Right? What happens if one of those pieces of log record maybe gets broken or gets missed? Well, we'll just peer to peer repair it from another storage node in a different availability zone maybe. What happens if a whole storage node goes away? Well, again, we'll just peer to peer repair that from uh from another one. So this is all happening under the covers, the database engine, and you don't even know that it's happening. We can add another replica. Here it's this read only one, it's reading from the same storage, so there's no um consistency lag between these two things, it's the same storage. We're doing async in validation and update between those two head nodes. So when we run a transaction on the read-write node, then the read only node finds out about it within just a few milliseconds. We can add up to 15 of these replicas in different AZ's or the same AZ if you want to. Again, this is not disruptive, we're not having to reboot any of the cluster or any of the other replicas in order to do this, we can add or remove them as we like. These replicas can be different sizes, they can be different types of instances. Here we have an R8G which is a graviton, we have an R7i, which is an Intel. We have a DV. Servius which we'll talk about some more later as well. The storage expands up to 256 terabytes automatically, you're not provisioning this space, you're not provisioning performance here, this is completely elastic and automatic. When something goes wrong, maybe we lose a whole availability zone of those head nodes, right, we're able to automatically promote one of those replicas to be the rewrite node. And your application will be, we'll check into route 53, the DNS server there, we'll change the endpoint, and we'll start to talk down to the rewrite node. So if you wanna have even faster failover than that, normally that's about 30 seconds cause you're waiting for the DNS, you can use the advanced rapid drivers for JDBC ODBC, no JS, a whole bunch of other ones. And they'll be able to um change over within just a few seconds there, so it's up to 66% faster. That's the whirlwind tour of Aurora architecture. I'll test you later to see if you've got it, right? Um, one of those things that allows us to do is, is to go multi-region. So this is the same picture on the left, and on the right we have another region, global database this is called. So when we add another region, the most basic thing we can do here is we can just asynchronously replicate the storage. And if we look carefully, those orange arrows are coming through the replication server, going over to the replication agent, which are things that I manage, not what you manage. They're coming from the storage, not coming from your head node, your head node's not involved. So your application doesn't know that global database is happening, doesn't have to make any changes. We replicate over. So when you write, those log records go up, they go through the replication server and agent, and into the storage for the other side. Now we can make some replicas on the other side as well, in region B. They'll be read only cause this is a single writer system, and they'll be able to see that same data within whatever your RPO lag is there. So that's typically less than a second, it depends on your choice of the two regions. You can have up to 15 of these up to 10 of these regions, sorry, if you like. You can put, uh, you can put your application running inside that other region too. This is a really cool pattern for doing um low latency region local reads, so you don't have to worry about the cross-region latency. So with global uh database, it comes the question of how do I know which region I wanna talk to, where is the writer, that's where global endpoint comes in. So this is a DNS name. That points to the region that is the writer at this point in time, right now it's region A. So then, what happens if region A has a problem? Well, you're gonna issue a, uh, a failover operation, you're gonna tell me, Tim, you need to fail over and make region B be the primary region, please. So I'll promote one of those instances to be the writer node. Um, you can see there's that allow data loss flag down there in the bottom right corner. That's reminding us that because this was asynchronous replication, there might be a little bit of data inside that asynchronous replication window that might be lost when we do a forced failover. When we've done the failover, we've promoted that one to be the right, we'll also update the DNS name for that global endpoint using the Route 53 uh data plan API. So that's really reliable and really quick, much better than you could do with your own DNS. Um, so that was a failover operation, that's when something's broken. So global database switchover happens when something's not broken. We have two regions, they're both healthy, and we just wanna move the writer, maybe from region A to region B in this case. Maybe because you wanna follow the sun with your operations. So we've recently announced some improvements here, we've gone down from about 5 minutes of, of uh RTO here to about 30 seconds, so I really wanna explain to you how it works. You can see down the bottom left corner, there's those colored squares, that's those log records, right, and they are in a time sequence. This one was written before this one, before this one. And we say, I wanna do a switchover at this point in time, so I'm gonna write a special one of these log records into that log stream, that's my little star there. And that's gonna flow through the normal replication machinery there. And when it pops out in the second region, the second region's gonna see that, it's gonna interpret that as switch over now. So we can use this log-based architecture of Aurora to get really fast switchovers. We can get RPO of 0, we're not losing any data. And an RTO of about 30 seconds. If you'd like to learn some more about this, then there's 442 you can watch the recording of because it happened yesterday. Alright, so local right forwarding, this, this picture here we can see we've got 2 availability zones, we've got 2 application nodes and 2 replicas. What I'd really like to do is be able to write from my second uh availability zone, availability zone 2. But I've got a single writer system, so if I try and send that right to the reader only node, it's not gonna work. So I can turn on local right forwarding. Now this does not make us an active active system. What it does is when we send a right down to, from availability zone 2, we'll forward the right over to the other side. It'll execute the right exactly as it normally would. And then the results will be pulled back again. So here's a bit of an experiment I did. One of the, one of the questions comes is, well how do I know about consistency, cause this was asynchronous replication, right? So we got 3 different consistency modes, visibility modes. The default one is session. My test here does an update inside a session, and then it selects the thing that I just updated, and then it selects the thing again that I just updated, right? So in the session visibility mode, we can see, I did the update, it took a few milliseconds, because it had to go across to the other side, and then, Um, when I did the first select, I had to wait for it to come back again. In the eventual consistency mode, this is like the no seatbelts mode, where we don't wait to read our own rights at all. So we did the update, it took whatever time it took, and then when we did the select, that came back really quickly, because we didn't wait for anything that was happening on the other side, right? Maybe we did not read our own rights in this case, maybe that's a bit confusing for your application, so you have to be careful. The other option, the extreme other end is global consistency, right, where you always wait for everything that's happening in the whole cluster. So you can see that the first update took quite a while, because we had to wait for things to come back, and then the selects, they all took the same amount of time too. So right forwarding's useful, but you gotta watch out for your um consistency model. So we can extend that. We can talk about global right forwarding, so it's a similar picture, but we've got two regions now instead of two availability zones. We've got the same problem, read only know, tries to write, can't write. I want to turn one on global right forwarding. Same thing happens, I'll forward the query over to the writer, region, I'll execute it, and I'll pull it back again. We have the same consistency modes, the same considerations that you need to be aware of. Obviously the latency numbers will be a bit different because we're talking about cross-region. So that's global right forwarding. Again, it's available on most modern engine versions. Right, so I'm gonna dig into the storage a little bit more to explain how it works. So here we're looking at an Aurora storage node, inside what's happening. Um, and we've got our rewrite node, and it runs a little storage demon, this is basically the driver that lets our engine talk to our storage here. OK, so we're gonna write this log record called A, it's gonna come into the storage node. Remember this is 1 storage node out of 6, so this is actually happening 6 times, um, comes into this incoming queue, that's in memory, so we drain it from the incoming queue to the hot log, that goes to disk. Now we can acknowledge it, cause it's safe on the disk. Then we do it again. He comes right C, goes into the incoming queue, goes down the hot log, acknowledge, it's all good. Now, if your alphabet's any good, like mine, you'll notice that B is missing in the middle there, and maybe it was just delayed in transit or something, so we can just go and peer to peer fetch it from some other storage node. Here comes B. So now we have ABC, all in an order, no gaps, we can move things over to the update queue, and we can then turn these log records into pages again, we call that coalescing. This is all happening really quickly and inside the storage, so then when we need to do a read request, we've got it ready, so your, your read latency is not impacted. This storage node is also continuously dropping all of those log records and database pages into S3. This is a continuous back-up, so you can do point in time restored at any point in the last 35 days in your retention window. Now, in IO optimize, we'll talk about this more, this is a configuration option, we change some of this to increase uh throughput for IO heavy applications. What happens is we change the, that storage driver over on the left-hand side there, so it's batching more aggressively. It's really good for IO heavy applications. And with new modern engine versions, we can turn this up to the next level. We changed that incoming queue to be a durable queue, so now when I try and write log record D, it comes in. It's gonna be durably queued directly in that box, you don't have to wait for it to drop down to the hot lock, so we can acknowledge it directly. This means that your latency goes down, cause I have to do less work, your jitter goes down, um, and performance improves. We'll see some results for this in a minute, alright? OK, so Aurora Posgris is fully Pogris compatible, so we also always take in uh Posgris updates from Upstream. So I wanna just talk through some of the, the laundry list of what we've got here, and this is a very long list, lots of things are missing, so I apologize if the thing you're looking for is not here. Um, we support up to Pogris version 17.6, only just did that last week. We support the RAGD instance type with a local disc. We'll talk some more about that today. We've got a bunch of performance improvements from upstream, correlated subquery cache, adaptive joins, tons of stuff. Shared plan cache, so this is when we've got multiple postre processors running. They, uh, each have to plan their queries, and they can look into shared cache. It saves a bunch of memory. We improve read availability for large instances and large replicas, so they can boot up faster. Uh, we do PIPS 140-3 security encryption across the board now. Lots of extensions have been updated, PG vector being the most interesting one for some people, and up to 256 terabytes of volume size. Like I said, a whole bunch of other things in there, I just wanna focus in on a few of them today. So, let's look at Aurora Pogress performance, uh, throughput, just uh over different instance generations. So this is a suspension read only test. Basically it's a CPU test. It's all in memory. The purple line, we've got an R524 X large, so that's the biggest incidence we had 10 years ago at the birth of Aurora. And then the blue line, we have an R7i48X large. So that's twice as big, two generations newer, still Intel. The Y axis is queries per second, so higher is better. We can see that that's a 2.1 times improvement in performance, this is CPU bound performance, just by doing a couple of upgrades of your uh underlying instance up there. It's pretty straightforward. So then if we add in the R8G, so this is the graviton version, next generation one, current one now, 48X large, same size, again we could get 2.7 times improvement against the baseline there. So that's better than linear scaling. If you did nothing else other than just follow the normal scaling rules that we were giving you, you get 2.7 times over 10 years, that's pretty impressive, I think. So our first new feature I wanna talk about today is Aurora Postgress dynamic data masking. So, this is for organizations using Aurora that need to protect sensitive data. So maybe you've got an example here, you've got account numbers, you've got account holder names, PII kind of stuff. You've got an account balance, maybe you wanna give that to an analyst, but they don't need the exact balance, they just need some rounded version of the balance. That's what dynamic data masking's for. So, what we're gonna, what we want to get to is, we can mask things out, make them, maybe make them X's or something, we can apply some uh different functions to do some rounding, something like that. Right? That's what dynamic data masking lets you do, but it lets you have the full expressive power of SQL, so you can still do joins, you can still do uh use all your indexes, all those things. So let's see how it works a little bit. So it's implemented in Aurora, in this new PG column mask extension, where we define a policy for masking for, uh, in this case it's called fully masked account data for my example. We're gonna apply this to the accounts table, and then this is a list of the uh columns that we're gonna be masking. So this customer ID one, for example, we're gonna mask and turn it into X's, and this account balance one, we're gonna apply this round function. That's how we want to do masking. We're gonna apply it to all of the roles that are in this list. This list has only got one role called analyst, and it's got a weight of 50. This weight is used when we have overlapping policies, so we know how to apply them. Alright, so, this is pretty useful, I think already, but um I wanna talk about how it's actually implemented, because I think that's interesting. So, we have this select query, right, how does this actually work? Well, inside Postress, we have this pipeline, we pause the query, analyze, rewrite, and plan, etc. So this actually plugs in, DDM plugs in, in the query rewrite layer. We rewrite the query to fetch masked results. We don't mask the fetched results, if you like. And that's how we can get by and have really good performance and make your indexes still work and things like that. That's pretty important. You don't have to believe me, you can see the action of this in the describe um output here. You can see the mask function there being applied to that column. So now for MySQL, Aurora MySQL, again we track upstream. Same story with the laundry list here, I apologize if your favorite feature's not here, the list is just too long. So we released 311, just a couple of weeks ago. That gives you MySQL 8043 compatibility. We also released a 3100 long-term support version. That gives us an in-memory relay log cache, that's up to 40% log replication throughput if you're using bin log replication, that's pretty awesome. We have these, those advanced rapid drivers that we talked about, so now they support ODBC as well for MySQL. 256 terabyte volume support, and one that's pretty neat for me, global database secondary readers. So when something happens in your global database, those readers can now stay up and serve you reads for longer. So it increases your read availability when you have a global issue. So now Aurora servalus. So this is the instance type that I'd like most of you to consider for your workloads. Uh, it makes managing your fleets easier, because you don't have to worry about instance sizes. This is what we used to call Aurora Servius V2. Um, V1 went end of life, so now we just called it Aurora cervius. Um, it's naming is hard, I'm sorry, just bear with me with the names, OK? Um, so what is Aurora servalus? So it's an elastic instance type. You can think about it as just an instance type like a 4X large or something, except you can plug in and plug out CPU and memory, and we do it for you automatically as the system needs, right? Every time we do this, there's no impact, it's not like we're rebooting your engine or anything. We're doing this every second, we're scaling up and down the memory, CPU and network for this instance. We measure this in units of an ACU, Aurora Capacity unit, which represents 2 gigs of RAM and the associated memory, um, CPU and network that goes along with it. So here on the right, we have a lambda, and it's talking to a small, surus instance. And then another lambda comes along and it wants to talk to that instance, and it sends it tons of queries, so it's too big, so we need to scale it up a little bit, so we will. Then a big analytics job maybe comes along, and so we need to scale it up some more. And so we're scaling up and down, and we're we price this per second, so as soon as we scale back down again, you're no longer paying for the things that we scaled up, right, so this cost curve, we'll see some more of this in a second. Concrete example, so we start off with an example with 4 ACUs, right, Aurora capacity units. We are watching for changes in these triggers, CPU, memory, network, and IO. We also have this bucket of credits off to the side, this is how the scaling mechanism works. So this scaling bucket is being filled up periodically. So as it fills up, it means that if you need to scale now, you've got this many credits with which you can scale, up to your max ACU limit that you've set. So now I do need to scale, I've triggered something, maybe I wanna use some more memory. So I consume some of these credits out of the bucket. I consume 4, and then I consume some more. So now I, my instance has scaled up to 12, that's really fast, it's done this in less than a second. But my scaling credits have reduced, and they'll refill again later. So what we've done, just recently, is we've um. Enhance the responsiveness of this, so we've given you faster scaling. So the triggers respond in less than 1 2nd now, our bucket size is bigger to begin with, and it refills faster too. So what I want to talk about is, uh, some performance examples with this in a second. The other thing we've done with Aurora Servius recently is introduce platform version 3. So this gives you up to 30% improved performance. Uh it's available for all new clusters, so all you have to do is just restore from a backup or a clone or make a new cluster, you'll get this. It's not even an option that you need to select anymore. Um, so this will give you up to 30% improved performance. So, let's look at both of these two things combined. First test here, this is just for faster scaling. So this is platform version 2, yellow one is fast scaling, red one is not fast scaling. OK, this is a sus bench reed, so we're pushing pretty hard, goes up to 210 or so ACUs. What we first notice is that yellow curve is a lot steeper, we're scaling up a lot faster than the red curve is. Then because we scaled up faster, that peak performance at the top runs for longer, so we can get your workload done more quickly for longer time, 3.6 times longer. And then we scaled down at 40% faster too. So if you integrate all of that, then towards the end, you'll notice that's used 9% fewer ACU hours, they're the things you pay for, right, so you're paying 9% less for this particular test. That's great, so that's platform version 2, faster scaling. So now we turn on this platform version 3, the new thing here, we stick with faster scaling. So, a similar test, it's just a little bit heavier, so we can push even harder, and we look at the purple line there. That's platform version 3 with faster scaling, and the yellow one's platform version 2. The first thing we notice is the purple one runs for 20% less time, because it's going faster, right, so it doesn't need to run for as long to get the same job done. And then at the end of it, because it's scaled down, we used 20% fewer ACU hours, so that's 20% less bill that we'd have to pay. By combining these two features, faster scaling platform version 3, all you have to do is make a new cluster, you'll get both of these for, with no extra effort. OK. So now another one. Let's talk about one of Aurora's newest innovations, was announced only yesterday, um, and pre-announced. uh Aurora, create with express configuration. So, how often do you people in here, um, create database clusters? My guess is that this hand-drawn diagram, which is of course completely accurate, represents this population of people in here. So over on the right-hand side, there's the the enterprising mindset people who don't create data clusters very often, like basically never. Um, then there's the guys in the middle who create, maybe every week or something, but then, like, there's this population that wants to create things, like almost every second, this is the CICD kind of people, right, you wanna do things really agile, really quickly. I want to address that orange part there. So that's where Create with express configuration comes in, so this was pre-announced yesterday. Coming soon, so for Aurora postcris what this does is, we can create a DB cluster in seconds. And that lets you open your mind to now using it in those CICD pipelines, you can use it from your Agentic AI applications, you create a new database for every single interaction with that, if you like. So we can see here a few things. So these, these fields we can set, we'll create in a few seconds, we've got a flexible configuration there, so we can, this is servalus, we start off with 16 ACUs if you like, this is an editable field. Um, we can change the name, we can only select a couple of post-cris versions at the moment. But you can see that right-hand column, modifiable post-creation. So it's yes for most of those things. So even if you don't like the defaults that are here, as soon as the cluster's created, you can change it if you like as well. So this one starts off with 16 ACUs, that's good for a lot of people, but if you want a provision system, that's fine, just bring up your surplus one and switch it over, we can just fail over like we talked about before. Um, then it's secure by default, so you get encryption turned on, you get, um, IAM turned on. All by default. And it supports almost all the Aurora features. This is a regular Aurora DB cluster that we're making, it's not something special. So you could do global database, I talked about before, zero ETL, all the other features we talked about before. Backups work the same, it's all the same. So one of the new bits that I want to talk about a little bit more is this uh no VPC thing down in the bottom there. So that's pretty interesting. So without a VPC you need a way to get to your database instance. You probably don't want to put your database instance on the internet, that's normally not good practice, right? So it's Aurora Internet Access Gateway is this new component we've built, which allows us to deal with this. This is a highly available endpoint that gives us access into your Aurora cluster. It's Postgress wire protocol compatible, it's not a big heavyweight, um, proxy, so it's not giving you tons of latency to worry about. So that means you can access your DB cluster from anywhere, your, your laptop anywhere, you don't have to worry about VPNs and VPCs and things like that. Really reduces the friction for you and your developers to do whatever they need to do. So, um This also integrates with the Amazon um IAM and it integrates with AWS Shield, so we can talk about the features that it provides like fraud protection, um, And uh other ways to safeguard your data. Alright, so that's internet access gateway comes by default turned on when we do express uh configuration creates. This is not an ergentic AI talk. Laughter, good work. But I have to talk about some of the cool things we've done here. If you would like to see a agentic AI talk, there is another one down the bottom there, if you want to listen to me tomorrow, you can hear about that. Um, but there's two really interesting things that I want to talk about here for Aurora, just in the very last minute. Um, so a critical component of agentic AI, agentic AI is a loop, right, so you need memory for this thing to work. Well, I'm a database, I figure that Aurora's pretty good at being memory. Um, so how can we do it? We wanna remember something like it's favorite color is blue, something that we wanna do. So you can uh use any one of these open source frameworks, we partnered with a bunch of people already like uh like Versel or uh Letter. So here's an example of doing it with Letter. So it's only like 3 lines here, right? We've created a DB cluster with that express configuration we just talked about. Takes us a few seconds. Then we go in there, we enable the PG vector extension just because we wanna do some vector embeddings for our LLM maybe. You don't have to do that, um, and then we can turn on, um, tell, tell letter to start its docket container and just point it at that, uh postgris endpoint. We're done, now you're using Aurora Postgris for, uh, genetic AI memory. Now this is the letter example, there's a bunch of blog posts or other things that I encourage you to go and have a read of for the other frameworks of your choice, lang chain and all kinds of ones. The other thing is uh MCP servers, this is model context protocol server. So this is the glue that lets an agent find the tools that it needs to talk to, and talk to them. So AWS um open sourced a whole bunch of these MCP servers for all its databases a little while ago. What this allows us to do is run natural language queries that understand the schema of what's going on inside an Aurora database, and turn your natural language queries into SQL queries. So this is super useful if you're new to a database, you're just spelunking around trying to find your way around, or maybe if you're a power user, this will make you much more effective. OK, that's it for generative AI. Patching and upgrades maybe a bit more close to a lot of people's hearts. Um, so, hopefully I've convinced you, and you've already got tons of Aurora clusters going already, and now you're worrying about how to upgrade and patch them, keep them secure and up to date, right? So, Aurora's always given us a managed experience here, right, so I have a console screenshot here, we have a pending maintenance action, it's telling us, um, I need to apply some system update right now, and this is a managed flow, you would just click go and it would go and do it for you. What do we do differently now? Well, OS patches, they happen in a rolling fashion now, so that if you have multiple nodes in a cluster, we'll just roll through them, that increases your availability, that's great. We have a maintenance window, you've always been able to set that maintenance window that lets you set uh the day of the week in which you wanna uh take maintenance on this particular instance. We give notifications so if it's happening or not, um, this pops up in A Health, and you can opt into this being automated or not, some people opt out of it because you want to control it from your own um terraform or something, that's completely fine too. So this is one DB cluster. I think it's pretty under control. Now when you've got a fleet of clusters, I've convinced you all, you love Aurora, you've got tons of them, you've maybe got some dev ones, some QA ones, and some prod ones, something that you wanna sequence the upgrades for, right? If you wanted to do this yourself today, maybe we want the dev ones to happen on Monday, and then we want the QA ones to happen a couple of days later, so we have some bake time, just in case something goes wrong. The prod ones we want to happen on Saturday, so that we can um do it out of business hours, right? There's not very much time between Monday and Wednesday, not very much reaction time. There's also, I don't know what's happening inside your databases, I don't know which ones are your dev ones and your QA ones. So I might announce uh maintenance on Tuesday. And if you have a set-up like this, then your QA ones will be upgraded before your dev ones, which is probably not what you want to happen. So what we did was we've announced this um AWS organisation's upgrade roll-out policy, just last week, to tackle exactly this problem. So here we have our same 3 environments, and what we've done is we wanna break them into 3 waves, 1st wave, 2nd wave, and the last wave. Which is really what you were trying to express to me anyway, I think. Um, so what's gonna happen is, first we'll notify you, give you a maintenance notification just like we did before, and then we'll wait for the maintenance window for all the resources in that first wave to come along, and then we'll upgrade all of those instances in the first wave. And then we'll bake for a while. A lot longer than we would've baked before, so you've got some time to react, and then we'll wait for the maintenance window to come up for the resources in the second one, and then we'll upgrade them. Guess what, when we wait some longer time and we do it for the last wave as well. So we're not actually blocking if something's going wrong from one wave to the next, but we're giving you enough time so that you can just opt out again, you can turn the tag off or turn off AMVU if you'd like to. We're upgrading these things in sequence, so it doesn't matter which day of the week I release an update, it's gonna happen in sequence for you. Alright, so how do you do this? How do you get on board with this? You, um, have to enable AWS organizations, if you haven't already, you have to put your accounts into the organization. You have to do the normal things you would do, like enable automatic minor version upgrades, check a maintenance window that says what you want it to say. Now the interesting part, we have to set a policy, so on the left we've got the, the console version, on the right we have the JSON version of the same thing. And what this is telling us, it's allowing us to associate a tag, you're probably already using tags on your resources, here we're gonna make a tag called env, not a special word, you can call it whatever you like. And we're saying that, OK, every resource with a tag, uh, called en that's got the value of prod, for example, I want to put it in the last wave. And if there is a tag that I don't recognize or no tag at all, that's gonna get the default, which is the second wave in this case, right, so you don't have to do tags at all if that's not what you're interested in, you can just accept the defaults, that's fine, and everything will be upgraded at once. Alright. So then once you've created that policy, we can attach it to uh either your entire organization, the route, or to individual accounts in your organization, so you can be selective here. And then when an upgrade actually tries to roll around, you'll see this in the normal way, you'll see in your pending maintenance actions, up in the top left there, now it says, this is gonna happen in the 2nd wave. And then you'll also see this in AWS Health, same thing there, you'll get a health notification with the, in this case, the second wave. So I think that'll really help, so give that a try. That's the organisation's upgrade roll-out policy. OK, blue-green deployments. So all of these techniques are fantastic that I've just talked about, if you're doing compatible upgrades that we can roll through. But when a major version upgrade comes along from, from open source, these are generally incompatible by definition from open source. So we can't do them in place without taking a bunch of downtime. Probably you don't wanna do that. So blue-green deployment, what is it? So here we have our production environment up the top there, a couple of Aurora nodes, some shared storage, your application's talking to it through an endpoint. When we want to create a blue-green deployment. So that's going to, we're going to, in one click, create a complete copy of your production environment. We're gonna make all the nodes be the same, we're gonna sync up all the data using logical replication, and keep it in sync, as long as you keep this blue-green thing running. Any new rights that are coming into the blue, they'll be pushed down into the green already, right? Once that's done, then you can upgrade that green environment. You can test it with your test application. You can do whatever you like, you can spend an hour here, you can spend a week in this situation, doesn't matter. When you're happy that the upgrade's done what you want it to do. Then you can do what's called a blue-green switchover through the CLI or the console, and we take care of renaming all of your AWS resources, so that you're not left with a bit of a mess afterwards. Uh, we, we make sure that we drain the logical replication first, so you're not gonna lose out on any data. We're gonna switch the endpoint around and your production cluster just keeps on talking to that endpoint. And now it's talking to the, what used to be called the green environment. We have the old blue environment is still left behind there, so you can, you have a, a look back plan again if something goes wrong. If this times out for some reason, normally the switchover is less than a minute, but if this time out for some reason, then we'll automatically, Uh, undo it and go back to the original blue environment, again you don't have to deal with anything. So that's Aurora blue-green. It's a great way to increase your availability when you're doing these major version upgrades. I'd much rather you do the version upgrades rather than stay on an old version. I don't think anybody wants that. OK, and it's useful not just for version upgrades too, it's useful for schema changes, static parameter changes, maintenance updates, anything else that you think is a bit too risky to do in place and you want some blue-green protection from, you can use a blue-green deployment. Now the interesting thing that we just talked about with BlueGreen just last week, is support for global database. So now I've got a two region picture here, right, remember it could be up to 5, 10 secondary regions, but we have a global database. We're doing that replication, physical replication. And I say, I want a major version upgrade, that thing. Well, now I can use blue-green to do that as well. Same idea, I make a green environment, I keep it in sync with logical replication, everything I just explained works the same way. We end up with an RPO of 0, we're not losing any data, and the RTO is about 1 minute, so our switchover time is about 1 minute. So the entire global cluster can do a major version upgrade and be managed that way. It's pretty new, and I encourage you to take a look. OK, so let's talk about another neat feature that's enabled by the way that Aurora disaggregates its storage. This is Aurora's zero ETL extract transform load. So on the left there we have an aurora post, Chris. And we have a red shift, and we wanna get our data from a postres into a red shift, for example, and we wanna do this really low latency, and I don't wanna manage, well, I don't want you to have to manage the ETL pipeline that goes along with it. Cause that's hard work, that's brittle, that's can be expensive, it can be time consuming. So we can add a zero ETL integration, this is a CLI that you can run. What that does is it tells me to make a pipeline between the Aurora cluster and the Redshift cluster. Easy as that. And we'll have a 5 to 12th replication lag, so once you've written something into the uh postgress side, it'll pop up in the red shift side within 5 to 10 seconds. That's a really good turnaround time for an ETL pipeline. So If you were to do this yourself, you'd have to worry about data seeding, what, how do you start this thing off from empty, um, you'd have to worry about how to do this with, uh, how to do maintenance of this, we'd handle all that stuff for you with zero ETL. The picture gets a bit more interesting because we can do multiple auroras, maybe even different ones, mossicles and postcresses into the same red shift that you might already have in that same data lake. We can get even more of them. We can also go from Aurora mice sel into SageMaker as well, uses the same technology. So I think this is pretty cool, but I think it's even better is how it works inside. So that's what I wanna get into, is how it works underneath. So here I'm talking about a MySQL one, just because that's the one I like to talk about better. And we, we talked before about how Aurora understands the physical transaction log of what's going on. But in order to do CDC streaming, change data capture streaming, we need to have a logical log, not a physical log, right? So it's not the thing that Aurora traditionally knew how to deal with. So we have to capture that CDC log. We also have to be able to seed this data to begin with. It's no good having a change log if we have no basis to base the change on, right, so we have to seed it. So firstly, we can start off at the storage layer, we can do parallel direct export. This is where all of those individual storage nodes export directly into the redshift storage, in this case, to create a seed. So your, your head node's not involved in this, it happens really quickly, and it doesn't impact performance on your head node at all. Once we've done that seed, then we can use um what we call enhanced bin logs, so this is a bin log for MySQL or the wild for postcrest, still works the same way, but this is where we put knowledge of the format of that log, that logical replication log into the storage, so we understand how it works. So then the, the storage nodes, understand the enhanced spin log, we spin up these CDC streaming servers. They read the CDC log from the storage, not from your head node, so by turning this on in your head node, you're not hurting your performance there, which is what commonly happens with MySQL based systems. That CDC streaming fleet's gonna apply filters there, it's gonna throw away the tables that you don't want, it's gonna do all the modifications, and it's gonna push that data down into Redshift. So there's no arrows between MySQL head node and Redshift. It's all going through the storage, so you're not feeling any of that performance impact. I think that's pretty neat. So let's talk about Aurora storage types for a minute. We talked about I optimize before, we'll go into a little bit more detail. So here's Aurora standard, this is what you get if you don't choose anything. I had the same picture before, and we're gonna talk about the life of a few IOs and how much it might cost. So application, it's gonna do a select, so this is read only, right? Inside your head node, you've got a cache. And we're gonna hit on that cache, so it's, it's not gonna cost you anything other than a few milliseconds of running the instance, right? No IO. Or it's gonna miss the cache and it's gonna go to storage, and it's gonna read a database page, which will be 8K or 16K, depends on your database engine, and it's gonna cost you a fraction of a cent. Um, so what's gonna happen then when we do a write? Remember we're writing these log records, they can be varying sizes, they can be batched together in different ways. When we do a write, up to 4 kilobytes, that'll cost you some, that same fraction of a penny, right? The tricky part comes when we do different types of rights, we might batch them together in different ways, and that might not be batched into one IO, it might be batched into up to 4 IO's, right, cause they're, they're 4 or 88 or 16 kilobytes in size. So this is an unpredictable pricing model, which sometimes it works out pretty well, and sometimes we don't like the unpredictability. So we wanted to give you an option to say, how can I make this more predictable? Uh, this is where Aurora Bio Optimize came in last year. So this is a, a pricing choice. You can choose this whenever you create a cluster or at any time afterwards, you can switch it online, once a month, no problem there. What this does is it changes the way that both the the performance of the system, the way that it works, and the way that it's built. So it's a cluster level configuration, not an instance one, cos there's some storage side changes too, and these are storages shared. So, what I encourage you to do is to look at the IO proportion of your Aurora bill, if you're already using Aurora, and if that IO proportion is more than 25%, Look at IO optimized, it will probably actually save you money. I'm not trying to sell you something that's not useful, I'll think it'll actually save you money and give you better performance, and give you predictability. And even if your IO proportion is smaller than 25%, give it a look, you might like the performance too. OK, so this is available in all modern engine versions in the last 18 months or so, and it's also compatible with the newly announced um database savings plans, if you watched the keynote this morning. So how does this work? So in in terms of money, on the left we have Aurora standard which we talked about. So this is the normal AWS method, you pay exactly for what you use. So you're paying for compute, you're paying for storage in gigabyte months, and you're paying for IO at some rate, depends which region you're in. Then in the IO optimized SKU, if you've chosen that, then you'll pay for compute at some slight premium, you'll pay for storage at some premium, and you'll pay nothing for IOs, zero cost. So you might look at those percentage numbers there and become a little bit worried, but I want you to just remember back and say, if your proportion of IO is about 25% or more, this will probably actually save you money. So let's look at this example again, it's very easy to explain because all the numbers are 0s. Doesn't matter if I cache hit or miss, doesn't matter how I batch up the rights, it's just 0, right? Very easy to understand, very predictable. Cool, so let's look at not just the pricing part of Bio Optimize, but what it's gonna do to performance. So this is throughput. This is a Hammadibi test on a 16 X large, not the biggest box, but it's a pretty big box. It's pushing pretty hard. The Y axis is uh NOPM, this is the metric for this benchmark, higher is better. And we start off with an R5, which is that older instance type, and it's the version 12 APG. So this is um uh extended support version, old baseline, right, it looks OK. So then we turn on um an R6I 16 X large, version 14, not much difference in the postcris version there, and we turned on IO optimized. We got a 1.9x improvement, basically just by turning on IO optimized and going up one generation. R6I is still not very new. We turn on an R7I, version 16 post, Chris, another 10%, just by doing an upgrade. We go to version 17, the most recent one, same instance, we get another 10%. So all you did was upgrade post-Cris Maium version that time, probably just blue-green to do it, right? So that's even better, that's good for that's good for throughput. 2.3 times overall improvement in throughput there, just by turning on IO optimized, probably reducing your bill if you're working the system this hard, and upgrading a few um postres versions. OK, so now let's look at the latency of a similar test. This is actually what we built IO Optimize for, the throughput ones were just bonus points. This is what, where the money is, right? So this is suspension right only, this is a latency on the Y axis, so lower is better. The blue line is the R524X large, version 16 post gress. We can see how it's, it's getting saturated towards the right-hand side there, the latency's kicking up, we don't like that. And we've got the pink line, that's an R8G um 48 X large, version 17 with IO optimized. You can see how that line's almost flat, that's really what we want from a latency graph. So over on the low end, we've got a 3 times improvement in latency. I would be very happy with that. But on the high end, we're even better, we've got a 6.4 times improvement in the latency. That's the thread count along the bottom there, so the harder you push, the better this gets. So I optimized for latency. Now if we turn this back into throughput, we have the same test again, we can look at it and say so this turns into a 5 times improvement in throughput in those same two baselines. Just by turning on IO optimized. And going to RAG. So give Bio Optimize a shot today, and if you don't like it, that's fine, you can just switch it straight back off again, it's all online, there's no failovers or anything like that. So that was all about rights. Now we just wanna talk about wreaths too, I didn't forget about that. So one part of the puzzle is temporary objects. So when your postgress is doing something like a, a really big index rebuild or a really big sort, it might run out of memory, and it needs to build a disk. And in a normal system that disc is an EBS disc, so we have some performance considerations there. So if you choose a D instance, like an RAGD, then you have a local NVME instance storage device inside your database instance. So then when we spill to disk, we'll spill to that thing instead, up to 6 times the size of the memory we'll allocate inside there, right, so that means obviously the latency is a lot lower there. We'll improve our performance dramatically for workloads that use those temporary objects. Right, so if we turn on IO optimize though, we reduce that 6 times down to 2 times your memory, still good, still works the same way, but it's only 2 times the memory, so what's the point? Why did I save all this space over on the left there, that's what I wanna talk about. In that space we put this thing called tiered cash. So if you're on a regular APG and you do a read, you're gonna look in your shared buffers in memory first, and if it's there, we'll read it back and and we'll be done, no problem, right? If it's not in shared buffers, like it's not now, we'll go to storage, we'll read it back into the shared buffers, we'll give it to the engine, we're happy, OK? So, when we turn on optimized reads with one of those D instances, in that space, we're gonna allocate 4 times the amount of memory that we've got on the disk, and we're gonna use it like we use shared buffers. It's the, it's the cache now. And you're gonna take a little bit of memory to handle some metadata there for us. So now when Postres needs to read something, we'll check that metadata and see if the thing I want is going to be in the disk case, disk cache or not. In this case, it's not. So I'm gonna read it from the storage, directly into your memory buffer, give it back to the engine like before. So the fact that tiered cache was there did not help or hinder us in this example. But now it's there in the shared buffers, that's good. Eventually, the shared buffer's gonna get full, we're gonna have to evict that data out somewhere. So instead of just throwing it away, we're gonna evict it down into the tiered cache, we're gonna keep a little piece of metadata up there to remember that we've done this. So now when we go and try and read that data, we're gonna check that metadata and see that it is there, so I can just fetch it back from tier cache, and it'll be nice and fast, low latency. Now, if I do an update, I need to invalidate that copy that I have in the tiered cache, right? But I don't want to go and write to it all the time, that would be pretty bad for performance. So all I need to do is really just flip that metadata bit, so that I forget the fact that I, I have that data in the tiered cache, that's what we do. So now when I try and read it, it doesn't matter, we're not gonna go and look there. Recently we um added the ability to change the size of the tiered cache versus temporary objects, so if you have a, a workload coming where I know I'm gonna need to spill the disk quite a bit, I can increase the temp space, then that workload's finished, I can decrease it back again and have a nice big tiered cache. So that's now elastic and dynamic. So R8GD instance, that's a new one there, and that's the same price as an R6 GD so that exactly the same price, so you're gonna get, I think it's a 165% improvement of performance that versus an R6G. So for the same price, I think you better go and check it out, if you're using tiered cash, and if you're not, maybe give it a look. So let's look at some performance examples here. This is a histogram, so we want to be over towards the left and up high as much as we can, it's a latency histogram. So now we've done a suspen point select and we're doing a uniform distribution. This is a terrible test, it's like really random, it's not like what a normal test, a normal system would do at all. And this all fits in memory, that's why we've got a really tight spike over on the left-hand side, latency is good. Now we do a much bigger test, 340 gigs, that does not fit inside a 4X large memory, and so we can see a spike over on the right-hand side where we're reading from Aurora storage. That's 4 times higher latency. So then we're gonna increase the size of that test again, and we can see the same kind of pattern, right, we're reading from Aurora storage and the latency has gone up about 5.5 versus the baseline. So now we turn on tiered cash. We look at that 340 gigabyte one, we look at that yellow spike. That's in that space there, the, the, the mid-range latency, a little bit worse than memory, much better than Aurora storage. That's where all your reads are coming from. Notice there's no spike at all in the Aurora storage site in the yellow. That's because it all fits in tiered cache. So only a 1.5% increase in um latency versus the memory baseline. So now we go to that really big test, the one that doesn't fit in memory at all, and we can still see there are some purple reeds over on the right-hand side, but not very many, so overall there's only a 3 times uh, Deficit in latency versus the memory baseline, for something that was 8 times too big to fit in in memory. This is a really, really neat approach. But that was a, a, uh, uniform random, so now we're gonna look at a Pareto random, something more like what your application probably does, and you can see that it's even better. We have the same set of tests here, tiered cache turned on, um, and we can see that it's only a 1.4 times latency reduction. For that massive test compared to the one that fits in memory for a more reasonable distribution, it's really powerful. Right, so to give you a real use case quickly, this is PG vector benchmark, um, so this is a bigger benchmark, really good recall, and we're comparing an RHGD to an R8G, so that's optimized reads versus not. We can see there that's over a 3.5 times improvement in the number of uh, Queries per second that we can get there. So then we can add in the R6 GD and compare that, just to compare the R6 GD versus the 8GD, remember they're the same price, that gives us over a 1.6x improvement in vectors as well. OK, so that's it for Aurora my sequel and Aurora Po gris. Now we're gonna talk about Rawer D sequel for a few minutes. Um, and it's not a deep one like I talked about before. What I'm gonna give you is the flavor of the differences between these two engines so you know how to think about them, OK? So on the left, Aurora Pogris. It's fully aura, fully postgris compatible. On the right we have Aurora D sequel. What's common, so we have storage across 3 availability zones in both of them. We're gonna have a, a query comes in and it's gonna write to some query processing thing, a headnote I called it before, and it's gonna write some log records to this storage. All looks same, same so far, right? Then, we're gonna add in a 2nd query that needs to come through, 2nd application. In APG like I talked about, there's only one writer, so it has to go to the same place. Alright, we're gonna use implicit or explicit locking to deal with any kind of conflicts that are happening because of that. On the DSQL side, we'll spin up a new query processor. This is active active, it can do multiple rights here. We're gonna use optimistic concurrency control here instead. So you're gonna have a bit of a race condition going, and one of them's gonna, um, back off and have to fail and retry. Right? If I want to scale out, I can add replicas like I talked about before in Aurora Pores. Now each of those replicas has asynchronlication between them, so you have that consistency question we talked about, and it has caching, so you have good performance and then you might fall out of the cache, depends, like we talked about for optimized rates. Um, if on the DSL side we do this, we have a, it's own distributed block store for handling reads, and that's gonna scale independently. So that means that you don't have any caches inside your head nodes, but you have the ability to push down, what I call optimized reeds there, you have to push down some query predicates in there so we don't have to be so chatty with the, with the reeds. So as we scale up some more, Aurora DSQL, we'll keep on adding query processes, and Aurora Postress we can do the surplus thing like we talked about before, and that can scale all the way down to 0 after 5 minutes of inactivity, in the same way that DSQL will scale all the way down to 0 once we don't do anything, right? So clearly we can see here that this is an active passive architecture on the left-hand side with Aurora postres with explicit locking. And Aurora DSQL on the right-hand side has an active, active architecture. This is all in one region. OK. So now we'll talk about, we'll just follow a reads and writes, look a little bit deeper. So we have our AZN 0.3 of them, cause we've got 3 AZs, and a read's gonna come through, goes through the AZN point. Gonna go to some query processor that we choose. Query processor says, I need to read from these 3 storage servers in order to read the data that this query's interested in. Off he goes, fetches the reads, we're done, no question. Now when I wanna do it right, so this query is a right, instead the query processor is gonna be spooling up all of the rights that happen as part of this transaction. We're not talking to the, any of the other stuff until the transaction commits. And then when the transaction commits, I need to talk to these things called adjudicators. Remember that I could have multiple of these right queries going on at the same time. The adjudicator is the component that decides who wins and who loses, right? Now in this case, I've touched a bunch of stuff, so I have to talk to two adjudicators, because these things are sharded. And the adjudicator says, OK, you can commit this one, Tim, that's fine. So then we send those spooled rights to one of the journals. The journals are storing these, these logs across multiple AZ. And then the journal is gonna push whatever updates it needs to the storage shards that are impacted. Not all of them, only the ones that are impacted by the things that we're changing, that's important for scalability as well. OK, so now the global story, the multi-region story, um, just very quickly at the top there, we have Aurora Postgress, at the bottom we're gonna have DSL. So we have some replicas, we have read only on the far side. We have asynchronous replication, active passive, we've talked about this a lot now. That means that when we commit, your commit latency is an in-region construct because the across-region latency is asynchronous. In desynchle, things work a little bit differently. When we commit, We're going to synchronously talk across to the other regions, so every time you commit, your commit latency is cross-region latency. That's the fundamental consideration to think about between Aurora D-Signal and Aurora postcris. Alright, if you wanna learn some more about Aurora DSQL, I encourage you to stop listening to me and listen to some of these other talks there, if you want like chalk talks or breakouts or workshops. We've got lots of things to choose from there, and if you've missed it, there'll be uh recordings as well. So, on that note, I hope this gives you some feeling for how Aurora works internally, what we've been up to for the last year. Now of course, I'm only doing this because I talk to you and you tell me what you want, so I want you to talk to me again afterwards and tell me what you want for next year. And also tell me, um, in the survey, how we can do this better for next time. This is really how we're graded. Thank you very much for your time. See you around.