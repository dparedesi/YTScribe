---
video_id: jmjLcCqa_oU
video_url: https://www.youtube.com/watch?v=jmjLcCqa_oU
is_generated: False
is_translatable: True
---

All right, so we're gonna, we're gonna dig into lessons from the leaders in Agentic AI. And so my name's Roger Primo. I lead corporate strategy for IBM and a lot of our strategy, we've been on this journey, uh, for the last several years, going back to 2020 where we declared this hybrid cloud and AI strategy and obviously with cloud, we also know so much being here at Reinvent. In 2020, we got this question of why AI, why not blockchain, why not VR, all these things. I think today everybody understands. The necessity of AI. And I'm just going to try and get these slides to start. Let's see if it goes, um. And what we're seeing, and I, I lead our corporate strategy team, and what we've looked at is this technology and understanding how does it compare versus prior generations to technology. And I think there's a lot of buzz in the market around agentic AI. People have heard so much. I think the message if I could leave anyone with today is if you're starting, keep going, and we're going to hear real examples from companies that have applied this technology to change their business for the better. But if you're one of the many that MIT put out the famous study that only 5% of companies are getting value from AI, if you're one of that 5 of that 95% that's not getting value, the time is now to start changing that because the companies that are starting to use this technology, the advantages are compounding, and we're seeing real examples inside IBM's business, in our clients' businesses, in the market, where, Agentic is far more disruptive than any technology generation that's come before. It will come faster. It will touch more businesses, more categories, more industries than any technology disruption we've seen before. And so if you are among that 95% that haven't truly turned Gen AI and now agentic into value, to me the real question from that MIT study is not why aren't 95%, why are 95% not getting value, it's what are the 5% that are doing? And how can we learn from them before they put the laggards of adoption out of business. If I had one framework to think about this, we've used this, this idea of raising the floor and breaking the ceiling. We'll have Mark come up in a second talking about both of those working together, but this technology changes. Your best process today is your worst process tomorrow, and I'd say that, you know, when my corporate strategy teams looked around the world at success cases and adopting this technology. What's fascinating is there's almost no industry sector that's not among the ones that have gotten value from it, because in those raised the floor use cases there's real value, and we'll talk about it. The main patterns are in things like customer service, back office, and code development. Every company in the world has customers. Every company in the world has a back office. Today, most companies in the world write code. The patterns are there to create value. I think what I've seen as a failure mode is companies take on an exotic, break the ceiling use case, but they haven't solved things like data access and security, skills in their business to implement this technology. Trying to burden the creative use case that should come for your business with these technical challenges sometimes becomes too heavy. So start with a lot of those proven patterns, or if you're an innovator like Mark, you can start by breaking the ceiling if you really have the vision and persistence to drive through it. To me, this metaphor at the bottom of the page, I think we all know about Moore's Law. I think agents reduce this translation barrier. So many times we've been anchored in human processes, and it's what slows down business innovation. The agents don't care about your prior processes. They'll learn how to deliver for the best outcomes if you can if you can create the evaluation frameworks that tell them where to go. And so to me, the translation barriers between Moore's Law and the actual outcomes for business shrink. And so I think it means that, you know, this cliche of every company being a technology company has never been more true than this agentic era. If I just broke down, how does this come to life? Let's take a look at the classics of people, process, and systems. And while there's a lot that we can say on all these topics, I'd just say two things. On process It is this notion of optimizing to outcomes, not processes. If I look at prior generations of digital transformation or cloud transformation, one of the things that held companies back is they're anchored in today's workflow, and they're incremental on improving on what they do today. The agents don't have that anchoring. If we tell them the right outcomes to optimize for, they will shatter today's processes that hold us back. They'll find new creative ways to implement. They'll deliver value in ways that a traditional kind of human-driven engineering process may have never found. On the right side of the page, you know, this is how we've implemented a lot of it in IBM's business, and I'll spend a minute on that. But this technology touches every layer of the business. At the base, individual productivity workers, this is part of the toolkit of the modern worker. I grew up early in my career, I sat next to the former CEO of my employer and he'd kind of come up in the 70s and 80s. And every day he had his assistant print out all of his emails and then he'd read them and he'd scroll notes on them and his assistant would type those back in. If we're not the adopt, if he didn't adopt email and it held back how he'd communicate in a modern era, if we're not all the users of this technology every day. We talk a lot internally at IBM of if the first attempt of using the tool, when you prompt it, it doesn't give you the right answer, learn how to prompt it to get better on the next wave. And if it still gives you the the wrong answer after a couple of attempts, pass that feedback on the development to the development team so they can create a better experience on the next wave of it. But every knowledge worker has to know how to use this technology. At the center layer on the right side of it, if we think about end to end business processes, there's so much optimization there that can happen, and it creates ways for if it's your CFO, CHRO, etc. ways for them to optimize and create new ways of serving the business in their various domains. And inside our business, we see general managers and CEOs that are using that insights and decisions layer, being able to look at the cumulative effect of that generative AI deployed to the individual worker, to enterprise processes, and then be able to look at it in an integrated fashion across the entire business. So the CEO can ask the question of how do I make my business better and the agents get to work on asking that question in a way that touches the entire business and comes back with an answer. Sometimes in minutes versus if we were to ask individual leaders to come back with 10 ideas on how we become better, that's often a multi-month process in so many businesses. So the rate and pace of that top of the pyramid of insights and decisions works so much faster and so much broader than it did before. Since we're at Reinvent, I want to talk a little bit about the technical foundation of this because. There's so much innovation occurring across AWS, across the edge, at data centers, across other cloud providers, across SAS applications. One simple thing I'd I'd leave you with from a technical perspective is one of the things we know about agents is that if I give it more, if I give agents more information to make decisions on, and I give them more tools and places they can take action across my business. They'll be more impactful if I give them that breadth of access. And for most organizations in the world, that means giving them access to to learn from data that lives in those SAS applications, lives in AWS, lives in other clouds, and the ability to call tools across all of those environments. So we have to think differently about how we platform engineer our technical architecture to provide that type of access to the agents. I'd also think if we think about the IT environments and the application environments um that our employees work in, I'll talk about the IBM example, but we swapped out our core HR system at IBM. All of our work was done through an agentic interface. Most employees in the company didn't know that we'd changed out our HR provider behind the scenes because they'd become so accustomed to interacting with a conversational interface. That interface of work is changing from the application to the conversation that touches any application or data in your business, regardless of where it lives. So thinking about that way of working in the technical layer and how you think about your application and technology environment is critically important. And then the last thing I'll say is the data journey is incredibly important, so accessing both data quality, data access, data permission, and security. How we think about things like identity across this environment so that when an agent in one part of your environment can have a conversation with the other and they can know that that agent has permission to have that conversation. There's a lot of important technical architecture work that has to be done on this foundation as a prerequisite for success at scale with Agentic. That doesn't mean you can't do pilots in specific areas, but I think re-looking at platform engineering in the agentic context is critically important. As an IBM example, we want to be the exemplars of using this technology in our business. We want to be a best practice example so we can feed it back to our product teams and our consulting teams to help our clients, but then also to improve our business. And so all of this data is publicly reported in our in our audited financials, so this is kind of the real data behind it. But we have raised our floor and we're in the process of breaking our ceiling. In IBM by the end of this year, the run rate of our business will be $4.5 billion better than it was just 3 or 4 years ago, based on a Gen AI based transformation of how we operate. We've we've added enormous productivity into our back office functions. So today I do my HR work in a tool called Ask HR, which is basically an agentic interface to those HR technologies I discussed before. The same is true in finance, IT, procurement, so many of the back office functions that. There's so much data in those in so many businesses that you can learn how to do it. If it's customer service and in code, we're seeing just new ways to innovate and I think those are well known in many areas of the industry. If I think about breaking the ceiling, we're innovating how we do consulting with something called IBM Consulting Advantage built upon our orchestrate platform, which is our agentic orchestration layer. We've changed how we do customer service. We've built our own Gen AI native IDE that's driving both productivity internally and with a set of customers that are part of the private preview of it. So we're seeing both the ability to fundamentally change how we operate and how productive we are, and changing what we bring to market with our with our clients. The last thing I'd say is these feed each other. We're not taking all the productivity money and just distributing it out to shareholders. We're reinvesting that in innovation so that break the ceiling can go faster. And I do think for most organizations in the room, in the room, some version of that pattern it probably applies for you as well. But there's hope. So this has been so hard. 95% are failing. There are some of these exemplars, and obviously this conference is filled with a number of people that will talk about that success. But if I had to synthesize across the companies that we've looked at that have beaten the odds and gotten value from this, and I sourced it a lot from our internal examples as well. I think it comes from a set of vision and leadership, alignment from the top all the way down to the individual employee that use this technology. It comes from this notion of purposeful processes. I'll just say that the kind of anti-pattern there is so many companies I've spoken with, they have 100, 1000 Gen AI pilots going that live in disparate places. But if they're in disparate places, that means that the data quality work for that one use case doesn't help the data quality work for the next. Thinking about these as end to end processes so that the work compounds, the technology platform integrates, and the benefit accrues in a much more systematic way we see as a pattern that continues to be true. Investing deeply in data readiness and data quality, we've spent a lot of time working on our view of a customer, of a, of an employee, of a product to better represent it both for traditional data analytics and for generative AI. Data quality is always a good idea in so many businesses. I think now there's so much more of an agentic prize to be gotten that if particular data quality initiatives couldn't make it over the line in your organization a year or two now, two ago, today the ROI is probably there because there's so much more value to be created with Agen. The 4th is spending time on that technical foundation, and I talked about it, but those little use cases that so many companies went down in their, you know, hundreds or thousands of pilots. If that one small use case has to figure out The data security and access challenge all unto itself. It kind of crushes under its weight, so there has to be this technical maturity that is paired with the use cases that you pursue. To be able to make sure that we don't burden one use case. With the technical work that will benefit the entire business. And the last thing I'd say is there is a new development model that's emerged and we've worked to codify what we've done internally. I'll talk about it a little bit, we worked with anthropic to publish what we call the agentic development life cycle, but the traditional software development life cycle, which is very kind of linear. Doesn't lend itself as well here, so it's much more of an optimization learning cycle both in development and in production. That we think when you get to that point of understanding that begin with evaluations, and those evaluations mean the business outcome, they mean the model cost you're willing to spend. The governance and security boundaries that you want to put around this technology. If you began with the right evalve framework and the right experimentation to get there, Results follow, so definitely recommend kind of taking a fresh look at the development methodology as well. And I'll just say very quickly, I've hinted at some of this, but we're living those best practices in our business. Everything from the CEO mandate through to every employee in the company, leveraging, leveraging generative AI starting with those processes I talked about before. Our technical foundation where we've used, we are a hybrid cloud company that runs across AWS, our own data centers, other cloud providers, building that technical foundation so we can bring innovation everywhere that our business needs it. And then helping to codify and really understand that ADLC, which is now the methodology we use inside of our business. You know, has been part of our journey. So, real quickly, if you want to learn more on ADLC, I skipped one other Project, Bob, which is our Gen AI IDE, but that's one of part of how we're seeing profound results in both how we develop code, um, and how we are getting much more productive in our business. And then Watson X Orchestrate, which is our agentic orchestration platform that runs across environments, ADBS in the data center and other cloud providers to bring. Agentic orchestration and agent ops to basically any environment where your business happens. So with that, I said we'd have lessons from the leaders and hopefully that synthesis that we've done in the research was helpful, but I want to bring over Mark Mark Murphy, who's the CEO of Claims Connection Group, to talk about a real world example of how he's used this technology to create real advantage in his business, Mark. So MIT meets boots on the ground, my friend. MIT meets boots on the ground. Sure, I'll take that. Well, those are great boots. Those are great boots. Well, Mark, I just uh Uh, maybe we just start off, we just talk a little bit about, we'll get to it in a second. Talk about your, your company, talk about Lexari and how did you get started on this journey? Uh, it's a really good story actually. Uh, so I, I, I had a construction company. I've been in the insurance restoration business for years and, um, decided to move to Texas. I'm from Minnesota, so just a redneck moving down south and, uh, you know, my goal is to help people, uh, and I helped a lot of people in my construction company. But you know, 500 to 1000 a year is not all of them. So my goal was moving to Texas, you know, is to start a new company. And, uh, the, the catalyst was, is I worked with existing CRM managers in our industry. Uh, trying to recreate the wheel for our business processes, so I had 8 businesses trying to get it down to 1. And uh it wasn't working with them and one of my young bucks, uh, he, he came up to me and he goes, Mark, you ever heard of IBM? And he's 26, right? And I'm like, yeah, I mean, I, I know who Watson is, right, playing chess back in the 90s. And uh I'm like, yeah, I'll send him an email. So I sent him an email, um, I'm not a tech guy, never have been. Uh, but what happened was, is it, it was, you know, process, which is what we're all, we're all about, right? We're all about process. So it's like, OK, how can I help all the people instead of one or 500 or 1000? And so long story short here, uh, sent the use cases and. Uh, IBM got back to me and I started with it. I had a lot of use cases, right? I'm trying to do a, a 48 state level deal immediately, and I told them 3 to 5 years and then IBM came along. Uh, one of my first, uh, experiences, uh, as a CEO was, uh, where's my money suck? You know, where where I spend the most money and where's my throttle. And for mine, it was estimating. So we automated estimating immediately within 3 weeks. And so, um, my average estimator could do 8 a day and, uh, we can now do 244 per user license per day, which saved me 14,000 bucks a day. That's get me, that gets me excited. Not only am I saving money, but I'm helping more people. You know, and that's, that's the biggest part. And so the next question is, who has an insurance policy here? You didn't raise your hand. No, um, so Lexari is, uh, so what happened was, is we started to build out an internal BAW for our processes, and it spun off into three different companies built strictly off IBM technology. And so, uh, Lexari was the insurance, uh, deal. So what happens, what's the next throttle? The next throttle is in my company, is I'm the one that has to, if you have a claim, I give you not advice, but I mean, because I can get an ENO claim, which is errors and omissions, OK. And so that throttles up to me, right? Well, well, now on a 1000 person level, still busy. But now I do nationwide. I can't do that. So like, OK, let's use agenic AI. And so we built a private AI using orchestrate and Watson X AI. And um what it can do is is where I spend. I have to have the call. Hey, here's the claim. I'm talking to you, right? You're calling me. That's a half an hour of just this and it's like, here's the advice, Roger, you know, let's do something, OK, so that's 1 hour a day, right? 8 a day. Now we can do it in 2 minutes without any interaction and they're getting the same advice as I would give. So now we're able to help a lot of people. That's fantastic. Uh, so I, I think this notion of the merger of process and technology, that's kind of the core, the, the boots in the ground and, you know, IBM, uh, if you just think of so many people, every business has a process about how urgent do you feel like this topic is if you said to other leaders in the room, how urgent is it to really tackle this now? Um, you're 2 years late if you haven't started yet. I think that says it pretty well, and I agree with that. I agree with that. Um Talk about the implementation itself. What are some of the challenges along the way? How did IBM help you through that? How much did, uh, how much did you have to help yourself through that? Talk about that journey. It was, um, you know, me, I'm organic, uh, no software, you know, I utilize software to make money and help people, of course, uh, but with the IBM journey and, you know, and trying to, I mean, anything when you're talking one state to 48 to global, um. You're, you're there. Uh, the part where we. Where we often, uh, you know, as me, it's like it was tough. I took 18 months off and did not make income. To do this. And I sat with engineers, expert labs, client engineering, um, and we, you know, I had a lot of use cases and we had to put them all together. I learned a lot of things about my business and my processes. Uh, during that, and a lot of times I've been like, man, I shouldn't be up here right now because I'd have an island if I would have done it correctly to start. You know, and, and that's, uh, on this level, to your point is we, we, we gotta, it's always this. It only has to be this to start. You know, where's your money suck? Eliminate that thing, then you get pumped up, and then you keep doing it, right? And you can go down to organic level, sending emails and all the other things, right? But how do you help more people? How do you make it easier? And more effective I, I just, I, we're prepping for this. I love the phrase, where's the suck as a mental model for figuring out where to focus in your business because you got back to what I was talking about, it's putting the, putting the effort into the things that are gonna have the real economics. And then that means that each use case gets easier and easier along the journey, but you start with one where you know it's going to be a moneymaker, or at least there's a strong belief it'll be a moneymaker. Saving money is just as good as making money, my friend. It's, it's true. And, and by the way, now you're doing both with you're able to then serve more customers, so you're making more money and you're doing it far more productively. So you're doing both. Money is a byproduct of doing things right, you know, that's all it is. Um, I'd love to, I'd love to, and then I made just as an aside, just if you think about Mark's journey of kind of prepping for this, this is like a use case that this technology is fantastic for. If you think about understanding process in one state and then all the variants across 48 different states, that's the type of pattern that I think for a human being is really almost impossible to understand all that complexity. But it's far easier for this technology, so it's almost a a perfect case study for how this technology can help with barriers that just couldn't have been broken without it. Correct, you know, I mean, you know, again, you're helping more people, um, you know, and the same as you help one, you can help a million. Right, it's just how do we do that. Without Uh, you know, hiring more people and doing all the things and, you know, like again, this new, these new companies I started with IBM is. Is literally built off this foundation of where Roger started this in 2020. You know, and I'm a perfect byproduct of his vision. Uh, there are a few other participants in setting that vision, but I'll take, I'll take a little credit. I appreciate that. Um, Mark, if you have to net out though, I mean, we talked about at the beginning, like the MIT study went viral earlier this year. So many companies haven't got and got an ROI, not just from Magente, which is obviously even more complex to implement than traditional Gen AI. How do you look at, just talk about how do you net out the ROI and how did you know you're like how did you track that you were on a path to really get value from this technology along the journey? Like what are the what are the measures you very simple entrepreneur style, right? 90% of businesses fail. That's a fact. Now you got 95%. I watched the MIT study and I, I'm like, well, I got 5% less competition. Very simple. You know, it's, it's what it is, uh, so you're much more as a, as an entrepreneur, you're comfortable with that risk and potential to fail, but don't fail but fail to try, yeah. Now we got a lot of people from larger companies here. Any advice from how, how would you, you work with a lot of large companies as well. How do you, how do you translate that kind of entrepreneur mindset into. That's our inherent problem with all of this is the enterprise level companies. Uh, they move slow. You know, and you're talking legs and it's meetings on meetings and you know, and it's, it's just like again take a bite of the apple, right, um, you're not gonna be able to embrace the eugenic AI, you know, on security level and everything else immediately but find the one piece. You know, do that. You know, and then it compounds, but it, it cannot be, hey, we're gonna, you know, take a, I don't wanna use big company's name, large insurance company, OK. Uh, you're not going to rinse and repeat and get rid of everything you built. So what I originally started with IBM was BAW workflow for my own processes. Then we compound agenic AI on top of that. And we were already moving good with the BAW right now we're just getting better. And I think that's what a lot of existing enterprise companies have, you know, is that existing infrastructure that you're not, I mean, I would not do it as a CEO. I wouldn't rinse that. But if we can amplify it, which is a genetic AI, then we do that. Um Mark, one big question you touched on this a little bit before, but like, People talk about governance and security for this technology and for you personally, those ENO claims like for people that aren't like if you, if the AI accidentally gives your customers bad advice, you are financially you're, yeah, your financial, your, your, your, your well-being is at risk. How do you, how did you get comfortable with this technology, say I can believe in it such that you can take that personal risk or you you avoid that personal risk. I don't avoid any personal risk. It always lands on me, my friend. Um, the, so what I did during this process of building out Lexari, which is our policy reader, you know, again this is not, you know, so I drop into all the large language models, everything, you know, all the deals, including building our own, but what I trust, uh, I don't, large language model, I'm not gonna drop company names, but. You have to, you know, is, is, it has to be the right prompt to give the right advice, and that, that's the biggest issue, you know, on compliance and HEPA. So, uh, in for our story, my story is to build the, um, that product to where I felt comfortable where I'm not gonna lose my home. Is building the eugenic AI with IBM. Um, Mark, uh maybe one last question for this audience. You've been through this journey. If you had one thing that you, knowing what you know now, is there anything you'd change, or what was one piece of advice you'd give for the people that might be earlier in their journey? I feel like I'm a wild veteran at this thing, um, which I'm not, you know, you don't have to be the smartest kid in the room. I'm 2.3 GPA from a trade school. OK, and we figured it out, right? It's you find the right people to work with, you find the right business partner, which is IBM. They don't pay me to be here, by the way. Um, but you know, like, uh, my business model is to help people, and the reason I'm sitting here is because I want other people to help people. So if you have a question on where to start or how to pitch your boss, what I, what I find is the biggest, um, I've been to all the events and a lot of people come up after, you know, I talk, and they're, they're here, they got sent here for their boss. What do I do? What? I got all this data, Mark. I come back to the CEO. Well, and he says I'm crazy. Well, you are crazy, uh, you understand where you're at, but again, to the point, where does the money suck? The CEO is gonna love that, you know, you got to hit from that perspective, which is hard to do as an employee sitting here in the crowd. But I, yeah, I mean, I think it's phenomenal advice and goes right to the back to the beginning. I mean, we have this technology exists to create value. We have so many other categories of technology that have been much more mature before you had to wake up and adopt them. And so we knew the proven patterns of value, but this technology is moving so fast and so important that you have to find the suck in your business. You got to put the tire to the pavement now to get going. All right, well, listen, Mark, I want to thank you for joining us on stage here. It's a pleasure to have you as a partner. And uh I'm gonna, I'm gonna pass it off to Vishal to introduce our next client from Apollo Tires. Thanks for. Thank you, Roger. OK, yeah, so I was saying Shaliner from Apollo Tires is gonna go fairly technical about how they're using Agenec at the organization, uh, but before we do that, I'm gonna spend a minute or two on uh AWS and IBM. AWS and IBM, it's really a story about momentum. We've built together, we've built one of the strongest alliances in the industry. We've got 12 Partner of the Year awards for innovation, design, and client collaboration. At the center of this is IBM as AWS's premier client consulting partner. Powered by 25,000 trained AWS consultants, over 200 locations. And about 34 delivery competencies including gentech and manufacturing. And we've made strategic acquisitions over the years. Red Hat, for example, it brings open source innovation that integrates very well with AWS. We just acquired texture so that we can help our clients with target operating models. Similarly, Ndesic Towers, they bring cloud native and managed services for our clients. But the real impact is in client, how we deliver to our clients. We use our garage method to deliver 75% better outcomes for our clients. I'll give you an example. Delta Airlines, they came to us. They wanted us to transform their passenger experience and flights. Together we modernized, containerized, and these were to CloudNet, about 600 apps. Not only did the clients save money. But they became a lot more agile and a lot more productive, so the story is really about acceleration, innovation proven by client outcomes. So when I talk to my clients, it's becoming very clear that we are going past the AI hype cycle. Clients are making strategic decisions, decisions that will determine whether AI remains a set of experiments or it becomes something more productive that gives real value to the clients. IBM's Institute of Business Value, we did a study. And the results were very striking. Only 15% of our clients right now qualify as leaders. When I say leaders, I mean that they have gone past the pilot mode. They are actually embedding workflows into their applications and processes, and they are able to get the ROI that they need. So basically it's AI is not a gadget for them. It's something that is producing ROI for them. So the foundation of this success is is really data. A lot of our clients are starting to to invest in data because they know that without clean, connected data, the promise of AI will never be possible. The 3rd thing I'm seeing is Agentec. 80% of execs are making a huge investment in Agentec because they expect the workflows to get re-engineered and for the agents to produce a lot of productivity. And finally, of course, you need security, and that's why our clients are spending a lot of money on security. But how do you do it right? The instinct is to go from right to left. I would say let's not do that. Let's go from left to right. Set your strategy first, align it with your goals, then come up with initiatives that align to your strategy. Then you start to embed AI into your workflows. And then you have to of course take care of your talent, upskilling, culture, and then you bind all of this together with security and compliance because you have to make sure that the AI that you are putting in your systems can be trusted. So, in terms of value, it doesn't come all at once. It comes in layers. The first layer of course is productivity-based agents. We've all seen summarization tools, chatbots, all those things. The productivity of that comes only when the employees adopt them. The second is re-engineered workflows. That's where when you start, you start to combine AI, gen AI and automation to really change the workflows and get value out of them. The third, of course, is nirvana. It's ambient AI where AI is almost everywhere. And then you are able to use real-time data to accomplish big things. So one of the clients who who's really doing this really well. Is Apollo Tyers. I'm going to invite Shelinder to share how he's using agentic AI in his organization. Shelinder. Thanks Michelle. I hope I'm audible to everybody. How's everybody doing? So exciting times, exciting keynote if you attended today. Uh, and, um, before I talk about the tech part of it, let's try to understand why is it even important. What is the problem that we are trying to solve. Apollo Tires, a well known brand within the Asia Pacific. We are heavily invested in the US market. $3.5 billion company, 20,000 employees. Complex product group. We are across all the segments passenger, farm, trucks, off-roading, two wheelers. We have two brands, Apollo and Pedestine. Protestine is our premium brand which you can find here in the US. In the farm segment, we have Apollo tires in the US all across Europe. Uh, so, fairly large organization, complex processes, uh, to solve these things, what we need are, again, some exciting technologies. In fact, the word exciting excites me a lot. Matt spoke a lot about it today. So what we did, we started our tech journey 4 years back when we started moving all our workloads, manufacturing everything onto the cloud, our manufacturing education system, uh, Scara systems, VMIs, most of those things, production systems, our entire ERP SAP is on the cloud. The best thing what we did is that we removed the data silos. After we removed the data silos, the first thing that we did is we created a giant data lake onto the cloud itself. The objective was that anybody who is using the data should have a trusted data, single source of truth, no more silos. We have 7 manufacturing facilities. Earlier, the data was within the manufacturing facilities. If you're familiar with the manufacturing processes, the Scada, I'm talking about, they store the data in the historians. terabytes of data. We do a lot of quality checks using the X-ray images, terabytes of data. Today we have more than 400 terabytes on my S3. And nearly 8 terabytes in my data warehouses which are built on Redshift and Aurora. What do I do with all this data? Terabytes of data. What insights can I get? There is no point in having all this data if you can't make a meaning out of it, if you can't answer a single question. The result was we were using traditional BI, more than 500 reports. Everybody who wants something, they'll come to us. We are the bottleneck. Can you create this report to me? I'll take 15 days, understand the business process, deliver one report, then they'll say, Oh, I also wanted another question to be answered. Here's another report for you. Here's another version of the report. So these things pile up and this is going on with everybody in the traditional, you know, business intelligence reporting. So what we did is that The good part with is that now you can use to convert whatever the human is saying into the natural language part of that into a SQL query. I can very easily execute that SQL query into my database and then get the answer instantly. There is no need of any BI. My business users, my CIOs, CXOs, everybody can just use this to find out what was the sale as of today morning in real time. What was the total dispatch done today? Has it reached the customer on time? What is the OTIF? How is my productivity happening in the manufacturing plant? My IOT devices, which are directly talking to my data lake, instantly give me the insights of the plant. What have I manufactured today, which machine was down for how much time? I know the latency between my manufacturing to the warehouse to the dispatch to the customer. Has it reached on time or not? How many orders have I missed? Till now, everything was within the batch process, a delay of 4 hours, sometimes 24 hours when it comes to the BI tool. So what we did, a very simple thing, we put the LLM on the top of my entire data lake. This is just a POC what we have done, and the results are phenomenal, Amazing. Everybody who saw from the business. They were absolutely blown out. A very simple thing what they can do is fire a command and then get the results. Not just that, they can store the sessions, they can go back to the session, have the context as a memory. They can also generate the charts out of it. And if the default chart generated by my system is not good enough, they can say, oh, I want the same data in the pie chart. No, no, I want in the line chart. From the previous query, I want to further refine and drill it down. So what we did. We just, just. So what we did, uh, laser pointer. OK, hey. So I have two data warehouses I mentioned. One is Amazon Aurora and the other one is Redshift, depending on what kind of, um, data I want to store and what kind of, uh, analytics I want to do. While Redshift is very good in terms of the columnar storage, large data storage, indexing and creating the UDF or the procedures are a little complicated, so that's where we use Aurora for some of my use cases. The data inside the Aurora we took as the first trial of the POC. On the top of Aurora, we simply used the Amazon bedrock and then using the bedrock we created a context model for at least one of the databases. There are hundreds of them and hundreds of tables. We picked up one of the simplest cases for the warranty issues of the customers. Very simple thing we did and my users can now query this database. They can find out what was the warranty claim, what was the total percentage, how many dealers are claiming, what, what are the product failures. They can very easily find it out rather than using a BI tool. Go back I'm storing all these sessions into my Amazon open search with all the context. User can store 10 number of sessions. They can come back, retrieve a session, see what they did last time. On top of that, they can again run a context query. The second thing is I want to use the data which is stored in S3, other than the Amazon Aurora, as I mentioned, 400 terabytes of data. I want to expand it not just to my structured data, but even to my unstructured data. My marketing says I have thousands and thousands of marketing materials. There are insights from the marketing agencies. There are PDF files. What do I do with that? It's hard to make a meaning out of it. The simplest thing what I can do is that I can run an LLM on the top of that using the same tech stack, and then my marketing team can get the entire summary of what is happening with the competitors, with the other agencies within the market. My R&D says, I want to understand my engineering drawings better. My shop floor says that I want to solve a problem when the machine is broken. I have to read through the manual and see what exactly has to be done. So this whole thing now, just a POC has opened so many avenues for me to deliver on the top of my entire 400 terabytes of data lake. The X-ray images that I have, when a warranty issue comes, I go and analyze what happened wrong with that particular case. Was the manufacturing, was the manufacturing at fault? Was it like the post-manufacturing, the curing process, was there? Was there a foreign particle within the tire, or what exactly happened? I want to analyze the whole genealogy in that particular thing and find out who manufactured which shift it was manufactured into, which assembly line it was manufactured into. These questions are extremely complex and then they take a lot of time to get answered. Earlier my R&D team, my manufacturing team was spending days to get those answers. On the similar lines, we have developed another prototype using the graph databases where they can find out the whole genealogy, the parent and child of the manufacturing process. So essentially, the results are extremely exciting, very positive, very promising, and the single POC we plan to expand, we want to take it to the next level, put it on the entire data lake, and give it to all the users. We call it the self-service data lake, just like the self-service BI tools people use today. So there is no need of me going to train to business how to use it. This is so easy. The simple user interface integrated with Active Directory. They can go and log in. I can control who access what part of the data, and then they can just use it across all the segments till the executive level, till the CXO levels. Zero training, ROI from day one. In terms of if I want to measure some of the quantitative parts of that. A simple report if I want to create, it takes probably 15 days for me to create a report. Business will come, tell their problem statement. I will hire a BA, a business analyst who will understand the problem statement. The knowledge transfer will happen. They'll say X will understand Y, and then a number of iterations will create a report, deliver the report, and again they'll do, you know, a dry run on that, give me your feedback. I'll define the report. The whole process can take 15 days to a month depending on how complex or easy the report is. Gone is that particular time, I don't need that. Business doesn't have to tell me what they want. In some parts, yes, because yes, I have to create a context of the data, especially when there are multiple tables. The good part is that when you create a BII report, your knowledge is drained. The BII report is containing your business logic and the knowledge. But here now I can store my entire context and the knowledge within my data lake itself, which is my goal as a single source of truth. Once I have done that, my KPIs are uniform across the company. If my sales is my sales value is X, my commercial and my finance cannot say yes, this is different because everybody is looking at the same number across the board. The reporting time reduces where my book closing happened within 10 days. Now using this thing, I can have my book closing and get the answers to what was my total quarterly sale or monthly sale within probably 4 to 5 days. This is what we are targeting. So, if I want to quantify the benefits, this slide probably won't be enough to quantify those benefits. So that's um that's all I wanted to share from my insights. I'll hand it over to Vishal before I go further, I have a question or two for you. So what I see is a lot of our clients have, you know, tech data, tech tech debt, uh, process debt, uh, data debt that really inhibits their AI journey. I'm guessing, uh, Shaleer, you face some of that in your organization as well. So talk to me about how you overcome those debts that you have and still make this possible. So interesting, again, if you attended the keynote today, Matt also spoke about exactly the same thing. He spoke about the tech debt and a lot of agents that he has introduced, AWS introduced to, to solve some of these things. We have very, very simple rules when it comes to removing these debts. So we have a very simple rule. We want to, you know, remove these debts. Uh, when you talk about the data debt, I spoke about the data silos. That was the first tech debt we removed. No more data to be stored within my on-prem systems. Whether it is X-ray images, whether it is my historians, whether it is my transactional data, my SAP data, everything must land within my data lake. One single data lake which must be used for all my reporting, all my analytics, all my AI. My entire AI layer runs on that. So that is the first thing we have done as a futureproof thing that we want to remove the data debt. When it comes to the tech debt, we have chosen two tech stacks. Either we'll work on Python, which works very well for everything. You want to do web development, you want to do API, you want to do fast API or API in the flask. Or you want to, you know, run your AI on top of that, it seamlessly integrates with all the AI systems. I want to analyze the data, I can run it within the Jupiter. Whether I do it in AWS or if you guys are using Microsoft Fabric, it runs everywhere. So that is my 2nd text stack that I want to use and remove the tech that no more any other technology. Probably in some cases, yes, we use Node JS or there are some legacy applications still running on .NET. Then my golden rule is, if I can run it on Linux, that is my first preference, I'll run it on Linux. My first preference is I run it on Graviton. That reduces my costs by 40 to 50%. I run Amazon Linux on Graviton, cheapest solution that you can get in the market. My second thing is, if you cannot run it on Graviton, if you need the Intel architecture, Exodus architecture, fine, I'll give you AMD. If not, then I'll give you Intel. That's how I manage my cost. If Linux doesn't work for you, then yes, I'll go for Windows. That is the only solution. So those are some of my standard rules I have created that I remove my tech debt. When it comes to the databases, I'm very clear I will not run any database on-prem until it's absolutely needed for the manufacturing within the edge within the plant. I'll run it on RDS. If I'm running on RDS, I'll give you a database, not the whole server. Traditionally, people had this habit of buying a separate instance for everything that they want to do, where you see multiple, you know, licenses coming up. Again, in RDS if you can run on on Postgra SQL, fine. If not, then probably if you want MySQL or something. If not, it is something that has to run on Oracle and SQL, fine, I'll give it to you. So these are the standard rules that I use to remove my tech debt. I hope I've I've answered those questions. Fascinating. Yeah, so I know we need to get to our lessons learned, so I'm going to take maybe a couple of minutes just to share with you a coup a couple of things, um, so. IBM Enterprise Advantage. Think of it as a complete toolkit for you to take your AI ambitions to reality. And think of it as a three layer cake. Roger talked about, of course, IBM Consulting advantage, so that brings together all the tools, assets, and services for you to take the entire AI life cycle. On top of that, we have an Advantage Marketplace, which is, by the way, vendor neutral, so you can use use the tools from IBM, AWS, or other partners so that the solution that you are building fits your environment, not the other way around. We also include the Agentic Studio. It's a development platform and a hub that has all the tools and assets for you to scale and optimize AI faster and smarter. On top of that, of course, is AI implementation services so that you can scale your AI and you can optimize your AI as you go forward. So the story is really simple, right? So it is not about just the technology. This framework is about tools, people, processes that we bring to you so that you are able to scale your AI journey. I'll spend only a minute on the marketplace. So this marketplace has has what you need in terms of agents. These agents can be business agents. They can be by industry. They are by SDLC. They are by domain. You can license these from IBM. And when you do that, basically you're able to not start from scratch, so it's already half done. The cooking is half done, and then you can bake your own cake from that point onwards. So at the core this really embodies IBM's asset-based consulting approach. We bring to you packaged reusable assets that you can use to bake your own cake. One last thing. A lot of people ask me, so how do I think about AI agents? Should I think about them as robots? I would say no. I would say think of them as your trusted employees. Think of your most trusted employees, right? What do you think about them? They are skilled, they're dependable, they're coachable. They have all the access, and they are supervised when it needs to be. So your AI agent needs to be like your trusted employee, not like a robot. So what do I mean? So skill set. So when I'm training my agents, I'm not training them on a big LLM. I'm going to take a very domain specific LLM and I'm going to use your data so that I can train them in the in the right format, right? I will use your processes, your methods, so that the agent understands that. Now when I onboard an agent, I'm going to give it access, privileges, everything like I would do to an employee, nothing more, nothing less, so it has to be constrained in that format. It has to follow your rules. So whatever the constraints you have in the organizations, the rules you have, your agents have to follow that. And then it has to be coachable, so it's not going to be perfect on day one, right? So you should be able to to coach it, give it feedback, and then of course you have to work within the parameters of of your risk management that you have in your company. And finally, uh, human in the loop is is very, very, very important. It doesn't go away. So I'm going to go to the lessons that I think we're going to share. The first one, at least for me, is that human in the loop. Is not optional, not yet, at least, right, for the sake of enforcement, for the sake of compliance, for the sake of security, for the sake of your, your reputational risk, you need human to be in the loop right now. Your agent cannot be fully autonomous on day one. You can give it some autonomy, and as the agent proves to you that it is consistent and getting more and more consistent, that's when you give it more autonomy. But humans stays in the loop. So that's one thing that I think about it a lot. What are some of your learnings? So the best, uh, the best learning that came through this is, um, always start small, do a POC of course, uh, you can't ignore the quality of your data. That has to be, you know, uh, a good quality data that you want to work on. The POC that we did, I'm happy to share and you won't believe within 5 days we were able to get the initial results. Things are so easy plug and play when you use the Bedrock, the knowledge base, and the the search engine that we are building. OpenSearch, or rather we are using. Within 15 days, the prototype was ready and I was able to take it to my CTO to seek an approval that this is what we are building. And after we had the approval that yes, they're going to sponsor it, we can take it forward as a full scale project on the entire data lake, which is a massive project that is going to be there. Sometimes what happens, business will come or probably you will think I want to solve the most complex problem because that is the pain area. Early wins are very important. You show the early wins, and then after that you move to the complex one rather than picking the most complex project and Either delaying it, going for the cost overruns, so that is one of the most important lessons that I would say. You should follow as a rule. I mean, I was very, very impressed on how you took a pain point that is so common for you and you created a pilot and you started small but high impact. You went for early wins and that's why I think you're getting the momentum that you are well done. Another thing that I think about is when you think about agents, think about the business outcomes, right? Don't think about the technical outcomes. Start with the business world, right? So is it validate? Is it detect? Is it a claims processing agent? So you have to think about agents, not as something technical. What is the outcome that you're trying to achieve and design the agent around that. That gets your business along with you and you get momentum that way. Yeah, absolutely right. Again, I would go back to the keynote. You can't avoid the agentic framework now. More and more agents are being launched. The new one that was announced today, the front-end agents rather than the back-end agents. In one of the use cases, what we did in the multi-agented framework, we created two agents, while one agent is trying to interpret the natural language and generate the query. We created a agent we call as judge, who is going to judge whether the query generated is right or wrong. For example, when I'm saying, Give me the top 5 products. Has your agent generated a query which really gives you top 5, or is it giving you top 10 or top 4? How do you know the sequel generator is right or wrong? So we pass that to the second agent to interpret those keywords and the judge qualifies and then corrects the first agent. So these kind of frameworks, if you want. Ideally they should be implemented and there are very good articles, uh, whole books on that in case you are looking for multi-agent frameworks on the web. You should go through that. Yeah, I'll amplify what you're saying, right, so don't try to make a super agent, right? Make smaller specialized agents who talk to each other because over time, like I said, agents have to be coachable. So if you make smaller agents, then they get specialized and they are coachable, and then you can get them to behave the way you want them to. So in my mind, you know, having multi-agents, so you think of it like a planner, a researcher, an auditor, you know, different agents who are working with each other to get to the outcome that you want. We have less than a minute left, so I'll let you have the last word. Yeah, see. My suggestion would be, in case you are planning to build any such thing, Baseline framework should be strong enough. What we did right in this case was our focus was that fine, we can catch up with the AI, but our data layer should be extremely, extremely strong. That's where we focused. Otherwise, what happens when you develop these things, the data silos become the pain point. You do not know which data to trust upon. You'll run the AI on one particular data silo, it will give you X results, and then you bring it to the second one, it will give you Y results. Training becomes a pain point. Retraining has to be done. So the baseline data layer must be there, which should be company-wide, globally, uh, depending on, of course, how you're organized. But then this is the first thing that we did right. The second thing was that we focused on more of real-time data. We heavily invested in the IoT, considering we are a manufacturing company. So directly getting data from the PLCs from the plants was our priority, and this has worked very well in terms of the real-time insights. Then we have a cloud first strategy. If I can run it on the cloud, I will first prefer to run my project on the cloud, which gives me absolute scalability, control over the cost. And we have converted the entire KE model into the APEX model, so no more heavy investment for on-prem. These are some of the golden rules that I have followed, and they have worked very well for us. Awesome. Thank you, Shaleer. So we're out of time, but Mark Shaleer and I are going to be on the sidelines. If you have any questions, we are available. Please come talk to us. Thank you again. Thank you. who