---
video_id: t1JP8lwG5lU
video_url: https://www.youtube.com/watch?v=t1JP8lwG5lU
is_generated: False
is_translatable: True
---

Modernize SQL Server and .NET together with AWS Transform new AI agent. I'm Kuram Kwaja. I head the product management for AWS Transform. I'm accompanied with, uh, Nits Chikanathan, product lead, and as well as, uh, Vijay Mandari, uh, senior manager, software development. We are going to discuss about one of the problems which almost every enterprise faces, how to, uh, modernize the Windows-based applications. In this session we will try to cover how we help through the agentic AI, uh, AWS transform to modernize not only the UI framework but as well as the .NET code alongside with my modernizing the SQL server to Post Postres SQL. And then deploy it on a on a Linux instance. We will walk you through some of the, the things which we hear from our customers alongside with giving a demo of how exactly things work. And then finally, Taking a deep diving into under the covers of how things work and how the agentic AI plays a role. as well as give some uh customer anecdotes and then finally close with some of the uh Q&A whichever uh so so that we can get feedback from you and as well as answer any questions which you may have. When we speak with our customers, we ask, what's holding them back from the modernization effort. And the answers across the customers are fairly consistent. It's not about the technology. It's not about the business. It's about continuing. Upgrades and updates which are required because of end of support for the SQL and the Windows Server, which requires their developers, their resources to continue to upgrade, update, and continue to patch it to keep the lights on. The previous, secondly, the monolith applications running on .NET framework are inhibiting their progress to adopt the cloud native uh methodologies. Like the DevOps, the AI, um, uh, AGM, um, analytics integration. And then finally, since it's monolithic, so you have to overprovision the applications to keep, uh, to even accommodate for the smaller amount of the peaks of traffic. And the code is so old that even to just continue operating that code, you have to The troubleshooting gets bigger, patching gets patching gets much, much more complex. To just keep on running everything. And finally, Cost is definitely a factor, as the licensing cost is one of the biggest line items in most of the IT budgets. So all of these factors combined together are holding the enterprises back to focus on innovation. And just continuing to operate on this burden of the different factors. If you have transformed. If you look at the, the biggest blocker in this case is not just one part or the other, it's the SQL or the database modernization as well. So if you've ever gone through the migration of a SQL project along with the application, it's not an individual task, it's a coordinated task across multiple personas across multiple different elements which have to come together. So you start by, for a sequel modernization, you start by understanding. What is the database? What are the, the different queries? How do they relate to the different applications? What impact will it have if you change the schema? Followed with that, you have to kind of go into the schema conversions. What is the efficacy of the schema conversions? How much manual effort is required for things which cannot be automa automatically translated. Then you modify the application. The application modification in order to go through and connect to the new database or to new Postress type of SQL instance. You deploy, validate, and everything has to be done as it's done at one database at a time. So if you have a large number of databases, if you have a large number of applications, you continue this iterative process across multiple applications, one application at a time. But here here comes the complexity. It's not one person or a limited number of people who are doing this. You have the SQL Server, which is being handled by the DBA. You have the .NET code being handled by the developer. Then you have the uh deployment and validation across other teams so you have to bring all of these different personas together, all of these different teams together in order to make sure that it is done correctly the first time and it is repeated consistently across the remaining portfolio of your applications. Which is hard it's fragmented. Every team uses different rules. They have different scripts. They have different methodologies, so bringing everything together is labor incentive. It makes the overall, it becomes an inhibitor to do the modernization across an enterprise. This is where AWS Transform comes into play. It's the first gente AIBS platform modernizing the full stack Windows, including the UI layer, the .NET code, the database modernization, as well as deploying it into the EC2 Linux instance, bringing all of those personas together on a single platform so that. They can work together to first get the modernization done, accelerating this coordination as well as the tedious task of consistency across personas by 5X. Achieving consistency across the transformation of the different elements which are which make up your application, back and front end. Making sure that it's repeatable across uh, across hundreds of applications through that single, single platform. And by adopting the cloud native or the modern technologies, uh, you are able to slash open-source technology, able to slash the licensing costs, resulting in 70% of the operating costs and licensing cost savings. If you kind of look at what is the historical state and what, where exactly is the target, you can see on the left side that we start with the assets which are .NET framework. Really old code, monolithic, most of the times using older technologies, UI layer, uh, which is their business logic, data access layer. Then you have the SQL Server and everything is running on top of the ah the Windows machine. Now the target state for this is the cross-platform. .NET Core 8 or 10 through AWS Transform. Modernizing your UI layer to modern component-driven technologies like laser, MVC Core. Transforming your database from SQL to open-source Postress, Aurora Press. Database and then helping you deploy on. Amazon EC2, Linux instances EC2 or ECS. How does AWS transform do that? It's a 4 step process which the AWS transform does take into account. It starts by analyzing the relation between the databases and the .NET application, understanding the dependencies of the queries, understanding what SQL queries are there and how exactly they impact the application. It builds that analysis. It does that assessment followed by the schema conversion. Of the SQL into PostScript SQL, making, doing the semantic analysis to make sure that it conforms to what you had in the SQL. And then even um you can migrate the data as well using our uh Amazon DMS service. Data migration service. The second part of that, the 3rd step in this is where the dependent application code is modified with the connection strings with the ORM and any other SQL dependent application code so that it can start communicating or start working together as an application with the PostScript SQL, which is finally deployed, validated, deployed, and validated on EC2 Linux or ECX instance. To give you more to what exactly and how exactly it does, I'm gonna request Nest, Nit Nits to come over here and show how the things that work. Nits. Hey, everybody. Uh, my name is Nitz, and I'm a product lead for AWS Transform. For Windows. All right, before we go into the demo, just want to get a show of hands of how many have played with AWS Transform or do you have some familiarity with it? OK, I see a couple of hands in there. OK, good. So, for folks who do not have, um, you know, like have used AWS Transform before, let me just quickly like set the context on how do you get there. This is a recorded video, so I will click through and stop at the specific points and explain, uh, what's happening in each of those stages. So, right, I have the fun part of the job. I'm gonna go through a demo. This is the first time for some of you like where you'd see a full end to end experience across the whole stack. You will modernize your .NET framework applications to .NET 8 or 10, and then we will also show an experience of how you can move from SQL Server to Aurora PostChres as well, OK? All right. So, the first thing is, um, what you see here is the AWS console, and this, in order to log into this, you have multiple options. You can either like create your own identity center or use your own IDP providers to log into that, use your credentials, and the first thing what you will be faced with will be a workspace, and workspace is a container for all your .NET, SQL, modernization jobs. And the first step you do is create a job, right? When you create a job, there are multiple different agents, uh, different capabilities. For example, like in this case, you see a mainframe modernization agent, and for this particular audience, this is a Windows modernization, right? Like, so you come here, you, you select the Windows modernization, and you are faced with two options. One is a .NET modernization and the other one is a SQL Server. So in order for, in order for customers to migrate their, you know, like legacy applications, the first thing they have to do is modernize from .NET framework to .NET 8 or .NET 10. So the first work part of the workflow we will see will be like transforming your .NET framework applications to .NET 8, and then after that we will take that same application, we will run it through, uh, transforming application and SQL Server together so that you get a fully modernized stack. OK. All right, you select the modernization piece and what you are faced with here is essentially the transformation plan. This is the high level plan which AWS transform things of all the steps that it's gonna take to transform your .NET applications. We will first connect to your source code reposts and then we will assess and identify dependencies across your repositories. If there are projects, you know, like reposts that are dependent on other reposts, we will create that dependency mapping and we will do all the transformation. And if there are private Nougat packages, we will transform those as well. And you will have the option of selecting whether the target should be .NET 8 or .NET 10, or even for some of your class libraries, you want to leave them to .NET standard, you have all of those options to pick. OK. So the first step here is like definitely like setting up access to your source code connector. We support two mechanisms. Either you use code connections with your GitHub, GitLab, Bitbucket, or Azure reposts, or you can upload source code directly using your S3 buckets. OK. Then after that is set up, What we will do is we will go and look at the repositories in your account, right? Like, and then here is where you get a chance to select them, which branch you want, what's your target you want, and this will allow us to perform assessment, right? If you have like hundreds of repos and you want to transform, like let's say like 10, you select these ones and then let the process go. OK. So you select the specific repositories you need. And then send it for transformation. And what we are showing here is the private Nugat packages. So if you have private Nugat packages, we support two mechanisms. One, if you have Azure artifacts, uh, where all your private Nugat feeds are, you can directly interface with that. Or you can, what you can do is you can download a script from our side, and then run it on the same machine as a Visual Studio, and we will collect all the dependent packages as one zip file and you can upload it there. Right? So then, yeah, you can upload those package files and that way we will be able to resolve all the package dependencies. And finally, you get to review, here are the set of your work. This is our transformation, I would say like input, right? Like the repos that we want to transform, any dependent reposts and dependent packages. Right? And then this is when like you review it, accept it, and send it to AWS Transform to modernize. And once the transformation starts, it is essentially like an agentic workflow where it will start identifying, you know, the which is the order in which we want to transform, and we'll start going through each and every project and in those repositories, and you can use the dashboard to check the status of what's, what's currently happening, right? Like if there are any failed. Uh, repost, you will get a transformation summary of why we are not able to transform it, and you can, and with the corresponding next steps on how do you fix those, right? And then you can feed those into your, uh, coding assistants like Quiro to complete those jobs, and then you can come back and run further transformations as well. Yeah. So that is basically the .NET, um, you know, like framework portion of the conversion. So this, what it means is that like at the starting point, you have a .NET framework, you go through this process, at the end of it, you get a .NET 8 or .NET 10 application. And that becomes the next stage of the pipeline, which is the SQL Server transformation. And this is also, it starts with the same, right? Like you create a job as you as you did before and you select the Windows modernization as always. But in this case, instead of .NET modernization, actually, give me a second, sorry, uh, the SQL Server is create a job, you come back into. Windows modernization, but instead of selecting the .NET, you will select the SQL Server as an option, right? And as now it will be familiar with the same kind of sets in the transformation plan, but here you would notice significant differences between what you saw at .NET versus here. The job plan has, like, you know, we are validating permissions and we are making sure that we have the right access to your databases. You have the option to review databases and repositories together. And you before doing all of those assessments and wave plans and things like that and Khuram was pointing out in that flow where like the sequence of assessment which has like you know like we identify all the reports, all the databases, identify dependencies between them, create wave planning, and then after that we do the transformation. So the first step is like definitely the prerequisites that is needed because we are dealing with databases, we wanna make sure we have the right roles, the permissions and accesses to the right accounts. So once you validate all of it, you get started and hear from um. You approve the connector and you know, first the database connector where your AWS account where all your databases are installed, and then the next part will be the source code repositories that you will be installing them. And after you do all of that, essentially, give me a second. Yeah, Give me a second. Sorry, the video is I might need to go back. Yeah. Selecting the area, there you go. Uh Apologies for that. Like, we might selecting controls within the video is a challenge, so we'll go again from the beginning. So, but yeah, it's, it's a fairly short video, so I'll go through it fast. Uh, so yeah, here, select the job, go through it, and as we go through the source code connector and we will go into the assessment, I will stop and talk a little bit more. Right. So you get to the um prerequisites, and after that, You'll go into the database. This is where your AWS account, and after, you know, you'd need to send it to an IT admin for your AWS account to approve it. And after that comes the source code connections where your source code repositories that you transformed before and you're able to use both of them together. So that's the true power of the full stack modernization here. You can go change the applications and the databases. Right. And then you have an optional deployment. If you want to deploy those transformed applications, you can do that as well. OK. So, once all the connector stuff is set up, we will basically, what we want to do is we want to run a validation of all your permissions, making sure that we have the right level of permissions, the roles, all of that. OK, the permissions are checked, everything is good, we would first wanna go do a discovery, making sure in your AWS account are we able to identify the servers and the corresponding databases, and along with that the repositories as well. So here you will have the option to select which repositories you wanna, you wanna transform, which databases you wanna select, all of those. Right, Then you approve it for assessment and as part of our assessment we will go and identify the dependencies between the apps, the databases, and we will create those wave plans that we talked about. You will see those like here in this case you are able to see two waves. Each of those waves have one database each and one repository each because they have a dependency relationship and because they are independent, you have created two waves and they will be transforming independently. And that also keeps separation between like which teams have to collaborate together and which teams have to like, you know, work together to resolve those. OK. And you can, you can download the waves and you can edit them as well if you, if you think like there has to be more uh dependency relationship that you have to adjust. Right? And then the first part of the transformation is schema conversion. So for the SQL Server to Postress, what we wanna do is we want to take a look at your server, uh, and then identify all the database schemas, and we would want to make sure that we are able to transform them into Postres compatible schemas. So the schema conversion goes through by leveraging some, you know, the existing AWS services with like AWS DMS schema conversion service under the hood. We will do the transformation and we will use the target cluster that we created, and we'll target schema conversion for that. Once the schema conversion step is done, essentially, like that's when like the rest of the core transformation and the migration will come. So in this case, you can select which one of those, um, you know, like target clusters. And you can also download and you want to make changes after the schema conversion portion is done, right? Like, so we will do the schema conversion using the generative AI mechanism. We will identify schemas in, you know, SQL, convert them to postscris, run a self-debugging loop. If we identify issues, we will fix those, and at the end of it, you will get a summary of all the things. If it is fully transformed in this case, we'll say it's fully transformed. If it is not transformed, you will basically be able to see. Um, you know, like what, what functionality we are not able to transform, and you can leverage our transformation report to go fix those yourself. OK. And then the next part is the migration of data, right? Like, so whether you would want to, uh, validate this by migrating a snapshot of your database into, uh, the target cluster, that's an optional step for you. If you want to do it, you can do it. And we are, uh, again, we are leveraging an existing AWS service, AWS DMS, and we have a deep link into the console if you want to go check the status of what's happening there as well. So in this case, like the data migration is completed, and then this is the step where like code transformation is happening. So if your application has entity framework or ADO.NET code, uh, which is using the ORM to interact with your database, we will make the corresponding changes in the application, pointing to that. Right? So if you have embedded SQL, you have connection strings that needs to be updated. Or, um, you know, our ORM, all of those things are transformed by AWS transform. And that, that actually like, you know, it saves application developers a lot of time because they don't actually have to go work with multiple DB teams to try to figure out like what's the scheme updates happen so it it reduces a lot of back and forth. OK. So one of the things that we ask for is a feature branch where we would commit those code changes for your application, so that your original source code is not updated. All right. So in this case, we would basically like select and all the transformation reports are available. And finally, the, you know, Essentially Yeah, deploy the stage and you would use a deployment connector to make sure that like we're deploying it to the right AWS account and with that essentially you can set the target um whether you want an ECS or EC2 instance as your target and you can select those parameters and once that is sent we will basically like deploy those uh applications into those accounts right and now you have a full at the end of it. You have a fully validated mechanism where you can have apps that are transformed to your postcres. You have a postsCres database with your converted schemas, and you can combine them together and run through validation, right? Like, so that's, that's the powerful functionality that you have in a single workflow here. All right, that concludes the demo, and I was able to show through a, you know, like a high level of how it works, and now we will show you like under the hood, exactly like, you know, what we are doing so that like, you know, you have more comfort in terms of what we're doing as a service. And for that I'll invite Vijay. Thanks for the demo. Um, as you've seen how the product works, uh, I wanted to take this opportunity to talk about how our service works under the hood. Uh, before I get started, quick show of hands, how many of you have experience working with agents, agentic systems, MCP tools, uh, quite a few, right? So this should be, this should be pretty easy. So, And under the hood, uh, all of this. So this is a complete agentic AI solution that comprises of dynamic and goals seeking agents. The center of this multi-agent framework is Windows modernization agent, which acts as a brain orchestrating the entire workflow end to end. Um, it uses something called connectors, and these connectors act as a bridge between customers resources, AWS account, and the agents, right? So there, uh, there are 3 different connectors that, uh, agents primarily use. The first one is the source code connector, which acts as a bridge between the source code repositories and the agents. Um, the, the source code connector under the hood relies on the AWS service called Code Connections, which provides a safe and secure way. For the agents to interact and download the source code reposit download the code from source code repositories. Then we have a database connector. Um, the database uh connector is configured with all the rules and permissions that are needed to access databases in a customer's account, uh, discover them, assess them, uh, transform them, and it also has access to all the secrets using which the agents can connect to both the source, uh, database as well as the destination post SQL database. Right? And then there's also a deployment connector that has all the rules and permissions that are needed by the agents to spin up instances, spin up EC2 clusters, build the application, transform and move all the transform binaries into these uh uh ECS clusters and actually run them, right? So, the orchestrated agent also has access to a few specialized agents. Um, uh, some of them are like the assessment and planning agent. The responsibility of this agent is to assess customers' portfolio, to figure out what applications are running, what databases they're talking to, and generate a dynamic plan. The plan is basically customized based on what these agents are finding in customer's environment, right? Depending on the version of the applications, how many databases they're talking to, for instance, right? And then, the, uh, once a plan is built, the schema conversion agent is primarily responsible for, uh, uh, um, migrating all the database objects across, convert the SQL Server database objects like tables, stored procedures, views into the Postgress uh uh equivalent versions. And Um, we also, uh, the, the orchestrated agent agent also has access to an MCP tool, uh, which does all the data migration. Once the convert, once the schema is converted, then the data can be migrated from source to destination. Then there is a core transformation agent, which primarily identifies based on the nature of the applications, uh, the, the underlying frameworks that are used for queries, and then transforms the The SQL query based on how the objects were converted, transforms the code and then commits it into a specific branch, right? And the deployment agent is capable of taking this code, uh, building it, uh, launch necessary EC2 instances or ECS clusters based on customer preferences, and then copy this binary across and then build, build up, build and run the application. So, uh, uh, the system is completely, uh, urgentic. All of these agents and tools come together to basically make the workflow dynamic, um, right, uh, based on the nature of the applications, the version of applications, the number of databases they're talking to, uh, the plan is catered, uh, and the plan is generated based on the customer preferences. And all the interactions that customers have with the system are led through chat. The orchestrator. Has access to a chat agent which enables customers to provide natural language queries and like, you know, provide the necessary answers to them. So, the, the chat agent has access to an underlying knowledge base, which encompasses all the AWS knowledge as well as how the job is progressing, um, all the reports that are generated through the process, any errors the system runs into, all of that is. It is committed to the knowledge base so that the chat is able to provide guidance to the customers on what the next steps are, right? So it has access to some of the common errors that customers run into and whenever there's an issue or an error, it can provide guidance on how do you unblock yourself so that you're able to move forward, right? You don't have to go ask. Chat is pretty, pretty interactive. It provides, it knows where you are in the system and what you need to do next and provides you the necessary guidance. And the, the workflow is completely composable, um, based on customer preferences, right? You want to migrate data, you don't want to do that, you want to do deployments, or you want to take control of the deployment process. The, the, the entire moderation journey is custom is customizable. And, uh, even though these agents are capable of making decisions, uh, they also provide visibility of what they're doing and provides ability for customers to inspect and interject as needed and control the overall modernination process through Hits that it generates. So now, as we've looked into the overall system, let's dive deep into each phase. The first is assessment. The assessment and the planning agent have access to the source code repositories and databases. They use the source code connector as well as the database connector to first validate that all the prerequisites are properly set. Um, in case any prerequisites are missing, uh, through chat, it interacts, it, it tells the user on what the missing pieces are and how to fix them so that the job can be successful, right? And once the prerevalidation is done, It does a discovery. It goes and identifies what are all the applications that are configured in your source code repositories, and it also goes and discovers all the databases that are running, and then tries to do a mapping between which applications are talking to which databases. And there are a few ways in which this is done. Um, the agent tries to parse the source code and then figure out if there are any connection strings configured, um, or are there any environment variables that are set up in pipeline that can help identify which application is dependent on which database. In, and then it also has a fallback logic where it tries to identify the database objects that are referenced in code. Like for instance, stored procedure names, view names, or table names that are being used in code, it is able to go detect that in your source code as well as uh detect that in your databases and then kind of create a cross mapping between these two. And then it creates logical units, a logical unit of like dependent applications and databases that should be transformed together. Right? And once these logical units are formed, uh, the agent, uh, tries to determine the overall complexity of transforming this logical entity from SQL to Postgress. Uh, there are different factors it uses, uh, the factors like, uh, how, how big is the source code, right? The line, the lines of code, um, as well as the number of objects that are present in the database, um, uh, how Compatible they are between SQL and Postgress. Based on this, it tries to compute a score, and then once it computes a score for each of these logical units, it creates modernization waves, um, uh, each wave comprising of a logical unit of dependent applications and database together, uh, databases that should be transformed together, right? And this, uh, this, this agent, uh. The system being completely genic also gives an opportunity to the customer to express their own customers preferences on how they want to transform the order in which they want to do them. They can express that through natural language, and the agent kind of goes in a loop adjusting the wave plan based on the user needs. And once that is done, And throughout the process, a lot of assessment reports are generated, uh, and if, if, if the, the, uh, the agents are running into any errors, all of that data is consistently stored in the knowledge base, so that the chat agent can continue to tell the user on what to do next or how to unblock themselves. Once assessment is done, the conversion process starts. Um, there are 3 steps in, uh, in, uh, uh, converting uh uh SQL database to its, uh, PostSpace counterpart. The first, the agent uh uh connects to the source databases, fetches all the networking information, figures out, uh, figures out what are the uh uh roles that are needed to launch the target database, uh, based on the networking information it, it, it, it gathers from the source, um, it creates a destination cluster and configures the Pores cluster so that the agents can talk to them and then, like, you know, create all the database objects. Once that is done, um, uh, the, the schema, the, we use, uh, the orchestrator uses a schema conversion agent that actually starts the conversion process and converts tables, views, and stored procedures into the post-risk counterparts. Um, and it, like the, the agent is also equipped with The some of the complexities of this conversion, some of the common errors that customers generally run into, and it has examples on how to fix them. Using these examples, it goes into like a self-debugging loop, trying to generate the required object, validate it, and if the validation fails, regenerated based using LLMs until, until the validation is successful, right? And the way the validation works here is the, once the corresponding Pogress objects are generated, it does syntactic validation, so that the created objects are compatible with uh what what Posgress expects. Right? And during this process, it also generates a mapping file, a mapping of what were the source database objects and what were the converted database objects. This mapping is important for the agent to also update the corresponding query in, in queries in source code. So once the schema uh is successfully transformed, Uh, there's an optional step. Um, uh, the orchestrated agent has access to an MCP tool, which under the hood uses database migration service to move the data from SQL to Postress. Right? So once the, the, the database conversion is successful, the, the orchestrator starts the code transformation process, and the, uh, for the code transformation agent, it uses the application source code as well as the mappings that were generated between the source and the destination database as uh primary inputs, right? And there are different patterns in which Applications can interact with underlying databases. Uh, the most popular patterns are using either Entity Framework or if they're older, uh, old, older projects, then they typically use ADO.NET. So, the, the agent, based on what it figures out, if an application is using Entity Framework, um, then the agent is capable of, uh, uh, understanding how the frame, how the application is built. Update the corresponding entity bindings for them to work with the destination database. Before any, and this is also an iterative process. It uses LLMs to figure out what changes need to be made. There are different ways in which entity framework can be configured. Some of the popular patterns are either using annotations or APA invocations, or there are also XML binding files, XML configuration files that have information about how these bindings are maintained between the source code and The database, right, and the agent can figure out these patterns and automatically update the code to make it compatible with Postress. And once the validation is done, and let's say if in case of applications that are relying on ADO.NET, the agent parses the code, identifies the corresponding SQL queries, extracts them, and it first uses a rule-based engine to transform these extracted queries into Pogress, and then it also falls back to an LLM-based model where it it generates postgress queries, validates that the queries are accurate. Data and are working in the same way. The validation is two-phased here. It first does a syntactic validation to ensure that the query is syntactically correct, and then it also does a functional equivalence validation where it relies on formal verification mechanisms to ensure that the query that is generated in Postgress is functionally equivalent and is generating the same kind of outputs that the SQL query is generating. Right, And once the transformation is complete, the agent has now done validation on the queries that are transformed. It also has to ensure that the corresponding the surrounding .NET code is working as expected, right? And for that, it does a .NET build of the application once the queries are replaced, and uh if the build fails, it goes into a debugging loop where it tries to fix the error, fix build errors, uh, generate new code, and then retry the process until the build succeeds, right? And in this process, um, if the agent finds that there are unit tests uh associated with uh source code, it also builds the application and then runs those unit tests, and once they're successful, it commits the transformed code into a new branch. So once the code transformation is complete, then the deployment process kicks in. Um, the deployment agent primarily takes the uh transform source code from the target branch, launches an EC2 instance, and it builds the application. And once the application is built based on customer preferences, it either launches an EC2 Linux instance or it launches an ECS cluster configure set, uh, uh copies the built binaries into these and brings up the application. And then it also does a couple of validation steps to ensure that the application is up and running. First, it does a health check whether the application is reachable. And the second thing, it also does a connectivity check between the application as well as the underlying databases so that customers can continue to test using either an automated test suite that they have. Or manual testing that they can do, right? This is an iterative process where continued where customers can continue to check out the code, make corresponding changes, commit commit it back to the branch. Agent always picks up the latest code, builds the binaries, and copies them back to the launched EC2 Linux instance of the ACS container so that customers can continue to test this. So, this is a high-level overview of how the Windows FullStack modernization works, and to talk more about like um um based on how customers have been using so far, how using the system so far, and the feedback that they have, uh, Khuram is gonna talk about that. Thank you BJ for uh. Uh, two things which I want to highlight. One is that this full stack modernization is available for SQL, which is hosted on EC2 Linux and the RDS today. And second, which is a more important part, is this service is available at no cost to you. You don't pay for using these agents. You only, uh, basically pay for the resources which you use like the EC2 instance or posts cluster, but the whole agentic workflow, the access to it through, uh, the AWS transform is at no additional cost. Hopefully, that kind of gets you excited to try it out, OK. And uh take the first step, next step. Uh, uh, based on our customer feedback and what we have been working with, and Veris is one of them, which has been, uh, in the industry, uh, insurance industry providing technology, uh. Um, solutions to the customers, so they expect that with this combined full stack modernization they can really see the, the output accelerating their modernization timelines by 4x with the chief of achieving the cost optimization of about 40%. Teamfront, another customer who had a really, ah, they have been an early adopter of AWS Transform for .NET. They, they were able to transform their monolith application from framework to core. They even participated in our beta for UI based uh transformation, were able to take their web forms to uh to Blazer, and they're now looking at the SQL to work together to do the complete modernization which will help them do the full stack modernization as a, as a combined step instead of multiple steps. And Common Commonwealth Bank of Australia, again, they are looking at the overall transformation of how they can accelerate it, and with AWS transform, they see a path which can help them achieve their objectives instead of years and months and years of effort. We've been working with our, uh, some of our key, uh, some of our launch partners who have been helping us out or working together with us on the database migrations in the past and Kalin Technologies, Presidio evolved tech Systems. And the key thing which we hear from them is that bringing together the code alongside with the database modernization is something which will help them accelerate work together with their customers in a more effective and more optimized manner instead of uh moving across multiple steps of the transformation across different personas. From our point of view, from our request is These scan those QR codes, go to AWS Transform, understand more. There is interactive demo you can. Uh, look through it, how exactly it works. Uh, you can have more, uh, specific, uh, sessions on this one. There is a workshop. There are a couple of workshops which we'll be able to, we will walk you through each and every step and how exactly the, the full stack modernization or the, the .NET code as well as the SQL transformation works. Attend them. Get your uh experience on it. If you want to get more in-depth ah in-depth information, you can go, if you scan the QR code and look at the SkillBuilder to get trained on it. But ultimately, we are here to work with you. So, any feedback, any comments, anything which we should be doing better or we should be able to uh help you address. Reach out to us. We are always available and we will work backwards from your request. Thank you, and we will be able to now take questions and uh. Listen, thank you.