---
video_id: JQ2wQFTszsQ
video_url: https://www.youtube.com/watch?v=JQ2wQFTszsQ
is_generated: False
is_translatable: True
---

Hello everyone. I'm Ora Lenner. I'm the CEO of Bright Data, and today we're gonna talk about something that sounds trivial but actually it's not. It's intelligent models versus knowledgeable models and what does that mean? So it's been exactly 3 years since the launch of ChaGPT 3 and that magical moment. To me, the magic continues. I keep working with these tools like everyone else here. And we're experiencing this same magical moment only almost on an hourly basis when we're using the tools, right? It's super intelligent models. They know everything about the world. They actually answer very complicated questions. They're winning gold medal, uh, in, in the meth Olympics, so their intelligence level is extremely high. By definition, the models that we're using today are the smartest the world has ever seen, and their next version that might come up tomorrow or the next foundational model builder that we might launch their model in a week by definition will be smarter, so the intelligent level keeps on growing and expanding and it's just magical. However, all of you know the feeling that you're using this intelligent model. And at the same time it can be, I don't have any other better word to use, extremely stupid on various things that you actually want to achieve on just a daily routine, you know, buying something on just asking something simple that every 5 years old can answer, but if it's lacking the knowledge, intelligence is not enough, and this is what we're going to talk about today. And we're going to look at it from the data perspective. Pausing this thought for a second, I want to introduce briefly Bright Data and kind of show you the reason that or, or, or the, the, the ability of Bright data to look into this um intelligence versus knowledge and model ecosystem and our unique position into, into the AI industry. So Bright Data serves 20,000 customers today that are obsessed about getting the data they need that they need from the public web in order to do various things including AI. So this includes most of the large language models and foundational models and pretty much every other AI company that builds on top of the, of these models and they, when they need data for training or even data for real-time. They come to us. It also means that the largest e-commerce platforms that needs to understand what's going on in the world and be competitive when you're coming to their website to buy something are also using our infrastructure to get web data. Same goes for financial services. Think of the largest American banks that need to get smart investment decisions. They need data for that. Cybersecurity as well, to find a threat in this huge ecosystem of the World Wide Web, you actually need to collect a lot of data. And many other industries and vertical news cases that all need web data. This creates massive scale. We see roughly 50 billion web pages a day. Our customers are using the Bright Data platform to collect data from this huge amount of internet on a daily basis. That's 3/3 times more of all of the Google search queries globally, worldwide, every single day. So the scale is massive. And it's not an easy thing to do. We invest a lot in research and development and considered to be one of the leading companies in the world when it comes to different technologies around web data collection, web scraping. We also keep a very large portion of the internet that we're seeing, and we are increasing our web archive that just passed 450 billion webpages and growing very, very fast. And to do all of that we have the largest known um pool of bots that are actually using and browsing the web every second of the day to collect this information. So when we are talking about AI in the form of or in the sense of data, we know what we're talking about because we are the largest vendor for the AI industry when it comes to data. Now When you want to build an intelligent model. You need 3 major ingredients and that's kind of obvious today for everyone, right? One is very smart people to ride the sophisticated algorithm of the large language model. Then you also need a lot of compute to train the model and obviously you need a lot of data to feed those massive clusters of GPUs that needs to train the model. Now, the trends that we're seeing as the largest web data provider for this industry. are as follows we see that on the Algorithm side, the open source and open weight models are already in par with the closed source closed weights models, right? So you will get almost identical performance on almost all of the evil tests out there when you compare open source open weights to closed source close weights. In addition to that, we see that training is becoming cheaper. It's not just the cost of acquiring the compute and the GPUs, it's also what you can do today with previous generations of GPUs, but also the cost of energy and the cost of cooling, which is essential to training large language models, is decreasing and actually it's, it's going down pretty fast. So if the starting point to train new models is actually easier than ever before, I'm not saying it's easy, but it's easier than ever before. Then what we're seeing as a data company is that the data becomes the major mode. Because if you can all get the same compute and use the same open source, open weight models, then the data matters the most. Now, with that background of our scale and what we're seeing and the fact that we're servicing the vast majority of the foundational model builders, let's get back to the subject we started with, intelligent versus knowledgeable. LLMs. Now, an, an, an analogy I like to use is physics. Can a theoretical physics prove a new phenomenon? Just think about the brain of a physic. The answer is no. What they can do is describe the new phenomenon. They have a theory. They can describe it. They can propose and develop theories and models in order to prove or disprove this theory. But it stops there, so they can be very, very smart, very intelligent, but it stops there. What they can do afterwards is work with their colleague that experimental physics. To run an experiment in order to provide evidence and prove or disprove this new theory or this new phenomenon. LLMs today works the same. So using the same analogy, I'll ask a different question. Can an LLM purchase the right product for you today? And we'll also talk about the future. But today it's very, it is very intelligent and sophisticated model that you can use, the answer is no, it can't actually do that simple task of, let's say, buying milk that you can pour into the bowl of cereals that you want to eat tomorrow morning in your breakfast. It just can't do that. So today the models are more like the theoretical. Physics And they're still lacking that knowledge to actually do that experiment in physics, but in the real world to buy that carton of milk so you can eat your cereals. So, if it doesn't have the real-time price, just one example of a crucial piece of information so that for you to use the model to make it both efficient, smart, and useful for you, then it's not there yet. And as the Internet, that World Wide Web, last 30 years of information that was, you know, built by the largest tech companies out there and all of the data that is generated is becoming that infrastructure layer for the new Internet, these chatbots that we're all using, we see two major trends that are taking shape in 2025 and. Something big is gonna happen in 2026, which is only a few weeks away, and we're gonna cover that as well, but what we're seeing is that everyone is consuming as much data as they can to build the most intelligent models and if this graph represents the usage growth. Of data for training, you can see that it is growing and it's not gonna stop growing. However, it is growing in a linear manner. And you already have these very sophisticated intelligent models, right? So let's use this example of milk again. These models can tell you everything about the ingredients of the milk. They can tell you about the class action lawsuit that the milk company got 10 years ago and what was the outcome. They're perfect for that, but what we're seeing now is an absolute explosion and an exponential growth when it comes to real-time data to add also the knowledge layer on top of the intelligent layer to also tell you what is the price of the milk, not just everything about the ingredients of the milk. This is not a vision, this is what we're seeing from our perspective as the largest data vendor for this industry. And OK. Got back and we're seeing that not just in milk obviously everywhere just think about the world around you think about what you're doing every day. You wanna know everything about the Las Vegas sphere but also you wanna go to a show so the intelligent layer of the model will tell you everything about the construction of the sphere and how much it cost and who was the construction company. And everything you wanna know about it, but to buy a ticket to tonight's show in the sphere, you can't do that unless you're adding the knowledge layer and giving it to the uh uh allowing the LLM to access that layer, and this is the current trend that is starting to take shape again, it's not there yet, but this is the trends that we're seeing adding knowledge on top of intelligence. Now I took um a very um popular evil test that is working specifically or testing specifically reasoning and knowledge, exactly what we're here to talk about. And you can see all of the models performing one way or another. And for this event I was focusing on the Chat GPT open source 120 billion tokens that everyone can use and test as an open source tool and what we're gonna see now. is an example for using only that intelligent and again very intelligent. In this case, the open source of GPT. But lacking that knowledge layer, and that will be on the left hand side. On the right hand side, we will see the same model exactly using that knowledge layer. In this case, the bright data MCP. So giving that open source LLM access to real-time information from the web. Let's take a look. It's a bit hard to see from far, so I'll explain. We are asking about salaries from Glassdoor in different companies. We just wanna know that because we wanna recruit on the left hand side without access to web to, to real-time web data. The model kind of says in, in, in a very apologetic way, sorry, I can't get this information. So actually completely useless. I just got the most sophisticated model out there. That is completely useless for a daily task that I want to perform. On the right hand side with the bright data MCP, it actually got you a complete table with all of the information you wanted to get everything, the salaries, per position in different companies. As a human, you can do it in 5 minutes, but taking that super smart model that can win a gold medal in math Olympics, you just can't do that without that knowledge layer that gives you access to the web. We're seeing by working with these companies that in 2026, the the knowledge layer and the intelligent layer are gonna merge. This is something huge for us, for humanity I would even say, because this is where it is actually going to automate everything that we're doing. It's not gonna happen in one day. But you're starting seeing that in e-commerce, in travel, when you're not just using these models to plan your, your trip or you're not using these models just to um ask a question about the product. We're starting to see and sense the ability of actually getting the relevant real-time information like the availability of the product, the price of the product, the shipping time of the product to your location. Or the price of that flight or hotel room. And again, from our perspective, from the data perspective, we're seeing that in 2026, this is going to unlock a huge Huge opportunity for everyone who's working on AI with AI and just for everyone in the world who is using these tools because when you combine knowledge with intelligence, It's really unlocking everything that we're doing as humans. It, it can and will replace a lot of the tasks that we're doing on a daily basis that you don't really need to put in effort anymore. You can use your time doing other things. I'll finish by Inviting everyone again to our very Cool and interesting and unique event tonight in the Battlebot Arena. Um, you can visit our booth right after this call and the talk and take, uh, all the details and we'll see you there in a very exciting, um, bot event. Thank you for joining.