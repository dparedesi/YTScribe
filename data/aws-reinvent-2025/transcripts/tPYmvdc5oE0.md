---
video_id: tPYmvdc5oE0
video_url: https://www.youtube.com/watch?v=tPYmvdc5oE0
is_generated: False
is_translatable: True
---

So, my name is Nathan Perry. I'm a senior cloud FinOs architect on the AWS optics team. And I've spent the last 11 years at Amazon helping some of our largest AWS customers build modern and scalable approaches to FinOops on the AWS cloud. For the last 5 years, I've worked with Amazon and all the Amazon lines of business as an AWS customer. So if anyone's ever had like a challenge explaining what they do to their friends or family, um, double that for me because I work for Amazon, but my customer's Amazon, and so it kind of breaks my parents' brain, right? Um, but the idea is that I help Amazon understand how to operate effectively in the FinO space, lower cost, work on cost visibility, cost allocation, right? And so I'm here today to share um some of the lessons that I've learned um in the last 5 years working with Amazon on this. So I want to share 3 key lessons, um, from our modernization journey, um, that can help you accelerate your FinOps practices. First, Building on AWS billing and cost management services for your foundation. 2nd, driving efficiency through business aligned mechanisms. And 3rd, scaling your FinOops practice through intelligent automation. So whether you're just starting your FinOps journey or you're scaling up, these insights are intended to help um move faster as you integrate your financial management systems with AWS billing and cost management. So Let's start at the beginning, to set the stage. Amazon and all of our lines of business operate on AWS. Shocker, right? Um, so just like many customers, Amazon had to learn to operate in the cloud, and more specifically how to build a really comprehensive FinOps stance, with the only caveat being, you know, enormous scale. So we started with a data foundation. Our FinOps journey started with custom financial reporting that provided monthly views of our cloud costs. Today we're working on transforming that foundation using AWS data exports, AWS cost and usage reports or CR, and then other AWS billing and cost management services. We're moving away from visualizing cost at a monthly grain or an account grain in favor of ARN layered, uh, I'm sorry, ARN grain and hourly grain. We're democratizing our cost data, and what I mean by that is Very often, cost visibility can be siloed. It can be owned by FinOps teams or finance teams or operations teams. We're putting this in front of all of our teams, our builders, our leaders, our finance, our FinOps teams, right? So building on this Kerr Foundation, we're enabling Cost Explorer across the organization to allow self-service cost analysis and enable more real-time decision making. We're deploying organization-wide tagging strategies that track investment and provide better fine-grain cost controls organization-wide. Um, and we're integrating this with C and AWS features like compute optimizer and AWS cost optimization hub to vend efficiency opportunities at scale. This represents a bit of a shift for us from some of the centralized reporting to a more distributed model of cost intelligence. And we're also leveraging AWS organizations to help establish consistent controls, um, and it provides an aggregated tool set across all of our account footprints, like a unified framework for our entire AWS footprint. So remember that building on AWS services allows our teams to focus on driving business value rather than simply having to work on analysis, right? So with this foundation in place, let's look at how we approach efficiency and how the integration of business-specific data helps play a part. So the next challenge that we encountered was in driving widespread adoption of our cost management practices and in integrating these into uh like to run more efficiently in the cloud. Um, our key insight that we discovered was to make it as simple as possible, um, to connect cloud costs to business outcomes at the team level. So we started by taking data and trying to make it more insightful, right? We combined two critical elements, granular costs from cost and usage reports occur. And business metrics that teams actually care about. Um, this allowed Amazon and it will allow you to see, uh, not just how much you're spending, but what you're, you know, what you're getting for each dollar spent. So, 2nd. Integrating business context. The key for us to driving adoption was connecting costs to business outcomes for our teams. We've included accounts and tag-based cost allocation to business context, investment tracking, and we're automating return on investment analysis with AWS cost management services as this foundation. And we're working to simplify cost visibility. So for instances where the democratization or availability of Cost Explorer by itself is not not enough for a team. Um, we're leveraging the AWS cloud intelligence dashboard. Um, if anyone hasn't, is not familiar with the cloud intelligence dashboard or the CID, it's an open source framework, um, that was built to provide AWS customers, you know, very actionable insight and optimization opportunities at really any scale. Um, an example is Amazon's budget data, right? So we nest AWS service-specific budget data against actual AWS usage. Um, and this allows teams to see, uh, budgetary variances. So finance teams or operational efficiency teams can step in, um, if, if an individual builder team or a larger part of the organization is having challenges, if they need to work on cost reduction initiatives, or if they need to revisit their budgets or their forecasts due to changes in business needs, right? So we use the CID to integrate that contextualized business data alongside AWS infrastructure usage. And we create roles specific views um that enable even more in-depth service analysis by our teams. Um, they can now answer their own questions in a lot, like a lot more strongly. So, you know, I found having conversations with builders very challenging because without that visibility, it's like everyone is expected to be a finops expert and. You know, we just really can't expect that of our engineering teams, right? We want them to build, and we want the monotony of FinOs to land on our shoulders because we're the FinOs practitioners in the room, right? Um, so here's a real world example. Um, when a team sees a cost spike today, they can identify the accounts, the services, the resources where it originated, right? They can visualize the business impact by, by looking at that alongside uh metrics like revenue or budget. Um, and they can tie it to an individual or initiative so that they can take immediate action. Um, so now that we have teams engaged, um, with this cost data, let's look at how we're incorporating efficiency into that mix. So while costs of visibility is crucial, And honestly, it's probably the thing I'm most passionate about. Um, driving efficiency really requires mechanisms that can measure, monitor and improve resource utilization, um, at full scale. So here's how we evolved our approach to efficiency. The first thing was realizing that efficiency is not one size fits all. Um, in the early days of our AWS adoption. We recognize the need to provide efficiency reporting to Amazon teams. Um, Amazon has a pretty well-known culture of efficiency, um, you know, with our frugality mindset, and that's really baked into how our builders operate, but that alone wasn't enough to really enable efficient usage of the cloud. So we started by measuring the basic resource utilization metrics, right? Um, CPU utilization, uh, memory usage patterns, um, network throughput, right? Across all of our teams, and we quickly learned that efficiency was not one size fits all. Different workloads required different approaches, and um the version of good that that translated very well for a team like Amazon retail wasn't necessarily the same version of good that translated to teams with very different workloads like Alexa or Prime Video, right? So we needed to build central efficiency mechanisms and we needed a line on how we could get as close to perfect in terms of these centralized efficiency metrics as we could. We built mechanisms to track business specific efficiency and monitor resource utilization against this like centrally agreed upon ideal. And again, this wasn't universal, um, but for the lines of business that it held mostly true, we saw very significant gains in efficiency and cost reduction really right out of the gate. Um, we created a, a metric called the credit score, um, and so our credit score, um, it essentially measured resource efficiency across lots of different, um, services, and it was an iterative way to basically continue honing this ideal of like a central baseline, um, while, you know, while iterate while continuing to build on what that version of good should look like, what the North Star is, right? So, um, our teams using graviton. Is usage aligned with central efficiency campaigns around um you know, capacity utilization or storage class optimization? Is it aligned with um how, how like the business data that you're pulling in like revenue or your budget data, is it correlating to that? So all of these were included in this formula that allowed us to measure essentially the FinOs maturity of all of our lines of business. And it allowed the mechanisms to really help teams optimize and save. Big dollars, large dollar amounts. So here's an example of how it would work in practice, right? Teams would receive a weekly efficiency score, um, and it would provide cost recommendations that could be reviewed and prioritized by their level of impact. Teams were able to group these recommendations by things like technology category, storage, compute, generative AI database, network, right? Um, and then they could see them on accounts, on teams, they could associate them with owners. All stakeholders in the cloud cost life cycle could see the opportunity and where it sits, right? So finance teams, um, leadership, technology owners, or, uh, operational efficiency teams, all of them could view this data through the lens of their own respective disciplines, so they could see it in a way that made the most sense to them. So, Now that we've established our efficiency mechanisms, um, I want to talk about how automation has been helping us scale these practices. At Amazon, we've learned that true cloud financial management is not a series of isolated tasks. Um, it's a continuous intelligent cycle. Um, by integrating AWS services with automated workflows, we're working to transform what was once a very manual and reactive process into more of a self-improving system. So Starting with this concept of an intelligence cycle. Our journey, which is still in progress, right? Um, towards automating FinOs, it started with a really simple goal, which was just give the teams better visibility into their cloud costs. Through continuous iteration, we're working to create systems that have deeper insights into infrastructure spending patterns. So where teams once spent hours, you know, on manual analysis and spreadsheets, we're introducing automation into key processes like financial planning. Each improvement works to feed back into this learning cycle, and it's helping us enhance our capabilities and move closer to our vision of intelligent cloud financial management. Effective finops automation starts with really comprehensive usage of trends, budget variant, uh, capacity requirements. When optimization opportunities are identified, teams receive notifications, and they receive these through their own preferred channels. Um, for well understood scenarios, teams can define policies, and they can define thresholds that trigger automated responses while maintaining appropriate controls over more complex decisions. Um, this balance between automation and oversight is super important and it's crucial to building trust and driving adoption. So on the topic of trust. The key for us to scaling FinOops wasn't just technology, it's building trust through very consistent transparency. Every action, whether it's automated or whether it's manual. It has to be logged. It has to be tracked in detail. Teams need to see exactly what's happening with their infrastructure costs and why. This this transparency first approach has been really crucial in driving adoption of all the automation and the planning capabilities that we use across Amazon and all the Amazon lines of business. Particularly in retail, um, where we've seen the impact of combining human insight with automated analysis. So Starting a FinOops automation journey doesn't require building everything at once. Um, begin with AWS services as your foundation and focus first on gaining visibility into your costs. Then gradually automate, you know, very well understood processes. Um, like, in our case, it was our financial planning and our OP one cycle, right? Um, planning and capacity management were big for us. As you build trust through transparency, um, and you have results that can back that trust up, you can expand both the scope and the sophistication of your automation. Um, our goal, um, and it's important to remember this, wasn't to like remove humans from the mix. Um, it was essentially to elevate their role from, you know, routine analysis to more strategic decision making. So, now that I've talked about how these 3 pieces fit together, visibility, efficiency, and automation, I want to take a look at how you can build your own FinOs roadmap. Throughout this section I've droned on about various aspects of cloud financial management. Um, so let me share something that I find pretty powerful, you know, specifically how these pieces fit together to accelerate FinO's journeys of, you know, different sizes. Every successful transformation starts with a solid foundation. We begin our journey with everything custom, our own tools, our own mechanisms, our own processes. And what we discovered. Was that AWS billing and cost management services now provide better visibility than our custom solutions really ever did. The AWS cost and usage report gives the granular data that our engineers and our leaders really never knew that they needed. Until they saw it, they didn't understand the power of that fine-grain cost control. The AWS cost and usage report gives, I'm sorry, um, Cost Explorer puts analysis capabilities directly into our team's hands, and organizations lets us implement, um, governance at massive scale, whether we're managing dozens, thousands, tens of thousands of accounts. But data alone is not enough. We learned that lesson the hard way. Real transformation for us happened when we connected business outcomes to our cloud cost. Um, you know, think about it. Knowing you spent $100,000 on compute or storage, um, that's important, it's a helpful metric, but understanding that that $100,000 attributed, uh, can be attributed to like, you know, a million dollars in revenue, um, that's something that's very actionable. So that's where the AWS cost intelligence dashboards come in for us. They don't just show costs, they show team level value. Everybody is able to see the metrics that matter to them in their language, aligned with their goals. And so, you know, what began as uh like an internal efficiency mechanism has evolved into features really that can be implemented by anyone today. And automation. Imagine moving from monthly cross reviews to daily optimization actions. We're not talking about just alerts, we're talking about intelligent systems that detect anomalies, recommend optimization, um, and even implement improvement automatically. Teams that once spent hours analyzing spreadsheets now focus on strategic decisions while automation handles a lot of the routine. Um, and this isn't just about saving time, it's about operating at scale. I wanna make this concrete. 3 years ago, we were where so many AWS customers were or still are today. We were juggling multiple tools. We were wrestling with manual processes and we were really struggling to get clear cost visibility. Today, we're integrating AWS services and we're automating insights. Looking ahead to 2026 and into 2027, we're enabling AI enhanced optimization, predictive actions, and we're automating capacity planning. The part that is the coolest to me is that this evolution is not years away for anybody that's trying to embrace it today. The capabilities are available right now. So the acceleration path starts with 3 clear layers. First, Laying your data foundation. Enable the cost and usage report, implement a solid tag strategy, and get comfortable with tools like Cost Explorer and Cost Optimization Hub. This gives you the visibility that you need to move forward confidently. Next, build your integration layer. Deploy tools like cost intelligence dashboards to connect your business metrics and enable automated recommendations. This helps turn data into business intelligence. And finally, Activate your optimization layer. Implement efficiency recommendations. Enable controls for transparency and automate response actions. This is where Finn's practices become really scalable. So remember how we started talking about the Dunning-Kruger effect? When Amazon started our FinOps journey, we really thought that our expertise in building custom solutions and tools was our greatest asset, and it gave us a very like false sense of confidence in terms of how successful we were going to be right out of the gate. What we learned and what I hope you all take away from this is that um often the fastest path isn't necessarily the obvious one. It, it requires that we challenge our assumptions. Um, and while Amazon's scale can seem daunting, and it still does to me at times. The principles that we've learned work for organizations of any size. Start with AWS billing and cost management services. Build mechanisms that matter to your business units and automate intelligently. What we found is that, you know, the smartest choice was really the simplest one, and it's not what we started with. Um, that choice is something that you can use today to scale your own organisation's approach to cloud financial management. So thanks everybody. Before I leave, I want a quick plug for One Amazon Lane. If you haven't been to it in the Caesar's Forum, it's in the southeast corner, but it's a very cool interactive exhibit to put hands on, a bunch of really cool Amazon tech. Um, thank you all for your time today and um enjoy Green Bay.