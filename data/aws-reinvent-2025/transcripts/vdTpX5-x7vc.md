---
video_id: vdTpX5-x7vc
video_url: https://www.youtube.com/watch?v=vdTpX5-x7vc
is_generated: False
is_translatable: True
---

OK, so before we get started, I want to touch base a little bit about what is multi-channel marketing and uh what does it, uh, what are some of the challenges that are associated with multi-channel marketing and how ANT AI can help in solving some of those challenges, so. Multi-channel marketing is a customer-centric marketing strategy where you're providing seamless integrated experiences to your customers at the touch points where they are interacting with your particular brand, and at the same time you need to ensure that there is consistent messaging across all these channels that they are interacting with your brand. So let's take a look at some of the challenges that come with it when it comes to automating multi-channel marketing and how agentic AI can help, and I will cover what does agentic AI mean, and how we evolved into agentic AI, and all those details in the upcoming slides. So first, let's look at the business problem. So the first challenge with multi-channel marketing automation is associated with the workflows that you need to orchestrate. There are different customer journeys. There are multiple channels. There are different touch points for your customers. And how do you ensure that you have this overall workflow? deployed in a way that it is flexible enough with traditional workflows, they're kind of too rigid and they're like sticking to a particular script, but whereas when it comes to agentic AI-based or agentic AI enabled workflows, you will have the flexibility to have multiple agents coordinating with each other in real time, and they can even have like specialized agents that are built for specific marketing channels. You can also have a dynamic workflow. Let's say your customer responses and behavior is a little bit different than what is expected. The agentic AI-based workflow can adopt based on your customer behavior, and you can also have cross-channel context preservation, and you can deliver consistent messaging across all these channels that you're trying to reach them on, you know, whether it be email, SMS, you know, online, you know, web personalization, social media, and so on. Then there is the challenge of real-time personalization, whatever that you're delivering, the messaging that you're delivering to your customers, you know, personalizing to those customers. You have thousands of customers across multiple channels. When it comes to that level of that kind of a scale, gentic AI can definitely help in that situation with the traditional systems that they usually lack the ability to deal with those kind of things and the complexity that comes with it. So with agentic AI based systems you can have intelligent content generation. So depending on the particular customer segment and customer behavior and so on, you can dynamically generate what specific content makes sense for that particular customer and that particular channel. You can also do real-time decision making in terms of, OK, the customer is more interacting through email, you know, or they're more interacting on social media platforms. So depending on the kind of interactions that you're seeing and observing for your customers, you can switch between different channels as necessary. And you can also have brand guard rails baked into the AI agents themselves. That way you have that brand consistency and compliance already built into the AI agents and you don't have to worry about it. The next challenge is with, you know, with any typical enterprise, you know, you see these data silos, you know, data system across your CRM systems, your e-commerce systems, your data analytics systems, and so on and so forth, and looking at all this data in a holistic way and acting upon the data, the customer data that you that you have across all these systems is pretty complicated in nature. Where agentic AI can help is build that unified data point of view. You know, you can have APIs and MCP servers that are exposing the data from these individual systems, and agents can actually get all the data from these different systems associated with a specific customer and identify their behavior and the patterns associated with them. You can also have things like data cleansing, you know, there may be certain places where you need to cleanse data that is coming from your CRM system or some other system, or you may have to do some data mapping between different systems. All those things you can automatically achieve using AN AI. Then there is the speed to market and campaign agility aspect of it, right? So traditional, if you look at traditional marketing campaigns, they take a lot of time to set up, right, you know, whether it be the content generation, whether it be, you know, think of how to customize it, what are the target or segmented audience that we are targeting at that particular point in time, all those things, they actually take a lot of weeks of effort, whereas. By and by the time you would basically miss market opportunities, right? You know, it's gone, right? With agentic AI you can have natural language based campaign definition so you can say I'm trying to target. Audience that are like under 25 years of age who use Instagram a lot or you know some other social media platform a lot and living in California living in so and so city and you just provide the definition of the campaign in a natural language way and the agents will be able to understand that identify the right audience, identify the right content that needs to be generated, and so on. You can also have instant campaign optimization. So let's say your performance, the campaign performance data is coming through, like it is streaming, and you want these AI agents to look at what is going on and if you need to optimize then and there, you can do that. You can have that real-time campaign optimization in place. And then there is one of the biggest of the challenges is the attribution and ROI measurement across all these touch points. So it's not single touch points. So you have these emails that are going out, those SMS messages that are going out. They're interacting with your brand at a store. So there are so many different touch points at which your customers are interacting with your brand. So with agentic AI you can have that intelligent attribution modeling that accounts for all these different uh you know, touch points and all the complex customer journeys across all these touch points. You can also have real-time ROI optimization so you can actually see. Where or which particular channel is performing better versus other channels. So let's say your marketing campaign is targeted for like, OK, I need to send 10,000 emails and I need to target the same thing, the same campaign on like social media. A platform, but you are seeing more responsiveness on the social media platform versus the email so you can also quickly switch between channels so that it's much more optimized and you're spending the right money on the right things. You can also perform like predictive analytics. So even before you are executing your marketing campaigns, you can start by, you know, measuring what or or estimating what would be this campaign performance if I am executing across these channels, if I am targeting these particular audiences, how exactly this is going to, this campaign is going to perform, right? So all those things you can bake into your agentKI workflows. All right. So I did promise you that I will cover what does Asiantic AI mean in the first place, right? So, and how did we evolve into Asiantic AI today? So, on the left-hand side. Yes, on the, on the right hand side for you, you'll see the low agency systems, right? You know, these are traditional systems where they are completely rule-based and they require a lot of human oversight and on the extreme left, right side, you see there are high agency systems which don't need much of human oversight. So traditionally companies have usually started like around using rule-based RPI or robotic process automation, which are kind of rigid in nature. They are task oriented, so you say this is exactly the task I want to accomplish. These are the set of the rules, set of rules that are associated with this task, and they can only focus on that, and they require a lot of human oversight. And then came the generative AI assistance where. They know what they need to do for specific tasks. Humans are not significantly involved in that, but they still need some level of human oversight. You can just say this is the task that you're supposed to do, and they will do it for you. Think of it as some examples are like you can have this customer service chat assistants which are powered by. AI behind the scenes or intelligent document processing, you can just read through the document. It is supposed to just go through the document, understand what the document contains, and be done with it, right? So it understands what tasks need to be done and it will do it by itself, but you still have to define the workflow. You still have to tell that generative AI assistant what exactly it is supposed to do. And then came the goal driven agents, right? They, they're kind of the next level, and this is where we started seeing real business transformation, right? These things understand what is the business objective. You're not defining individual tasks anymore. You're basically saying this is my business objective now please go do this and. These agents are able to come up with the tasks, intelligent tasks that need to be executed, the workflow, the order, and so on and so forth, and execute those and accomplish those objectives that you are trying to achieve. And then there is a fully autonomous agentic systems. These are kind of rare today. We don't have a lot of them, but this is where this is the highest level of agency and this is the highest level of autonomy that we are working towards. And these systems, they can make. Strategic decisions on your behalf, you know, they are not just, you know, business objective oriented. Now they are able to make decisions on your behalf, interact with other agents, interact with other tools, and, you know, make, uh, let's say make a payment on your behalf or, you know, those kind of things. OK, so what does an AI agent mean, right? So you may have heard about, you know, or been using LLMs, large language models or small language models and so on, where they lack the ability to solve problems, you know, they're like, you say, OK, can you write me a poem? They'll write, write you a poem, but they don't exactly know if you say, uh, this is my objective, go do something, they will not be able to do it. You have to specify what needs to be done. Whereas AI agents are autonomous or semi-autonomous software systems that are able to independently plan and act on your behalf with minimal human oversight, and they are also able to interact with the environment that they are in, whether it be the APIs, the data sources that you have, all those things, and able to take independent decisions on their own. So it is relatively easy to build an agent, you know, for those who have already built AI agents, you already know how easy it is to build AI agents, but when it comes to taking them to production, you know, think of all things that need to happen when it needs to go into production, right? Think of the thousands of invocations that will potentially happen for that particular agent. Think of the thousands of interactions that this agent will have with other agents and other tools as necessary. All these complexities that are in place and if you have to manage your own infrastructure for this. They're not going into production, right? This is where most of the customers are like building agents, they're doing prototypes and not taking them to production, and that's where Amazon, Bedrock agent core services come into the picture. So agent core services let you build, deploy, scale, secure, and observe your AI agents in production. And you can use any agentic framework. So if you're familiar with Lang graph or, you know, crew AI, strands, all these different agentic frameworks, you can use any framework, and you can also use any LLM, right? You can use, you know, Bedrock-based, uh, models, whether it be the cloud models and so on. You can use OpenAI models. You can use Gemini models. You can use anything that you want, right? That's the flexibility that agent core services provide you. So Agent Core is a set of modular services which you can use all of them or some of them as necessary for your particular situation. You don't have to use every service out there. You just pick and choose the ones that make sense for your particular agentic AI application. The first one out of the services is Agent Core runtime. So runtime allows, as the name suggests, it allows you to run your AI agents and MCP servers. And it is a completely or fully managed service. You're not managing any of the infrastructure. You're only purely focused on what your AI agent needs to do and the code associated with it, and you go deploy it in there, and it is secure in nature. It has its own session isolation and other capabilities. Also, there are data production capabilities and all those things that come baked into the runtime itself. You can have real-time interactive agents, or you can have long-running agents, agents that may be running up to 8 hours of duration. Then there is the agent core identity service which allows your AI agents to securely interact with other services whether it be your enterprise APIs or other services like whether it be interacting with your salesforce or Slack or Google. You know, all these GitHub, all these things that are external services as well can be accessed securely using uh agent core identity. It basically reduces, you know, when you think of, uh, authentication authorization life cycle, right? You know, your AI agent, let's say it needs to go talk to Salesforce first. The user has to authenticate, then there needs to be some some level of token exchange that is happening between, uh, Salesforce and uh the user itself, you know, you got the token. But now that token has to be passed to your AI agent to go continue doing the work, right? So all those storing those, uh, you know, tokens in a secure vault, making sure that only the agent that is supposed to access the token is, is able to access it, you know, and, and reusing tokens as necessary. These tokens don't just expire, right? You know, sometimes you have longer duration, uh, tokens, 1 hour, 2 hours, whatever the job tokens that you generate. So depending on that, you know, and you don't have to write even a single piece of code. All that you do is you reference a couple of decorator functions of agent core identity, and you will be able to all the boilerplate code that is necessary for authentication authorization will go away. So that reduces the amount of development time that is required for you to take your agent to production. You're not writing any piece of code over there. You're just using in-built capabilities, and the beauty of it is it already integrates with some of the, uh, the, you know, identity providers, whether it be your Octa, your Cognito, you know, uh, think of uh Entra ID and so on. Then there is the agent core gateway which provides a secure secure mechanism to integrate with your existing APIs and lambda functions or even external services and so on. And what it does is it is acting as the name suggests, it is acting as a gateway between all your APIs and it can convert those APIs into MCP compatible tools. So you don't have to build your own MCP servers in front of your APIs and lambda functions and other AWS services. You can just leverage Bedrock agent code gateway. So that, you know, it just helps you with that MCP exposure and your agents are able to talk to that MCP through that protocol. It also allows for like, you know, let's say you have thousands of APIs across your enterprise and most of them, you're trying to convert them into MCP servers and tools, basically. When the tool collection keeps growing and when your agent is trying to go find what are all the tools that are available, you know, the context window for your agent keeps getting bloated up and you know you don't want to do that. Where Gateway shines is it provides you with a semantic search kind of a capability where the agent will say, Hey, I'm trying to send an email. Can you give me a tool associated with it and Gateway will pick and choose the specific tools that make sense for sending an email and expose only those tools to the agent so that your agent context window is not bloating up or going overblown. Then there is the agent core memory. So in case if you want to have memory associated with your AI agents and you want to store and retrieve information across multiple sessions of your invocations of your AI agents, you can leverage memory. It has. Both short term and long term memory capabilities. So depending on what information you want to store, what type of AI agent you're building, and whether it requires some level of data retention for some level of chat history or whatever, whatever your agent is doing, if it requires memory, the agent core memory will help you with that. And then finally, there is an agent called observability. This is a fully managed uh ability uh or service, sorry, uh, which will help you to take that single pane of glass of uh kind of a view into what exactly your AI agent is doing, but what. What model it is calling, how many tokens are used, what are the inputs, what are the outputs, uh, what tools it is calling or MCP servers that it is calling, so you get that auditability and observability right, right in the service itself and some of the frameworks like strands and all these things, they already have those things baked in and all the logs, metrics, traces. Are open telemetry compatible. So if you want to push those logs into CloudWatch or Dataog or CloudSmith, Langfuse, all those different tools you can do so. With that said, I will like to hand it over to Jitin. He'll cover the architecture patterns. Thank you, Sandeep, for covering the marketing automation challenges and the what and whys of Agent Core. Uh, hi, I'm Jitan Dadia. I'm a senior solution architect, uh, specializing with AIML and Gen AI. Uh, I cover the advertising and marketing industry across the US. Uh, just with a show of hand, I'd just like to know how many of you guys are, uh, from advertising marketing industry. OK, just a few of them. So, good thing is, whatever I'm going to cover, or while it may have focus on advertising, marketing, it is going to be applicable across the board. So, any of your use case, financial services, life sciences, everything is going to uh be applicable, same thing. Uh, what I'm going to do is deep dive on how to use uh agent core or how to use agent, a multi-agent system. Uh, what are the patterns, what are important things to consider, uh, and we'll deep dive into those aspects of it. Uh, in particular, we'll start with like agent to agent communication. What are the options, uh, pros and cons for that, uh, then we'll go into security aspect of it, uh, and finally, like multi-tenancy and, uh, observability. So let's take uh a distributed communications uh system, right? Like multi-agent system. Uh, the communication is like the nervous system of uh the brain of it. Uh, here, what we have is multiple agents are shown here. Uh, these are marketing related agents, but as I said, like, they could be any agent. As Sandeep has referenced, these agents could be built using any framework. So, uh, one thing we're propagating is that don't necessarily restrict your team to using one kind of framework. You could use land graph. Some teams could use land graph, others could use strands, right? And it's a perfectly cohesive system. They can talk to each other very smoothly within agent core runtime. So that's not a restriction. Now, if you want to standardize as an enterprise on one thing, it's fine, but it doesn't have to be, and that's something you need to realize with this. Um, here you see like a user, he's going to typically interact with an application, maybe an existing application, maybe a new application. It could be chat or it could be a web app. Uh, and then what the application is going to do is that is the application going to communicate with one of the agents or multiple of these. Um, in many scenarios, you will see that there is an orchestrator agent. So the application hands off to the orchestrator, and then the orchestrator is going to decide who it needs to talk to, when it should talk to each one of these agents. Now, let's see how can it talk to these agents, right? So the We have a few options here. You can see here there's Boto 3, and then there is A2A, right? So let's say the application first calls using a Boto 3 API. It invokes the orchestrator agent. The orchestrator agent now has a choice. It can use Boto 3 APIs to invoke the other agent. It can use A2A communication. When would you use which one, right? As an enterprise you need to standardize, not necessarily. AWS Boto 3 will give you built-in retry logic, will, will give you error handling, some of those native things that you're used to, right? It will make your life simpler. When would you use A2A then? A2A is going to be an open source protocol. So if you want to standardize on open source, uh, what if you have agents living outside of AWS that you need to call? Maybe those cases are when you would typically go for an A2A kind of approach. Now, imagine a world, and this probably is true for many of you who have been building agents for a while before Agent Corps came out, before deploying it to Agent Corps. What you would typically do is maybe you have an ECS container or EKS or Kubernetes like where you would have written your Landgraf agent and you would have deployed it there. Now those agents, legacy agents as I call it, they're still there. And you start building new agents and you start deploying them in agent codes. Uh, they need to talk to the old agent as well, and that's where probably you would use APIs to make the call to those agents. Uh, you'll write a tool within one of your agents or the orchestrator agent, and that tool may call out as an API to these other agents which are sitting in ECS or any other container. Then we take the next case. So here is where it gets a little bit more complex use case, but this is a real life enterprise situation. There are multiple teams developing agents. Uh, there are reasons where you will need to use multiple AWS accounts. So maybe some of your agents are deployed in this account, others in this, and another in a third account, right? When are those use cases? One, as I said, is there are multiple teams who are developing them, so for ownership purposes, for cost allocation purposes, you need that. But then there are use cases where let's say you have a database which is sitting in an account A. And your agent needs to interact with that. So in that case, you may want your agent to be sitting in that account and talking to your database there. But then the other agents will need to talk to that agent, and that's where you will need to do communication between them. Uh, another use case is shared services, right? Maybe there are some shared services type agents that are written as a common framework for your enterprise. Those agents could be living in a different account as well. So again, you'll need to communicate across AWS account in those cases. And Uh, but either way, uh, the same thing applies whether it's within the same account or cross account, you still can use the Border 3 APIs or you can still use the A2A communication. So you don't have to worry about that and feel free to deploy it wherever you need to, uh, based on your use case. The next is an MCP server. So typically agents will require tools. Tools are going to be written as an MCP server. Now, how do you communicate to an MCP server? Using the MCP protocol, right? So that is available out of the box as well. With Agent. So those were the patterns to communicate with each other. Now what about security? Uh, I'll say like if you ask your security team, the first thing they'll say is, how do you control the access to the agents? So that's the thing, right? Uh, the authentication, the authorization, the fine grain control, all of that is needed, uh, for multi-agent orchestration. So what are the options that we have here? Uh, so basically, uh, we have two choices again here to make between the two, IM authentication and OAth. OAth, you need an OAth provider which can do the OAth token generation for you. Uh, IM is the native AWS authentication that you can use. Both of those options are available, and again you can mix and match. You don't have to choose one over the other. You can decide to some agents can use IM authentication while others can use OAuth. For an MCP server. Again, here, the standard MCP uses OAth, but we have modified that within Agent Core to use IM as well. So if you deploy an MCP server within AWS Agent Core runtime, then you can use just IM authentication as well. Uh, so then you can do native IM authentication across the board if that's your preferred choice. With you typically require an OA provider, either Cognito, Octa, or any other OA provider. If you're not familiar with it, what the process is, is basically your OA provider is set up for a certain agent. It can generate a token. That token comes when you call the agent. You'll pass that token along with it. Now here's the beauty of it. What Agent Core does is it's going to intercept every single request. It was going to inspect it. It's going to see whether the token is present or not. Once the token is present, it's going to. Go to the provider, validate the token, and only then the first line of your code gets caught. So that's where the security comes in. That's relieving you of the security job. We are guaranteeing you that we will be intercepting the code. We'll be taking care of the authentication, and only valid requests are coming through. So that is a very important thing to note here. There are two cases of OAth tokens. One is a user generated OAth, and another is machine to machine tokens. So there are two types of tokens that you could use potentially. When do you use which one? So as we see, first, the user is calling the app, the app is calling this, so that. You will use the user generated token, so the user's identity is getting passed. The token generated by the user will get passed. You'll use that. But then maybe between the two agents to agents or between an agent to an MCP, those are machine to machine things. You may want to just use a machine to machine token. Again, agent core identity supports both of those options, and you can use any of them. Uh, Another thing sometimes you need is the user's identity needs to get propagated further to the MCP server, right? You have an MCP server which is a tool. Let's say it's accessing database. You want to limit the access based on who the user was. And in that case, you will pass on the user's identity onto the MCP server and make that decision. If that is not the case, then use the machine to machine token makes your life simpler. Sometimes you do need fine-grained even further down. So for example, you may have an agent that is doing multiple tasks, and then you need to have fine-grained control, and that is something you may need to implement using code within your agentic code. And how do you do that? So what we do is the identity that is passed on, we allow you with easy methods to extract that identity token from the request, from the context. So you can get the user's identity. Now you can inspect it and you can see, oh, is this user allowed to do operation A and B then. Keep doing both the operations. If it's only allowed to do Operation A, then just allow him to do Operation A, and that is something that you built in with your core. Next we decide like how do we decide between IAM or OAth, when to use which. Again, the decision is simple. If you want to stay in AWS ecosystem, if you're using just AWS across the board, you can keep using IAM and makes your life simpler. Also, when you're starting up a new project, it's much simpler to just use IAM unless you have already used OA in other places, right? So then it becomes simpler setup wise, uh, getting up and running very quickly. Now, on the other hand, uh, OAth, if you're already familiar with OA, if your organization has uh an OA provider already set up, or if you want to call across cloud, right, like if you want to do have the cross cross cloud compliant, if you want to use open source standards only, then OA is the way to go. A Little bit more set up at the beginning, but then it's standard, you can use it across the board as well. The next we go is when we said about multi-account. If you're using IM, then you may need to use cross account rules. That's the only difference. But other than that, it still stays the same. Finally, we'll talk about the gateway. So if you remember, uh, Sandeep spoke about Agent Core gateway, uh, this is where if you have enterprise APIs, so a lot of enterprise APIs, uh, what you don't realize is you start writing MCP servers and wrapping around it. You don't need to do that. You can just use Agent Core gateway to do it. But as soon as you introduce this, how do we do security around it? How do we do authentication and authorization for Agent Core gateway, right? So Agent Core Gateway supports OA as your mechanism. It exposes everything as an MCP server by itself, so it will allow you to do. So now an agent needs to call an API that is living in your enterprise. What you do is introduce the gateway. You supply an M2M token to the gateway token. And that token agent gateway will verify, validate it, and only if it's valid, it will pass it on or call your APIs. It's not going to call your APIs otherwise. So that's again the built-in security that you get. Then let's say your token is valid. Now how do you call your APIs? So your enterprise may have secure API keys for calling the APIs. They may be already using to authenticate with your APIs or. Could be nothing. Maybe it's unprotected APIs. So all of those options can be supported by Agent Core gateway. So gateway can be configured to say, OK, this API is protected by an API key while this other API is protected by OA, and you can mix and match again. The key is don't change necessarily your API code to do anything. Just configure the agent code gateway to use your existing API. Makes your life simpler across the board, and then expose it as an MCP server. So we saw how to communicate between multiple agents, then we saw how to secure them. Now let's get into multi-tenancy. So this is a real requirement in many use cases. The multi-tenancy patterns here are very similar if you were using a SAS system. So if you had an originally a SAS web-based application which was multi-tenant, same patterns do apply. There's not much of a change. It's just how you look at it that is different. So option one is you can have multiple instances of the same agent deployed, one for each tenant. Again, complete isolation, you get complete boundary separation. The second option is you can have an endpoint deployed. So when you deploy an agent to agent cops, you can have multiple versions, and each version can have endpoints associated with them. So you can say that endpoint A is for client A, endpoint B is for client B, and you can associate it with that way. Again, you have some degree of separation, you call it separately, but behind the scenes there is the same agent going on. Or you can just have a single endpoint and do everything in the code within your agent. So now you just have one instance of it running. But remember, even when there is one instance of it running, every time you invoke an agent, it's a completely different isolated session that agent core gives you. So we, uh, so a session when user A calls an agent for tenant A and user B calls an agent for 10 B, same agent, we completely isolate that session for you. So there is no need to go with option one or two. You can just have a single endpoint and handle it. If you do decide to do the 1 or 2, that is also a fair game. It's just additional management that you will have to go through. So that's the decision point, whether I want more separation with a little bit additional management or I can handle it within my code. Another thing to remember about multi-tenancy is cost attribution. So that's where the hotel logging that we were saying, Opal telemetry, that comes into play. Uh we will uh you will need to log those for auditing purposes and cost allocation. So make sure that if you have a multi-tenant system, you'll log enough things around it and use hotel and then you can use that anywhere. Finally, we come to observability. So observability is slightly different. I mean, you need the standard observability that you need for any system. But agentic observability is slightly different here. You need to trace every single component, what's going through it. Why did the agent make this decision? How did it make that decision? Is it calling this system, this agent, and then this agent and this tool? All that traceability, right? You need all of that to understand, to debug, and finally to audit it as well. That's where observability comes in. So out of the box, as we said, like cloud watch dashboards are provided. You can go and do session level tracing. So if you look at one of the dashboards that we provide out of the box, you can click into a session. You can click into every single component, how long it took, what was the request, what was the response, all of that detail is available. But if you already have a third party observability system, lang fuse, Langsmith, something different. Feel free to use that. We have the hotel logs provided to you. Take that, feed it to your existing system. That's a fair game as well. So both those options are fully compatible with Agent Core. Finally, a futuristic agent, an agent observing all the other agents, and that's where you want to eventually get to. Come to a final solution. So this is the solution that Epsilon has implemented. What it did is all the patterns that we have discussed, they are talked about here. So for communication we standardized on OCTA. So we are using OCTA for security, authentication, authorization. Uh, communicating between the agents, we're using Photo 3 here, so every agent is talking with each other using Photo 3 APIs. Uh, we are deploying some agents in our account so that they can talk to these native databases. So let's say for example, Neptune or any of these other databases that we are there which are private in a particular VPC. Same with the APIs on the right hand side. If you see the people cloud messaging APIs, so those are the enterprise APIs that are there. And those APIs are protected through or accessed via the gateway. We're standardized, as I said, on OCTA, so MCP servers, gateway, agent to agent, everything is OCTA for security purposes, and then we access the APIs through that. Um, yeah, so if you want to take away a few things from the deep dive of this portion, one thing is don't build a single monolith agent, but split it into a micro agent doing a small amount of work, right? What I've seen is while you may have this kind of architecture on a picture, they build it into a single agent in land graph using a workflow or something like that. No, separate it out. Each can be scalable on its own. The second thing is security. Day 1, day 0, like you need to have that built in trust but verify. That should be their principle for security. The 3rd is the multi-tenancy. Build it from day 1. So make sure if you need multi-tenancy, it's built into it right from the get-go so that you don't have to go back and refactor. I'm going to hand over to Prashant who's going to show you all the magic of the agent core, how these agents are implemented. All right, click clicker. Thank you, thank you, thank you. All right, thank you, Jitin, to go over agent core architectural patterns to address marketing automation challenges. Hello everyone, I'm Prashant Attota, SVP of Product Engineering at Epsilon Data Management. You guys hear me OK? All right, thank you. So today, I kind of go over, first of all, who we are, what we do, and the type of the opportunities we identified. To build agents within our product and ecosystem, and the type of the agents we built using agent core and Bedrock, and a small demo of those agents at play, probably the most interesting part of my whole deck. And the benefits. And the challenges we faced while building those agents, lessons learned, I would say. All right, so. All right About Epsilon Epsilon Data Management, or Epsilon in short, is a subsidiary of Publicis Group, world's leading advertising and marketing company. Epsilon is a data-driven marketing company providing data technology and services to help our clients understand their customers and engage them across various communication channels. At Epsilon. We serve many industries like quickserve, finance, retail, automotive. In a, there's like uh CPG travel and advertising, so many, so forth. All right. So what makes Epsilon unique in this industry? Customer identity. We carry over 200 million. Privacy protected IDs. Linking address, name, and at least a single transaction. 95% of them are verified, and 100% are deterministic. And the data we host a national consumer database. Consists over 200 million+ consumers self-reported over 1,000+ attributes, over $3 trillion spent on transactions. And our best in care solutions like digital media, retail media network, clean rooms, customer data platform, loyalty and messaging. Also industry leading support services. employment. So at Epsilon we believe in personal first marketing. Our one view Like using our data and identity, we provide a single comprehensive view of the universe to potential buyers for their marketed products. And then with our one vision. We understand who to engage, when to engage. And, you know, using their real time, like, you know, the spend. and then the one voice delivering an experience that is relevant and personalized for each individual at a point in time. So these are the kind of, you know, we looked back and said, OK, what are the improvements, where we continue to use our agents. So some of the areas is effective personalized messaging, kind of providing the targeted message at the right time for the right individual. By doing that, the results are like, you know, we get a higher engagement for that message. And then dynamic customer journey orchestration. To provide User experience. Relevant to the user transaction, which will in turn improve the conversion rates. Integrated systems for engagement. So we would like to bring the agents together so we can integrate all these products together. So we have more, obviously, less less uh resource usage and more efficient in operating those products. And then the rapid innovation and automation, building our GI platform helped us to build agents at much faster speeds. And to reduce, you know, improve the time to market. All right. So driving the performance across the wound channels. Most of, most of the brands, they would like to know their customers. And to create effective segments of the audience. To do that, we build the agents. One is like our 360 degree customer view. And Audience AI Audience AI is more like instead of understanding their databases, complex relationships, complex SQL statements, they can literally write a plain text and get their segments done. With the plain English. And then defining the campaigns across the channels. So type of the like agents we build like a brief agent, campaign brief agent, branding agent, creation agent, and campaign agent and AA assisted on demand and scheduling so they're all coming together like multiple agents to build those campaigns and then once the campaign is generated, once the campaign is executed, we have agents. Kind of measuring the performance and readjusting the optimizing the strategy of those campaigns. So whether it is campaign analytics, agents consuming the incense, etc. So here is the kind of the timelines, like our journey when we started back in 2024. In Kyoto, we introduced the Gen AI, which is more for the audience creation, where this platform can build audience or segments using the plane. English text to SQL conversion. Then we kind of in Q3 implemented subject line, image tagging on the bedrock, you know, some of those agents. Beginning of this year. We have the first content creation or HTML agent. And then the Q3, we kind of introduced AI into our SDLC. Which definitely improved our productivity, getting almost like 20 plus agents in a short time period. And creating the content, monitoring, etc. on our platforms. And at present, we have 7+ teams working alongside of AWS. Building our agentic platform. And that said, I believe we're going to go for a small demo of all these agents coming together, playing along. Yes. Every minute brands send tens of thousands of emails and the vast Sorry. Every minute, brands send tens of thousands of emails, and the vast majority land in blind inboxes. With Epsilon, that ends. Engage with customers on a deeper level across all devices. Let me show you how Epsilon agents build campaigns. Every strong brand starts with a clear message. Inside Epsilon messaging, that message begins with a campaign brief built on decades of Epsilon's identity intelligence and marketing precision. A campaign doesn't start with chaos, it starts with structure. Epsilon Messaging instantly organizes intent into a clean, dependable workflow. Choosing email here isn't selecting a format, it's activating one of the most trusted channels in modern marketing, with a few details, the platform aligns data, context, and audience signals behind the scenes, shaping a foundation the brand can build on confidently. The editor opens not as a blank canvas, but as a guided space where the brand's voice naturally finds clarity and direction. Templates remove the burden of design guessing. Branding is applied with precision, so every message aligns with the brand's identity, instantly recognizable, always consistent. Once the template is in place, the brand stands on solid ground, the styling is locked, the look is unified, and the message can now focus purely on meaning. A generic campaign fades fast, but when Epsilon's AI agents shape the audience, timing and message, your campaign hits with precision and drives real action. When the message fits the moment, the channel becomes effortless with Epsilon messaging. Edits that once required long back and forth cycles become frictionless. Phrasing, flow, and rhythm adjust with a level of precision that keeps the message sharp. Suggestions add another layer, subtle, thoughtful, grounded in brand tone and clarity, the small refinements that elevate communication. Personalization becomes identity driven, no long segmentation work, no manual filtering, relevance at scale, supported by the industry's most trusted data. Dynamic elements bring the message to life, effortlessly adding motion, interaction, and depth without additional creative complexity. Tone controls bring discipline, professional when needed, optimistic when desired, a brand's voice clearly expressed the way it was intended. Readability and visual refinements enhance comprehension. Clean spacing, balanced design, and structured hierarchy guide the reader through the message effortlessly. With one click, the message sharpens into its final form. Campaigns miss when they lack relevance. Epsilon's AI agents build relevance at scale, so your message lands and your customer responds. A full review confirms the message is aligned, structured, and ready. Device previews show consistency across screens and environments. Timing decisions shape performance. Epsilon messaging aligns delivery with patterns proven through identity intelligence and decades of engagement data. And with that, the message moves from creation to execution, built with precision using AI agents, strengthened by identity, delivered through Epsilon messaging, the platform the world's strongest brands trust to communicate with clarity, scale and purpose. Good. All right. So, now I'm gonna go over like at the type of the benefits we observed by building all these agents across our product suite. Asian prototyping. By using the agent core, definitely we see like reduced prototype typing time, the number of, you know, days it took from weeks to days actually. And then campaign setup time, it's we observed 30% improvements, but again, as the adoption goes up across. Campaign managers and analysts, I'm sure that we're going to see more. Uh, personalization capacity increased by 20%. Uh, campaign creation times, obviously we saved many number of hours, but again this is all we're just starting with the multiple agents as we build more and more agents across, uh, other areas, we're definitely going to see a lot more improvements or savings, I guess. So the lessons learned. You know, it's kind of We used to spend a lot of time manually creating workflows versus switched our focus now, more like uh automation and outcome-based journeys. And We also have the teams changing their mindset, what to think about more of the outcome than what to do and how to do things. Uh, so, even in any use cases, like, instead of worrying about what models out there or what they're coming up with, where you should more focus on. Like, what are the type of problems we're trying to solve, what are the outcomes we are looking for, and then look for the models that are more suited for your needs, rather than going after models by model. And rapid prototyping, definitely, you know, using some platforms like Agent Core, uh, using like their plug and play abstraction layer planner complaints and recommendations, it will help you to build, experiment and deploy the agents at speed. Uh, and, um, using something like Amazon Q integrating with your SDLC improved us like, you know, especially ADLC and also, uh, AI pipelines, integrating them. Definitely helped us to speed up our iterations. And fail fast. And then what's next? Autonomous everywhere. We would like to expand our agents, use of agents from marketing over to other areas like auto, data, and other platforms, loyalty and other areas. And building self-healing, self-monitoring type of agents. Uh, also integrating the, uh, DLC pipelines with the operations so we can have autonomous agents working for maintaining the platform and stability and secure safe security and compliance, etc. And a unified intelligence layer. By using the agent gateway, bringing all the products together, so we have MCPs and the tools are all coming, working together, and the data is shared across the products using the same agents exposed to the same agents. And commercializing and acceleration, we'd like to take these architectural patterns and you know, and also build agents that can be used by our clients or. Let the clients build their agents using our data, using our APIs and etc. And I also publish some of these agents. Uh In the marketplace So, you know, we can kind of monetize based on those. All right, that said, um, Sandeep and complete. All right. Am I still audible? You like me? Yes, good. All right, so here are some of the res learning resources that I think will be really helpful for you. These are some of the things that I refer to every day. There are great examples in sample code on GitHub as well, and there are free learning courses on, uh, uh, SkillBuilder, AWS Skill Builder. So please take advantage of these and have as much as hands-on practice as possible so that you can build those great. AI agents and deploy on top of Bedrock agent core services and if you love us, you can clap at the end of the session, but first remember that you have to fill the survey, especially look at my face. I'm very, you know, innocent. I'm a nice person. Please do fill the session survey and uh give us good ratings, OK? Thank you so much guys. Take care.