---
video_id: EPRE8_FHGdQ
video_url: https://www.youtube.com/watch?v=EPRE8_FHGdQ
is_generated: False
is_translatable: True
---

All right, good morning, and I hope you all are having a great conference with the reinvent. I'm Avinash Kolui. I'm a senior solutions architect with AWS supporting Amazon and its subsidiaries on their cloud journey. And today along with me, I have my co-speakers Yaal, lead applied scientist from Amazon Ads team, and Fabio, principal engineer from Amazon Ads team. And what are we going to discuss is how Amazon Ads has democratized ad creation with their creative AI agent. I know this is a I I learned one, but how many of you are here familiar with the buzziest word in this year at the tech industry? Which is agent. You can raise your hands. Nice. I see a lot. So in that case, you are exactly in the right place. We're going to show you about how Amazon Ads has built their creative agent, and in fact we have quite a packed agenda. Initially we're going to go over about what's Amazon Ads overview, and then we are going to dive deep into the ads creative agent. In fact, just a spoiler alert on ads creative agent, this is something that Amazon Ads team has recently launched in their unbox, which has got a great momentum and attention. And then we'll also dive deep into the science and research side of the house along with the infrastructure challenges and implementation of the infrastructure, and towards the end we're going to discuss some more advertising use cases on generative AI and make sure how AWS is helping to evolve on the landscape for you. So with that, I'm going to present it to Yaasal, and he's going to discuss about how an Amazon ads overview and as well as about the creative agent on the science and research side. Hey, good morning, everyone. Thanks for attending. Uh, my name is Yael. I've been at Amazon for 9 years and I am a lead applied scientist on the team. I'll be walking you through 3 key areas. I'll first introduce Amazon ads and the scale at which we operate. Then I will introduce creative agent, and I want to be precise here, this is not another text to image or text to video model. It's a complete production agentic system that's running on AWS and serving real customers today. And then we'll dive deep into research and science, and we'll talk about the challenges that we faced and how you can use AWS to solve these challenges. So Amazon Ads has evolved into a full funnel solution. It is available to businesses of all sizes, from Fortune 500 companies to small and medium businesses. We serve over 300 million average monthly read across the US. And to put that into perspective, that's almost the entire US adult population. We have over 200 million reach on streaming TV alone. And we power advertising across a variety of surfaces like Amazon.com, Prime Video, Twitch, Audible, Fire TV, Music, and even more third party publishers. Now, let's take a quick look at some of the features of streaming TV. Play along at home, see if you can get there first. What's up? Let's get back into it. Exciting, isn't it? And that is just one of the various formats we have. And all of these formats and advertise advertisements, they need to be created. So advertisers need to create text, images, videos, and headlines across all of these variety of formats. And that's where our team helps. So over the last 3 years, we have launched a variety of products, models, and features to power generative AI for ads. This includes image generation, audio generation, headline, and even video generation. And all of these features are available in the AI Creative Studio. It allows advertisers to select any of their products on Amazon or even upload their own images. For instance, in this example, we see a set of cups that are sold on Amazon. And this is a feature that we first launched over 2.5 years ago and have improved since. So for the products like these cups, you can generate imagery or videos that feature these cups. And along with improving this, we have launched other features like holidifying your images, animating videos, or creating templatized multi-scene videos. And as we continue to improve these systems, we identified some areas that are important to our advertisers. And I want to highlight that these are not good to have. These are must-haves in today's generative media landscape. The first is scale. So for every campaign that the advertisers create, they need to generate 1020, sometimes even 50 variations, and you need to do that for all the events. You need to do that for Christmas, Black Friday, Thanksgiving, Father's Day, Valentine's, and so much more. And then you multiply that by the hundreds of products you have, you can imagine the number of variations in content that you need to create. And then you couple that with the demand for video, which is more than ever before. So advertisers need to create a lot of content. And then here's a paradox. All of them want automation, but they also want control. They want these systems to think intelligently. And automate the generation, but they want to do that using their own brand guidance. They want to control how these systems operate. Then think about time to market. In advertisement. Time to market is critical. So by the time they may generate content, the market trends may shift, so you need to be fast, and every small advertiser cannot spend $100,000 to $50,000 to create this content. So you also need to think about cost. All of this of course requires expertise. We need expert technical creators, content writers, and so on, and not all small businesses may have access to these. And finally, it's not just enough to create. You need to optimize, you need to know what colors work, what band messaging resonates with your shoppers. I need to optimize all the content. So if you think about the entire traditional approach, you need to plan and hire, that you spend weeks creating content and then you optimize it, and then you take feedback, and then based on the feedback you repeat the whole process again. So by the time you spent weeks creating your content, market trends may shift. So you need to democratize content. So how do you democratize creating content for advertisements? Well, The answer is creative agent. Watch as it springs into action for a simple query like creating content for my latest hiking gear. It immediately responds and reasons and shows real-time update to the users. It presents some concepts about the video to the user, and at any moment the user can edit and chat with the agent to update them. In this case, they decided to go with concept 3. And the agent immediately begins executing. It generates stunning imagery for the concept and presents them as a storyboard, as an artifact in the UI. The advertiser can review these images, they can chat to edit, or they can choose to animate them. Once the advertiser asks to animate, it begins animating all the images into a stunning video. It compiles compiles everything into a single video and brings together, and you'll notice it highlights the product and then it's ready to serve on Amazon. And that is creative agent. It is not a simple model as I talked about. It has planning. It has reasoning. It acts on behalf of advertisers, and it is intelligent. It is built on 3 key pillars, and as I mentioned, it's not a simple UI wrapper over a single model. So it's important to have great experience. The users can chat with it naturally, or they can also interact with it in a full-fledged image and video editor. Second key pillar is integration. Our traditional AI models operate independently. You have a model that generates text to image. You need to take the output and then pass it on to another model by yourself, but this integrates not just all the models, but also Amazon product data and other features that are powered by our systems. And last is intelligence. It does not just execute commands on behalf of the user. It's not the user who is always deciding what to do and what to say. It intelligently knows what to do and it uses multiple agents to do so and acts on behalf of the advertisers. Now let's get to the fun part. Dive deep. Before I go, I have a quick question. Raise your hand if you ever face problems with tokens, context windows, or if you've ever gotten the message that you've raised your daily limit on AI systems. Exactly, it's so commonplace, and that's exactly the kind of challenge that we face and we solve. So we'll go through these challenges and how we solve them. I will cover 4 more areas, and while this gets technical, I want you to stay with me because these challenges and the solutions apply to any agentic system and they're not just applicable to our system. The first is agents and routing. So do you cram everything into a single system prompt and hope for it to work, or do you build a modular system? Long running tasks is one of the toughest problems to solve in aging systems. Every conversation in creative agent has hundreds of images, and a single LLM does not support hundreds of images. So how do you make sure that the agent can see all the images and act accordingly? And then this one kept me up at night. How do you evaluate your system and make sure that every deployment is safe and actually improves rather than leading to regression? As we went through these problems, we answered some key questions, and each of these questions is important because it has a direct impact on the scale, latency, cost, and the performance of the system. The first, as we discussed, do you put everything in a single system prompt and hope your system works, or do you build multiple agents and tools? And we tried that. We tried with a simple system prompt. We put all the instructions in a single system prompt, and it worked OK to start with. At a small scale. It works OK, but as you add many features and you build a bigger system, it simply fails. The model starts reasoning for simple questions or it simply ignores some instructions and does things by itself. Second important thing is handling of user queries. So not all user queries are equal. Asking a simple question like what can you do is very different from saying take my top 10 products and create amazing video for it. So you need to understand what the user needs and adjust the complexity and difficulty based on that. And last is balancing real-time updates versus long-running tasks. So naturally, as you support many features, some of them take longer, like making a video may take 1 minute, but generating an image only takes 3 seconds. And then responding immediately may also only take 3 seconds. So how do you balance showing real-time updates while also doing tasks that take longer? And as we answered all of these questions, it led to our current design. And before we discuss this, I want you to understand that this is a dynamic system. It is actually living, so based on every query, the, the path it takes and the tools it calls changes, but this is a generalized view of what happens. It starts with the user's message. As soon as the user sends the message, our system decides, is this a difficult question, do I need sub agents to handle this, or can I handle it myself? It then does two things in parallel, so it forwards some of the requests to subagents, but at the same time it immediately begins responding to the user, and that response is shown to the user in real time. While it is showing it to the user in real time, it sends that message to the sub-agent, which have their own tools in intern. These tools can be image generation model, web search, and so on. And all of these tools have access to memory where they write. So for instance, if they generate images, they can write to the asset store. They can save some content to the shared memory as well, and this is shared across the tools and subagents. Once they write to the memory, they send that response back to the subagents. The subagents correlate all the responses, and then we have correlated response sent back to the agent. Once everything is generated, it's also shown to the user in the UI. And that's how user sees the real-time messages and also content like images, videos, and so on. And all of this is fed back into the conversational memory and ready for the next one. And because it's a chat system, all of this can keep happening and you keep rolling loading from the memory and from the user. Now we build this over different steps, and I want to walk you through those steps because you'll understand how we build them in layers. So this is the most basic agent, and it was step one for us. It can take a user query, with reasons what to respond, and then it sends that response back to us. Then we of course use prompt caching or KV caching to improve speeds, and that alone led to massive improvements. So this agent works fine for simple queries, but it cannot act on user's behalf. It does not have any tools. It cannot really take any actions based on behalf of the user. And that led us to our step 2. So now this agent, as you see, it takes a user query, can reason. But instead of directly responding, it plans. Then it acts using the tools and sub agents that it has. And once it has the response, instead of showing that response directly, it also reflects. So based, so if you're generating an image, it will call the image model and then reflect if the image is good or not. And then it can either send that message back to the user or it can choose to continue, so it builds a loop. If you think about a multi-step process like making a video, it can generate an image, animate it, add music, and then decide to show that to the user. And this is very powerful because it generalizes to almost any task you have at hand. However, there's still the problem of complexity that we talked about. Imagine asking a simple question. What can you do? Do you really need to reason? Act, think, should I really reply this, spend a paragraph of thinking, and then respond to the user, oh, I can make images. You don't really need to do that. And that led us to our final iteration, which is to have a multi-level router. So now, when a user sends a message, we quickly decide does it really need level of thinking or does it need, can it be responded fastly. And if it's a simple question, we immediately respond, and if not, we spend the time needed to reason, to react, to reflect. And here's a quick example. This is actual output. For a simple query like what can you do? and you'll see that it immediately responds to the entire content. It does not spend minutes thinking, reasoning, and then respond after 5 minutes. So we adjust the effort based on difficulty. The reactive loop that we talked about, it also handles errors because if your image model fails, it can read the error and react. It can think that, oh, this model is overloaded. Let me call another model. It is modular and reusable, so it not only helps to build this system, but tomorrow if you wanted to build another agent which has a subset of these features, it's very easy because not everything is crammed into a single model or a system prompt, so you can reuse components and tools. And finally, it helps to optimize tokens because for a simple question like what can you do, you don't spend thousands of tokens thinking on how to respond. You can respond immediately with a simpler model. So that was agents and routing. Now let's talk about one of the most complex problems. So we talked about the loop, but imagine asking a very complex question. Find my most. Selling products and make 10 videos for them, so you can imagine it may take 1020, or even 50 steps to do that. So how do you ensure all of those 50 steps execute correctly? For instance, if I asked what are the key steps needed to make a video, even the agent responds that it has to do a lot of things. So as you're executing these 50 steps, what if you fail on step 41? Do you restart from all over again? How do you make sure that all of this fits into the context? As you're generating images and making videos, you may go out of LLM context window. So how do you make sure that on step 49, LLM still remembers step, step 1? And then how can you optimize? Can you, do you really need to do these steps one by one, or can you do them in parallel? Then those are the questions we ask. So how do you ensure that they can run successfully? How do you make sure that it fits into the context? And do you really need to run them in serial? For instance, if you're generating 10 images and they're independent of each other, you don't need a loop to keep generating them one by one. Can you generate them in parallel? And that simple question led us to the most basic design, which is to ensure that all tools are called in parallel. Now this can be done either using parallel tool calling, that's some LLM support, or you can build this into your own tool. You can design the schema in a way that it ensures that things are executed in parallel. So the agent invokes multiple tools in parallel, but you need to bring them together. You need to reduce them to a single output. And in the most basic implementation, you use another agent to do so. So the agent invokes 10 different requests, and then another agent looks at all of these 10 responses and combines them into a single output. However, that led to some problems. You always need an LLM to reduce them to a single output, but that is very costly. So we improved the tools using something called stateful tools. So now instead of needing another LLM to look at the outputs and reduce them to a single output, we can use fast, non-LLM based reducers. So if you're generating two images which are parallel, you can reduce them or join them into a single list without needing an LLM, which takes a minute to do so, and that led to massive improvements in speed. And it all comes together with subagents. So instead of calling multiple tools in parallels, you can call multiple subagents in parallel. Each of them can take multiple steps. So if you think about those 50 steps we talked about, maybe 10 of them can be taken by a subagent. So as soon as that subagent takes those 10 steps, the head agent does not need to know about all 10 of them. It can reduce them into a single output. The original action of taking 50 steps reduces to certain chunks which are hidden away from the main agent. So the subagent reduces them to one output, and all of those outputs are reduced to a single head agent output that ensures that the context remains in control. And the results speak for themselves. Our video animation became 8x faster. Our context reduced by over 4x. It led to parallel execution, but also crucially, it led to parallel development. Because before you had a single system prompt or single agent where all the scientists and engineers need to collaborate. There are so many merge conflicts, but now. All of them can develop these things in parallel. You can have some person improving image agent, another person improving music agent, and you can bring them all together into a single system. Then some tool operations which did not need LLM and that's not a typo, it really went from 30 seconds to a few milliseconds because you don't need LLM to do everything for you. You can just write code to reduce it. The 3rd, and I think this is one of the key innovations that we added, was how to handle multiple images and videos. So imagine a conversation in which you've already created a video, you've gone through the whole cycle of 50 steps, and then you ask to edit it and let's look at that conversation. So you say, hey, this video looks good, but can you add logo and slogan to the end? So now in this case it needs to remember the full context, all the hundreds of images and videos it already generated. And moreover, if you remember the UI edits I talked about. The user can also interact with the video in a full fledged video editor. So the agent not only needs to remember all the hundreds of images and videos it created, it now now needs to act on them. The user may edit these videos and then take actions in the UI. And because it's chat, you know, the user can come and say, do what I just did, but better. And so now you need to remember all the UI actions that the user did as well. And you can imagine that that simply cannot fit in a single LLM's context window. It's millions of tokens. So how do you ensure that your agent can handle millions of tokens and hundreds of images and videos? And this is the design for that. For every UI interaction event we have a special processor that listens to all the events in the UI and then processes them and saves them in a place. Similarly, for any uploads that the user does, images, videos, we have a special media handler that processes them in place. And both of these are saved in the artifact memory, so you'll notice they're not directly fed into the LLM, but rather we save them in the memory first. Similarly, all the user messages continue going to the conversational memory. Again, all of these still don't go to the LLM directly. We make sure we decorate the memory and select appropriately. So based on every request, we select what media or what UI events need to be sent to the LLM. Similarly, all the conversations are not directly fed in. We compress them, but also select which messages are most relevant. Then all of this is then fed to the agent. And this sort of pattern in between ensures that no matter what user does, it could be millions of tokens instead of images. Our agent is still shielded. And the selection is intelligent, so we don't forget. So you still remember step one, you still remember the first image that you uploaded. And again, this also led to massive improvements. Our agent running in production can support hundreds of tons. It can support 10x more images and videos than our first version. It costs lesser and runs faster and interestingly it performs better. So you'd think that you know reducing context or selecting makes it worse, but because you're helping the agent to focus on what matters and removing anything that does not matter, the quality actually improves. Now let's talk about the daunting task of evaluating. The key questions here are that it is ambiguous compared to traditional ML evaluations. So you know, you might, might have seen those capchas about selecting buses and images. It's mostly black and white, you know, sometimes they have buses which, you know, you're really not sure if it's really a bus or not, but compared to that. Evaluating generative AI systems is much more ambiguous. What is a good Father's Day ad? You know, Gen Z may like something else. Millennials may like something else. So it's difficult to have a binary yes or no answer. You also need speed, as we're improving our ability to code and deploy faster, you also need to evaluate faster. And finally, this dichotomy of manual evaluation. You need manual evaluation because you know they're great quality and you cannot rely on automated systems, but at the same time, if you're pushing features like 10 features every week, by the time you're done with manual evaluation, you've likely made 10 more features. So how do you keep up? So if I were to summarize, we have ambiguous success, and to solve that, we made our system adaptable. So we started with making fixed rubric, like, is there brand color in this image? Does it have a headline? But that led to fixed benchmarks, and it did not really evolve with the system, so we make sure our benchmark adapts to the growing needs. For speed, we made sure we use automated benchmarks when possible. And to ensure that we can rely on humans at the same time keep up the speed, we make sure that we validate instead of depending solely on human evaluations. So this is the architecture we follow for any bug, feature request, or feedback from the user. As we create a ticket We make sure to write a test agent prompt. So instead of writing a fixed rubric, we instead write a test agent prompt that chats with a real agent. And this simulated conversation shows us what's possible for this specific feature or a bug. Then, a human evaluates and refines the test agent prompt based on that simulated conversation. And this is iterated until the reviewer is satisfied with the simulated conversation. And what this helps us to do was that as our agent evolves, our benchmark can evolve along with it. And the test agent prompt becomes part of our actual test suite. So now we have a collection of hundreds of prompts which lead to hundreds of test agents which all simulate different aspects that are important to our customers and PMs. And we can simulate conversations with our agent. That was a deep dive into science and research, and I have some key takeaways for you which you can apply to any agentic system that you have. The first thing we talked about was agent architecture, and it's important to specialize here and it's not just to make your system better, but it's also helpful to develop and deploy in parallel. For long running tasks, it's important to execute in parallel. And to use stateful tools and workflows. While LLMs can do everything, it does not mean that you use it for everything. You can depend on your own code to reduce different contexts or perform certain actions that are much faster than relying on LLMs. To handle multimodal context, you don't need to feed everything to the LLM at the same time. You need to ensure that you offload as much as possible and then intelligently select and forward that to the LLM. And lastly, it's important for evaluations to be liquid. You cannot have fixed rubric that stays on for 12 months. It needs to evolve and it needs to consider feedback loop from real customers. And with that, I'll hand it over to Fabio to talk more about the underlying infrastructure. Thanks, Yashal. Hi everyone. I'm Fabio and I'm a principal engineer in Amazon Ads, and I directly support the team behind the Creative Agenda. While Yashal has mentioned a lot about the science and research behind this project, I'm going to dive deep into the engineering and architecture that's powering the service at scale and then lessons learned, a road ahead for the new improvements that are coming along next year. With G AI agent products and workflows, usually 20% of the time is spent on achieving 80% of the prototype, and then you spend 80% of the time to fine tune the last 20% and productionalize it to make it work. In that last part. Is where we found our main technical challenges. How do we avoid duplication efforts since every team's in Amazon and every teams in ads are building GI workflows, and then how do we keep up with state of the art that we keep delivering at the same pace as anyone else in the industry? Also scalability and latency. We want to make sure that our services don't just work for a prototype subset of users, but they scale up to millions of users. And lastly, how do we embrace nondeterministic agents with classical engineering. You have a certain input and you expect a certain output. With agents, randomness is a feature, so how do we make that all work? Let's tackle the first challenges, because if you can't build the reusable components, you will spend a lot of time just building a single prototype and won't be able to replicate the successes. So our main challenge was solving this problem with architecture discipline. So we divided it into 5 different layers. Let's start from the bottom. Infrastructure is what comprises of all the building blocks components that are reusable across our our project. Then we have models and services layer. This layer is what allows us to reuse every model and connection within Amazon advertising and the overall ecosystem. Then we have tools layer. This is where we create the tools so that are reusable across many different agents. Above that, the agent layer that my colleague Yel focused on, where we have agents, orchestrators, sub-agents, and all the capabilities collected for the agent to work. The last layer is the service layer, and that's what our advertisers see and interacts with, which is our advertising console or could be our AI creative studio. Let's get into the details. The diagram shows the actual implementation and how the components are spread across these layers. So something that I want you to notice is that there is a spectrum of skills where science tends to contribute more on the left side of the diagram, while engineering is usually mainly focused on the right side of the of the diagram. And those skill set helps as well bridge some of the gaps in between. Here is the architecture that made all of these reusable, as you can see, as I mentioned before, on the left side is where the customers interact with. They join one of our entry points and websites, and then a service gateway shuffles the request across our compute workflows depending on the type of workflows that they request. Here in the compute workflow we have one of our main components that allow reusability, which is our agent S decay. But also we have some services that we decided to centralize so that every team didn't have to rebuild it from scratch, one of which is the guard rail service. Guard rail is at the key of our workflows. We don't want any harmful input or any harmful output to go out from. Our workloads and also capability operators, that's where we centralize most of the capabilities so that once implemented by a team, they are usable all across advertising. It's also all powered by some registries, workflow registries and other registries, so either the single components and model or services or the overall workflow that we create or agents could be easily available for anyone in ads to be reused since they're made. This is how the agent SDKy powers any new agent creation within Amazon advertising. So first, I want you to look at this. It's very simple. And allow us to create an agent description and with that we would import subagents. Which are the main components that you shall describe. Each subagent would use the same SDK to import a series of tools that are used. And then moving forward, each tool would have their own capabilities. And those capabilities are nothing more. Than clients, and some of those are Bedrock clients or Sagemaker clients. So this is also very reflective of our layer infrastructure is uh Architected and what kind of contribution engineering would do on which part and what kind of contribution science would do. The result is that we could build sophisticated agents in a shorter and shorter amount of time, the more capabilities we have at the bottom side of the layers. Moving forward, we don't Just allowed to reuse tools or some of the capabilities, but some foundational blocks that we don't want every single team to reinvent, which are logging and monitoring. We won't standardize the logs across all these workflows, logs. Are some of the most important components in nondeterministic systems. You want to know at any given time why a decision was made and where. Also, security is incredibly important to centralize. We want our security teams to just focus on one part of the infrastructure so that everyone can benefit without having them to go on every single team. Cashing is another thing that we want to serve out of the box either from caching or asset store caching. We want to make sure engineers don't have to go through the exercise of reinventing it every time. Checkpointer is something that every agent needs and allow us for any lambda failures or compute failures to recover from where the workload was left. State management is incredibly important because it allows us to persist the conversation across days, months, eventually in perpetual state. Time travel. Allow us to understand what happened across a conversation and recover from a previous step. Well for conversation it's extremely important to test different scenarios when we improve our tools or our prompts, and all of this is baked in the SDK so that any new agent that test. Has to be created that already benefits from all this work. So the challenge that we have. Is how do we make these tools then and capabilities available to everyone. So we created a very simple component that's the capability operator, and every capability that gets registered by a team. will flow into this component that orchestrates the traffic and routes the traffic across the different components. So a team only has to know about the ID or A capability name and from there they could easily connect a route to the traffic through there. I also want you to notice. A box that's the red box on the 3P capabilities and that's what I mentioned before the security team will focus all their efforts so that every team doesn't have to do the same. Moving forward, RAI is not optional. It's not, and it's not also simple. So some of the unique unique challenges that we faced are that RAI has to work on multi-modality. We need to have security and safety through text, images, videos, and audio, but also there's category diversity. A guard rail might work for a category, but for not for another category, so we need to make sure we diversify. There's also scale and latency consistency, consistency when talking about reviewing a video or assessing. That for any specific guard rail, that usually takes a long time. So how do we make sure we don't ruin the experience? And then accuracy and consistency. We need to sustain high accuracy and high coverage across all our workflows. So also here we came down to a layered approach. So we have multiple checks at input and output so we can diversify the type of checks, but also at every single step between layer and tools, and we also have multiple layers of filters that are much simpler than. A a machine learning gardens. So some of the solutions cover real-time scalability. We do parallel moderation as we do parallel to cooling, but we also do sliding windows. When it comes to streaming output, we don't want to block our stream before it's over to understand if it's, it could be damaging to the experience. We also have content safeguards, so there are category specific protectors that we invoke when we classify and categorize a prompt or a tool output, and we have customized rules for diversity, PII detection, and so on. We also have automated checks and safe filing. So with this kind of workflows, the cool part is that when something fails, if you pass back the output of the guard rail, then the agent can take another part in this conversation or can try a different approach. So the conversation never stops, and we can always guarantee an output for our advertiser. Here is how it's implemented. As you can see on the left side, input guardrails and output guardrails is where we apply our guard rail service. We also apply that at any step between agent and tool, specifically when it comes to 3P integrations. Here we didn't have to invent much. AWS already provides all the building blocks, so the service is fairly simple. It's a router collecting all the services that AWS provides comprehend, bedrock guardrails, sage maker for some personalized guard rails that we have, but also recognition. AWS makes it simple and it's a fairly one-stop shop for all these guard rail rules. Some of the results we achieved with our usability efforts, it now takes just 2 days to productionalize a new agent from prototype. We have more than 100 experimental workflows running today and 40 production gene workflows and agents that are currently supporting advertiser traffic. We have on board more than 130 models. These are not different models. They could be similar models, different versions, different fine tunes, or not even LLMs. And we generate 150 million+ assets every single month. And my favorite one is that it just takes 2 hours from when a new model comes out to implement and serve that to every hour of every one of our advertisers. Now reusability gives you velocity, but that means nothing if you can scale it to all the customers that you have. So here is how we moved from 10. Beta users to millions of active users today. On the left side, scalability. Using a lot of the building blocks on the infrastructure layer that we discussed before that are coming from AWS makes it very simple. You need more traffic. You need more scale. Service quota is where you would do the change, and instantly you can get more of the scaling. We also implemented a lot of fallbacks on similar models that allow us to diversify the model we take, and if a model capacity. Is not responding as we expect, we can move over to a similar model, text to text or text to image that could do that could produce a good output. Similar to that, we have spillover quotas. So we make sure that we provide. Access to some models and the same model on a self-foster capacity so that if we have capacity constraints, we can spill over this quarter to our self-foster models and that we can control much easier. Very important for scalability is also service map and resource tracing. We want to know ahead of time when we're about to hit the limits. So knowing every service and their contribution to the whole general workflow and what's their quota left is very important. So at 70% of the quota we can proactively increase all the limits. Now we can also move into latency, as we mentioned before, where we implemented sliding windows gathered for streaming, that guarantees a very short user perceived latency. We do parallel tool execution. We also do quick start workflows. So what I shall showed before, many decision steps for the agent. Many times we recognize that those steps are recipes that advertisers want to execute all the time. So when we recognize that we classify that we can run a series of steps in parallel so that we shorten the time that advertisers feel they need to get to their output. We also have token caching that's saving us more than 3 times the cost that we were paying before, and latency is also affected quite massively. Thinking versus non-thinking. Not every task needs thinking, and also not every task needs the same thinking thinking quota. So giving a quota to an LLM for thinking, most of the LLMs will try to use all of it. Having that dynamically, depending on the task, helps a lot in reducing the latency. We also have aggressive timeouts. We understand that with this kind of workflows, Some of the components, tools, or LLMs could suddenly take a huge amount of time, and we don't want that single use case when you have 10 tools running in parallel to jeopardize the whole execution. So what we do is we apply aggressive timeouts and then we try more often. There's also seeds over prompts. We were used to create prompts for every single variation of our assets, while many times just changing the seeds or randomizing the seed could get as higher quality diversification across those assets, and that saves a lot of time. Now we can move to auto diagnostics. So Here as well, traditional engineering. Usually relies on certain inputs and certain outputs, as we discussed before. With agents, every single execution is a different path, so it's fairly impossible when you have millions of customers to analyze the logs, spot a problem that might only happen 3% of the time or 0.1% of the time. So how do we get through all these logs and understand if we have a problem? Well, we created some notebooks that allow us to automatically collect logs from all our executions, and then as you can see on the right side, we categorize those logs per conversation, per turn ID. And what we do, we use LLMs to read all these logs and proactively tell us if at any step of our conversation something could be optimized, a tool is not working as expected, or a prompt could could be rewritten. More than that, if we find a problem. These notebooks will try to see if there's already a ticket open to address some of these issues. If not, they will download the code repo, try to reproduce the same problem with the inputs found from the logs, and if they manage to reproduce the same problem, they'll try to create a fix. So engineers will wake up in the morning or middle of the day and find agents providing them with the clear signals and code changes to apply fixes to these kinds of problems. This is AI using AI. To build AI, which is something that we're trying to push more and more forward to make sure we can. Always understand What our agents are doing. Some of the results for scalability and latency. Our average time for first chunk is below 4 seconds. That seems a lot, but for GI workflows and some of those creating a video, that's a fairly low average. We also have more than 1 million active users in the US that use our services on a daily basis, and we consume more than 5 billion tokens per week across all the foundational models that we use, and our service availability is 99.9%. Which is not as good of a standard like AWS would have, but this is a genuine workflow, so there are so many things that could go wrong. Now we solved velocity, we discussed about scale, we solved that. Now comes the real problem. How can we build a reliable system when we have non-deterministic agents? The try strategy is everything you need to make sure you can control your agents. So we make very good use of fullback strategy, spillover quotas, and retry strategies for any type of use cases, for example, tool error, we we could try a different tool or the same tool with an exponential back off. Agent error, we can try a different agent. We can restore from a checkpoint error or we can try a completely different path from the orchestrator. Network error we can also do exponential back off, aggressive time out, and we can swap different route and eventually overall time out. But as you can see, no matter the path of what can happen across this. Many flaws, we always end up with a successful completion, so we always try to make sure we have an output from for our advertisers. Now non-deterministic systems demand observability at every possible level. You can't debug what you can see. So as you can see, we divided this very much with the same idea of the architectural layers. We have agent level observation. Here is where we track latency, tool calls, tool steps, and structure logs. We also have platform and infrastructure logs. These are the classic logs that you are probably used to when you use systems like Amazon, lambda logs, web socket logs, and dependencies. We also have tool and model level logs so that we can improve every single log, every single tool execution or model inference, depending on the path that's taken across our our workflows, and then product and UX layers. We want to know how our advertisers are using our product. How they turn our creatives into campaigns and if they're actually successful. Now this seems a lot But it was only half. We also have guard rail and safety. We need to make sure we have proactive alarms if we can detect any of the abuses. Capacity and quota providers we track 12, 3P models, 3 pieces of infrastructures, quota usage limits. We have alarms and all of that, and we have automatic. So that anyone in the team can address those problems. We have playbooks on how to move regions, on how to fail over on different models, and how to close that gap very quickly before even advertiser notice. And then closing the loop. From signals to fixes, as we discussed that we have a lot of auto evaluation in places that they are able to understand all the signals, understand all the logs, and help us trying to fix before any problem spreads. Now, so we built this, we scaled it. Does it work? This is one sample of the first results we got from our creative agent. As you can see, this was one of our partners that were using Creative agent, and some of the results are shocking. 338% increased CTR versus all other campaigns that were were not using G AI workflows. 89% new to brand offers. This means that we don't just appeal to current. To current brand customers, but all new customers, we completely unblock a new set of customers and also 121 return on ad spend. This means that we're lowering the costs using GI workflows. Advertisers are seeing double the revenue compared to the spending ads. So We know it works as metrics. We know it scales well, but how does it look? Let me show you. How cool was that? So, those were some of real campaigns that the advertisers are running on streaming TV. Now what are the lessons learned across all of this? Production line, the building blocks, not the demo. We started with just one prototype. We understood pretty quickly that that wasn't scalable, and we had to shift into productionizing building blocks. Keep page and scope small, optimize for context, delegate through an orchestrator, as Yel mentioned, we discovered at a very early stage. And then build for parallelism me drive from day one. This is key to work with non-deterministic agents and also make evaluation and observability part of the development, never an afterthought. Without data, it's impossible to debug. Moving forward, these, these are some of the things that we want to improve in our creative agent. So creative agent autonomy and deep research to enhance context, we want our agent to have way more intelligence, know everything about a brand, and try to predict what could work for any advertising campaign. Deep integration with broader Amazon native agents. Every team in Amazon is building agents. Every team in Amazon Ads is also building agents. We want those agents to collaborate between each other and leverage each other. One could specialize in data. One other could specialize in supply or specific customer segment, and we want to use all that intelligence within our creative agent. We also want to continue expanding our multi-foundational model effort. We don't want to just focus on one or a few models. We want every model that's best for the task dynamically selected by our creative agent and also scaling the service worldwide. We are doing all our efforts so that we can serve this as of in the US to every other advertiser worldwide for free. And now I'm inviting Avinash back on the stage for some final remarks. Thank you. All right. Am I audible? Thanks Fabio. Thanks Yashal. That's a great dive deep on the entire creative agent for ads, and uh, I would be continuing with some of the industry-based use cases within the agentic AI and also show you on like how AWS landscape is helping out. Well, we just discussed one of the use cases, which is the creative agent, but there were many to begin with customer experiences. In fact, we have seen a lot of agents building about chatbots and assistants within the advertising industry tech, what we could see is these agents are actually helping out and building campaign management and building out insights and also serving as a chatbots for many of the appliances. And then you have the personalization. I'll not go more into it. Just now we discussed about ads use case on the personalization. It's all about how creative you can be with the agents, in fact, building videos, images, stitching it all together, and driving the insights. Well, this is my personal favorite text analysis and automation. In fact, many of you might have seen on Amazon.com as well, there's a rooffus agent which predominantly helps you out on summarizing all the reviews and also giving you an insights about the products, and that's another use case where we were seeing a huge growth in terms of how agents are being used. And then comes the democratizing analytics. This is where the actual insights that help drive the business. For example, you want to make sure that your campaign ad managers or even the business insights people, they put a natural language text, for example. Show me my last 10 reviews or show me my last 10 products where they are at the top scale, something like that, and these can be easily converted into SQL queries so that they can automatically build those insights and dashboards for you. The reason why we highlighted personalization is that's the key theme for today on the creative agent. With that, agentic AI is evolving a lot and the landscape is changing rapidly. We have been seeing agents moving from POCs to production within less time. And in fact, as Fabio and Yal mentioned, there's a lot of aspects within the entire agentic AI systems. For example, you need these agents to talk to each other and at the same time they have to scale to support from hundreds of users to millions of users. And that's one of the primary challenges what you're seeing over here in the orchestration and scaling for these agents to start communicating to each other and then maintaining and then scaling. You need a certain best platform where you could go build and deploy and run these agents. Comes prompt and guard rails. Fabia has just mentioned about the responsible AI, and in fact this is something that is not limited to the creative side of the house. Any agentic AI applications should be equally responsible in terms of doing proper guardrails and mechanisms. In that case, it could be a few shot prompting, prompt injections, prompt leaking, all these sort of things have to be taken into control and make sure that you're implementing all the responsible AI methodologies. The third comes the advanced memory. So agents are not like fire and forget. You are constantly interacting with them, and you wanted to make sure that these interactions stay intact so that when you come the next day, it picks up from where you left off. For that you need a lot of context here. The context engineering is the new keyword that is evolving, but for all of this, it requires a lot of memory. So advanced memory techniques are another challenge, as in the wheelhouse that's going to be implemented for the entire agentic systems. The final identity and access, which doesn't need a great introduction. All our systems, in fact, something that I could talk about is being from the generative AI specialist area, I could see that most of these systems are following a trend of evolving from monolithic to microservices and now to the agentic AI systems where you talk with multiple agents, so you need a proper access mechanisms for all of this. Well, as we discussed all of these challenges, if you're building agents, you don't have to do something from the scratch because these are at a fast-paced environment and you need some systems that could be reliable for you in order to help you start building out these agents and ship to the production and start seeing those ROIs. And what we have on the AWS is I'll try to unfold it for you and make it simple within the entire AWS AI stack. To begin with, we have the infrastructure layer. And on the right side you're seeing Amazon Sage Maker AI and the left side AI compute. So if you're building models or fine tuning the models to make the models well suited for your agentic AI systems, something that we usually recommend is Sage Maker related products under Sage Maker AI. And then the AI compute, we have ranium and Inferentia, which are AWS based GPUs to help you host. And the very next layer that we have is the development software and services, and this is where we can spend more time in discussing all the available agentic care components. In fact, we recently launched Amazon Bedrock Agent Core. Bedrock agent core is sort of like a system where it has multiple components. To begin with, the runtime where you can deploy and host your agents and also scale your agents so that you don't have to go with the rest of all the orchestration mechanisms. And then the agent core gateway is a personal favorite of mine. It serves as a central piece for you to host your tools and MCPify everything, which is another buzziest word, MCP, so that you can connect with all your tools in one go. And then we discussed on memory. So agent core memory also provides you the capabilities where you can go ahead and have a large scale short term or long term memory systems. We'll not go more into it, but we also have the capabilities around Amazon Nova models which doesn't need a great introduction. They are the foundation models and Bedrock Asian Core and all of this also support. The open source SDKs like Lang chain, Crew AI, and strands as well is another one. But if you don't want to build these by your scratch, right, and then you wanted to use something off the shelf, then we have Amazon Quick Suite, Amazon Connect, which are purpose-built ANTKI systems so that you can go ahead and directly use it off the shelf and Kiiro is an IDA based agentic care system that has been recently launched. I'm pretty sure you must have checked out near the expo area, there's a Quiro booth too. So Quiro is a spec-driven development, uh, which is agentic AI based. Well, with that, I hope you all have a great session and really thanks for making out here. Feedback is a gift. It helps us to enrich and make sure we bring the right content for you. So please fill out the session survey, uh, towards the end and thank you once again. Have a great conference.