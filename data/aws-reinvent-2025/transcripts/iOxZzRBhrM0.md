---
video_id: iOxZzRBhrM0
video_url: https://www.youtube.com/watch?v=iOxZzRBhrM0
summary: "In the engaging session \"GenAI in the Beautiful Game: Data-Driven Success in Football\" (SPF302), Steve Drew, an Enterprise Architect at AWS, details the digital transformation occurring within top-tier professional football clubs. Drew argues that in a sport decided by fine margins, relying solely on human intuition is no longer sufficient. Modern clubs are sophisticated enterprises that must process millions of data points—from tracking players’ physical movements via GPS to analyzing thousands of match events—to gain a \"competitive edge.\" He presents a comprehensive look at how teams in the German Bundesliga and English Premier League are moving from basic spreadsheets to advanced Data Lakes, Machine Learning (ML), and now Agentic AI to revolutionize scouting, match preparation, and performance analysis. Drew highlights compelling case studies, starting with Holstein Kiel in Germany. They established a robust \"Intelligent Player Analysis\" platform that centralizes data from disparate sources. By capitalizing on Amazon Bedrock, they enabled non-technical staff (like coaches) to query complex databases using natural language. A coach can simply ask, \"How has Harry Kane's goal conversion rate changed in the last six months?\" and the system—powered by an LLM interpreting the schema—executes the necessary SQL against Amazon Redshift to provide an immediate answer. Moving further into innovation, Drew describes their experimentation with Reasoning Agents. These AI agents don't just fetch data; they \"plan\" investigations. If a striker’s performance drops, the agent might autonomously check injury records, then look at tactical diagrams, and finally compare recent match footage stats to offer a multi-dimensional explanation. Another fascinating example comes from SV Darmstadt 98, a club celebrated for its data-driven culture. Drew describes a targeted ML project focused solely on penalty kicks—a rare but game-deciding event. Using Amazon SageMaker, they trained models on historical penalty data to predict shot placement patterns of opposition strikers. This insight was boiled down to simple instructions taped to a goalkeeper's water bottle, blending high-tech analytics with low-tech pitch-side application. The session pivots to the English Premier League with West Ham United, known as \"The Academy of Football.\" Drew reveals that West Ham is building an end-to-end GenAI Scouting Platform. Traditionally, scouting involves filtering a global pool of 100,000+ players and manually compiling lengthy text reports. West Ham’s new system leverages Generative AI to ingest and synthesize diverse data types—match videos, news articles, and performance stats—into concise executive summaries. This allows scouts to cover a wider net of talent without getting bogged down in administrative \"toil.\" Drew outlines a future architecture driven by Agentic AI Workflows, where specialized agents (e.g., a \"Medical Agent\" or \"Tactical Agent\") collaborate to build comprehensive player profiles. He concludes with a powerful message: AI in football isn't about replacing the \"human eye\" or the manager's gut feeling; it’s about enriching human expertise with objective, accelerated insights to ensure that decisions—whether signing a star or making a substitution—are evidence-led."
keywords: Sports Analytics, Generative AI, Amazon Bedrock, Scouting, Agentic AI, Data Lake, Football, Premier League, Bundesliga, Amazon SageMaker
is_generated: False
is_translatable: True
---

Hello, good afternoon all, hope everyone's doing well. My name's Steve Drew, Enterprise architect at AWS. I work with some of our strategic partners and customers um as they're building solutions and using AWS technologies. Uh, today I really want to talk through the use of Gen AI and the beautiful game in football. Something that I'm quite passionate about. I mean, been a football fan for over 40 years now. I've worked in the data space in a while, like put the London Olympics data APIs together. But what I've been really happy to see is the explosion in the data that is created, how it can be used, and insights can be gained. And I thought I'd put this up. So uh Brian Clough, so one of the, one of the best managers ever from England. If God had wanted us to play football in the clouds, he'd put the grass up there. Now Brian Clough was not a man to argue with. And I don't think I'm arguing with him, but what I'd like to show is how AWS services are are influencing how football is being played. From today, what I'd really like to talk through is a little bit around some of the sports data platforms, the basis of what's going on, the information that Gen AI and AI services can process. We've got a couple of use cases which are coming from some English Premier League and German Bundesliga clubs. And then maybe a little bit around some of the evolution into agentic AI. And you know, football is one of the most popular games worldwide. You know, from people playing in parks to stadiums with up to 100,000 people to or billions watching a World Cup final. But one of the key things to say, it's not just a game of 11 players versus 11 players. You know, modern football clubs are very sophisticated organizations. We have a lot of different roles in there who are supporting the players to try and drive performance. I think with this this shows that results are determined by more than the 11 players who are on the pitch. And when teams are competing at the highest levels, there's some pretty fine margins involved and it's becoming increasingly important to try and find potential edges or to gain an advantage. You know, fundamentally, you know, what we're trying to do, trying to win more games. You know, but we have to do this by playing by the rules, we can't just invest in limited amounts of money anymore. But I think more importantly, you know, with the huge amount of community that's involved around football, you know, we want our fans to celebrate success. We want to grow our club in a sustainable way. And building that community is a big element of it. So if we think around the use of technologies by football clubs. How do we break this down into our sort of main components? So we have our use cases of, of what we want to solve, what problem we're trying to solve, where are we're trying to gain an advantage, you know. This is supported by a combination of data, some traditional analytics, as well as AI, ML, and Gen AI technologies, which is hopefully then driving us to gaining some insights, getting some value, hopefully getting a better competitive advantage. I mean, I think this is just a small sample of some of the use cases where we've seen professional football clubs using technologies. You know, whether that's around from a preparation element, you know, what should our training schedules look like. From a performance analysis point of view, you know, how are specific teams or the group of players who are on the pitch performing, how are they trending? And then the other big group is around scouting, so for both developing our own players and trying to identify potential future targets to bring in, to bring us more success. And I think a few, a few of you have probably seen this slide before, but data is the foundation. You know, it enables us to use those AI and Gen AI services to then derive insight and to try and gain that edge. And if we think of this in a football context, you know, we have external data sources, we have our own team's internal data sources as well. You know, we have videos that are being recorded ever ever more frequently. Where the highlights of specific parts of games, we have text data coming in. Which can be around, you know, coach reports, scouting reports. There's a huge amount of tabular data, what's coming through. If we think through the thousands of data points or data fields that are available around from how a player has performed with their passing KPIs, we have GPS tracking. Um, there's an ever increasing amount of data, again thousands and thousands of data fields and millions of data points. And as before we can start answering questions um with Gen AI on our use cases, at the end of the day we're still building applications. So we need, we need a database, you know, for the user experience outside of invoking the LLM. And you know, pretty standard stuff here where we've got a data pipeline might look like that data ingestion, where we're bringing in either via batch or real-time structured and unstructured data, setting up the pipelines to process this, to transform it, to get some initial insight out. But we have considerations as well, if we think around a data governance element. We need to ensure the privacy um and the security of that data, er where we can have potentially like players' medical histories in there, things like that. There is PII data and private data in there. So Why I was trying to face, to think of actually before we can go to that sort of general level, we still have our traditional data processing uh to do. From the combination of uh data AI ML and Gen AI. You know, from the clubs that we've been working with. The AIML is still there, it is still ever-present, really coming through from three parts. One from around the sort of statistical analysis of our er huge amount of data that's coming through. We're looking at trend and pattern detection, and also as well, where I've got down this sort of feature identification, trying to look at what actually what become the important data fields in this plethora of data that we have. And We still see a a large amount of use of AIML again as another layer of processing the data, which can then be used by our Gen AI topics. And again this this is just a quick summary before I go into the detail, but where we're seeing. The uses of Gen AI with clubs, we've got around that data extraction part, intelligent document processing, scout, how handwritten reports, things like extracting specific data attributes that might come out of that, uh, unstructured data. We look at that from an insights perspective, now we have our data lakes filled with data, how can we aggregate reports, information, and other part and other parts in there. And move to that last part from around democra democratizing our data, where we're thinking, OK, how can we make this, our data pools easy to look at, so that the, the scouts, the coaches, the other personas can easily query this data. And maybe to start off with what's a fairly common use case we've seen across a good number of clubs, where to start off with looking at how do we analyze the, our teams or players' performance. Again, this is taking the the thousands of data fields that exist and trying to work out where we can try and gain that competitive advantage. And that common approach really starts with that data platform, some er analysis, visualization and maybe a little element of Gen AI. And we're bringing in here, so from this example, one of the, there's a club in the, the German Bundesliga. You take the example of, they wanted to build groups of key performance indicators, which could then be analyzed and then looked at, processed for specific players. So we end up with, it's part of our data pipeline, where, where we come in, we've got 6, 800 different data points. We're extracting the groups of data features, whether that's like possession KPIs, tackling KPIs, each of those groups of KPI's can be made up of numerous individual KPIs and so we're doing that in our sort of data prep preprocessing points. Once we've had that, then as users are putting queries in or building dashboards, we can then do some longer term data processing, either in a single player, multiplayer, do player comparisons going across a season. But this becomes the foundations for our visualization. And I thought with this, there are many architectures that we've supported clubs in developing. Well, I've tried to pick one of the uh more simplistic ones to go with here, but the components are really the same. We have a number of 3rd party data APIs in the top right. We have a process to ingest that data, to ETL it, to then store it in whatever data stores that we like, using Red Redshift as an example. And then Fronting with either a custom build DUI or something like Quicksight to provide easy visualization of the data that comes through. And I think if you look up here, so the example from this club, very simple dashboard, but here I can query and compare players against these groups of KPIs that I look like, see how those two players can play. Now I'll move on to, as we start sort of evolving what's going on. We've been working with Holschenkiel in Germany, uh, in the German Bundesliga. I think the key message to highlight here is data, data helps us to generate important objective information in a short amount of time. And you know, football clubs are generating vast amounts of data, but often struggle to transform it into competitive advantages. So with this, the approach initially that Houston McKeel took. Was thinking of it from a data architecture perspective. And, because the data sources should not be sort of viewed in isolation, we've got many linked data types in here, really starting from er creating a sort of primary ID of every player they have, they could track long-term, the progression of how those players were performing both on the field in training, how they were progressing through the different clubs. And I think with it just to call out, there was this topic of opportunity on the left. They had identified that there were 6 key areas that they wanted to look at, whether that was the team management, workload management, or scouting. These become the sort of football domains that they found were valuable to use to them to gain insights. And sort of with this again, from that data model, we had a er data processing environment er set up, but that focus was on that intelligent player analysis. And sort of with this, there were 5 key technical principles that were put in place around scalability, and having a secure data foundation in there to build it as a sort of modular architecture so it could be expanded in the future. And I think a key part as well, is approaching this from a sort of event driven, but also logically separated view. And why was this important? Because this reduces the technical development or maintenance that's required into the future. Because at the end of the day, a club like Husin Kiel are, their focus is on football. They are not a technology provider, as is their core business. I think sort of in this example, this is trying to show how the um for a specific player, how their er attacking performance had changed over the last period of time. Then, building on this from that sort of data platform. Hosecure have been looking at how they could be use bedrock or use open AI on Bedrock to then gain further competitive advantage, trying to look at those sort of forward looking technologies. And I think Liam The the three areas that you may have seen before, it's trying to use it, how can we use these reasoning models such as OpenAI to try and ask questions via sort of NLP, natural language in here to have it for the LLMs to consider all of the available data points. Again to try and move on from what's a pretty static dashboard. I think they're trying to sort of visualize, maybe from that first part, from how we can bring in some natural language search into our existing data platform. We've seen a number of cases where it's a fairly easy part to start with. So from in our point number one, in our application, um, users can ask that natural language query, um how has Harry Kane, uh how, how has Harry Kane's, uh. The conversion rates changed over the last 6 months, taken in via what here we have a custom AI running on, on Amplify. That that user query is then passed passed to Amazon Bedrock Knowledge base, where. We can do both data retrieval, data processing. The knowledge base is then converting the user's request into a SQL query, er which we can then push to our existing query engine, Redshift in this case, to then extract the data. And sort of in here we've got a few places where we can have our data either labeled at the Field level in redshift, we could be using like grill tables to enrich it. But as our data, our, we now have our SQL queries run, we have our data returned back and we can then pass it back, er we can process it with our LLM pass it back to the user. With this, we can then go interactively, think around further questions to refine. Now There are some more complex reference er architectures that we have for looking at this, you know, a common way becomes as well, er adding er. Adding like a rag type data store here as well, so you can have pre-populated or pre-used queries defined by the data analyst to use. But it really falls back to the use case of how can we democratize our data, how can we get to that sort of uh better usage by what we have ofwi classes non-technical staff, whether that's the the coaches or whatever. I think one of the four, Hodgson Kiel with their choice of using OpenAI or Bedrock, um. It was looking for the reasoning capability that comes in, that's powered or becomes available. So maybe in that sort of question of why has our striker's goal contribution dropped 40%, some of the results we may see without heavy uh system or prompting that come back from an LLM is a very one sort of step answer. With the use of reasoning LLMs where it can be broke down into multiple tasks. Go into that sort of multi-step planning. We can look through, we can investigate more of the data sources that we've collected. You know, if we find conflicting information as we're iterating through the plan, the LLM can revise, um, its future plan to then use tools, whether that's SQL queries via to er via tools or er running code to then provide a more accurate answer. So I think having that er validation step in here, if we are planning to use er the data to change maybe how we're doing our training methods, becomes important. One of as Hush and Kiel were going through. Um, some of their sort of, let's call it digital transformation, they were trying to work out, you know, what their sort of compass should be, that, that phrase of what's our North Star. And it really came that way rather than just introducing new technologies, it's trying to answer some questions such as like how will our different teams or departments work together in the future. Most importantly, how can we enrich the human knowledge that we have. We have staff members with decades of experience. How can we enrich their skills with modern technology? And then how do you measure the success of new approaches? So they put together what they call their um. Data value generate the flywheel. And the high level idea here is to start off with looking at the data that they have stored, that they have available, to think through what the potential use case is from, it's because coming back to that point, it's important to work from that use case. With the technical infrastructure they've put together, it was then to take a use case to to quickly POC to iterate on it, and to see actually do they get value coming out for what they're trying to do. You know, then taking that to a sort of a a a full functional solution. If it's coming that way if that use case is successful. And we do have positive results, we can then start using it more and maybe we devote more people's time to using it, more financial incentive to it. But that then contributes back into the overall value of the er data platform and AI platform they've put together, because for each iteration when new features are being added. There's a better overall insight that is coming out. And I think again to to bring out another quote from it, I think it's the operational improvements to deploy human expertise more specifically is the key part to come out because all the technology that we're using or we're putting together, um, is there to augment staff at the club. moving on to a a a different club and it may be a little, a little bit more er ML than from, from Gen AI and as an England fan it always pains me to bring up the topic of penalties, er but in the Bundesliga, um, so Darmstadt, well I see Darmstadt, um. They are an extremely data driven football club. They try and build it into all of the decisions that they're making going forward. So as I was speaking to one of their data scientists, trying to pull out, like an example of uh where they are using some of the technologies. And you know, something like take penalties in football games, it's not a very frequent occurrence that they happen. Like they've got a pretty good conversion rate, 78, 79% on there. So they took the experiment to see if. If they can gain a small advantage here, it potentially modifies something pretty big on the pitch, that sort of goal event. OK, where to focus. So where we've got our as before, we've got our external data providers like from a penalty kick perspective, you know, you can have coaches going through manually watching videos. There is extrat, there are third party feeds available so you can see where for each player, for, for each player, which coordinates did he put the ball. Those sort of things, how do you approach the the layup. We have that stored in our uh data storage system at the side. And Fabian's view here is the focus is really trying to gain an edge rather than running, uh, setting up and running infrastructure. So here, you know, the choice he went with was by using Sagemaker Studio Lab just to easily set up his environment, um, to then using Sagemaker to train the model. One of the things that scale would help with this sort of scale to zero, sort of relatively low cost to run. And as they went through models built, um, the testing, I'll say still ongoing, that's I don't think that's something they're they're willing to share at the moment, um, but it was an idea where this, the use of technology was then used by the goalkeeping coach and the goalkeeper. To then have that list, you know, that list is still then stuck on a water bottle stuck behind the goal, but they've done analysis to see if well actually from the opposition striker, where is he likely to go. And I think with it it's trying to sort of be practical with it of, we don't have to deliver the most complex architectures to. Solve or answer questions or to gain insight. And I think with this, I mean, one of my favorite quotes at the top here, that emotion drives football but data drives progress. I think that's a really er powerful thing for a club to be saying, and this is where they want them, this is where Darmstadt at 20 or are using data at every step. Now, OK, previously you've been talking through how a lot maybe sort of stats, sort of data analysis, those sort of parts from it. But there are other sets of data that we wanna get er insights from, we want to augment the tabular data that we have. So within a football club, you know, we've mentioned that there are large amounts of coaches, scouts, and other parts coming through. And we want to take some of what are those still some of those handwritten reports that come through, some handwritten, some on tablets in other ways. To then looking how we can bring this data in to be queried alongside our tabular data. And again I've tried to keep it as from our sort of previous er data platform, we've got the ingestion, we've got the transformation, we've got some processing in here as well. The approach that was sort of taken here was to have the have photos of the handwritten reports just uploaded to a portal and then be ingested, stored to S3. We're then bringing it in sort of step function to initiate uh the processing, and through experimentation, er and some comparison against against extract. The use of an LLM was brought in to to do both the OCR or or IDP and telling doc document processing part of it to then extract some key insights and some key entities from that information. Um, as part of that process to do some validation on things like player names and other parts, some of those fixed known variables. And then That information was then written back to into our data stores, so it could be visualized alongside the existing dashboards um that were, had been created. And then maybe it brings out, so we had some document ingestions, and document processing. You know, the next we as we start building the increasing the types of data that we have available, we start looking at that next iteration of from our application, how can we start searching across multiple diverse data types and data stores, because having data stored in one specific, uh, we always try and pick the, Best data store for the right type of data, a better sort of performance that way. So you know, the, the next iteration was then looking at rather than er the use of say Quicksight for dashboards, we've got our, we've got our custom app written on Amplify, hosted on there. We're then looking at maybe how we can use um at this at this time it was Bedrock Agents to then look at to take the queries coming in from the user, you know, how is Harry Kane's conversion rate for the last 6 months as my previous example, um. We're then having our agent then connecting out to our structured or unstructured data stores, to then try and extract the relevant information, to then bring it back, to combine it. And then present that back to the user. And I think we then sort of move on. Where There is still er experimentation rather than essay into production going on, at least at least from what I'm seeing, but you know agentica that that hot sort of topic in there. You know where we're trying to take our three key inputs, you know, our memory of what's been done before, the tools that are available, the goals of what the user is trying to achieve, to then take some actions to query our data, make some observations, and then sort of iterate. And it was trying to think, sorry, it was trying to bring out how that single agent approach could work, coming back to maybe one of the tasks that were talked around. So what becomes the task? So we're looking at sort of er match analysis. So we want to look at the previous game and we're thinking around how does er how did our pressing play perform today. We're then passing that request into our agent, which is then looking at it from a maybe from a planning perspective, so from the user's query. How, what tasks do I need to break this down into, whether that's, you know, I think I've got it there for assessing users' asks, for evaluating responses, to analyze the data, something that the planning steps can be modified, can be iterated that it comes through. We're then calling out to some tools or some actions which will be commonly be those parts such as querying our data stores, so what does the historic er attacking performance look like? We want this sort of player level analysis or a team level analysis. And then with this, we have our agent then iterating through, going through the plan, ticking the points off, maybe adding some new ones in. But where the idea being that we now have a more flexible approach, or a more autonomous approach, whereas new tools, our information is discovered, we move away from it being sort of um er fixed coding or fixed prompts. And again like trying to bring up from the, from the architecture perspective, you know, I've a lot of people will now be talking around Agent Core for hosting our agents. If we think through in here, so from our user front end hosted at the left within Agent core runtime where we want to deploy our agents. You know from within here where we have the instructions of what we would like this agent to do. So if we think of it from a football data analysis perspective, have some of the the rules, the guidance of what it should look like. We can build out so some of the historic er like reports that we had available, things like these player reports, team analysis or player stats, we can make them available as local tools to the agent. So they are actions that can inform, they can go out and query our different data stores uh sort of in here. And again as it's iterating through, we can make calls out to Bedrock and the LLMs of our choice. Um, as we want to work out what to do, as we want to process our information and get towards the goal that our user has prompted us for. And I wanted to bring this one back to the 6 domains that Holg and Kiel had talked through. So as our systems evolve, as the, as we want to generate more er insight or gain more er visibility into our information. We can maybe approach it from that sort of multi-architecture approach, a multi-agent approach, sorry, I should say. Well actually we're thinking around those more specialized agents that are focusing on specific tasks. So they're moving to it, so this gives us that sort of we have more modular agents coming through. Again maybe one focused on that match analysis. It gives us flexibility because we can quickly add or remove. Um, agents and functionalities were coming through from a workflow perspective. We can think through of As our as we are using an orchestrating agent at the front, it can pick and choose the right tools or agents to use to fulfill the user's request. Again, coming back to the, there may be some sometimes that we only need to call a single agent. Maybe if we're looking on how a player has performed, but there could be, there can be some queries coming through, where actually we may want to make queries against 5 or 4 or 5 of these domains to then aggregate the results, uh, and to then come back. And I think what does this give us. It's really coming that way of that er flexibility of we we now rather than having previously having er rigidly defined rules. We're now looking at, we're now presenting a huge amount of data, a huge amount of tools, and then the actions taken can be customized or planned automatically by the LLM. Either based on the user's request or as new information is discovered, because we may get something back from, uh, if I take injury history in the medical insights, where actually Harry Kane's conversion rate went down because he'd injured his left foot eight weeks ago as an example. That might change some of the further analysis that is being done. And change the reports that are presented back to Our end users. And I think this, as we start deploying um multiple agents in here. I mean, in my view, it doesn't become much more complex. You know, we're still using agent core runtime to deploy those individual agents. The the pattern that we see is actually for some of the common tooling and the common functionality to expose that as er er either an MCP server er via Agent Core gateway. So the idea where we can have our common functions, our common reports, we can have them hosted in Agent Core gateway to be exposed to all of the agents that are running in there. With this, we can take either our existing uh API endpoints or we can take our existing lambda functions, interface them with agent core gateway, and then they become available to be used by any of our sort of agents that are running. And I think, so I've talked through some data, I've talked through AI, some bit of ML, a bit of Gen AI as well, and, and, and now from this point with agentic AI, right, not everything needs to be agentic AI. We, we really need to think what it makes sense based on our use case. So it comes with it, we can end up using a combination. Yeah, where we can be using a generative AI to be doing our uh information extraction from documents or report summarization, reports correlation and summarization. We can combine that with maybe some predictive AI where we're looking at trends that are going on in our stacks based data. And then maybe we consider using agentic AI if we're looking to maybe to plan, but most importantly to take actions. Depending on what we discover. And I think with it as well, there's always gonna be some components of workloads that make sense just to be run as traditional code. There there is no, there is no problem sort of with that. And With this, so. From a Use case perspective or sort of getting started, there's really two sets of guidances or teams that I would like to really bring out which can sort of help you on your journey. At the first is where you can build with the AWS Gen AI Innovation Centre, um, or secondly looking at building with an APN AI competency partner. You know, both groups have got a huge amount of experience of all the sort of technologies that we've sort of talked through today to help you deliver those projects faster, and I'll sort of call out a number of our partners as well because in sort of the partner network where there's some real deeper sort of industry er specialization. So maybe you want to sort of come through on. What I'll say is the the the final use case for today. So from West Ham United in the Premier League, you know, West Ham have a long running tradition around talent development, you know, known as sort of as the Academy of Football, and they have a strong, long background in identifying, nurturing and building talent. And with this, the West Ham's technical recruitment team have been looking at building uh an end to end Gen AI scouting platform. And I'll, I'll go on to this in a, in a little bit more detail. The first club in the Premier League, who were looking at using Gen AI end to end. And sort of with this sort of West Hamer partnering with both AWS and with APN partner Crayon as well, to try and make sure they're using the best technologies out there for their specific use case. If I, if I think through it, so like when I say er end to end platform using Gen AI, if we think through the scouting process or how it can look for, for er like a Premier League club. We're starting with a worldwide database of 100, 10, 100,000 players in here across 180 countries. Of the available players who are professionally playing football or coming through youth youth teams, they're using that, those initial data analysis going on to try and shortlist maybe some of those candidates. Based on some of the, the stats or the reports in newspapers or some of those other data sources that can come through. And that's sort of trying to break it down to a the first level watch lists of players to investigate in more detail. From that sort of watch list, you've then got scouts who are looking through watching videos, doing further analysis on players' performance, their trends, other components like that. And then they're building, though the scouts are then trying to build what's a text and visual report around that player. Now this is something that can become quite time consuming. Based on that shortlist, there's then reports are created, there's a er further priority list identified, but you've got to think the scouts are then going out to view these players in real life because statistics, video clips will not capture everything. And once that player has been uh scouted, there's then a much longer report put together. You know, you'll be talking 2030 pages putting together as they start, as clubs start thinking of should they proceed, should we spend more time, potentially spend money on this player. And with this, with all of that, we have we have some statistics and data analysis going through. But there's a huge amount of human element in it with the report creation. You know, and that's something where The Jenny LLMs and AIs become Very powerful at both helping create those reports fast, but also to help summarize reports. So maybe an idea of where you have uh sat on your desk, you've got 30 players to prioritize, 100 players to prioritize, to use the tools to help to bring out what a set is the most relevant information to then use. And with this, the time spent writing reports, analyzing reports, gathering that data is time that could be used better by actually seeing players and doing the analysis that way. So this really becomes the where West Ham really want to get to with their use of er Gen AI is using the technology to help scout and recruit scout and recruit players. um, really there to be to complement their existing scouting methods, um, to really to make this process faster and to get better visibility across, uh, the number of players. And by using the right technologies we can get that better scope of players covered. And I think it it's with a lot of it where we can use and clubs are using Gen AI around to give those productivity boosts to help with scale or to bring out that sort of further detail and um further insights that are coming through. So I think trying to come through that and try and sort of summarize where er West Ham. West Ham are with their talent identification platform. You know, covered sort of where they want to get to, to reduce that time and element from the er the scouts, the coaches they have available, to increase the level of analysis that they have available and to grow that player coverage. For me, The considerations, the data inputs that go into um our environments, well again we've got those er human crafted scout reports, those match reports and those ratings. We've got that combination of other modes of data, that event level data. Tracking data, physical data, there's a large amount of information going in there. That we want to consider in to to help advise the further decisions. And then from the, where does the the sort of JediI component come in come into it, so from the. Talent platform. Really coming in here. To process our different modes, our different types of data. Um, to be able to provide that sort of reasoning capability to think through what is being asked of it as new data or new, new variables, new insights are extracted. Um, to help increase the coverage of reports and the level of detail that's in the reports. And then coming to that sort of final part of it. Um, that evidence-led decisions to augment existing practices, again, coming back to that part that, The technology is there as a tool that is there to provide either more detail, a higher level of analysis, or to save time. Um, to save time that could be better spent in other places. Getting to that point where we have Automated creation of the due diligence reports, which can then be used in a er a scouting or a transfer context. And I think that's that's come through, so. The part I'd bring out about this quote is around there are many dimensions that go into identifying the right player for our club. Some can be technical, some can be financial, some can be a human part of it. The idea of where we can use data, AI gen AI services, we can increase the quality of the reports that are being created to allow us to make sort of better data driven decisions. So Much like uh LLM, I think my, my head's a little bit nondeterministic every time you'd maybe get a slightly different answer, but from a recap, 4 points that I'd call out. What we've seen across many clubs is that solid data foundation is really key, where we need to store the right types of data with the right technologies and then funnel it into a. Single interface where it can be queried depending on what our use cases and what our users want. The use of GI by the clubs is there to enhance users' experience rather than replace them with their. We, we have a game in football, there is still such a human element in it and those decades of experience, it's there as a, a complimentary um. Set of knowledge. And Without By collecting more, having more diverse types of data available, we can make better targeted decisions in when we're looking at our analysis and where we want to get to. One of the key things is, as our number of data fields start expanding and getting bigger. The use of LLMs will help us identify what is the right data to look at or the right data to consider. And then as we're looking at this from er with the use of er agents as well, as they're working through processing the data, this and narrowing down the right information to use, they can maybe take corrective actions if they discover new data, or if they get an answer back that maybe doesn't look right or requires further investigation. So I think that's all I had for today, running through er er. Running through that a little bit quickly, um. If anyone's got any questions or any other topics they'd like to talk about, feel free to come and see us at the side. Um, ask, ask questions now. However, anyone would like to do it. Um, thanks, that is a really interesting story, it's really weird to hear my voice come back at me, um. Is there anything going on in refereeing that you've seen as well? Not that, not that I've seen, um. Uh, it's been more relationship with the clubs rather than the FA sort of type level. Um, I would suppose, where, where would be your area of interest in there, maybe analyzing past performance thresholds around where yellow cards go or I'm. Yeah, I think as play breaks forward, they've all got a monitor in their ear. Real-time data going into their ear, I don't know. Player going into the box, this, this player's 90% chance of diving, or that real-time data going through, I don't know if that helps them or if there's anything. So there are, there are real time er there are real time analytic solutions available, none that the public can talk about today, but from that idea of adjusting that real time data, like when I was talking through the data sources, you know, some of it's pole, pull back, back looking. Some of it is that real-time screening based data, you know, if we think like with the, um, you could look at the way, so based on the GPS data that's coming through, you could analyze the players, I'll pick on Harry Kane again for some reason. You know, he has a 60% chance of going down when there wasn't proper contact uh to then feed it back. You know, from a, from a latency perspective, the services exist that that could be built and put together because you'll be talking with, You know, um, not necessarily subsecond, but within several seconds processing, imagine from capturing an event to then having it available to then correlating it against the existing statistics. That could make a very interesting um value add for a sports broadcaster as an as an example. But yeah, interesting question. I'll have a think on that one. Where do you see, uh, wearables? Many teams are using Catapult and Whoop and some other things. And so are you starting to see clubs requiring or asking for data associated with wearables in today's market? Uh, yes, so there's from a from two of the clubs mentioned today, so they are the, the data or wearables data from a, from a. Tracking location on a pitch perspective is being brought in and being ingested, and used for analysis on things like, uh maybe some of the performance stats on, um, miles run and other parts from it, from looking into the as as well there was a, Um. A use case to where they're looking at how, sorry, I forget which club it was, but looking how their back for their defense er linked up during a game so were people getting out of position, again that's more from using say GPS so from a player tracking perspective rather than say a individual er joint movement perspective. But that's something that falls into the data lakes that have been built. I think at this point it does come up a little bit more from like um AIML type analysis rather than gen AI, but it is something that's being considered. Alright, so I wanted to go back. Of AI and football going. Towards real time, so rather than having it as being used for more and more decisions at at at at at event time rather than either forward looking or at previous review. So like direct communication with like the coach or assistant coaches. So this is the idea, so what can you now, so where you may have if you think um. In a in a football ground you know you've got video monitors available, providing that insight so rather than the scout putting a handwritten note out, it then becomes, well actually here is, here are some real time things analysis that we're seeing that maybe should change the tactics that we're employing. I think from a. I think it would be a an uptake. It still feels a lot, so, there's still a lot of focus, I'd say at the moment around the preparation elements rather than at least with the clubs that speak to the past data and then they could use it during film sessions. Exactly, so we're going, OK, so based on based on the historical data, let us set up in a different way for the next game. Let's change this player's schedule. Or again from like the scouting part from it, but I think as we've seen from other industries, it will go to more and more real time information. Now on that real time information, there are some clubs um who are doing it in in training, um, there may be some clubs out there who are doing that who I haven't spoken to who are doing it live. So do you think the coaches would be open to that? Because most of the coaches are from. Let's just say, uh, like a legacy generation, right when you're moving servers and migrating everything right, going from legacy to the cloud. No, absolutely, as I say the. There was still a huge amount of human element in there if you think some, some coaches, some managers who've been in the game for 50+ years, you know, who, who may be, who may be less forthcoming to it, but I mean maybe if I go back to Hodgman Kiel's data flywheel from it, you know, at least conceptually. That idea is if you have shown and you can prove with a ROI that this process is giving you an advantage, it gains more acceptance and the the manager's still likely to make very strongly held with his opinions, but he may be more open to it. Thank you. So perfect. Well look, thank you, thank you all, um, if anyone's got any further questions, feel free to come and see us afterwards. Um there's a couple of the team, I think from Crayon here as well who've been working with West Ham and some of the Bundesliga clubs, um, and enjoy the rest of Reinvent.