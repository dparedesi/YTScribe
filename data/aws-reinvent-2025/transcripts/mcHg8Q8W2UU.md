---
video_id: mcHg8Q8W2UU
video_url: https://www.youtube.com/watch?v=mcHg8Q8W2UU
is_generated: False
is_translatable: True
---

All right. Getting observability right in multi-cloud environments is critical for our customers. I'm Nilo Bustani. I'm a senior solutions architect at AWS. I'm Santosh Mohanti, senior solutions architect at AWS. Santosh and I have both been working with our multi-cloud customers, and today we'll share some patterns that we see when implementing observability for multi-cloud workloads. So before we get into that, a quick word about multi-cloud. At AWS we define multi-cloud as the use of at least 2 cloud service providers to operate your IT solutions and workloads. AWS is committed to helping you succeed at your multi-cloud strategy. Now customers typically tell us the reason for selecting multi-cloud is either differentiated capabilities or as a result of mergers and acquisitions or regulatory compliance with AWS you'll have the freedom to choose and uh to make the choices that best suit your needs and innovate wherever your workloads are. So AWS's multi-cloud approach is based on the open standards-based cloud maturity model by the Open Alliance for Cloud Adoption. Now, multi-cloud is not just about technology, it's also a strategic decision. So AWS aims to help you create capabilities in both technical and non-technical, uh, pillars of people, process, and technology. In this session, we'll be sharing some cloud agnostic guidance and patterns to help you with your multi-cloud needs. So coming to the foundations of observability, um, you all are probably already familiar with this, uh, we wanna get good at detecting, investigating, remediating issues with the end goal of reducing our mean time to resolution and understanding our system's behavior and to do this, we collect signals from our applications in the form of metrics, logs, and traces. Metrics logs and traces are the first building block of the observability strategy. Here, we may have to ask how do we instrument our workloads across both the clouds so that we can gather telemetry consistently. Then we process this raw data into useful information. At this stage, we may have to ask what signals do we prioritize and keep as we scale. Our storage strategy answers questions about cost effective and performance storage for each data type, and then what visualization tools do we use to make sense of all of this data. So these questions are going to be part of any observability strategy, but when it comes to multi-cloud, there are a few challenges that get magnified. One is complexity. Customers tell us that with multiple clouds there's multiple tools and service dependencies, and teams find it cumbersome and time consuming to go between dashboards to arrive at the root cause of issues. Then there's process overhead. Multiple clouds means multiple services to instrument, and that means more work. Also, team members have focused knowledge in their own tooling, so there's a learning curve to overcome. And then also customers tell us that it may take months to get all of their observability tooling to talk to each other. Finally, scale. So with multiple clouds you have multiple streams of telemetry and that increases the amount of data that we need to handle. How do we tackle ingestion latency? How do we manage our query performance? And then how do we make sure that our data egress charges don't spiral out of control? Now these are problems that impact customers as they adopt multi-cloud and it doesn't matter which cloud providers you're using, they have a real impact on teams and then eventually the business. This is exactly why we need to discuss systematic approaches and patterns like the ones we're going to do right now. So we've seen two main patterns, the centralized collection pattern and federated query pattern, and then some hybrid combination of these. We'll discuss these two patterns and then also implementation approaches using open source and cloud native tooling. Now you may be using partner solutions for your monitoring and that's fine. When you look under the hood, you'll find the same patterns at work. So coming to centralized collection pattern. Here we're going to take an example with AWS and Google Cloud. We have workloads running in the two clouds. Uh, this is just for simplicity. This could be any clouds. Uh, so we have telemetry being generated in AWS and Google. Now we need something to collect all the signals and export it out, so we have a collector agent that we would have running on our compute workloads. Now for the infrastructure telemetry, this usually goes into the native tooling that the that each cloud provider has. So for this we may have to create configurations or we may have to build some mechanisms to export the telemetry. Then we need to make sure that the signals get reliably to its destination so we have an ingestion layer where we do buffering, routing, and handling back pressure. Now, in order to make querying easier, we would like to have our data format in a common format so we have a normalization layer where we collect all of the data and convert it to a standard format. Now all of our data ends up in the storage layer where it holds the full context of our request, and we can query it from our visualization layer to build a global view of our application. So that was the high level for the centralized collection pattern. Now let's look at uh an open source implementation of this pattern. So for the collector we've chosen the open telemetry collector. A quick word about open telemetry, it's a standard by CNCF. It's gained popularity because it's vendor neutral and it provides a standard way of collecting and processing your telemetry. Uh, it has support for multiple coding languages and auto instrumentation, and then there's a growing ecosystem of support around this. So that was open telemetry for our collector. For our ingestion layer, we can choose Kong as the API gateway and router, and we can have Kafka as the durable buffer to handle large volumes of requests. For normalization we can have open search data prepper to standardize time stamps, normalize service names, do aggregation, and then we'll index our logs and traces with open search for metrics, Prometheus specializes in time series for metrics, so that's what we have, and then Grafana for our visualization layer to correlate everything and to have a global view of your multi-cloud application. Now if we want to eliminate complexity a little bit more, we can have managed open source services. So we use Amazon managed Service for Prometheus, Amazon OpenSearch, and Amazon Managed Grafana. Customers love the out of the box security and abilities to scale that comes with these services. For instance, with Amazon managed Prometheus, you can have 1 billion time series. And you find that the ingestion layer is no longer needed because it's built into the managed services, and all of this is still in keeping with open source and maintaining interoperability. So let's see a cloud native implementation approach now here we're going to choose Amazon CloudWatch as our centralized storage. So this would be really straightforward for AWS workloads. The infrastructure telemetry is already going into Amazon CloudWatch, and we have the Amazon Cloud Watch agent for our compute workloads. We can use the same Amazon Cloud Watch agent for our Google Cloud workloads as well. Now for the infrastructure telemetry in Google Cloud here we need to build a pipeline to export this so we can have Google Pub Sub and then we can do the normalization in AWS Lambda and have all of our telemetry end up in CloudWatch and CloudWatch is also our visualization layer where we build dashboards, we do troubleshooting, we can do anomaly detection and then have automated remediations. So to sum up the centralized collection pattern, essentially we reduced our complexity by having a standard collector and by normalizing all of our data to a common format. Our process overhead is reduced because teams have fewer tools to learn and implement. And then we have a global and unified view of our multi-cloud application. Now Santosh will cover the federated query pattern. Thank you, Nilo. So we just saw how we can use centralized collection pattern to uh Consolidate all your data from different sources to one single space to get that unified observability. However, this approach may not be possible for all customers in all scenarios. There may be some use cases where. Uh, you need to keep your data in its original location. It may be due to your compliance reasons or it may be due to your, uh, cost reasons. In those use cases we can use federated query pattern. Let's see what is federated query patterns. So like I said before, federated query pattern allows you to query data across multiple sources while keeping the data in its original location. Let's take Nilo's example. What we have is your application as well as your infrastructure telemetry data has been generated and collected using collectors and stored locally in AWS and in GCP. The end goal is to create that unified observability for your multi-cloud application. In federated query pattern, we will have a federation layer that will take the query from your visualization tool and split it into multiple sub-queries for each cloud provider and once the queries are executed in this uh. Specific cloud provider, the results are then aggregated and presented to the, uh, visualization tool. And to process and plan the queries, the Federation layer uses metadata catalog to store the schema information. So we just learned what is federated query pattern. Let's see how we can implement this using open source as well as cloud native tools. So, Let's first look at open source, uh, for storage. We will store the telemetry data locally, which means we will store all your AWS telemetry data in Amazon S3 and all your GCP telemetry data in GCP storage. Now, in Federation Layer, we will use Tino, which is an open-source tool as our query coordinator. And we will use Hive Metastore as our metadata catalog to store the, uh, uh, schema information. So, and also we will use Grafana as our visualization tool. Now looking at the flow, Graphfana will send queries to Trino. Trino will break down these queries into subqueries, and then each, we can use Trino connectors to execute these queries in each cloud provider and retrieve the data from AWS and NGCP and then we will, uh, Once the data is retrieved from each cloud provider, Trino can aggregate those results and present it to Grapha for visualization. So that was open-source tool. Now, let's look at how we can implement this. We're using cloud native as well as managed open sources. So, we will keep the storage the same. Uh, we will store all your telemetry data in AWS telemetry data in Amazon S3 and your, uh, GCP telemetry data in GCP storage for Federation. We will use Amazon Athena as our query coordinators, and we will use AWS Glue as our, um, meta metadata catalog, which will help the Peterson layer to plan and process these queries. Now, we will use Amazon Managed Graphana as our visualization tool. Looking at the flow, Amazon Managed Graphna will send the query to Ethna. Ethna will process these queries and breaks these queries down to multiple subqueries for each cloud provider. And once the data is retrieved from AWS and GCP Ana will, uh, um, process these results and aggregate and present it to Amazon managed Graphfana for visualization. So though we just learned about these two patterns and how we can implement this using uni, um, using, uh, a cloud native as well as open-source tools. Now let's look at some key decision points between these two patents. When we look at these two patterns, this is the choice really comes down to your, uh, business drivers. Let's. If, if you're looking for like, you know, like the, the central or single source of truth, you should go for centralized collection pattern. Think about how you can get faster, uh, better analytics or better governance. Those things will be done in centralized collection pattern. But if you're looking for that, uh, like if you have compliance or data residency. Requirements, then you should be looking at the federated quarry pattern. With centralized hub, uh, you're optimized for speed and simplicity, which means faster queries, easier governance. However, federated query pattern gives you that flexibility and data freshness. Your data stays put, your storage costs are also optimized, and you're always working with the latest data. Let's look at some drawbacks or Some of the, uh, trade-offs, I would say centralized collection pattern increases your, uh, storage cost. However, in the same time, federated query pattern introduces query latency as well as, uh, it's, it's more complex orchestration. So while uh you make your decision, it's, it's very critical to consider these trade-offs early in your decision making process. So think about like when you make your decision, consider factors like what is your compliance requirements, what is your data freshness requirements, how cost sensitive you are, and all these questions will lead you to the right design pattern. Now, remember this, like this is not either or decisions. You can always do, uh, do a hybrid also solution depending on your use case. Now, let's look at a customer story. Phillips 66, a global energy company, they had challenges managing thousands of applications across multiple cloud providers. They have around, uh, 70% of their workload in AWS, but they have, uh, footprints in multiple cloud providers as well as on-premise. So, as a solution, they implemented centralized collection hub pattern. Also adopted open telemetry for their data collection and used tools like Amazon Managed Service for Prometheus or Amazon managed Graphfana to get that unified visibility they are looking for. With that, they were able to get 30% faster meantime to resolution, which is really great. Now, let's look at some next steps and resources. Uh, let me highlight some of the breakout sessions, uh, at Reinvent 2025 that deepen your multi-cloud expertise. Uh, these sessions are recorded as well, so it will be available after Reinvent. And also, do not miss our multi-cloud kiosk Klos Village. It's a space where you can see live demos. You you can deep dive into specific use cases, and also talk to our experts who can guide you, ask you, uh, if you have any questions, they can answer your questions as well as you, if you're tackling any problems, they can help you solve that problem as well. I also wanted to highlight some resources that will help you in your cloud journey, whether, uh, think of it as your toolkit if you're strategizing your multi-cloud um architectures, you're creating new architecture, you're optimizing your existing architectures, these resources can help you to move faster. Again, thank you very much for your time. Hope, uh, this session was useful for you.