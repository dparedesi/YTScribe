---
video_id: xTw9baDfXkU
video_url: https://www.youtube.com/watch?v=xTw9baDfXkU
is_generated: False
is_translatable: True
---

OK. Uh, good afternoon, everyone. And, uh, I'm Xavier Wang. I'm leading the specialist solutions architect from AWS Greater China Team. So today, I'm honored to be joined with three excellent speakers, uh, together to present what we observed in Greater China market. So we will have, uh, Kevin from MAC, uh, from LARC, sorry. Uh, product VP and Jason from Tuya, Chief AI architect, and Mike Gu from Deloitte, China, uh, the key leader from AWS alliance. So, here is today's agenda. I will start with some observations, uh, business insights, and the technical trend, uh, that we observed from Greater China market, uh, trying to share some insight and hopefully give you some inspirations how you could do AI. Uh, in the next steps, and then our guest speakers like Tua and Deloitte will share their product and how they are innovating with it the best. So, let me start with the important statistics, uh, from Ganner. So here's the number. Ganner says, uh, 41% of companies uh started their POC has brought their project into production. So the number is quite, uh, For most of the people here in AI every day quite disappointing. So, why is, why is that? And here is the disconnect, where the disconnect happens. So also from Ganner, we can see on the left side, the CEO top priorities for 2024 and 2025 was the revenue growth. But on the right side, we can see that the CIO and our technical leaders are investing their AI project mostly focused on productivity improvement. So that's what's happening today, and I think there is a code explaining why all this situation. The AI value has happened. AI really brings values to our customers, but, uh, like the phrase say, the future is already here, it's just not evenly distributed. We see companies are leading or succeeding with the AI. They are doing both, but maybe just more focused on revenue growth inside of only on productivity. So I want to share. Uh, 3 inside today. So the first one is more like from the business side. Which means I want to share some cases that our customers are succeeding, uh using AI to achieve more revenue growth and to others for software development and for the enterprise grade uh AI agent are more like emerging technical trends that I want to share with our technical leaders for the next step, what direction you can invest on. So, let's start with the first AI powered business transformation. So here, we summarized across all uh Greater China customers, 11 categories of use cases across different industries from the first one translation to intelligent operation, uh, from uh role play like applications, character AI to educational purpose assistant. And from customer service to auditing, content moderation and the intelligence, daily operation and maintenance improvement. So we have seen a lot of use cases. So the question is which use case Has the better business value comparing with others. So to answer that question, I want to show you, uh, two concrete examples. The first one is, uh, Huawei Keji. This company is a high-tech company, makes smart cameras for our customers. So, with the collaboration with AWS with uh Amazon Bedrock Services, which provide the API based mode access and all the building blocks necessary to build AI agent, uh, Huawei is able, uh capable to build their agent-based new features within 4 months, including, uh, for their, uh, childcare. Pet monitoring, dating companionship. Taking an example of the uh monitoring, today, Huawei is providing a subscription feature to their customers that uh a user can use natural language to ask, is my package delivered by Amazon stolen by others, or does my child arrive at home on time? So, for uh manufacturer customers, which is, has a business, business model of one-time deal to sell the device, today they are featuring their product with a subscription-based new business model. So another example is quite similar, which is called Ped AI. So this is a greater China's um Startup customer. So, uh, they are also the co-founder engineers are also having hardware background. So they are very good at making hardwares that collect good voice to reduce the environmental noises. And today with database collaboration, they are capable to host their models to give instant summarization of the recorded uh meeting minutes and uh like this morning's maths keynotes right after the meeting. The application provided by Cloud AI can give a summarize and highlights on the product launch. So these two examples are giving us, uh, very, very good samples of companies that are building new business business model for the hardware industries. So, uh, AI is giving these companies very positive feedback on returns of investments. So from business side, that's the first thing that we want to share, comparing with productivity, maybe we should invest more on business out uh outcome-focused use cases for AI project. And the second insight I want to share is the technology trend on the software development. So we have been uh going through the journey to communicate with machines from hardly like we, we write zeros or ones to communicate directly with machines to uh we invented like a high-level coding language like Java Python, just more accessible for AI, uh, for, for human coders. And to today, we are largely uh using AI to help us to code. Uh, today's AI capability is very good at generate um Code. So a non-technical person today is also capable to write codes to communicate with machines with only neutral language. So that's what what we are seeing AI powered the programming, the coding market. And globally we are seeing startups saying that like the model provider on topic, they are saying that. Uh, 80% of their product cloud code. The code of cloud code, 80% are written by AI. So that's also something we are seeing across, uh, Greater China's customers, especially for, uh, ISV customers, ISV startups. I will show some examples later, but, uh, for this technical trend, what we want to share, uh, through the slide is, uh, this is the SWE bench, uh, benchmark leaderboard. Uh, to explain, SWE is a software engineer benchmark. It lists, uh, many of real-life, uh, GitHub tasks for AI models to resolve, and here we can see the top 12, and 3. the top ranked models are Chinese model providers like the 3 is the mother, uh, company of our today's guest speaker, large company. So, what I want to uh emphasize by this slide is that uh Chinese uh model providers are very active on model, uh coding models and also providing different coding IDEs. That is a trending, uh, that we need to pay attention. Maybe tomorrow we will have some really good products coming from, uh, Chinese vendors. And through that example, uh, It will bring us to the 3rd technical trend, which is AI agent. Here, I think everybody agrees that we are talking agents everywhere, but what I want to emphasize through this speech is the distinction between the word agent and agenttic. So while agent tells us The nature of this AI assistance is helping us to finish task, but Agentic is telling us the how behind how we achieve this. So taking the example of Kiro, Kiro is Amazon's coding IDE, and before the very first generation of coding agent or coding IDE, what we are using, leveraging is the model capability to predict or complete code. Means human type the first sentence of the code and AI help to complete the code, right? That's the very first generation of AI coding IDE, but today's IDE, the key capability is not just coding. Once it has implemented the task, it will run the code and it will fund automatically the issue and To do a self in a self-reflection way to do the loop and correct by itself and do the the loop uh unlimited times until the task is done. So that comes the word agentic means. So today, the agent and agentic represent different things. The technical trend is that we are doing every use case another time with a new approach, with the agentic approach. So the reason behind it is quite simple. We are seeing the model capability increasing on the model reasoning. Means that today's agent, we can have a key agent to do the planning, split task into the smaller ones, and it can do the self-reflection loop across different agents. So that means As I said, today's focus for agents to execute different tasks. We need to focus if the environment is secure, is the um Observability well managed by the company or if the tools that agents will use could be easily fine. That's why we launched at AWS, the agent core so to facilitate enterprise to use uh agentic approach to build their AI applications. So here are two examples of the 100% gentic approach applications, uh, the two startups are called Manus and GSpark. They are capable to generate report, automated report generation, uh, like PPT creation, and the, the most important is that they are doing the planning, uh, in a 100% autonomous way. So, uh, today, uh, In different industries, we believe that every use case could be rebuilt again or uh with agentic approach. That's what's seeing happening, uh, starting from ISV startups like Manus and Gens Spark, but we believe we are start seeing large enterprises also collaborating with us at, uh, in greater China regions, uh, to start building agent uh or new applications with this agentic approach. So before I hand over to our guest speakers, uh, I want to share also because we, we not only AS are helping our Chinese, uh, companies expanding their business globally, we are also helping uh multinational companies like Siemens, uh, like many other, uh, manufacturer or different industry customers to lending, uh, to land their business in China. So we are offering uh global consistent. Generative AI technical stacks through three layer from infrastructure, model building platform and the solutions, uh, assets, uh, uh, but beyond that, we are also offering. Our expert human resources to help our customers, including fine tuning their models using distillation or model pruning technology to make the models smaller to be running on edge devices, and we also have global partners or local partners like Lloyd. Uh, our today's guest speaker to help us, our customers really lend their generative AI applications into production. So, uh, that's how what we can offer, uh, as product and services, and that's how, uh, for my part of sharing. So now, uh, let's welcome on stage our first guest speaker from LAAC, uh, Kaien Shi, uh, VP of product. Welcome, LA. Welcome, Kevin. Is that a shot. Hi everyone, it's great to be here at Reinvent. I'm Kevin and I lead the product team at LAC. Today I have 3 things to share with you. First, what is LARC and LA base? That's my products. Second, how we innovate with AWS. And finally, I'll show you some real world examples of how our customers use AI to work smarter. Let's start with luck. Lucky is only one works with. We bring together the tools you use every day. Like chat, meetings, and docs, but we don't stop there. We combine them with powerful business apps, like approvals, ORs, and our local platform Labase. Our goal is simple. Teams shouldn't have to switch between 10 different labs. We integrate everything into one unified workspace. This makes work smoother, faster, and more efficient. To make all of this work. Great product design is uh only the part of the story. We also need to make sure our service is stable, reliable, and secure at every scale. Over the past few years, we have invested heavily in our infrastructure. We ensure that organizations of any size can depend on luck without worrying about performance and safety. Let's talk about lack base. You can think of Labase as a flexible database, that feels like a spreadsheet, but works like an like an application. Is we design our goal is to let the system build. Their own operational system. And Quickly and with confidence. You know, Labase, um, is a no-code platform. We, we offer a lot of tools inside Labase. And uh last year, we have Publish a lot of new features. The first one is uh database. This is the core foundation of Labase. The database we built specifically for Labase. In real environments. System built on labbase generate a lot of data. Especially when many people work together, our the system has been running for a long time. Teams also use flexible formula and the relationships across different tables, similar to Excel, but at much larger scale. To support this, we build a database. That is designed for these scenarios. A single table that business users work with can store up to 10 million rows, while still handling high levels of concurrent editing, and frequent read and read operations. Even with this volume and flexibility, teams, the system still stays fast and responsive. Another capability our customers use a lot is the dashboard in in workbase. It's designed so teams can build the reports on their own, quickly and with confidence. The dashboard connects directly to large amount of data in Labase. And it comes with a rich set of charts and visual components. Teams can explore data, build a real-time view. And present insights quickly, even though the data set is huge. The performance is smoothly, smooth. And that makes daily operations. And decision making easier. And once you have the data, well organized. The next step is making a flow. That's where our workflow capabilities come in. With laba Teams can set up very flexible and powerful workflow automation. So data moves smoothly across steps, and every process becomes more efficient. And through deep integration with services like AWS, Lackbase can pull data, trigger actions, and connect your business system end to end in a very similar way. We also bring many AI capabilities into Lackbase, helping users learn the product faster, build more efficiently. And to bring intelligence directly into the everyday business workflows. And later, I'll show you some real showcases. With the support of AWS, the core capabilities inside Labase run with strong stability and performance, even as our customer scale. At the same time, many of the intelligence services available on Amazon Bedrock are now integrated into Lackbase. For example, teams can set up, teams, teams can use bedrock models inside our fields. To extract key information from natural language text, how to clean and structure large sets of data. This same AI abilities also available inside our workflow engine, so users can automate every steps. And let the system handle routine. Analysis for them. How does this integration work technically? This diagram illustrates the flow for the AI field shortcut. Bed powered by Bedrock. The AI field shortcut is our most popular features. I will, I will introduce some. Uh, new, uh, some real world showcases. So next, let me give you two concrete examples of how Bedrock's AI capabilities are used inside Labase. You can see the red one. The first is customer sentiment analysis. You know, traditionally, analyzing the voice of the customer data is highly manual. With log base and bedrock, you can simply create a new color. And instantly invoke AI capabilities. The AI analyses the feedback, whether it's text or an image, identifies the sentiment, summarizes the core issue, and automatically applies relevant text. This structured insights can then be used in BI dashboard for trend analysis. Auto automated support workflows. You can see the left one, left one. Another powerful use case is smart recruitment solution. You know, HR teams can upload resumes in various formats. Using the AI field shortcuts, like this extracts key information. Like skills, education, experience, and more, and automatically generates candidate tags. It can even perform intelligent matching against job job requirements. And generate suggested. Interview questions. Based on the candidate's profile. In both scenarios, we are transforming complex and manual processes into efficient AI powered workflows. Trigger that just a simple click. Beyond the technical integration. We are also deepening our partnership with AWS. Lagbase, L, and Labase are now available on the AWS Marketplace. It's much easier for companies to get started. And we are also seeing great momentum from the AWS ecosystem. Many AWS channel partners have become. Like resellers. And we have built a strong coal cell. Motion With AWS sales teams. Today, LAC works closely with AWS teams. In many countries and regions around the world. And these collaborations continue to grow. Well, that's a quick look at how we think about luck and luck base. I will work with AWS and how teams are using these capabilities to run their businesses into efficient and smart smart way. Thank you. Thank you, Kelvin. Uh, thanks a lot, Taiwan, for sharing how LARC is, uh, building the Agentic end to end productivity tools. Now let's welcome our next guest speaker, uh, Jason from Tuya who will share how generative AI could also empower the IT world. Welcome, Jason. Hello, everyone. Good afternoon. Uh, I'm Jason, uh, Chief AI architect from T2R. Next, I'm going to introduce Tua Omni AI Foundation. But Before we talk about that, let me share a little bit, uh, a little bit about first. Tua is a leading IT company in the world. Uh, we focused on making our lives smarter and uh we do that by providing a cloud platform that connects a vast range of IOT devices and let you see some numbers. Uh, our shipments are ranked number one in the world as an IOT part supplier, according to CIC report. And uh we have a large amount of developers. We have around 1.6 million registered developers developing on our platform. And We cover 200 countries and regions in the world, and 2I enabled devices are available in around 120,000 channels in the world. This timeline shows the history and the milestone of Tuyang over the past 11 years. Tuy was founded in 2014 with a focus on providing a global IoT platform. And by 2017, we were expanding into the global markets. And by 2019, we were Our business is accelerating by providing an open and neutral platform ecosystem. And 2021 was a major Milestone of 2 years. We list on the New York Stock Exchange in that year. And we list Hong Kong Stock Exchange. In 2022. And recently, we were more focused on sustainability and the ESG. And uh we also innovating in areas like smart commercial and smart energy, etc. Throughout this journey, uh, Our partnership with AWS has been pivotal. We launched the global IoT platform in AWS US region in 2014, the same year the TI was founded, and uh we launched the European platform in AWS Frankfurt region in 2017. And uh In Mumbai 2019. And uh we became the APM partner in 2021. So we are constantly innovating together with AWS. So let's talk about Ty Omni AI Foundation. We are seeing a huge Surge in agentic AI but building. Agenda AI on hardware is really difficult. There are a lot of challenges. You need to tackle the problems like unreliable network and the the un-devised coding is really cold, is really difficult, and uh. To bring the conversational AI to the device, you need to bring a lot of AI services together like ASR TTS, larger language model. It's really difficult. So we aim to create an AI hardware innovation platform to empowering our customers with practical, secure, and reliable AI hardware. So that's the overall architecture of 2 AI on the AI Foundation. We designed this AI foundation with 3 key principles. It's state driven. It's domain focused and it's scenario oriented. And we provide AI foundation, not a single API or uh devices SDK. We combine them into uh integrated solution. We use generative AI embedded OOS cloud software, and then we also use China's strong manufacturing supply chain. So, on the right side, uh, it's basically how we design the platform. At the bottom, it's uh AWS infrastructure. We use services like EC2, S3, as uh As a base layer. And On that, above that layer is IOT data and knowledge layer. In that layer we collect a lot of device data. And uh we process them and we convert them into IT knowledge and that's the whole AI whole base of our AI system. And next is the AI model layer. AI model layer is just like the brain of the AI system. We use uh AWS Nova and uh we also use some small models we train onage Maker. And uh on the top layer, on the top layer is uh AI agent layer. On that layer we provide many Components that connect to devices or provide an easy to use platform for our developers. Uh Now let's look at a key component of the two-year Army Air Foundation, two-year real-time communication network. That's the reason why uy minent AI Foundation is so responsive. It's robust and it's efficient. But why? There are a few reasons. The 2-R real-time communication network is not new. It's built on 8 years of 2-R IPC experience. It's already handles tens of millions of real-time audio and video sessions daily. And its global reach is massive. We have 7 data centers. 10+ acceleration networks and 1,300+ nodes. So that really makes our users. Uh That really makes our Network responsive. And it's secured by design. We use per device secure token and uh we use for data isolation to protect our user data. So the performance metrics really highlight its powers. Uh, the TRTC is resilient to 70. 30 to 70% of network packed loss, so it's usable even under the bad network condition. And its global average latency is is uh 86 milliseconds or less and we have AV start rate that is below 0.8%. We have video instant start time that below 100 milliseconds. So build on that. Really fast network. Let's see the real-time conversational AI engine. We achieve a subsecond latency and a seamless for duplex interaction with that that engine. It's really about the whole process we Process the audio from the device and uh to the cloud then we go back to the device. So it starts with the device side and by the way, we provide the device SDK for our developers so they don't need to. Handle the difficult of noise reduction, echo, echo cancellation, etc. And the device will send the audio data to the cloud. This is where the engine starts to work. And uh we will process the audio through the server VAD ASR and the ASR will turn the audio into text. And then we do context engineering, like we will do web search, we will select correct tools for that conversation, we will recall the memory. When everything is ready, the context is feeding to the larger language model. The we let the larger language model to generate response. And We will audit the result of that response, then we convert back into audio and send it to the device. So we do a lot of optimization in that process. And uh we can achieve 1.3 seconds of the global. Average end to end. Latency. When we say end to end latency, we mean when the time. User stopped speaking, user stopped speaking to the point the device receives the audio response. That just takes 1.3. Second, global average. So let's see how we make the whole platform easily usable for our developers. That's the uh developer portal we call it dynamic orchestration aging system. Uh, you can see it's actually a, a canvas, so developers can create the AI agent just by drag and drop the nodes on the canvas. There are a lot of nodes there. You can create no nodes like a large language model, uh, intention, recognition, and uh. You can connect them together. This is a, this is a screenshot of our real. Real world agent, it's used by our uh 3R smart app. With this DOA system, our developers and customers can create. Agent easily and Intuitively So after developers and uh customers finished their testing and uh Developing their agents, they will put the device into production and we are ready for the Massive influx of the AI hardware request. We have the experience of manage large amount of connected devices and uh combined with the capability of AWS. Infrastructure, we are capable of handling such large amount of AI hardware requests. And uh we are not just connecting them. We are Bring more powers to the devices. We can create automations uh with our rich skills and uh we can remember users uh references and uh we have a large IT devices knowledge base. And we are not just innovating in the audio side, we are also innovating in the vis visual security. By providing the IPC motion detection solution, uh, based on AWS BedrockageMaker, and OpenSearch. Our ABC solution. Support standard object detection like package identify, manage acquaintances, and abnormal event alarm. And uh we also provide advanced generator capabilities for broad applications. And Our success rely on the strong partnership with AWS. We have achieved many certificates from the AWS and uh we are, we are proud to be recognized as a partner, partner of the year for both 2024 and 2025. And currently, 80% of to their customers deployed on AWS. And uh it's across 5 regions worldwide. And by innovating together with AWS we are able to save, save 10% on the cost of AWS infrastructure. And some of our Solutions already available on AWS market, uh, for example, to a hardware solution. To a hardware solution is actually a lightweight private IT server software. So It's designed, it is designed to run. can be run on minimal infrastructure. And Our develop it uh provides core capabilities of IOT and uh also it provides a robust API so our developers and customers can use to a hardware to build their business logic and to create unique IT applications. So that's all. Thank you again. Thank you. Thanks a lot, Jason. Uh, so, while Tuya and Lark are exemplifying, uh, Chinese companies expanding their business globally. Uh, we also have our last guest speaker who will explain how to run their own, uh, productivity platform, a 100% compliant way in mainland China as LA is not only our global partner, uh, not surprisingly, they are also very close partnership, uh, with Database in mainland China though. So, uh, let's welcome Mike from Deloitte to present how Deloitte is improving their productivity in mainland China. Thank you. Good afternoon ladies and gentlemen. Uh, my name is Mike. I'm the partner from Deloitte China. And today I will give you a quick overview of how Deloitte is thinking of the enterprise usage duplication of generative AI in a 2B market. Actually, uh, AI, you know, is a very popular topic right now around the world. Everybody using AI, but it's uh mostly it is in to see perspective, right? Everybody has an application on our, our cell phone. We use it very conveniently. But how AI be used in a business group, in an enterprise, actually is quite different. So let me share something with you. OK, uh, Deloitte has made our own generative AI platform which we call name is Delta AI. And then we build this platform based on these 5 considerations. Actually, we have made a lot of interviews with some business leaders. We have a very deep conversations with these high-level management people of a very big company, a very big business group. These 5 questions are the most frequency questions they've asked and we've been discussed. Actually, questions a lot of uh maybe more than 10 questions, but these 5 is a very high frequency appears in our conversation. You can see the first one. Use case, the so-called use case actually is the scenario. valuable scenario in a business group, it's very important for them to use AI. Not everything can be enabled by AI actually in a business group, in a large company. We need to find out which one is the most valuable that AI can enable it. So that's the, the, the, the, the leaders, that's the ownership of the companies they they considered very much the most conspiration things. And the second is the choice of the large language model and the business partner, which is the tools. OK, we have a very, we identify a very high value scenarios, right? And then use what kind of tools and the uh who will help us, help the company to, to, to implement this tool is the second consideration. And the third is, OK, we have scenarios, valuable scenarios, we have, uh, very suitable tools, right? We have a partner to help us, and then what incremental capabilities a company should have. To fit to meet this implementation. And the third is, OK, we have people, we have vendors, we have tools, we know what to do, how much we should invest on it. This is a very important thing for a leader of a company they will think about. And how much, how much and how long we should invest. And then the last one is we have all this ready. A transformation will happen. How we do the transformation? Maybe the organization of a company will totally changed. So, based on these 5, we have our own platform. Let's look at it. Use cases, OK? Use cases, which means, uh, now we are talking about, we are using another one, not use cases, we are using the terms of the high value scenario. You know, a company from R&D to manufacturing, then supply chain and sales and marketing, and then back in office, finance, legal, a lot of things, whatever. Which part of the business? is very much be empowered by AI, by generative AI. So we have this, uh, 4 quadrant diagram. The, OK, we have the 4th stage, you can 1234. From the beginning, we have an efficiency play, right, which means we can identify some quick win scenario. Let the company know what, what, find a very easy one to find out the result. Let the company have confidence. OK, gene gene generative AI can really can help us. So we will find out some quick win scenario first from efficiency play. This is very easy to, to, to, to think. Uh, change human from machine with high efficiency, right? And then we come into the experience play. What, what do, what does experience mean play means? The difference between the one and two is the quality. We are not just increase the efficiency, but also increase the quality, so we come into the experienced play. Step by step, the scenario has been identified and then we come to capability play which a set of agents coming to a platform which can change the whole process of a company's business running process, make a very high level some we, we, we said we can unlock the strategic value of a company by using GAI. And then the last stage is what we say stays with human, which means we have a digital employee. Not just human employees, we also have digital employees who can run a lot of things for our company. So this is the steps we identify a valuable, a very valuable scenario for a company. So we call it uh be cases. And that the right choice of the two. You know, in the world there is a lot of large language models right now, so many tools right now. So our strategy, Deloitte strategies. We are not, we will not place a bet. We will remain opening. You know, we remain open because every model has its advantage, its benefit, but some disadvantage, right? Everything has pros and cons. So we will use the, the very important thing is we will ensure using the most optimal model. Of which the most suitable to our business needs that make sure that it has been. Implied consistently. This is the very key thing. So we are remain open and we are value driven and capability driven. Make sure the right things has been implemented to the client so we are not just stick on just one, we are open. So our platform has connected to a lot of modules, you know, in China, maybe some, uh, some, some models in the outside world cannot be connecting. We will use some local modules for replacement, something like that. So we will have a set of technology method to make sure customers can have uh multiple as much as bigger the multiple tools they have. And we have the right tools, we have the right scenarios, OK, then the incremental capability must be built in the company. So, what we will do, you can see, uh, in the core, these 4 levels, business partners and use case management, right, which is the uh valuable scenario. It's very important. That's where, how to implement, where to use it to make it valuable, to make it show benefit. And then second, the generative AI product management, which is the platform, which agents we use is the most suitable one to make sure the suitable one to meet the business needs, right? And then the third is the uh model management, which is the tools choosing. And the, the last but not least, the knowledge management of data and integration is in GAI perspective, we are not calling it data management, we're calling it knowledge management. You know, actually today all the data is we call assets of a company. Maybe it's more valuable than money itself. So all this data, all these assets come together will be all knowledge of a company. It's very valuable to make very few, very long term benefit for a company running. So surrounding these four levels of the core capabilities, we will have, uh, we will of course have the compliance, right? The bottom line, the red line should not be crossed, so the compliance and safety and security, and also on the top we will see the strategy of the governments, which is the company's running strategy, and all these core competitors will support a company's strategy. And then besides that, we have, uh, for example, company like us for their uh business partners to help them to implement all these capabilities. OK. Then, OK, this is a very important thing as we talked about a lot of the, uh this topic with all those CEOs, those leaders of a company. How much and how they should spend on it. OK, this is a very typical, uh, Ghana, Ghana hyper circle, which is also uh we call this smiling curve. Every new thing coming to the world, we experience this smiling curve. From the beginning, People will have a very high expectation of a new thing. Everybody says, oh, GI is very good, we can use it to make a lot of benefit, a lot of money, something like that. So the very, very high excitation come up. And uh on this rise, we'll call it the 2nd you can see the peak of inflated expectation. Of course it will be inflation because you have some expectation which is not actually can be done. So after that, people will feel disappointed, says, oh, generate generative GI is just like that. It will not help me at all sometimes, maybe just a little bit use, so you can see it comes down and we call it, it comes to the sort of disillusionment. People come to reasonable, rational thinking. When they come down, they will come back to think, what really a GAI can help us, can help me in my business, in my daily work. So you can see the blue line in the middle. The blue line, the use cases, the number of use cases, which is the value can bring to a company, actually is very consistently increased, but the people's expectation. As long as the investment will go through this peak of inflated expectation and then come down to the sort of disillusionment. That era coming to a stage we call the slope of enlightenment. People become reasonable thinking about how GI be used in a company. And then you will find a Plato stage come. The Plato stage is the productivity. Continually consistently increase. So a very important thing is when we come to the stage 3, you will see the total cost. Actually will not increase linearly with the number of use cases, which means if you go through the 123 to 4 stages, after that you will really gain the benefit from GI, which means less investment but more. Uh, benefit you get. OK, and then we have all these benefits, we have tools, we have everything ready, and uh how an organization make the transformation. Because the, the traditional way we do now is so much different from the GI, uh, the the JI age. So tradition uh traditional way is come the Uh, uh, but, uh, uh, top to top down, it's top down way. Leaders, the management team, they have an idea and they endorse or they even give the order to the execution, executive level to say you have to do this, do that, and from top to the bottom, people just make execution of the orders come from the management team. This is traditional way of the digital transformation. But in the AI generative AI age, things are different because a lot of information is not come from the top. Maybe it come from around you, come from the world, from the other people, and come from the, the very basic 1st, 1st line employees, so you will see. Top down, also, there will be top down, right? But a lot of it come from bottom up. The first line employees, they will find out some very good things. Even the boss didn't think about it before, and they will, they can give the ideas from bottom to the top. And then also some outsider change. Outside changes also make a very big influence in the company. So the transformation will be three parts combined together. This is the new model of the transformation in the organization we, we have found in our customers. So the organization itself has been changed a lot. It's not just like the normal uh hierarchy. The hierarchy is also very, very flexible right now. OK, the, uh, with these 5 considerations, we built our platform, we call it Delta AI, but now we changed the name to Nova. Actually it's a, it's an integration of the agents that meet the business needs of a company. And we build on the Amazon, a cloud platform. From end to end you can see from the R&D, from supply chain, manufacturing, marketing, from the all the life cycle of uh uh uh a tradition, a normal company, every business unit we have covered in our platform. Each of the box is aging, so you can, I give you a a screenshot of our platform in our customer. This each each box of this platform is the scenario we identify together with our clients, which is the five candidates at the top. The first, the first of those 5 considerations, identify the most valuable scenario first and then think about how to implement it. So this is a sample of one of our clients. And also in our company ourselves in Deloitte China, we also the user of this platform. We are not selling this to our client. We also use it by ourselves. So you can see the numbers. Uh, we have uh uh 20,000 employees in China, Deloitte in China. Some audit people, test people, and the consulting people in the technical team, we have more than 2000 users are using our this, uh, Delta AI platform, this generative GAI platform. And the, the, the monthly active user is more than 10,000, which is a very high frequency COC. And the most important thing is you can see from that. The gross margin, we have our internal calculation, the gross margin has been significantly increased from 36 to 43. This is very important for a company like us. So this is the, this is a proven provement of that if you identify the right scenario, the right business case, you will really get benefit from it, from GI platform. OK, then why we choose database as our partner. Because the DAI is built on AWS, because, of course, uh, AWS has the world-class cloud infrastructure, right? And also they have a lot of their own agents. Their capability is built on this platform. We can easily gain the benefit from them. So make our team to build the D AI more easier. And then they keep upscaling their platform. We can grow together with them, so enablement and upscaling is also very, very important from the support to us to Deloitte. And also the solution incubation and out out and outreach we together develop some new technologies, new methodologies, new tools to our clients. So this is why we uh stick very uh strong relationship with AWS together on this GAI platform, not only for us but also for all Deloitte clients. And in this platform, we have these 5 layers, 4 and the other 5 over there, and this is the technology platform of our uh Delta AI. So we have knowledge base, we have model, multi-models, of course, and we have agents. The agents means that those cases we identified. And support those use cases and also trustworthy security, something like that. OK, this is, uh, this is more like an, uh, advertisement of our platform, so I will not talk too much about that, but you know this is very, uh very good platform we build together with AWS, right. OK, uh, this is the, uh, my last page of this, uh, today's presentation. Generative air technology continues to advance at incredible speed. That's true, right? Day by day, very rapid. However, that's what we found. Most of the organizations, a lot of the companies, they are just moving at their own speed. Their own organization, they have their own habit. They are not changing that much to fit the world's changing. So they are not at the speed of technology. This is a world we always talk to our clients, ask them to, you need to think. Outside your outside your box. Think about the world, how the world, how technology grows faster, you need to catch up. Otherwise you will follow, you will, you will lose this competition with your competitors. OK. This is my uh presentation today. Thank you. Right on time. Oh, thank you. Uh, we are reaching to the end of our session and a quick recap of, uh, uh, our today's presentation. So we have seen our, uh, customers' story, uh, how AI is helping them, uh, transform their business globally and locally in China, and we've seen the technical trend on AI coding and the agentic AI. Uh, but most importantly, what we want to deliver today is that, uh, we hope our stories can inspire you, you, your team, and your business, your company to really capture the real value for your business. So, uh, if you want to do some more QA, we will stay there for a couple more minutes. Um, that's all. Uh, thank you for listening. Thank you.