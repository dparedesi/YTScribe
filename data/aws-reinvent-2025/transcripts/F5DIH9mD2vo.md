---
video_id: F5DIH9mD2vo
video_url: https://www.youtube.com/watch?v=F5DIH9mD2vo
is_generated: False
is_translatable: True
---

Hello, everyone. Um, it's great to be here with all of you today. Uh, thank you for joining us in today's session, which is the last of the day, and of course the best. Um, and it is Trading Innovations, Jeffrey's AI assistant on Amazon Bedrock. My name is Alex Marrake, and I'm a principal industry specialist for capital markets at AWS. In my role, I lead business development for trading and financial market infrastructure providers globally, and I've been doing that for about a little over 4 years now. I'm really looking forward to today's session, uh, not just because I'm presenting it with Sanjay, uh, but because it showcases how the industry is trying to adopt Gen AI into those at-trade workflows. Uh, before I pass things to Sanjay to introduce himself, I'll quickly share our, uh, our agenda. So today, you're going to hear how Jeffrey's built a trade assistant agent on AWS to solve a common problem that the front office faces. Which is accessing and analyzing massive amounts of data for trading purposes. You'll hear a bit about how Jeffrey's trade assistance capabilities. You'll, and you'll also see its architecture and a demo. Uh, then to wrap up, we'll share with you the impacts that AI Trade Assistant is already having and some of the next steps that Jeffrey's has in store, uh, for the solution. Uh, our goal here is for you to leave with, you know, some fresh ideas and strategies that you can use in your own organizations. Uh, oh, quick housekeeping note, um, we won't be taking Q&A, uh, during the session, but Sanjay and I will be available afterwards, um, I guess around there, uh, to answer any questions you might have. So, uh, with that, uh, let me invite Sanjay maybe first to talk about the partnership between Jeffries and AWS, uh, and then the, uh, the trade assistant agent. Cool. Thank you Alex. Uh, hello everyone. My name is Sanjay and I'm an SVP at the electronic trading, uh, at Jeffries. I lead innovation in Jeffrey's equity technology space where we design and support multiple mission critical applications. Our focus spans, uh, messaging, processing, distribution, and visualization, all essential for enabling fast and reliable trading workflows. A little bit of, uh, about Jeffrey's. So Jeffrey is a 60 year old, uh. Full service investment bank over that period we have built a reputation for delivering top ranked, uh, capital markets and investment banking capabilities across a wide range of industries and geographies. The key to our success has been our motto clients first, always. It's not just a tagline, it's a mindset that we drive that drives us in every decision we make. Our mission, our mission is to help every client we represent to fulfill their maximum potential. Whether it's trading or investment banking or analytics, every solution we build is designed to empower our sales and advisory teams to deliver sharper insights and better outcomes for our clients. So I'll take a few seconds to discuss about uh Jeffrey's and AWS's partnership. AWS has played an increasingly important role in helping us drive continuous innovation for our customers. Our journey began in 2022 with an initial infrastructure buildout, and today, AWS is in every aspect of the Jeffrey's, uh, innovation, innovations. In fact, every corner of Jeffries, uh, there, you, you'll find, uh, a cloud native, uh, solutions that are running on AWS. For example, in trading, Jeffrey's built our fixed income algorithmic trading platform right from scratch. It responds to RFQs, executes trades, and runs complex algorithms natively on the cloud. Our equities trading pla uh options, uh, team uses AWS to calculate multi-factor pricing scenarios in an extremely volatile market. And, uh, uh, for and, um, beyond that. I think we've also democratized Gen AI across Jeffrey's with the rollout of our Gen AI GEF AI, our enterprise grade AI platform that offers secure modular, uh, system for generative and agentic AI. It supports tasks like, uh, smart retrieval, document summarization, and automated workflows. Employees can build custom bots, conduct deep research, and streamline operations. GEF AI seamlessly integrates with many of our internal, uh, systems and supports leading AI models for maximum flexibility. And the use case that I'm personally most proud of is the trade assistance which we're going to discuss today. Here we are going to, we are deploying Gen AI to improve business user engagement through a chatbot that provides traders with AI driven insights on trading patterns and market liquidity, while also dramatically reducing analysts and developer toil. In short, AWS is not just a technology partner, it's a catalyst for innovation across Jeffreys. Let me talk about the trader system now. So why did we partner with AWS to build a solution for the equity front office? The reason is to, is, is to solve a set of challenges that Jeffrey's, uh, equities traders face today. And it's hard to access real-time, uh, insights about client behavior, trade patterns, and market trends because the amount of data is so vast and so fractured that we are able, I mean, we are talking about millions of, uh, trades a single day which are stored in multiple different data stores and visualization tools, and this is global. It also is impossible to have an end to end visibility that all the traders want. Traders need a way to coalesce around all of this data and generate insights, but oftentimes they don't have the time during the day or the coding ability to generate and maintain a system capable of delivering this. The result is that traders find it difficult to arrive at at the insights that they need when, uh, when they need that they need when they need them. They face barriers that slow down their decision making and impact both trading and, um, and, and providing, um, and. Then and so what we set out to is to solve these exact problems and we built a solution that reduces these barriers to providing insights that empower our traders to access real-time conversation analytics and with JNAI. This is how the trade assistant was born. Let me ask Alex to walk you, uh, through the solution, um. Capabilities and architecture. Great. Thanks, Sanjay. So ease of use and accelerating time to insights were key drivers in the design here. Um, when the trader submits a query to the trade assistant, the underlying LLM, which in this case is the Titan embeddings model, uh, generates the result resulting SQL query. It then queries the underlying data and services the answer, the answer in a variety of, of form factors, you know, text, uh, tabular outputs, uh, charts and graphs. Uh, the solution has, as Sanjay was mentioning, um, just now, a conversational analytics uh interface which allows traders to drill down on topics and explore data insights, uh, conversationally. And the system maintains um conversational context to provide relevant insights and suggestions uh for deeper analysis over the entire um lifetime of the user's uh session. The solution also uses strands agents, which enables Jeffrey's technical teams to build and run AI agents with, you know, minimal code. Um, and there's also flexibility in here uh for Jeffrey's to easily choose different LLMs for specific use cases uh through Amazon Bedrock, um, as the trade assistant uh evolves. From a security perspective, uh, the solution has advanced guardrails coupled with low-level data entitlements to prevent accidental access to customer sensitive data. Uh, through intelligent access controls and all conversations of course are logged with, uh, complete audit trails, uh, to meet compliance requirements. I'll, I'll pass it back to you, Sanjay, maybe to walk us through a demo. Mhm. Thanks, Alex. So I'll show you how this works. Uh, what you'll see here is a user interface, uh, with a sample question that the trader will post to the assistant. The interface is part of our our existing BI platform called the Global Flow Monitor or GFM for short. The GFM contains a trove of real-time trading data that our front office traders rely on every day. And when the traders log in, their credentials, um, um, they, I mean, uh, the credentials are verified to ensure the right entitlements so that they only see their data that they are authorized to see. The experience is simple and intuitive. A trader can type in a question like, uh, give me the sector breakdown for trading in the US today. Behind the scene, the assistant uses the power of, uh, LLM to generate the appropriate SQL query, run, run it against our, our, uh, relevant data sources. In our case, we host all everything on grid gain, our in-memory data grid that retrieves the data instantly. But we don't stop there. The response is then passed on to a Python library that converts the raw data into a visual story, charts, tables, and insights that does displayed right on the screen. This contrasting feature combined with conversational analytics with a rich visualization has been received well by the trading community. I'll pass it on to Alex to walk us through the architecture. Cool. Thanks, Sanjay. So, let's look at the architecture in a bit more detail. Uh, first, we establish a connection between the trade assistant and Jeffrey's on-prem business intelligence platform, uh, GFM, which, uh, Sanjay just mentioned with an AWS direct connection in step one. Um, you know, once a trader logs into GFM, they have a UI widget to interact with a trade assistant agent. Uh, as you can see, um, in steps 2 through 4, we build several services, uh, using AWS EKS to authenticate users and create user sessions and query LLM agents. Uh, once a user successfully authenticates, uh, the, the request is routed to the bot services, um, step 3. Which establishes a user session and invokes query agent. Um, double clicking a bit on, on step four, for a second. The query agent here is actually a strands agent, which I mentioned a few slides ago, um, that operates at the core of that LLM interaction. It takes a question from a trader and interacts with multiple MCP, uh, tools to decide which data source to pick to best answer the trader's question. Uh, we selected STRN's agents for their simplicity and advanced functionality, but I think we didn't start with, with strands agents, right, Sanjay? We took a few steps beforehand. Yeah, we started off with the lang lang chain, and then eventually pivoted to strands basically, uh, based on the recommendation from the AWS team, we observed a lot of improvements in the processing and, uh, having the, that ability. We decided since we're starting. Starting from scratch, might as well use the latest. Makes sense and easier to orchestrate. Yes, cool. Great. Um, so back to strands. Uh, so Strands plans and executes, uh, the agent's steps using the advanced reasoning capabilities of the underlying model, which, um, I mentioned earlier is the Titan embeddings model, and we also decide to use Amazon Bedrocknowledge Base as a vector store, as you can see in step 6. Once the query agent identifies the right data source, uh, and creates the under the SQL query, the query executor service queries the underlying data. The LLM chooses the visualization to display, and we use a markdown UI library to render the visualizations, um, in step 8. Um, I'll pass it back to Sanjay to talk about the impact and some of the next steps that Jeffrey has in store for the solution. OK, thanks, Alex. Uh, we are already seeing significant benefits from the trade assistance in our beta rollout to, uh, around 50 users across sales and trading operations. We delivered an 80% reduction in the time spent on routine analytical tasks. That time savings unlocks massive efficiency and translates directly into increased revenue generation capacity. The adoption rate has also been high, which speaks to, um, um, the solution's effectiveness and the user satisfaction, and we're planning for a global rollout to our uh trading user base. Beyond the time savings, the, the solution has reduced the tech burden for producing custom dashboards across multiple prototypes and trading desk. It's self self-service capabilities also means lesser dependency on tech resources while creating a consistent. User experience across multiple desks. We also democratized data access. Business users can now query millions of records of equity trading data using simple natural language that enables real-time discovery of trading patterns and market opportunities, something that was previously out of reach. And importantly, the architecture is future-proof. It's self-learning, so it continuously improves and adapts. It integrates easily with Jeffrey's, uh, existing BI platforms and infrastructure, ensuring scalability and maintainability. In short, this solution ensures, I mean, sorry, in short, the solution bridges the gap between complex financial data and business user needs, providing a platform that's not only powerful today but built for continued growth. Throughout the journey we have learned, we have learned a lot about ANTKI from the architecture patterns to prompt engineering best practices and performance trade-offs. This was possible thanks to the deep collaboration with Alex and the AWS account team where we experimented, iterated, and refined our approach. Looking ahead, our global rollout strategy focuses on three key pillars multi-product expansion, extending the trade assistance beyond the equities. To support diverse uh prototypes and trading this. Second, the global deployment proven bringing proven efficiency gains to the international trading operations. Third, enhanced governance, strengthening observability and auditory capabilities to meet our regulatory and compliance requirements. We're also exploring advanced code generation. This means transitioning from a UI based, uh, Java tools to sophisticated NLP driven code generation for a better user experience. At the heart of our technology organization is innovation and reusability. We are identifying similar opportunities across other business areas and aiming to turn this solution into a generic AI generic API that can be used firmwide. In short, we are not just solving for today's challenges, we are building a foundation for the future. There are a few learning, um, there are a few key learnings that we want, that I, we wanted to share with you all today. Which we put on the screen in front of you. Uh, the first is don't rely on LLM to generate visualizations because of the risk of hallucinations. Use a faster data store like an in-memory database to maximize speed of the result output and build LLM interactions with Python, uh, for flexibility and everything else can be in Java so that we can port your existing code to the, uh, to the Java interface. And maybe Sanjay, before we go to the next slide, can you just kind of double click on, on takeaway number one? Jeffrey's leverages the LLM to select the specific agenda output um for the query, but doesn't generate itself. It's the Python library, the markdown library that does that, that generates that so that way we have more control over what can be generated and we can leverage over the open source available which can make, make those, make that difference and minimize the hallucinations. Yes, perfect. Cool. Um, well, thank you, Sanjay. Um, we look forward to continuing our partnership with, with Jeffreys and, you know, supporting you as you roll out the trade, uh, assistant, uh, to, uh, more desks and more product types. Um, and thank you everyone for joining us, uh, today. That concludes, uh, our talk and our presentation. Uh, please be sure to fill out the survey which is in the app. And as I mentioned, uh, Sanjay and I will be available offstage to answer any questions you all have. Um, enjoy the rest of your reinvent, everybody. Thanks. Thank you.