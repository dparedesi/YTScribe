---
video_id: HFOdQbWhg5c
video_url: https://www.youtube.com/watch?v=HFOdQbWhg5c
summary: "In the session \"Fixing AI’s Confidently Wrong Problem in the Enterprise\" (AIM269), the speaker (representing PromptQL) confronts the \"elephant in the room\" regarding why 95% of AI pilots allegedly fail. He argues that the root cause isn't a lack of raw intelligence—LLMs surpassed human IQ benchmarks long ago—but rather a trust deficit caused by AI's tendency to be \"Confidently Wrong.\" In a business context, a wrong answer delivered with high confidence is worse than no answer at all. The speaker posits that human colleagues remain valuable not because they know everything, but because they have the self-awareness to say \"I don't know\" and the capacity to learn from context. Current AI products lack this \"admission of ignorance,\" breaking the feedback loop required for improvement. To solve this, the speaker presents a novel product philosophy implemented in PromptQL. Instead of a black-box \"Chat with Data\" interface, the system uses a transparent \"Knowledge Wiki\" architecture. During a live demo, he shows how the system handles ambiguous queries like \"What was GM (Gross Margin) last FY (Fiscal Year)?\" Crucially, the AI parses the query and visualizes its \"thought process\" using color-coded links: Blue for known concepts (e.g., \"Gross Margin\" is defined in the wiki) and Red for unknown assumptions (e.g., \"Fiscal Year\" is ambiguous). Instead of guessing, the AI flags the gap, prompting a user or an invited domain expert to provide a definition. This interaction triggers a powerful \"Learning Loop.\" When the expert clarifies that \"Fiscal Year ends in January for APAC,\" the system doesn't just use that fact once; an autonomous background agent updates the central corporate Wiki. This effectively crowdsources the maintenance of Tribal Knowledge, converting ephemeral chat interactions into persistent, structured assets. The speaker contrasts this with competitors like Databricks Genie or Snowflake Cortex, scoffing at the notion that enterprise data can be flattened into \"25 tables\" for a context window. He claims PromptQL's wiki-based approach allows it to scale to 100,000 tables and 10,000 metrics, as it doesn't need to \"know\" everything simultaneously—it just needs to know where to look in the wiki. The session concludes with a strong message: AI adoption will fail if organizations try to \"pre-load\" all knowledge before launch. It is impossible to capture 100% of a company's tribal knowledge upfront. The only viable path is to deploy a system that starts imperfectly but is designed to fail gracefully, admit uncertainty, and empower users to teach it. This shifts the user's role from a passive consumer to an active \"teacher,\" building the very trust required for AI to move from a toy pilot to a mission-critical tool."
keywords: AI Trust, Tribal Knowledge, Human-in-the-Loop, Confidently Wrong, PromptQL, Enterprise Knowledge Base, Continuous Learning, Chat with Data, Data Wiki
is_generated: False
is_translatable: True
---

All right, um, so, um, I'm gonna talk about, I'm gonna talk about this, this big challenge that we've seen, uh, over the last year that you've read about. I don't know how many of you saw the, uh, MIT 95%. Pilots failed report have people come across that report that was like all the news a few, few, uh, months ago, um, and, and one of, one of our kind of takes on the problem is that the big issue is that that we're not really solving for is this problem of AI being confidently wrong, right? And, and so what do I, what do I mean by that? um, AI has been around for. 223 years now, right, we've all been using it, um, I, I don't think ever in the history of any new technology it's gotten close to a billion users in such a, such a short period of time. Um, it's kind of insane, but, but if you think about the kind of science fiction reality of us as technologists going to our business people and saying. Um, here's AI. Go, go use AI and, and make decisions. Ask, ask questions on your data and say things like make, make decisions that will improve the business, right? Uh, make better staffing decisions, make better pricing decisions, um, uh, make decisions that will improve the business, uh, in a meaningful way, in a way that you couldn't have done before, and that's what AI can give you. Uh, it's, it's finally, it's finally accessible. There's the big challenge there is that. You're still not able to use AI connected to your data in a way that you can trust, right? So. Almost all of us would have tried some kind of AI on data project, right? You take an LLM, you connect it to a database, MCPA, whatever, whatever connectivity technology you use, and you can make it work. But, but when you are on the business side and you ask a question that is loaded. The impact of that question is pretty serious, you, you know for a fact that you're not going to trust what it says, and, and the reason is because. You know that it's gonna be hard for even a human to answer those questions, but at least the human would tell you that they don't know. And if an AI tells you something, it's just extremely confident, and you have no idea whether you trust that confidence or not. If, if you think about this ability that AI has of just being confident all the time and its impact on being confidently wrong, that, that is kind of what really hurts adoption, uh, as, as you start to use it, right? It goes from like a fun project to I, I can't actually trust this to do anything useful, um. Is this a is this a better models problem or is this something that we can we can do something about can we solve this problem ourselves? So I'm gonna share with you our learnings um as as we've kind of built an AI product on how we tackle this problem and hopefully some of those learnings are useful to you as you folks think about your projects, um. And, and, and, and that gives you some ideas on, on how you can tackle this problem, right? Um, how many of you listen to, uh, Dwarkesh Patel's podcast? Do all right, cool. All right, no, uh, for those of you who don't, you guys should, uh, uh, listen to Dwarkesh Patel's podcast. It's got a bunch of, bunch of really fun stuff, um. I think the most recent one is by Andre Karpathsi and then by Ilya who is the co-founder at OpenAI, um, talking about a bunch of topics around learning and continuous learning and utility of AI, right? And, and this is, this is something that came out from his blog post a while ago and I really, really like this quote, right, which is that the, the reason why a human being is useful. In your business is not because they have 500 points of IQ because they win the IMO gold medal, um, every time you talk to them, right? It's not their raw intelligence. The, the raw intelligence kind of was passed by LLMs a while ago, right? Um, it's it's not the raw intelligence that makes them useful, it's, it's somehow this ability that they have of picking up context on the fly, of, of, um, looking at a failure, thinking about it. And, and fixing that failure, right? Um, it's, it's this ability of like, Incrementally improving that you can trust the human to do. Even though the human is not as quote unquote smart as Deep Seek V3 which just won the IMO gold, but, but somehow the human is still more trustworthy, right? And so this ability to continuously absorb tribal knowledge and improve, um, is critical, right? But But this is, this is obvious, like we all know that we want AI to continuously improve, learn tribal knowledge, and do whatever, right? Our key, the key point that um. I want to share is You can only teach something when it says it doesn't know. And that's kind of the critical thing that's missing in AI products, that confidence, confidently wrong hurts you. Even if AI got really good at learning continuously, the confidently wrong problem hurts you because if AI doesn't tell you when it's wrong, you can't teach it, and if you can't teach it, you can't use it and, and that's kind of this core product loop that's missing, uh, with AI products, right? So let, let me, let me talk about what we do at PromptQL and show you a demonstration of how we kind of approach this problem, right? Um, broadly, we're yet another chat with your data product. It's uh it's fascinatingly amazing and new and differentiated uh with everybody else here, um, but the idea is to say that if users are interacting with data they typically talk to multiple people um to get some kind of insight, right? When you want to solve a problem, you wanna make a decision, you're a business user, you talk to an analyst, you talk to a scientist, you talk to an engineer, uh, they talk to each other, they talk to data, something happens, some spaghettiness happens and you get the result at the end of the day. Um, most often when you ask a question you'll probably get the result like 2 weeks later, by which time the question is not very important, right? And the promise of AI is, um, we'll have this cool, uh, AI thing that sits in the middle that users will use. Users will use that AI. The AI will do everything that the. Human does the AI will do data engineering and it'll do data analysis and it'll do data science and it'll compose all of it magically and give you an answer and by the way this might have sounded like rocket science like a year ago, but today you can see very clearly that it's already possible. You can take cloud code and make it write a pipeline for you and then you can make it write a sequel thing for you and then you can make it write a data science program for you, right? It's already in the realm of reach. It's already possible. The thing that's missing though is that you can't actually expose it to end users in a way that they can trust it. If you look at all of these chat with data products, ultimately they all turn out to be text to SQL products where you need the technical person to look at the SQL to verify it. So you can never give it to a non-technical person. Because a non-technical person can't read SQL, uh, how do you trust it? You, you can't trust this AI system, right? And so our operating model is to get AI to admit that it doesn't know so that experts who are the red boxes can teach it. So that the AI gets better, but most importantly, because the AI can tell you that it doesn't know, even on day zero when it's only 50% accurate, it's fine. Users can trust it because if I can ask you a question and you tell me that you don't know, that's great. I'll ask you two questions and you tell me half the time you don't know, that's totally fine. I can still use your product, right? Um, so I'm gonna demo kind of how we do this in, uh, in product. Um, this is the This is the core loop that I'd like you folks to watch out for. The first part is to tell you what it knows and what it doesn't know. That's kind of where the cycle begins in the product. The second piece of the cycle that's critical is that you can, once it tells you that it doesn't know, you can ask it to fix its stuff. And then once you do, it learns that these are kind of the three pieces, um. that I'd like you to kind of anchor on, right? All right, so Um, I'll do a recorded demo and then I'll do a live demo because like live demos are fun and dangerous and uh who knows if they'll work but let's say for example you ask a question on what was um GM broken down by region yesterday, right? What our system does is it. First, it, it does a plan to solve the problem, but you notice that it highlights in blue links what it knows, um. And where that knowledge comes from, right? Internally, if you, as a user go click on that blue link. That is actually a wiki that powers the AI internally. This wiki contains concepts like gross margin that are pretty flexible. Let me roll that up for you. So the gross margin concept, for example, says this is what gross margin is, this is how you calculate it, these are what our targets are for this quarter, um, these are what expected range of values could look like, right? And this is how you calculate it. And so that's kind of a wiki entry that backs this, um. And, and, you know, it's like just like a wiki, there's multiple concepts that are connected to each other, blah blah blah blah blah, fun, fun, fun, um. And, and that's kind of the core piece of how it works, right? But what, and so this is fine, we all have this today like you have some kind of knowledge base, you refer citation on the knowledge base and you make it work, right? What happens and what is interesting is when it doesn't work. So you say what was GM last FY, right? And here the first thing that the AI does is tell you, well. FY it's this new thing. It's a new thing that I think in this domain is a concept that is not known, um, and that's, that's a red link that it will make an assumption about and so it makes an assumption and tells the user what the assumption is, uh, and then the user kind of goes on, sees what the plan is, looks at the answer, right? Um, and now as a user when I look at this answer and I look at the value I'm like this is fine. But I also don't really know what the fiscal year is. This is the most common thing you'll notice your business users will use the product and they'll be like, thank you for telling me that you don't know something, but, uh, true facts, even I don't know. Like I know we have a fiscal year. I don't actually know what the exact period is because we're a global MNC and like is it different in different regions? I, I have no idea, right? And so this is kind of critical where. You now kind of bring in. Another person into this conversation. Uh, an expert or a group of experts to say, can you, can you clarify what fiscal year means? This person kind of joins our conversation. This is an actual human being. The human is an expert, joins the conversation and says, Well, Prompt Q, our fiscal year is whatever, whatever, whatever. And Prompt's like, Cool, that fills my gap, that fills the assumption that I had, and it redoes the plan and gives you an answer, right? This was really important for two reasons. One, the user is actually happy. The user is happy that they got an answer that was right. Because they did something, it was not accurate. I brought in an expert and I got the right answer. This is what I would have done even without AI. I'm not, it's not surprising. It's, it's natural to me, but what is really nice is that this entire conversation has so much tribal knowledge that just got captured. This conversation is the seed of learning. So now there's kind of another agent loop that goes and helps you create a wiki entry. And updates the wiki based on what just happened in this conversation. And because it's a wiki, it's literally a wiki like a Wikipedia, um, AI and humans can collaboratively maintain that wiki. And that we can kind of keep getting better. Over time so that you can use it, right? And then in the future, let's say for example, you ask a question and you say, um, whatever wiki, etc. goes live. What was the GM last fiscal quarter, right? That's kind of the key capability where you also can reference these advanced kind of concepts in the wiki despite what users are saying, right? And this is kind of how you surface it up. Um, I'll take another example. To kind of show you um how we think about what goes in the wiki, right? So this is another example um of, of a finance kind of data set, right? Where I can say um true north revenue for Q3. Um. Also forecast Q4. Right? And, and you can literally imagine what it's doing in the background is it's kind of going here. It's going to True North Revenue, the wiki article. It's reading that and the wiki article is like literally just a wiki. So it says, you know, go to this table, uh, this thing is in Google Drive, it's a PDF you'll have to extract from a PDF like subtract adjustment. What is an adjustment? Go read up about an adjustment, learn what an adjustment is, read up, read up about all of these things, right? Um, and that's kind of what it's doing for this first step of the plan, right? Um, in the next. In the next step of it, what it'll do is it'll try to read what forecast is, right? um, and forecast is a wiki entry that says do this data science thing, these are the outliers that you need to think about whatever, and these are kind of progressively maintained. You can imagine that these are sparse and they get more and more structured, they get better and better as the knowledge accumulates, right? Um, whereas initially it's just basic revenue forecast use this model, then later somebody used it and said nope, Black Friday bad outlier please factor that in. Maybe a data science expert comes in and teaches that to you, right? But that kind of powers um the ability to create an accurate plan, right? Uh. There's kind of another really important piece here because the kind of uncertainty and lack of accuracy is not just semantics and business concepts, but it's also in the details of fairly specific. Technical problems, right? And so what we do is we also surface the fact that the forecasting methodology um. Assumes that something should be consistent, right? It should assume that there's no refunds. It's gonna assume that there's no refunds. Now whether or not that is important to you is something that you can discuss, think about, bring in an expert, and they can say, yeah, you know what, this assumption was good or this assumption was bad like let's not do this again and so you teach it, fix it, and again kind of the learning loop improves, right? The way we think about our product is that for non-technical users we surface the wiki. And for technical experts we surface it in what we call the confidence analysis of the confidence score and and and users are expected to think about the wiki and experts are expected to look at the confidence score and that creates that creates the loop um so that's that's kind of a quick look at um at what this looks like. The what we've kind of observed and, and this is kind of our core pitch is whatever AI you're using today is is doomed for failure, it will fail, uh, and the reason why it will fail is because you've you've probably not managed to get 100% of the tribal knowledge into your AI anyway because how can you? It's not possible if you're a business of any respectable size. It's not even possible to try to embed that tribal knowledge and so you're doomed for failure because not only do you have. Do you not have knowledge but you also don't have a system where people can trust what your AI is doing and and what we kind of wanna get you on the path for is to say it will always be inaccurate can we tell you that it's inaccurate and then can we learn, right? And so kind of put you on this path of actual adoption and that's kind of what's allowed us to scale massively, right? And it's allowed us to focus on solving. Interesting technical problems like for example the fact that our AI system is not restricted by the size of the schema. Um, if you look at things like um Data bricks, Genie or Snowflake and Cortex, um, they have, you know, 2025 tables AI on data. Who has 25 tables, dude? Like who's, what enterprise has 25 tables that you work on? It's, it's not, that's not even a problem like that's not even real. Right, um, and of course it's a problem because you can't squeeze that much in context, so we've kind of focused on solving problems saying 100,000 tables, 10,000 metrics, how do you solve for that? But you can only start to solve for that once you fix the product loop of saying whatever the size of your schema is or whatever the size of the context is, um, unless you have that improvement wrong loop, um, you, you can't even get to those interesting problems, but that's allowed us to scale. Um, since we started, um, early this year, uh, across, across a bunch of, um, uh, really interesting use cases where there's a lot of high velocity decision making that's happening, um, come stop by our booth at 1733 if you wanna learn more. Um, uh, we've got a bunch of, uh, tech folks, we've got a bunch of sales folks. If you wanna buy this and use this, I will never say no, but also if you just wanna stop by, exchange notes and learn, please pop by, um, and, and we can chat more. Uh, thank you for your time, folks.