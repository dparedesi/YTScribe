---
video_id: VtrfpAVFKdE
video_url: https://www.youtube.com/watch?v=VtrfpAVFKdE
summary: "In this collaborative session, \"Anti-Money Laundering Multi-agent Orchestration with AWS Strands\" (DEV326), Boneshwari Subramani (Chief Evangelist at Intuitive.AI), along with Ayana Jay Krishnan and Vivek Raja PS (both AWS Machine Learning Heroes), present a cutting-edge, production-ready solution to combat the staggering $3.1 trillion global financial crime crisis. They argue that traditional rule-based Anti-Money Laundering (AML) systems are failing, generating up to 95% false positives that bury compliance teams in noise while allowing sophisticated money laundering schemes—funding drug trafficking, terrorism, and fraud—to slip through undetected. To revolutionize this antiquated approach, they introduce a sophisticated \"Agentic AI\" workflow powered by the open-source AWS Strands SDK and the enterprise-grade Amazon Bedrock Agent Core. The solution moves far beyond simple chatbots, deploying a coordinated ecosystem of specialized autonomous agents that mimic the cognitive processes of human investigators but operate at machine scale. Boneshwari lays the technical foundation, explaining how the Strands SDK enables developers to build agent logic with minimal code, while Amazon Bedrock Agent Core solves the \"death by POC\" problem by providing the necessary infrastructure for production deployment—including secure identity management, observability, and persistent memory. She specifically highlights the critical role of the Agent Core's short-term and long-term memory modules, which allow agents to retain context across complex, multi-step investigations, ensuring that insights from one part of a transaction flow are not lost during processing. Ayana and Vivek then dismantle the architecture of their multi-agent workflow, revealing a series of discrete, high-performance roles. A Perception Agent act as the first line of defense, triaging incoming transactions by analyzing KYC data and device fingerprints. This hands off to a Context Agent, which retrieves historical behavioral data (like 60-day transaction rolling averages) from DynamoDB. Crucially, a News Herald Agent injects real-time external intelligence by scanning live news feeds and sanction lists (via a Bedrock Knowledge Base) to detect dynamic risks, such as a sudden geopolitical conflict in the transaction's origin country. These rich inputs feed into a Reasoning Agent, the architectural \"brain,\" which synthesizes the data to formulate hypotheses, calculate precise confidence scores (e.g., \"85% confidence this is suspicious\"), and generate a transparent, human-readable explanation for its verdict. The workflow concludes with decisive action: an Action Agent executes the final decision—automatically freezing funds or filing a Suspicious Activity Report (SAR)—while an Audit Agent immutably logs every investigative step to satisfy strict regulatory requirements. Finally, a Learning Agent closes the loop by feeding the investigation's outcome back into the database, continuously refining the system's accuracy. Through a detailed technical demo, the team illustrates how this hybrid approach, which combines generative reasoning with legacy machine learning models (via a Risk Agent), enables financial institutions to modernize their compliance stacks without discarding existing investments. The result is a system that not only drastically reduces false positives but also accelerates the filing of high-quality SARs, transforming compliance from a bottleneck into a proactive shield."
keywords: Anti-Money Laundering (AML), Agentic AI, AWS Strands SDK, Amazon Bedrock Agent Core, Multi-Agent Orchestration, Financial Crime, Suspicious Activity Report (SAR), AI Agents
is_generated: False
is_translatable: True
---

Let's get started. Every day, people are on the move, whether jet setting across the continents or racing through the ranks, or savoring their unforgettable experiences. But out of all this, every financial institutions have one common mission, that is to ensure that your funds flow in the right direction. Slowly Safely and smoothly. And ensure that every single transaction checks out, stays compliant. And keeps us all protected because the world moves so fast that the right flow of fund and the airtight compliance is crucial. This lets us run without a glitch. This is Boneshwari Subramani here, chief evangelist at Intuitive. AI, AWS hero and AWS ambassador, joining hands with two amazing machine learning heroes, Ayana Jay Krishnan and Vivek Raja PS from AWS India community, joining here to talk about AWS strand's power. That is, we're going to talk about the use case anti-money laundering. Multi-agent orchestration with AWS strands, and this will propel you to healthy financial institutions. Maintain compliance with confidence. That's what we're going to see today. So we'll be focusing on the global impact of anti-money laundering and the evolving compliance. We're going to see how the agent care workflow implemented using AWS Trants is going to solve this problem against the financial crime, and we will also take you through the demo in detail with a real life solution. So, financial crime is a global crisis. Around 3.1 trillion illicit funds. Flowed in 2023 and a similar pattern got repeated in 2024 as well. Where are these funds coming from? Majority of these things, majority of the causes are from. Drug trafficking. Human trafficking, terrorism. And fraud. So all of these things constitute towards millions of dollars. Loss, it's a huge financial impact, right? So much of these things goes undetected. That's why we say that anti-money laundering is very, very crucial. So financial organizations like FinCEN have started working on regulations for a quite a long time, and no one can solve this alone. That's why we are here to talk about how agentKI solutions powered by Strans SDK is going to help fight against this. And when we're talking about this, if we go on a little bit of history, I'm not much of a history person, but still, let's take a quick step back and see how the AML standards have evolved. It started with the Bank Secrecy Act in 1970. Followed by Creation of which had 40 specific standards as the recommendations that the institutions have to follow, and 1992 was the year where suspicion activity report came into existence. That is, if there is any deviation in the financial transaction, the financial organization has to file the suspicious activity report. It could be. A real legitimate risk or it could be a potential risk, but it's the duty of the financial institution to file the suspicion activity report and also it continued to evolve. In 2020 is what we had this anti-money laundering Act that came into the picture. So this is the history of how these things evolved, and each milestone has only increased the responsibility and vigilance for the financial institutions how we can fight against this financial crime. So why are we talking about all these things, right? So we have to deal with a diverse set of data when we are talking about anti-money laundering. So in today's enterprise world, We operate a mix of legacy applications combined with modern technologies, so just as goods and capital flow freely across the borders, it is the responsibility of the financial institutions to ensure that the money flows in the right way. Without a glitch that is very, very essential, right? So here the organizations, the financial institutions deal with diverse data. It could be your financial transactions, customer profiles, or it could be the KYC data, even news feeds, right? There could be some news feeds. There was some issues they were raised or standards that got published, so they'll have to keep track of all of these diverse data. And you have the high volume data, high velocity of data coming from different data sets. All of these things have to be taken through a system. That system is like a legacy traditional rule-based system. This rule-based systems actually had too many false alarms. These are a false positive up to 95%. For example, if there is an enterprise which has the business sending. Alerts about the legitimate transactions. Maybe report anything above $10,000 USD. If it's going to report about $10,000 USD, there could be hundreds of legitimate transactions happening in that month. If it ends up prompting and reporting for all that, and later, the compliance personnel, the human who has to sit and review this, it takes a lot of time, a lot of energy, waste of resources, costing, all of that, right. So this slows down the real threat detection. So what do we need? We need real context aware methods which can cut down the false alarms, increase the focus, and then Helps us to detect the real risk quickly at a lower cost. That is what we need. Before we get into the Actual solution and agent implementation. I want to talk a little bit about the technology that is powering the implementation. So let me say something. All of us might have used talking to either Siri or your Alexa, a bank chatbot, something or the other, even in the middle of the night. Many times we would have felt that it is far more better and easier to talk to these bots than your close friend or even for your spouse for that matter, right? So I see a lot of smiles. So this is the fact. So when you have a bot. Which is so powerful and responding, let's see what is the tech powering the bots. Imagine you have an agent, which is so powerful implemented for this, so what is this agent basically built out? We also had. A lot of things that Dr. Swami covered as part of our morning agent KI keynote about the agents and the latest launches. So when you talk about an agent and simple, you have a prompt which is sent to the agent that is the question that you wanted to ask. Maybe you have a diverse set of data coming in. You're defining an agent which is going to take the data, process it. So when the prompt is sent to the agent, the agent is capable of invoking any tool. It could be the code interpreter or it could talk to your database, anything. It could invoke your tool. The tool will process the information and return the data to the Agent and the agent is also capable of invoking the LLMs. It could be Olama GPT, anything. So this again fetches the results back to the agent. So both the results are available in the agent, and the agent is going to process that and create or curate in a human readable content, and it's going to pass it on to the user or the application from where this agent is being invoked. So that's the agent in a nutshell. So when we say agent, what is the difference between agentic AI and agent AI workflow? Because the solution that we're going to implement for this is gentic AI workflow, right? So the agent TKI, it's basically an autonomous entity which makes decisions and act upon those decisions to accomplish a goal with minimal human intervention. And when you talk about agent care workflow, it's the coordinated sequence where the multiple agents are orchestrating to accomplish a complex goal to solve the biggest problem that you have. So this is what we talk about agency care and agency care workflow and When do we use urgent care workflow? Just because everywhere we talk about agents, not necessarily that we have to use only urgent care to every damn problem that we see. There are advantages in using traditional as well as agent AI. So that's what I wanted to talk about in this. So when you take about agentKI, when you want to deal with complex workflows, when you have a diverse data set, or when you wanted to have a memory that is to be retained after the conversations that is happening from start to end, so in all these cases you will go for urgent AI workflow. When we talk about the tools that are powering this, you will understand and relate to this better, but for now, so for all these scenarios, we'll go for urgent care workflow. And for the traditional, when you have the mission critical applications where the results have to be 100% deterministic, we would go for this traditional workflow. And when you have a system which needs ultra low latency, you need this. And if it is a fixed rule-based system. Which can actually derive better results with that, then traditional solution is better. OK, so now when we talk about these things, what are the technologies that is powering these solutions? So we're going to talk about AWS Trans SDK and Amazon Bedrock Agent Core which has powered these things. So when you say Strans SDK, it's the open source framework from Amazon with which, without worrying too much about the infrastructure. Or writing thousands and thousands of lines of code with just a few lines, anybody should be able to create. An agent. If you had watched the keynote today, Saswami gave an amazing number. There are already over 5 million downloads for this SDK. People are really using day in and day out. Anybody talking about agents or building agents with strand SDK, it's becoming so, so powerful. So that's what we have used as well to create our agents. It can actually natively integrate with any of the AWS services and it can connect to native tools, any servers, whether you have created or it's external. It works seamlessly. It can work with any model. That is the power of St. And so when you have one agent you create it for one task, it's all good, right? Imagine you have a stream of agents interconnected to actually think, act and remember all at once at a massive scale. That's when we need service. Like Bedrock Agent Core to take care of all of this completely. So you build agents with strands SDK or you can build agents with any framework for the matter. It could be from Lama. Lama index, Lang chain Landgraf Crue. Or Google. So you build with anything you can use Amazon Bedrock agent code to deploy. That is so, so powerful. It is not just a single service. It's a composite suite of services which helps you address a whole lot of logistics that is involved in deploying an agent at a production scale. You imagine an agent when you wanted to deploy. You don't have to deal with infrastructure. That's where runtime comes into the picture. And when you're deploying it, you have to ensure that the conversations between the agents are secure, seamless, and nothing gets leaked beyond the conversation. Context. So in this case, the identity management comes into the picture. So when your agent wanted to interact with other tools and other stuff, Bedrock Agent Core gateway is there. And when you wanted to audit, debug, and report, that's where agent core observability is there. And so when you want this information across the conversations and chats has to be remembered, referred for insights. That's when agent core memory comes into the picture. All of these components holistically work together to help you deploy agent run at a production scale. But otherwise, if you see, I have a friend who was actually saying when you do a lot of PCs. Agent KI solutions. Most of the POCs end by death by POC. That's a term that was used by one of my friends. So everybody starts with agentKI where it suffers, where it struggles is for taking it to production has been struggles. That's where Agent court is here to rescue and take care. Let's drill down and look into 3 major components. We can talk about Agent Core for hours together, but I want to drill down and talk about 3 important components here, which we are going to extensively use for the workflow that we have designed. So you take Agent Core runtime. It is the completely managed surveillance service, but it's not like a traditional surveillance service. We are just invoking a function, returning a result, and going to use it. This agent core runtime is a micro VM. Whenever you're hosting an agent, deploying an agent, this microwa VM is started and this micro VM. is available and runs for a maximum of up to 8 hours to serve the functionality of the agent to the invoked application. So that is how the microbiome is available, which is unlike the traditional system. And using this, you can actually deploy the agents created from any framework as I mentioned earlier. It could be from your lang chain, land graph, Lama index, accrue AI. Irrespective of that, you'll be able to build. All that is needed is when you invoke this agent core runtime, it creates the docker compost file and it deploys it to the ECS repository. Once it is the image is made available in the ECR repository. It can be invoked and deployed into the runtime. Once it is deployed, you have an endpoint made available which can be used to integrate with the application to serve your customer request. So that's how this agent core runtime works in a nutshell. And when we talk about the agent core gateway, So you're creating one agent. This agent cannot work alone. It needs to interact with multiple agents. Right? So when you wanted this agent to interact with multiple agents, for an example, We spoke about diverse data. When the diverse data are coming in, we have an agent who is going to read the data and see whether some data is actually false positive or not. So you need an agent. So this agent should also go and check the KYC data. Or the last 7 weeks, 7 days data to see is there any risk. So when it has to do all of these things, it has to interact with different tools. One agent cannot do everything, right? It needs to have multiple agents or multiple tools, so. You can use agent core gateway to connect to the API gateway, and the API gateway in turn connects to different tools within AWA services. It can invoke and it processes and returns the information that is needed. We can also make this agent core gateway. Connect to your lambda function, which is going to process this set of tools and return the results. It can talk to another set of tools, so the inbound authentication stops at this agent core gateway, and the agent core gateway takes care of the rest of the interactions with the tools, MCP tools or the AWA services like APA Endpoint or lambda and the return results. So that's how agent core gateway works. And the next one important thing is, OK, you have a runtime, you have a hoster, you have a gateway which can help you interact. All is fine, but we need memory. Whatever conversation that happens, whatever the processing that happens, all that has to be recorded, stored for using it now, at least during the process or later. So for that, the agent core memory has an amazing feature. Let's talk about two things short-term memory and long-term memory, how it works. So when you take an agent, there is an agent implementation. When the agent is implemented, there will be a sequence of events happenings. When the sequence of events are happening, there are messages which get exchanged, and the state that needs to be stored. So these messages and states will be stored in a memory called short-term memory, and this short-term memory can be made available. are stored maximum up to 365 days. Don't ask why 365 days. It's a number. It's nice to say 1 year, right? So it is configurable. You can say whether I need it for like 1 month or 365 days, but the maximum is 365 days for short-term memory. And in case of long term memory, you have a module called the automatic memory extraction module which processes these data which gets stored in short-term memory asynchronously and extracts insights, summary information, or the semantic data. All of that and stores in the long term memory. On the other hand, the agency implementation that has whenever it needs any of this information could be user preferences or the insights that you want it to process. You can actually go ahead and invoke this information and then use it asynchronously. So that's how short term and long term memory are super beneficial for the agentKI workflow implementation. So we saw what is the global impact of anti-money laundering, and we went through the diverse set of data that we have, how the false alarms get raised, how the compliances have been evolving, and we also spoke about the tech that is powering this agentKI solution and our agent EKI workflow is implemented using Stras SDK and Amazon Agent Bedrock Core. So with this, Insights, I would call upon my co-speaker Ayana Jay Krishnan Aja to continue from here. Thank you so much. Thanks, Bono. OK. So we all love strands which is really flexible and we also love the agent core it's very modular and we can deploy at a scale. And let's dive into the solution. How are we solving the anti-money laundering age, money laundering, leveraging the agentic workflow. So these are the agents we lined up, act as an individual persona. Each one has a different role to play in this workflow. Let's start with the first agent, perception agent. This naming convention speaks for it. When the transaction comes, it will understand what is this transaction, add additional perception to it, and then it will connect to the different data source based on your requirement, based on your enterprise, it will connect to the different data source and add to the context agent. And the data source can be varied, but the context you need to have a streamline the information before sending to any kind of. reasoning agent. So the context, whatever we are telling, it's all within the enterprise, OK, but. When it come to the real when it come to the enterprise, the real-time data matters a lot. That's where we are going to add the news agent into the mixture which will connect to the real-time data source and add to the reasoning agent. This is where the real powerful comes. The reasoning agent will leverage both the unstructured data as well as it use the existing context retrieved from your enterprise and make a reasoning and forward to the risk agent. The risk agent make a decision. It can connect to your enterprise existing risk mamL models as well as based on all the context we have retrieved from you, this workflow. It also give a context and make a risk. Then the action agent comes, so all good. Currently, whatever the actions we are making, it's all highly manual. This action agent, take out those major chunk of this action and automate it like it can do the straight through processing if it all goes good. And after that, all the workflows are fine. When it comes to any financial institution or any enterprise, we are building it application we are building it. The auditors play a pivotal role. And when it comes to the audit, all the agents make a decision. And we want to make sure all that every information will be triaged and logged so when we make if anybody wants to go and make a decision why the risk score was different, we have all the information from multiple agents went through. We have an audit. Then learning agent, this is one of my favorite agents. We need to keep the system more autonomous because we want to whatever we observe we want to add to the system as a feedback loop. So when it will evolved over the period of time, then we need to create a final report. So if you find it suspicious, you need to create a The suspicious activity report, we will create a report leveraging LLM. This is a high level. We orchestrated the workflow. It's completely modular. We can, we can plug into our enterprise need with a different agent. I want a little bit zoom down on the risk agent, which is very important, OK. Based on the risk agent, the action agent will be invoked, OK? If the score is less than 30. OK, perfect, we can do the straight through processing. The agent can do the straight through processing. Then if there is a. The score is on 30 or to between 50. This will vary. We can make sure we are notifying it, OK? And if it finds it's a repeated pattern, we need to mandately file the report. The report will be created using LLM, and we also make sure this transaction is monitored. And flagged, but if we feel the score is high, currently, whatever the action we are making, sometimes most of the time we do the false positive. But with this kind of approach we will be able to take a freeze that and make the next action. This is how the overall system we were orchestrated let. Let me come into the technical deep dive of how we lined up this agent, how we use the strands, and made it monodu. We made it as a layered approach based on the use case. We all started with a major chunk of use case in the AML, the transaction monitoring. And post created created this workflow end to end and made it work. We made plugged into the additional layer which we added a more context by adding the real-time information like a news, OA, all those information. Now we have created a context. We have created an entry into workflow. We want to make it more autonomous. That's where the third layer comes. We made it, added the learning agent, and we added more audit into the picture. OK, so this is how we step by step we have built the agents. It's all Let me dive into the transaction monitoring and spend some time on it. The real-time data we are processing using a kinesis. Once we have our real-time data based on that transaction information, we will connect to the existing data source. It can be your CRM or think like we have everything in our RDS or a relational database. It'll go connect to it to get those KYC and the perception agent. Based on that, it will create a triage of how this transaction looks like. We are using a bedrock. For different kind of model for different, different purpose. Now let me come to the next one. The context agent. With all the information we collected, we created the context agent, but the context agent had a very critical thing. About the historical data, the historical data currently we are keeping all the information at Dynamo DB for the foster retrieval, and we build a flurry of tools. Take a lasting transaction till the so and so date transaction is recently flagged. We created multiple tools using a lambda function and we kept agent core gateway as the front end, and we connect from the context agent to. To those lambda functions to retrieve the data via gateway, so we don't need to change the architecture. If you have an additional requirement to connect to the data, all you need to do is build an additional tool, and it will be more flexible based on your requirement. We can add it. Now we have created a context agent and connected to the historical data with the real-time data. Good. Now we are adding to the reasoning agent. All the context will be sent to the reasoning agent. It used the reasoning model to make a complete understanding. It created a risk code by itself based on how we prompted and orchestrated with all the context, we got it from perception agent as well as the context agent. Once we have the complete details from the context agent. We are and the reasoning agent, we are taking into the action agent. We created the tools here also. We can build multiple tools based on your requirement, at least for the transaction monitoring. The notification is very important. We created a tool for a notification and also we want to make sure if it is high risk, we want to flag that transaction. So we have created the tool based on the information we got it from the context, we got it from the reasoning agent. We will be able to make action and if we find it, yes, this is a transaction which we want to create the suspicious action report. Currently in industry everything needs to be done manually and whatever the transaction they have seen, they have to create a manual report with a proper prompt template structure. We will be able to prefill this one and store it into the estuary. As I mentioned clearly, auditing is a very important task if you want to make a decision. That's where the audit agent will come into the picture. All the context we've taken from the perception to all the layers and whatever the action we take, we audit everything and keep it in an elastic search. So think like it. If they found there is a suspicion suspicious in the transaction, it automatically created a report. If the human in a loop, they can check the report at the same time how we made a decision, everything will be in an elastic search. So that is how we orchestrated this flow for the transaction monitoring. The next layer what we build is the adverse media monitoring where we want to add the real-time information of the news. OK, we added the news. We created a new agent which is a new news herald agent. So that is how we modular, we make it very flexible so we can keep adding our agent based on our use case that with the power of strands and agent code. We added the news Herald agent. And whatever the information it is getting, it added to the memory. Why memory? Imagine if there is a new transaction coming and the same person is doing it. We do, we want to make a quick action. So yesterday there is news comes and we may be flagged, and if there is a change in news, it'll have both the contexts. There is a negative news, there's a positive news. This is the recent information. We can make a decision accordingly. Currently whatever we are doing is we are doing it manually, but with the agent core memory this will add a context in real time what we are fetching from the news agent. To make a decision, all this will be fed into the context agent. If you look at before, this will add. Your batch, your previous internal information to the context in a transaction monitoring. Here we are adding a real-time information to the context. So news is one factor, but every When it comes to the anti-money laundering, it's very vast country to country. It will vary. The data source which each country or whatever the act they have will keep vary. Take an example of OfFA, Office of Foreign Asset Control, which they publish the report very frequently. It has all the information. If any political exposed a person, something the sanctions are happening, every information will be here. This I'm taking an example. So based on your requirement, we can add to that particular data source. We use the lambda which will periodically retrieve the data. And of course we are using a bedrock to do the embedding and write it to our knowledge base. Why knowledge base, when we want to the news Herald agent, whichever we built it, it has both the context of the real-time information which we fetch from the news as well as according to your country or act, it will have this information in a bedrock knowledge base. Both the information will be fed into the context agent. OK. So Post to the second, this is the final layer we have built. It's all more about instant risk interdiction. The reason why we want to do this manner is currently, mostly we are doing it in a reactive fashion. Now as I'm saying it's not 100% we will be able to proactively do it, but we can make a quicker action and avoid more false positives in this approach. Here we added two more agents. One is on the Risk assessor agent. What this risk assessor agent will do, right? So it will integrate into your class internally currently whatever the way we are doing, right? We may be using a classic model. It can be your classification model or it can be your clustering model, the classic ML model you have. That is how we are flagging whether it is a risk or not. What we are doing is we are adding that as an additional context to the action agent. So, whatever the information we got it, we are adding a new agent which will connect us to the API and get the, what is the risk score for this kind of transaction and add this information to the action agent. And Finally, we are adding the learning agent. Whatever information the risk was done, it will be taken into account using the learning agent. It will take all the contact information and write it back to the Dynamo DB. Then it acts as a feedback loop for our transaction monitoring. This is how we have structured the agent. So it is highly modular. Every use case will differ and every requirement may be differ based on your use case. You can think this is a known reference and you can build on top of it. What we have done on this workflow, what we learned on this workflow, right, we identified the classic ML way we are doing is really, really working well, but that is a challenge. We are not able to do proactive action, because a lot of decisions we are making, it's all in an unstructured manner. This agentic workflow, we added the classic ML feature into our agentic workflow pipeline and we leveraged the G AI to process the unstructured data. And using a bedrock, we applied all the guard rails needed to make sure that it is not hallucinating or aligned to the enterprise need. What does, what we have achieved via this anti-money laundering agenting system we built using a strands and agent code, right? I love the future of observability, agent core observability. All the information we have called, what tool we have called, and how much time the tool spent that time, how we made all the information. I no need to build anything. I take care of my audit trial and what done at the transaction level, everything was absorbed by the observability. Then real-time injection we have used a kinesis and we can use a Kafka according to our requirement and session insulation. We are adding the context is what the center of the piece, right? We are using a bedrock knowledge base. We are using an agent core memory to manage the complete session. And semantic reasoning for it and security and compli compliance, we want to store all the data into the history and it is encrypted and we are using a bedrock connecting to the bedrock model as well as agent core using a VPC endpoint. Then all the transaction information, the lineage, everything, we are using an elastic search surveillance which is highly scalable for our requirement then. Our favorite, we are using different model for different requirements. We are using for the reasoning, we are using a bedrock cloud model. So under the bedrock we are using a cloud model for a different purpose. We are using a NA model. So this is how we structured it. What is our expectation result? Yes, we reduced the manual review, as I mentioned, how this report was generated is manual. We are able to accelerate using our LLM to create those reports. And reducing the false positive and try to track it in an earlier manner. And audit trial, whatever the agentic workflow done, all the context, all the lineage information, we are able to track it down. That is the expected results from us. That's all from me and uh this is me, AJ. I tried to hand over this, the demo, real-time demo, which will be done by Vivek, my fellow AA hero. Thank you. So it's time for the demo. We have understood how things work and what we have achieved to do. So I'm going to concentrate on one of the most important agents in this whole workflow, which is the reasoning agent. So the reasoning agent is built using the stance agent SDK, and as you can see, the agent class is instantiated, which is from the stance agents, and the name of that is reasoning agent, and the system prompt actually defines the behavior of the whole agent. Which includes figuring out what the transaction does by creating hypotheses, indicators, explanation, confidence, and recommending what steps needs to be taken next for this particular transaction that comes through. With that being said, it also understands that the reasoning agent depends on the output and the context that comes from the previous agents that is in the workflow that is helped using our agent code memory. This helps the reasoning agent to make very informed decisions about how to navigate to make an informed decision about a particular transaction before marking that as a fraudulent transaction or not. So this agent code memory helps you to maintain the context across the whole session of the workflow by saving the outputs of each and every single agent that works in this particular workflow. And as you can see here, we are trying to keep the context from perception, context and all the other agents, and all these outputs have been put under here. With that being said, this helps you to actually understand how we need to actually take a transaction, stream it through Kinesis, take it from Lambda, and also work through the entire agent core system and figure out how this transaction comes through. So this is a simple UI that we have built, and this is preloaded with a couple of scenarios that you can see on the, on the left side. The scenarios are of different transactions of different types of categories, which includes low risk transactions, medium risk, and high risk transactions, and you can notice at the below that. You can notice in the below that how this looks like, and we have both a PEP donation into microstate NGO. That is what we are going to pick as one of the first scenarios that we want to run it through, and there are multiple orchestrations that we have already seen. We're going to pick the first one, which is your behavioral signal triage, and that has a 5 agent system which is your perception, context, reasoning, action, and audit. We're going to run the system to see how this transaction is being dealt with this gentic workflow. So all these agents are being executed at the moment, and once the whole execution is done, we also know how it really works under the hood by interacting with the gateway and interacting with the agent called memory and all the other stuff, and the verdict that this aging workflow gives for this scenario is that you need to file an SAR report and freeze this transaction. But we are really interested to understand how this decision is really made by the agent because we want to uncover this black box. So the perception agent tries to understand the users, which is the receiver and the sender, about what amount is being sent, what is the currency that is being there, and where is it being sent, and so on. And one of the most important jobs of the perception agent is to understand the KYC of both the sender and the receiver here. So it picks up the KYC details of the sender and the receiver, and as you can see, the sender is also marked as a high risk entity, and the receiver KUC also have been marked as one of the high risk entities that we have in the system. So these are some of the important features that the perception agent picks up. And not just that, the perception agent also calculates a couple of other features such as what the device is being used and what's the deviation of the amount that takes place in the transaction and so on. And with all this information that is being stored in agent code memory and that is passed down to your next agent, which is your context agent. The context agent picks up the details of the sender and the receiver of the 60 day transaction that takes place, so it calculates a lot of behavioral features from out of it like what's a rolling average and so on. And now comes one of the most important and the core agent of the whole workflow, which is your reasoning agent. So the reasoning agent comes with three different things, which is it creates a hypothesis first to understand what to really make out of this transaction. So the hypothesis that it really makes out is that the transaction may be suspicious about the involvement of a PEP and an excluded provider, and it creates an indicators how it really marks why it makes this transaction a little bit risky, and it gives a detailed explanation of what really it understands from the transaction. And the decision made is around 0.85% of confidence and it recommends the steps as well, and that is passed down to your action agent which recommends that this needs to be filed a report and you need to freeze this transaction. And a lot of other actions have been executed along the same, which is like you have to freeze the transaction, notify the operations team, and you have to also store the SAR report. But depending on your organization, you can also execute a lot of other tools and workflows underneath. And the audit trail is one of the important agents in the system which understands and picks up all the necessary outputs and details that has been generated by each and every single agent in the system, which basically keeps your audit clean and ready. And with that being said, the output is to we have to file an SAR, and this is the SAR report that has been generated, and the audit trail actually gives a detailed information about each and every single agent that is being executed and what information has collected and what information has produced and so on so that a human in this particular loop can identify and figure out how it's really the decision is made. Now let's try to run the same scenario using our next use case, which is a reputation pulse scan. And you can notice that we are going to include a new agent in this workflow, which is your news agent. Let's run this orchestration and see how that works out. And it goes through each and every agent and it tries to understand how the transaction works. And with that being said, once the transaction is completed, you get to see the entire results of how this agent has taken this particular verdict. So we already know how the other agents work. Let's jump into how this news agent is really working out in this new use case. So tries to understand what is the sender country, receiver country, and so on. And one of the notes it has really maintained is that the receiver is a sanctioned person. So let's go into audit to really figure out how the news agent really came up with this particular research. So you can see here that in the news it has mentioned that the receiver is sanctioned, but also this news agent does not stops there. It tries to understand who is the receiver, who is the sender by going and interacting with the sanctions list that is available to mark if the person is. Under the sanctions list and also also checks the geopolitical situation of the transaction to see if some transaction needs to be restricted based on the country of the sender and receiver. And the third orchestration workflow is that you have all the agents in the workflow, which is your complex and the full use case that we see, and it involves both risk and the learning agent. So let's try to see how this orchestration goes through and our. Now going to be our focus is to learn about how this risk agent comes into the whole picture and how does it really influence the whole decision making process and how this learning agent is going to keep us involved in this whole process to figure out how these patterns are not being repeated in the future. So once this agent has been executed, let's jump into what we are really interested about, which is your risk agent. So we have marked a rule engine system in this whole workflow, and this rule engine could be your organization's rule engine or maybe the compliances rule engine that you might have. So the rule engine that we have created is that the agent has figured out that there is a high risk of entity rating for the sender and there is a sanctioned status of the receiver. Let's go into this audit report and see how this this agent really worked out and what are the information it was able to figure out from this whole thing. So you can see here that these are the rules that this particular agent was able to pick up and execute based on how it really worked. So this agent is not particularly an LLM focused agent. It's a Python agent, but it's driven by your machine learning classical machine learning model or your rule engine. Based on all these roll engines that has been created, these are the contributing factors. It has figured out that it might influence the transaction status and what needs to be done with the transaction here. And with that being said, the learning agent tries to fix up all these learnings, put back into the dynamo DB that we already have, so that when the next such patterns occurs, your agents are much more intelligent enough to go ahead and make more informed decisions around it. So now that we have seen a scenario with almost all the three different use cases, let's try to mix and match different scenarios and see how that really helps out for us. So we're going to run the whole. The L3 use case with the second scenario which is you're going to execute a payroll which is from a Singapore public official. The verdict is that you need to file an SAR, but this transaction is OK to be let out, but you need to keep monitoring to see if something really flags out in the past, in the future. So you can see that who is the sender and the receiver of the agent. The reasoning agent picks out that this is a payroll payment and so on. And this is the verdict that it comes out with. Now, let's even go with a very simple low risk entity scenario and let's run with one of the most simplest agent workflow that we have here. With that being said, we are going to. Run a scenario which is a synthetic community payroll. Though this is a very low, low risk entity, uh, this still flags out that you need to file an SAR, which is your suspicious activity report, and you have to monitor the transaction over here. And if you go into the audit report, it figures out and shows you the whole detail about what really made this decision needs to be made. So with that all being said. We have seen scenarios where how a transaction is being taken and how it's being sent into Kinesis and how this whole agenting workflow has been deployed in agent core runtime, which makes it super easy and with the help of gateway to access more tools outside the agent to give the agents much more accessibility and also the memory to keep a context of every single transaction that comes from. From the perception to the end of the agents to figure out to make more informed decisions around it. So we have used a couple of strategies to keep the memories much more consistent. So we have used short term memory, but we have manually written down each and every output of the agents which goes there. So this is a complete demo that goes into it, but let's take a bit of time to understand how this couple of other agents have been written, because not every single agent that we have seen is not a strand agent in particular. So, uh, let me. Go to one of the agents that we have, which is your So let's start with the perception agent, which is our most familiar agent that we have. So here the perception agent is not really your an LLM powered agent, but it is a Python power agent, but it still utilizes the tools which is being exposed to this in a way that it was able to access the information about your KYC details and much more. And We have the context agent which tries to retrieve the same about the 60 days transaction details of both the receiver and the sender, and even that is exposed to you by from Dynamo DB through a gateway tools that is being through agent code gateway tools, and we all know the most important agent is the reasoning agent which you already seen at the start of the demo, and this also ensures that it drops down the whole information about how the decision is being made. And how it is being made as well and the transaction, the reasoning agent has a couple of entities like the indicator, what hypothesis it has made and what explanation it has given. And also the most important thing is how confident it is with the score that has been generated so that this transaction could be flagged or not. And next we have is our. Before that, we also have a news agent, so a news agent is something which we have we have actually taken a special interest to create it. Usually this news agent will be a couple of APIs which gives you information about the reports or the securities reports or the sanctions list and so on, but for the simplicity of this particular demo we have stored the entire sanctions and the securities list in a knowledge base, and we have exposed this knowledge base to the agent so that it can access to figure out whether the receiver or sender is part of this particular. Sanctions list and so on and most importantly, not everything could be just covered by saying that it is if it's just from the sanctions list, it is meant to be a fraudulent transaction. It's not necessarily need to be. So we also actively monitor what is the geopolitical situation that occurs around the transaction. For example, there is a war-stricken country and it's trying to transact an amount which is absurdly which is very high. Of course, the human who is in the system would be able to easily understand that hey, there is something wrong which is going on. But your agent might really pass it out because that's not really that flagged out as a suspicious transaction, but the news agent, which has access to the internet through the tool of using the browser, it's able to understand that hey, there is a war-stricken country and this is trying to make a transaction. And with all this information about this news, the details, and the history of the transaction, your reasoning agent now has more information. And as much efficiency as a as a human to make more informed decision that this transaction might be flagged as a money laundering transaction being over here and the rest of the agents keeps the actions being executed so the action agent figures out which sort of risk band that it falls through and we have your risk agent which actually combines your existing. Machine learning models or the classical models that you might build for your company or your organization so that you don't leave out the legacy system out of the picture, but you also use them as one of your helping hands to make much more informed decisions. This also helps you to keep the compliances much more intact with the new solutions and keeping the old legacy solution into the system. And all that being said, the audit helps you to keep the entire trial of the transactions, and that helps you to keep your compliance team much more happy to understand how this agent is making much more informed decisions. And we have finally the learning agent where it gives you the feedback loop of how this transaction has been has been evaluated and what was the risk which was associated and what was the reasons it has been made. And how this entity's risk band has been updated post this evaluation, and this learning agent keeps updating the databases, which helps you to make much more informed decisions of such existing patterns occurring in the future as well. So with that being said, this completely helps you to understand how we have built an entire workflow to understand how to flag out transactions which might be a money laundering fraudulent transactions here, and the multi-agent organization systems have been really helpful to increase the accuracy and decrease the time in flagging out the system and improving the efficiency of the whole organization as well. So this is Vivek Raja. I'm. Sorry. I'm AWS machine learning hero, and uh along with me, uh, is Boneshwari Subramani who is uh AWS hero, and we have uh Aya Jay Krishnan who is uh representing AWAS community, and he's also a Michelini hero. We'll be around in this, uh, hallway if you have doubts or you wanted to interact more about how this, uh, solution works. Sorry? OK. So this is us and we'll be available in the hallway if you wanted to catch up with us to understand more about how the solution works or how you wanted to integrate this with your existing solutions that you have in your company or you wanted to explore the same. So thank you for this.