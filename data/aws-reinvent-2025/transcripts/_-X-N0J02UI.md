---
video_id: _-X-N0J02UI
video_url: https://www.youtube.com/watch?v=_-X-N0J02UI
is_generated: False
is_translatable: True
---

All right, so let me start with a statement which is, um, older application or legacy applications are reliable, 100%, no doubt in that, right? But when it comes to, uh, the adaptation or automation, it becomes a little bit tricky with the legacy application. And it becomes when it becomes really tough when you are new to that application, you do not understand the code base and you want to modernize it, but you're still figuring it out how it works, right? So. If I tell you that you can create an AI agent who will interact with that legacy system and can act and think on its own without rewriting anything, that would be pretty awesome, right? That would make our life a little bit easier as a developer or architect, something like that. So, well, to show you exactly how to do that, uh, I am Depali Tandre along with my colleagues Franz Stefan and Janhos. Together we will demonstrate how to use Amazon Bedrock Agent Core to create that agentic AI into the existing legacy application. OK, so before we dive in, I know you all are here to see us coding, you know, troubleshooting online, everything like that. But give me a few minutes to go through the core concepts so that it is easy for all of us to follow what we are doing and why we are doing it and after that Franz is gonna take over and he's gonna start by showing you how easy it is to create an AI agent, uh, using SRS SDK and run it on agent core runtime all in an empty project. And after that Jan is gonna show you how to do the same thing with an existing, uh, within an existing legacy system. OK, so let's start by understanding the agentic loop itself or how the LLMs work on a very high level. So you begin with a prompt uh that you provide to the agent and which could be something like what's the weather in London today? This will basically trigger the initial loop and agent you can think of as a controller or an orchestrator who knows what to do based on its logic, it will determine when and how to call a model and model is the underlying intelligence. These are the foundation models which powers your agent and generate the responses based on the uh data that they were trained on. Uh, next we have, uh, um, but sometimes, uh, model cannot answer the direct, can cannot answer you directly. For example, if I ask model, give me the 10 recent Jira tickets or Gyra tickets for this project, model doesn't have the access to that kind of information. And that's why we have tools, and tools are the external entities um that allows your agent to talk to outside world other than model to perform tasks like web searches, database lookups, uh, code execution, calling APIs, anything that your agent wants to do for the task completion. In fact, the agent can uh create a new prompt internally that goes through the same loop again. Um, and this is the this process of, uh, uh, acting, interpreting, planning is what we call as agenttic loop, and it continues until the task or the task is completed. Uh, the framework which we are gonna use today to build the agent is strands SDK, and to define strands, um, it is an open source Python SDK which will let you build the AI agent, um, with just a few lines of code. What that means is compared to other frameworks where developers are required to um uh to create the complex workflows for their agents, strands agent follows the model agnostic or model driven approach, the similar thing which we saw in, uh, Agentic loop, um. So, uh, what happens is a strand can run, strands can run on any infrastructure, and it can call, um, a model that are either hosted on Amazon Bedrock or even OpenAI model. So to quickly, uh, summarize this one, strands will let you define how your agent can think and act on his own, but the next question is, how can you make, uh, or make this agent run in a scalable and production way, uh, grade. The answer is, use Agent Core. So the Agent Core is a managed runtime, uh, and infrastructure offering from AWS which will let you build, develop and operate your AI agent on at scale. Um, it provides a lot of out of box components, which you can see, some of them you can see it on the screen. And if you're hearing about Agent Core or listening about the Agent Core for the first time, um, do not worry about it. I will go on very high level about the components so that it is easy to follow. Um, so we have an agent who can think and act, um, but it needs a runtime which will basically, um, uh, basically allows to fulfill the business goals we have, for example, multiple users access, auto scaling, sandboxing sessions, um, inter interacting with the tools which we will have, uh, in the agent, uh, and most importantly, the performance, um, for everything like that you will need an agent core. Um, you can think of strands as providing the intelligence to your agents, and, uh, agent core will provide the structure, the scalability, the security that your agent needs. Uh, on top of that, if I want my agent to remember the conversation I had in the past, I could use memory incapability, which is, um, which will store the context information across the session and the agents. Uh, along with memory and the runtime, uh, Agent Core does have built-in tool support, um, and in AWS it provides the native integrations so that your agents can, um, either, uh, uh, store your data in S3 buckets or trigger a lambda function or even, uh, write into Dynamo DB databases. Other than native integrations, you can also register your APIs as MCP tools, um, um, so, so that your agent can access them securely. Um, so there is more, you can see on top. It's gateways, uh, agent core gateways, uh, will allow you to expose your internal APIs and lambda functions, if you have any, as MCP tools. And finally, we have identity, which will, um, which will give you plenty of options for authentication and authorization to basically lock down everything. Um, so we have seen strands, or we, uh, you, you just heard me about strands which will define the agent capabilities, and you will run it on agent core runtime for the scalability it requires. So what is missing in these two? Uh, so. The answer before the answering it, let me ask you, why, how do you think that the um context, the memory or the tooling information or any other thing is flowing reliably between the agent and the uh system it needs to interact with that missing link is MCP. So MCP is the open standard which will let you, uh, define how your agents can connect or communicate with the applications and the services, um. It provides a consistent way to expose the capabilities, and what I mean is like your database queries or APIs or any other services as tools so that your agent can access them securely. Additionally, MCP doesn't just expose the capabilities as a tool, but it also provides three key capabilities for your agent, and first off, first off, that one is tools, and these are the actions that your agent can perform. Essentially, you're telling your agent, this is what you can do. For example, you can fetch the weather or trigger a workflow, or, uh, even retrieve the customer data. Second, we have prompts, and these are the data, uh, external data sources that your agent can access like database, list, documents, files, URLs, basically all the information that your agent can read. And lastly we have prompts, uh, which is an instruction manual, uh, including text and arguments, uh, so it is basically telling the model that this is the given context, uh, for the response you will send. OK, so to conclude everything, uh, once again, we have strands that will let you define the agent capabilities. Agent Core will allow you to run in a scalable manner, and MCP will, uh, expose the capabilities as a tool so that your agent can access them. Altogether, you will build an AI agent into the existing legacy application. Um, so we have the scene now. We know we have gone through the concept. Now, I'll ask my colleague Frans, who will demonstrate to you how to create an agent, uh, using strands SDK and run it on agent core runtime all in an empty project. To you, Franz. Thank you. Let me switch over to the other screen. And hello everyone. Frantz is my name. So next to Jan, uh, we will try to for the remaining 15 minutes to do some coding stuff. So as we started with the preparation for this code talk today, um, we had initially much more slides, but that's a code talk, so we're not here for, uh, going through a lot of concepts and, and, um, um, theoretical aspects, but we had to set the scene to give an understanding that we want to use and to build an agent today. With strengths, with the strength agents as the key, transform it to a bedrock agent core uh agent deployed then to the cloud and then adding some capabilities so we will start a little bit low level, but the level will increase, um, yeah, the second step we had then to to take a trade off. uh, do we want to code everything from scratch would not fit within the time, so we will have some parts now that we want. Uh, to go through, so we will also copy some code and then trying to give an understanding. Feel free to ask questions as well. Uh, we are here after the session as well in case of questions, um, but it's encouraged to ask questions in between. I hope you apologize if I sit down, but it makes it much more easier than to start with decoding. Um, and to give an understanding, uh, what we wanna start with first, um, I think you can see the screen, just let me try to make this a little bit more readable, um, yeah. OK, is this good? So what we're going to start with. As you can see, or maybe not see, this will be primarily based on Python today, so we will use Python, um, as this is the main supported language as of now, uh, to get started. There are other options how to use other languages. I will come to that in a second, but the first thing I want to go through, um, is to make use of these three packages. So I have defined these 3 packages in my requirements TXT file. And uh those packages are all we need to um, to transform the agent that we're gonna start now with uh to deploy it and also to AWS intend to extend it. So let me increase this here a bit. So in addition, what I'm going to do now is. Also to create a virtual environment. So the next thing I'm going to do is to import. The packages. And as these packages are getting imported, I need to create a file so that I'm able to, uh, that's my main file for the agent itself, um, reinvent demo agent MAM 345, for instance. So what is now needed to start with the strengths agent, uh, it's pretty easy and straightforward. First, what we wanna do is to import the agent class from the strengths package. So as you can see there, there is a class from the strengths package um that is needed that we need to instantiate. Uh, which is receiving user input, processing the input, and so on and so forth. So that's the first thing we need to start with, uh, when, when taking care of building our first agent, uh, or our initial agent. And then the remaining three lines to say that we have now built the first agent are those ones. So what we are going to do is now to instantiate the class. The second thing here is to take an input. So usually we are used to taking an input from a user interface. We have also a user interface that I will show you in a second, but in that case we are taking the user interface from the CLI. So in in Python that's input, um, yeah, give my name a and I give myself a name, and then passing the user input to the agent. That's pretty much it to get started. So I'm going back to my CLI. Just started And we can now ask a question like what is the capital of the USA? So based on that question, um, that's something the LLMs are trained on so that's nothing very sophisticated, so we will get immediately a response. But if I would ask now something as mentioned by my colleague Depali before that requires some real-time information like uh what is the weather today in. Las Vegas. I would expect that the LLM cannot return it back and as you can see here, the LLM is not trained on real-time data as we know, so this is something now where we need to introduce that was mentioned by my colleague before making use of tools. So these tools either you can write as part of your agent itself or you can use an SDK that has already some tools uh included. That's what we are going to do now. Or making use of MCP which we will see then later on by getting some tools returned. So primarily when talking to agents, the question is what can you do for me? And I will get in response some tools that give you some understanding so that the the loop between the agent and the LLM is about tools and the the reasoning, uh, so that it can say, OK, I found a tool that might fit the prompt. I will make use of it. So this means we need to add something in addition, which is now the second package that we imported, uh, we want to make use of, which is um coming from the strengths tool package. So what I'm trying to import here is um uh a tool that already exists as part of the strengths um package, and you can see here a bunch of tools that we can make use of, we have here. We know that the LLMs are not that great at doing mathematical stuff. We have, we have a calculator tool. We have also an RSS tool so we can use that tool, import it, so to get back, uh, give me the 10 most recent blog posts on the AWS channel in that category, for instance. request itself is more generic but very helpful because it has the capability to get outside to the internet, invoke some. Other APIs and give us something in return and that's what we want to make use of. So something we need just to add on top of that is or what I want to make use of is a system prompt. System prompt primarily is um like a persona. I want to set some um some guard rails or some pathways so uh and maybe also some some um some boundaries. So that it is easier to get further. So in that case, I'm asking and giving as prompt that it should only use APIs that are not requiring any kind of authentication, keys, authorization, etc. Usually we want to do that for the sake of simplicity. We are trying to get access to some external endpoints that are not requiring that and. The last remaining part that we need to take care of is to pass the system prompt. To, to the agent and in addition. We also need to pass. The tool In that case we only make use of one tool, we can have more tools that we can make use of, um, in that case, we are passing the system prompt and the tool to our agent. So let's try it again if there is a change compared to the initial question that we have seen. So I'm again calling my agent. What is the weather today in Las Vegas? And as you can see here already, It found a tool that it wants to make use of. Um, I'm not debugging all information we can, we can take a look into that in a second, and what it tries now to do is to find some APIs with the help of this uh agentic loop, uh, um, routing and to go somewhere to find out the recent information about the weather and it found something as we got in return. Something that seems very reliable and it's a difference compared to what we have seen before, so we extended now our agent with tools. The next step is, as we have seen, we have 3 packages we want to make use of. So we use the first one. As the base one for creating an agent, the tools, agents package for making use of existing tools, and the third one is the Bedrock agent core package so that we can transform this to a Bedrock agent core agent and being able to deploy it into the cloud. So what is needed to, there's not much needed to uh, to transform this one, but what a surprise, we need to import another. Um, class which is coming from the Bedrock agent core package, so we need to, um, have an, we need to instantiate the class Bedrock aging core rep. Which we will do here. And by doing this, so what is it taken care of if you're instantiating this one. It's creating an HTTP server listening on port 8080. And it has two endpoints that are important for a bedrock agent core agent. There is a ping endpoint, so kind of a health endpoint, especially also interesting for multi-agent communication, and the most important one is the invocations endpoint because the invocations endpoint is the one that is taking the prompt, uh, listening to the input, so the Jason file in most cases, and then to proceed with the further stuff. We will see this in a second. Uh, uh, how this is going to work, and in addition, some minor changes that we need to take care of. So we need to also have a decorator being part of the agent. This is mandatory for any agent or agent to have an entry point. So we have this decorator app entry point and then a function that has the payload that we pass through. It's trying to find an in adjacent attribute for prompt. Uh, we are passing the user input, so it's primarily the same as we did here, but no longer from the CLI but passing it then as adjacent and then returning it back. And last remaining point we need to take care of is um. To add this year to make the app running. So that's pretty much it. Let's see how this is going to work. And the first thing you can see here, your agent is live and it's blinking. That's because now we have an HTTP server listening on port 8080 and waiting for requests, uh, uh, coming from a client. So what I will do is to switch over to a second tab and now I could use a Postman or something that is integrated in the IDE or I can use Curl, uh, which I'm going to make use of here. So I'm, uh, having here a curl. Um, command and trying to ask a question, so like what is the weather today in. New York So this is gonna, this is getting passed um to the running uh agent listing on board 8080. You can already see that it is trying to make use of the tool that um that is passed through, and here we are waiting for the response. This agentic loop introduced on the slides at the beginning, this iteration, this can take once, this can take multiple times. So what I've seen also were questions like I'm using lambda. Can I now use instead uh agent core? Uh, probably in most cases not depends on what the use case is usually to transform something, uh, but you should not forget this, this, this kind of loop might take a couple of seconds, especially. In that case, as we are trying to find an API, we are not aware of because this is a decision taken by the LLM and the cycle between the agent and the LLM. In that case, uh, you can see already that this took more than one iteration. You can see that there was at least a second invocation, uh, but in return we got something that already makes sense, and this is the response that we got back from the time. That's a question. Can you get a screaming response from a call? Yes, simple answer, yes, in a, in a minute. But good question. Um, great. So Still, we're running locally, um, that, that's not what we want to do, but, um, um, yeah, usually when we start developing it's, it's locally. The next step we're gonna want to achieve is how to deploy it in uh to the cloud. As mentioned before by my colleague, um, we have this surveillance runtime agent called run time where we can run our agents in. And uh the next step is now to deploy it. There are multiple ways how to achieve that. So you could use for pro pro environment you would use infrastructures called cloud formation, terraform, etc. um, something that exists when making use, especially um uh um or using Python, um, is a toolkit that we, um, that I haven't introduced uh so far, so. Because this becomes very handy as it gives you some uh some possibilities with help of the agent core CLI uh uh to deploy and to configure some stuff. When you're doing this, if infrastructure is code, you need to pass some attributes and some configuration items, and this is something we, uh, we will see here in a second by making use of another, um, package and I'm trying to install this now. This is called, and this is not mentioned in the requirements TXT because I just want to make use of it in the in the IDE Bedrock agent core starter toolkit. And as this is getting downloaded, um, I can now uh just say configure, agent core configure um and pass through um my uh my agent class. So. It's now going to ask me some questions that are mandatory and important to to to mention uh or you need to consider when you're using uh cloud formation or terraform. First question is what should we name the agent? If you don't pass a name, it will take the file name. We're good with that and um taking this as standard, do you have a requirements TXT file? Is it named the requirements TXT? Yes, we are good. Um, what kind of deployment configuration you want to make use of? So Bedrock Agent Core is GA for a couple of weeks, a few weeks. Started with container or docker deployment. Now it's even more easier, very comparable to how you would deploy lambdas, so you can use the first one, which is now the default one. It would then zip all the assets needed um together, uploaded to S3, and in behind all the magic is going to get it deployed to runtime. Why you should then consider Docker as a second option, especially in that case if you have specific requirements, dependencies that you want to adjust in your Docker file. But also one question might be, OK, Python is good, it's fully supported. What about Java, Go, or other languages? So you could theoretically make use of these other languages as well. Uh, as soon, as long as they are not fully supported as Python in that case, um, by, uh, building then a wrapper so that you have these endpoints that are mandatory, the invocation endpoint and the ping endpoint, that's where you would probably then also make use of Docker. So we are good with the default option which is the number one, which Python environment we want to make use of, and yeah, execution role very comparable to Lambda. You want, uh, you have a role that has, uh, the necessary. Um, policies, actions needed to run the agent in your environment. If you don't have one, we are good to go with the default one, so it will take care of this as well as free bucket where to upload it. I don't have one. I'm good to let one created, um, authorization configuration so you can use OAF or in that case I'm good with IM authorization. Take this one. Uh, you can also define some, uh, request headers, especially if you have multi-agent collaboration, uh, very handy. We are good to ignore that as well. And last but not least, um, we have memory was mentioned in the slides at the beginning as well. If we, we are passing and having the communication in the user interface, we don't want to have. We have the context existing. We don't want to pass 50 100 lines of information. We want to memorize it. That's where we have short term and long term memory that you can make use of here as well. We will come to that in a minute. I'm going to skip this, and that's primarily it. So what is happening now, uh, in addition, um, is we have not skipped it yet. I have not skipped it, yeah, sorry, thanks. Yeah, so one of the advantages is if you're using this data toolkit, it gives you immediately also some best practices how to proceed. So agent core launch would be the command to deploy the agent, um, which would be now the next step. And in addition, what, um, also happened is it creates, it's creating, uh, YAML file locally based on what you have passed through and, uh, for all further um. For further communication with this startup toolkit, it will reference to this one. So I will skip this. What we want to do now is to Invoke Agent Carlange. And it will show you now what is happening next. So it's packaging, all assets needed, um, all imports that were considered in the requirements DXD file, and it's creating now the ZIP file, uploading into S3, creating the execution role, uh, and deploying it to the runtime and to showcase you this in the console. It's gonna look like this, uh let me increase this a little bit. So So you have this agent core service, uh, which you wanna start. You have then here some of these capabilities that we introduced at the beginning and let's start with run time and um you can then see here immediately all the agents that you have deployed and running in your account in your region. So in that case I'm in US East One. North Virginia and I have here already my running agent so if I'm switching back I also have here um a response in a positive way uh you will get also here immediately a possibility to tail on your cloud watch logs so in case something happens observability um is a very important aspect also of Asian core so open telemetry is fully supported, um, um, we have all the traces and. Uh, um, responses that we might see also in a second, um, and now we can invoke this from the CLI or let me switch now to introduce you, uh, to a user interface. Which more or less is listening, listening all the agents that you have deployed in your account and that's the one that we have deployed a minute ago. And I can now ask more or less the same questions as we have done before. What is the capital of take something different? Germany And the initial, um, the, the initial um. Uh, invocation of the agent, uh, may take 1 or 2 seconds, uh, longer as it's starting to, to spawn up, uh, but will then remain in the session. Um, yeah, and you can see, mm, in a very dirty way just the Jason output, it's getting us something back from the LLM. I can do now the same with something we have now seen 3 times, so do not bother you with something we have already seen. I'm happy to switch over to my colleague Jan who will try to make, uh, use of the existing agent and extend it with more capabilities. And also to attach it to the legacy app without touching the legacy app. Yeah, go ahead. Sure, you defer the application to the cloud in the 2nd iteration. Why did it take the agent twice to. It. You can, you can, um, you can debug, uh, the, the whole cycle and what is going, uh, um, um, so the whole communication and the cycle between agent and the LLM you can for sure trace this, um, for sake of simplicity. I have skipped this now, but uh you would then see it could be because it did not found the API or it found an API that was not able to respond in a given time. You will get all this information out as part of your uh debug information. In that case it was not disclosed in this demo, uh, but usually there are reasons why API is taking too much time, it's not responding. I'm not getting it in an exact manner. Everything is disclosed in the output as you define uh in your debug configuration. But fair question, especially for HTTP requests, this may take longer because it's kind of a black box where it goes. If you then use something that you have more control over, which you will see now in a second, uh, it usually it's much faster because we have the expectation on the end points we want to take care of. Jan will introduce you to that. Yeah. Also, to add on this one, adding a general tool like HTTP request means the LLM is like tempted to use it for everything, right? It might know what the capital of Germany is, but it might ask an HTTP endpoint nonetheless to validate it's, it's really true. So these general tools might tempt the LLM to do stuff which we don't want to do. OK, looking at your faces, you want to see some legacy applications, right? You're missing it already. So, um, we do have a legacy application and I have no idea what it is doing of course I have, but let's assume we just um got this on the table and we um have to add some urgentic AI stuff to it, OK. So, um, it's running on ECAS. It's, it's some Java application. It's using some database. Um, let's check it out what it is doing, and, um, I heard you all love unicorns, so the great part is it's a unicorn store and we can shop unicorns. That's great. So let's go ahead and add an agentic capability for our users to not only use this website, which is quite old, but also use an agent to shop unicorns, OK. Um, for this we have the first issue here. I don't know the endpoints the application provides. I have no idea which west endpoints are available. So, um, my first idea would be let's use Amazon Q Developer and ask it to create an open API specification out of my application, right? Um, that's quite simple. I don't know what's going on inside the application. But let's use Q Developer to figure it out. So please create an open API spec out of my legacy application. Please ignore text plain endpoints because we don't want this. OK, so while Q Developer is not working, I will show you the result in a second, but I prepared the result already, um, and I will, um, pick this up, um, to, to use. So, um, we do have an open API spec, and I swear this has been generated by Q developer. We will just pick this, um, open API spec. And um we will go and switch over into the agent core console into the gateway. So the gateway has been introduced. It's a way to host tools basically, and we have provisioned one gateway already and you can add several targets to a gateway. Targets can be, and we will see that in a second, targets can be MCP servers, which you find on. Any open source GitHub, for example, it can be a lambda function and it can be West APIs. So we can go ahead and say West API open API schema and inline schema. That's great. We are just pasting the whole API schema that has been generated. Um, by Q developer in here, um, for authorization we are selecting an API key which we don't need. Our application is accessible from the public internet, but in case you could also configure OOS or an API key. I will add this as a target to my gateway. That's great. So now we have a second target. We will get to the lambda target later on, but now this gateway is able to interact with our application using the open API schema. So what we have to do next is we have to update our agent to make use of this gateway, right? That's, that's the next step. Um, to show you what we are going to do, I will quickly switch over to this architecture. You can see the legacy application part, right? Um, and we are going to add the gateway. We are going to use our agent on the left side. We're using the front end that you have seen already and, um, yeah, we, we will, the goal is that our um. Client, our agent is using the gateway, um, and then the open API specification to invoke endpoints in our legacy application. So we are not touching the legacy application in any way we are really enhancing it, um, just to add a sentence because I had a recently a conversation with a customer who had the same challenge they have a legisy application. There is an open API schema that that you can write or exist or generate with uh AI and the question was, OK, but where do I where I need to write the code? You don't need to write the code. The translation, that's where the gateway comes in and makes it so super easy. Is the open API schema that translates then all the paths into tools that you can run and invoke from your agents, so you don't need to touch your legacy app, you don't need to write a code, you're writing a code to connect to the gateway which can has multiple targets, but you can communicate without making any changes, writing any code uh uh to make use of your legacy application. OK then we are going back to the IDE. I have great news. um Q developer was able to create this open API specification file. I will show you, so he was able to create it. We could have used it, but I wanted to speed up things, right? So, um, what we are going to do now is we have to enhance our agent like Fran said. Um, we have to add the capability for the agent to invoke the gateway, which means fetching some credentials and configuring the gateway. I will guide you through it. I will copy stuff, stuff over to make it more quick, but, um, we will, we will get there. So the first thing, um, we have to do is, can you increase the size a bit, the, the size, uh, to increase it in general. Yeah, yeah, I will increase it. Sure, thanks. So what we are going to do is we are adding some more imports at this point. I will guide you through it. I'm setting up the logging because I want to be able to see what the agent is doing. And as I mentioned, we do have to get some parameters or some secrets, right? We have to authenticate towards the gateway and we also have to get the gateway URL. So what I'm doing here is I'm defining some variables which is the gateway URL. So this is the address where our gateway is reachable. I'm defining the memory. We will get there later on and I'm also defining the agent core gateway or provider URL. This is used to get an access token, right? So the agent is calling the um OS provider getting an access token, and with this access token he's allowed to access the um the gateway. I'm defining a model ID as well and um a system prompt which uh uh which is a bit different saying you are an agent which is helping with shopping unicorns um so that's it um that's it for now we are getting the power meters. Next step what we have to do is um we have to get this access token and the great thing is in the strengths SDK there's a decorator requires access token. um we are just passing in the OR provider URL. And we are getting back an access token. That's quite nice. Um, now we have to change the agent initialization a little bit. When we are talking about tool usage and gateway usage, we have to take care of several user sessions, right? So users do have sessions with an agent and we have to have, um, we have to handle that internally to make sure that a tool, um, is bound to the session context of a user, um. For this we will just add the um init agent method and yes that's a bigger one but I will guide you through it what it is doing so um in in this init agent we are trying to get the agent from the context all the context stuff that you are seeing here is completely related to session management so it's all about separating user sessions and getting an agent for this user session. Um, if you already have an agent, that's great, we just return it because it has been initialized um for this user session already. If not, we want to initialize it, get the gateway access token, right? Um, as I mentioned, you need to authenticate towards the agent core gateway. We are doing this using the method we just created, um, which is, um, getting the access token, um, then some sanity checks, that's fine. And the next step is we are creating an MCP client. So our agent is now will now use MCP to communicate with the gateway, and the MCP client takes our gateway URL and the gateway access token, and we are doing some time out, right? So 2 minutes time out for a call that's fine for our demo. So afterwards we do have the gateway client. We have to start it. We are starting it and then we save it in the session. Um, that's happening here. So, um, for the next week request the user does, the session is already started and we will just pick up the existing agent, including the, the sessions. Um, we are creating, um, the model, um, we are selecting a specific model in this case, and, um, then we are initializing the agent like we did before. We are passing in the model and we are passing in the gateway tools and I was jumping over this one. This is quite important. After initializing the MCP client. Um, we have to do fetch the tools which are available, right? Our agent is running in one time and the gateway is running somewhere else, and the agent has to fetch the available tools from the gateway. To inject it into the prompt right for the LLM to be able to make a decision and that's what's happening, what's happening here. So on the gateway client we are invoking the list tools Sync method and we are retrieving all the tools, meaning targets and for the open API specification target all the methods available. So we are getting back the tools we are passing this to the agent, storing the agent in the context so we don't have to do it again in the next session. And we are nearly done, just a small step left, which is the lifespan manager. So, um, you can see that we have been using the um Bedrock Agent Core app before, but now we are passing in the lifespan. That's also completely related to session management. I will not go too deeply into it, but basically it's tying the agent and the gateway client towards this session and Bedrock agent core, the SDK extension is taking care of this. Great, then we are nearly done. Um, I just want to make it a little bit more beautiful and there was a question about streaming we're doing that now, um, so the agent invocation. Um, the agent invocation, let me go over there we go. So as you have seen in the user interface, we were returning the, the Jason right, and that was not really user friendly. If we want to offer an end user experience for shopping unicorns, um, we have to do some parsing. So, um, I'm invoking the agent Azin here and I'm, um, then parsing the results and just returning the real text. Um, also, the other things I'm just doing some sanity checks to check if we do have a session ID, if we do have a user message, so a prompt coming in, and, um, then I'm initializing the agent. And invoking it, that's all what we had to change, and this is a one time, one time change that you have to do. Now it's as easy like Franz mentioned, it's as easy as adding a second target to the gateway and the agent will automatically pick it up. So, um let's see how that works by updating our agent. Um, I will just do an agent core launch. Like we have seen before, I've configured this stuff, so I have a Yam YAL file here and um we will now update the agent and see if we can get some information out of our legacy application. So Want to switch to the console to, to, uh, I mean, yeah, we can quickly go to the console and take a look, um, so we do have a one time here this is the session name agent and it has been last updated at 12:18 yeah that's that's exactly what happened so um let's switch over to the browser. And take a look into. Our front end. I will just reload this one. And we are creating a shopping session. So these are the sessions. Shopping session is the session ID that that's getting passed to the agent one time and based on the session ID it will initialize an agent. OK, um, which unicorns. Do we have in store? Let's see, so the first request, as Franz mentioned, the one time has to spin up and the agent is being initialized, including fetching the excess token, fetching the tools from the gateway, so the first request is taking some time, but afterwards, um, the requests are quite fast. OK, um, that's quite nice. So we get an answer that we have 3 types of magical unicorn products a unicorn float, a unicorn party dress, and the unicorn hip hop. That's great. So, um, based on the open API spec, the agent was now able to figure out the user's intention and giving me the products, um. And I would like to shop a unicorn, so um I would like to go ahead and say let's buy a party dress for example, but for this to work um we have to create a user account and the agent has to remember which unicorn I want to shop so we will use make use of the memory now because memory allows um the agent to retrieve previous messages that I have sent and that he answered. And I promise compared to what we did before, it's a really small change, so let me quickly switch over. The memory one is really quite easy. Um, So we are going back into the IDE. There we go, and. When we are initializing the agent right here. We are just adding Um, the agent core memory configuration, so we are passing in the session ID I've shown you in the user interface we can create a new session and of course we want the memory to be separated between sessions, right? I don't want user A to retrieve information from user B. So, um, and we could add the actor ID, not doing that today, but we will separate on the session ID. And next step is now that we have the agent core memory config we are creating um a session manager, right? And in this in this case it's an agent core memory session manager and we are just passing this one over to the agent so that's the whole thing. um, the memory has been created by me before, but um as you have seen in the CLI which once used, you could use this CLI to create a memory for you so that's quite convenient. OK, change to the agent has been done. Next step, we have to update the agent. And oh that's local agent call lange. so um it will now just update the agent and afterwards we are going to shop a unicorn. Um, let's go back to the console. To check um what's happening, I can quickly show you the memory that has been provisioned here. Um, so as you can see, we do have a memory available. Um, we can also see that, um, events expire after 30 days, so nothing super interesting here, but not to forget about observability. To showcase this as well, yeah, yeah, um, we can take a look at observability in a second. I quickly want to buy one unicorn at least, um, so, um, the agent has been updated. Um, we will go back to our front end. Um, and create a new session which is the, um, memory shopping session. OK. I want to buy a unicorn. No, um, I want to show the guided experience that the agent will provide so I mean I was quite unspecific in my intention, um, well yeah, quite unspecific, um, I expect the agent to deliver the available unicorns to me and then he will guide me through account creation and stuff, yeah, that's great. So, um, he's offering me the available unicorns um I'm for a party dress definitely. Uh, let's go with the party dress. OK. The next question should be, do you have an account or would you like me to create one? OK, I want to create an account. It needs my name, first name, last name, and my email address, which is this. 345 Monday at Amazon. OK, let's see. He should figure out all the details and in the background now this loop will take some time because he will create an account and he will add the unicorn to my basket in this account. And this legacy application has no checkout process to it, but we will look into the application and see that it really worked, right? So account has been created and I do have a unicorn party dress inside my basket. That sounds fantastic. Let's go to the store. I'm going to log in. The password is not being checked so I'm just using anything in this case, but we can see I'm logging in and I do have one item in my cart. So by just adding an open API spec to the gateway, the agent is now really able to interact with my application which I have not touched in in any way for for this example. Um maybe show in the open API the the post method that was used for that case. Yeah, I, um, I would like to show you, uh, some, um, observability parts for the last one or two, seconds because, um, adding all these capabilities to the agent, it might get quite hard to understand what, what is happening, right? And, um, for this we can enable, um, tracing on the agent one time on the memory on the gateway and what this allows us to see is um a whole overview of. Um, what is going on, so we can have. Uh, uh, um, Application map. So if we go into. The application map. And expand that we can see our agent right here. That's the agent running on Agent Core one time. We can see that it is using the Bedrock Agent Core service, of course we can see that it is using our gateway. We can see that it's using the memory. And the OOs, right, we are getting an access token. We can also see that it is invoking bedrock and um the LLM really and did 8 requests to the LLM and we can also see that we are using sequences Manager to fetch the OO secret and um the gateway UL so um we get a real insight into what's happening and the real cool thing is. The gateway is invoking our unknown remote service, so we can see that the gateway is invoking our application and we do see that several requests happened to this one and I think that's a great great way to really see what the agent is doing and also how many requests to an LLM it's doing in a great visual way. To wrap this up, um, these three, QR codes, especially the third one, all those, uh, demos that exist. Especially the third one is a large GitHub repository with a lot of tutorials. The second one with a lot of use cases, so they're ready to deploy cloud formation templates that are primarily showcasing that what we tried to do now in 60 minutes. We had some stretch tasks that we wanted to show you today as well, but with respect to the time, not feasible and easy. Uh, but really encourage you to, uh, uh, to make use of Tequita Prepo. Deepala, you want to wrap up with the last one? No, I think you did it. I hope you guys enjoyed our code walkthrough. You have hopefully you're taking something back home to try that out in your personal environments or company's environment. Um, so yeah, uh, enjoy the rest of your day. Thank you for attending and please provide your feedback if you loved our session. Thank you. In the moment. Thanks. Thank you.