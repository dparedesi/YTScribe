---
video_id: OuuaczRTfHw
video_url: https://www.youtube.com/watch?v=OuuaczRTfHw
is_generated: False
is_translatable: True
summary: "Gaurav Arora from AWS, along with Aaron Sam and Stefan Buckman from Slalom, present the concept of an \"Agentic AI Factory\" to address the challenge of scaling AI agents from a handful of pilots to hundreds or thousands of enterprise-grade production systems. They note that the AI agent market is projected to grow exponentially, but organizations face significant operational, technical, and governance hurdles.\n\nThe \"Agentic AI Factory\" is a framework provided by AWS, available as a starter kit and set of accelerators (likened to an \"IKEA flat pack\"), designed to standardize the agent lifecycle. This lifecycle consists of four stages:\n1.  **Assess:** Using an intake agent to qualify use cases against business, technical, and commercial criteria.\n2.  **Plan:** Detailed designing, resource planning, and governance checks.\n3.  **Implement:** Deploying agents using standardized blueprints (e.g., for loan origination) and a \"fabricator\" agent that can auto-generate worker agents based on specifications.\n4.  **Iterate:** A recursive learning loop where agents improve over time based on operational metrics like hallucination rates and speed.\n\nThe architecture emphasizes security and governance, with six pillars including identity, data security (redaction/encryption), model security (guardrails), operational safety (sandboxing), governance (aligning with ISO/NIST standards), and runtime controls (human-in-the-loop gating). Aaron Sam demonstrates the factory's UI, showing how an administrator can manage teams, use the \"fabricator\" to build agents from the Strands SDK, and run an assessment using an AI agent to analyze requirements documents.\n\nStefan Buckman shares a case study of a healthcare customer in New Zealand who moved from fragmented pilots to a streamlined process, identifying 14 high-priority use cases and establishing a Center of Excellence. The session concludes with the launch of the Agentic AI Factory assets and an invitation to an early adoption program, with a roadmap that includes FinOps for agents and Marketplace integration."
keywords: Agentic AI Factory, AI Agents, Governance, Slalom, Scaling AI
---

Welcome Great to be here with you all. I'll start with a quick pulse in the room, just um just to get a sense of the room. Show of hands if you have built, or your organization have built a handful of agents, like 1015 agents. Oh, quite a few. Fantastic. What about 50, 50-ish mark, 50, 50 to 75 agents? Keep your hand up if you build 100+ agents. All right, why not do it. Thank you for that. Um, as we evolve, we're expecting our organizations to build 100s and thousands of agents. Not just by your teams, but your organizations, your teams across your um technology departments, other business units. And think about it, how are you're going to manage them. Sounds a bit chaotic, isn't it? And if you think about that, you're not alone, because that's what we're hearing from our customers globally. And that is precisely why we're here, to talk about how do we go from building a handful of agents and operating them to hundreds and thousands, and doing that in a repeatable, secure manner and at speed. My name is Go Arora. I'm based out of Sydney, and I lead the partner solution architecture team for Australia and New Zealand. I have with me a couple of my friends and also colleagues, Aaron and Stefan, over to you for a quick intro. Hi, uh, my name's Aaron Sam, I'm the next-gen tech lead for the Asia Pacific and Japan region, uh, and I'm focused on solving the problems that you don't know that you have yet. And hey everyone, great to see you all here today. So Stefan Buckman, I'm head of solutions for slalom and really happy to join my two friends here. Lovely, thank you, thank you for being here, Stefan. So objectives of this session, um, we'll start with a bit of a context setting, what's happening in the industry, what opportunities we have, but also we talk about some of the challenges we need to solve together. Then Aaron and I will do a bit of deep dive of Agenic AI factory, but it is, and we'll do a bit of a demo. And then we'll have Stefan coming to stage to talk about and provide insights from his, um, his journey from building agentic AI factory with us, and then I'll come back and do a bit of a close and and next steps. Let's get started. Now what's happening, what, what are we seeing in the industry? Um, we see enterprises doubling down on new paradigm of AI. Now, I call it new paradigm because it's generative AI and energetic AI together. They are different, but let's just call it new paradigm of AI. Analyst research tells us that AI agent market will go from $8 billion today to $98 billion by 2032 at 45% annual compounded growth rate, which is huge. And that's just AI agent market, not the ripple effect it will create to broader kind of technology, services, project services, managed services, and other application development avenues. Now VCs, venture capitalists, are all in. First three quarters of 2025, 50% of all VC investments went to AI first organizations. And also, from an enterprise software point of view, currently we have 5% of our enterprise software as per Gartner with embedded AII agents, but by next year, it will grow to 40%. So if you think about it, um, you have. Software, you have capital, you have innovation, all aligning towards solving a bunch of problems using authentic AI. And we have a tremendous opportunity ahead of us. And that is why we're here in the room to talk about how do we actually capitalize that. Now let's look at the evolution from Gen AI to agentic AI. We started with generative AI, chatbot assists, chat GPTs. We, we provided prompts, we got some um answers, we interacted with it. We used the outcome to solve day to day problems. Do email better, provide insight better, get some reports better, get a better image, create custom images, for example. Then we move to simpler agents. Agents who can actually break down the task into multiple steps, make an API call, get some data, fetch some data, and be able to do simple actions. Now through to multi-agent orchestration. An AI agent Has a single purpose and scope. It has a very narrow context. Versus Multi-age energetic systems are able to actually handle and uh and deliver complex multi-step processes from a business point of view, and be able to deliver real business value. Now what does that tell us is we are actually Looking at the rise of the agents. Gardeners tells us that by 2028 we will have 1.3 billion agents in our industry. And think of it from a team of 3 to 5 people. You'll be working with 50 to 100 agents working alongside you. Which is a fundamental shift in how you work today and how you'll work tomorrow. And for that we, we need new type of foundations. We need new type of way of thinking, how are we going to support these agents within your own teaming, within your own organization. Now no innovation, unfortunately, is without any blockers and challenges. For that, to talk about some of the challenges we are seeing in the market, I'll actually invite Steph to come and talk about some of the challenges he's seeing in his day to day interaction with the customers. Thanks, Garth. Excellent. So I wanna go through a couple of things in terms of as we look at the challenges that we've uh observed within organizations. So we've been deploying AI initiatives, agents through organizations for a number of years now, and I think what we've seen time and time again is there a repeatable pattern of blockers and challenges that organizations face along the way, along the way. So what I've got over here is heading from what are the operational challenges all the way to the strategic, it's really important from what we've seen that you're tackling things all across the spectrum in terms of where problems arise. So I want to go through a couple of those today and talk about some of the challenges we've seen with customers. So the first one that we're observing, and I'm starting from the operational side, is that lack of technical foundations. One of the big challenges that we're seeing organizations face, and specifically in this case, a retail customer that we're looking at, is without a strong technical foundation to deploy agents and deploy agents at scale with the right governance across them, your AI initiatives are gonna become blocked really quickly, and so that's an area that we've been helping customers with in terms of where we really need to focus early on. Alongside that, AI and AI agents themselves are only as good as the data that we actually make available to them. So where data is siloed, where it's potentially not in cloud or not really readily available, that's a major aspect in terms of where customers come undone. In this case we had a manufacturing customer that was needing to join up um shipping records and inventory, and in this case with data siloed, sitting in different databases, not readily accessible, created a real challenge for how AI had the right context to right to make the right decision at the right time. Now, more importantly, as we start to look at workloads that need to get to production, when we start to look at regulated customers, how you're providing that security, trust, as well as the governance across those AI workloads becomes essential. We've had FSI customers as an example with real regulatory controls, and building observability into agents, as well as being able to trust the answers that you're getting from AI is really critical. So how are they building the frameworks that number one, give them the guardrails necessary to operate. But also the observability in order to trust what the agents are actually giving them back. And one of the core aspects here is if you look early on from an AI perspective, AI was really siloed in, you know, maybe one or two areas of the business. That's not the case anymore. AI is spread all over the organization, all over IT. And it's really important from a leadership perspective that everyone's rowing in the same direction. Everyone understands what they're trying to achieve from an agentic point of view, and you're bringing everyone along for the ride. So that leadership misalignment, as well as how you're upskilling people and bringing people along for that, is really critical. One of the big things that we've seen through organizations is that shift that needs to happen in terms of critical thinking skills as you start to operate with AI agents, and how that talent gap really needs to be uplifted in order to address that challenge. Now, one of the things we talk about a lot is that agents are stuck within POC purgatory, if you will. They're stuck within proof of concepts and not necessarily getting to production. Now, what we're finding is that path to to production really needs to be underpinned by the value that you're gonna bring at the end of the day. What is the return on investment, what's the customer value or the process or efficiency value that's gonna be uh gained. If you aren't going into your AI initiatives with that value well understood and able to measure that value, you're unlikely that you're going to be able to actually accelerate or get that workload from a, from a uh development environment and into production. And finally, you know, I think when Gerve asked the question in terms of how many people are deploying 1020, hundreds of agents, as we start to really scale agentic adoption and use, having a repeatable pattern, having blueprints that you can actually lean on and leverage becomes incredibly important. We've had customers in the space, specifically in manufacturing. Customer that lacked those repeatable patterns and we're starting from scratch every single time they try to deploy an AI workload. That's fine for the beginning, but as you start to scale to hundreds of agents, that's clearly not gonna work. So one of the core challenges that we see is how do you start to build repeatability in those repeatable agents through the organization. Those are the core challenges that I want to talk about, but I'm gonna hand back over to Gov. Thank you, Steph. Thanks for the insights and, and, and summary of the challenges. Um, look, what the 6 of them, and there are multiple more, um, they are all telling us loud and clear that we need to think differently. We need a new runway. We need a repeatable framework. We need strong technical backbone. And also we need to find a way of aligning business use cases, business value with geogenic deployments to get that ROIN value. In short, we need a gentea factory. Now, AWS Agena Factory is actually a, uh, it's initiative for partners, primarily for partners, but it's open for customers as well. We wanted to help you get from those business use case concepts to production at scale. And as a part of that we are providing a set of accelerators and assets. Think of them as IKEA flat pack for you to build your own factories. We're providing blueprints and framework. And playbooks so that it has all the best practices built in, all the patterns built in, so that you can actually take that and, and build your own, establish your own factory. We're also providing a platform starter kit. It's a platform interface, which has in-built agents, in-built blueprints, integrations, so that you can actually do rapid deployment using the factory. And also, as Steph talked about, um, if you remember, most of them were security and govern governance-based challenges, trust challenges. So we want to lead with that. We wanna make sure that within the factory, security govern governance and compliance are actually built in natively so that you build that trust going in. Now let's talk about some of the core concepts of the factory. Let's start with, first one is the inner working of the factory, um, like any factory, you want to take raw material and turn that into, um, productions, um, products, in this case, um, production systems. Ageneia factory has 4 processes or 4 stages. And each stage is actually backed by backend agents or life cycle agents. The first one is assess. Assess will take your uh intake of a use case. Use case can be industry use case. Hey, I wanna build a loan origination, um, kind of flow. And then it will qualify against business, technical, um, commercials and governance kind of avenues. It will look at some of those criteria, which Aaron will demo in a bit, and then provide you a bit of a report. Once you've actually interacted with it, it will ask you a bunch of questions, upload some documents, and then it will provide you a bit of a report which has a bunch of um kind of aspects, technical, business, commercial aspects of it. Once qualified, you can move to implement stage. Implement is taking the output from assess and what was approved, and now we get to detailed planning, resource planning, timelines, sprints, detailed design. Um, environment or or organization readiness, your governance and compliance requirements, everything you need from a planning perspective so that you can actually move to implement, which is the next stage. Implement will take that and then deploy that within the factory environment, but also you can um deploy those agentic systems in your other AWS um external um environments and accounts as well. That includes deployment, QA testing, and go live. You can do that in uh non-proud or lower environment or production environments. From there we moved to ITrade. And this is a key differentiation of the factory is recursive learning. So when agents operate over time, they collect metrics, and we have a capability within the factory we're building where it will actually take on metrics like hallucination rates, error rates, uptime, how fast the agents worked, or business workflows worked, so that they can learn over time and be more effective in terms of cost and performance. So you go from factory intake to production systems through those four processes. Another concept is integration strategy. We need a robust integration strategy because agents don't operate in bubble. They need to interact with external systems to be successful for the actions they want to take. And we have built-in integration strategy within the platform. You want to talk to agents need to talk to APIs and other agents, agent to agent, agent to tools and objects, agents to data. And we support, um, uh, that is Bedrock, Bedrock Agent Core supported, uh, integrated, but also GraphQL RT, A2A, etc. Now agents need to react in real time when things change from a factory life cycle point of view, but also when you deploy agentic systems from the factory. And for that we're we're supporting going in IBridge, which is the core messaging hub of the factory, but also SNS, STS, Kafka, MQTT, etc. Agents need to access data and do it securely. We have um in-built connectors with S3, um, bunch of vector databases. Also, you can use SQL and JDBC strings to connect to other data sources as well. And also other external systems you want to integrate with identity. Is it SAML? Is it OR 2.0? MCP, your own MCP servers, a MCP servers, but also third-party MCP servers. You can actually integrate that so that agents have access to um the tools and the data, um, they need to, they need to use to take actions. Another key concept is AI agent and agent blueprints. Like I mentioned, AI agent is like a microservice of a new AI world, defines scope, context and purpose. So it's a building block in itself. We also have a concept of agent blueprints. Agent blueprints reflect, represent your business, agentic business workflows. Like I said, loan origination, you need to have intake agent, you need to have document processing agent, approval agent, um, loan allocation agent, offer letter agent, and so on. So, blueprint will be um orchestration between multiple agents, objects, data assets. So it gives you a defined business outcome. And this is super important because now you have a building block which is an agent, but you also have a building block, abstracted business block, building block which is a blueprint, so you can actually use it across use cases. So that becomes your repeatable asset and provides you, saves you time, money, and resources. Next concept is security and governance, very critical, um, for us, there are 6 pillars of security governance, part of the factory framework. First one is, uh, identity and access for humans to operate the factory, but also agents, and agent blueprints. Second is data security. Agent have need to have just right level of access to the data, um, assets and objects. PII and sensitive data redaction or filtering, encryption, and so on. Model security, we, we integrate directly with um um Bedrock and Bedrock Agent Core, provide you guard rails in terms of um uh protect against prompt injection, and validate the input and the output of the model interaction from the factory. Operational safety. Operational safety covers a bunch of things like um Agents sandboxing. When agents are want to do some action, they'll create a sandbox, spin up a a instance or a container or code. You want to make sure that you operate that safely. Also from agents, agents will have access to a bunch of tools, which tools are available, which tools are not available. You can actually monitor that and audit that uh within the factory console. Next one is governance. Now, going in, we are implementing AWWS best practices, uh, responsible AI best practices, but we have in our roadmap, which I'll cover it in a bit, um, we wanna actually align to standards like ISO and NIST as well, from within the factory, provide relevant controls within the factory. 6th 1 is runtime controls. Super important. For example, um, things like agent gating. Now you have agent or agent workflow, and they need to do sensitive action, for example, updating financial records, or deleting something, for example, um, rightly so. But you want to gate it. You want to have a human in the loop, you want to have some checks and balances in the loop. You'll have some controls to do that as well. And as well as um feedback loop integrity. So as agents are picking up the metrics and the feedback loop, how do you make sure that the integrity is there so that you're not adding the bias back into the system? So these are the controls we're building natively within the factory. With that, those are the core concepts of the factory. I'll hand it over to Aaron, which will take, who will take us through the demo and architecture. Thank you, yeah. So uh Gav and and Stefan have talked about what it takes to build a factory in terms of people, practices, and even assets. But what does it take to actually technically implement a factory? So a factory requires standardized patterns, we've already talked about agentic blueprints. What does that mean in terms of technical implementation? Well, that's the prescriptive guidance on how do we actually build, what do we need, what are the, the raw materials that that Gurav was talking about on the intake of a factory to get to a product. These standardized patterns mean that we're always going to have uh a structure and this governance that that both Stefan and and Gav are talking about around how to get to our end product. But that governance needs to obviously be repeatable. Obviously we want to make sure that every time we're taking a blueprint, it's not gonna change with the, the nature of agentic AI being, being uh non-deterministic, we wanna use the non-determinism of non-determinism of agentic AI for the benefit of the emergent behavior in our workflows, but not for the er, Non-capability or the, the, the output or the hallucination that we we're trying to govern and control, so this is where the patterns along with the repeatability, so the the er guard rails and the control and the, the um, Mechanisms that we use to control our emergent behavior are made repeatable, but not in a way that we can't extend and integrate, so that we, essentially not not wanna just build something in isolation that's not going to do anything for us realistically, like it's fun to have a chatbot, but if it's not actually integrating with one of our internal systems to draw on the data or to, you know, start a workflow or to actually execute, um, you know, agentic workflows within our organization, Then why are we building it? So we need extensibility of the actual factory itself, and the agentic solutions that we're building, and interoperability between maybe the agents we're building, whether it's within a platform, whether it's within other third party platforms, uh, and with our internal systems. So how do we do this, how do we implement this? This is, this is, I'm gonna take you through, so apologies for the non-technical people in the room. I'm gonna get a little bit technical just cos I'm the, the tech guy in the room, so uh let's look at this in terms of a blueprint for a factory. What do we need to start with? So we we've already talked about having the, the underlying blueprints. Obviously AWS has a wealth of best practices, we've got the well architected framework, these all feed into the types of understanding or knowledge that's required to build our own solution. However, on top of that, we've spent the last, Year building out and researching or researching and developing um agentic solution blueprints, building up prescriptive guidance to help guide people through how to actually build agentic systems and take advantage of the cutting edge patterns like supervisor, arbiter, fabricators, different patterns to allow agentic development. But on top of that, what's important is our partner ecosystem. Obviously drawing on the the experience of, and the assets that our partners are developing in the same way. The assets that they're developing for their customers, their experience, their knowledge, as well as understanding the the customer environment, the the constraints, the governance, everything. That needs to be done in the customer environment, all of this knowledge needs to feed into a factory, otherwise if we're missing any one of these, then we've got gaps. You know, we may build something that's novel, but it may not fit the governance structure of our customer, or we may build something that's AWS best practice, but it may not fit what the partner is trying to achieve or what the customer is trying to build. So that needs to feed into knowledge and memory. So this is our knowledge base in terms of understanding what we're building, but also it forms the memory layer of any agentic systems on top to understand where they're at or what they're doing within the environment, to understand what it is that they would need to do next, right? So if we're building agentic systems with agents, which is what we're getting to. Then we need to know in terms of when we get into our reasoning cycle, if we're building something and we're trying to achieve something, how do we plan out where we need to go next. So it's not just a rag or a knowledge source, it's also a a a shared memory layer that helps fulfill what we want to build from a prescriptive guidance point of view and also what are we in the middle of building. So this is where we get into the factory that Gurav talked us through, where we have, Starting with an assessment, we need agents to then assess based on this under underlying knowledge source, but also like essays in the room or anyone who's done any level of consulting, whether internal or as a partner, you know we need to go through requirement solicitation, we need to understand what it is that we're trying to build. To get to our end solution. So the assessment in the factory is agents that are running through requirements solicitation, understanding what are the gaps between what you have and going back to the knowledge source around what we're trying to build. From there, we need to get into planning, so we can take an assessment, we can get a high level design from assessment. We need to understand it now, what are the additional governance controls, what are the different compliance requirements, what are the resources that we have, how long do we have to build it? We need to build in all of this into our design, so that we can actually get to the stage of implementation. From implementation, It's not always gonna be the same, right, we maybe we want to automate some of that imple implementation, but maybe we already have some pre-built products or blueprints that we don't feed in through the factory that we wanna keep separate and integrate in. Now we have agents to work with the high level and detailed design and the plan to now start outputting capabilities like spectrum and development, uh integration for project management, and also the fabrication of automated agents. So that the the spec driven development helps us move into AI driven development, if you're anyone familiar with Quiro or Q Developer or any um AI assisted development tools. So you can start there. If you don't want to actually get in and integrate from a hands-on development point of view, you may go straight to auto fabricating within a factory, so being able to generate capabilities without having to do the development. Or if you're a customer, and maybe that's when you go to your partner and they can work within the factory to help build out the custom modules on top of anything that can be auto-fabricated. That also moves into orchestration. Once things are fabricated, they can be orchestrated. And from orchestration, obviously that's the execution of workflows, we obviously wanna be aware of observability and reflect on any metrics, any logs, any capability and emergent behavior to understand and refine on the next iteration if we're going to go back and start improving and rebuilding and developing on top of what we've already built. Now all of this are the underlying building blocks of what it takes to build out a factory, an orchestration engine, an ergentic factory, but all of this, I mean, we can't just run it all through a CLI, so it all needs to be governed through a usable UI where we can have a single interface into, Integrating with the entire platform, and when I say interface, I'm, I'm talking we can't have queries across many different systems, otherwise we in itself, need to introduce additional layers of security, additional layers of governance. So it's securing the factory down to allow for the implementation of solutions that are best practice and are following security first principles. And then also being able to manage from what Gav was saying, it's not just one agent or a couple of agents. We need to manage users, roles, teams, entire organizations, so that when we get to the hundreds to thousands of agents, we have some level of governance and control over the agents in different departments, the agents in different teams, or individual, down to the individual agent. And so all of this works towards the the plan that Garav was talking about before, where we have our assess, plan, implement and iterate. We start from requirement solicitation. We can then build and automate um the the solutions that we're trying to build, and then taking the observational material or observational logs and metrics, we can then refine and build back into the system. So the sys the the factory continues to improve over time. So I'm gonna take you through a little bit of a a demo of what we're releasing today in terms of a preview. Can we see on the screen? Awesome, has it started playing? Yes it has, awesome. So, from a security and governance point of view, obviously you want to have a uh a, An authentication, an authorized way of entering the factory. For the preview that we're releasing today, uh, at the moment you can sign up. So what you've just seen is we've, we're, we were going through the sign-up process. I haven't gone through, uh, and signed up because I don't wanna wait for the, uh, the token that we receive in the email. It can take sometimes 10 minutes, so for the purposes of the demo, I've gone and logged in. But first of all, when we come into the factory, we can see our, our metrics, our logs, all of our observability data, understanding the health of the agents that we've deployed, the current intake that we're doing in terms of the factory intake. Anything that we've deployed Garav was saying that, you know, it's a, it's an organizational thing, right, it's not just an individual user. So when you first sign up, you can see here on the left, a new user will come into the lobby and doesn't really have access into anything until they're assigned a a a an organization or a team within the organization um or a role. As the administrator in this case, I've logged in this, as the administrator, I can see everyone in every role, and I can see anyone in the lobby where I can go ahead and assign them a role, whether it's a developer, an architect, a project owner. And assign them an organization. From there, when they select their organization, then they get the difference between, The entire organizational metrics or just the team that they're in and seeing the metrics that are relevant to them. But what's what makes up the factory in terms of actually being able to build solutions into the factory, and we talked about orchestration before. At the core, we have the agent agent catalog. So in the agent catalog we have a series of built-in agents, you can see the fabricator down here at the moment is the only built-in agent for the the preview. The fabricator is the core agent within the arbitration pattern, where, if we're doing a supervised workflow and we wanna go and create an agent. For that supervised workflow, we can use the fabricator to go and build out what we call a a worker. In this case, I'm creating an agent on the fly, that will read from a document that I've uploaded into S3, do a summary, give me a critical analysis and upload it into a document store. Along the way, I get to choose tools that I want the agent to work with. Uh, at the moment you can see that there's no custom tools in the catalog, however, what I just clicked on on the screen was the tools available under the strands SDK. So any of the tools in the strands SDK you can, you, you, the fabricator can automatically select from, or you can select from custom tools that you've built or implemented already. From there we can select our integrations and any data stores needed for building an agent. From here, We then obviously check that everything that we've selected is is what we want. When we go ahead and select create agent, this is the auto fabrication process that I was talking about. Now we can actually go out and create for you an agent built on strands SDK, so it's a self-eating dog food. The strands agents are building strands agents, but within the governance and control of the tools that you've selected, with the integrations that you've selected and the data stores that you've selected. When the fabricator has built that, the agent will show up in the agent catalog where you can then activate it. Obviously it starts as deactivated so that you can go through and check that it is compliant with what you've asked it to do, make sure that it's covering everything that's needed. You can go into apologies I forgot to to do in this demo, show you the actual edit the um spec and see how to communicate with it and and what it requires. But from there you can go in and and modify the agent or activate it, deactivate it, delete it. Play with it. The most important part of this though is the integrations. This is what you're looking at at the moment. So without integrations, what good is an agent? If we can't integrate our agents into different systems that we have internally, into third party systems, then the agent has a very limited capability. Let me jump because we're we're onto the intake now, so from an intake point of view. We start with assessment, we already went through this when I was talking through the building blocks. When we talk about assessment, the agent that we built for assessment is essentially a requirement solicitation agent. Right now on the screen, you can see us starting a project. When we start the project, we're going to initialize the um the assessment, obviously, We can turn off initialized assessment, that's an auto prompt, but that kicks our agent off to start understanding what is it that we now need to achieve? What do we need to do in in terms of requirement solicitation. So we're going from technical, we're going from business, we're gonna have a a a requirement solicitation session or or conversation with the agent to get through all of those uh technical business, um, governance and and commercial capabilities to get to a high level design and uh the analysis of what it is that we want to achieve. Now this preview is also a demonstration of capability, so as we're going through and talking with the agent, it's also showing us what is the chain of thought that the agent is going through. How did it get to asking this next level question? When uh what what we're demonstrating now is we wanna start with a technical assessment, but instead of going through and and talking through every single question, I've got a high level design from a previous solution that I wanna upgrade and just take all the specification from that. So I've uploaded the document and it's sent it to to the agent, instead of sitting and waiting for it to do the assessment because it can take 1015 minutes. I'm jumping into one that we've done previously where we're already halfway through the conversation. So you can see that we're progressing through, you can see the chain of thought here where the agent has gone and looked at the document, it's done a gap analysis and it's now asking questions based on what's left, what information does it need. You can see though that we've got to 100% technical. So the agent now knows I've got enough information to move on. Now let's gather more on the business and commercial side of things. We'll continue going through requirement solicitation until we get to 100% on all. And then the agent will tell you, I've got enough information, let's go and generate a report. This is where we're at now. So I've jumped out and come into one that we've gone through the entire requirements solicitation session, and here we can see the top recommendations, any issues or gaps that we have, and even download a high level design or download a report to help us get to the next stage of planning. So knowing what we want to build, we can now start to plan out what we want to build. For the preview, we're gonna stop there in terms of not not releasing too much of our secret sauce. For those who uh Gurav will talk about it later, sign up to the the early preview, we will release more um to the to the early preview. But from here, we're giving you the capability as a starter kit to get in, run through your assessments, start integrating into the supervisor pattern, even utilize the fabricator to start building agentic orchestration or agentic solutions on top of a governance controlled secure platform. I will leave it at that for the preview of. That went back, we wanna go forwards. Alright, so again, sorry, this is gonna get a little bit more technical now. I will try and keep it as high level as possible. I'm going to start putting module pictures over the top of this, so if you wanna take a photo of this, I'll just leave it up on the screen, but this essentially is the architecture of everything that I just took you through in terms of the the UI. Um, from the factory point of view. So when we talk about the life cycle agents, in the very, very center there we have the 4 life cycle agents. It takes 1 agent to do all the requirements, elicitation. It takes another agent to go and do the analysis and all of the design, and then moving into planning we have another agent and then into implementation we have another agent. That implementation agent is the one that actually talks to our arbiter patterns, so the fabricator takes requests from the implementation agent to go and build out our workers. What I didn't actually show you in the in the demo is you don't, you're not just building your own fabricator agents from the, the UI. If you're going and building your own custom agents within the catalog, you can also import your existing agents, so that you can start utilizing them through the, Supervisor pattern or start utilizing them through the orchestration. So hopefully you've all got your your picture. I'm, I'm gonna start talking about what each module is. So from, from the UI point of view, we're coming from the AWS best practices around application and web hosting development, so obviously it's a statically web hosted application. But for the capability of talking with agents, there's a lot more needed than just a simple R-based API. So the the entire UI factory in terms of taking the governance of all of the agents is utilizing a single API through AppSync and then web sockets, so that we've got bidirectional communication between the front end and the backend, but everything is securely hosted in a single S3 bucket which can be distributed across multi-regions depending on, Uh, how big your, your deployment of the factory may be, or if you're keeping it small, to 1, to 1 regional, um, Cloudfront distribution, but the UI provides all of the governance from our factory point of view. If you were taking it and using it and building on top of it, the reason also it's behind a single API is so that you can take the UI and scrap it if you didn't want it, and integrate your own, or if you've already built a platform but want to take advantage of the capability, you can start integrating through that singular API. So that's where the API provides all of those capabilities that we were talking about, in terms of doing the assessment, running through the assessment agent, then going through planning, then going through implementation. That implementation then feeds into. The orchestration. So I call it agentic orchestration, others call it choreography, others call it different things. At the end of the day, it's essentially implementation of agents, whether they be the fabricated through the the uh the platform itself, whether they be through the custom agents you're building and integrated or configured into the platform. But allowing the emergent behavior agents to communicate through a supervisor pattern, so having a supervisor understand what are the agents at its disposal, what are the tasks it's trying to achieve, and handing the uh handing requests off to the agents uh able to fulfill the task required. That allows for the multi-agent collaboration of building out emergent behavior, so instead of really orchestrating step by step by step, you can get to advanced workflows or advanced use of agents by simply supervising the overall workflow, managing the state through uh individual state management instead of through an orchestration state, like a state machine. Each agent can then manage its own state through the supervisor, so that it can overcome issues or problems that it faces throughout the workflow. And then finally, everything runs through an observation and analysis layer. So everything that we're doing in the system is observed, is metriced, is, is stored and analyzed, so that we can feed back into the agents, both the fabricator agent to understand, maybe two of the agents that we have running are better as one agent, or maybe one agent that has too many tools should be broken up into two agents. It also feeds metrics around the health of the entire system. So that feeds the dashboard that we looked at at the start and understanding, What's the health of our agents, um, how many agents do we have active versus how many are inactive, how many have we built versus how many are we using? All of this information along with the runtime and observation information feeding in to help you understand how to build out and govern better agentic systems. I'm gonna hand it back to Stefan now to take you through a little bit more about how slalom has er implemented agentic factories within their customer environments. Thanks, Aaron. Great, fantastic. So that is really interesting in terms of what AWS has built here. And one of the things I wanna take you through is some work that we've been doing with a healthcare customer in er New Zealand. And one of the things I want to really underscore is using the concepts um that Erin and Ger have spoken about, how you start to apply those to customer problems and some of the results that you can see from that. So for this customer, there are a couple of things that this customer was experiencing uh when we got there. Number one, fragmented pilots, and I'll start to get into some of the details around that. Readiness gaps and wasted investments. I've started to talk about things like ROI things like how you get from proof of concept into production, and how you actually prepare the organization to get ready for AI use cases. So from a fragmented pilot perspective, in this case, this customer's pilots were isolated, they weren't using repeatable patterns, and they were struggling to get from the proof of concept stage into production ready agentic systems. Those readiness gaps really existed across two things. Number 1, what did data look like? What did the technical gaps look like that they had to overcome, but on top of that, what was the talent gaps and the governance gaps that needed to be focused on at the same time. So from a data quality perspective there were issues there, but also there were skills gaps in terms of the people and processes that existed in the organization. And in terms of wasted investment, when you're focusing on those things, no one wants to actually waste money at the end of the day. We want to make sure that we have a way to build repeatable patterns, leverage the IP that we're actually building to consistently build more and more agents, and so that ROI, being able to measure and metricize it, as well as how you govern it and standardize that really were aspects that this customer was struggling with. So if we look at the process that we went through here, so same phases that Aaron and Gerv were talking about, so we've got to assess, plan, implement, and then starting to get into that measurement and enhancement. And so this is how we started to look at how you execute on a factory process using an underlying system like what AWS has been building. So from an assessment standpoint, some of the things that we look at are how do we align leadership, how do we make sure that everyone understands the tools and processes that we have, and across divisions in an organization, we're able to implement those. Of course, from an assessment perspective, we wanna make sure that we can catalog the current state. What do the processes look like, where is the data, how do we start to bring some of those things together? But then from a talent perspective, how do we look at the AI gaps, how do we assess the talent gaps within an organization, and the readiness to actually adopt AI initiatives across the organization. So a lot of things happening in the assess phase to really ready that organization for the next steps. In the planning phase, we started to look at what are our opportunities, what are our use cases that we think we can execute on. You can look at through those use cases we're looking for potentially what makes sense to augment or potentially to um automate processes within an organization, and starting to map those out. But alongside. Mapping those out using a factory approach, how do we start to define what the return on investment looks like? What's the value that we can pin at the end of the day to these initiatives, and then designing that roadmap for the type of capability we need to build and prioritizing the use cases that we uh potentially want to uh leverage here. From that point, we start to build the flywheel, which is what we want to see, because you're not going from, you know, 1 to 10 agents, you could be going to hundreds of agents. So you need a repeatable process using this factory approach that allows you to really scale and deploy these initiatives um at speed in an accelerated way. So under underscoring all of this is the coaching that you provide through the organization, but through that coaching, we start to build the flywheel around enabling people and processes. Adapting an operating model or center of excellence around AI initiatives, making sure, as Aaron touched on, that we can monitor and manage the workloads and the AI agents at the end of the day. Making sure that at each step of the process, that we can measure either the value being achieved or what that agent is actually able to do, so we can actually identify when we need to adjust or change our approach. We start to look at how does this start to change an organization, where are we accelerating, where are we offsetting roles, where people can focus on different things, so making sure that we're doing that role and process transformation at the same time, and then of course alongside all of that, we start to really redefine the technology that we're deploying through the, through an organization. So hopefully it shows you some of the things that we can start to bring together using a factory approach to really achieve those results. Now for this customer, how did this actually look when we when we executed this? So you can start to see from a from a pipeline perspective, we went in there with about 50 use cases that we're identifying and managed to whittle that down to 14 high value prioritized use cases where the data was readily available, the platform was ready for those use cases, and they had a defined return on investment that we could actually attach to that. We want to make sure that we can measure productivity, when we deploy these things, how are we able to test and um validate that we were actually achieving the outcome and that they were actually allowing us to uh showcase how that return on investment was actually achieved. Now through all of that, the center of excellence was incredibly important. How do we bring together the architectural patterns, the blueprints, the ways of working through an organization, as well as the governance perspectives. That's how you start to scale and that's how you start to accelerate using something like a factory approach. And then of course, we needed to get it out there really quickly, so that rapid business validation to get it out into production in an accelerated way, but bringing the leadership teams across at the same time so they can see the value and the speed that you're able to move at. That's where a factory approach is really essential in terms of moving from tens of agents to 100s or thousands of agents, and that's underscored by using something like a factory approach. Gv, handing back to you. Lovely. Thank you, Stefan. Thank you for you to you and Slalom, to be here and, and sharing your story as well, and your and for your partnership. I do appreciate that, folks. We, we discussed why the, the shifts, the trends, the opportunity, the challenges. We looked at what the factory framework, the, the platform, um, and, and deep dive into the architecture. Now let's talk about how, how can you get started? Now, Um, I'm thrilled to share that we are actually launching, uh, Agenticare Factory assets today, right now. Um, they just went live a few minutes ago, when, when we were, um, before this session. Essentially, I will actually share a QR code for you to actually, um, get to a landing page, and you'll have all the assets there. What, what's on the, um, landing page, um, give me a couple of minutes before I do that. Um, there is, uh, early, um, adoption program registration, so if you're interested, um, in actually working with us, we'll do onboarding, we'll do. Um, essentially a guided experience working with you to actually help you establish your factory and launch that factory, um, together. Um, so there is a, there is a, um, a kind of program for that. So if you can register, um, uh, for that program on the landing page, you'll also get, um, access to the, uh, Agentica platform starter kit, uh, which has just been made, uh, public on, on GitHub samples. So there is a link there you can use and start to play with it. And also there is, um, like I've talked about, the playbook, the agentic app prescriptive guidance as well, from a people process technology so that you can establish your factory. Now the point is, we didn't want to do just do a starter kit, drop off, and then run away. We want to make sure that we provide you that hand in hand experience. Hence, um, that uh program registration, if you choose to do so, it's super critical so that we work with you, and we're also working on some investment program as well, so we work together and do a co-funded, co-built kind of factory, um, kind of program. Now this is the QR code. I'll give you a minute. OK phone's out, if you can um get the link. Hopefully Wi Fi is working. Lovely, lovely, thank you. Thank you. Moving on, um, look, you saw, um, uh, Aaron demoed, um, the part of the factory, uh, we have a prioritized roadmap of incrementally building it out, develop the factory itself. In the next two quarters, this is a prioritized roadmap. First one is full operational experience within the factory, where you can not only assess, go through, assess, um, plan, implement, and nitrate, you can actually operate it from the factory as well, deployed gentic apps, operations, alerting, um, everything. So you can do that from within the factory, that's on our roadmap. Second is, once you have that operational aspects, how do you do iteration? How do you do recursive learning? And that will be just follow fast from after the operational kind of aspects. Third one is compliance automation, like I talked about, we are actually building out a bunch of controls from a compliance perspective, uh, starting with ISO 42,0001, but then we'll move to NIST AI RMF, uh, just after that as well. Another feature we're working on is agent Finoffs. That is actually from a direct feedback from a customer when we had this discussion is they're struggling to actually capture how much money is going by agent, by application. So factory will have a bunch of capability where you can, you'll be able to see cost by agent, by agenttic workflow, but also by use case or application. And also what's on Roadmap is integration with our AWS AI marketplace so that you can not only consume agents and agentic products and solutions from our marketplace. If you choose to do so, you can actually monetize your custom agents as well. You'll be able to publish and list agents directly from the factory and host that within the factory as well. So these are the roadmap items for the next couple of quarters. Now, before I wrap up, I would want to leave you with a thought. We are providing you the framework, the, the, uh, platform interface, and the starter kit, and the know-how, and the guided experience if you choose um that um early adoption program. We will providing you all the foundational assets, but the real magic will come from you. As you take that, and build your own factory, you add your own industry insights, your IP, your knowledge base, your processes on top. So that you carve out the factory for yourself. Think of it light bulb as a as your own little spark. Use that to build your own differentiation in the market and solve customer problems. With that, thank you for being here today. Please don't forget to provide feedback in the service. With that, thank you and have a great rest of the reinvent.