---
video_id: X7PhEmmp9rc
video_url: https://www.youtube.com/watch?v=X7PhEmmp9rc
is_generated: False
is_translatable: True
---

Great, great that you're all here so um I hope you're all excited to be here. I hope you're excited to learn about all the new products and services and features and all that here at Reinvent is anyone excited? I thought you could raise your hands. I saw that earlier. Yeah, there you go, that's one. And tell me again, just, no indeed raise those arms. You're gonna be doing this a lot of times this week. But who here is excited to use those new services and features when they get back home or back at the office, of course. But who have you Also has some rework that needs to get done. So who here has a backlog who'd like to use those services but still there's something to do. There you go. Alright, this is Matteo Palazzi and I'm Chris Neylander. Oh, I'm sorry about that. We're professional services consultants for for AWBS professional services. And as consultants we're working on the clock and we need to get things right the first time every time quality security, but it's not only us, it's the team as well so it's partners, it's it's customers, it's you. And today we're going to show you how we do. And how you can accelerate your code delivery by using development containers with uh Amazon AI code assistance. But before we get into that, I just wanna know, so are there any other consultants here as well? No? Engineers? 101, OK, we've got some engineers as well. Have we got my security people as well? Wonderful, wonderful, but actually a more important question, is there anyone here already using development containers? Uh, good, good, good. Well, no worries, we'll go through the basics as well, so everyone's on the same page. Um, one final remark, this is a code talk and I don't know if you've done a code talk before, if you've attended one, but it's like a, a long live demo, so we'll be doing coding and stuff like that and yeah hopefully you'll enjoy but it's also interactive so if you do have a question. We'll try to pause every now and then so you can pop on in. And if we can't answer it, then you can approach us afterwards, that's also fine. Cool. Alright, first thing I want, I really wanna make sure we're all on the same page here, so let me set the stage. So I want you to imagine that it's Monday morning, maybe the Monday after we invent, and indeed you're excited to get to work to try those new services and features. But remember that pull request you had from last week? Yeah, it got rejected. And as you're getting ready to fix it, to mend it, now you have security reaching out over Slack that they found an overly permissive bucket and you need to drop everything and fix it. Alright, now it's Thursday and you're everyone's hero. You mended your PR, you fixed the bucket. But it is Thursday already, and your sprint commitments are in serious jeopardy. Does that sound plausible? I see some nodding heads, that's good. And it should. Because 45% of production deployments actually require rework. It's even higher, but I'll get to that in a little bit. Or rollbacks. And about that open S3 bucket, so we still have the broken access controls on the OF top 10. At number one, Um, mind you, security misconfigurations is that too, so we're doing exceptionally well. But if you think you've got everything tied down, you know, your, your buckets are all locked up. Collectively, we pushed over 23 million secrets onto public GitHub repositories over last year alone. And we're not doing that well with private repositories as well, so yeah. All right, now, where do we want to be? So imagine again that it's that same Monday morning, but this time you're starting on a new project. And you're already delivering your first meaningful commit that very same morning. No extensive rework, no security people knocking on your door, no onboarding issues, no runtime issues. That's where we wanna be, right? Sounds ideal. You want to be one of those elite engineering teams. Alright, but what does that actually mean? So uh I've got some numbers for you and is is anyone here familiar with Dora? I'm, I'm not talking about the little girl with the with the the monkey in the boots, right? I'm also not talking about some European legislative piece, right, for you security people. Now this is a long running research program from Google about operational excellence in software delivery. And so this is a survey. It's been running for 10 years already. And since I have you all here, We can kind of repeat the survey. So I'll ask you about the first category, that's the change lead time. That's how long it takes for a commit to go all the way into production. So I want to ask you to raise your hands again. And tell me, how long does it take your teams? Months? From a commit all the way to production? No? Are you all good? Sometimes, there you go. Alright, a week. Yeah, that's more realistic, right? Right, is there anyone who can just pull this off within a day? Oh well you're elite mate. You should be up there, we should be there. Right, no, but that is indeed how it is like we have the um the elite teams taking under under a day to do this uh then moving towards the low performance taking weeks up to months. I'm sorry mate. But we'll get to improve, that's why you're here, right? Alright, 2nd thing is deployment frequency. This is how often you would actually deploy to production. So, um, are we talking about, uh, once every few months again? I would expect the same hands, and there you go. Once every few weeks. Yeah. Alright, so we got the elite teams here just doing it like on demand. Like whenever you need it, push there to production. And by the way, why is this metric important? Uh, and this is one which is important also with regards to AI. This is talking about how small your commits actually are. Like the smaller the commit, the lower the risk, the less impact on production. And the funny thing is with AI you usually make very large commits, so it's uh. Cool, alright I'll I'll spare you the other uh the other metrics for the survey, but um I'll tell you the field deployment recovery, so this is how long it will actually take you to go from that bad situation onto. Um, a normal operation again and you have the elites typically taking upwards of a day, uh, where the low performers taking. Maybe days to weeks to months just to restore our service and this is of course impacting your um your customer experience. And the last bit, the change fill rate, that's actually the metric I had on the other slide, so it's 45 to 60% of all those production deployments either require rework. Or rollbacks, that's pretty significant, and you have the elite teams typically around 15%. It's all right. That's nice numbers, right? So how do we get there? So this is where de containers help remove the potholes, to actually make you go fast. Uh They enable you to uh create a continuous develop uh no, a consistent development environment with embedded quality controls, with security checks, uh, like having your um static analysis tools, you've got your linters that you can integrate, you've got your code formatters, your scanners, all that can be integrated within your within your dev container. But it it's also the tool to quickly help you adopt other tools like Amazon Que Developer, and that helps accelerate your teams, it accelerates your onboarding. Uh, one final note on this though, and if you read the Dora reports, they'll tell you there is no silver bullet. Which will improve everything, but dev containers will definitely help you unlock those elite practices. So that's how you should view this. All right. And that's what we're gonna talk about today. We're gonna talk about how we can use those de containers to actually make our AWS projects, our deployments all the better, uh, just accelerate those deployments. And on the first bit Matteo is going to explain a little bit about the anatomy of a deaf container. So what are the key components there? How is the configuration built up? Um, In the second bit, he's going to talk about how you can integrate Amazon Q Q Developer inside a dev container configuration and enable these complex workflows which go over the rule-based stuff which is usually in your static analysis tools. The third bit is because we also want to scale, we want to enable some kind of modular system within those development containers and luckily there's development container features which are like these repeatable building blocks so instead of adopting it just for one image you can use it for the other and for the other and for the other, right? Now to scale even further, um, we'll also talk about creating a pipeline for these development containers. So it's no longer just you building it on your local laptop, it's building it inside a pipeline and to make sure these images are available, images and features for anyone who needs them. And before I hand over the floor to Matteo, again, I'd like to remind you, it's an interactive session, so if you do have a question for us, you know, pop one in. Matteo? Thank you Chris. So as you very well said we as consultants need to be right the first time all the times, and this means. That we need to take care about all the little problems, all, all the little bits before creating an artifact for our customers, right? This means that We might want to discover all of the problems before a CICD pipeline starts and find that right, so it means that we want to shift left all the checks into our development environment. So What do we have here today? So here I have Visual Studio code, right? Are you familiar with that? I think so. Um. But how do we do shift left these checks, so we use it's. Pretty easy, right? Use dev containers. So we create dev containers to standardize our development environment across developers in the team across teams, so we all get the same environment, OK. What is a depth container? You can guess it, it's a container, right? So. As a container, we need two main things to use it. One is the container runtime. You can use Docker, you can use Finch, you can use Venture, you can use whatever dock, whatever container runtime you prefer. And the second thing is an IDE that is compatible with dev containers like VS Code, IntelliJ, and many others. So let's get into, into the demo. We have here a CDK application right? you might be familiar with that it doesn't matter, right? It's not the scope of the session today we're not going to say. How CDK works, how to deploy a stack with CDK doesn't matter. Just let's take it as a Python code. We want to create the environment to be effective developing the Python code, right, in this case. To do that, we need to create a dev container, and the dev container needs to be inside the dev container configuration needs to be inside a speci a specific path. It needs to be inside.def container slash deacontainer.reason, right? That's the config file. And a conflict file could be very easy. Or a bit more complex. In this case you see that there is only one line. It's quite easy, right? So this is the image that the container runtime will use to create the container. That the IDE will be connecting to. As you see on the screen, there are also other lines commented out. And let's go through them quickly. So the first one is one example of a life cycle command. With depth containers we can use the life cycle events. It means that we can run commands, scripts based on the life cycle event. Which means, for example, when, when you create the container, after the creation, it's run a, a command. When you attach to, to the container, which is similar to when you open the laptop in the morning and you start developing, so you attach it to the development environment, it might run another set of commands. Then you can also configure your ID setting, um, for example, the tab size and this size in, in, in this example. Or maybe installing some extensions. Lastly, we cannot features. We will talk about features in more details later during the session, but in this case, I, I wanna show you how to, how, how easy it is to create the container. So we have this uh configuration file and then we just. The reopening container. And it will detect that the the dev container JSON file is there. It will read it and it will create a container that the ID will be connecting to. As you see here, I'm running a Mac. I'm running on a Mac and if I run here you name. Minus A, I'm in Linux. This is because I'm running inside the Devia container. OK. But You know this is a plain this is a very basic image we want to have an effective environment to develop. So I've, I've prepared another example. As I said before, the dev container JSON file might be a bit complex. So in this color is in, in this, um, example, it is a bit more complex. Instead of using a single image, I'm, uh, referring to a Docker file, a Docker file inside the dev containing directory. It's important. That Docker file is gonna build an image locally, right? As we are talking about a Python application, we need the Python VM, right? And the Python VM is Based on the host that you are running on. So for example, if I create the running the Python VM on Mac OS, it's going to be different from the one that is, uh, is going to be created on Linux, right? So we want to create the VM all the times that we create the new container because otherwise when you, when you clone the ripple inside the container, it might have a different virtual environment and it could not work. The other thing that the other things that we are adding here are peep audit and peep licenses as part of our security guidelines, and we run those commands when we. Open our laptop so when we connect to the container. I'm also adding some configurations, some configurations for, for the IDE. So for example, I'm defining the Python default formatter uh to black format that is gonna be installed as an extension as an extension. Together with Pin and Flacate, of course you can add all the extensions you want. You can add from others, links, all the security tools you prefer. Um I'm also adding some features. In this case, I'm adding the common utilities features and the Python feature. All of them are going to install other tools as part of the feature itself. And remote user is the user that is inside the container and It's connected To the user on your laptop. OK, so as you see here I'm starting from a, let's say a vanilla. Uh, VS code, there's nothing in it except the dev container extension, of course, otherwise it doesn't work. And If we connect To the container now. It will load this configuration that has. Quite a big amount of settings and you will see popping up on the left hand side some extension icons you see Python now um. And also testing, right? So it's also running the commands that you have seen before, the pre the post attach commands and the the uncreate commands just to be sure that for example the licenses are up to date with the packages that we are using. Inside this project, right? As, as I As I have, um, added the Python, uh, feature. And we are going to see that the virtual environment is loaded automatically. And we should see now um uh yeah, they are, uh, here they are, some problems in this file. So I thought to have written a good file. No, I'm, I hadn't. So, we need to refactor this file, otherwise the CICD pipeline would fail, right? Because in, in the CIC in the, in the CICD pipeline we will have all the checks. So, let's go and refractor this. To refractor this. We need to add Amazon Que, right? To, to add Amazon Que we need to add the extension. So, if you don't remember the extension ID, I don't, OK. So I just search Amazon Que. And then you can simply do add to death container touch chasing. What it does is You will see down here, right? So you can dynamically update the JSON file. Then do we want to use Amazon Q as it is? No, we don't. We want to add some context to Amazon Que in order to perform better. To do that we create. An an MD file that is going to be used as a rule for Amazon for Amazon Q developer and we want to do, we want to make it inside the dev container right so we need to, I'm sorry, we need to. Add it to the. dev continuing directory. And we also need, I don't, I don't wanna write it down. So I'm gonna copy. And where is it here? So we add this command to the post create. It does create. Amazonque rules at the root of the project. It's a mandatory path, OK. And then it copies the MD file into that directory. What do we have in the MD file? So we are setting just general rules. We want to have all the, all the files, all the Python files with the header, with the copyright and the license, right? We want to have all the functions with the dock string. We want to have all the Python files to be compliant with web page, right. It's just an example you can add whatever you want. OK, so now we need to rebuild the container in order to have This is inside the container, so we do rebuild container. It's gonna, let's say, start from scratch. And rebuild the Docker image, um, most probably it's cached, right? And then install all the features, run all the, the post-create commands, including the Amazon Q command. And you see here, um, it's gonna uh rebuild uh the Python environment. It might take a while. Did you save it? Oh damn it. It's a classic. It's not gonna solve all the problems. Some problems are behind, uh, between the chair and the laptop, right? Yeah, right. We just enable auto saving. So, conscious of time, uh, I'm gonna, um, comment this out, uh, because as I said before, it's important to create the VM, right? Or, uh, in this case, as we are starting from the container already, it's not mandatory to rebuild it. So I'm gonna save that one as well. I'm going to rebuild the container. It should take. Last time OK. Thanks, Chris. OK. It's building fantastic. We will see that now it's going to run the um. You see here, the Amazon Que, the copy of Amazon Que rules inside the directory. And if we refresh, we see Amazon Que here, right? Where the best practice is fine. And also, we should see Amazon Que. Fantastic. We have Amazon Que, we need to log in. Let's log in the key thing here is that the, the depth container is kind of independent from the repository. So you tie them two together and then the repository gets whatever context for Amazon Que you define in that depth container. Inside the repo, so you can centrally define a context and manage that context. And that's really powerful. OK, so now we can refactor the Python file. So let's ask Amazon Que to do that. A factor. It's going to take the entire file and as a context we see that we have also the best practices MD file right and as you see here I'm having the new comments at the top of the file, the new header, and it's well formatted. We have all the module dock strings. Ready to go, most probably. The CICD pipeline won't fail. But We have done it here locally inside. This only container, right? It doesn't scale We need to create this building block that could be shared between people. And to do that, we switch to features. So features are the building blocks that can be packaged. And be shareable between developers and teams. Between other different containers at the end, right? So to do that, We need to create a folder inside that container named as the feature, so that that is going to be the feature name. And As this is going to take a while to build, I'm, I'm going to do that. One thing I want to highlight is that as you see here in the in the config file, I've commented out the copy Amazon Que rules that we used before, so we don't need that anymore as we don't need Amazon Que anymore because it's going to be part of the of the future. So I'm gonna rebuild it including the local feature so you can reference local features this way you just provide a path right? and it's gonna be included inside. The de container. So let's switch here in the on the terminal. I'm going to show you what files we need to create the feature. Essentially we need 2 files, at least 2 files. One, it's named Installers.S. And by the way, these two files need to be named this way, OK, it's important and the install a sage is just an installation script that will install the tool you need essentially in this case it's going to create. The Amazon Cre rules. The other important file is the dev container feature Jason, right? This is the configuration file for the feature. It requires a semantic versioning. You can use the same blocks as you used inside the dev container.json file for the dev container itself. So for example, here I'm, I'm installing the extension Amazon Que, as we were doing before, inside the container, inside the dev container, and also I'm moving the Amazon Que rules inside the repository. That's an important thing because otherwise when you create the container you create the the rules, but the repository is not mounted inside the repository yet so when it mounts inside it will override everything, right? When you mount a system over a mount point, if you have something in that mount point will be won't be accessible anymore. Um, so these are the two important things, uh, the two important files. Let's see if it's built. Oh yeah, it's built. Perfect. So, now we see that we have Amazon Que now here as part of the uh repository and. It's the new one I've added the label inside the file. Um, of the feature, right, you see here, this is actually the same file we have in the actual Amazonque rules path. OK, so we have created finally the, the, the feature. But it's still local, so this is the development process to create a feature that is gonna be reusable afterwards, right? To create the reusable feature. We need to package. And create an image for that. So we have created a factory for that. Chris will tell you more about it later. And I want to show you one thing that is the last one, that is. Let's say the outcome. Of that factory, so we have seen the, the deaf container convict file the feature, and if we condense everything together we create one image, right? And that one image is this one so. You can think I mentioned before about building blocks. You can have con dev containers features. You can put different things together and you can create one single image. It's quite easy for a developer to create an environment just creating the configuration file with one line, right? So you can provide developers this thing. Um, as you see here, I'm starting again from, uh, a plain, um, VS code project, but I have this image that is actually the, uh, the union of everything that we have seen today. So if we reopen that in the container. It will check the convict file that has only the image. On the image, right? But it's gonna create everything for us. We will see extensions. We will see post create commands, um, post attached commands. Amazon Que, Amazon Que context, everything just with a one line config. So essentially this is what we usually do when we develop. And Chris, over to you again. Thank you, Matteo. Um, before we do, um, please switch the screen for me, Ken. So yeah, um, we're kind of approaching the, the end of the session already but uh we wanna leave you with something more tangible indeed that container that uh Matteo just pulled in that was built remotely with code pipeline and this is very high level, uh, diagram. So we built a CDK uh pattern for a pipeline which is essentially a warehouse with stateful resources and all these different uh pipeline stacks per per image and per feature. Right, um, the way this works is we just copy a configuration or you copy a configuration onto S3. That will trigger event bridge, kickstart the pipeline for each image or feature that you actually push the X3. And that will deliver it to ECR. And from that point on, you can either then pull it into your project like Matteo did. Or you can use Crane to bring it over to your repository which is available to your employees or your teammates. Or you create this uh this landscape, this modular landscape of a base container with an uh an extended container which uses that and which brings in features that you also have managed by other teams or whatnot. And that's a little bit how that is um it's published on AWS samples. I'll give you the QR code is on the is on the other slide. Is there any questions on this? So this is also a multi-architecture image, so it builds it for Mac and for for PC again using AD 64 and arm with Graviton. So it'll run on all the machines. Cool. Maybe we can also show how to, how to create a, um, I mean a feature with, with the pipeline, right? Oh yeah, well, let's, let's do that, um. Do do we use a recent package? Yeah. OK. So, as Chris, as Chris mentioned, we have created, um, a repository that is public on AWS Samples, and there, there is an example for key or CLI. So we have created a, um, the, the key or CLI feature that can be added to the dev container. Um, let's do it together. So, um, to do that we need to create a new folder here, hero CLI. And then Install. SH right. Here we are gonna put the the code to install Hiro CLI. So what we usually do when we develop features, we understand how to install that package that we want to do. So we go and check Kiiro. We did do here CLI uh oh it's pretty easy, right? So we copy that single line but that single line is, is going to install that. With the root user. We, we want to install that with the remote user inside the container, so, uh I'm not going to write everything from scratch, so we have it already, you have it already, it's public. So we are going to add this code here. OK, that's gonna. Create the other file. They have container. That F But Jason, And in here we need to put the config file, so this one, essentially. OK, it's more readable here. So we define the name, the ID, the semantic versioning, the description, and, um, let's say a constraint. So it's going to be installed after the other feature that if you remember well, um, it's part of the, um, of the dev container uh config file. So we do this and to package everything up, we need to, so here we are inside the depth container folder. We see the KCLI directory. We go into there. And we have just 2 files, so we need to. Zip. This content into a zip file. And then we are going to upload. As 3 API we are going to upload this zip file into the S3 bucket that Chris mentioned before that was part of the architecture as an entry point, right. So this one is going to be pushed to the S3 bucket. This is the version ID. And if we wait a bit, it's going to be built by the pipeline. We have created it already, right? Um, so what we can do is just add. The future. Features. And I'm going to take this repository, it's the same. Without the dictionary. Right? It's pretty difficult doing that. Here, OK. Do do do do. OK. Perfect. Uh, what am I missing? The comment you gotta change the name. Like it's not a base image. Right, yeah, saved. Thank you. Um, OK. I need to change features and Kiro CLI we name it this way. Right, so we save again. And we rebuild. OK, it might take a time, uh, a while. Um But at the end, we are going to have the same environment as before with a curious CLI installed. So we are going to to check that from the terminal if I didn't do any typo. Right. OK, it's running the beep licenses. Because we are building again and we are not just attaching to the container. OK, come on. In the meantime, Maybe you're already able to open up a terminal. Any other questions? Um, Give it a shot. Here is your life. We have it. Right. Loading the VM. Curiously lie. Help, yeah, we have it. So this is. Online on ECR and it can be shared with everyone. Yeah, so, so, so this is really easy, right? Um, it, this does give you a rather large container and you need do need to look at how Kiro actually looks. I did this with Amazon Queveer at first, but it was an unstripped, uh, unstripped binary, so it was massive. So, um, but yeah, this unlocks like really powerful patterns. If you want to have like pre-commit hooks using Qiro as well, or you want to use Qiro to give you some insights on those on your commit, just your commit messages you're doing changes in one certain format, that's how you can use this as well. So that's yeah, thank you. Awesome, and then I promise the the last slides also featuring the QR code for that repo. And uh yeah, I mean, you've got a full week ahead of you, so make good use of it. Enjoy your time here and reinvent.