---
video_id: L6J5TsZcPt4
video_url: https://www.youtube.com/watch?v=L6J5TsZcPt4
is_generated: False
is_translatable: True
---

Hi, good morning everyone, and uh thanks for taking the time to join our session today. Um, I am Scott Warren. Uh, I run the, uh, America's, uh, cloud Center of Excellence for CAP Gemini, um, and I'm joined by Cedric Bordone, um, who is a global technology leader with AWS, and, um, the project we're gonna tell you about this morning, you know, uh, Cedric and I both worked on and, uh, was jointly delivered for our customer by Cap Gemini and AWS. Um, sorry about the little bit of a late start. We had some minor technical difficulties, but everything seems to be working OK now. Um, so a quick run through of what we're gonna cover this morning. Um, uh, our customer that we built this, uh, AIPOC for was called Fortive. Um, so we're gonna spend a few minutes explaining who Fortive is and what they do because I think it's really important to understand their business model, to understand what we were trying to do with this, this POC. Um, we're gonna do a deep dive onto what we call Fort Brain. That is the actual project that we built, um, talk a little bit about some of the business outcomes we wanted to see out of this, um, get into the, the AWS services and architecture that we use to build this product, um, show you some, uh, real life, um, footage of the, the product in action, um, and then kind of walk through what's next for this, uh, this project. Um, so jumping in, who is Fortive? So, um, Fortive is a customer of ours here at Cap Gemini. Um, they're an industrial technology company headquartered in, uh, Everett, Washington. Um, they have 18,000 global employees and, and operate in 50 countries. Um, so really big company with a big global footprint, um, and I think one of the key things here is, uh, Fortive does have an innovation hub they call the Fort, um, and that hub is where the idea that you're gonna see today was kind of incubated and created. Um, for their main like lines and areas of business, Ford of, uh, really focuses on workplace safety, healthcare, environment safety, um, you know, servicing frontline workers, scientists, and patients, uh, in those 50 countries all across the world. Um, so really key to understanding what we built with this brain project, um, is Fortive at, at the end of the day is an operating company. So they've got all these different companies that operate fairly independently underneath Fortive. Um, and you'll hear us reference these operating companies throughout the project as we go through today. Um, and we'll use the term opco to talk about them. Um, but you can see that the opcodes that Fordive runs today are really broken into three main categories. Um, intelligent operating solutions, um, so think of facilities and asset management, you know, in, in office buildings, construction sites, um, detection and safety, anything around operating, you know, real estate, um, Precision technologies is really focused on electronic and test measurements. Um, there's one company here, Fluke, that you may have heard of that is really the focus here, and they work in the healthcare and, and, and all these, all different industries. Um, and then their final pillar of, of Ocos that Ford have runs is, uh, specific to health care solutions, um, so I think, you know, infection prevention, um, so you know, during COVID this is a really big thing where, you know, masks and sanitizer and things like that, um, surgical asset management kind of falling in line with what they do with, with facilities management but specific to surgery centers. Um, and then end to end clinical productivity solutions for, again, healthcare facilities. Um, so, as we go through this, you'll kind of see how all of these companies come together within this AIPOC that we helped Ford to build out. Um, so talking about brain, um, so if we look across all of these different operating companies that Ford of operates, um, they all have different types in, in different data stores, um, so think structured data, you know, Postgras databases, SQL data. Bases Oracle databases, um, things like Snowflake for data warehousing, um, each different opco could have all different kinds of structured data, same when we get to unstructured data. So think of things like SharePoint, Jira, any other kind of document storage, um, and then the third, uh, type of data in, in in scope for this POC was, uh, software engineering data. Um, so every one of the opcos that you saw on that previous slide has their own IT department, you know, they may be using GitHub, they may be using an Elassian product, you know, different code repositories across all of these different, um, OPOs. Um, and so what Fortive wanted to do with the first iteration of Brain was, um, give all of these different operating companies a like seamless integrated platform where they could build chatbots for their end users, um, for their non-technical staff, for their software engineering staff, um, but Fordive really wanted to do this in a way that was completely. Structured, um, secure, governed properly, and standardized across all of the different operating companies. So the key here is we didn't want Opco one going building one chatbot, these guys building on another platform, another platform. They really wanted to bring, um, all of this into a centralized way for all of the operating companies and so that is the idea behind Ford of Brain. Um, there was a previous iteration of the brain product and not on AWS, um, but one of the big blockers there is, is it was static versus dynamic. So if you think of building a chatbot against a structured database, something like SQL Server or Postgrass, um, there's gonna be changes in that database, not just day to day with the actual data, but the structure of the database itself, the table structure, the schema, things like that. So in the older versions of the brain product, um, any time a change was made to the structure of that database or the data source, um, we'd have to go and remap the whole schema, train all the new data, um, every time a change was made. So really building this new next generation brain on AWS was completely focused on how do we turn that dynamic. So if a change is made in that Oco database, um, the tool and the AWS platform takes care of that on its own. Um, and the actual Oco, you know, building and operating the chatbot doesn't have to worry about that. Um, really wanted to, um, again standardize this. So each of these different opcos has different, um, IT departments, different levels of, of expertise, different skill sets, um, so making this very user friendly. Um, you know, as much auto generated code as possible was really key to this project, um, and we really wanted to make this a, you know, as close to a server-less architecture as possible, um, so, you know, scalable, on-demand, cost effective on how we built this on AWS. Um, so some of the challenges we faced as we started, uh, digging into this project and how we would architect it on the AWS platform, um, you know, there wasn't really a set standard on how to implement this type of thing across all of the different opcos and Fordive. Um, they worked in silos, so we really had to build something again that was easy to use, and these, these different operators could come in and build it on their own. Um, there was no common EUI for building any of this. Um, so that was a, a key to the project is to build out a EUI where you could add new data sources, um, on the fly very quickly. Um, and then, uh, like I mentioned earlier, and one of the keys of this project is make it dynamic versus static. Um, so some of the project requirements we dug into, um, kind of like I mentioned, so a centralized platform, governance, security baked in, so the different opcodes didn't have to worry about it. Um, we needed specific training for each of the OPCO's data repositories, and we had to segregate that data as well. So, you know, company one's data couldn't be accessed by company two, so on and so forth. Um, we needed real-time or close to real-time data access, um, and, you know, everything as a service or as a standardized API economy. So I think this diagram does a good job of kind of showing conceptually what the brain product is and how it works. Um, so on the left-hand side are actually where the chatbots and the different operating companies would sit. Um, so you can kind of see the different applications and where those could live. So you know, things like Teams and, and Outlook, um, and then more importantly and what we focused on for the first version in the POC for this was, um, streaming through, through Streamlet or JavaScript primarily into web applications, um, but there is, you know, plans to expand this and, and have a lot more different consumers where chatbots can sit, um, on the right hand side is all of the different types of data that we eventually went to build into this product and platform. Um, and so you can see these data structures sit within the OPCO's ITs environments and it can be lots of different things from unstructured, you know, Jira, S3 buckets, SharePoint, Confluence, um, to the structured data where we're looking at, you know, Amazon RDS, Oracle databases, MySQL, Snowflake. Um, and then the software engineering data, um, you know, GitLab, Bitbucket, um, other Atlassian products, um, so the key here is we have to build this platform in a way where it can ingest any of these data sources, um, within the Oco's IT environment, um, so we've really picked three to start for the first version in the POC that you'll, you'll see when we dig into the architecture, um, so for unstructured data we chose SharePoint, um, for structured data we did, uh, Amazon RDS, and for, uh. Uh, the software engineering data we did get lab for the source control. Um, and then in the middle, you can see what the, where the actual AWS environment sits for this. Um, and so this is, you know, the, the fortive brain that we built out where the OPco user can input their data source, um, that ingests the data into our bedrock, trains against the data, um, and then allows the, the end user application to access that via streaming. So as we began to build and architect this, there was some, uh, some business outcomes we really wanted to focus on for For of. Um, the 1st, 1st dimension during the POC itself was the web interface with chat functionality. Um, so we wanted to end users within the, uh, the operating company to be able to interact with this data, um, via chatbot using natural language. Um, we really had to make this scalable and performant so there couldn't be lag time between accessing the data. It couldn't take hours to ingest the data into, to the AWS environment, um, and really I think like a lot of folks here, we had to prove that this all worked, um, to get investment and funding and buy-in from executive leadership to continue on with the rest of this project. So it was really important to show quick wins, um, how we can do this in a very rapid and scalable manner, give them that, that dynamic data access that they wanted. Um, to be able to, you know, prove out to leadership that we could, uh, move forward with this project. Um, some of the guiding principles we used on this project as we, uh, you dug into development, um, first and foremost, everything needed to be infrastructure as code. Um, so the primary method we used for that was the, uh, the AWS CDK and Terraform for the infrastructure. Um, so we wanted no access to the AWS consoles, everything done programmatically through code through the deployment pipelines. Um, GitHub was our data source, uh, our, our code repository. Um, for all of the project that we built out, um, data processing was done using the AWS Glue service. Um, all of the, the knowledge base creation for ingesting the data in and running the learning was, uh, Amazon Bedrock knowledge base. Um, we did agentic implementation using Bedrock that you'll see a little bit more, uh, in a few minutes. Um, there was some existing front end for setting up new data sources and building new chatbots. We've pretty greatly enhanced that. Um, and we knew we needed basic, uh, telemetry and UX metrics using some of the existing 4 different systems that existed out there already. All right. So with that, I'm going to hand it over to Cedric, who's gonna, um, dive into how we actually built this on AWS and which services we use. Thank you, Scott. Hi, everybody. So, before I dive into the architecture, um, I just want to give 2 or 3 words on what we set out for this 8 weeks POC. So our first objective was really to prove to Fortive that we can interact with 3 different data sources types, so structured, unstructured, and And repositories. We had multiple requirements. So the first requirement is that we wanted a familiar web UI so that the 40 users can adapt the solution, adopt the solution quickly. The second. The second requirement was that we needed it to respond quickly. When you are interacting with humans, you need answers in seconds, not in minutes. We wanted to keep it very conversational and not asking and coming back a few minutes later. As you can see in the architecture in the center, you don't see Amazon Bedrock Agent Co. So this is not an architectural decision. This is a delivery decision. So Agent Co went to GA at the very middle of the development cycle of that POC. So we decided to stick to what we were building. And to move to age and core in the future state. So with AI moving so fast and innovating at that pace, we all should be ready to iterate. We cannot change every time. So build something, finish it, prove, and iterate in the next in the next version. So that being said, At the left hand side of the of the architecture we have the customer, the customer view. So the customer view connects to web UI. The web application runs into a container that is hosted on Fargate. So we did the decision of going Fargate to have the advantage of containers, the flexibility, without having to deal with the underlying complexibility of managing all the container infrastructures. It is published to the end user using Cloud Front and And the web application firewall for the security and the delivery content from a back end perspective, we decided to use API gateway and lambda so to orchestrate the different requests and to add a bit of context to those requests. Lambda passed the request to a first agent, that is the SQL query agent, and that agent is responsible for the. The prompt pre-processing, so this agent makes sense of the request. It adds some meaning to it and he is able to understand to which data source he needs to tap in to give an answer to the customer. So once he decided to which agent, to which data source he needs to tap, he passed the request to a second agent that is in the action group agent, and those agents connect to the different data sources. As you can see, we have data sources as GitHub and Postgrad SQL connected via an MCP server, and we have a SharePoint connected directly to Bedrock using a Bedrock knowledge base. So The whole session is about static to dynamics. So what makes that solution dynamic is really the MCP. So MCP stands for Model context protocol, and this is a standard for connecting AI models to tools. So it's not only about connecting to a data source and querying the data source. It's, it's also about interacting with that data source. So if you are a sales manager and if you want to know the results of yesterday, you don't want to, you don't want to wait next week for a knowledge base to be updated, indexed, indexed, and everything. So with MCP you are targeting the live database and you can retrieve the live, the the the the live data directly. So again, MCP is not only about querying, but it's also it gives a whole set of tools so you can interact with the external with the external systems. So you can, for instance, start a workflow in an external in an external tool. You can commit in Git. You can. Add a new row in SQL, so it's not only about querying, it's also about interacting with the data source. For SharePoint, we decided to go with Amazon Bedrock Knowledge base because here we have lots of documents and there is no need for it to be real time. So you want to have. A quick answer and to pass and to go through unstructured data and documents, we are using Amazon bedrock knowledge base together with open search vector database so that we can so that we can retrieve the data quickly and keep it short for the answer. Um, and not only, um, So for SharePoint, there is a knowledge-based connector, native connector, but due to the time constraint of this POC, we decided to go with the web crawler connector, which makes the trick for the POC. But in the next iteration we're going to go with the Amazon SharePoint native connector. Why did we do that choice? Just because of a time frame constraint. We had no time to go through all security requirements and checks from the customer. So what does it look like? So as Scott mentioned, Fortiv has many companies. Every Opco has its own IT. Every IT has its own maturity on how to handle AWS, AWS infrastructure, AI solutions. So we made it very simple for them to add a new data source and then to interact with a new chatbot. So as you can see, there is a vet. Workflow toward any new data sources connecting to a new. Let's say you are the sales manager I mentioned before and you want to know the sales, um, the sales report from yesterday. So you just ask a simple question to the chatbot. The chatbot answers to you with the data. It, it makes an analysis of the data. It gives you a quick analysis, and then it also gives you the SQL query that it uses through the database to get the data back. This is important because it helps you also refine your prompt. So if you have if you want more precise data using that, you can refine your prompt and you can ask a better question to the chatbot so that you are closer to the answer you're expecting. Um, for GitHub. You are a software engineer and you want to know how your code repository looks, so you can ask to list a code repository and to give you some recommendation, and the chatbot will answer you with a branch, the structure of the branch, and if it looks good, if you might change something, if you need to change something, if you need to add something or to remove something. Shape on chatbots here it's all around the company. If you're HR customer support, you want to know if you have a question on a product, manual, a user manual product, you can just ask the question to the chatbot, and it will not only give you the link to the document, but it will also give you the real answer that you are looking for with the source it tapped in. Uh, that being said, I hand over back to Scott. Thank you. Yeah, thank you, Cedric. Um, so as you saw there we were able to build out this POC like Cedric mentioned in about 8 weeks, um, where we had the 3 different data source types, um, the OPOs could go in and add those data sources through the UI that you saw, um, so I think it's a pretty powerful thing to be able to stand up this type of system supporting lots of different companies in an 8 week time frame, um, so I think we hit all the targets and achieve the goals we wanted there. Um, but if we look at kind of what the next steps are for this application and how we wish to expand it, um, first and foremost, that diagram I showed you a little bit earlier with all of the different data source types, remember there was Oracle on there and, and Jira and Confluence and many other things, um, so that's kind of the next step is adding more and more data source types that are standardized and used by the different operating companies that you saw. Um, and the MPC servers that Cedric talked about are going to be key for that in, in keeping this a dynamic versus static type application. Um, uh, the next thing we're gonna add is, is, uh, you know, really utilizing some of the newer AWS services. Um, that's one of the tricky things about doing, you know, applications and, and pilots like these is, um, you saw that during the, the development of the, the 8 weeks itself there was a new AWS service, Agent Corps that was released, um, that would have made this, you know, a little bit easier and a little bit faster, um, but at some point we had to kind of stick to our architecture. Um, and you know, finish it, show the value, um, but really implementing things like Agent Core in the future are gonna be key to, you know, expanding this application, making it more, more functional, um, and providing more value to Forive down the road, um, and then lastly, um, if anyone's familiar with AWS Quiro, um, this was actually announced back in, uh, July, um, during the, the development of this and went just generally available from AWS, I think a couple weeks ago now. Um, and that's one thing we're, we're testing and planning for on the next version of, of this product is how do we integrate Quiro into, um, build this even faster and make it even easier to use, um, so some things we've started testing and they're doing right now. Um, is using Quiro in the end to end development life cycle, um, so the first thing we can do is, um, create a sample DB, um, to help test this. So you know, a very simple human language query was sent to Quiro in this case to create us a sample database with, you know, users, products, and orders, um, so with that very simple knowledge query you can see that it, it, it creates the sequel, um, to actually build out this database in a matter of seconds, so. Now we don't have to go and manually populate a database for testing or, or, or use, and we can actually build this out real time with Kira. Um, next, we can create the MC MCP servers to actually query against that data and load that data into Bedrock. Um, so you can see the very simple query here too is, is create an MCP server and tools for connecting to the database that we just created. Um, and so about 2 minutes, Quiro generated the code. Executed it and spun up the MCP servers where, um, I think during our development effort this was a, you know, several week process to do this, um, and something like Kiro can take that down to a matter of minutes so this is again in a way we can show value to our business stakeholders um and bring value into the next phase of this product where we can significantly reduce the development time using a tool like this. Um, next thing we can use Quiro to do is actually, uh, you know, test, um, that the whole Fort Brain product is working as specified using MCP, um, and so in this we just ask it, you know, how many products do I have in my database, um, and this is gonna go out and create all of the code, um, needed to, you know, send the natural language query to the, to Bedrock using the MCP servers, um, to show back that in this case the, the test database that was created. Um, with 7 products, um, so think of this as something we can significantly use to reduce, uh, testing time, um, so rather than having somebody from the QA team come in and, you know, build manual test scripts or, or build automated test scripts, um, we can use Quiro in this example to, um, create all of the test code and then build that into our, our, um, deployment and testing pipelines. Um, and then finally, um, we can actually, you know, expand upon that testing even further, um, where in this case we can actually give Kiro a business question, um, so in this time we asked, uh, who are my best customers, um, and it's actually gonna build a, you know, fairly complex SQL courier in the, in this scenario, um, where we can, you know, look at multiple fields within that database that was created and, and see that Alice in this case spent the most money with us. Um, so we really wanted to highlight this as, um, you know, a very new and cool, um, innovation from AWS that just very, very recently became available to, to everybody, um, but you know, as you're building these types of applications that are, you know, pretty complex on AWS, have lots of different services and, and architectures in play, um, you know this is really gonna be kind of a, a cornerstone of the future of this product and, and, and how we go and build it out in the future. Um, and it can hopefully provide us some, um, real value and and speed to market as we, we continue to progress with the product. Um, with that, that kind of covers, you know, Fortive and Fort Bra. So, um, we've left some time for questions at the end. So, um, just go ahead and raise your hand if anyone has a question.