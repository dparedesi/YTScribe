---
video_id: XnwrWIzSW8I
video_url: https://www.youtube.com/watch?v=XnwrWIzSW8I
is_generated: False
is_translatable: True
summary: |
  Rick Anthony, Anthony, and Nerei outlined how Amazon Inspector tackles modern vulnerability management across compute and code, and showcased new shift-left and prioritization features that reduce noise. They contrasted traditional scanners—periodic, licensed per host, blind to elastic fleets—with Inspector’s fully managed model: enable it once at the account or organization level (with auto-enablement for new accounts), and it continuously discovers EC2, ECR images, Lambda functions, and now managed code repositories on GitHub/GitLab. It rescans automatically on changes: new resources, package installs, patches, or newly published CVEs, closing findings when instances terminate. A delegated administrator account gets a centralized view, while member accounts still see their own findings.
  Prioritization relies on the Amazon Inspector score, which blends severity with exploitability and exposure. Inspector ingests intelligence from partners like Recorded Future to flag CVEs with known exploits, CISA listings, or malware kits, correlates that with resource context (internet exposure, reachability), and surfaces the most urgent fixes. A built-in vulnerability database lets teams search CVEs, see affected resource types, and map to MITRE ATT&CK. Findings flow into Security Hub or ticketing systems so remediation can happen where teams already work.
  New capabilities expand coverage. Inspector can generate SBOMs in CycloneDX or SPDX for monitored resources, run CIS benchmark scans on EC2 (scheduled or ad hoc), and integrates with CI/CD (e.g., Jenkins) so images are scanned before push. Coverage dashboards show which VMs, Lambdas, and container images are protected, reasons for gaps, and allow toggling features per account (e.g., enabling Lambda or code scanning). Container settings let customers control re-scan eligibility based on last pull/use dates to avoid wasted effort on stale images. A container image–to–workload view links findings to running ECS/EKS tasks to accelerate response.
  The team also introduced Inspector Code Security to shine light below the “production iceberg.” Integrated directly with GitHub/GitLab, it performs software composition analysis on third-party dependencies, static analysis on first-party code, and IaC checks (Terraform, CDK) for issues like hardcoded secrets or overly permissive buckets. Security teams define guardrails centrally, while developers see findings inline as PR comments and in their native repos, enabling fixes early and avoiding costly production scrambles. A demo showed commits with remote code execution patterns and secrets flagged automatically on PR creation. Nerei noted persistent risks like Log4Shell—30% of downloads still fetch vulnerable versions—illustrating why catching issues in source is critical.
  Inspector’s goal is to make “secure the easy thing” across the lifecycle: automated continuous scanning in production, contextual scoring to cut noise, SBOM and compliance support, and shift-left code/IaC scanning that meets developers where they work. The presenters closed by pointing to Security Hub’s correlated risk view (combining GuardDuty, Inspector, Config, Macie signals) and invited attendees to deeper breakouts and builder sessions.
keywords: Amazon Inspector, vulnerability management, SBOM, code security, contextual prioritization
---

Good morning everyone Welcome. This is SEC 316. I am Rick Anthony. I'm a senior manager for the Amazon inspection team. I'm here with Anthony and Nerai. They'll be speaking to you later, and we're gonna talk to you about Amazon inspector and strategies for vulnerability management. Um So quick agenda for this morning we're gonna talk about some of the challenges of traditional vulnerability management. We're gonna talk about what is Amazon Inspector, how does it work, what are some of the key capabilities, show you a couple of demos and talk to you about one of our newer features, code security. So first, challenges with traditional vulnerability management. A lot of traditional solutions haven't been built for the cloud, and one of the superpowers of the cloud is that it's elastic. Resources can be scaled up. They can be scaled down to meet your needs, and there's a lot of different types of compute that you can use as a customer. You can use virtual machines. You can use containers. You can use serverless, and you want to be able to cover all of those with your solution. And so some of the environments that your developers are gonna create can be really complex. And that really also leads into some resource constraints. How do you know what resources are out there and running if they're going to be that dynamic? Some of the traditional solutions also ask you to license each of your resources. Well, how do you do that when all of your resources are going up and down together? How are you also ensuring that you're seeing all of them if you're only scanning periodically? Once you do scan, you end up with a lot of findings, and if you scan on Monday, you generate 1000 findings. You scan again on Tuesday, you have another 1000. How do you deal with all those? How do you prioritize the findings that you're getting? You could use some simple methods. You could look at the severity, start with the criticals, but more and more there are a lot of critical vulnerabilities out there and that they may not be the most important ones for you to remediate based off of your environment. So this is where Amazon Inspector comes in. We launched Amazon Inspector a couple of years ago. And we created Amazon Inspector to be an automated vulnerability management service that continually monitors your workloads for software vulnerabilities and unintended network exposures, and you can see that we've highlighted two really key features of Inspector right here. One is automated, and what this means is that once you enable Inspector and configure it. It does all the work for you. You don't have to manage it. You don't have to tell it what to do. Number 2, it continually scans your resources. So in that dynamic cloud environment as resources come up, inspector sees. Them it scans them and as resources goes down, Amazon sees that and it will automatically close findings for you. You don't have to manage the service for you. It does it. Our goal is for you to worry about remediation and taking action, and that's it. So when we launched Amazon Inspector, we launched it with support for virtual machines through Amazon EC2. Container images through Amazon ECR and then we added support for serverless functions through AWS Lambda and then most recently this year we also support manage code repositories through our interactions and interfaces to GitHub and GitLab. So really a quick overview of Amazon Inspector. When we talk about Amazon Inspector and how you use it, we really talk about 4 different phases. Phase one is enablement, and this is as a customer you going in and turning Amazon Inspector on either for your account or for your entire organization. You can do both. Second, once you do that, Amazon inspector will start looking at your environment. It will discover all your resources and scan those resources to get an initial set of findings so that you know where you are from in terms of your exposures, and then it'll start monitoring so as changes take place, Amazon inspector follows suit. Third phase is looking at your findings. Inspector will contextualize your findings so that you can prioritize what's important. Severity is not the only critical thing. Some of your resources are exposed to the Internet. Some of them are not. Some of them have vulnerabilities that can be exploited. Some of them don't. Inspector takes a lot of different pieces of information together to give you a prioritization score that you can use to take action. And taking action is our 4th phase where once you have your findings, where do you wanna do your work? You can do your work in an inspector, you can do it in security hub, we give you lots of different options. We're gonna dig into each one of these quickly. So number one, like I said, when you turn on Amazon Inspector, you can enable it for your account or you can enable it for your entire organization. We see most of our customers turning on inspector for their entire organization. What they do is they use their management account to assign a delegated administrator. And from that delegated administrator account they can tell Amazon inspector what to scan and based on what settings and we also provide you a way of automatically enabling inspector for all new accounts added to your organization and the power of that is once you get it set up, if you say turn it on for all new accounts, you no longer have to worry about having gaps in coverage. Inspector will enable itself automatically. Secondly, that delegated administrator account not only does it configure your entire organization, it also has visibility into your entire organization. So as a user within the delegated administrator account, you have a centralized view of all your findings regardless of. Account as a customer you can manage all your findings for your organization from that one view while your individual accounts still have visibility into their own findings so if you cut a ticket to one of your teams saying hey you have this vulnerability. They can go and inspector they'll see the exact same details that the delegated administrator sees. Um, we launched with this capability, uh, when inspector launched a couple of years ago, and we also upgraded that capability to do an organization. In configuration enablement through support for organization policies that just launched this year. Phase 2 is the discover scan and monitor phase, and this is where Amazon inspector. When you turn it on, it sees all of your resources. So if you ever wanna know what are your accounts running, what are the resources, what do they look like, Amazon inspector knows it sees these resources as they launch. It sees these resources as they terminate, and it updates accordingly. Like I said before, we support EC2 instances, container images and ECR, lambda functions, and now manage code repositories. Inspector works in near real time so that as changes occur you get those findings right away. Amazon inspector is also intelligent. We talked about one of the challenges of traditional vulnerability management where you as a customer have to decide when you're going to scan. You don't know if you're catching everything. He inspector monitors your your environment and scans when it needs to scan. If a new resource is launched, Amazon inspector scans it. If you install a new software package on a resource, Amazon inspector scans it. If you patch, Amazon inspector sees that patch, re-scans, and if the findings for vulnerability are now remediated, it will close those findings if there's a new CVE published. Amazon inspector knows which of your resources have that package and will automatically re-scan so that at any point in time you can go to Amazon inspector and know what is your security posture at that moment in time. You don't have to do any work to get there. And then phase 3 is contextualization of those findings. Amazon inspector supports what we call the Amazon inspector score, and this tries to answer a whole bunch of questions that you have. One question may be, what is the most severe vulnerability that I need to remediate? Is it for a resource that's. Exposed, does that vulnerability have an exploit? Is that exploit common in the wild? Amazon uses all that information in order to score up or score down your vulnerabilities so that when you look at Amazon inspector score, you're truly looking at the most important things for you to fix within your environment. We do this using a bunch of advanced vulnerability intelligence information that uh we partner with Recorded Future to gather so as a security professional you can go in and see. OK, this vulnerability, how is it mapped to miter attack TTPs? Is it, is there a known CISA exploit? Is there a malware kit for it? Is this commonly exploited in the wild so that you can double check or work and make your own decisions as well as to what you wanna remediate first? We package all of our vulnerability information into a format where you can search it for yourself. You can look at CVEs. You can know, OK, does inspector know about the CVE? What are the details? Is it a high? Is it a low? I can check to see, uh, what type of resources it impacts, and I can also immediately know which of my resources are impacted by this. A couple of years ago we did a talk very similar to this talk where we had a customer join us from Volks Volkswagen Financial Services. They are a user of an inspector and the speaker Crispin talked about having a call from his boss on a Monday morning as he was commuting to work. His boss said, Hey, I just read about this brand new Windows vulnerability. It looks pretty severe. Are we impacted? And so Crispin said that sitting at his desk, he was able to go into inspector, type the number of the CVE, see that inspector supported it, and because inspector had already scanned all of his resources because this is done dynamically in near real time. He was able to identify every account and every resource that had an impact and was able to email a note out to all those owners to do a remediation within 14 minutes because all the information was fresh and it was at his fingertips. That's the power of near real time and always knowing what your posture is. One of the new pieces of information that inspector reports on which we're really proud of and we're excited to talk about is near real time malicious package detection. So through a partnership with the Open SSF we now pull in malicious package information. And we use that in order to determine do you have packages that are malicious? Are these going to cause some unknown or unwanted behavior within your account? Not only are we using the information from Open SSF, we are contributing as well. In fact, right now we are one of the largest contributors. Earlier this year we started scanning NPM registries. And through a set of our own specialized detection rules that are a combination of static dynamic AI rules we are able in near real time to detect malicious packages. We post this to OpenSSF. They assign a malware ID. We put this into inspector immediately and we begin. Reporting on this within your own environments, we published a blog, um, a couple of weeks ago where using these techniques we found one of the largest campaigns to to do tokenization, uh, farming, uh, what we think ever occurred, so we detected over 150,000 malicious packages in NPM registries. It's a great blog article. I, I encourage you to go out and read it. Um, we're really excited about this program and this is something that we're going to expand into other forms of registries. So really let me spend a couple of minutes to give you a quick demo of how this would work. All right, so one of our security researchers put together a Docker file where he installed a known malicious package. It's that one called Anne hackle test, and as a note, please don't repeat this. This is actually a real malicious package. He built the Docker file. He pushed it into the ECR registry. ECR is one of the formats that inspector supports. Here you can see within this account we have Amazon Inspector running. We have scanning for ECR enabled. This is the repository where the file was pushed and here you can see we've detected that malware package automatically in near real time. Obviously we've accelerated this for today's demo, but along with the information for this malware finding, you can see we've detected other CVEs as well, and as a customer there's a lot of different information we provide you, so you can either feed it into other systems or just go in and look at it yourself. Here you can see this has an inspector score of 9.8. It's sourced from OSSF. This is something we detected. The version of the package and where this package lives and if you want to look up more information, we give you a reference so you can go back and see that this was truly a malicious package. Published by OSFF and here this is credited to Amazon inspector as the finding. OK. And then finally, our 4th phase of using Amazon inspector is taking action with findings. So, within Amazon inspector, using that delegated administrator account, you see the findings for your entire organization. You can operate directly within Amazon Inspector. You could send your findings into Security Hub as another one of our tools to help you focus on your remediation efforts, but you have other options as well. We send our findings out to EventBridge so you can. Hook those up into other systems using lambda functions. Uh, you can have partner applications that pull into this data, or you can look at it in some of our other services as well. As an example, Amazon ECR also will show findings for your container images. And then finally, as a last way of looking at your data and taking action is software bill of materials. So Amazon inspector at any point in time you can say to inspector, please export S-bomb for my environment, and you can choose your account, your organization. You can filter the data any way you want. We support S-bomb in Cyclone DX format. We support it in SPDX format. And once you have that data, there's all different ways you can slice and dice it. You could send it into Amazon Athena to do different types of queries, or you could send it into Quick site. Lots of different ways. That S-bomb data is free of charge, and you can do whatever you want with it. All right, I'm gonna hand off to Anthony and he's gonna talk about some of the other capabilities of Amazon Inspector. Thank you. Thank you Rick. Um, can everyone hear me OK? Great. Um, my name is Anthony. I'm a product manager and inspector. Um, I work closely with Rick and Arai. Um, my purpose of this section is to give you an overview of actually how do you as a customer go about using Inspector as a product to meet those effective vulnerability management use cases that Rick talked about and hopefully as an objective of this section of the presentation you have a deeper understanding of actually how to use Inspector to go start this journey of setting up Inspector and working through these problems. Um, a quick pull of hands, how many of you are already using Amazon Inspector? OK, great, so quite a few people there to learn about how to set this up and use this product. So before I get going, I just wanted to touch on sort of where we are in the overall like life cycle of developing and launching products and managing software vulnerabilities, and the section that I'm gonna focus on here is really monitor and respond as well as some components of build and test. So the core capabilities of of inspector is really monitoring and providing you that visibility, near time vis visibility on those resources and those findings so that you have an accurate understanding of your security posture. Um, but as a customer, what you really want to do is start shifting left, but I'm gonna focus here a little bit more on what we do today to help you in this monitor and respond area. This slide is gonna be sort of our map which is just gonna kind of help guide all the capabilities I'm gonna talk to you about and it's gonna help just orient you as we go section by section on each of these. So as a mental model there's really two different sort of groups of capabilities as I as I like to think of them for inspector. There's continuous monitoring which is providing that real-time. Ability into those resources and that covers EC2 lambda and ECR images and then we have some additional utility capabilities I call them ad hoc which include bandaging S-bomb some of that is what Rick talked about, um, CIS benchmark scanning and then we also have some other tools that help you shift left in build and deploy. Before I get started with that, I wanted to just take a second to talk and underline the importance of continuous scanning. So the purpose of continuous scanning is that essentially as the days go by and you're doing your, your day job, the goalposts are always moving in security. So I have this very simple illustration of just why that's important in terms of why scanning today, tomorrow, and two days from now, um, helps you understand as a customer when you need to take action or not. So we can imagine a scenario where on the 1st of January, um, you have 10 packages that inspectors detecting, inspectors not finding any packages associated with the CVE and therefore it's not cutting any findings. We can imagine 10 days later, on January 10th, there is a new CVE published for a package, but that package is not in something like let's say your ECR container image. But on the 15th of January there's a new CVE published and we actually do observe as we scan that that package is associated with a vulnerability and at that moment we're going to cut a finding to you and you're going to have a finding which you can choose to react to or not react to depending on your risk appetite. So this, this is really important just to illustrate the fact that it's an, it's an ongoing job that you have to understand your security posture and the information that inspector provides you is informing what you as a customer need to do to take action to secure your environment. And I'm gonna go ahead and jump to ECT scanning. So I'll go EC2 scanning, lambda, ECR image scanning, and then I'll touch ad hoc functionality. So there's a few key points to understand about Amazon EC2 scanning. Um, an EC2 instance is obviously a virtual machine. Um, and one of the key decisions that you have to make as a customer and hopefully you'll be making this decision as that inspector delegated administrator across your entire organization is what kind of scanning mode do you want to implement across your environment. So there's two different modes that you have a custom you as a customer have the choice to choose. You have an agent-based approach which uses the AWS Systems Manager agent, the SSM agent. We like to use the term to describe it as ubiquitous and it's meant to be as easy as possible to install across your fleet. When the SSM agent is installed and operating correctly on an EC2 instance and you enable EC-2 scanning, inspector will use the SSM agent and a small piece of technology that we have to go actually execute those scans, do the work, and then cut the findings to you via the inspector service. Um, there's some capabilities within Systems Manager that you can also leverage to have a full view across your entire AWS organization for every single EC2 instance that's gonna tell you whether every single EC2 instance is being managed by the SSM agent, if not, why not? And there's also some tools that help you diagnose and remediate common operational issues with that. Now we have a 2nd scanning mode which we call hybrid, which came after our agent-based approach, and this is actually what we most recommend to customers and is the default experience for new customers. In the hybrid experience, we are gonna be scanning using the SSM agent in the agent-based approach. If the SSM agent is there and if the SSM agent is not there, we will use an agent-less scanning approach. The benefit of this approach is that you can effectively ensure that you have close to 100% coverage across all your EC2 instances. Mainly there could be operational challenges with managing an agent or getting that agent there as well, um. In our agent list technology approach we use EBS snapshots and an important note here is we'll never take that data outside of your account, which could be a compliance concern for certain customers. Um, so again, if you're gonna take one thing out of this talk in terms of turning on ECT scanning for inspector, use hybrid. It's really simple to set up. I'm gonna show you that in the demo and you should get full coverage across all your EC2 instances. It We're back. I just wanna touch on a couple other points about ECT scanning for Inspector. The first is that Amazon Inspector has network reachability analysis, so it uses automated reasoning to actually determine whether or not a VM or an EC2 instance is reachable via the Internet. This is an important indicator because that's going to help you prioritize those findings that are generated in inspector. We use the network reachability score based on our analysis to actually inform the Amazon inspector score, which is our proprietary scoring that takes the base score from the vendors and our vulnerability intelligence information, and then it overlays information like network reachability to provide you a better indicator of the actual security risk for that specific finding on that specific EC2 instance. The next capability is Linux deep inspection. So as a customer within an account whereas operating as the delegated administrator, you have the ability to specify custom paths that SSM or inspector will go ahead and analyze and look for. Software vulnerabilities as well as application programming package vulnerabilities for those specific paths. So if there's a specific structure that you have in place for your developers or the people managing your infrastructure, you can tell them or you can configure inspector to go scan those paths specifically. An inspector will do its job and it will actually provide a higher volume of findings for those paths. So I return to my map, um, we'll move on to the next capability which is lambda scanning. Here I present a table and I'll just talk through more or less how lambda scanning works. So lambda scanning has essentially two modes. The first is lambda standard scanning, which is scanning for package vulnerabilities, and the second is code scanning, which is scanning for application code vulnerabilities. As a customer, you'll have the ability to either turn on standard scanning for an account or standard and code scanning for a specific account. So you can't have code scanning. Without standard scanning. And standard scanning is gonna work similarly to VM scanning where we're looking at those packages and we are cutting findings for those CVEs. Code scanning is actually gonna analyze that code and it's gonna look for things like injection flaws, data disclosure, or weak cryptography. As Rick mentioned, with our continuous scanning approach, we're gonna be scanning when new resources or in this case functions are detected, new versions are published of the lambdas. Or when we have new information in our database that tells us that we should reevaluate those lambda functions. From a remediation perspective for standard scanning package vulnerabilities we're gonna go ahead and tell you what package you should upgrade to that's pretty standard. But for code scanning, we're actually gonna highlight to you what the vulnerable lines of code are, specifically in red, and then we're gonna give you basically an AI generated snippet of how you can adjust that code to make that more secure. The 3rd main resource type that inspector scans for are elastic container registry images. So inspectors actually scanning images and not running containers, and I'll talk a little bit about how we can help you sort of bridge the gap between how you're actually leveraging containers versus what inspectors providing you. And I'll get into some of the details about how this works. So as a customer, ECR actually out of the box, you can turn on inspector basic scanning. And that's gonna scan OS vulnerabilities operating system vulnerabilities only and it will also scan those images when they're pushed into the repository. So that's an on push action only. So this effectively does not have continuous real-time monitoring and we provide some light vulnerability intelligence about those OS vulnerabilities when we do cut those findings which are then visible in Inspector. Now enhanced ECR image scanning is our basically our inspector level capability of continuous ECR image scanning. That's gonna scan OS vulnerabilities and programming language packages. As a customer we are gonna scan you can configure to scan on push, but you also have the ability to control whether you wanna which images you wanna monitor based on their pull or their last in use date. So the reason why this is important to know in terms of just how you're setting up and using Inspector is that you're not gonna wanna necessarily scan every single image in the repository. That may be an operational challenge for you to manage that, but you can use these settings to control which images are actually getting scanned based on those dates and those metrics. These are the knobs that you have to control the volumes of those findings. And then in terms of enhanced standing we're also just providing the full suite of vulnerability intelligence like we do for all the other continuous monitoring capabilities. And I want to touch on a few other components of ECR image scanning. The first is that earlier this year we launched a feature that enables you to map the image to running containers, so we're actually looking at EKS and ECS information to tell you how many pods or containers are running a specific image. The reason why this is important is because as a customer if you. Have a finding or a a variety of critical findings on a specific image you may or may not want to prioritize those findings based on the number of containers that are actually using the images, right? So that level of visibility is gonna help you prioritize and in the demo in a few minutes I'll show you what that looks like in the console. Lastly, um, just to call out, we're always expanding the ecosystems that we're scanning and we're, we're generating vulnerabilities for so just a few examples WordPress, Tomcat, um, we continue to expand on this and we do that based on customer demand as well. The last thing I wanna cover are essentially some of the ad hoc functionality related to additional utility capabilities that we provide you as a customer for Inspector. So just take a step back, I walked through some of those continuous scanning capabilities as a customer you can change some of those settings to control how you're actually using Inspector to meet those use cases, but we also provide some other capabilities that you can use as part of your effective vulnerability management strategy. The first of these is I'm loosely referring to as manage S-bomb, but as Rick mentioned, you can have the ability to basically export an S-bomb that Amazon inspector is detecting because we're actually monitoring those resources in near real time. You have the ability to export those, but you also have the ability to use our scan S-bomb API which takes an S-bomb as an input. And then generates findings in inspector based on that actual S-bomb. So that that's really the evaluation of the S-bomb, um, but you can make that API call yourself and that can give you some flexibility in terms of how you use the intelligence and the capabilities of Amazon Inspector. The S-bombs are in Cyclone DX and SPDX format. The second capability is CIS benchmark scanning for EC2. So you can execute ad hoc or schedule scanning of EC2 against EC2 instances. You can use tags on this. So this is not quite as real time as our other capabilities, but in terms of this use case that we believe that that meets the customer needs, you can view those results. Certain customers in certain industries are going to need this more than others, um, but again, this is a piece of capability that you have the ability to use. And lastly we have a few CICD integrations you can see here it's it we have an example with Jenkins but you can use popular CICD tools to orchestrate the integration of the S-bomb generation and scan S-bomb to meet use use cases like. Scanning container images before you push them to a registry so you can use these tools to bake into your operational development process and this is part of your journey to sort of shift left um it's a taste in our journey to shift left and we'll be talking more about that in a few minutes. So with that I'm gonna go ahead and show a demo we're basically gonna walk through some of the console to show you actually where to go and inspector to go and and leverage these capabilities and how to control them. So this page here is account management and as a delegated administrator basically what you have the ability to do is see this giant grid of all the different accounts in your organization and which capabilities are turned on and you can granually control which ones to turn on or not. So in this example you can see this account in all sixes. Doesn't have lambda scanning enabled, but I was able to just simply click that, turn on and activate lambda standard and code scanning. In account management as well we have this coverage you can see resources coverage on the left it's gonna fire through some of these screens, but effectively. Across your entire organization, what is every single VM that's being scanned or not scanned and then I can drill in and see those details about those resources themselves. You can see we have the same thing here with lambda functions. And also container images, so we're decorating that information that you have an understanding what's actually being covered or not. The key point there being you cannot manage what you cannot see. And then we just have some other information here in the console showing like why is something not being scanned that would be relevant um to understand from a security perspective or if you're reporting to your managers. Um, you can see here also I'm just firing through the X-bomb export, so inspector is continuously monitoring all those resources. And you have the ability to simply decide which resources to generate the export the S-bomb for, and then you can put that in the S3 bucket or not. This page here is our EC2 scanning settings. Simply enough, I talk about the hybrid mode versus the agent-based mode, but it's easy enough to just go to the console, click the EC2 scanning settings, and then turn on hybrid scanning. At that point, inspectors are gonna start doing the work to detect all those other resources and use our agentless technology. And then the last real knob you have, which I talked about is a major piece of control for container image scanning. You have the ability to determine when an image is going to be re-scanned or enter scanning eligibility. And you can do this by either choosing a last in use date or a last pull date plus a push date so you can use those dates to control the images that are eligible for scanning. And lastly, I'm just showing here the vulnerability database database search. So we're decorating the findings with the information here but if any time you wanna go do research about a specific CBE you can simply type that in. We'll provide all the information here about the finding as well as any other intelligence that we have to help you understand more about that vulnerability. This will be a quick minute demo. I'm gonna show you what the container image to container mapping capability is. You can see here I drilled into some critical findings for container images I'm here in the dashboard. I drilled into some of the findings for this particular image. I'm here on the container image. You can see I have a variety of findings here, many findings. I can go view those findings if that makes sense, so I have visibility into what those findings are for this specific resource and then you can see here there's a hyperlink to the deployed ECS EKS tasks and pods. I can see the workload name there and then I can simply just go click into that workload and explore all the details about that, where I'm actually using that, which is in ECR itself. OK, so I gave a quick overview on basically how to use Inspector to meet some of those use cases. There's plenty of additional content to help you do that. More or less, you wanna be able to set up Inspector to start doing that scanning and play with the knobs as an administrator how to actually use Inspector to start that vulnerability detection. And with that I'll pass it to Nerei. Thank you. Thank you, Anthony. OK. Moving on. How many developers here in the audience? A few good, uh, actually more than a few, um, I like to start talking about code security from the perspective of this iceberg image. What we talked so far in our journey was the tip of the iceberg. Everything that a security person gets to see when their workloads or images are running in production. Oftentimes, it is harder to patch these running environment workloads in production. The challenges become that's not visible, which is underneath the surface, basically under the water. Our developers are iterating, writing codes on a daily basis with a sprint to make changes, oftentimes not knowing what security vulnerabilities or exposures that they may run into. Let's take an example. Business wants a brand new feature that's going to change the world. Product managers and business owners are working on defining it. Your customers are eagerly waiting for that. Developers have actually worked weeks and weeks trying to write code to get that ready for launch. Monday morning, the launch is set to go, and before you hit the green button, you discover a new critical vulnerability. You're now faced a decision point. What do you do? Do you actually hit the button, launch it, or do you actually scale back, go back, fix the vulnerability, and delay the launch? How many of us have actually run into that scenario where you've had to make that decision, right? Sounds familiar? I wish there was a way for developers to know earlier. That hey, what I'm writing has these vulnerabilities, has these critical vulnerabilities, so I don't have to wait all the way till Monday or Saturday or Sunday to discover them, right? That's what code security is doing, throwing light underneath that water surface to be able to catch things earlier. Their production workloads have vulnerabilities. You have to patch them with high urgency, obviously, but what's below the surface is all the code that your developer's writing. All the dependencies with open source packages that they may have that may have uh vulnerabilities that you may not be aware of and your infrastructure has code, right? Like I'm writing code to scale my infrastructure and I want them to be secure before I actually go ahead and scale up my infra in production. And we started the journey with inspector all the way to the right where we started to monitor everything right from. The EC2 instances, lambda functions, the images that are used to bring up your pods and tasks, we introduced an ability to actually build and test with your CICD pipeline, but you told us that's not enough. The same iceberg analogy, it's not enough. You have to start catching these early. It's very expensive and to patch and fix these vulnerabilities in production. Oftentimes you cannot even touch it. And you own that risk, and we want to actually allow you to balance it. So we're further shifting left based on the feedback that you told us. Let me give you an example why it's important. How many of us here know about Lo 4 J or Lock 4 shell? Very good. To your surprise, the graph actually shows the downloads of vulnerable L4J since January of 2021. If you see this scaling up, even today, it's been around for 4 plus years. It was detected in December, end of December the previous year. Um, even till date, 30% of the downloads that happen are vulnerable. And oftentimes we push that code to production and we now have to go and patch it as security owners. So it's very important to catch this early enough where we don't need to worry about fixing and patching things in production. And that's the reason why we further shifted left in the development cycle to catch vulnerabilities, not only in your third party dependencies of open source packages the developers are using or pulling. But also your first party code, which is like your proprietary code that you're running. So scanning right where your developers are working and iterating on your code. With native integration into GitHub, as well as GitLab repositories. It's very expensive and costly to actually find these defects further, right? And so we're shifting as left as we can to meet your developers and allow them to do security right from the beginning. What is part of code security and what are we gonna scan? So we'll integrate with your GitHub and Gitlab. We'll go ahead and expand our capabilities. The inspector natively does third party open source package dependencies and to detect vulnerabilities in your compute environment. So we're expanding the same capability, the software composition analysis, further left. So in your GitHub or Git, uh, GitHub or Gitlab repositories, if your developer is using third party or open source packages that they're pulled into your code base, we'll scan them to detect vulnerabilities early. As they write and iterate the code. But we understand that even though 80% of your code may still be open source, um, and your source code analysis is important, we still have proprietary first party code that we write, and it's important to scan that as well. So we're expanding the capability from not just supply chain or SCA capability, we're also adding static application security testing scan, which is scanning for security vulnerabilities in your first party code as well. And then we all typically use infrastructure as code. To scale our environment, making sure that the IAC configurations and my files are secure inherently before I use to scale my cloud environment is very important. So, no different than scanning the rest of your repository, we will also scan your ISE files. Terraform CDK. Uh, will also be scanned using the same mechanism to find security flaws such as hardcoded secrets and other detectors built into it. Now, we often talk about security person or persona wanting to implement guardrails. But from a developer persona, it is very difficult to kind of follow through and always adhere to those guardrails and oftentimes it comes late in the system where a developer is mad at a security person to get that finding generated a lot later in the system, right? Um, we talk about Devse ops, it's been around for a very long time, but in reality. It's very hard to implement that entire Devseop's journey by unless you natively embed and bring the culture in the developers' workflows. So with code security we're adding an improved governance model and what do I mean by that, right? Like typically a developer will work in its own environment, write code, go through the sprint, and at the tail end the sprint we'll get to know about the vulnerabilities. There'll be a bunch of back and forth, we'll have to go fix, negotiate with the security person, fix the critical ones, and then move on. But what if I told you that with this capability. We're gonna change the governance model where we're natively embedding security within the workflows of the developer tools without them having to switch tools or even go to the security persona to look at what the findings are. So instead of the developers having full freedom to just iterate the code but then find out later and slow them down, we wanna give them incremental information as they're doing PRs as they're merging code back to the main to show them that hey, here are your top vulnerabilities. Let's go fix them, give them guidance of here's what I recommend your fixes to be as well as you write the code, and here's the guardrail defined so that. We can build a culture where security is not a blocker but an enabler for allowing developers to write code fast, be agile with security in their mindset, and write secure code right from the beginning. All of this can be set by a security persona to set and define the guard rails for what your code should look like before you actually merge into Maine or before you actually go to production. And within those guardrails your developer now have unvetted freedom to quickly trade the code, learn, fail fast, and improve so that overall the business has agility, able to launch features faster in a secure manner, and you're actually de-risking your entire development life cycle. The other thing that was very important that we touched upon is you have to meet them where they are. The challenge with some other code security capability was security personnel wants to go ahead and build out guardrails, build out visibility into the code repository, but the only way to look at it was to come into a security persona's view. So you'd have to hypothetically come in to inspector to see what the vulnerabilities look like, and developers often don't want to switch tools like I'm writing code. Um, in my IDE environment, I pushed it to my code repository in GitHub, and I'm iterating on GitHub with PRs and pushing back code into my main branch, and I'm ready to go, and you're asking me now to switch context, go and find the vulnerability somewhere else, right? So it was very important for us to have the experience natively embedded into the workflows where the developer is. So you have both personas. If you are a security owner, you certainly have a centralized view with an inspector to look at all the repositories that you actually have or a subset depending on what's important to you, such as show me the findings only for production environment or anything tagged pink for that matter. So what's important to you, you define and you see the vulnerabilities is no different than how you do with inspector today. But if you're a developer, you do not have to leave the tools you're using, you're writing code in your GitHub, as you do PRs, as you merge the code back in, you will get to see all your security vulnerabilities as comments, as well as recommendations on how you would fix the code. Let's quickly go through a demo. Um, I promise it's a short one and the last one. Um, I'm gonna wear a hat of a developer. Um, not a very security savvy developer. I just wanna move fast. Um, I'll, this is my standard, um, Python application. I have infrastructure as code, uh, as well as web application with built-in vulnerabilities that I wanna show you and walk you through in terms of the scenario. I'm now committing it back to my, um, GitHub environment. It's a standard flask application. It's for demo purposes, um, has a bunch of vulnerabilities as you can see, application vulnerabilities as well as infrastructure as code vulnerabilities that I wanna walk you through and identify them within my setup and inspector. As a security person, the setup is no different than how you would do it for the rest of the environment, right? So you'd come in, set up an integration, depending on what code repository platform you may have, you'll go ahead and set up a configuration integration with GitHub. In my case, we'll also highlight all the default configuration settings that we are recommending, right? So we're gonna say, go ahead and scan them every time you're doing a pull request, pushing back to the main. You also want to scan them weekly and scan across all of it, right? Scan across your first party code, third party um dependencies, as well as your infrastructures code. By default, go ahead and scan all of it. And create this scan configuration for you to be able to know exactly what's happening in your code repository. You certainly can filter out, depending on what you may need. Um, I'm gonna go ahead and finish the installation. There is an app that gets installed, um, natively. It'll walk you through that entire workflow. Um, what the app is actually doing is allowing, giving you permissions, read, write permissions, so read only so that I can discover all the reposts and write so that I can put comments on your PR and the write permissions only for PR so that I can get you comments from security findings directly natively into GitHub. Let's go back to Inspector. I've now discovered the 3 repositories that I actually had in my setup. Um, we'll go ahead and quickly look at the findings from the setup in my web application. And if you can see, I have not run any scans right now. I'll go ahead and initiate a scan in my repository. Generate the findings. I'll go ahead and quickly just run a, um, on demand scan because I set it up for weekly scans starting Wednesday. Today's Monday, so the next scan will happen on a Wednesday. We'll go ahead and set, set the scan up to go see the critical findings that are generated automatically. We'll go ahead and see the findings on my web app that I had written poorly what those findings are. It was scanned. I can see the project ID. It's important so that you know which project I actually scan and what the RN is and what are the vulnerabilities. If you notice here, I have restricted IM policies. I also have hardcoded secrets, and I have a public read Ale in my repa, which means I have an S3 bucket with access publicly allowed from the outside in. We'll go ahead and highlight what the vulnerability is, when was it actually detected? This one's a package vulnerability, um, what are the affected packages, where, if it is a code, where exactly in the code the vulnerability exists as well and what the recommendations are. Real quick, I'm gonna actually make a quick change on my terraform file. I'm gonna add a new feature. I'm gonna actually commit it back to the main. Um, and then run another scan to see if it generates the finding, and we could do the same on. We could do the same on uh PR as well. If you notice the scan commit ID changed, we've generated a new finding certainly sort by the age. The finding generated this time has the restricted actions with the principal S3 bucket. I continue to write bad code. And I get all the findings. Here are the 15 lines of code that has an issue, and it was all detected. Now, real quick, let's just see what happens when I'm doing a pull request. Um, I am gonna continue to write bad code, more, um, things I'm gonna add in here. I'm gonna have a hard coded secret. I'm also gonna expose with remote code execution. Um, if exploited, so just bad practice, uh, continue to happen, and when I'm doing that, what happens when I do a pull request, the findings actually will get generated automatically within the native tool that I have. And there's a pull request. I'm, I think it's a great code. I'm, I'm excellent. It's good to go. Let's just do a pull request and see what happens and there are no conflicts and I'm gonna start generating all the findings associated with it for me to now realize that the code that I've written is actually not very good. Here are all the hardcoded secrets that I need to go fix, as well as our remote code execution if exploited would actually put me at risk so I can go ahead and make the changes in the code while I'm actually doing pull requests. Just to summarize, we talked about scheduled scans, on-demand scans, and Git event-based scans, which allows your developers to actually iterate code securely, full visibility, governance model that allows them both to collaborate together. And with all of that. Right from the production workloads to scanning right in the beginning of the code repository, we wanna make the secure thing the easy thing for your developers and your security persona so the organizations can and should build secure software. To get the speed and agility that we need today. And just to summarize the same iceberg. With Inspector for vulnerability Management, we're not only just showing you what's in production. And the the vulnerabilities that are available but we're also shining light underneath that so you can start early to understand all your code, the dependencies infrastructure as code security vulnerabilities earlier fix them in the life cycle. And then when it comes to security, it's not just about vulnerabilities, right? Like that's one of your problem. We've um. Many of you probably already are familiar with Security Hub. Like our original security hub is now rebranded as Security Hub CSPM. We have a new, um, platform for security finding aggregation that aggregates findings from threat findings from guard duty, vulnerability from um. Inspector controls for resources exposures, um, and configurations along with sensitive data from Macy all of that together to have a combined risk score we'll automatically correlate these findings for you. Generate a prioritized risk so that you can take action on what's more important to you rather than just looking at one aspect of risk. This is a combined correlated aggregated view, so you can prioritize, take action based on what's important, and it already has automated response capability built into it for you to do investigation on all your critical findings. Um, lastly, there are additional sessions to go deeper into security hub, inspector code security or appset capabilities, um, so feel free to just step into one of these code talks or breakout sessions or workshops to get hands on. Some important blogs and other useful information on Inspector if you were curious to learn more. And you guys have been wonderful audience, sorry, uh, you guys have been a wonderful audience so thank you so much. um, please, uh, use the app to, uh, give us feedback and we'd love to learn from you. Thank you so much and we can take questions in the back, uh, if anyone has any. Thank you so much.
