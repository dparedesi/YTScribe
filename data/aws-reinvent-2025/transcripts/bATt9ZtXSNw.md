---
video_id: bATt9ZtXSNw
video_url: https://www.youtube.com/watch?v=bATt9ZtXSNw
is_generated: False
is_translatable: True
---

Good day everyone. Um, I'll be giving a talk on secure Amazon ECS of solubility with CDK and Grafana. Like I mentioned, my name is Chibike Wachiku, so let's begin. You may ask yourself what uh prompted this talk. What came, why did I come up with this particular topic. So sometime in June, I sat down with my CTO and he came up to me with a particular problem. He said, TBK, we're having our non-technical staffs having issues seeing what's happening within our applications. To give you context, I worked at a healthcare startup, so they wanted to see how patients were signing up and interacting with doctors having live calls. But then these users had to, uh, these non-technical users had to have to interact with Cloud Watch to see logs, and they were having issues doing that. They had to always go back to the technical team to really understand what was happening. So he really wanted me to try and fix this particular problem and really explore the open source space to come up with a particular solution that will enable them to have freedom for the non non-technical users to be able to like see life happenings, logs, and other metrics. So I will go on to under the like through the rabbit hole of really figuring out the particular tools I should use. I will go on to choose um Loki and Grana. The reason behind this was to find a solution that complemented Cloudwatch but still giving me the opportunity to have real. Insight which was a very, very important challenge that the CTO mentioned. I saw they having a beautiful interactive and intuitive dashboards that allow non-technical users to really explore and understand what's happening, make sure the vendors are independent and has the open source flexibility. So we'll go on to build or go on to architect and build or set up the whole graphana Loki dashboard, and we have, um, non-technical users actually seeing what's happening, right? So to actually go beyond what I, what was required at work to have what I call the full auto framework. At that point, we're already focusing on logs. I wanted to start, um, add metrics and traces, right? And what better way to do that than, like I said, open source, but to also follow the IAC approach, right? I wanted to use AWS CDK and based on my own experience, I find out using IAC actually reduced in terms of development time and time to production. So what are we going to be looking at today? This is um a high level of view architectural diagram. We'll go deeply into this within the talk, but to give you an idea, we're going to be talking about um security, client VPN, um, Amazon Money, Prometheus. X-ray of an application signal. So who exactly am I? Um, like I mentioned, Chibike Wachiku. I'm a proud Nigerian. I worked as a, as a full stack engineer at Micro One, building software solutions for companies, for clients of ours. Sometime in 2021, I became tired of always sitting in front of my laptop, and I became a certified chef. I had to add that image because most of my friends actually doubted that I can, I was a certified chef. So, um, this is my quest for knowledge. I will go on to take up the AWS certification challenge for like 2 years, 4 months, become fully certified and get AWS golden jacket. And you'll find me generally writing articles, traveling, and speaking across the world. So what are we going to be exploring today? We saw or we have seen what actually prompted this talk. We have seen why this talk. We will next go into the observability in in details, the AWS way. Next, we'll look at the three core pillars that actually guided this talk, that is security, CDK, and GitHub. And then we'll look at a demo on how the application works. And finally, we'll look at actions and resources, um, for us to further explore on our own. Before we really go into this talk, we need to understand exactly what is observability. I see it as an ability to see um what's happening within a system from external, right? It gives us a better view into the inner workings of a particular system without actually being inside our system. It allows us to ask questions about how is our application actually responding to user interactions or what exactly is happening in our application. Three main core pillars in terms of how you emit um telemetric signals are logs, metrics, and traces. Observability is a very broad topic, and that's why we have um hotel, that's open telemetry. That's a standard way of instrumenting, it's the framework for instrumenting collection and export, exporting of telemetry data. Why it's very, very important is that I'm very, very unique to our application or the general application of data of observability is that it allows us to instrument once within our application and sent to multiple different locations. It could be AWS services like X-ray, Amazon uh managed Prometeus, or it could be other third-party, um, AWS partners. Due to the the actual use of open telemetry, we see it as the second most popular um. Project in the CNCF space 2 just shortly to Coberettis and it's really community-driven and open source. So, what are the three core pillars of observability? I mentioned logs, metrics, and traces. What exactly are logs? We all build application likely, and we see logs as mostly the default. The logs allows us to know what exactly happened within our system. We see it as a time stamped text record of events. What matrix allows us to understand how many times a particular event occurred within our, our, our applications, right? You see it. Basically as a qualitative measurement on a particular service, tracing, on the other hand, gives us a more holistic view to tell us how a particular incident took place within our application. I call it the ability to show us the trace of requests that flows throughout our system. So we know we've heard now about observability. We see how Oel comes to help um make observability more, let me say accommodating. But how does AWS come to play up in this particular space? AWS has what they call AWS Distro for Hotel, which is also called ADOT for short. Basically, what Otel does is that it secure production-ready open source distribution supported by AWS. If you're running it on ACSfait, it's going to run as a sidecar close to your application. If it's on lambda, it will run as a particular lambda, um, layer. So, it allows us to just auto-instrument our agents by adding slice code snippets, and then it automatically adds a lot of details and pushes it down to a particular AWS service. So, it's a very simple and very simplified way of deployment of pushing metrics, logs, and um traces to AWS services. So, like I mentioned, uh, it collects traces, it collects application metrics, and Catronic correlates them and allows us to move them to multiple AWS partner solutions or AWS X-ray. So, let's go into details on how this architecture works. The first core, uh, what I want to core pillar is the user. If you look at the right-hand side, we have two particular subnets. We have the private subnet and the public subnet. A user interacts with the public-facing application and sees the public URL and interacts with the login application, right? Whereas the login application has two sidescars at this point. It has the ADAT collector that moves traces and matrix to um AWS services and it also has a cloud uh it's a sidecar for fire lens that moves logs to low key that runs in a particular private subnet. This same log application also interacts with AWS SQS as well as AWS Dynamo DD. The second layer is when an authorized user, mostly a developer, tries to, let me say, see what's happening within Graphana space. So they connect using the AWS client VPN through the private subnets, and they can then access, um, the ECS, Graphana, and low-key stance running securely, and both of them are connected to both EFS and S3 for persistent storage. So let's look into details. First of all, the security first approach. We, we mentioned AWS client VPN which gives us the ability to have secure connection, encrypted tunnel to the private subnet. We also implemented what I, what I mentioned earlier, where it's private subnet and public subnet. The idea of segmenting various, um, subnets to give us, um, security and also leveraging security groups for lease privileges, right? IM rules also leverage um of um to make sure um particular services have the required rules to assess other AWS services. I want to dwell more on the availability security. We have two layers. Like I mentioned, the AOT scar runs close to your application, right? So it collects matrix and traces and moves to AWX X-ray and Prometheus. For the first part, it moves it from the sidecar to AWS X-ray, and this is secured using IM rules to make sure no one can actually access the logs going through, and that is secured basically by AWS. The second layer of security happens from within the Alogger application whereby it is run, the, um, it can access the adult collector. On localhost 1337 and because this connection never leaves the local container network, you don't have interactions from outside the network. So this is a secure connection moving traces and metrics through the localhost 137 down to the collector and then that moves it moves it straight up to AWS services upstream. This is an example of Fire Lane scar. Uh, the particular ECS task is defined, um, using tax definition. And then we see how we add that particular sidecar to our local application. If you look at the URL closely, you'll see we are actually accessing a private um router with the true network. And we see the local local.internal.com can only be accessed when you're connected to a particular VPC. And then we can then move log securely to locate. I mentioned AWS CDK and AWS and and basically IAC. This allows us to have IAC as codes, improve developer productivity, as well as easily manage, um, resources by just changing lines of code. Also, I want to really explore how dependency sharing works using the AWS CDK. We're going to see an example shortly and the idea of avoiding circular dependency, which we also see shortly. Another very important point is that we have ACR um um scan on push. We could just have like a line of code added to an application. And once we push codes, um, to like using GitHub to the particular AWS, uh, environment, we, it runs the CRCR scan to make sure there's no particular virus within the stack. So this is an example of access points. If you don't know if, um, if you don't know what access points are, they allow us to have permissions attached to our EFS, um, volumes. So I created the access points and I said I imported it then in the low-key tax definition as a storage method and I'm using it. So, where does GitHub come to play? Basically, GitHub is just a source code, uh, repository that is being used. I want to emphasize that you should actually figure out using OIDC over using access keys and adding them into your GitHub, um, repository. Uh, uh, OIDC allows us to have rules specific to that particular repository and allows us to like connect to a particular, uh, AWS service. I integrated 33B for running, um, once you run the side city um push the code you actually run some tests to make sure everything works. Automated flow actually allows us to have central management when we come to like deploying our code. So let's really look at how the application works, in particular, very, very short demo. First part is importing the OpenTel packages. I tried as much as possible to add lots of logs so we could see what was happening at real time. In summary, I added, imported all the necessary packages, and the gray mark checks shows that we have everything up and running. I mentioned in the beginning of my talk about how we have auto instrumentation and this is a very, very simple example whereby adding this particular code snippets we have we have um um instrumentation already added to our application. So for instance, we are using SPS and Dynamo DB. It's all we need to get detailed metrics and detailed traces that involves both S3 and Dynamo DB. But most times we want to have other custom metrics. We don't just want to focus on the predefined metrics that AWS gives us by onto instrumentation. We want to have other metrics perhaps um counters or how many times a user comes to our application that we're actually counting internally. And that's why we have the ability to have. Constant matrix and metadata capturing within the open telemetry um system. So if you look at the right-hand side, we're actually capturing the queue, the message queue, and we're saving a particular start of our success. We'll use, we'll see this in the next slide when we head over to Grafana and we look at the Prometheus. Um, Amazon Grafaa managed Prometeus basically, we can see we are counting and we see we have two particular results. So, what we pushed in the code, we can actually see it happening or see the results on Graphfaa. We can also look, go back to Cloudwatch to see the traces. Now, we have two options of seeing the traces. We can see the traces in CloudWatch. Uh, this is through application Signal, or we could go back to the Graphfana dashboard where we have the application Signal, um, plugged in to see the particular traces. And we can really drill down within each trace and see each metadata that each trace actually contains. So, it's, it's one thing to like talk a lot about theory, and it's one thing to actually see the application or how you actually react when we have a particular error or issue. So I tried my best to simulate a 44 error to see how the application responds on that instance. So, I have a particular endpoint that creates a basic record in Dynamo video, right? The primary keys are basically the ID and the timestamp. And then I made a, a get request, uh, the town, but to see, to get the ID. But if you look at, there's a significant change. I'm trying to get the timestamp of latest, and this is not going to match within our dynamo, so it's going to give us a 44 error. Once we do that and we head over to application signal on Grapha, we can see we'll begin to see some red around our greens. That means we're going to have a particular error happening in our application. And if we click on that, we see the particular error message is actually a 44 error. We can actually drill down to understand what exactly is happening. If you look closely on the right-hand side, you can see the main error started happening from when we had the get Dynamo DB um call. So we see the local application was working properly, but the red error started happening when we did the dynamo get Dynamo DB data. So that allows us to have understanding in terms of traces on what actually caused that particular error. We can also go to the matrix to see exactly more what's happening. If you look down, we see the application, it actually works in the log application, but then it happens, the yellow line shows it happened on the get item request, and we have a not found and we have a success. The issue happened for a not found, which is the 404 error. So we see both matrics and traces allow us to actually see what exactly happened within our application. So in summary, What are the lessons learned using this particular architecture approach? We focus mainly on security and the key point is to make sure we start with security from the inception and not as an afterthought to actually build within the application. If you go that other route, you're going to have a lot of problems. The second approach was or is to use open telemetry. I don't know if you know AWS made a particular announcement 2 or 3 months ago that they're actually ditching out the AWS X um X-ray demon to favoring Hotel, right? So this is because Otel actually got a lot of traction within the open source community and AWS want to go through that same route. So we want to leverage open telemetry, um, for basically for a vendor in society and because it has a large open source con um contribution basically. And lastly, we want to learn to automate everything. For this example, I use CDK and GitHub. You could use CDK. You could use and order maybe Gitlab or Bitbucket. I, this talk stemmed out of a two-part technical article I wrote. You can find the GitHub report for the project, yeah, as well as the medium article for the application. It's a two-part medium article on the right-hand side. So, I'll give like a minute and then I'll go on to the next slide or some seconds. Thank you. Um, thank you for coming to my session. You can connect to me on LinkedIn, Chibike Wauku. Um, please remember to fill out the survey on the mobile app. If you have any questions, I'll be at the back to answer your questions. And once more, thank you for coming to my session.