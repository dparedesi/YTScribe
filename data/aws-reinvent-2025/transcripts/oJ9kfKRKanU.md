---
video_id: oJ9kfKRKanU
video_url: https://www.youtube.com/watch?v=oJ9kfKRKanU
is_generated: False
is_translatable: True
summary: "This session, \"Maximizing AI Governance and Speedâ€”Only with ServiceNow + AWS (ARC337),\" presents the \"AI Control Tower,\" a solution from ServiceNow designed to manage AI compliance, security, and lifecycle management without sacrificing speed. Speakers Amanda Grady, Sampada Chavan, and Offer Weissler discuss the challenges of scaling AI in the enterprise, such as bias, hallucinations, and data privacy. The AI Control Tower, built on the ServiceNow platform and integrated with the CMDB, provides a centralized inventory of AI assets (models, agents, datasets) across the organization, including those on AWS. It allows for the orchestration of AI workflows (onboarding, changes, unexpected retirement), aligns AI initiatives with business strategy, and ensures regulatory compliance (e.g., EU AI Act). The session also highlights \"ServiceNow Vault\" for data security, offering features like data classification, anonymization, encryption, and zero-trust access to protect sensitive information processed by AI agents."
keywords: AI Control Tower, AI Governance, ServiceNow, CMDB, AI Inventory, Data Security, Risk Management, AI Lifecycle, Compliance, Zero Trust, ServiceNow Vault
---

Sorry, I didn't know as we're live. Hi everyone. Thank you very much for joining us today for our session on maxing AI governance and speed only with ServiceNow and AWS. My name is Amanda Grady, and I lead AI platform security at ServiceNow. And I'm joined here today by Sampada. Hey everyone, uh, nice to be here. Uh, my name is Sampaha Chavan, and I'm part of the AI platform product team and the lead product manager for AI control tower. And offer. Hello everybody. My name is Offer Weissler. I'm part of the platform product management team and I lead the AI control tower. So welcome to the session. We're excited to have you. Uh, before we start, just have to show this uh safe harbor slide. You all know the drill. Don't make purchasing decisions based on future statements. And with that, Let's start our session. So, we've prepared a great presentation for you about governance of AI and about securing AI, but before we jump into that, I wanna talk about the ServiceNow platform just a little bit. So, we built the ServiceNow platform in order to automate work for people. You all know that. And we've been doing that now for over 20 years. So in fact today our platform powers billions and billions of automations every month, flows, playbooks for many, many thousands of customers across all industries. So automation is not really new to us. In fact, it's part of who we are. It's part of our identity. Now we all know that the landscape is changing and AI is taking the world by storm. And we think that this change is going to be pretty significant. I'm sure some of you, if you're at least as old as me, then you remember when virtualization came out. Everybody thought in the beginning that this is about saving server costs. Well, fast forward for today. It turns out that it fueled the entire revolution into cloud computing, enabling new products, new services, new business models. And we think that AI is gonna be at least as big, if not bigger than that. And that's why we've built AI natively into the ServiceNow platform, making sure that it continues to be the platform for business transformation into the AI era. Now we think that The AI revolution is going to be so big that over the next few years every workflow for every industry is going to be reimagined with AI. That's a pretty bold statement, but we know that AI is not a one size fits all. We know that in order to build amazing AI experiences, you have to pick the right model. You have to pick the right data. You have to pick the right infrastructure that it will run on. So We know that That's exactly why we built the ServiceNow platform in a flexible way that allows you to do exactly that. You pick the use case and based on that, you pick the right model for the use case. You pick the right data for the use case, and you pick the right cloud that you want this use case to run on, so it runs most efficiently at scale. So we all know how powerful AI and how big is the potential, right? It can help unlock so many amazing business outcomes. It can increase productivity, it can accelerate time to market, it can reduce costs. But even more than that, it's actually becoming table stakes, right? If you're not implementing AI then you're gonna stay behind, you're not gonna be able to stay ahead of your competition. And that's why it's not surprising. We're seeing many of our customers now looking to move from experimenting with AI to operationalizing AI at scale. But, you know, the potential is huge, but with this potential there are also increasing risks, right? If you played with AI and you experimented with AI, you know that having a successful POC is one thing, and scaling AI and getting enterprise value out of it is a different thing. So AI obviously comes with a huge set of challenges. It's an undeterministic technology by nature, right? So you cannot overlook things like bias, hallucinations, or lack of transparency. Also, there are increasing concerns about risks and security issues and data privacy, especially as this technology becomes more capable and even more so, more autonomous. So scaling AI is not just a technology challenge, but it's actually at least as big as a governance challenge. Now as you start looking into organizations and how they are implementing AI and who's involved in this process, you tend to see two forces. On the one hand, you have product owners and business users who want to prove value fast and move as quickly as possible. On the other hand, you have risk teams and security teams and compliance teams and legal teams. They also want to move fast, but they're thinking all the time about all the new threats that are coming if AI is going to be used without the appropriate guardrails. So many companies are stuck in this kind of phase of analysis when they're looking to transition between proof of concept to scaling AI. And most of them do not have the right governance process and tools in place to enable that scale with trust. So in response, we are seeing many organizations that have either created or are in the process of creating AI centers of excellence. Those centers of excellence are responsible for holistically managing and coordinating and governing the implementation of AI across the enterprise. But just creating those organizations is not going to be enough. What you really need is a seamless collaboration between all the stakeholders that are involved in the process of building AI, deploying AI, and addressing issues like risks and compliance issues when they arise. What's needed is a truly way is a true way to break down all the silos and have everybody on one platform. Everybody needs to speak the same language. Everybody needs to see the same data. Everybody needs to get the same context from a technology perspective and from a business perspective in order to understand how those AI initiatives are going to impact the business. And that's exactly why we built the AI control tower. The AI control tower provides an integrated and holistic approach to manage your AI at scale, so you don't need to trade off between moving fast and moving safe. You can now do both. So it streamlines all the life cycle of AI from onboarding to change to offboarding, and it connects all the dots between your AI strategy, your AI execution, your AI governance, and the value that you're generating from AI. So all of that is built also on top of our CMDB and that is a super important fact. And let me now just touch on each one of those pillars so that you can understand a little bit more the details and then we will go into a live demo that will show you how it all works in real life. So let's start with the underlying data model. Here's the thing AI assets are just like any technology assets. They need to be discovered. They need to be tracked. They need to be governed. Just like any other server or business application or network device that you're already managing. And that's why we build ServiceNow control tower on top of CMDB. So the AI control tower discovers all your AI footprint and not just agents, but also the models that those agents are running on, the data sets that those agents are trained on, the prompts that help define those agents and what they do. And this is how the AI control tower provides a single system of record for all your AI footprint on one platform and because it's integrated with CMDB, it, it is also out of the box, uh, coordinated and tightly aligned with your technology architecture, your er er network architecture, and your workflows. Now when you think about AI, you always want to start with your strategy. You want to make sure that all your AI efforts are tightly aligned to your business objective. And that's why we integrated AICT with our strategic portfolio management solution to give you exactly that visibility and connection to your strategy. So what you can do with AI control tower is you can connect all your business priorities and business goals into your AI initiatives to make sure that your AI efforts and your strategy are tightly aligned. Now with AI moving so fast, it's critical that execution will be flawless. So with the AI control tower, we've also packaged out of the box workflows and playbooks that allows you to run all the AI life cycles seamlessly, ensuring that nothing falls between the cracks. So for example, if a team wants to onboard a new model that kicks off a new workflow. That goes to security teams, to risk teams, to legal teams for review to ensure that this model is not onboarded and become operationalized without the appropriate reviews and sign off. Same for, let's say you want to make a change to a model that is powering an agent, or at some point you would also want to retire some assets. All of those playbooks are packaged together with the AI control tower, ensuring that your execution is smooth and everybody is on the same page. Now also, when you deploy a new application, a new agent, a new model, you want to make sure you have the right controls in place. You want to make sure that you stay in compliance of regulations. You want to make sure that you have auditability and access to audit trails. So AICT is integrated with our market leading IRM solution which allows you to track your risk exposure. It also comes with out of the box regulatory frameworks like AI EU Act, so it maps your risks into the right compliance framework and regulation, and it ensures that your exposure is minimized. Now at the end of the day, the last pillar of the AI control tower is value. Everybody wants to understand what is the bottom line, what return am I getting on all those investments. So with AI control tower, you can see all kinds of value operational metrics like productivity gains or ROI. And because we know that value is defined differently for different use cases, then we build a very flexible value framework, framework that allows you to create custom value templates and associate them to the use cases and measure value the way you want to measure it. So the result is AICT helps you unlock all this potential of AI at scale, move from proof of concept to successful implementations that actually produce real value at scale, but better aligning aligning with your business goals, streamlining your project delivery, maintaining compliance, and seeing the value that you're generating. And with that, I want to hand it to Sapada to show us a real live demo of the product. You can see how it all comes together. Thank you. All right, so let me switch over to the view that the AICOE sees. Um, so with AI control tower, we talked about how the AICOE, the governance team, actually helps connect the dot across multiple cross-functional teams. And what this, uh, AICOE gets to view is the state of the AI in the enterprise. So they have a view of all of the different AI systems which are available. Where are they in their life cycle? What types of AI do you have? So, within the AI inventory we can track AI agents, your generative use cases, even the classical AIML use cases where you were fine tuning models for, uh, let's say prediction or classification type of use cases. The data model handles that. You also have a view into what is the overall risk classification for those AI systems, where are you sourcing them from. So it could be ServiceNow AI, AI that is on your AWS instances, it could be AI that is embedded in other software applications, bringing those all in. And then looking at overall, where do you stand in terms of the compliance, uh, in terms of your standards, regulations, or even your own internal governance policies. You can also track the productivity. Value is very important. You would want to understand how AI is being used, what value it is deriving, and you would have the ability to measure that as well. So once you have this overview of AI in the enterprise, you can then start digging deeper into each of the aspects of it. When I look at AI strategy, I am able to look at what are my overall strategic priorities, what are the targets that are associated with it, and how am I tracking towards those, uh, those particular goals as well. I could potentially also look at planned costs if, uh, if I have access to it and prioritize my AI work. So again, ensuring that the AI that is getting built and deployed aligns with your overall AI strategy that you want to implement in your organization. In AI asset inventory, you are going to get a little bit deeper into what type of AI artifacts are available. So you have your AI systems, the AI models, prompt templates, even data sets that you could be using for evaluations. If you're fine tuning and training your own models, you could capture those data set information as well. And then additional information on how those assets are spread across the board. Next up with value, this is where you are going to start looking at what is the overall value that AI in the organization is driving, where does usage look like, and potentially a scoreboard of what are your most used systems, what are the most valuable systems. You get a view and an insight into that as well. Next up, with risk and compliance, this is going the next level of detail into risk and risk status and classification of individual assets. So be it AI systems, different models, data sets, it all comes together. Along with the compliance of where we are in terms of the particular uh standards or regulations that you're looking at, as well as your own internal policies. Now, how does all of this information come together? So it starts off with ways of getting the data into the inventory. Uh, you could have a standard intake process where as a user I can go in and say that, hey, I want to build this use case out or I want to use this model in my system. Another way to look at it is also where we provide discovery capabilities. So by directly connecting to AWS Bedrock, we are able to bring in agents and their associated information into this inventory as well. Now let's talk about an example of such an agent. I'm going to pull that up. Here we talk about this autonomous recruiting agent, which is being used uh or built and deployed on AWS Bedrock. We are able to bring the information or the metadata about that agent, but it's not just that. Along with it, we are also able to bring in what are the related assets or artifacts to it, because that is what is going to give you the full picture of how an agent is going to be designed. And then deployed and then used in the system or in your enterprise. So you have a view into what are the different other agents that this particular uh agent would be calling, what are the tools this particular agent has access to, uh, what are the models that this particular agent is using, and so on and so forth. And then once you have all of this information, you will want to ensure that you're onboarding this agent into your enterprise. So that's where playbooks come into play into picture wherein as a playbook I can, I can set up different tasks of like bringing those cross-functional teams together to run either an impact assessment to understand how is this agent going to be used, how does it handle fairness and bias? Is there going to be a human oversight present? And based on that, you can also look at does it, does legal need to wane? Is there data, security and privacy concerns that we need to look at? Kind of bringing all of that information together will then help you understand what is the risk associated with that particular asset. So once you run through that, you run through those different assessments, you can then identify what are the risks associated with this particular agent to mitigate those risks, what type of controls do I need to handle. And then as you move this agent through its life cycle of assessing, approving it to be built and tested, you can then start looking at validating whether those controls are present, do you have the right set of guardrails available? And also at a point in time, look at how do you measure the value of that. And those are all tasks that need, that would be associated or provided to the specific users, bringing those teams together. An example of how do you measure value is going to be looking at a formula that we look at, like once this agent is deployed, we would want to then look at how many times is this agent going to be used, and this is where the data will come in from those cloud watch integrations that I just showed you. So we look at how many times this particular agent is going to run and then making an assumption in in this particular case that every time this agent runs, we are saving about 10 minutes of an end user time, so that becomes our productivity metric and assuming an accuracy of. 5% is also the way we would capture the value for this agent. Now this is constants, but you could completely bring in additional data streams into the platform to have uh indicators uh available to run this particular formula. So now imagine this is everything that we are doing for one single agent. When we start doing this over multiple different AI systems, the models, that is where we start bringing all of that together into this AI control tower view that we first started off with. So I focused a little bit on the inventory, the risk and, uh, risk and compliance, and the life cycle, uh, of that asset. Amanda is now going to talk about the data security and privacy aspects. Great. Thank you, Sam Per. So Sambata just gave us a fantastic demo of AI control tower, and Oprah also talked about how that helps you manage your AI life cycle, um, govern your AI and uh manage the strategy and understand the value of your AI. I'm going to talk about another aspect which is the security of your AI. And we're really in a completely new era of cybersecurity. I've been in cybersecurity over 20 years, and this year the pace of change has just been, I would say at least 3x any other year, if not, if not higher. Uh, and we've really moved. From, you know, computer security being on individual computers or individual devices to cloud security, which was a massive shift. And now to AI security, which is another really seismic shift. And all of the existing challenges that we had in that or that we still have in the cloud in the cloud security era in terms of things like data breaches, privacy leaks, uh, adversarial attacks, whether from nation state or just malicious actors who were trying to make money. All of these challenges still exist. But now we have new challenges to worry about. Thinking about what AI agents can access. Thinking about. MCP and agent to agent, uh, being concerned about model poisoning and prompt injections. So with that in mind, these are some of the key considerations that you need to think about when you're considering deploying AI agents. The first pillar really is the identity and access controls. We consider that AI agents are a new type of identity. Somewhere between humans because they're kind of like anthropomorphized humans and machines. Because they're kind of like code. But just like humans, we're going to need to ensure that they have they adhere to the standard security principle of least privilege. They should only have enough access to do their job and not more than that. I'm also very excited that ServiceNow today announced the intent to acquire VISA, a modern identity security company, which I believe is really going to enhance the ServiceNow AI agent trust story. Because today we are well known as a system of record for IT assets. We are also very well known as a system of action across many different types of use cases. And now we will be a system of record for identity as well. Second pillar that you need to think about is data security. And this is ever more important in the AI era where, Uh, you know, we have AI. We, we all know that AI needs tons of data to be able to operate efficiently. But it's more important than ever to know where your sensitive data is and ensure that that data is protected. So those two, those 1st 2 pillars are really the hard boundaries that are essential for the foundations of secure AI. The next pillar is the guardrails. So ServiceNow is actually we have a a model agnostic strategy. So we work with all the major hyperscalers including obviously AWS. And all of these LLMs have all of the LLM providers have guard rails built into them. On ServiceNow we have our own guardrails as well, called ServiceNow Guardian or called Now Assis Guardian, which ensures that. The, uh, it's monitoring for offensive content, detecting prompt injections, and also detecting personally identifiable information. Finally, monitoring is an essential part of any security strategy, ensuring that you know what's going on and ensuring that you have an audit trail in case something does go wrong. So let's just talk a little bit more about identity and how this impacts security. So again I talked a little bit about how security was very localized. In the cloud era, identity really became the the new perimeter. But what we're seeing in the AI era is the boundaries between internal and external IT are starting to blur more and more. Because the vision really that we have is that AI agents will be acting on our behalf and working across different platforms to uh to be able to carry out autonomous. Actions on our behalf. So this means there is just going to be an absolute explosion in non-human identities. And that explosion has even really already started. In fact, there was a report by Imperva, now part of Haas this year that said 51% of internet traffic is automated. So as AI agents become more prolific, this is only going to get even bigger. And we, we're seeing an evolution still in the standards. We have things like MTP agent to agent, that do require Oop. But, uh, it doesn't really go deep enough, and I think we're going to need to see, in particular, more standards evolving around cross-platform authorization or cross-platform access controls today. You know, the problem that identity providers really solve is cross-platform authentication. So another reason why I'm super excited about ServiceNow, um, announcing the intent to purchase Visa. So we will see what happens there. But uh even today, we have a great view to help you with your AI with AI control tower. And AI control tower helps you with the security of AI agents and AI assets by providing you visibility into access, ensuring that you have the trust that your AI AI assets have the right level of access. Uh, showing privacy violations, ensuring that any sensitive data, especially personally identifiable information, is. Either redacted or detected as appropriate and giving you visibility into the security through either guard rail detections or um observability of uh you know, providing that observability uh chain. And With that, I'm gonna have Sampata come back up and we're going to show another demo of AI control tower. So I just wanna show a couple of use cases that AI control tower can help with. Showing when AI agents have privileged access, which can, uh, you know, indicate potentially more risk. Showing dormant agent ident sorry, identifying dor dormant agents. Potentially agents that are ready for retirement, they don't need that access anymore. Showing streamlined access visibility. We're also showing already AI scoring, security scoring, with plans to enhance that in our uh very soon, coming up in our January release, we're gonna be adding the new AIDSS scoring mechanism. Uh, as well as not just highlighting issues, but showing automated issue resolution. So with that, I will pass to some bit again. Thank you. Thank you, Amanda. All right, so let's talk about the, uh, security and privacy tab. As Amanda mentioned, for to, for someone to truly trust and have that confidence in AI, securing data, having that confidence and privacy is very important. And with AI control tower, you are able to manage that data security and privacy for all of your AI systems, be it ServiceNow or with AWS. Those are the agents that we are discovering. What you'll see here is that the first and foremost important thing is to have that transparency and visibility of what data do your agents have access to. And you kind of do that through your access maps. So as you go to an access map, I can bring up a particular agent, I can look at what are the different tools that agent is leveraging. Let's take this as an example. You have access to that, you can then get information about the particular type of that tool, where it is running, what data it would be getting access to, and that helps in understanding and having that truly transparency and visibility into how your agents run. The next step is how are these agents running? Are they running in a supervised fashion, or are they autonomous? And having that visibility into what are your autonomous agents is extremely important because knowing that you are able to then set what are the right set of guardrails that you would want to ensure that the agents run within. Now digging a little bit deeper, once your agents run, you also would want to understand how are these agents running, with what access levels are they running with. Any agents that are running with an admin access would be considered privileged agents, and you get a visibility into how many of your overall agents in your ecosystem are running with that higher axis. On the other side, you would also want to know which agents are not being used because they become open doors for threats and vulnerabilities. So with the eye control tower, you will be able to also get to how many agents are dormant. The next step is the guardrails that Amanda was talking about. With that, we would be able to bring in guardrails around, uh, things around what is offensive content. With Guardian, you can identify different types of offensive content in terms of either toxic toxic content or inappropriate content. You could flag that, you know how your agents are performing. And the other piece that is also equally important is the sensitive data. So you would want to understand, are your agents processing or handling sensitive data, which could be PII. In this example, we, of all the data that we have collected, we have not identified it. But again, having visibility into that becomes extremely important. And then if there is sensitive data, uh, detected, you would also want to have anonymized. We would then capture that information as well. All of this information is great, but you really want to make this actionable, so what we then offer is insights. So as your insights run, and this is life, so let's see how it comes across, uh, so with that you can see there are things that are working well, what are the areas that need attention, and anything that is particularly actionable, we would be able to drive that as well. So by bringing together the inventory, the governance and the life cycle that we talked about, and then completing it up with the security and privacy, with AI control tower, you can actually have your full oversight and governance for AI in the enterprise. Now, Amanda is going to talk a little bit more about how we talk, uh, get to like the sensitive data and, uh, managing that as well. OK, great. Thank you. So, AI control tower is all about governing and securing and managing AI across the enterprise. But what about when you're building AI specifically on the ServiceNow platform? So we truly believe that security is absolutely essential, just as it was in the cloud era. It's even more essential in the AI era to be able to trust the platform that you're running your AI on. That's why at ServiceNow we have invested in multiple layers of platform security to give our customers the right controls of the security and privacy of their data to be able to bring that data to the to ServiceNow. So things like I talked a lot already about identity and access controls, but also things like security center to give you visibility into the into the posture, the security posture of your ServiceNow deployment. Then for customers that need even more and really want to make sure that their data is secure, we have ServiceNow Vault. So let me talk a little bit more about that and why it's super important. So a lot of people think about service now as, you know, our roots, IT service management. But of course we've evolved, um, a lot since then, being a Fortune 500 company, serving multiple different kinds of use cases out of the box, like CRM, like security operations, vulnerability management, employee workflows, finance and supply chain. Like you name the C-suite leader, and we pretty much have a product for them out of the box. Not only that, but. The power of ServiceNow platform is its customizability, so you can really fulfill almost any kind of use case you want. In fact, I had one of the, you know, top 4 US banks tell me recently, I, I love the ServiceNow platform because I can achieve in a few clicks what my colleagues can only dream about. They're talking in weeks or months to achieve certain use cases. But of course, with all of these use cases comes more and more types of sensitive data. So it's very important to be able to ensure that you have the right visibility and control over this data. That's why we created ServiceNow Vault, which is a unified console to help you know your data, protect your data, and monitor your data. And this is again very important because ServiceNow is in this uh I think very strong position in the AI era of bringing together the data that we already have. Now the AI and the workflows to truly be able to automate work across the enterprise. And of course, not only are we helping to secure AI, but we're using AI to help make security easier. Uh, these are the products that are included involved. I won't go into too much of this cos I'm gonna show you in a demo, but data privacy essentially helps you find not just personally identifiable information, but really any type of sensitive data. Multiple layers of encryption can be applied either at volume or at the field level. We can apply granular access policies. We have near real-time export of log data via Kafka stream to your, you know, your security log monitoring tool, your SIMs, or whatever your log analytics platform of choice is. And we provide code signing to ensure code that is being deployed out to your IT assets in your network is secure and untampered with. So let's take a look. So here I am in a ServiceNow instance. I'm going to start at the vault console. Now we already have a good understanding of the out of the box applications. So we are able to we we know that this instance has a couple of pre-built ServiceNow apps. So I'm gonna get started. And here I can see that based on our knowledge of the data model, we have suggested data classifications. Now of course as a customer you can review these data classifications and make sure they adhere to your company policies and your local regulatory requirements. Adapt them if needed. But providing you're, you know, you're good with these classifications, you simply need to check agree. And apply recommended classes. So very simply, within a few clicks you're able to classify the data of an entire application. So of course we're not just um finding data via data templates, we're also using our um we have pattern-based matching, we have out of the box templates. And we also use AI to detect personally identifiable information. So once you have found the sensitive data, then you have various different ways that you can protect this data. So. One of the ways is anonymisation. It could be that, hey, this is something like a credit card or a social social security number that I just don't want in the environment at all and I'm going to redact it. Or it could be that you're cloning all of this data to a lower production environment. And you want it all anonymized. You want the developers that are working in those lower production environments to have a very real world like uh environment in terms of the shape and size of the data. But you don't want them to see the actual sensitive data. So that's a a a good use case for anonymisation. You can encrypt. This is a good compensating access control and it also ensures an extra layer of security against insider threat access against the cloud service provider privileged access uh users. And then the third type of protection that you can apply is zero trust access. So these are above and beyond. These are like dynamic access policies that you can apply to specific sensitive data to when the risk, you can, I'll show you an example, but let's let's write a policy here. So I'm going to create a policy for confidential data. I'm typing very fast And I'm going to apply this to all of our confidential data for CSM case management. And the policy that I'm going to apply here is that I'm going to enforce multi-factor authentication. Because this is highly confidential data, I want to make sure that the user really is who they say they are when they're accessing this data. But a couple of other types of policies that you could choose to apply are if the user is in a specific or, you know, in or out of a specific geographic region, in or out of a specific IP range, we can also use Risk factors from the single sign-on, so from the likes of Octa for example, as a factor. So you can dynamically change a person's access, based on their risk profile, either at the time of logging in or using continuous authentication. So with this, I can see for this this table of classified data, what protections have been applied and what's still available to me. So now I can see that the zero trust access policies have been applied to this table. And just like that within again within a few clicks I have the ability to find my sensitive data and ensure that it's protected. Now we're not only detecting data that's written in tables, we're also doing this with real-time data. So whether it's in now Assist, our AI powered um uh chat, or email, for example, you can also detect data in real time. So with this I'm able to again very quickly find and protect the data. But that's not all. Um, as I said, we're also using AI to make it easier to protect the data. So I can chat with Now Assist and say, can you write me a new. A new filter to detect, for example. Uh, zip code and it will, uh, we will choose. Generate custom data pattern and it will help generate that regular expression for me in case I don't know how to write regular expressions. They're not that hard, but you know, not everybody knows how to write them. Um, and it will also test it for me and. I can just say looks good and I can apply that. So now both in I can use that both for again written data or real-time data detection. So that's how the Vault console helps you find, protect, and monitor your sensitive data. And this helps you ensure that data in the ServiceNow platform is kept secure and private, is aligning with regulatory compliance, uh, and, you know, really reducing your risk and enabling you to bring more sensitive data to the ServiceNow cloud. And really this emphasizes that with AI control tower and with ServiceNow Vault, you have security, privacy and access controls really baked in. Uh, and not bolted on. And the reason why this is ever more important is because again, those boundaries between internal and external IT are starting to blur. Um, with ServiceNow workflow data fabric that is connected to the AWS data lakes. You know, we're operating on the data as if it's in ServiceNow. So it's again super important to be able to ensure that you are able to monitor the access of AI agents, be able to detect sensitive data, be able to do this for external AI, and to have those security policy enforcements and guardrails. Thank you. Hope you have a great conference. Thank you. Thank you.