---
video_id: 95xCRSsevaY
video_url: https://www.youtube.com/watch?v=95xCRSsevaY
is_generated: False
is_translatable: True
---

Hello everyone, thanks for joining us today. Um, so nice to meet you all. My name is Shani Cazaz. I'm a go to market specialist for containers based in, uh, Madrid, and with me, Petro. Uh, yeah, hi, my name is Petro. I am senior solutions architect based in New York area. Uh, thank you for coming to our session. Cool. So, Now you are going to help us to solve one of the most Asian debates out there. Are you ready? OK, so I like dogs, Petro likes cats. Who is better? OK, so probably you think that I'm going to ask you to raise your hands, but no worries, I'm not going to ask you to raise your hands. We are going to do it in a proper way, and we are going to do it using a voting app. Now, Let's OK, cool. So our voting app is having, uh, has 5 components, 3 different microservices. And then one database and a cache. So, the microservices are going to, we are going to deploy it using Kubernetes and And the post, and the database and the caching. We're going to do it probably with a different tool, right? So how much time do you think it takes to deploy this app with those 5 different components? So, with Kubernetes, it's going to be probably a few minutes, right? We're going to do it using helm chart. But what about the database and the cache? How much time it will take us to deploy those components? So let's break it down. So if I'm working in a big company, And I need to deploy those components. I will probably need to use some pipelines, right? I will probably I need to go first to the networking team to uh, to use the networking pipeline to get things like the VPC, the subnets, maybe an IP address, right? And then I will take those uh out uh the outputs that I'm getting from the pipeline, and I will take those and I will put them into, and I will use with, uh, I will use the infra pipeline. To get my database. And if I'm lucky enough, I will get the endpoint and the credentials in the same pipeline, but if not, I will probably need to use different ones. Then with those output, I will need uh uh to put them into the pipeline that the platform team created for me to use the EKS. Now, if I'm lucky enough, everything worked smoothly at the first time. But as you know, when you are using tools such as Terraform, they sometimes fail without any good reason, right? And they need to do everything all over again. So this process can take a full business day, right? Kubernet has just turned 11 and we still need to deploy those components, probably a full business day. And what the developer does in this full business day, it will probably just wait, right? It needs to wait to every pipeline. And now let's assume that everything worked perfectly and everything is good. Some companies have uh also the compliance pipeline, which just makes sure that everything is compliant with the organization standards. What if the pipeline runs and decides that my RDS is not compliant? It will probably uh delete this uh RDS, right? And if I'm lucky enough, I will know about it, but if not, I will just get some errors and I will need to figure out. What happened? So Yes, so now we can understand why it can take on average a full business day. So if we are summarize it, pipelines are not composable, right? I need to connect between the different components. They are not self-healing. Once the compliant pipeline deleted my RDS, nothing will launch it again. I need to do it by myself and. They are not, they are not keeping the state, right? Where is the state? Is it in the infrastructure as code? But in the infrastructure as code I have a database, but the compliance pipeline deleted it. So maybe it's in the execution files, but which one? Because the, the, um, infra pipeline went, it went smoothly. It launched my RDS, but then the compliant pipeline deleted it. So where, where the state is? And if you're thinking that Gen AI is going to solve your problems, garbage in, garbage out. If you will feed the Gen AI with a lot of mess, it will probably create much more mess. So That leads me to think, are pipelines the right tool right now? They are not composable, they are not self-filling, and I don't know where the state is of the whole system. Let's think about a different uh tool or concept that we can use. Let's try to think about APIs. The whole internet runs with APIs, so why not to deploy our infra using APIs? So I want on the one hand that the different teams will create the infrastructure as code. Separately, they, everyone will work independently, and I wanted to go through one place, let's call this place a Gitripo, and I want from the uh other hand that the developers will consume those capabilities that the different teams create. In one place using API. And if I'm thinking about a technology that allows me to create APIs, Kubernetis is a really powerful mechanism to do it, right? I can create different APIs and I can do it using controllers. Controllers are the basis of Kubernetes, right? In Kubernetes, I'm declaring what I wanted, what I want the desired state will be. I'm not saying how Kubernetes will do it. It just does it. I'm just stating what I want it to be. And the controllers uh uh doing the magic behind the scene, and they are making sure that the current state and the desired state are the same. If they are not the same, they will act upon it and will change the infrastructure. And since version 1.16, I can now create my own uh APIs, my own custom controllers, right? So I can actually build anything. Now, today, there are also controllers to order pizza. So why not controlling my cloud resources, right? OK, but, but the question that I have. If I can write a controller, should I? Well, I need to write it, I need to maintain it, I need to update it. So, let me introduce you to ACK. ACK is an open source that developed and maintained by AWS. Uh, and it basically allows me to deploy and manage my cloud resources within, uh, from the, my Kubernetis, my, uh, my control plane. Just like other Kubernetes objects. So cool, now I can deploy my Kubernetes resources with my cloud resources in minutes, so we solved the problem, right? But I, I do have one question. Now. I need to have a lot of control, a lot of controllers, right? How many controllers do we need? We need a controller for the EKS. We need a controller for the IAM. We need a controller to the VPC. We need controllers to everything and also the Kubernetis controllers. So Prato, how many controllers do you think that we need to have? Very, very good, very good question, Shanny, um. I think like in reality it looks more like this. Multi-region, multi-environments like development, testing products, so you have a lot of, a lot of stuff, um, and, and this saga continues, so you have Organization scale, more tools, more, more resources, hundreds can be clusters and, uh, and it's not specifically with like ACK tools, like with Terraform, you can reuse models, but uh it's as as we scale, it, it's harder to manage this, uh different pipelines as Shani mentioned, um, and distinct state stores, uh, it does not offer like central view, so. This problem become more evident. Uh And like, it's not only AWS or cloud resources infrastructure. What about like some third parties like you connect your telemetry, like various things, so there is much more even to this. And in the beginning we promised something. Simpler, right? You know, it doesn't, does not look that simple. Um And this is where Crow comes in, right? This is new open source project and I like to think about this as all-purpose glue for Kuberneti's resources. Short timeline about here, so, uh, AWES open source in November 2024 in Cecon conference and shortly, uh, like in two months, actually Google and Microsoft, they joined the project, uh, becoming like a steering committee and main interns, main interns, and, and this is honestly like, I think first open source project where like all three major cloud providers become involved from the This early in, from the beginning of the project and it progresses quite fast, so if it's not exciting enough, in September, Roy actually moved to Kubernetis SIG oversource, right? So essentially paving the way to become like core feature of Kuber Natives, not just another open source project, right? Just core, core feature of, of Kuber NIS. So, as Shani mentioned, right, before Crow, for example, so you have Each controller standalone controlling different aspects of this, right? With Screw, we can rely on Kubernetis uh API management and essentially create composable uh abstractions and group different resources together. Kubernetis, cloud, short party resources, you name it, any. Any resources and crew enables us to reuse like outputs from one component to, before creating other. so what Shani mentioned the problem to retrieve the database ID or secret or VPC IP addresses, so now we can do this everything. Uh, automatically with scroll, right? And let me, uh, tell you about like some core features which makes them special. Uh, there is, at heart, there are 3 core capabilities. Um, so first of all, Crow provides really human-friendly and straightforward way to to define your CRD SEC, your API, uh, under the hood, it uses simple schema. Uh. And schema this schema is under the hood, it automatically generates open API3 schemas, but for you as end users, like this simple schema is much easier. So those who, if you have experience with open API 3 schemas, you, you know, it's far from human friendly, so to speak, to read. Uh, Another one is Crow incorporate cell, um, for defining logical operations, and this is the same, uh, expression language that Kubernetius itself uses, for example, for web hooks. Um, it has, it's very simple. It has, uh, advanced AET features like write time cost budgeting, and type checking, um, and with this, you can define your, uh, like dependencies and pass values from one resource to another. Um, and another one, so Crow automatically constructs, uh, directed, uh, a cyclic graph, uh, for this composable orchestrated resources, and, uh, it figures out the way in which resources should be provisioned when, so you don't need again to kind of take care about this and think about this separately. How it works. So when you install Crow controller in your cluster, and it's install custom resource definition, uh, which is called resource graph definition, right? Uh, and then, like platform, like security database team, they can collaborate and create essentially this custom API, uh, composable, right? Uh, and then it will be instantiated by Developers and reused in the cluster and Crow uses standard Kuberneti's reconciliation pattern, right, so it's observed, so after controller is in place, CRG is registered, right, so it's observed if there is new. New resources of this type or if there are changes to resources, then it compares state to desired state, creates updates or deletes if necessary. And uh this, this ensures essentially those like constant reconciliations what Sonia was talking about like self-healing, so if somebody changed, it will reconciliate this. Uh, this is how it looks, so this is like a resource graph definition, like, it's also very familiar for all Kubernetis, people who are familiar with Kubernetes, right? Like uh any resources, there is actually three main parts, metadata, spec, and status, right? So, um, Spec itself consists of two main parts schema. This is where you define your API and as you can see here, so in the schema, specs, this is fields which end users will be able to configure. You define for them status, this is what crow will populate, right? So this is for passing these values between other resources. So when, for example, OK, database and point is ready and it's reflected in the status. And you define what fields users can configure default values. You can define default values. You can define validation rules. For example, you can set port ranges, for example, can be only in this range, right? So if they will try to define something else. Compatible, it will not work, right? Resources section, this is you specify your resources with variables, default values and variables, and as mentioned, so yes, this combinations, this can be directly Kubernetes resources like port deployment and grass can be cloud, can be third party resources. Um So what it gives us at the end, right? So from going from this, right, so developers can go from this to this, right? So this is our Vote application. This is not RGG, right? This is this final what, what developers are now GLN increase, instantiating instance. So this is very simple. You just give name, um, remember those conditions are supported. So for example, here it says res enabled true. So if we say this, OK, the application is exposed to the world, right, using load balancer. You can say false, it will be just internal service, right? But all other like structural components, architecture remains the same. Same for cash, you can say enable through, you don't want cash in this case, disable the rest of you don't need to change anything else in template. Right, so this simplifies this a lot. Uh, and as we already build it, um, you mentioned, so yes, we will not ask you to raise your hands, but We still want to solve debate, right, so I would like to ask you guys if you have phones, if you can. Go actually and vote, so help, help us to solve to figure out like That that was original, right? So we, we still need to solve debate, so despite explaining how we solved it, we, we would like to solve it. Uh, we also would like to share some extra resources with you, right? So if Everybody voted. OK. So we have a few more, so this is actually crow. Website, like where is documentation, so we will encourage you to go check it. Uh, um, it's open source, you know, we are an open source, so you are welcome to contribute as well, contributions are accepted, um, and everything, so this is very, very dynamically uh involved project, but you really can be involved here and, you know, help shape the future of Kubernetis Resource orchestration. Uh, From AWS side, we have, uh, also a lot of, uh, we have skill builders, there is a lot of free, even if you don't have like AWES account paid or, uh, so there is many, many free courses and, uh, this QR code leads specifically to like containers-focused topics, so you might, you might find it interesting as well. Um, and let's, um, Let's see who won, who won Petron or me. And by the way, in the meanwhile, um, please, uh, use your app and vote and, and do the survey for this, uh, session. This is really, really important for us and it will be super helpful. OK, 21 votes. Cats are cats are better. Ay ay ay. Well, next time, next time you will choose the right answer. Oh yeah. Thank you very much for attending our session and we all, all, no, it's what we do in AWS always, we, we work backwards from customers, so your feedback is crucial, so, uh, we would really ask you if you can spare a few. Moments to uh complete sessions through wins app. This really helps us and helps us to create like content like this, other content, we see what, how we can improve. We take feedback seriously, so we would really, really appreciate um if you can spend time on this. Thank you so much. Thank you.