---
video_id: tyjc6Mknacc
video_url: https://www.youtube.com/watch?v=tyjc6Mknacc
is_generated: False
is_translatable: True
---

Perfect. So before I start, how many of you guys are developers? OK, cloud architects. Let's say responsible for any type of application or infrastructure. OK, quite a few, so perfect. My name is Luis, er, last name Giddygay that's why he didn't want to pronounce it. He didn't know how. So I'm based out of Miami and my role is I'm the head of infrastructure solutions within AWS. The idea of today's session is to understand how you can build applications and systems that are reliable and efficient. So for that, and this is gonna be annoying. So number 1, there are 3 very important concepts that most people, especially the 1st 2, they tend to kind of combine or mix resiliency, reliability, and efficiency. So resiliency, the ability to recover from a crash, OK? That's simple. If you have a problem, if something crashes, the way you recover, that's your resiliency strategy, OK? It could be seamless, it could be 5 minutes later, it's up to you, but that's resiliency. The next one is reliability. Reliability is everything you can do to prevent a failure. So the more you spend on reliability, the less you have to worry on resiliency. That's simple. And the last one is efficiency. So the concept of efficiency is when you're building something that thing, it's supposed to do what it needs to do, consuming the least amount of resources but still meeting your SLOs, OK? Your service level objectives. Now, the last two, the way to do that is through performance testing. So what is performance testing? By the way, according to Gen AI, that's me. Same shirt, just different shoes. So. Think about me as the application. Think about the car as the workload, the number of users, the number of transactions, whatever, so that picture was taken in a very specific moment of time, but what happened if I put another car on top of me? What happened if I try to walk? What happened if I get to walk for how long or how fast? So. For how long can I hold that card? All those questions are things you have to answer in the context of performance testing, right? So it's the ability of understanding how your system or your application will behave under different load conditions. That is performance testing now. Most people when they talk about performance testing, they only say low testing where in reality, low testing is just one type of performance testing you should be focusing on. And let's say that you are a company with a million customers, right? 1 million customers is the expected load. That's why you should always be prepared no matter what. So that's why emphasis on the word expected. The next one is stress testing. There are two ways to approach stress testing. One is, I want to find my performance degradation point or my breaking points, right? Because especially if you're doing end to end testing and you have a lot of endpoints in your scenario, different endpoints might have different performance. degradation point, for example, your, your database may be able to support more requests than your HTTP server and your API, you know, one might be able to do more than the API number 22. So all of that. The other way to approach stress testing is. Based on my expected load, which let's say a million, can I go 2 x 5X, 10x? so stress testing is all about finding those limits. The next one is endurance testing or soap testing. How many of you guys are Java developers or were Java developers? OK, quite a few. So in development or in general, if you are going to have a memory leak, that memory leak will not happen in the 1st 2 minutes. It will happen after an extended period of run time. So that's why it's very important that when you're doing performance testing, you need to understand. And not only if you want to hit capacity, but for how long can you sustain that particular load because especially if you're running, you know, a massive event and that massive event happened to last 3 hours, you gotta be prepared for at least 3 hours. Next one is actually pretty simple. It's just scalability, meaning that if your peak, if your goal is to be able to support, let's say a million users, you wanna make sure that from 0 to a million you can scale, and this is under the assumption that that's gonna take a few hours or maybe a few minutes, you know, to go from 0 to a million. Now the next one I actually like this one a lot for two reasons. Number one is. Most people think about scalability only, but what happens if you're, let's say, running a promotion and that promotion starts at 9:00 a.m.? What's gonna happen is that at 8:55 you will have probably 0 people, maybe 1000 people on your website. But at 9 it's gonna go from 0 to a million in less than a minute. So you need to do that, especially if you're doing things like auto scaling, whether it's Kubernetis, ECS, auto scaling group, or whatever auto scaling technology. You wanna make sure that your system can auto scale fast enough based on the demand. Now here is, here is another cool fact about spike testing. A lot of people only measured on the way up, but what about on the way down? Those sudden changes are very important to analyze and understand when you go from 0 to a million in a minute, but also when you go to a from a million down to 500 also in a minute. You wanna make sure that your system can downscale appropriately and your application itself can handle that reduction in workload. And the last one, and this is where you take the picture is volume testing, OK? Volume testing is all about understanding how your system behave on the massive amount of data being ingested or read. You can apply this to like you know your database files uploads and so on. And by the way, it's not one or the other, right? You can combine all these tests also based on what you're trying to achieve, you might want to do one or the other. And here is a cool tip a lot of people, they do this only once before they launch. In reality, you should be doing load testing at least load testing on a regular basis. So, Once again, why performance testing? Number one, you can scale and deploy with confidence, no more no more guessing. We have an impressive amount of compute offerings and database offerings. So the easiest way to know which one is the best one for your particular workload is test it, right? And that's how we do performance testing. The other one is reliability and efficiency. As I said, the more you spend doing performance testing and focus on your reliability strategy, the least you have to worry about a resilient scenario. Yes, you cannot prevent a flood. You cannot prevent a fire, an earthquake. There are major events that you will always have to be prepared for because there is no way to prevent it. However, in. There are, like, different opinions on what the number is, but it's a significant two digit number, the amount of outages and failures that could have been prevented by just doing performance testing. Better experiences whether you are e-commerce or you are providing an infrastructure or an application for your internal, you know, employees, it doesn't matter. You wanna make sure that your site or your application or your API responds in 3 seconds or less, otherwise you are losing that client, you are losing that customer and the last one is cost optimization. So If you're developing or launching this particular site, you go, let's say small, medium, large, right? You do a small size, you know, whatever environment, and you get a 5 seconds response time. OK, let me try medium. Again, you are measuring this by doing performance testing, right? You do medium. Oh, now you're getting 2 seconds response time. Perfect. What do you do next? You go large. OK, now I'm getting 1 2nd response time. Awesome. What's next? Let's go in extra large. Oh, I'm still getting a 2nd response time. Let me go to Excel. I'm still getting a 2nd response time. At that point, what's the sweet spot? The sweet spot is large. Why? Because you are still getting that 1 2nd response time maybe that you are going after, but you are not oversizing your system. When you should be doing performance testing. I usually tell this joke that if you are in IT and you are responsible for either code or an application or infrastructure, and you are breathing. You should be doing performance testing. Whether it's before a major event, whether it's, you know, through unit testing because you as a developer, before you pass that, you know, milestone, you wanna make sure you test it, whether it's through infrastructure changes. How many of you guys familiar with Graviton, for example? So quite a few, right? So if you're running on X86 and you wanna see, huh, I wonder if I'm gonna get any performance gains by switching to Graviton, that's how you do it through performance testing. And once again, do it early, do it after, and do it always. I said a few minutes ago, you know, if you have if you have an application that, you know, on a daily basis you wanna make sure it's behaving the way it's supposed to, you know, set a baseline, do a low test every morning or every day, identify what's the baseline, what's the sweet spot, right? and then that's your baseline and then on a daily basis run it. You want to measure and you wanna know when that application behaved let's say 5%, for example, could be 10% up to you. Let's say 5% is slower than usual. You want to investigate what happened, why that particular day that you know, performance is 5% slower. Now let's say that tomorrow it's 10% faster. Do you think you should investigate? Exactly right you should because most likely something was supposed to do something and it didn't do it and that's why it ran faster that particular day. So that's why having a baseline doing daily or often performance testing is extremely important. What to measure number one percentiles. Percentiles is basically what tells you how the consumers of that particular application or that particular API are experiencing that service and this could be a human, you know, experiencing that particular service or could be your system calling an external API or one API calling another API, but that's what those percentiles means. You don't wanna go for 100 again that's kind of up to you, but 100 give you like everything like how every single response is being handled. You wanna go for 95 99% because that's what's telling you is that let's say 95 95% of the service request or request to that system, that's how they are perceiving the response. You want to look at transactions per minute. You want to look at transactions per second. You wanna look at bandwidth. You wanna look very important at how, especially if you are launching a distributed, you know, a launch, let's say that. You have a global site and you're expecting traffic from Japan, Europe, Latin America, you know, North America and so on. You wanna make sure that latency not only from one single region but globally and this is why. Most people that do performance testing today, they, they, they do it from a single region. That's not a real test, right? Why? Because you're measuring, like, from your garage into your kitchen. No, you wanna see what happened from another neighborhood, from another city, another country, and so on. Errors, no need to explain. If you have an error, you go see what it is and why. And last but not least, resources, especially if you're going to root cause analysis, you wanna see what's happening with your CPU, your memory, and so on. There are 3 very common popular performance testing frameworks, and I'm gonna go really fast now. J Meter has been around forever. It's really good, really complete. If you are into Java XML JAL, go use it. If you are into. JavaScript you can use K6 from Graffaa again. It allows you to basically develop scripts or testing scripts using JavaScript and the last one, if you are a Python developer, you can use Locus now and this is where we AWS come into place. If you wanna use each one of these, most likely you will have to deploy your own infrastructure for that particular, you know, framework however we at AWS we have a solution called distributed load testing on AWS. It's an open source solution fully supported by AWS. And quick difference compared to AWS services is single tenant. You have to deploy it in your environment, use it if you no longer want it, you just remove it. We give you a cloud formation template that within 5 minutes is up and running in production. So let me actually show you how it works. By the way, Recently announced as literally just a few days ago this is version 4, well 401 to be precise, when you deploy this solution, this is what you get out of the box. You you don't you don't have to build, you don't have to code, everything is ready to be used. I'm gonna do a quick test and this is a test that I kind of pre-created just because of time. Let's say that I'm a major, you know, er, sport vendor provider and I'm gonna do a test because something's gonna happen tomorrow and I wanna make sure that my assistant can with return the the the load. So the name of the test is Global sport Global Test. I can run the test now, once tomorrow or a week from now, or I can run it on a weekly or on a daily basis or if you don't want to use the web UI, you can actually use your CICD pipeline and call all these tests through the APIs. So I'm gonna run it now and I'm gonna use live data and this is what I was telling you. You can use a single HTTP endpoint, or you can use JMor, Kasic, or Locus within this single platform. You don't have to deploy three different environments, just one for everything. And I'm gonna keep it simple. I'm gonna do a single HTTP endpoint. You can play with, you know, K6 scripts, J meter scripts, and so on, but here again, I'm gonna keep it simple. Now, this is where it gets really cool. In real time, if you want to do a test that's a global test, this environment is set up for 4 regions. You can do it for as many regions as you can, but if you want to simulate real traffic coming from all over the world, this is how you do it. The solution in real time is going to go global. To all those regions is going to spin up all the infrastructure you need for that simulation. It's going to hit your endpoint and when the test completes, it's going to go back, clean everything up, and that's it. You don't have to worry about managing any any kind of infrastructure. Now, I'm doing 4 regions, and I'm gonna say for each particular region I can do a combination of how many unique IP addresses, how many concurrent users, and so on. So again, I already have all this data set up. And I'm gonna say I want this test to go from 0 to whatever total is, let's say a million in 1 minute, and when I hit 1 minute, I want to stay there for another minute. So I'm gonna hit next And then wrong. By the way, I'm using the WiFi from the venue, so it's not the fastest one. So what you see now is that region by region is telling me like OK this is how many unique IP addresses or containers or tasks I wanna use this is how many virtual users I want to simulate on each one and this is kind of what's happening. I'm provisioning all those tasks or containers and eventually when they start running we will start seeing all the traffic going into the system. And I need to finish this in 1 minute 36 seconds. Now, this is gonna take a few seconds, but I do have another test that's already running. OK, there you go. Come on, please. There you go. So There you go. Here is another test that I started right before this session. You see that this is the average response time. This is all the successful requests. Those are the errors. By the way, Errors is because this is using out scaling and I made this environment in a particular way that is gonna show me those errors to tell me that the instances are too small and I'm triggering, I'm triggering the auto scaling event too late so that's why those errors and that's kind of how my ramp up is going up and eventually when I hit my goal it's just gonna stay flat for let's say uh one hour. And if I go back to my other test, still going. It's gonna take a few more seconds, but because I don't have any more time. I'm gonna go back here. And I'm gonna say guys, if there is something you wanna do either maybe not tonight because you're gonna go to dinner or to a party, but maybe on Monday when you get back home, deploy the solution, test it within 5 minutes it's up and running in production, and if you have any question, I'm gonna be at the AWS village from 3 to 6 p.m. doing a much deeper demo into the solution. Thank you very much.