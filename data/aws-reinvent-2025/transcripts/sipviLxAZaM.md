---
video_id: sipviLxAZaM
video_url: https://www.youtube.com/watch?v=sipviLxAZaM
is_generated: False
is_translatable: True
---

We're gonna cover um a topic that's often neglected in observability actually. um so I want you to imagine as we go through this talk, this is a er relatively straightforward case study. You guys hear me OK? Oh like so many thumbs up, this is great. OK, um, there's positivity. So one of the things that really comes up very commonly is um. Organizations talk about things like observability being very, very expensive. They also talk about things like the value being unclear. Um, super interesting industry because, uh, often there is a budget for observability. It's, it's fundamentally really important. It's very difficult to operate the software that drives our businesses and and our bottom line without it. So we know how essential it is, and yet we still feel it's very, very expensive. Um The theory here, and I think it's, it bears true over and over again, is that actually it's not really about it being too high a price, it's that the value is unclear. Um, and so what this talk is kind of an example, taking probably some of the most um. Unstructured, uh, like simple data that we can take and apply a few different transformations and enrichments, and we end up with something that can be carried all the way to our C-suite and we can tell them about it. A message that can be carried across the entire company. And that is a fundamental component of business growth. We'll talk about how information flows through a company, we'll talk about the um the importance of technical events and what they actually mean across the entire company. And once again, I'm I'm talking about very simple data here for a reason. This is what you can do with even the simplest data in a few lookup tables. You can imagine what can be achieved when you have full APM traces, logs, metrics, when you can correlate those things together. You can tell a much, much richer story. So. Quickly, about CoreLogix, um, we were launched in 2017, um, the platform, uh, has grown massively. I've been at CoreLogix for about 4 years, um, and in that time we've gained thousands and thousands of customers. Um, big thing, 8 high availability regions including GovCloud, uh, and we are FedRAM ready, so we are gonna go, uh, fully approved, uh, uh, mid next year. Uh, so we're going through that process right now. Uh, the high availability regions mean that we have multiple deployments in these regions. That includes if you have a European presence and you have GDPR requirements, for example, we have European places, we have East Coast and West Coast deployments in the US and as I mentioned, GovCloud as well. Um, super important, of course these days, data residency, uh, regulations are becoming tighter. Um, so yeah, and, uh, you know, raised a great deal of money in in funding and now we're moving to the stage where we scale, uh, and we start to think more deeply about what the customers need. Um This slide we bring out a lot um and it's super, super interesting. So, um, one of the things that I think really sets us apart as a company is uh is the platform is awesome, but the support and services are really next level. Um, this is most aptly exemplified by this, less than 32nd median response time. That's no bots, no um L1 engineers, it's straight to a person whose whole job is to figure out what the problems are in observability stacks and help you fix them. But the engagement goes beyond that, and this is kind of what a part of this talk is about, um, the engagement goes beyond just problem resolution. It's, it's what are your goals and how can we move you towards achieving them. Um, less than 1 hour median resolve time. To give you an idea, the next fastest, um, response time is about 3 hours. So a median response, a resolve time right now is faster than the, uh, response time SLA of our closest competitor. Um, and there's no tiering in the solution either, so there's no enterprise packages or anything like that. There's just, uh, charged by gigabyte ingested. If you ingest 1 gigabyte, you get this. This is something we've scaled, and that some of you have gone, hm? And the reason why is because you wonder how will that scale, how are we gonna scale that kind of thing. When I first started at CoreLogics, uh, 4 years ago, we had about, I think it was about 2000 customers, just under. Um, and we used to advertise a 5 minute median response time. Uh, now it's over 4000 customers and, uh, and we are less than 32nd median response. We've actually got faster as we've scaled. Um, it's a big, big thing with automation internally, uh, heavy documentation, but we have over 80 people in our support organization and we're a company of 600. Ultimately, one of the things we identified was a big problem in this industry and that the support does not match the importance of the software. Observability is becoming like a core pillar of how we run our businesses. It's becoming a really important part of how we operate and grow, not just our software, but our practices as teams. Many of us will be thinking about things like service level objectives. We're thinking about high level table stakes metrics to make sure that you can, the teams can make autonomous decisions within sensible uh frameworks. All essential for scaled software engineering, all powered by observability, and without the observability, very, very difficult to achieve. So that's the reason why we offer this support, because it matches the importance of the software, matches the importance of the application. And of course cost optimization support, so um we have some of the best cost optimization tools in the market, um, and we can talk about those later. Um, and the migration times are crazy fast, you can check the case studies on the website, but we have multiple like 24 to 48 hour turnaround times for full stack, logs, metrics and tracers from very large engagements. Um, that's largely powered by our commitment to use open telelemetry. Uh, open telemetry be, uh, we'll do a show of hands. Anyone familiar with open telemetry? In this crowd, I imagine it's gonna be pretty uh, yeah, yeah. So open telemetry for the one or two hands that didn't go up is a collection of um software collectors, so it's a collector that actually captures the telemetry. Uh SDKs, so it goes inside your code base and it'll help you generate the telemetry you need to generate. Uh, standards and protocols, so standards and protocols like the OTLP protocol, uh, which is the, um, the actual like. The the actual informational protocol that communicates the telemetry, logs, metrics and tracers, profiles, security events and so on up to an OTLP compliant collector, much like CoreLogics. CoreLogics is fully Otel compatible. Um, in fact, our APM and our tracing is Hotel native. Um, so there's no, uh, some of the other vendors, what they do is they say they use Otel, but when you use it you lose a bunch of features or something. Uh, that's not us, you get full feature coverage with Otel. Um, that's how we run that, and it's been very, very beneficial. It means the migrations are really easy. If you're using your hotel today, it's typically a few lines of conflict in your hotel conflict. It's very, very easy. Um, very briefly about myself, um, I, my whole background is SRE and software engineering, basically. Um, when, when I, when I told people I go into software engineering, they asked me if I can fix computers, and they didn't know how to explain to them that most of it is breaking computers, um, and it's great fun. And the, um, yeah, and then I moved into engineering leadership, um, a very, very large retailer in the UK. I was responsible for $100 million of cloud and on-premise infrastructure. And uh my job was to try to coalesce around tools, especially hosting and observability tools, uh, helping, I think it's 2500 engineers across hundreds of teams in, I think every time zone, um, trying to get them all on the same line was, was interesting. And uh I realized at that point that what I should be doing is evangelism, because that was more or less my job anyway. Um, so I tried a few different roles and I landed at Corologics 4 years ago. And since then we've grown the evangelism program. We have people uh in the States, in the UK, um, in Tel Aviv, um, where we are constantly going to customers and just talking to them and hanging out with them and working out what the problems are and saying, well, what, you know, what's, and it can be anything from. I can't get this configuration to work, this hotel configuration isn't playing nicely for me, or my teams just don't understand service level objectives, and I'm struggling to get them on board with it. And we engage across that entire thing, and I'll talk a bit about that later um with the maturity model that we've made that helps to contextualize that. So The premise of this talk is very simple. There's a common, common misconception in a company, um, which is that there is the tech side, and then there's like the businessy side. Hansel, have you seen that before? It's like, yeah. Like tech tech in a room somewhere and and business are off doing businessy things. Um, the problem with this misconception is that, um, it, it's just not, well, fundamentally it's just not true anymore. Uh, it maybe was true a long time ago when tech was a niche part of the company, but now it's a horizontal enabler for everything. Um, companies that have the best tech compete better in the business. It, it's all mixed together. Um, but the problem is, is that many of the tools that we use to measure and track events, um, and correlate instances of things happening, um, still operate with this in mind. There's like a techie interface, and there's a business interface, and so on. The problem is the siloing of information is really difficult. It causes big problems. You cannot correlate across siloed information. You can do it, but with great difficulty and a lot of manual work. So getting everything to one place is very important. And the, the problem with this assumption fundamentally is this, um, if you have a CTO, an engineering director, engineering manager, and some technical event has happened, then it kind of goes up that trap, and it only really makes its way out if it's important, significant enough, quote unquote. But the definition of significant enough is often not codified. Uh, marketing insights make their way up to the CMO, but they don't really go anywhere else. And sales insights often make their way up to the chief sales officer or the chief revenue officer, and they don't go anywhere else. But I, as an engineer might be interested in the sales insight, because it's something a customer said. It might actually be quite interesting to know what, well, we don't do our sales process this way because the product doesn't facilitate it. That's interesting. As an engineer, I wouldn't know that. Um, I might have a marketing insight, the drop off on pages, the bounce rate on pages. These are all things that marketing teams tend to measure, but they are technical measurements that apply across the entire company. And so how do we change this flow of information? So what we don't wanna do is we don't wanna end up um in a situation like this, where we kind of rely on just ad hoc collaboration, which is most companies, like vast vast majority of companies. Why don't we wanna rely on ad hoc collaboration? It is basically, it's based on the goodwill and the friendship of a very typically a very small group of people. Um, for any of you who've will do a final show of hands, this is my favorite thing to do. Um, who's been in your company, in your current employment, er, one year or more? Yeah, 2 years or more, keep their hands up. 3 years or more? 4 years or more, 5, we'll jump 10. Yeah, OK. Thank you. So if you've been in there 10 years or more, you start to pretty much know everybody. And you, it, it stops becoming about following processes, like, oh I know, I know the person. So that is an ad hoc engagement. Um, and there's nothing wrong with that, it's great to have that as a natural thing, but it's not the bedrock. The bedrock needs to be the flow of information naturally is making its way across. And the way you do that is by joined up tooling. So you, you wanna avoid that, you wanna try and get away from this. And when we think about software events, they, these technical moments, they impact everybody. OK? If I have an API slowdown, then it is going to impact every single portion of that company if you're a technical company. Because if your API is slowing down, your pages load slower, your uh marketing the, the landing page that your marketing team just set up may may load slower as well. There may be ripple effects across your entire stack. Really important. So the really, really important thing to recognize here is these technical moments need to be surfaced in a way that's really significant. Right now, they tend to go up that technical track, right? If I see a CPU spike, I get told the CTO gets told about it. But it doesn't make its way out horizontally in a natural way. It's not common anyway. So how do we do something in practice? That's all the high level stuff. How do we actually take a very, very low level simple signal and turn it into something that we can communicate upwards? Let me give you an example. Uh, we have a log like this, it's unstructured, um, there's nothing particularly, uh, remarkable about it. This is kind of cool, by the way, this is like a log summary thing that we do. If anyone's using anyone using projects today? Yeah. You go to a log, hit space, you get this guy, it's really cool. Uh, there's loads of Easter eggs in the app like that. Um, and this will like pull out all the metadata that's automatically recognized, there's trace IDs in there for trace correlation. Um, but the log itself is not particularly useful. If you took that and you said, hey, I have an RPC not found error, and you go to someone non-technical, they're gonna be like, what the hell are you talking about? There's business context to this. This happens during a uh a checkout process. So every single time this happens, someone tried to buy something and they couldn't. That's the business context of this message, OK. So we, we can see something interesting in there, this ID on the end. And this is something we might want to filter on, so. We can take that technical signal and we can pass and extract the the really essential values, the ones that really matter. Why is that important? It allows you to index the fields that really matter, and then you can do things like query and filter, and you can aggregate on various different things, you can join and pivot. And I can show you how to do that. Um and then you can enrich. Enrichment is something that I think um I never see, and we do it a lot in the coologics platform. Um, what is enrichment? Enrichment is when you have some kind of field, and you say, OK, but I have tons of metadata around this ID. And I wanna add the metadata into my log. Now why do you want to do that? Because then you have a single document with all the context that you need. That's really important for like in-depth analysis. And finally, um, you can convert that data into something useful. And what I mean by something useful, I mean something that you can take, and you can take all the way up to the sea level and say, hey, this is a significant thing and here's why, and they will understand it. And that's the flow of information working in a less ad hoc way. So You can um you can begin by creating a lookup table. So in CoreLogics we have this idea called data sets. OK. Now a data set is a bit like a table in a database, it's a collection of similar data. Doesn't have to be all the same structure and shape, uh, but it's it's similar data. It doesn't have to be time series. So this is a lookup. Now notice the ID on the left hand side looks much like the ID we saw in the previous log. So and we have a bunch of product information here. So what can we do with that? Well, this is a lookup table with which we could enrich. So what we can do is use our language called Data Prime. So Data Prime is an analytics language that we use. Uh, it, you can query logs, metrics and traces in a single query. Um, it supports all the things that you would expect from something like SQL. So joins and filters and aggregations and counting and so on. In this particular example, what we do is we take that custom data set, product details, and we will join the original log on it. And notice here we've on the fly we've extracted the product ID as a field onto itself. So now we have a product ID in its own field and we say, hey, join on that and give me everything from that lookup table that's relevant to that ID. And that turns the original thing into something that's a bit more interesting. So what I can do is that once I know the price of the item, and I know it was a checkout process that was failing, I can start asking questions. How much money are we losing as a result of that? OK? So when you go to your boss and you say, I have a not found RPC error, that's tough to say. If you go to your boss and say in the last 15 minutes we just lost $1500 due to this bug, that's a compelling message. That will, that will take people's attention. So this massaging and preparation of data is really, really important for a number of things. Now I'll double click on them. One. Um, once you get your data into a more, let's say, organized shape, I think one of the things that we did in observability for a long time, um, don't remember this, this is an example, um. If I I the the common pattern was, and in in many places still is, it takes some data, all of it goes into sort of high performance index storage, open, open search with a uh SSD hard drive underneath it, something like that. And then after like two weeks, it goes into some sort of low cost storage compressed. If we ever want to access it again, we have to go back to low cost storage and pull it back out. And And the the assumption of that is that all of the data is equal cos it's all being treated in the same way. Uh, which is not true. Some, some logs only become useful after a certain amount of time, some traces are only are only useful for 10 seconds when they happen. Um, so we have to treat data differently. So what we can do here is that one of the really, really fun addition is that this is actually being queried directly from S3 as well. This is actually all held in customer cloud S3, which is a significant detail. Um, so that's really important because now I have a business insight, it's something that I can take to people. Um, I can communicate it to anybody, and it's really easy to do. So why are we doing this? Why am I stood up here talking about business insights as an SRE? Um, because I've just started with a very simple log. Now imagine what you can do with things like a trace. It's got a bunch of metadata on there that you've added in. And because we're using an enrichment model, we're not talking about going and changing 500 applications to make sure a correlation idea is making its way in there. What we're talking about is taking the stuff that's already in there and saying, oh, I can enrich on that. If this tag relate relates to this particular server, I can enrich based on that server. If it's based in a certain region or a department or any metadata that exists, I can enrich on those fields. And so the enrichment model amplifies the fields that are already there. And if you want, you can add more at source. And the reason why I'm talking about this is because um we've built this thing, it's the observability maturity model. Um, it's broken down into 4 different levels. Um, there's something really significant about this, we are bringing this to every single one of our customers. It is a North Star vision for how observability is moving forward. Um. Level one is essentially er telemetry coverage. It's getting a stack of er full stack telemetry, so logs, metrics, tracers, profiles, events and so on. It's basically just getting coverage for the stuff you've already got. Uh, why is that level one? It's very, very difficult to progress in this with massive gaps in your data. And a big problem today, uh, especially with a lot of the vendors, is that people make these massive cost optimisations by not sending logs, for example, which is tough. It makes, it makes causal analysis very, very difficult. Um, so avoiding those gaps is really, really important. The next level is engineering intelligence, and this is where most of us get to. And what we describe 1 and 2 is like a generic problem. So uh engineering intelligence is things like you have a telemetry, you coalesce it around your databases, or your infrastructure, or your servers or the the processes running on your servers, and so on. Uh, super important because this is the, uh, almost the gold standard for uh for SRE today is, um, defining SLOs, consistent measurements across teams, that kind of thing. And This is where there are observability maturity models out there today, and they all stop here. And and one of the things that we realized was there is this big problem that I mentioned at the start of this talk, which is that the feeling is we're not getting enough value out of this data. The feeling is is that we're not getting the return that we expected. How do we maximize the return that we can possibly get as engineers, but also as people working in a business? How do we connect these deeply technical signals to business growth and business impacting measurements? What we do is we start, start to say things like, well let's take all that engineering knowledge and put it into a production context. Production context means rather than just saying my API has breached my 500 millisecond SLO, it's what was the customer impact of that? And those, that's where things like APM become really, really useful, because you can actually measure the thing over time. But Data prime, and I showed you before, allows you to crunch all that data in new and custom ways. The the necessity of a really flexible, really rich query language is, is, is fundamental to the whole process. It's very difficult to get this done without that. And the, the second thing that's really, really important as you're moving into the later parts of the maturity model, is you have to have access to a significant portion of your data. Without it, it's, it's really, really difficult. If you, for example, as many of the customers I've spoken to do, they don't produce traces. It's just too expensive or it's just not scaling for them or whatever, um. We can, we can have a really, really good go at this, but it's hard because the tracers give you a really good visibility of how the different services are talking with one another. They help you identify bottlenecks and performance issues. Root cause analysis is really a lot easier with tracers. Um, much like without logs, by the way, there's a lot of talk now about removing logs entirely from the whole thing. I understand that, um, I think logs are great for causal analysis. Having just metrics, for example, you can tell you what's happening, there's a CPU spike. It's very difficult to understand the why, and logs often have the context for the why. But that, so having that data in the first place is really important, that's why it's level one, without major gaps. So we've taken our engineering knowledge, we've put it into production er context, and we're saying things like, rather than just SLOs, what does this mean to the customer relationships? Have we breached our SLAs? Um, and that's really, it's so useful, you know, you can imagine a VP of engineering or a sort of CT CTO level who's getting pressure about these things, can go to a dashboard and analyze that directly. It's not some derived calculation or something they're told about. And one of the practices that some of our customers have started doing, which I love, is they have started to define SLOs and then SLAs in the same dashboard, and they've defined their SLOs as a little bit of a padding between their SLAs. And so the SLOs become a leading indicator for breaching their SLAs. Super cool. And that's a really, really nice example of applying this kind of logic. So reproduction intelligence, there is the level 4. Now, 12 and 3, I think stand alone in the sense that they're about responding to incidents. If there's an issue, did we breach our SLA? If there's a problem, what was the impact to the customer? Level 4 is different. Level 4 is where you just go deep diving into your data to find stuff out, like we just did. So I, I, we said before, this is just a background hum error that's happening. There's no major outage, there was no spike or anything, we just started investigating stuff. And this is, this, the power of Data prime here is that we can. Like enrich it and decorate it with enough information to produce a business impacting insight, really, really important. Um, so the business insights there is about basically turning this, um, disparate collection of technical signals into something that anything can use. And I, uh, before I mentioned there were two reasons why, so I've talked about the maturity model. When you're getting to this point, is any of you, uh, looking at like AI agents or anything like that around your telemetry right now? Any hands? Yeah, so it's cool, we're getting there slowly, yeah. So, um, one of the most important things when you're using like any kind of agentic interface with your telemetry, there's a lot of telemetry. And your agent has a limited context window. There's only so much you can look at at one time. Well organized data means that your agent can decide, make decisions about which part to look at. So we have Ollie, for example, um, which is our, um, observability agent. It, it knows how to query logs, metrics and traces, it'll do full root cause analysis. Um, when you organize your data into things like data sets, as I mentioned, it knows where to look, it knows to go and look at data sets, or it knows to go and look at certain fields and so on. And by organizing your data, your AI tools actually have an easier time of making this ana analysis. That's really, really important. And people often think that like organized data is for people and all if it's not, it's for anything that needs to communicate it. Uh, we, we don't often spend time organizing our telemetry. Um, and I think it's, it's often seen as not necessary. But when we do it we get so many er benefits from it, and it's really, really significant. So we've mentioned that level 1, level 2 are about coverage and engineering insight. And level 3 and 4 are about putting that engineering insight into the context of your business. Um For those of you who don't know, our company goal, our mission is to help companies make better decisions. That's right at the top of this thing. Now if you have, if you, if you wanna start this journey with your observability data, you need a platform that has the necessary features. Um, there's a reason why we're, a lot of the industry is coalescing around things like APM and ROM, uh, security monitoring, infrastructure monitoring, log analytics, and so on. You need a platform that has all these things. Otherwise it's very difficult to get ahead, it's very difficult to make progress. Um The first half of that maturity model is mostly about the data. In fact, I'll show you. All of this, if you look here, it's kind of mostly about the data and getting it into OK shape. And the second half of this maturity model is about practices and processes. So it's about mature data and mature teams. Uh, I was, uh, years and years ago, I was working at a betting company, and I, uh, I discovered through just messing around with some of the logs that we were losing money at 22 racetracks. And I, I remember sitting back and going, cool, and then I got on with coding. I didn't do anything with it. And um I spoke to a lot of people at the time and a lot of people had similar experiences where they found something, but they were like, well, that's not really my thing, whatever. So if someone had come to me and said, hey, you should take this to the betting manager or to a certain part of the company, that's really important, that would have been a big thing for the company. 6 weeks later, the product manager came to me and said, hey, did you know we're losing money at these two racetracks? And I was like, oh, I've never heard of it. So it's uh it's a remarkable thing. When you, the reason why we do our engagement the way we do, the reason why the Deverell team, my team. Um, engage with customers is the way they do it is because so many teams just need that extra little lift to move forward. We find that momentum in these companies is so important, and the way you do that is things like hackathons and fun engagements that are just there to strengthen the relationship with the customer, but also give the teams the effective ability to make the best use of the platform. Observability is such a niche space, I think we forget that sometimes, especially for any of us who are fans. Um, and so because we think about it all the time, we forget that most people are thinking about things like. Server up time and they just wanna keep the thing running, um, so we, er, when we get ourselves into this space, we have to remember that education is a fundamental part of observability and this kind of strategy is only gonna be powered by education and engagement in that way. That's the reason why the Deverell team, a core part of how we are measured, is the number of engagements we have with customers, the number and the creativity and the timeliness of those engagements as well. So, um, it's all well and good me saying this, um, how mature teams, mature data, driven by a great platform, uh, accelerated by artificial intelligence will get you to better decision making. Um, but it's already happening to a lot of customers. So, um, Trade Web, for example, sending us 130 terabytes of data a day. They had a business problem, which was that they, uh, their audit process was taking a very long time. And because they had a rehydration model on their telemetry. So as I mentioned before, the data comes in, they hold it for a couple of weeks and then they compress it and they put it into somewhere else. Um, and what we did was we said, well. Uh, the data prime query engine allows you to query your data as often as you like, at no additional cost, with data that's held in cloud object storage in your account, S3 for the AWS context. Um, what does that mean? You can do audit queries in seconds, not in 2 weeks turnout, 2 week turnaround times. Um, that's a business problem. When it, when I go to people and say, what does an observe great observability stack do for you? People talk about APM and service visibility. I don't think anybody has said to me, it would be great if it could help with my audit problems. It's pretty rare, but it happens and it's significant and meaningful. Um, Soft Tibet, another example, um, this slide says they're growing really fast for us. This slide says they're sending 65 terabytes, they're actually sending more like 140 terabytes to us right now. Um, full stack, logs, metrics and tracers, um. A really, really interesting use case where we, we started with uh focusing on things like mean time to acknowledge, mean time to recovery. Um, but actually we got really wrapped up in the adoption side of things, um, because we just we, we saw there was this groundswell momentum within the company, a very big company distributed, um, and so 90% of all the dashboards being used today are Cologix dashboards. That includes business people. That's the 90% of the company are using Corelogix dashboards. And what does that mean? That means the same insights are being shared across the entire company because they have a shared platform. Really, really important, um, and of course it's always nice to have your mean time to acknowledge halved and your, uh, mean time to recovery, uh, reduced by 30%. It's always a nice added bonus. Um, and we actually help their teams move faster. Uh, I don't know if anyone's like familiar with the gaming space or anything, but it's brutally competitive, and it changes so, so fast. Um, teams that are able to release software faster are a differentiator, there's a fundamental differentiator in that industry. Uh, Caltura. This was a fun one. so we onboarded with them, uh, we took a look at their hotel config and we said, hey, this is inefficient. Um, we didn't have to, it would have worked, it would have been fine, we would have got it working, it made no difference to how Coologics worked. And we spent a few days with them just rewriting their hotel config, and it saved them 25%. Of their telemetry infrastructure, they're sending us 14 terabytes of data that's about to go up, um, so, 14 terabytes of, of data processing architecture is actually a reasonably significant amount of money that they've just saved, just by working with Otel, just because we figured we're at level one. To get this right, because this is a foundation for all the way through level 4. If we were only thinking about level 1 and 2, we might just, it's fine. It's a bit janky. It'll work. But we knew we were where we want to get to. We knew what the North Star vision is, and we know it needs to be really squeaky clean at the start, otherwise it's gonna be very difficult to get there. Um, and they had a 5 9s, uh, uptime target which is, is hard. That's, that's that's 5 9s is, um, I think AWS is 4 9s, right, so it's like it's pretty intense, um. And yeah, 25% reduction in all the infra spend, that's fin-ups right there. So what does all this mean? What can we take from all of this? What we're doing at CoreLogics is we're taking a typical model of engagement, which is, uh, we help you solve problems as they arise. And we're saying, OK, we're gonna partner with you, find out what not just your technical goals are, but your business goals, and how can we turn an observability platform from a dev tool, basically, to something that spans your entire company and has a massive impact across everybody. And we're gonna do it with the same kinds of things that power great dev tools, great APM, great real user monitoring, great SIM. Great AI based query, great AI agentic experience in in the, in the forms of Ollie. These things have impact across our entire business, and that the direction of travel is very clear in that regard. Notice every single observability vendor, they're all talking about things like intelligence. They're not talking about a few years ago it was like catch bugs, and now it's not that anymore. It's now it's about business intelligence, now it's about finding problems before they happen, and not just in that context, but constantly. Constantly improving even when there are no problems. So we're we're moving past the point of, um, let's say responding to issues, and we're even moving past the point of being proactive and catching issues before they come up. Now we're just going mining for stuff. The data is there, the insights are there, it just needs a bit of massaging and a platform that can do all that in one place. Crologics has been built for this exact problem from day one. The architecture, everything has been the same since 2019. Um, we started thinking about this stuff a long time ago, and through thousands of interactions with thousands of customers, this is the North Star vision we've produced. Um, thank you very much for your time today, guys, I really appreciate it. I'm gonna hang around with some questions if you're interested, um, but I really appreciate your time today, and as the slide says, thank you. Cheers guys.