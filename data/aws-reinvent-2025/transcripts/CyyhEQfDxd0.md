---
video_id: CyyhEQfDxd0
video_url: https://www.youtube.com/watch?v=CyyhEQfDxd0
is_generated: False
is_translatable: True
---

Hello everybody, can you hear me with your headphones on? All right, good, right, cool. Let's just get a little quick show of hands. I always like to do this, um, how many of you use SFTP? Um, um, how many of you use an MFT, a managed file transfer, or responsible for delivering an MFT? Great. How about AS2, the protocol, EDI? Anyone here? OK, I see some. And how about partners here who are helping our customers with their journey? Nice. I know I recognize a few here. Awesome. Look, y'all are in the right session here. STG 339, um, helping customers modernize their managed file transfer with event-driven SFTP. I'm Smita Shriram. Um, I'm, I lead the product management for AWS Transfer Family. Joined by me, Sue, who's also the p.m. for Transfer Family and Prebeer, a principal solutions architect for Transfer. So, um, so yeah, before the, you know, afternoon slump gets kicks in, let's get started. So, um, I'm gonna talk a little bit about manage file transfer and EDI just level setting on how what that means to, to you and, and, and our customers, um, and then talk a bit about trends that I've been hearing. How those trends are informing our road map and our approach to this space, um, and then I'm gonna hand that over to uh Sue who's gonna do a deep dive into features that underpin our MFT and EDI offering. Um, and Prabir has a demo, um, showing how you can build a cloud native MFT. There's some agentic in there, so I'm not gonna steal his thunder with that demo talking about it now, and we'll wrap it up, um, you know, we won't have time for Q&A here, but me and my colleagues can meet you outside if you wanna talk more. So, so as your businesses grow, right, so does your data and data sources, you know, and in order to get value from that data you want data to be mobile. For best of class data mobility, you need an MFT strategy that can help you move data securely, effortlessly and efficiently, you know, within your organization and across. And this value means different for many of our different customers for example, right, if you're in the payments, um, reconciliation or you're a healthcare company needing to process claims and claim payments you perhaps need to interact with a clearing house for settlements or you're a producer of value added data sets that you want to sell, uh, you want a robust MFT that helps you grow your subscriber base. Many of our customers use MFT to automate their internal processes from HR to finance to payroll. Customers in, you know, health care, pharmaceutical or financial services have to regularly submit filings to, you know, regulatory bodies like the FDA or SEC, and that's where an MFT has helped them streamline those submissions. A big industry or group of industries or supply chain and logistics where MFT is used for exchanging transactional data like you know purchase orders, shipping notifications and for all of these customers building their data pipeline using their MFT data has become super important. As such, there are 4 pillars that we see that underpin an MFT. One is support for industry standard protocols. So you have a business application that resides in your environment and your trading partner's environment, and the common denominator for them to communicate are SFTP, AS2. You know, I said EDI X 12, so these data formats make it seamless for applications and users across environments to communicate. Second is authentication and access control. So you give access to data that's that your users should only be able to see and use. Processing and automation so that you can build a data pipeline from this data end to end and 4th and most important is robust auditing to meet your data security and regulatory needs. Some of the trends that I'm hearing, starting with security has always been a priority and will always be, um, you know, customers are looking for secu secure and reliable SFTP uh and MFT in the cloud. Second is tools that give them proper governance so that they're able to track audit, you know, what's happening, who's accessing the data, who has access to what kind of data. And third is simplicity so that they manage as less infrastructure as possible and make it easy to build their MFT. And lately 3 more trends have popped up. One is I mentioned automation, so they want their trading partner relationship to serve a double duty, as even as a data pipeline. So as they're transacting, they're also able to get real-time insights into that data. By running analytics, a lot of these customers are also looking to become AI ready, uh, you know, and be, you know, innovate in their own business areas. And that's exactly the reason we launched AWS Transfer Family here at Reinvent 2018. Our team has like seven years of experience in helping customers like you modernize your MFT. The service is fully managed, highly available, and scales in real time to meet your business needs. There are a lot of features that we've developed over the years that help you migrate from existing MFT systems without having to change, uh, you know, a lot where it's difficult to change, let's say your business partner integrations uh so that, so we make it easy so that you can accelerate your migration. AWS Transfer family is built on event driven paradigms so that you get get run the whole process is. Gone are the days of Daniel polling, writing scripts. Now you can plug into Amazon, event Bridge, and automate your processes end to end. And finally and most importantly, the service comes built in with, you know, industry standard compliance such as HIPAA eligibility, PCI, uh, to help you meet your security requirements. More recently we launched AWS B2B Data Interchange, which is a managed EDI service. The service helps you automate the translation, validation, uh, and generation of X12 documents. Again, the service is fully managed just like AWS Transfer family. Uh, and it's pay as you go like any managed cloud service. A favorite feature of mine is the use of generative AI to generate mapping code between X12 and your custom format for JSON and XML and vice versa. So that has really helped our customers accelerate their EDI migration using this service. So just a little bit into the resources that we provide, Sue is gonna go deeper into some of the features we've added. Uh, we offer, we started, we launched the service with SFTP servers, so you have SFTP FTP clients anywhere in the world who can connect and the files land in your, uh, ST bucket or EFS file system. And then we added a feature called SFTP connectors so that you may need to talk to external SFTP servers. Now whether they are located on a public IP or even accessible over a private network, you can use SFTP connectors to talk to those servers. Now more recently we added uh Transfer Family web apps, which is a managed web UI for non-technical users in your organization to access files stored in S3. So it's going to talk more in detail about Transfer family web apps and how you can use it to empower those business users. And look, with the files in your Amazon S3 bucket, as many of you know, the possibilities are endless on what you can do with that data. Uh, as an example is, you know, EDI processing. I want to take a moment to thank tens of thousands of customers around the world who are using AWS Transfer Family today. And one specific customer that I'm excited to talk about is FICO. So FICO, um, you know, they help customers, um, in around 80 countries globally, you know, with anything from protecting credit cards, uh, from fraud to, you know, increasing financial inclusion to improving supply chain resiliency. Now as a global leader in credit card scoring and analytics, FICO processes massive amounts of sensitive data using managed file transfer, which means security and efficient file transfer is super important for their business operations. They were using a legacy MFT, and with that, the problem was they had to manage a lot of infrastructure even when they weren't using it, which resulted in overhead and costs. They embarked on a journey to modernize their MFT using AWS transfers family, and now they've eliminated a lot of infrastructure, reduced their deployment time, uh, because now they can use infrastructure as code and also lowered their TCO. They also now can track, you know, their costs more granularly and accurately as they roll out, uh, you know, transfer family across FICO's multiple business units. You know there's a QR code there that goes into detail on FICO's MFT transformation journey. Another customer, they don't need an introduction, right? BM BMW Group, a global leader and manufacturer of vehicles and motorcycles, they were, they developed, um, a vision, sound and analytics service on AWS not to keep up with their reputation right of delivering high quality vehicles, they used AI and analytics to analyze the, you know, image and audio assets from their production line. But in order to do that they needed their camera data to go into AWS. AWS Transfer family helped bridge this camera data into Amazon S3 by SFTP, the data directly into their S3 buckets, uh, and with low latency. Now with that, now all of this data into S3, they are now able to process and deliver, uh, you know, very compelling analytics, uh, with high quality. And they store about 1.3 million files worth 1.3 petabytes in Amazon S3. Let me take also a moment to talk about our partners. We have a service delivery program where we validate partners who follow best practices to deploy AWS stands for family for customers MFT implementation. Um, you know, for example, scale capacity recently helped the city of Los Angeles save substantial costs by migrating their MFT to AWS Transfer family, and that QR code goes into detail, uh, about scale capacity and city of LA, a public sector customer. Um, another partner story that I want to share is Biscloud Experts. So they are a leading, um, you know, IT consultant and DevOps company who helps businesses empower with scale and confidence as customers innovate. So a supply chain and logistics customer approached BisCloud experts um because you know they were struggling with their EDI infrastructure because of overhead, you know, similar story with overhead and costs. Now this customer were managing about 1000+ trading partners and exchanging 250,000 messages per month. This cloud experts stepped in. Right, Developed expertise in AWS transfer family and B2B data interchange and helped this customer migrate their EDI to these services within a very short amount of time, so short they did not have to renew their license. As a result, the customer saved over a million. billion dollars annually, you know, and also not only cost savings, they also reduced their trading partner on boarding time because now they have full control over the process. So this is a great story, uh, again, another QR code so you can read about more customers who have benefited from our services. All right, with that, I'll hand it off to Sue, so she'll talk about the features. Great, thanks Smita, and it's so great to be here with you all. So Smita gave you all a great overview as to the common use cases, trends in MFT and EDI, and an overview of our service. Now in this part, I wanna talk a little bit more about some of the specific features that you can use to build end to end complete MFT and EDI workflows. We're gonna start with talking about the launches for this year. The great news is everything I talk about today will be tied to a recent launch that you can see highlighted in pink. Unfortunately, I don't have time to go into every single launch, but after this, as Smita mentioned, Prabir Smita and I will be sticking around to make sure we answer any and all of your questions, and we're looking forward to the discussion. We're gonna return to this service overview that Smiha had gone over earlier, and we're gonna use this to really navigate through the various modular offerings of Transfer family and B2BI. And here I wanted to start with servers. Transfer family servers are fully managed endpoints that eliminate the need for you to have to manage or maintain your file transfer infrastructure. For servers today, we support protocols SFTP, FTP, FTPS, and AS2. And because servers are fully managed, they're scalable, they're secure, um, and they scale to your demand, we're finding that a lot of customers like you are using servers as a foundation for your MFT whether this is for use cases like um B2B exchange or you are integrating your applications or you're managing data distribution. Now when we're talking about servers and especially if you're in a regulated industry like financial services or health care, your first priority is often networking controls, and in 2018 we launched the service with a public endpoint. And the public endpoint is really simple to set up in the console you could set this up with a few clicks, and then your external partners can start connecting and transferring, uh, files over, over the public internet to a managed host name, and it lands in your S3 bucket. And we also use this managed host name for Highvill Billy, uh, failover, and, um, load balancing as well. And also on the public only endpoint there's built in, uh, endpoint protection that that benefits you as well. But as we were talking to you, um, we started to learn from you that you wanted more control and you wanted more control over who can access your endpoint and you also sometimes didn't want public Internet at all and that's why we launched the VPC endpoint. Where you can choose to make this internal, so anything that routes into your VPC, so this is great for your internal pipelines, um, your, your users can connect over VPN or Direct Connect, and this is great if you're, you can manage access through your security groups and things like that. But what if you want the best of both worlds? You want to open up your VPC endpoint to the public Internet while you still wanna leverage the existing controls in your security groups, and you can also choose to make your VPC endpoint Internet facing as well. You can choose which elastic IPs to bind to your internal IPs, and you can still leverage the controls, um. In your VPC and in your security groups and also you can also specify non-standard ports that you may be interested in alternate ports that Transit family supports today like port 2222 or Port 2223. And also for this, I wanted to mention that a few months ago we support IPV6 for both the VPC endpoint and for public endpoints as well. So now, um, the benefit of this is with a dual stack endpoint you can support clients that are IPV6 and IPV4 enabled without having to, uh, transition to IPV6 all at once. Now that we've talked about who can access your endpoint, now let's talk about who can authenticate to them. Transfer Family today supports 3 authentication modes. The first is service manage for simple key-based authentication, and this is great for, uh, getting started quickly. You can manage, create users right in Transfer family, and you can manage your users in the console as well. We also support a direct integration with AWS directory services. So if you're using AWS managed AD or you're using AD connector, you can simply select your domain in the console and use this with your existing users and groups. This is great if you want to maintain consistent access. And then our third most flexible option is the custom identity provider or custom IDP option. There's two deployment models you can use here. You can call Lambda directly, which is great for straightforward authentication flows, and what we recommend generally, but you can also route through API gateway as well, which provides you the benefit of being able to leverage. Um, web application firewall in front of your authentication endpoint, um, if you're looking for more things like freight limiting, uh, geo-blocking, and so on. A few years ago with custom ent uh IDP we did announce the option for multi-method authentication. So now you can specify a combination of methods, um, that your users will provide. For example, you can specify key only, um, password only, key or password, or key and password. And how this would work is in the initial authentication request your user would provide the key and then the server would then prompt for a password. The final thing I want to say here is that as of a couple of months ago we made it even more flexible for your identity provider. So now on a transfer family server you can dynamically shift between whatever IDP option you're using, and this is because we've heard from you for use cases like let's say you start with a POC, you wanna get started quickly. You start with service manage for key-base authentication. Your POC goes off smoothly. You're ready to move your workload to prod, um, but you don't want to recreate your server, and that's what this capability allows you to do. You can simply shift between your IDP modes, and there's zero downtime to your users. And double clicking a little bit into the custom identity provider option. The custom IDP option as I mentioned earlier, it's our most flexible option, so it's an adapter and it can pretty much talk to any any IDP out there which is great for lift and shift without having to worry about um importing your users or passwords. But we also heard from you that you know writing your custom IDP can or writing your custom adapter can feel daunting or and you want a blueprint for your specific IDP and also your IDP rec uh you can't store um access specific information that transfer family needs for your users and that's exactly why our essay community in partnership with our service team. Launched a transfer family custom identity provider solution which is an open source standardized option that you can use and it's, it's easy, easy to deploy with SA templates over infrastructure as code and it also has several ready to use modules for popular identity providers you may already be using like Cognito, Octa, Entra. You can see the list, um, on the screen. And finally there's several built in, uh, best security security best practices built in like granular per user controls so you can specify things like IP allow listing per user or per IDP. And with this option this really gives you the flexibility uh while maintaining security best practices. A few months ago, and Prabir's gonna talk a little bit more about this, I won't go too deep here, but we, we already supported terraform for transfer family resources, but we invested in transfer family specific modules and terraform, which gives you the benefit of being able to automatically provision and deploy transfer family resources along with your existing infrastructure. And as of a couple of weeks ago we also announced terraform support for custom IDP so there's a QR code there and I'd love for you all to check it out and give us feedback. Alright, so we've talked about access, we've talked about authentication. Now let's talk about storage. Transfer family directly integrates with Amazon EFS and Amazon S3, so your users can transfer files, um, to, to EFS file systems and S3 buckets. For more granular controls, we also support um S3 access points which through unique access endpoints you you can specify permission policies and network controls. Now earlier you may have heard Matt Garman in his keynote sharing that S3 access points now supports FSXN. Well, I'm super excited to share that Transfer family also supports this integration and also supports S3 access points, uh, through FS with FSXN. And I'm really excited about some of the hybrid access patterns that this will open up. For example, your external users can continue transferring files through SFTP while your internal users can uh continue using familiar protocols like NFS and SMB. And getting started is simple. Just create an S3 access point for your FSX file system, and transfer family will talk to it just like any other access point today. And with this launch your users will be able to perform file operations like upload, download, um, delete, and copy, while, um, some limitations to keep in mind are that, uh, rename and append operations are not supported and there's also an upload file size of 5 GB. If you wanna learn more about the full list of what's supported and what's not, there is a QR code where you can read the launch log to learn more. Great, so we've talked about servers. Now let's talk about connectors. So while servers are end points that your clients connect to, connectors work in reverse. Connectors are fully managed SFTP clients that connect to remote SFTP servers. And how connectors work today is again they establish a connection to your remote SFTP source and S3. And if you wanted to initiate your connector, you would do that through a CLI or API calls. Now let's say you want to do send a file to your partner. You can simply use a start file transfer with the file path. Now let's say you wanted to retrieve a file from your partner. You just specify the retrieve file path and the S3 destination. Now let's say you wanna check what files are available to do that, you can use start directory listing to get a complete inventory on the remote SFTP source. Finally, let's say you finished processing, you wanna clean up, um, you can use remote file operations that we recently supported, uh, which is move, delete, and also rename as well. If you wanna learn more about these new operations, there's a QR code that I'd love for you to click into. And just like we support BPC for servers, I'm really excited to share that we're bringing that same capability to our SFTP connectors. This means your SFTP connectors can now connect to private SFTP servers wherever they're hosted, whether this is in shared VPCs, on premises, or in your partner environments that are accessible through your private networks. All traffic does route through your VPC environment, so this allows you to, uh, enhance your security and comply with your security mandates by traversing through centralized, um, firewalls and traffic inspection points. You present the you present the IP address which eliminates the need for your partner to have to allow list any additional IPs. And finally for heavy file volumes, you get the full performance of your net gateway. Let's talk a little bit about how to set this up. So as a quick note, this does not require you to modify anything in your existing VPC configuration. However, this does require you to set up two simple components in VPC lattice, which is a feature of VPC. So first you would create a a resource gateway and you can think of this as a bridge between transfer family and your VPC environment. Then create a resource configuration so this represents your SFTP server address. You can use either the private IP address or the public DNS name. Then your resource gateway connects your your connector to these configurations and now can connect to your remote servers through your VPC. The best part again is that there's no changes required to your VPC, um, environment. There's and you can use your existing security controls. You can present your existing IP address. Everything should just work. All right, so now I wanna shift gears slightly because what if the end user persona we're talking about is different? What if these are, you know, human users, these are non-technical users in your organization like your, your HR business partners or your financial analysts or so on, all these people. Need to transfer files to S3 and for you S3 is where you wanna be because it offers security, durability, scalability, and so on. But for your end users you want to or you need to provide an easy to use experience so that they can easily upload and download, and that's where Transfer Family Webs comes in. Um, authentication is driven through IM Identity Center, so your users can SSO or present their existing credentials that they're already using for other applications. Now user permissions is driven through S3 access grants. So with access grants you can, uh, really enable fine-grain access control. So your users only authorize the data that they're authorized to access, and they only have permissions to the data that you allow them to have. So for example, read-only access or read write access. And finally with the web app and I'll go a little bit more into the different options, but you also have a few customization options, so your web app aligns with your uh company brand. Now as to how to set up a web app, it's pretty simple, and you can set this up in the console in just a few clicks. And while you're setting up your web app, you have a few options where you can add a company logo, you can add a, a Fabicon or a browser tab icon. You can also specify the page title, which is what shows up in the browser tab that's presented to your end users as web apps is part of Transfer family, it shares compliance status like HIPAA eligibility, FedRAM, PCI, and more. And most importantly again with your end user in mind, it's a simple to use experience that's accessible through any browser that they're already using, and it's a drag and drop, point and click experience. Now, We launched web apps this time last year and in that year, like we've really learned a ton from you as to like what use cases you're using web apps for. For example, we're hearing that your finance teams are exchanging reports through web apps or you know your marketing teams are uploading media assets through web apps or your or your research scientists are collaborating on data sets through web apps. There's a lot of use cases and while they all sound different, the underlying themes are the same one. Easy to use and user experience and the second is that you're centralizing access across your workforce again using existing security controls and um identity credentials. Now if you look at this flow here, it's, it's straightforward. So you as the admin will create the web app. You share the URL with your end user. Your end user would then access the web app through the URL. And then they would SSO or present or log in with their username password MFA that they're already using with whatever IDP that you're using. And after a token exchange between your IDP and identity center, your user then lands in the web app where they're only seeing the files and folders that you've given them access to access either because of their user identity or their group membership, and then they're only allowed to perform certain actions that again through S3 access grants you've given them permission to do. The back end all file transfers are going direct to S3 and in Cloud trail you can audit all user interactions down to the user identity so you're able to see who does what. And just like we brought VPC support for servers and for connectors, I'm excited to share that as of a few weeks ago you can also enable a VPC endpoint for web apps. So with a VPC endpoint, um, we create a service manage endpoint within your VPC at no additional charge. Your users can now securely access the web app through a web browser while keeping all traffic within your VPC. So this is really important if you have like internal teams who need to handle sensitive documents and you have like regulatory or security mandates that you're trying to meet and now your users can connect directly through uh Direct Connect or or VPN or from within your VPC. You can also further enhance your security by only allowing access from approved client IPs. And again, um, if you have some mandates you need to meet, you can do that through through this feature. Now with this launch you have two flexible options for using web apps. Through public endpoints your users can continue connecting over the public Internet, which is great for, you know, if you're, uh, using this with external external collaborators or partners, um, and now through a private endpoint your users can connect through your VPC, Direct Connect, or VPN. And this is great again for sensitive workloads that might require strict network controls. You can choose whatever deployment option works for you, or you can use both depending on who the user is within your organization. Great, so we've talked about different modes of being able to transfer data through servers, connectors, and now web apps, but now I wanna shift gears slightly because what happens if you need pre or post transfer processing, especially for your EDI workloads, that's where B2BI comes in. We're seeing a lot of customers using Transfer Family and BDBI together. Um, for their EDI workloads, and here's a typical architecture that we see, and I'm gonna start from the left and just walk through. So in this architecture your trading partner is transferring files, your EDI files through industry standard protocols with transfer family like SFTP or AS-2. Transfer family takes this file and puts it in an S3 bucket. B2BI is listening to the event monitoring the bucket, and now as soon as the file arrives, B2BI is validating the EDI file. It's translating it to JSON or XML, and it's writing to transform data into an output S3 bucket. It also emits an event bridge event uh with the output location as well and the status. Then this event triggers any post uh post processing actions you might want and allows your data to flow into your business applications like your ERPs or your data lakes. If you're interested in learning more about architectures like these, um, there's a QR code where you can learn more. We launched B2BI just a couple of years ago and as you can see we've been really busy investing into the different features for B2BI, more so this year, um, as you can see, most recently we expanded support into our first European region into Dublin to now support 4 regions and if you wanna learn more there is also another QR code that you can click into. Great. With that, I've talked about some of the components that you can use to build, uh, your modern MFT systems, and now I'm excited to pass off to Prebier who's gonna show you this in action. Thank you so much, Sue. Now, building on top of some of the components that Sue and Smithta mentioned, today I'm gonna walk you through how you can build a modern managed file transfer system using AWS that leverages Agente AI. Let me quickly highlight the core building blocks. We're going to build our secure file transfer by using Amazon ABS Transfer Family. You're going to add malware protection by using Amazon guard duty. And this is what makes the solution truly modern. So instead of using rigid code, rules-based engines, we're going to use AI agents to be the intelligence behind our file processing. Tying it all together is going to be Amazon Ion Bridge, which forms the foundation of our image-driven architecture. And this is what automates the entire system. Uh, how many folks over here use terraform? Awesome, quite a few of you. So you'll be super excited to know that the demo that I'm gonna show you today is built entirely using Terraform. I will be linking the QR code in the end, so please feel free to check it out. There's some other examples that you can also build on. Now for today's use case, we're going to take a traditional insurance claims processing system, and we're going to see how we can modernize this using our modern architecture. Also, like how many of you are from, uh, insurance or financial services organizations? Can I see a few of you? So the use case that I'm going to show you today is actually quite applicable to almost all industries who do some kind of file processing. Typically we start with an ingest phase in which you may have some kind of documents like for our use case we have policy documents, images or repair estimates are are ingested in an SFTP folder. The next up is our extract phase, in, in which case most organizations do have some kind of a basic OCR, uh, and OCR is a technique for those who don't know it's uh a technique to extract text from images. The challenge with traditional OCR is that it is rigid. It only expects files and formats in a certain way. And finally our next phase or the last phase of uh our flow is the analysis phase in which typically there is a bit of manual processing you may have some kind of rules based engine that does part of the automation for you, but this is where humans have to kind of get involved and you have the human in the loop. The challenge for this entire approach is that not only this is error prone, it is time consuming and it just doesn't scale. Now let me walk you through of how you can modernize this by using cloud native architecture. Now here's our modern approach that builds on top of the core building blocks that I spoke about secure file transfer, malware scanning, and agentic AI. I'm gonna show you a demo that will be that will automate an end to end workflow of claims processing using agentic AI all powered by image driven architecture. Let's dive deep into each of those components to explore more. Our first stage is where we are modernizing our foundation. We will replace our legacy SFTP servers with Transport family, which means that there's no infrastructure to manage, it automatically scales and it's highly available. Now we want to authenticate external users, and we do that by adding support with custom IDP. These external users could be anywhere from repair shops to partners that your company works with, and it allows you to like offload and almost integrate with their identity provider and you don't have to do separate credential management. Now we want to store everything in Amazon S3 for as unlimited scalability and high durability for all your files. In the next stage, we will be adding automatic malware scanning. This is a requirement for most regulated industries to do malware scanning of all files as they land, so we're gonna achieve that by leveraging guard duty's native malware scanning capability. Guard duty offers immediate threat detection and intelligent file routing for all your files. What it means is that your clean files will land automatically in a clean bucket and any malicious file or suspicious files move directly to a quarantine bucket, all done through even different architectures. And lastly, when we talk about intelligence layer, this is where we've seen a huge transformation happening in industries that are trying to modernize their traditional file processing workflows. So we are going to be using Amazon Bedrock Agent Core, and we have Agent Core orchestrating all of our AI agents. Now the agents themselves, they can use the most sophisticated models that are available in not only in Bedrock to even from other cloud providers. So these could be from, um, anthropic, uh, the cloud models that this, these could also be our Amazon Nova models, and these in general offer a lot more flexibility and accuracy over great over a traditional CR. Now finally we wanna make this accessible to human users in a simple way. So this is where we use Transfer Fam web web UI or web apps feature that is a simple browser-based access for your end users to access these files. It is completely self-serve. It's, it has security built in, which means that it provides role-based access, uh, the right access to the right people at the right time, built on the principles of zero trust. Now let me show you all of this in action. It's probably the demo that you've been waiting for. And before I dive deep in, I wanna mention that I've broken this demo down into multiple stages. You will see that in the code as well for this demo I've pre-deployed certain stages. I have the identity Foundation pre-deployed. I've set up a transfer family server with custom IDP. I've also set up our automatic malware scanning using guard duty. Now we're starting with the dual identity system. We're using I IM identity Center for our insurance users. Um, for this demo I've created local users, but your IDC setup may look very differently. You may have already federated with another ID identity provider. You see, I have 2 users, claim reviewers and claim admins, and these are what I'm going to be using for a demo. Now for our external users I'm using Amazon Incognito to simulate um user management. I've made uh any company insurance user and you see any company repairs user is the the the entity and identity that I'm gonna be using throughout the presentation of the demo. I've also set up a transfer server, so let's just check that out in a second. And if you look at the identity provider configuration, I set this up using a custom AWS lambda, which is our custom IDP. Solution I've created a bunch of different buckets. I'm using my Uh, random page generator. So if you like these names, uh, you know, I'm glad you did. Alright, so we're gonna be using our claims file to ingest all our files, but the, the bottom three buckets clean bucket, errors bucket, and the quarantine bucket is going to be used by our malware scanning. Now to test our even driven architecture what I'm gonna do is that I'm gonna upload a file and I'm using QR CLI by the way, so I'm not typing uh SFTP commands, you know, I'm very clumsy, so I thought this is a better use of, you know, like natural language by asking Ki to do the work for me. So what I've done is that Quiro created a test file. I've uploaded this to my bucket. Kiir is also parsing logs from Cloudwatch, so it states that the guard duty scan has now been kicked in. And let's see what's happening. So the first thing I see is that my claims file, test file did land up in my SFTP bucket. If my malware protection is working as design, I should have seen this file automatically processed, and if I do a refresh, it should end up in my clean bucket. Which is exactly what you see. Now I want to test the same thing for my malicious file. So um I don't wanna infect my system, so I'm using an ICAR file which is a test file that's used to detect malware scanning. It's the same flow. I'm going to be uploading this into an SFTP folder. OK, so again, Quiros uploaded this file using SFTP. We can double check on our console. We see that this this file did land up in our SFTP folder. Now I also wanna double check if my clean bucket is intact, you know, and if I quickly do a refresh, I see that, uh, nothing's changed. I still have my clean file that I uploaded earlier. But if I go to my quarantine bucket, this is where the magic is guard duty automatically detected this as a malicious file, and it moved this to my quarantine bucket. So now that I've done this again, uh, Quiro is summarizing all the findings. It detected everything that we saw in the console, so nothing new there. Now what I'm gonna do is that I'm gonna actually deploy my stage 3, which is the agentic AI foundation layer, and this is, you can, you can, by the way, do this using a simple terraform apply. That's all that the QO is doing on my behalf. So the, the commands that you see over here, they're not something from the Matrix, they are a terraform apply, so most of you are familiar with this. That's all I'm doing right now. I want to just quickly walk you through a snippet of what my agents look like. And What you see over here is that instead of using complex logic. I'm using a very simple prompt, and if those who have used some kind of chat-based interface such as chat GPT, this actually might look very familiar. So I've actually asked this agent to do something for me. I've said that you are a claims processing workflow agent. You use strands, and your job is to extract entities, uh, validate the damage claim, insert the enriched data into a database, and generate a summary. So that is my instruction to this agent. Now the agent's gonna figure out what to do and how to do, like, and which agent sub agent to engage. Now for this demo I'm actually using two different claim files so I'm gonna just show you this in just in a second, but before I do that, let's check our agents in Agent Corp. Anybody using Agent Corte? OK, some of you, all right, so, uh, for those who are using this, this might look very familiar. I've deployed 5 different agents and I'm using agent core runtime. That's exactly what we saw, like we had 5 different agent files. For this demo I've also created a dynamo DB table which again kind of stimulates how most financial services organizations do downstream processing that you may have some kind of database that you will keep as a book of records or downstream processing of claims. I'm going to show you quickly our claims filed. That we're going to be testing So our first claim is a um, you know, a regular claim that you know of a car that had a rear bumper damage in a shopping cart shopping center parking lot. Uh, there's an estimated repair cost of $995 so just. Yeah, some entities over here and I have, uh, an image of a car that has a bum, uh, a fender bender, so very consistent with what you saw in the claims form. Now let's test this. I'm gonna upload this in the same process, our event driven architecture. We're gonna upload this into our SFTP folder. We see that's just happened and Kiro is gonna start parsing the logs. OK, it's the second phase of urgent AI was matter scanning. We see that the file was successfully, uh, uploaded into my clean bucket and the agents actually moved them to a submitted claims prefix. So again just for organization. I see the same files that you saw. Now Kiro, I've asked actually asked you to parse cloudWatch logs. So instead of going to cloudWatch console, I, I like working the ID, so that's what I'm doing, right? So instead of going to the console, Kiro is parsing the logs for me, and we see that our agents successfully parsed the entities, and now it's giving me a summary of exactly what it found. My agent says that this damage is consistent. It is 90% confident that this claim is legitimate, and it gave me a reason why it thinks it's legitimate. I've also instructed this agent to write this file to an S3 bucket so it's that's exactly what it is so it's processed the claim and it created a summary for me for my end users. If I open this file, this is the exact same thing that we saw in the ID. Right, so basically it says that there's a car that had a minor bump, uh, bumper damage. It is consistent with a claim description, so perfect. Everything's fine, great. So it can be processed and, uh, and paid. I'm going to do the same test for our claims too now. We see our claims to were successfully uploaded, so same flow, nothing's changed. I see that my agents have finished the processing and extracted the entities, and now let's look at the results. All right, so this claim is fraudulent. That's what my agent says, you know, and it's 95% confident that it is fraudulent. Again, I didn't have to hardcore any of this thing. The agents did the reasoning. Let's look at claim 2 and understand why it is fraudulent, so I'm just going to quickly open claim 2. If I look at my claim form, uh, it's a form that states that this car had a minor front bumper scratch in a grocery store parking lot. There's some more description about the scratch itself. Uh, the scratch is about 3 inches long, um, and so on and so forth. Now if I look at the image of this claim. Do you guys think this is a scratch? Probably not, by the way, no cars were harmed in creating this demo. This is all AI generated. It would have been a very expensive demo otherwise. Awesome. So, uh, remember I, we created Dynamo DB tables. So my agents, one of my agents also ingested meaningful entities again. It knew exactly what to ingest into a dynamo DB table. So very consistent what we saw. We have two claims. One has a consistent damage which is, uh, labeled as true, and the others as false. All the entities that were extracted by a claim form and other metadata. Now all of this is great, but we want to make this data accessible to human users in a simple way. Your human users or your business users, they're not gonna log into Quiro and check out this data, and they're probably not gonna log into the Obi console. So this is where we're gonna be deploying the web apps functionality. So I just did the same thing. I created web apps using Terraform. And we see that the web app has been created. I'm going to log into the web app using its access point. And I'm going to use the two identities that I created in the beginning of the presentation, which were my claim reviewers and my claim admins. For my claimed reviewers, I've given them read-only access. And let's see if they have indeed what I I define in infrastructures code. As we see that our claims reviewer only have access to read these files of our process claims and submitted claims again very consistent with what we saw. We see there are 2 claims from our S3 bucket and just to double check, I can download this claim. And this is exactly what we saw, but instead of going to the console typing SFTP commands, this offers a very simple interface for end users. I also want to test the same thing for our clients admins. And for McClaim admins I've given them rewrite access to the entire bucket so they should idly see if everything is working as designed a little more than what we saw for our claim reviewers. Perfect. So they see the entire bucket. They have rewrite access so this is working as design, um, we see all the prefixes that were in the bucket and just to test that they have rewrite access, I'm actually gonna delete this claim file. Perfect. So if I do a refresh, I see that there are no files, so again this is working as design. Now many of you may, you may have some questions about agents, so I just wanna maybe double click on how I've created these agents. So Agent Core is a foundation over here that's orchestrating all of our agents and I've built all of these agents using strands, uh, anybody familiar with the strands? OK, some of you are so strands, for those who are not familiar, it's an open source SDK that, uh, that we built, built by AWS that really allows you to create agents in a very easy and flexible way. Fun fact is that all of these agents that I built, they were created in 5 minutes or less using QOCLI, so lots of prompting, um, yeah, and I just wanna walk you through like what these agents are doing at a high level. So we have our entity detection agent and I've actually asked it to detect entities, extract entities from my PDF. I have my validation agent that has uh a multimodal that is able to extract entities and read the text and also compare it with my image so this is what's doing the fraud detection, right? um, and this is what kind of gives the score that it's 90% confidence or it's, it's the validation agent's product. Our summarization agent is creating a meaningful summary that we all saw in our S3 bucket and also through web apps, and our database agent, uh, ingested all these records into a Dynamo DB table. Now the brain behind all of this is our supervisor agent. Remember the prompt that we saw earlier? You guys are familiar. So the prompt was for my supervisor agent to decide which agent, which sub agent to work at invoke at what time. So the patent, the reason why I'm showing this is because this patent is not only applicable to insurance, but it can be applied to any in industries, any use case. So whether you're in payments, whether in hospitality, whether you're in healthcare. This kind of shows you how you can take a file processing workflow, use agentic AI to transform, um, your file processing workflows, add intelligence to it by using agentic AI. Now before I wrap up I wanna emphasize that what you saw isn't just a demo. Everything that we built is powered by our terraform transfer family module. I have given the QR code over here so if you wanna grab it, please feel free to do so. Today we saw that we deployed a transfer family server. We deployed custom IDP support with it. Uh, I set up malware protection, agentic AI, web apps, and this is just one of many examples that we have in our terraform transfer family module. They're all built around real world use cases that you can deploy and use right away. We launched this module only a couple of months ago and we've already had over 10,000 downloads and I just wanna call out and thank the amazing solution architects that have been contributing to this module but also external contributors such as you. We've actually had a lot of external contributions so if you're there in the room, awesome, thank you. Um, we do maintain a public road map. So if you like what we're working on, please do a plus one on that so we know where to focus on, um, but if you, if you think that is anything that's missing, please do create a GitHub issue. My team and I, we review these feature requests daily, and I'm like actually super excited to see what you will build using these modules. So with that, I'm gonna pass it on to Sue. Thank you. Yeah. Awesome. Great demo for beer and so excited that this is all supporting for so I can do it later. So for this we are just gonna wrap it up with a few resources and next steps for you all. So hopefully from this session you are able to take away how simple it is to create a secure and modern MFT system using transfer family B2BI and like Pabir's demo showed you're able to see how you can unlock innovations using agents with transfer family as well. As for availability, here are all the regions that Transfer family is available in today. Um, all recent regions are highlighted in pink. At reinvent, if you want to learn more about transfer family and even rebuild what uh Prabir just showed you, here are some sessions for you to check out as well. And finally, here are some resources with QR codes for you all to save for later. So we have our user guide where you can see, uh, end to end tutorials, guidance. Here's our website where you can learn more about our different offerings and most exciting to me is a self-paced workshop that's hands on so you can, uh, get your hands dirty and build event-driven MFT workflows for yourself. With that, thank you so much and please reach out to your account teams to connect to us. We're looking forward to talking more with you. Thanks.