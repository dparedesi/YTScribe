---
video_id: oYpCvqZk9SQ
video_url: https://www.youtube.com/watch?v=oYpCvqZk9SQ
is_generated: False
is_translatable: True
---

Good morning everyone. Hope you're having a good, good morning and welcome here. Uh, we'll try to make this morning go even better for you. To start, I wanna um Give an example that Jeff Bezos gave uh in uh in 2005 when he was giving a lecture to business leaders. He gave this example of um in 1857. The commercially produced toilet paper was introduced. And ever since, it's really difficult to imagine to go back not having it. That had that much of transformation. So I think AI is like that. Um, it's a tool that once here, we, it's gonna be really hard for us to imagine going back and not having it. I certainly one of them, like I can't imagine doing things without it now. And so So today we'll talk a lot about it. My name is Igor. I run application observability in AWS and co-presenting with me today is uh Shiva. Solution senior solution architect at AWS and uh Mutu, senior director in CCC Intelligent Solutions. And we'll be diving in a topic of having AI in your applications and being able to run your business when AI is in it. And then as well as using AI for your own operational productivity. So, we'll cover those topics. Here's the common challenges we've continued to hear. We've heard them a lot before. We continue to hear them now from customers like yourself. So applications. Increasing complexity. There's more microservices, and these days with agents, You're gonna have agents crafting SQL queries to your databases you never imagined existed, right? So, It's ever more important to understand the end user and the customer impact when AI is, is introducing new things in your applications without your developers even designing it and programming it, right? Number 2 is standardization. So we heard commonly is, it's really difficult to operate multiple services and organizations when everything is different. Everybody invents their own metrics, their own log line, their own ability to represent the transaction. And so, not only reduces your productivity, but also affects uh mobility of your um of your, you know, your engineers among teams. When they join your team and everything is new and everything is different, then productivity is lower when they go on call and understand what's going on. The third thing is um ability to prioritize. So, not every anomaly affects your end users, and so it's really important to understand what actually matters and what doesn't when they, when they happen, right? AI is helpful, quite a bit, but usually, you need to give a little bit of a guidance to yourself or even AI to understand what is really important, which is a customer affecting. incident and which isn't. The fourth thing is just joint experiences. Multiple tools, one tool for logs, one tool for traces, another one for metrics, and everything is uh uh disjoint. And so when there is a spike of uh latency, it's really hard to understand what caused it, and you spend a lot of time uh going into a different tool or understanding how to, you know, Um, share context and, and, and correlate things. So those are the common challenges, they don't go away when we start to apply or introduce AI in applications. Uh, moreover, today, um, the entropy in your system is limited by ability of humans usually to make mistakes and, you know, maybe sometimes you have bugs, you know, um, checked in and so on. Um, or ability of, you know, humans to create traffic against your website, your digital business. And so now with AI that velocity of that entropy is gonna just increase, right? So, as I said, AI can just decide to use new tools, create new dependency that you didn't have, right? Based on some question that somebody asked, your end user asked. So it's ever more important to deal with these challenges. So a couple of years ago we've introduced Application signals in cloud which To address these challenges and, and be able to, you know, manage applications, manage your business transactions. So what it does, it provides discovery of your services, discovery of applications, the dependencies. It standardizes operational practices around, you know, how to look at daily audits of your services, what's important, what isn't important. Things we actually do ourselves and AWS for our own services. Service level objectives that allow you to prioritize and declare digital journeys, like mobile users logging in, you know, making payments, like that's important to you. Um, and an ability to correlate with between metrics, logs, and traces in one unified experience so you can do root causing immediately without jumping between the tools. How does it work? Um. So we collect telemetry using open telemetry for the managed services like lambda, EKS we embed that into our runtimes, into our managed services. Otherwise, you can just simply take as the case. And agents and then collect the telemetry needed for the, for this to work, uh, including agents. So we collect the same way we collect telemetry from open source agents that are implemented in length chain or, you know, strands and so on. Um, we vend open telemetry for you, so that it's security scanned and, you know, in, in a package that has all the security elements that allow you to authenticate against AWS services very easily and so on. Then telemetry gets collected either through cloud witch agent, which is open telemetry agent. Um, but we put a lot of improvements in it, in order to compress telemetry, to make, you know, adaptive sampling work, a lot of, um, uh, things that help you with cost of telemetry. Or you can send it directly to open telemetry and point that we have, right? So, either way, you know, you can send us telemetry. It gets processed and collected in CloudWatch and X-ray. Think of it as one product. Uh, where we, you know, derive topology, we compute the metric for you, and so on, right? And then application signals is just an experience that allow you to, you know, look at your transactions, look at your uh application map, look at your, you know, anomalies. Uh, including now agents. So, what are the 3 things? So the 3, the 4 things that are important about application signals, um, this year is, you can see a complete picture of your application even without instrumenting it in many cases. I will show you that in a demo. Um, so we reduced a lot of manual work required to even understand dependencies, right? So even if traffic isn't flowing, we know it based on metadata and configuration. Number 2, you can organize observability of the way you work. And what we mean by that is, we automatically detect applications, we group things by connectivity, we group things by similarity of names, similarity of attributes. But we also allow you to tell us how you want to see it, like your business unit, your teams. We can organize applications by the way you are working. So, we'll show you that in a demo. And then number 3 is, you can resolve issues in minutes very quickly using automatic operational audits. Like the things that developers do daily, we do them for you, uh, on the back end. So we audit every dependency you have, we audit every latency you have, every API and we derive the necessary insights for you to quickly address what, what is important, right? Without digging through and figuring out yourself. We also do change orders. So we detect changes in an application, your new deployments, and understand what part of it is affected and that you have a new dependency because of this deployment, for example, right? We'll show that in the demo as well. And 4, force and very important is that you can connect this tool to your own AI productivity tools. So your own AI, you know, whichever one you, you choose, your agents, you can connect these operational tools, and they're designed, our MCPs and, and so on. They're designed. To help AI to be productive. So you can save tokens by not scanning, you know, the telemetry 50 times for the same, for the same question. We provide tools like these operational audits, the change audits to the agents, so it can get productive. So Here's what's new this year. Number one, in application space, we Instrument AI agents with open telemetry, we allow that to, you know, to flow into the system and for you to see agents in your apps, how they interact, what they do, you know, what databases they use, what users they respond to. Number 2, we do automatic app discovery. We used to do just a flat list of services. Now we group them into meaningful units that we understand you may have automatically. We also allow you, as I talked before, for you to tell us how you want to see it. Declare an attribute and say that attribute is my business unit name, so every time, just please show me by business unit. So we'll allow you to do that. Uh, we support uninstrumented services, um, for ETS and things like lambda, API gateways, you know, many different services that comprise your application, even without any instrumentation or any agent withdraw the maps, we understand dependencies. We provide operational health audits, change impact audits. We now have cross account application maps, so you can see apps or parts of your application that are, for example, shared an accounts or calling across multiple accounts. We support automatic application discovery and instrumentation in IKES clusters without you actually having to install anything. So we would, in a safe manner, we will go and put code in the right places so we can instrument services running in IKES clusters for you. We now support adaptive sampling. We used to do just fixed sampling. Which allows you to do cost effective observability. Where the sampling rate will increase when there is an anomaly and you need to know about it, right? We also support exemplars uh on things like dependency, so you, if you sample, we actually take important things and we put them on the side for you uh to inspect later. For AI ops, uh, we released MCP servers, um, that, as I said, all the tooling that we provide for humans, we provide them for agents, so agents can be productive with operation and observability of your applications. We also launched the GitHub action. That allows your developers to leverage all the production, you know, telemetry to improve code. We'll do a demo of that. Real user monitoring, we expanded it to cover mobile, iOS, and Android. We now support source maps which allow you to understand the exact log um uh code line. Uh, even if your, um, you know, web, uh, JavaScript code was minimized. And then we support open telemetry ingestion for all the mobile. Uh, telemetry. Uh, in synthetics, we support, uh, multi-browser tests, so you can have one task doing all the browsers, uh, for you at once. Uh, we support Java, um, uh, we, synthetics, you know, we used to support all the languages and Playwright and Selenium and Puppeteer Um, now we support, we added support for Java. We allow you to have dry runs, so you can have a dry run of your canary before you put it in production and see what it, you know, what it would do and how it works. We now support small, you know, tiny API checks or just, uh, you know, ping checks in an efficient manner. And then now we have region parity in all the commercial regions, and then we support GovCloud. So these are the new things that we've introduced this year, based on the feedback and You know, um, The request that you guys made, basically, right? So now, to see it in action, I'm gonna invite Shiva on stage to show us uh all of this working. Thank you Shiva. Thank you, Igor. Hello everybody. Uh, my name is Siva GuroRadier. Welcome again to the reinvent. So I will be showing you, like, you know, a couple of demos on, like, you know, the latest and greatest features with the application signals, but let's take a step back, right? Customers want their application to be performant and available for the end users. For that, they want their, uh, observability to be centered around the way their teams work to make maximum impact for their end users, right? We listened to all these feedbacks, and uh so that's what we are going to show you in the last one year, whatever we have approached in this application signals. So, we automatically do operational audits on your application APIs as well as dependencies in real-time, pinpointing root causes, so that it is going to be like, you know, a time saver for your on-call engineers. So with every trace, you might be wondering like, you know, trace is more of a technical thing, how you are connecting that with your business insights, right? So, every time when you're sending a trace, and then when you wanted to convert that into a business insight, let's take an example of a GAA agent, right? So GAA agents have their own minds, and you wanted to understand like how their minds of GAA agents are working. So in this case, like, you know, with this application map, so this is a new feature we have added. So in this case, like, you know, you can have your custom grouping. So currently, I have my application level grouping, and when I'm searching for my breaching SLIs, it's coming up with a bunch of tiles. So continuing with the same demo, like, you know, we are going with the PET clinic application. So in this case, like, you know, I'm running some bunch of uh PET clinic agents, and currently you, you could see it is breaching an SLI. So instead of going into the weeds, like, you know, figuring out like, you know, locks, metrics, and traces, I just click on view mode and using the operational audit feature, it's easily seeing like, you know, there is a dependency availability issue. And then I can see there is a fault rate increase with this one, right? But I wanted to understand like, you know, what's going on here. So there is a sample trace link over there, and then I can click on it and then it will take me to an X-ray page wherein every bit of information is seen. So the customer is coming into my pet clinic front end, and then they're calling the pet clinic agent. And in the spans timeline, I see a couple of exceptions. So this is the very first exception, and this is where, like, you know, I'm seeing the exception that is being shown in the UI. But let's take a step back again, right? Because we are talking about GII agents. So I wanted to see and understand what is going on with the pectinic agent. So currently again I click on that view exception and this is exactly telling me like what is the exception, where it is coming from, which line number it is, which file it is. So these are valuable information that I can feed to my development team to fix it but again gene agents are different, right? I wanted to send the context as well. So my developer's life will be easier if I can send the context in addition to the exception message, whatever I'm seeing here, right? So that's what like, you know, the feedback we listen to you guys and then we have this LLM event tab. So this is exclusively available for GA agents and from here we are sending all the context. So these are all the context we are sending to the agents. And not only that, when that exception happened. What is the exact question that customer has asked, so we are capturing that information as well. So, using all this information, it is easy. Like, you know, currently, I can take all this information, and then I can send to my GA team, and then ask them to fix it, right? So let's move on. So, the Pet Clinic application that we have is so popular that we have launched mobile application, both iOS and Android. But I wanted to understand, like, you know, how my users are perceiving this user behavior from my mobile application. And we are happy to introduce, like, you know, we have added mobile RM Future recently, like, you know, like, like the last two weeks back. And currently, if I go to my pet clinic, Java, I do see, like, you know, there are 3 different app monitors, one for web, one for Android, and one for iOS. So from the looks of it, my Android is not doing good. And when I'm looking into the details, the right drawer comes in, and then I see like, you know, more than 300 crashes. So I want to understand, like, you know, again, what's going on here. So I do see like, you know, from my pet clinic Android app monitor. Many of these scratches are coming from only one screen, called Wornu details. So I wanted to fix this ASAP because I don't want my mobile users to be disappointed. So I rarely go to this particular place, and then from here, like, you know, I'm taking a random session, and from here, the exception is clearly seen, including the line level details. I just copied this exception. Let's use it later, but before getting into the technical side of the house, I wanted to see what is the user impact. I want to go to the impact analysis. From here I can see, like, you know, in the last 3 hours alone there are 240+ users are impacted. So there's a pretty serious issue, right? And I just want to fix it. Let me open my Android Studio. Fix the thread dump whatever I got from my application signals page and that's pretty much it. It's gonna be pinpointing like, you know, exactly where it is failing and from here looks like, you know, we are only receiving only one attribute, but we are processing three attributes so that's what the exception is saying. So for now, like, you know, I just delete these two attributes that I don't want to it because I just wanted to ensure, like, you know, this is exactly the root cause. So I just delete all the things which I don't want to edit, and then I'm running in my local environment. So in my emulator, my application loads up and I go to that exact same screen, on a detailed screen, which was crashing earlier. Now it is no longer crashing. So with this feature, like, you know, if you're running both mobile as well as web applications, with the application signals feature, real user monitoring feature, it's easy for you to figure out what's going on. And then when there is an issue, it's easy for you to fix it, right? So again, like, you know, let's move on with this one, right? Maybe show me your hands like if you're running applications, some of them could be like, you know, not instrumented, some of them could be instrumented, and you want an easy button to see like, you know, hey, if I can have an easy button to just enable my instrumentation flow, that would be awesome, right? So how many of you are thinking? Yeah. So, again, we are happy to introduce, like, you know, in addition to the instrumented flow, uh, we are adding, or we are showing you the both the instrumented as well as an instrumented flow in our application map. To prove the point, like, you know, I have two different exact similar application. One is called ticketing light, and another is called ticketing. So the ticketing light is not instrumented. That's what you are seeing, uh, showing in, uh, our dotted line. So I wanted to understand, like, you know, why there is an SLI breach. So not only we are showing you not instrument uninstrumented applications, but also like you know you can create some SLIs on top of it. So that's why you are seeing like, you know, there is an SLI breach. So from the looks of it, it is calling a bunch of services which is not having any interaction at all, and I don't know like, you know, what's going on. So there are a lot of availability issues. There are a lot of faults that are happening here and also like, you know, if I go into the one of the servers that is a summitting ticket light lambda, I do see like, you know, somebody has deployed. So there is a lot of chaos. So I, I wanted to understand, like, you know, what is going on. But unfortunately, I have not instrumented any of this thing, right? So if I wanted to understand this, then I need to ask my developer to instrument it again deploy it, and then I need to figure out the root cause. So that's why, like, you know, we listen to the feedback, and then we are enabling the application signals. So now, with just one click of a button, I just go there. In my grouping of this application, I click on the 3 button and then say enable application signals. So it will take me to the enablement flow. And from here, all the services which are grouped in this particular one, based on the way, like, you know, we are understanding, will be showing you like, you know, the different services. It's up to you to pick and choose, like, you know, which services you want to enable. So once I enable it, maybe after 5 minutes or so, this is going to be like, you know, the ticketing, uh, service will be like, you know, it was how it is working in under the hood. Now it is making much more sense, right? Because I'm seeing like, you know, there is a 70 ticket lambda, which is calling, there is a create tickets lambda which was no longer in the picture. We have not seen this. And also like you know it is doing a bunch of database operations, SQS message, etc. Now, if I click on the view more, and then I want to understand like, you know, what's going on here from the operational audit, it's clearly saying like, you know, we have been sending some messages to SQS which is a pretty lengthy in nature, but SQS can accept only that many number of bytes. So with this feature, like, you know, we have not opened an ID, we have not asked the developer to instrument the code. It's easy, like, you know, just one click of a button, you can enable it. So even though I've shown the uh demo for, uh, with the lambda, we are supporting other services as well, including EKS. So let's move on, right? Again, show me your hands. Like, you know, if you are a DevOps operator and then things were working fine in your production, and then suddenly, like, you know, somebody's deploying some changes, things are like broken, and then you are running poles to poles to figure out like, hey, what's going on, right? So how many of you have placed, uh, these kind of things? So it's, it's all in a day of on a Dev ops operator, right? So, I just want to show you, like, you know, how you can fix your applications before it is impacting your customers, right? So for this, like, you know, I have an audit service. So there is an audit service, which is having an SLA breach. And then again, like, you know, I'm showing you, like, you know, there is a last deployment that has happened, like, you know, 25 minutes ago. So as a DevOps operator, I don't know because somebody has deployed it and I wanted to know, understand like, you know, why they have deployed it, what kind of changes that they have done and all those, right? So when I click on the view details, it will take me to a cloud trail page. So from here all the information is shown here who has deployed it, what time they have deployed it, what kind of configuration changes they have done, all the information. So now I have heuristic, but I don't know, like, you know, whether this is the root cause. And I just wanted to do that. So now I go to my red metrics, and from here I can see like, you know, right after deployment I see my there is an availability issue and there is a fault. So now I'm convinced that this is the culprit and I just wanted to roll it back. So I go there, delete my latest deployment because which is causing all the issues, and then I once I delete it, it is rolling back. Maybe after 5 minutes or so, when I come back to my screen, now the SLA has recovered. But I just wanted to understand, like, you know, whether this is indeed, um, uh, solve the problem, right? Again, I click on the view mode. So this time it's showing, uh, like, you know, there is a deployment 32 minutes ago, which is what our rollback is all about, right? And now I can see like, you know, from the red metrics I can see like, you know, after my second deployment, which is right after my rollback, I can see like, you know, the availability has gone up to 100%, my 500 errors gone to 0, so that's what we expected, right? So these kind of things like, you know, you can easily see that. So we are not only tracking your deployments but also like if there are any config changes if somebody goes and then change any of your config like your time or parameter or anything for that matter, we will capture all the information so that all the information that you are looking for is available for you in your dashboard itself. Again, let's move on, right? So, let's talk about cross accounts. Again, like, you know, show me your hands, like, you know, if you are running in your environment or in your entire environment, like you know multiple applications, multiple accounts. So how many of you are already doing it? So this is a classical problem, right? So when I'm I'm talking to customers, they all running their own accounts. So sometimes, like, you know, the front end will be having their own accounts, uh, some, uh, back end teams will be at their own accounts. And then when I'm talking to GFS customers, they have like, you know, maybe, uh, lending is one account, and then that could be like loan could be another account, etc. etc. But all the applications are talking to each other all the time. So will it be useful, like, you know, if I'm a service operator. And I just wanted to see everything from one place, right? So that's what I wanted to show you. So let's see this in a quick demo. So currently, I have an appointment service gateway. And which is running like, you know, cross accounts to prove the point, like, you know, when I am going into the tile and then I'm when I click on this, uh, view more option, I can see like, you know, from my accounts tab there are like two different accounts it is running. So when I'm getting into the beats, I can see like, you know, it is calling a bunch of services. So from here, I can group it by, in terms of account ID. So, I'm saying like, you know, show me the, all the services in account ID 2341. The corresponding services are shown. I can rinse and repeat the same thing for my other uh account as well. So I do the same thing with the other account, which is account ID is 4084. In this case, the corresponding accounts are coming in. So not only that, whatever we talked about like now operational audit and then the change indicators, everything is available, even though like, you know, it is coming across account. So, you might be asking the question like, hey, what is the connecting tissue here, right? So the connecting tissue here is a database. So, that also I can do it. I can say like, you know, the dependency type is Dynamo DB. So that's the database here we are using. So from here, I can see like, you know, with my Dynamo DB it's uh both uh services from, you know, different accounts are like, you know, showing up here. So like this, even if you're running like, you know, 100s of applications with 100s of services or 100s of accounts, it's easy for you because everything is available from one place. So far we have seen, like, you know, the traditional life of an operator, but you might see, hey, this is an era of GI. So what's, what are the things that you are having in store, right? So let's see a story, a simple story, right? Again, this is our Pitclinic application. And uh we have introduced a chatbot called PetPallier. So with PEPal AA you can ask any questions. So, users can come in, they can schedule appointments, they can ask any questions for their nutrition information, etc. etc. So now I'm a customer, and I'm coming to the reinvent Pet Care, our pet clinic application, and I wanted a nutrition information for my pet rabbit. So when I ask the question, the chatbot is giving me like, you know, 3 different options. So, I am a customer, so I can choose, like, you know, whichever the option that is OK for me, right? So I'm choosing the third option. I would like to place an order with this particular one. So that's what I'm saying, OK, go ahead and then place an order for this particular supplement that I'm looking for, for my pet rabbit. So with this one, like, you know, I'm expecting like, you know, that to succeed, but unfortunately here the chatbot is saying it's, it's not available. I'm a user. I'm kind of dejected, but I have some other options, right? So I go with the second option, and then I say like, you know, OK, you said the third option is not available, go with the second option and place an order. But unfortunately, again, it's coming back with the same thing. So it is recommending products, and when I try to place an order, it says like, you know, it's not available. I get a little frustrated and then I say like, you know, I do the similar way like, you know, how a human can do, right? I say like, you know, tell me exactly the pet food that you have in stock, so that I can be sure that I can place an order. Again, the chatbot is coming up with 3 different other options for me, and I go with the first one, and then I say like, you know, this one, you said it is available in stock, go ahead and then place an order. But again, unfortunately the same problem. It says like, you know, there is a technical issue. I cannot place an order and all those things. I get frustrated and then I get, I go to my pet clinic uh support thing and then I created a feedback thing and then here I'm saying like, hey, your chatbot is recommending me products and when I try to place an order it's not working. What's going on, right? So, like this, you might be having a lot of users, or a lot of your customers that might be like not happy with the agent, the way the agent is working. So now I'm a support engineer in the pet clinic application. I come to my dashboard, and many of the customers are saying the same thing. Everybody's saying like, you know, the chatbot is recommending products. When I try to place an order, it's not working. So, in a traditional manner, if I'm a support engineer, I should have gone to logs metricstasis, but this is an era of Gen AI. So I open up my Kiro IDE which is having MCP integration with application signals. And from here, I asked the question. And as you can see here, like the way human does it, it do a lot of operations. It talks to MCP tooling, multiple MCP tooling for that matter, and then as and when it is getting a response, it knows like, you know, what kind of questions it needs to ask. Finally, it is coming up with a hypothesis. It says like, you know, these are all the key findings and these are all the next steps and support engineer, I as a support engineer, get some information and this is easy for me. So compared to that like, you know, I should have done maybe with the locks metric phases going into the thing codes and all, right? So now I wanted to take it and I wanted to go to my development team. So in this case, like I'm just using a Slack channel, it doesn't mean that like you know you have to use this as the only medium. It's just an example. So here I'm saying like, you know, hey, all our customers are complaining about this one. Looks like our, uh, chatbot is broken. Can somebody can go ahead and then, uh, fix it, right? So like this to sum it up, like, you know, with, with this particular thing, whatever we saw it as a support engineer, like in a, in a traditional manner instead of doing like, you know, the manual way of doing things, they can lend the help from MCP and other GAI tooling, right? So with that one, like, you know, let's go to the last one. So, we have recently introduced GitHub action integration. So with this one, like, you know, let's continue the story. To sum it up, We have our support engineer complaining about, like, you know, the user are saying like, you know, they are not able to place an order, and the chatbot is recommending it. So now it is coming to me. Now I'm a developer. And again, like instead of doing a traditional manner, I'm using the AWS GitWb action. So I say like, you know, AWC APM, so this is my scenario, fix it. So now the GitH action, what it does is it fetches a code from the GitHub and it knows like, you know, where my applications are running, and it does basically the same correlation, whatever the MCP has done, and then it will come up with its own hypothesis. So we might be asking a question like and how it is different as you could see here this is a little bit different because here we are seeing like, you know, including the file level details and line level details about what is going on. So in this case the AWS APM, our agent is saying like, you know, hey, these are all my um recommendations these are all the issues. What do you want me to do? So I'm a developer, I'm in the driving seat, so now it's up to me to figure out like, you know, how I can fix the issue. So now I say like, you know, OK, hey AWACPM go to this particular line, go to this particular file, and then fix this. So all I'm saying is go to this nutrition information Python file, go to line number 76 to 88, change the system prompt. And also, even though the agent is saying like, you know, the validation layer is a low priority item, the developer, I know this high priority item for me, and then I'm saying like, you know, fix this validation layer also. So not only that, I am putting some guard rails around it and then I'm saying like, you know, do not do any kind of database modification because I don't want my agent to do some crazy database operation, right? So once I do that, I'm asking the AWS APM to create a pull request with all the changes incorporated. So that's what like, you know, the AWS APM GitHub agent is doing. And after some time, it is coming back with this particular thing. So from here, like, and I'm going into the pull request, I understand, like, you know, what is the problem statement, it understood, what is the solution it is doing, and what kind of changes, and then testing it has done. So I go to the file changes. So here, I just wanted to review the changes, whatever I have done. So here I'm saying like, OK, the validation layer, I asked the agent to change it. So that's what he did. So I'm convinced of the fact that whatever I asked the agent to do, that's what he did. So I wanted to approve it. So I go to my um tab and then say like, you know, I say LGTM which is looks good to me and then I say approve. So, once I approve it, somebody merges the code, and then CACD uh flow kicks in. So, after that, like, you know, my changes are going to staging, and I wanted to test the same flow again. So now I'm coming back to my same flow. So here I'm asking the exact same question my customer is asking. So this time I'm asking like, you know, hey, what are the pet food options available, uh, for my pet rabbit? But this time the answer is different. It says like, you know, it still says, I don't have the details, but I don't know anything about your pet. I can schedule an appointment for you. So I say like, you know, I'm available on Saturday, book an appointment for me, and it is already booked an appointment for 11:30 on Saturday. So this way, like, you know, it is easy to sum it up like you know whatever you have seen the operational audits, the uninstrumented flow, the MCP integration, and then Gitup flow and all those things with all these latest and greatest features we are offering with application signals, you can make sure like your observ the journey will be easier with application signals. But don't take my word for it. Uh, with me, I have Muttu from CCC Intelligent Solutions, who is coming here to talk about how application signals and Cloudwatch as a whole is helping their observatory journey. So without further ado, I, I would invite Mutu to the stage to talk about their journey. Thank you. Thank you, Shiva and Igor, for the informative and power-packed demonstration. That's a lot of new features. Well, good morning, everyone. My goal here is to share my experience and help you walk out with a few things that you can apply in your environment. have 25 minutes, so let's dive in. Can anyone guess how many cars are involved in accidents per year in the US? Can anyone make a guess? Please raise sand if you think it's 5 million. 10 million. 20 million. In the US we have approximately 300 million registered cars. And 7% of the cars are involved in accidents every year. It means like 20+ million cars are involved in the accidents every year. So you must be wondering why I'm talking about car accidents in the cloud Dodge meeting. Well, Myself, Muttu, Muttu Kumar Adnari from CCC Intelligent Solutions. CCC is the leader in auto claims and collision repair industry. When life brings unexpected, CCC gets to work. We unite the entire industry, auto insurers. Repair facilities, automakers, part suppliers, we bring them together to help people get back on their journey, get back on their life, get back on the track. So to achieve this, CCC makes billions of decisions every single day. And we work with 300+ auto insurers, 30,000+ collision repairers, 5,000+ parts suppliers, and we handle 17 million clients annually. To support this, we have thousands of APIs and we have several portals and running on thousands of servers and on hundreds of databases. And every auto claim goes through thousands if not hundreds of transactions before the car is fully repaired and handed over to the customer, the car owner. Our systems handle 5 billion transactions in a typical business day. And we have a sophisticated system to handle the billions of transactions to ensure smooth operation for the system. We have a team of SRE and I manage the SRE team at CCC. Well, so we live in a world, accident happens, even if you are in a self-driving car. There is a possibility you may get into accidents. Maybe not your fault, maybe not the self-driving cars fault, but you may still get into accidents. There is a possibility. Similarly, If you have even best in class systems, the systems may run into failures or issues. At times you may have to deal with some of the issues in the systems. So my theme today is all about accidents, I mean system failures or system issues, and how we deal with that using the cloudwatch application Signal. Today, I will show you how CCC is using Cloudwatch Application Signal to troubleshoot issues and what are the things that we learned working with Application Signal for the last few years. And what are the key benefits, the business metrics that we see, how we measure, what and all we see the benefits standpoint. OK, let's start with the APM journey. CCC started our APM journey with Application Signal around 2023, uh, late 2023 or early 2024, and CCC was moving all our workload to AWES. At the same time, we were doing a modernization as well. We moved all our workloads from traditional EC2 to the EKS platform. So we were looking for a cloud native solution that can support that observability. And that's when AWS released that in the reinvent, around 20 late 2023 reinvent. And we started doing a POC. There are four things that stood out for us during the POC. One is the automatic instrumentation. The other one is the unified workflow, and the pre-built dashboards, and the cross-second observability. Cross-count observability is something that I love. Basically, it's a kind of a single pane of glass. If you have applications running on a multiple accounts, you don't want your SRE to log into multiple accounts to troubleshoot. You just need one account set up as an observability account. You just go to one place to manage everything in your infrastructure or in the workloads or environment, everything. So that was, that, that's what the cross account observability is all about. Now let's look at a few scenarios, how we troubleshoot issues. So as you can see in this chart, this screenshot shows some spike. This is a latency spike. And you see the baseline is around like 1000 milliseconds or something, and then the latency spike is up to like a 2,000+ milliseconds. So when you don't have a proper APM tools or when you don't have a proper process in place to troubleshoot such issues, when you have an alert, what you do is you go to, you look at the alarms, obviously start with, or you look at the metrics or synthetic monitor, locks or dashboard. All of this will tell you something, but not the root cause, right? So all of this will give you some information about the issue, but it will not help you with the root cause. So what we do is when we have such latency spike alert, We go to transaction search. From the transaction search, on the left-hand side, if you look at, we search for the spans with a higher latency. So in the spans, when you search for the higher latency, it gives you the traces, corresponding traces with the higher latency. So if I click on the trace, it will show the span time. Here in this case, it shows the post, the query SQL query that I'm running is actually taking longer. In this case, it shows it's taking 1.23 minutes. And if you click on the line, it will actually show the actual select query that is executed. Obviously, you cannot see it. I have mastered it for the security reasons. Well, you will be able to see the select query from this, once you have the query, you can actually, if you have a database running on AWS with a PA performance insights and Cloudwatch, you'll be able to go there and even understand why that query was taking time. Maybe some index is missing or any other reasons, you will be able to quickly understand. So this is one way to quickly troubleshoot an issue when you have an issue. Let's look at other ways to troubleshoot issue. So the application map is something that was recently launched, and we were a beta customer working closely with the product team, sharing all our feedback. This is something that I love most. Because it gives you the visual representation of all your workloads in your environment. So, basically, what you see is like multiple tiles here, and each tile represents the services in my environment. Each tile is a workload. So, and each tile actually understands the interaction of that service with all other services in my environment. Basically, when you click on each one of them, it will give you the interactive map of that system in your environment. So you will see that in the next slide. And this also has the real-time health of your system, which you can, you can see that in the top, you see there are circles with the red, and some of them in the middle is, you know, yellow, and most of them are in blue, which means they're all healthy. So when you want to troubleshoot something, what you can do is you can just simply filter based on what you are interested in. In this case, I'm looking for server files. The server falls, uh, you can filter it by server files, and it shows there are 4 services or the workloads has a Uh, you know, errors, server false, and then I can just click on one of them to zoom in and understand. So if I click on one of them, it opens the interactive map, and that helps me understand, OK, my service is talking to a database and there are other multiple remote services I'm talking to. So with that information, I'll be able to get the complete picture of my service. And if I want to understand the root cause, when I click on the service again. It actually opens that contextual troubleshooting drawer with the relevant metrics and insights. Here it shows all the health information of that and why it is even slow. So from here, I can even further go to that correlated span that actually shows the trace for the corresponding time period, why that was actually slow. So you'll be able to, you know, go to the correlated span to get to the trace. You don't have to go to the transaction search. From here itself, you'll be able to get to the Uh trace. When you click on the trace, you will be able to get to the root cause, you can identify it. But if you are interested in going to that dashboard, want to see that, you can click on that view dashboard button. This takes you to the application Signal dashboard. So if you are a visual person, if you have like an L1 resource who doesn't understand the complete picture, they need a visual representation to navigate through their troubleshooting process. Application map is really helpful. Also, if you are looking for the complete picture of all your workload in your environment, and you can use it, and we started using this for all our troubleshootings. Now let's look at other scenarios, how, you know, the insurance industry is impacted. For example, the unexpected events like a hurricane, how it impacts the insurance industries and our systems. So before we go there, can anyone guess how many cars were damaged in last year's hurricane in 2024? Any guesses? So I'll give you the number. So last year we had two major hurricanes. One is Hurricane Helen, and the other one is Hurricane Milton. Helen impacted 140,000 cars in southeastern states. And Milton impacted around 120,000 cars just in Florida state itself. So overall last year, we had around 350,000 cars damaged just by the hurricane itself. So what happens is like when hurricane happens. People stay indoors. They want to stay in a safe place, but the cars are on the road and they're, you know, even if they're in the driveway, you know what happens with the hurricane. It gets hurricane damages the cars, right? So when rain stops, people want to get back to their life. First thing they need is their car. So all of them, the moment the rain stops, everybody picks up the phone and then calls the insurance company to get the car repaired. Imagine like 1,000,000 people calling the insurance companies around the same time. Yeah, you know, the volume of climb goes up like literally by 5 or 7 times. So our typical day is like we get like 50,000 to 60,000 climbs. That's the 60,000 accidents in a day that we deal with. But in a short span of time, the volume goes up by like 5 to 6 times. Fortunately, we have a system that can automatically scale because we have a state of the art system that automatically scales and handles the volume, but there are times we may run into some small performance issues or minor things that we have to deal with. So I'll show you how we handle such a situation using that AA operations investigations. Let's look at this trace map for a second. So this trace map shows multiple services are involved in a single transaction. You see there are multiple services, databases. The transaction is going back and forth. This is one of the complex transactions that we have in our environment for our client processing. So when you have such a complex transactions, you cannot just look at one data point to, you know, come up with a conclusion or a root cause for the issue. You have to look at multiple data points. When you have to look at multiple data points, what it means is you are actually taking more time. Your MTTR is going up. So if your MTTR is going up, you are impacting the customer, customer is not happy. So what, uh what we do is we use the AA operations investigation. The AA operation investigation is agent-based. Be the scenes, it runs the agent. It's part of the cloudwatching part of the cloudWatch itself. It runs the agent behind the scenes and looks at multiple data points within a short span of time. It significantly reduces your MTTR. It reduces the MTTR by like a 95 or 98%. It takes only 3 minutes, max 4 minutes for all the data analysis to complete. I'll show you in the next screen. So, you can launch that AA operations investigation from the application signals page itself, or alternatively, you can launch that from application map itself. So if you launch it from application map, it automatically understands the context. It takes the time, and it can actually, you know, uh, uses all the metrics at the time frame that you are actually starting the investigations. Once you start the investigation, you can go to that. Agent Q begin the scenes. It runs the agent. It's uh, you can access it from the AI operations investigation. The agent Q shows what are the different data point telemetry data it is looking at. All the telemetry data analysis is available here. In this case, it's running 42 tasks. It analyses database, and all the component services that the transaction is involved with. And it gives you the summary of hypothesis. So, anytime you have an issue, you need 3 things. One, you need the data points, what are the data points that you have to analyze, and then the, and, and then you need to come up with a hypothesis based on the data points, and then you come up with the action plan, right? So, the agent is already looking at all the data points for you, and then it comes up with the hypothesis and findings. As you can see here, it has a hypothesis. There are some database-related uh hypotheses here. And then it gives you all the findings. What are the findings here. So based on this information, you'll be able to come up with a conclusion, OK, this is what you have to focus on. Your action item is very clear at this point, right? All of this is done within a few minutes. But if you have to have a human SRE to do this, it may take 1 hour or maybe 2 hours. You may still looking at the data point. You may not conclude anything, but everything is done through that AA operations investigation by the agent. This is going to augment your SRE and really helpful when you have a complex troubleshooting. Well, now let's look at GA observability. So CCC offers AA powered tools and technologies to our customers, and we use models. We have our own models running on the Sage makers, and we use models from Bedrock. So for one of the use case, we were trying to use some models from Bedrock. That was kind of one of the first use case for a Bedrock. And we sat with our, uh our product development team to understand the observability. And the product development team was trying to, you know, create a summary, as you can see in the screen. So in, in our website, we have shops reviews. We have collision repair shop reviews. We hired hundreds of reviews for a shop. They wanted to summarize it using the model AI, you know, using the AA. So you can, you can see that, you know, you, you don't have to read hundreds of summary, right? The reviews. So you can just look at one summary. And for this, we wanted to, you know, do some POC. We were trying to understand everything from the model standpoint. But the key thing was like, how do I understand the invocation latency? If I'm in the application is invoking a model, how do I understand the number of tokens it's using? What is the input token, output token. And we were looking for observability at the time, and then we reached out to our AWS and AAWS was working on the GA observability, and everything came out of the box, so we didn't have to do anything. So the GI absorbability is also another new thing that was released recently. The GNI absorb has all the information that we were looking for. It has the revocation latency, it has the token count by model. It also has an input-output token. Everything that we were looking for is available out of the box. And you can also look at by model. Basically, you can click on each model, and then you can even look at if you are using multiple models, and you can, you can look at that by model, you will have all the information. So this was really helpful for us, for us to support the things that we were using in the Bedrock standpoint. Let's, OK. Now let's look at what we learned working with Application Signal for the last 2+ years. So these are the things that we learned, and I hope this is going to help you in your environment as well. Maybe you already know some of them. Maybe you will learn something today that will be helpful. So transaction search, so you saw how I used transaction search to troubleshoot, but a lot of times people are concerned about the cost. So I suggest using transaction search for a 100% spam visibility. If you're looking for a spam visibility at a lower cost, I suggest using the transaction search. Let's say you have lower sampling rate in your non-production environment for less critical applications, but you want to have a 100% visibility at the time that you have an alert, you have errors, you have high latency. So you can use the adaptive sampling at the time. Basically, adaptive sampling will increase the, you know, sampling rate to the higher number that you define, may go to 100%. Once you get an alarm, so basically the alarm movement alarm triggers your sampling rate will go up. The movement alarm comes to OK state, the sampling rate will come down. So this is going to be really helpful if you want to have a 100% visibility in a non-product or a less critical application. You can simply boost the sampling rate with this. And the AA operations. So I suggest using the AA operations to augment your SRE team. This is going to be really helpful. They don't have to really spend troubleshooting it and going to reduce your MTTR significantly. And then application map is for visual persons, for even Elo or even if you are a senior resource, if you want to get a full picture, the application map is going to be really helpful to get them the workloads right now have a workloads I mean visibility in a visual way. So the pre-built dashboard, so I suggest using the pre-built dashboard for all the red metrics and even setting up alarms. You can set up the alarms from the dashboard itself. It's kind of very easy, so you don't, with a few clicks, you'll be able to set up alarms that you need. And then the runtime metrics. So runtime metric is something that we worked closely with the application signal team from the beginning. So we are really looking for runtime metrics to understand the memory, the heap, and all the garbage collection. This is going to be helpful if you have a memory intensive applications. You want to understand how your application is performing in the runtime. And the SLO alarms. So if you have SLIs defined, if you are really looking for SLO alarm setup, I suggest using the SLO alarms at the operational level. That's going to be really helpful to get the granular level of information in your application. You don't have to set it up at the service level. So if you have multiple operations, I suggest using the defending alarms at the operational level, at the dependency level, that's going to give you more information. And the container inside comes out of the box the moment you install the agent. That's going to help you understand the complete picture and all the metrics that you need from the container standpoint. Now, let's look at what are the business metrics that we measure and what are the key benefits that we see with the application signal. So overall, we see 50% reduction in MTTER. We're able to reduce the, you know, cost by 40%. So we see like a 40% cost. And we improve that productivity not just for the developers, we improve the productivity for our SRE team and testing team. And overall we see significant improvement in the system performance. So on one side, we see that the productivity goes up. On the other side, we see the system performance also goes up because we are able to proactively. Identify issue before even the customer knows something is wrong. We are able to address it quickly because we reduce our MTTR. So that has significantly helped our systems, you know, improve the performance. So, so Cloudwatch application signal can help you in many ways to reduce the, you know, um. And then the MTTR and also the cast and other things. So I suggest you guys give it a try today. It takes only a few clicks. If you haven't tried it, just go and try it today with a few clicks to install the agent, and then you will see that efficiency improving. You will see the observability stack, visibility is going up overnight. So with that, I would like to wrap. Uh, so I want to leave you all with one message. Cloudwatch can help you in many ways for, uh, you know, the observ standpoint, and CCC can help speed up the repair process and improve the efficiency, but only you can actually prevent the accidents. Whether it's a car accident or a system accidents, only you can prevent it. So always remember to drive like your grandma is watching. With that, I'd like to wrap. Again, thank you for listening. Uh, your attention span is stronger than my mobile signal in this building. Thank you. And I'll call Igor and Shiva back. Yeah Thank you, Mutu. Thank you, Shiva. Um, now, you know, if you have a claim, Mutu will take care of it. AWS and AI will help it, but drive safe. That's the first thing. So, thank you for sharing your time with us. And if you like the session, give us a thumbs up, you know, review. We'll take questions um here off stage, um, and again, thank you for, um, you know, being here.