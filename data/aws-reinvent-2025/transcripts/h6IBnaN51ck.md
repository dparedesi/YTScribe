---
video_id: h6IBnaN51ck
video_url: https://www.youtube.com/watch?v=h6IBnaN51ck
is_generated: False
is_translatable: True
---

Hi and welcome. Hopefully you are here for your, your AI agent is expensive and wrong, let's fix both. If you're not, uh, enjoy the next 60 minutes. Uh, and for those of you who I recognize from past reinventor Data and AI summit talks, thank you for coming again and, uh, and pleasuring us with your, your, uh, your presence here. So, my name's Craig Wiley. I run product management for AI NML at Data Bricks joined today by Nick Vicker and Marcos, uh, Nick also from Databrick, and Vicker and Marcos from Conde Nast, who will talk a little bit about taking some of what we're doing, what we talk about in the first half of this, about how they've implemented that successfully at Conde Nast so far. So let's dive right in, um. So this is what we're gonna do, we're gonna talk a little bit about why uh why a different approach to AI agents is needed. We're gonna go do a, a big thick, long meaty demo. Conde Nast will come up and talk for a bit, and then we'll finish off with any question and answers that you might have. If for some reason, we run out of time, which is reasonably likely, then we'll, uh, we'll do Q&A up here until they kick us out, and then we'll do it out in the hall. So, uh, if you have questions, feel free to keep them and make sure they get answered. So, with that, uh, apologies, but you are, I believe I am contractually forced to show you this slide, which is, this is Gartner's annual comparison. For those of you guys who don't know, this is really, I, I think used, Gartner says this is used very infrequently by actual customers and users and is mostly used by, uh, by the vendors to flex on each other. And, uh, given that I I was responsible for building the AWS stack and the Google stack, this was a particularly exciting flex for me. Um, but so with that, uh, let's dive in. So our goal at Data Bricks is to help democratize data and AI. And that goal has changed significantly over just the last 2 or 3 years, as I'm sure you can all imagine with, with Agenic AI becoming more and more of a, a powerful force in the industry. About 3 years ago, our CEO, or I should say, yeah, 3, just about 3 years ago, a little less, about 2.5 years ago, our CEO actually got up on stage at our annual conference and said in the future, you're just gonna use natural language to, To power data bricks and to to use data bricks, and while we're not there today yet, today on data bricks you can build pipelines with natural language and jobs with natural language, you can, uh, you know, build, uh, You can, you can do text to SQL, you can now do text to machine learning, you can now do text to agent, you can do text to visualization. So you, while you can't do kind of text to all of data bricks, you can get pretty close with some of the capabilities, and we'll talk about some of those today. This is data bricks, by the way, uh, more or less. At the lowest level we have your data in. Open formats in cheap blob storage. On top of that, we have Unity Catalog designed not only to govern and access control that data layer, but also designed to really be the brain and the kind of metadata collection system to be able to power some really cool capabilities which we'll talk about shortly. Then you have. Agent bricks, our ability to orchestrate and build agents on top of all of this, and then you have a series of engines, right? AIBI, our business intelligence capabilities, right? Our apps capabilities, Lake flow, our, uh, our pipelining uh capabilities, Lake House, our data warehouse capabilities, and Lake Base, our new OLTP. Capabilities. I, I don't know about all of you, but my in my experience, every data professional spent some amount of time early in their career, where they said, you know, oh yeah, I'll just go get the information out of the data warehouse, and they go and they, they look and they're like, hey, the information's not in the data warehouse, and someone smart in the company said, yeah, it's in the database. And, and you go, wait a minute, there's 2. Why? And you know, they, they, oh well, OLAP and OLTP and we all just nod and go, oh yeah, that makes sense. Those should be separate. But no, no, they shouldn't be, right, they should hopefully in the in the fullness of time be one thing. And so, you know, it's with that that we're really excited about some of those capabilities. So today we're really gonna talk about 3 things. We're gonna talk about Unity Catalog for a hot second. We're gonna talk about AIBI and some of the natural language capabilities we've brought into that because those end up being really important to some of our agentic capabilities. And then we'll dive into Agent Bricks, and what it means to build an agent with Agent bricks, and how and why that's different from building agents maybe using other platforms or other tools. So, this is how I think about the AI opportunity. Sitting in front of all of us right now, is, how do I simplify the creation for you, of high quality AI apps and agents on your data. Right, and we're very clear about what we mean by high quality, right? What we mean is, we want it to be accurate and secure enough that you could implement it in the path of risk. Right? Either financial risk, maybe in an internal workflow, or maybe externally in reputational risk as you expose it to your customers or your users, right? This is really a different goal, right? Most of my competitors. We say, we wanna simplify the creation of these systems, we wanna give you one click rag, right? But really, and those, that's great, and, and listen, if what you're trying to build is a little personal productivity hack for you and your, your colleagues, those are great tools. But we see the problem slightly differently. Which is, if you were to go deploy an agent into the path of risk, either externally facing or into some sort of internal workflow that at some point you hope to be hands off the wheel and allow it just to run autonomously, if you expect to be able to deploy an agent into those environments, your CFO is gonna have questions. Right, your CFO is gonna ask two things. Right, they're gonna ask if you can govern this thing, and by govern, I don't just mean access management, I don't just mean, you know, who can call the agent. I mean, who can, I do mean who can call the agent, but I also mean what precisely is the agent capable of doing at every intermediate step, right? What are all the systems it has access to? What are, uh, so what's it capable of and what is it doing? How, what's your strategy for monitoring and logging and ensuring that it's doing what you thought it would? Right, fundamentally, can you control it? Right, so the first thing your CFO is gonna want to know is can you control it? And the second thing they're gonna want to know is, is, is it, is it any good? Does it work? Right, and you know, today, more than 85% of agents are vibe tested. Right, so you know, I build an agent and then I sit there and I go, hm, yeah, seems to work pretty good, right, which is fine, hm, maybe not, but you know, if I said to you, hey, we're gonna give up on unit testing for all our computer science from here on out, we're just gonna have you try the happy path, see if it works well, and then just deploy it. Right, most of us would never tolerate that, or maybe we would, but our bosses might not, but fundamentally, If you're going to go deploy these things, you need to know whether or not they work. Right? I wouldn't build you a forecast for a sales forecast, and, and then say, you know, you say, oh how accurate is it, and I go, I don't know, it's pretty good, isn't it? Right? No, I would tell you the R square or the AUC or some other measure of, of fit. Well here, we want to give you that same opportunity, that ability to, using evaluation, drive these things to a point where they can be deployed in the path of risk, and where you can communicate their performance quantitatively to your colleagues and others. Right? So let's start with Unity Catalog, and a quick view on Unity Catalog. Why Unity Catalog is important. Well, I talked a minute ago about the fact that not only do I wanna govern access to this agent, I actually wanna govern every single thing this agent does. If this agent looks at data, I wanna know that. If this agent calls an API I wanna know that. I wanna know what it's capable of doing, and what it did on every single time it was used. Right? And so Unity Catalog does that, right? We not only, not only does Unity Catalog govern tables, it governs unstructured data, it governs embeddings, right? It govern it governs tools, it governs API calls, right? It can govern all of these capabilities. And when I say govern, not only. Not only can it control who can go do those things, but it can log every time they're done, right? And recently, oh I, I should say, it can govern prompts, it can govern Gen AI models, and the access to those models, and then most recently we announced it can govern MCP servers. So you can stand up a managed MCP server inside data bricks, and have any of the data bricks assets, right? Any of the queries or the text to SQL genie rooms, or the uh or the APIs or uh in there, or, or the tools you've built, or the queries you've built, all of those can be represented behind a, MCP server, that then your agents can call and access those artifacts within data bricks, but that's not it, because we, we don't just want to be able to govern the agents that you build on data bricks. If we gave you the opportunity to govern just the models on data bricks, then everywhere you build models, you would have to have a separate view of how to govern and and access control and monitor them there. So instead what we've done is we've made it so you can take external MCP servers. Maybe you have an MCP server that's part of a SAS system, maybe you have an MCP server that someone else in a different department built. Right, you can register those MCP servers inside Unity Catalog, and now anything. That you want your agent to to go and access, can be accessed, even if it's a, a separate SAS system, right, those APIs or that MCP server can be packaged up, registered inside data bricks, and now your agent, instead of going off and calling that MCP server will call it through data bricks and we'll be able to log and monitor every single thing it does. Right, this is really, when I, not long after the pandemic struck, I had a meeting with the head of trust and safety at a, at one of the world's largest retailers, and I said to her, hey, when the pandemic struck and all the human behavioral models went bananas, because we all thought that toilet paper was more valuable than gold, like, how on earth did you prioritize which models to retrain when? And she kind of sheepishly smiled at me and said, Craig. You think we know where all our models are? Right? There's some laughter, um, some uncomfortable laughter in the room. Right? If, if that model that was built was some forecast for used, you know, mystery books, maybe I don't care. But if that model had access to APIs, if that model could take actions on behalf of my company. Then not monitoring it very closely and knowing exactly what it's doing, starts to become a liability, right? And so that's why Unity Catalog is central to this, is it can become that hub of governance and monitoring, not just of the agent itself, but of all of the different things these agents might want to touch. Now, monitoring is the second half of this, right? Now we run monitoring not only for classical things like tokens and latency and all of these kinds of things, but we'll actually run LLM judges as a part of the monitor, so that you can measure things like ongoing correctness. Right, or you can start looking through your logs to see, hey, are there particular subject matters that I tend to get wrong, more than other subject matters, right? And this can become a way in which you can really start to surgically, Go after the performance of your system, right? So that's a quick overview of why Unity Catalog is so important to all of this. Now I want to dive into AIBI and you can really think about agents on data bricks in two ways. One is, we're building a bunch of agents to make it so that you can use data bricks more easily. The second is, we're building tools so that you can build agents more effectively. And so I wanted to talk for a minute about AIBI because it's really central to the some of the agents that we've been building that are getting reused when people build agents themselves. First of all, we've seen massive user growth, 500% year over year growth. And by the way, this AIBI capability, these capabilities, they're, I can't say free, but they just cost you the cost of the queries. Right, they don't cost you extra, you don't have to go get a separate contract to use this or an addendum or anything, you can just start using it. Right, that's part of what's driven this growth. It allows you to have text to visualization. You can just say, hey, show me the sales by region over the last 6 months, you know, uh. You know, broken down by product or something along those lines, and you'll get a dashboard, and then you can filter this dashboard, move these around, you know, uh, kind of do all the things you would expect in a modern BI tool, but you've created the entire thing with, with lang with natural language. Right? Now, we all know, I, I'm, I'm saying we because I'm guessing other data professionals in the room, that when an executive comes to you and says, hey, can you build me a dashboard? That's a rough day, because not only are you building a dashboard, but you are now answering an unlimited number of deep dive questions about that dashboard, right? Dashboards don't create answers, dashboards create more questions, right, where people are constantly saying, oh yeah, sales rep. Why were they up? Sales were down, why were they down? Right, all of these questions, we used to, when I was at Amazon, we used to joke that, you know, hey, I wanna know what sales were, and as soon as you told them they were like, I meant for blue things, right? And so how do you get ahead of that? Well, Not only can you use natural language to build these visualizations, you can start talking to your data. You can ask questions of your data, right? You can go in and just start saying, you know, hey, what was it that drove sales? I will tell you that this text to sequel or this er text to SQL capability or genie rooms, as you'll often hear it called, or genie spaces, ah. This is a it has a remarkable capability that's recently been announced, which is it has a deep research capability attached to it now. So the deep research capability won't just answer questions, I mean it will answer questions about the data, but it'll start to answer much more complex questions. Hey, describe to me where the most efficient places in my sales funnel would be to, for me to invest incremental marketing dollars. Right, and it will go through, it'll build a plan for how it would go after this problem, it'll check that plan with you, and then it'll start running the queries it needs to across all of your tables in order to start informing that plan. I had an amazing moment with a customer just two weeks ago, where he said they had a whole bunch of supply chain data in here. And he, he asked it for some help uh understanding what some of the supply chain costs and risks would be on some of their Trans-Pacific transportation routes. He hit enter, it came up with a plan, he waited, and then it stopped. And it said, hey, I don't have all the data I need to do this. I need you to give me access to another table. And I say that, cause that's a huge leap for this technology. For this technology, and we're seeing this both in our system as well as in some of the foundation models, that they're, they're just not making stuff up at quite the rate they were back when we were talking about GPT 3.5 and what have you, right? We can start to, it's starting to get to a place where we can, if we're careful, we can start building that trust a lot more effectively. And so, and then finally, in private preview right now, we have a data science agent. Now I'll tell you that on that last slide, that text to SQL deep dive capability, that one hit home for me. Because that was my first job at in tech, was, I was the guy who wrote really good sequel, who could answer the questions that the VP had, and I could answer them quickly and effectively, and that got me a lot of credibility and notoriety from the VP which was great. That's now being done by the agent. Well, now we have a data science agent. This data science agent will help you analyze data. Help you determine what features might be useful for predicting a problem, and then we'll actually go and help you train the model, right? We want to make it so that you could have text to machine learning model. We're not there yet, now it's a collaborative, back and forth with you in the system, but we're really excited about some of the things we're seeing from this already, and my guess is that by next time this year, we'll be sitting there saying like, hey, this is as easy as asking a question of your data. Maybe, maybe a year and a half, we'll see. And then lastly, we have a whole series of sequel capabilities that can be used to go and run Gen AI, right? Things like AI parse document, which we'll, you'll hear about very shortly, um, AI query, so AI query allows you to run any arbitrary, Uh, prompt as part of a, a query, so maybe you have a, a table that you wanna score every row of that table, or you wanna summarize every blurb in that table or something like that. That can easily be done with a single line of sequel. At this point So now we move into the meat of it, into agent bricks, into this new way of thinking about building agents, this really evaluation centric way of building agents. It's hard to build AI agents today. We know this, we know a lot of companies will come to us and say, hey, we've tried, we've we've, we've struggled, you know, we're having a hard time. It's even harder to build high quality AI agents. Right? And so when we think about quality, it comes down to evaluation, and this is just a quick view of our Eval stack. But the key to this eval system. So we built this long, about a year before we built Agent bricks, and the key to this eval system was, see those little red circles, those little red circles are where the judges failed that line. Uh, in the, in the eval, and if you, the key is that if you click on one of those little red circles, you don't just get, you get a description of why it failed. And that you get, you know, hey, here's, here's why we think it failed, here's the input and the output at the specific step of the agent that we saw that we believe failed, and. Most importantly, here's what you should go do to fix it. Right, as soon as we had that concept of here's what you should go do to fix it, everything changed. And the reason everything changed is it allowed us to build agent bricks. Now, what is agent bricks? Well, in the market today, you can kind of think about cost or about complexity versus quality. And what we have in the market today is we have these no code builders, right, where, you know, hey, they're super easy to use. And they produce kind of static, low quality agents, right? And you kind of have to put up with whatever they produced, and they're great, by the way, if, if what you're doing is creating a system that prioritizes your emails and writes you a summary of all your emails from last night, great, go for it. But if you're wanting to put something in the path of risk, you need something better. And so we have these complex, Very complex kind of DIY agents that are very high quality, right, we can tune them and continue to tune them until we get the quality we want, but they're really complex and difficult to build. Ultimately our goal with Agent Bricks is the uh the impossible in between. We wanna make it easy for high quality. We wanna make it so that you can very quickly and very easily spin up an agent that performs, or, or that you can then tune until you can get it to perform at the at kind of whatever your exit criteria is for your use case, right? Evaluation is difficult, so we immediately went after that. There's too many knobs, and when I say there's too many knobs, there's actually not a lot of knobs. The, the problem is. That the state of the art methods for building these agents is changing. Every 2 to 8 weeks, depending on what kind of agent you're building. So, you know, what we see is usually the people who are building these agents are app developers. And what we see is they come in and they do a great job of building an agent. But they may not be up on what the latest research was released last month. And so what Agent Bricks is designed to do. Is it's designed to take that latest research and those latest techniques and bring them into the system, right? And then, so that you don't have to worry about the knobs, you don't have to worry about how you're gonna structure your vector search queries, cos we'll just take care of that for you. And then finally there's a trade-off of cost versus quality. We all know that Gen AI can be a costly endeavor. Right? And so having the ability to be really deliberate. About how I'm going to spend and how I'm going to trade off cost versus quality is something that's really important if you're all of a sudden going to put something in a, in a maybe an externally facing capacity where you could end up with, you know, thousands, tens of thousands, maybe if you're lucky, 100s of thousands or millions of queries, right? And so with that, we have a series of of uh data bricks, uh agent or sorry of agent bricks, and those, those agent bricks are really designed as kind of templated patterns that you can come in and start using, right? Hey, you need a you need basically a rag system or a knowledge assistant, great, grab the knowledge assistant, uh. Agent Brick and you're off to the races. Now, we start with information extraction. Information extraction takes your struc your, your unstructured documents, maybe you've got uh receipts, maybe you've got uh shipping documents, maybe you've got contracts, right? It takes those and breaks them into structured data. Literally, you go upload your documents. And then into Agent Bricks, it identifies the schema, says, here's all the fields I'm gonna pull out of these documents, describes to you each field, and then you have a choice. Do you wanna keep that field, do you wanna erase it, is it important, is it not? Do you wanna add other fields and describe them for us? Right? And then we're off to the races. Now, with all of the agent bricks, the idea is that once you've built it. Unfortunately you're not done, cause then what we're gonna do is we're gonna start giving you examples, and we're gonna start asking you for examples of, hey, ask me a question that you would expect it to be able to answer, or here's some synthetic questions I would expect it to be able to answer. What do you think of these responses? And you'll sit there and go, well, 12, and 3 are good, 4 is not so good, and 5 is a train wreck. You know, and so we'll sit there and, and as soon as you give us that feedback, we're gonna go tune the system. And then come back to you and say, hey, let's try another few examples. And we're gonna keep doing that back and forth with you, until it gets to a point where you're really excited and satisfied by the outputs, right? And so making it really easy to just kind of take those documents and build them into structured data. Knowledge assistant, same idea except for rag. So you have a corpus of, of text. That you wanna make searchable and you wanna be able to answer questions about that text and what have you, great. Upload the text into Agent Bricks, start to engage with the system on asking it questions and it giving you responses, so that you can give it feedback, and by the way, when you say 12, and 3 are good, 4 needs work and 5 is a train wreck, we're actually gonna ask you, why are 4 and 5 bad? And we're not just going to go and guess, you're gonna tell us, hey, 4 is using outdated information and 5, like it totally ignored one of the policies we have. Right, and we can take that feedback, and we can drive that direct feedback back into the system, right? We can more easily reason over our knowledge, right, automatic vector search creation and optimization, all you have to do is upload the data and then talk to us for a while about whether or not the responses are responses you're excited by. And then multi-agent supervisor. This one to me is the most exciting one. Multi-agent supervisor takes a series of other agents, MCP servers, tools. Other capabilities and is able to work large kind of longer running workflows over these MCP servers, tools and other agents, right, really allowing you to build some pretty remarkable capabilities, which we'll see here very shortly, right? You can see here, you know, being able to talk over both data and unstructure, you know, both structured and unstructured data, right? Can I ask questions? of both my query or both my unstructured data as well as my policies and manuals, right? You know, uh, can I build tools so that I can drive higher levels of determinism in my agent, right? And then ultimately we have the ability for you to code your own agent as well, and the ability for you to kind of dive in and use, you know, all of the, the most popular libraries and what have you to go build your own agent, if you prefer to do that. So the good news is we're seeing some extraordinarily high quality. This is a comparison to two of the clouds, neither of which we are representing here today. And uh and so you can see how we were able to beat this blue cloud and this rainbow cloud on their uh in their efforts on RAG, and that not only does our performance beat them because we have some of those latest techniques built in, but our performance continues to. Improve as we keep that continuous learning loop going, right? So how are we able to do this, right? Let's say you're building that classic kind of, you know, HR chatbot with, you know, hey, I want it to answer all of my HR policies, and someone asks a question about vacation time, and you say, you know, hey, that's the wrong answer. Wait, that's before we changed the policy back in May of 2020. So you tell the system, hey, I want you to ignore all data before May of 2020. So the system goes in and it does that, it changes the, what's available in the vector search, it adds, you know, parameters to all of the tool calling, it builds LLM judges to make sure that moving forward, we measure any time we pull data from before then. Right, so that feedback we're actually gonna use to build judges to ensure that we meet it, and then it's gonna re-optimize the entire workflow. Right, this is a huge step in steerability. I would argue that in a year, probably in a year, maybe 1 year and a half, depending on the level of urgency, I think this is the product that all of the major vendors are gonna be competing with. Right, how can I use natural language to both build and tune my agent, right, that's the product that we all are looking for and that we all want. And so, really excited to be able to deliver that to you today in beta. With that, I'm gonna invite Nick up to give us a quick demo of all of this. So, thank you, Craig. That is, uh, yeah, for sure. It won't be the last time he's up, so you can still get him for Q&A at the end, but he deserves a round of applause for sure. Alright, so I'm gonna take you through a whirlwind tour of a lot of what you just saw, but to kind of tee it up, who here is excited to go home after reinvent, and uncrumple all your receipts and go start submitting your expense reports? Show of hands. All right, security, I'm kidding. So I'm gonna use that as an excuse to kind of show you how I built this end to end on data bricks, starting from, I literally took a picture of my receipts and all the way to the end to where I have something submitted and approved. So we're actually gonna start off, and Craig alluded to this a little bit, but Unity Catalog really is the foundation of everything across data bricks. Whether it's AI, whether it's our ETL, everything both starts and ends in Unity Catalog. And so, this demo is also gonna start in Unity Catalog. Unity Catalog can store tables, uh, volumes, functions, all sorts of things. And so what you're looking at is a Unity catalog volume that I've uploaded all of my receipts into. So you can see I click in, it'll give me a nice preview as long as the internet's a little snappy. Yeah, yeah, cool. OK. So you'll see, not even a great picture, right? It's like kinda at a weird angle. Now, if I want to start doing something with this, I need to actually extract all the information out of this receipt. Now, a few years ago, that might have been pretty challenging, but today, especially using agent bricks, it's super easy. So the first thing I'm gonna do over here on the bottom left, I'm gonna click into agents. And that's gonna take us to our agent bricks page. Now, you'll see there are a lot of them, and we're actually gonna touch, I think, every single one of them through here. But we're gonna start off with information extraction. And here you'll see there's two buttons. We've got use PDFs and then we've got build. And that's generally because we're gonna take a little bit of a two-step process. So first, we need to take from images and get the data from images into an actual table. So for this, we can click use PDFs. It's as easy as pointing it to a volume, like you just saw. Here's all my receipts. Can I confirm? And then I just tell it where I want it stored. I gave it my destination table. I can rename it. I've already run this before, you know, in the, the interest of time. And so if I were to hit start import, what you're gonna see is this. You're gonna get now your raw parse data. This is what uh the information extraction was able to kind of pull out of that image. And then you're gonna get this kind of semi-structured data, right? You've got a block of text. It's got the information that was in that receipt. But it's not in a really robust format that you can really reliably start building on top of. So, if we go back to our agent page, that's when we would click this build button. So what build is gonna take us to, is actually creating the second part of this information extraction agent. So we're gonna point it to this table. That's the output of the one we just saw. We're gonna tell it where the text is, and it'll actually auto generate the sample of what it thinks that you want to actually extract out of this data. Now when you hit create agent, what it's gonna do is it's actually gonna go through a couple of them, and it's gonna extract what it assumed you wanted, and on the right-hand side, it's gonna give you a whole bunch of definitions for the values that it extracted. You can now go and tweak these, if you say, uh, you know what, location for me needs to be only the city, right? I don't need to know the exact restaurant. And so you can kind of come in here and tweak. And then the really cool part is you can add new fields. For example, if you might need to know the number of desserts, you can actually add a totally new field. You can describe what is in that field, and this might be a little bit foreshadowing later, but it will figure out how to pull that data using the examples you gave. Now, going back to what Craig said about evaluations, how do you know that this extraction is working? How do you know that the fields you want it to pull are actually being pulled? We will automatically build benchmarks for you, and these benchmarks will look at all of your extractions, and it'll use LLMs as judges to tell, hey, this sample output normally looks like this. I'll give you an example for this one that failed for match. It says, look, the ground truth example names the restaurant name along with the city, but this prediction only has a city and state. So now I can go and figure out, oh, OK, cool, I need to go update my description, because it doesn't know what exactly I want it to give me. I want just the city and state. Once you're happy, you can click this optimize button, and I did promise that we were gonna make your agents less expensive, and I'll show you what the output of that looks like. Once you actually run the optimization, it'll go away for an hour or so, and it'll run a whole bunch of different techniques in order to take your kind of your samples that you gave it, and the kind of relatively big and high quality model, and fine tune that down to a way more efficient model, while keeping the quality the same. So you see that our throughput went up massively, and our quality didn't even drop. So it's much less expensive to run, and now you can actually run this on huge sets of data. So now we've extracted this data, right? We went from on the left, where we had this kind of semi-structured block of text, to now this beautiful structured JSON on the right, and now we've got all of our receipts nicely extracted, and we can start figuring out how to submit these things. Now, in order to do that, we're gonna tab over here to Unity catalog again. Now, I said earlier, right, Unity catalog, it holds a lot of different things. So if I go to volumes, you see that we've got our receipts, that's where we uploaded all of our receipts. We've got travel policies, that's gonna come in handy later. We've got some tables. This is where we've parse those receipts out into, and it's also where the information extraction agent is dumping the final beautiful JSON. And we've also got functions. So functions can be either Python or SQL. You define them, you register them into Unity Catalog. And now what it lets you do is really easily bind these functions to your agents, so that your agents can call them. With proper authentication, things you need to catalog. Uh, just so you can kind of take a look at what these are, they can be as simple as this. So this is just a, a simple uh SQL query, and all it's doing is it's grabbing the data from both my receipts parse table and the information extraction agent. So now, what we can do, we're gonna go right back to agents, and we're gonna use also my personal favorite agent, the multi-agent supervisor. We've got data, we've got some functions that do stuff with that data, we want an agent to actually do this all for us. So we can hit build. And now we can start piecing together this agent. Now, I've kind of I ran this in the hallway like 30 minutes ago, just so we don't have to wait here. But I want to show you first the configuration of the agent. So, on the left-hand side, we've given it a really light description. It helps users process expenses. And then we've added two subagents. These are just the two unity catalog functions that I showed you earlier. They allow this agent to retrieve the parse data that we looked at in the information extraction. And they allow it to hit your expense API whatever company you might use, in order to actually send the payload off to your expense agency for approval. So now we can tell it, hey, can you retrieve and summarize my dinner expenses from Las Vegas? So it will go through, it calls that first function, get uploaded expenses. It'll give you a nice, very clean summary, hey, you spent, you know, about $200 on dinners. Awesome. So I said, hey, can we, can we go ahead and submit these, right? Naively, I thought that in just about 10 minutes, I had nailed this. So I'm like, all right, we're good to go. Yeah, go ahead and submit them. And it said, sure, absolutely. Go ahead, it knows how to do it, right? And another thing that's kind of hard to show here, but in those functions, it actually gives a lot of descriptive kind of definitions of what that function does. Agent Bricks will automatically bring that in thanks to you need a catalog, so it just knows how to use these functions really well. So it goes ahead, it submits them, and it tells me, hey, you're all good, all 3 of your expenses are in. Cool. Let's fast forward a week, right? All of a sudden, I get my expense deposited in my account and I'm like. That seems a lot less than I spent. So I go and I'm like, huh, I need to, I need to go figure out what happened. So I'm gonna go into Genie. Now, Genie is our text to SQL solution, and I'm gonna bring in uh one of my tables, historical expenses. So this is where I'm pulling from my expense agency, just to see kind of what was submitted and, and what happened with it. And so now I can actually ask it, hey, can you show me if any of my recent expenses were rejected? And so it will go, it will do its analysis, as Craig showed earlier, it'll even give you the game plan and the reasoning that it used. And it came back in and said, hey, you have 2 recent expenses that were rejected. Both were declined due to the policy on desserts. Right? So if we look over here, rejection reason, whoa, more than one dessert per dinner violates the travel and expense policy. And I was a naughty boy in Vegas. I was getting double desserts. So let's fix that. Now, it wasn't the agent's fault. I just didn't give it enough context, right? It didn't know what the travel policy was, I never told it. So now we're going to go back into Agent Bricks, and we're gonna use our knowledge assistant. So if you go into knowledge assistant. You'll see we've made a very, very simple one. We gave it a description. It's meant to help users submit valid expense reports, and all we've done is pointed it to our policy documentation again in that Unity catalog volume. It figures out how to parse that PDF, and now I can actually ask it directly. Hey, can you give me a summary of why I can't get 2 desserts at dinner? And if it seems like I'm a little upset about it, trust your instincts. So you'll see, it'll even tell you what it's thinking, it'll go, it'll pull all of the information that it needs from our policy. And one thing that's really cool is it'll even come with receipts. So you can actually look to see exactly what it referenced within our policy in case you want to double-check that it did everything correctly, or if you want to copy and paste it and send a mean message on Slack, asking somebody why this exists. Now, because we have this knowledge assistant. We can go back into our multi-agent supervisor, right? And now, we're gonna add this knowledge assistant as another subagent that it can call. And while we're at it, so here you'll see that this one has a little bit more, right? We've got our travel expense agent. This is our knowledge assistant. We can also add that genie space that we use to figure out if the expenses, it was valid or not. So now our agent can call Genie to retrieve data. And then we still kept our original two functions, so we can still pull and submit our expenses. So now, when we ask it, hey. Can you retrieve any rejected expenses from Vegas? It will go through and it's gonna pass that off to Jeannie just like I did. It's going to get the two, you know, expenses back that were declined. It's going to tell you why they were declined. And then I said, all right, can we go ahead and fix these by removing the less expensive dessert, recalculating the totals? Sure. It goes, it checks with our travel assistant to make sure that we're following the policies correctly. And we're just gonna kind of skip through this. It's telling you, hey, all right, we applied these corrections, we resubmitted, and then at the end, It'll tell you, hey, look, you know, corrected amounts are gonna be a little bit less, right? But now they're actually gonna pass. And so I've submitted them. And then At the end, I can actually ask, hey, can you give me a detailed breakdown of my Las Vegas expenses to my genie room? It can go, it can pull all of the expenses that I've submitted, tell me that I had a total of 3 dinners approved in Las Vegas, all categorized as meals. Now I'm feeling much better, but I'm not done. There's 1 more thing I want to do. What happens if I share this, and now the next person comes along? They're gonna run into the same issue I did. So what I can actually do is I can go to improve quality, and I can start a labeling session. Now what I can do is I can tell it a question, hey, can you process a dinner, expense that has 2 desserts? Now, the reason I'm doing this is because now I can give it guidelines. I can tell it whenever anything similar to this is asked. This is what you need to do, you need to remove the less expensive dessert and recalculate the totals before submitting. So now I've not only fixed the problem for myself, but I've improved the agent for anyone that comes along. And you can imagine that as you start scaling these agents, you can have more and more people doing these review sessions, you can bring in your subject matter experts, and you can easily merge all of that into your agent, and I have written. No code. Doing this whole thing. Now, obviously I do need to know how Jason works, so it's not a totally no code solution, but it makes it so you can iterate so much faster. So, with that, I think it's time to hand it off to Vikram and Marcos from Conde Nast, who are gonna show us all the awesome things that they've been doing. Perfect. Can everyone hear me? Yes, great, fantastic. I'm Vikram. uh, this is Marcos, um, and thank you, Craig, and, uh, Nico for having us, um, and to my incredible account team. uh, thank you, Nasim, for having us here as well. So, um, you've heard Craig talk a lot about how, uh, Text to SQL empowers businesses. So, um, we had a similar problem. So earlier this year, my CEO came to me and said, look, Um, you built this incredible data platform on databas. Why is it that I cannot do self-serve or self-service myself, right? So we set about trying to figure out can we put text to SQL for, uh, to work in our specific use case. So that's the objective and that is the journey that we want to talk about. But before we get there we wanna talk a little bit about who we are as Conde Nast. We are a global media powerhouse. You would definitely know us through our brands, um, Vogue, Vanity Fair, uh, The New Yorker, Wired for those of you who are, uh, looking at tech deals over the weekend. Um, Conde Nast Traveler, if you're into food, obviously you're looking at Bon Appetit, um, you know, and others. Um, we operate in 12 countries. We are 22 global brands, um. And um we went through an interesting transformation in 2019. So prior to 2019, we were actually two separate operating companies. There was Conde Nast US and then there was Conde Nast in the rest of the world. Um, and the two of them didn't share anything uh in terms of process, in terms of technology. So in 2019, this was part of me joining Conde Nast. Somebody made the decision, look, we're gonna unify everything and we're gonna become one global company. At that point, 70% of our revenue came from print. Uh, it was only 30% digital. So, we started the unification process and it was more than just the data platforms, it was uh a total transformation of our entire system and our entire technology ecosystem. Um, and today, uh, our, um, revenue is 70% digital and, and, uh, 30% print. So in about 5 to 6 years, we have actually reversed, uh, where our money comes from. Uh, we support multiple, um, revenue, uh, streams, uh, whether it's commercial advertising, uh, whether it is, um, subscriptions, uh, we do live events, uh, we do, uh, puzzles and games, so our product line is very, very broad. So what I'm literally trying to tell you. Here is, uh, the problem that we were trying to solve with our data strategy was pretty vast. Uh, we needed to adapt, uh, that data strategy or the or futureproof our data strategy so we could evolve the data strategy to keep, um, to enable the business as it evolved. So, uh, 2020, that's, uh, that's our data landscape. Um, it was, yeah, it's completely decentralized, obviously, uh, we lacked any form of data governance, uh, privacy, data lineage, uh, business semantics, you name it. I mean, none of it really existed. It was purely in its infancy at that point, right? Uh, in fact, we relied fairly heavily. On, um, spreadsheet driven process if you wanted to, uh, get insights or KPIs, uh, about how our brands were performing globally, 2020 we made a strategic decision to partner with, uh, Databas, uh, and we've been a, uh, they've been a tremendous partner for us, uh, we. Remediated a lot of the challenges that I laid out previously, um, and what you're seeing today is a centralized data lake house, uh, where we have connected all of our data sources, but really what this enables us to think about is how do we put this data to use, right? How do we drive insights? How do we drive, um, you know, how do we report on KPIs, but more importantly, it has enabled us to build data products. Uh, on top of this, as we think about our customer 360, uh, our identity is fine, and how do we activate, um, both of those, right? Those are very important for us. Um, how do we plug AI and machine learning into this? How do we drive hyper-personalized, uh, audience experiences? How do we drive experimentation? Um, all of this is, is again, built on top of, uh, the data breaks, uh, foundations that Craig, uh, spoke about, uh, just a few minutes ago. Um, but there's more to it, right? So this year again, I was asked, hey, look, what's, what's the AI strategy? Um, you know, what are we doing about AI? Uh, and I think that's a question that everybody's been, been asking. An answer, and, and really maybe I'll, I'll try and explain this diagram a little bit so that it makes sense. We ended up building our centralized data uh uh warehouse, so you could see that in the orange. We've started to do things on top of that, right? But on the X-axis, as you, as you look at uh how we want to democratize our data, how we want everybody to use the data that's sitting, uh, within the lake house as close to the lake house as possible. Um, you know, we, we, we have a little bit of a way to go in that journey and the same thing with, with activation, but the point that we also want to make here is that as we transformed our, our, um, as the business transformed and as we transform and brought in, uh, all of our data sources into the lake house, we went through a fundamental shift, uh, in a variety of areas, and that changed how our KPIs were, um. Uh, work constructor, right, at the end of the day, uh, that was important. We had to build trust, yeah, and that was important. So maybe the point I'm trying to make here is if you don't have trusted, uh, data, if you don't have a ground truth, uh, for your data, your AI strategy is not gonna be successful as, as it scales. It may work for a couple of use cases, but. You know, think long and hard about your AI strategy, uh, independent of a data strategy, and this is our learning that we, we have taken, um, from this journey. Um, as I said previously, our, um, we have multiple brands, multiple markets, different revenue lines. Uh, every brand chooses to monetize, uh, its revenue differently, um, even within specific brands, sometimes the brand will do something a little bit different. So as an example, Vogue as an app will have a different monetization strategy, excuse me, than say, uh, Vogue.com. Uh, so. When we think about all of that, our data happens to be pretty dynamic. It's very, very, uh, disparate and diverse, and it's pretty complicated. Um, the volume is fairly high as well. We support both, uh, real-time and batch, uh, as I said, um. And of course, uh we have leveraged everything that the lake house uh offers to us we've, we've, uh, centered around the medallion architecture. Uh, we use the Unity catalog heavily for, uh, for, um, governance and everything else that comes with the Unity catalog. Oh, and when you look at Condeas and how our business areas, uh, are organized, uh, Mm thank you. um, you're gonna see that, uh, each of the areas, um, they have their own analytics team, uh they have independence, ownership, uh, and they have like a deep, uh, functional knowledge, uh, and what we question ourselves was, um, how can we enable collaboration and use collaboration of these teams so we can drive value faster. And we created like a uh what we call a federated collaboration uh strategy with them. So we partner with the uh business areas, uh, with the analytics teams, uh, we, they keep their independence, uh, autonomy, uh, speed, um, uh, and deep, uh, functional knowledge, but we try to create like a set of unifying, um, uh, uh, tools, frameworks, and data sets that it can use and, and move faster. Um, we work with them, uh, to unify also the semantic, uh, what of what they're doing, data quality frameworks, um, and other things like that, uh, and we moved that on, so the areas are exploring data within data bricks. They are playing with it, and then we received the question, OK, uh, how do we do, uh, to democratize our data? And this is where, uh, we start keeping the same philosophy so they can build and they can. Enable we enable and empower them to create their own text to SQL agents. So each of these independent areas started creating their tax to SQL agents and rolling that out for their stakeholders. So we have like executives, uh, asking questions to the to the data, having their charts and, and playing with it, uh, and, uh, learning a lot and, and changing a little bit the culture, um, after you do that, uh, you, so the, the question is, OK. Um, we look at the log of questions, we see that a few questions, they cannot be answered. Or they cannot be inspired by one, specific agent. And how do we, uh, connect these agents? And this is where we go to our, uh, super agent or the, our multi-agent supervisor. Um, that's, uh, Data bricks app, uh, connected to Agent Bricks that uses the different, uh, agents of, uh, the agent, uh, bricks that defines us, the multi-agent supervisor defines which agents they are gonna use, get to the answers, and get back, uh, with the res with, with the results. Uh, we use, we also connect to ation, that's our catalog tool, um, using instructions and, uh, judgment and, and guard rails on top of the multi-agent supervisor. Um, and that's usually, that's, uh, synced with, with unity, um. And um so now if a, if a executive wants to access our data, they go to the uh Data Bricks app, uh, put their questions, uh, agent Briggs decides which agents to engage, we get the answer and we go back. Uh, very nice in the PowerPoint, but Vikram is gonna show us a little bit like how that works in, in real life. Yes. Everyone can still hear me. So, all right, great, um, we start with the app screen and I think, um, Nicholas pointed out, uh, how to build apps so I'm not gonna get into this and again for the sake of brevity we've actually gone through and, uh, um, and done the work here so I'm just gonna walk through this very quickly. So as I said, uh, we have multiple brands. Every brand has, uh, different revenue strategies. We have subscription brands and in this case we're gonna talk about how the subscription brands are performing, uh, versus what is expected as you can see at the prompt at the very top there. Not sure, yeah, there we go, um, wondering if I should zoom in or if everyone's OK. And that is the prompt and that is then analyzed by the subscription so maybe a little bit of uh insight into how uh the agents themselves um are built subscription includes um everything that you want to know about the brand and it includes information such as the channels that um. The, the, uh, the, uh, consumers, uh, came in on, so, uh, and that's kind of important as, as we go through the, the demo. The second agent that we have speaks about audience and audience includes how our audience is consuming our content, but it doesn't necessarily talk about subscriptions or anything revenue specific. So when we run that, it, it runs through, um, and it comes back with the following response, right? It, it provides some insight into how the site is actually performing and in this case it's focused on Wired and it's saying look, Wired actually added 70,000 site subscriptions, uh, but in 2025 it, it, uh, we've more than doubled it. Uh, I do want to caution everybody this is not real data, this is demo data we're not allowed to share our, uh, our uh revenue and subscription numbers, um. Uh, publicly, uh, we are a privately held company, uh, so, um. Now, so it's, it's important for us to go a little bit further. So The New Yorker happens to be yet another subscription brand. So again, I, I went back to, to the agents and said, look, tell me how my top two, brands, uh, subscription brands are doing. And now it comes back and says, OK, the New Yorker actually has, uh, obviously it has more subscribers, it has about a million, give or take, uh, that's generally public knowledge, so I'm, I'm just sharing. That, but then it starts to get into um the comparison between the brands, right? So here it's talking about, yeah, sure, the absolute numbers for the New Yorker are higher, higher, but Wired shows more uh growth, right? All of this is like, yeah, sure, I mean, you can get all of this via any sort of dashboard, etc. right? That's great. But now let's get in a little bit deeper and we are gonna ask you the question, what is driving Wire's year to year uh growth uh inside subscriptions, right? So again for the sake of brevity I've already gone ahead and run it, um, and now it comes back and says look you wanna look at what the key growth drivers are and you remember I shared a little bit about a brand and how traffic gets to, to our, uh, to, to our properties, right? And this says look the top contributor. Channels happen to be social media. We see a lot of growth there, direct traffic, um, happy to explain these terms, but, uh, search, you know, it's generally OK. It's doing fine, but new channels have started to emerge, and this is very true for the, um, for media and entertainment in general. Uh, this could be driven off of newsletters and other subscri subscriptions, but AI traffic has started to add, uh, uh, a little bit of volume, uh, and it's, it's driving a little bit a few more subscriptions. Now we want to get a little bit deeper into the channel mix. So fine, you've told me that, hey, you're getting a lot of traffic from social media, that's great. But what specifically within social media? And that's where we come back with uh the following, right? So, um, I didn't necessarily speak about conversion rates, but I'm, I'm again, happy to get into all of these, but these are very specific to media and entertainment. So it says, look, search decreased significantly, direct traffic increased, social group, strategic uh referral uh grew, new channels have come in, and then it starts talking about conversion rate performance, right? Social has the most. Um, has shown the most improvement direct traffic and direct traffic for those who, who are uninitiated with, uh, with the and entertainment terms is when you type the, uh, the, the actual page or the URL and searches, you know, you go to Bing or. Or Google and that's, that's really what you're doing. But the notable declines are email, right? OK, so we're doing something wrong with our newsletter strategy now whether we should be doing more, maybe it's a content thing, maybe it's not a content thing, hard to tell again, right? Um, display, mm, not doing that great either. Google Discover again, right? So it, it provides us with a neat little summary of, hey, look. We're starting to see shifts in the way the traffic is consuming our, our, uh, audience. So now if you're the CEO of the company and you're looking at this, you're going, yeah, OK, that makes sense. Now you can start talking to your, um, to the rest of your leadership team about what the strategy here needs to be, what we should be focusing on, and what we should be spending our dollars on. I don't know how much time we have. We have just about 1 minute, so, um. Continue on. Yeah, so we should, why don't you wrap up with the, OK, can we go back to. Um, cool, uh. And, uh, what, what have we learned, like, uh, in this journey? Um, one thing is that what you probably are listening everywhere, uh, that if, if you don't have good data, you cannot, you're not gonna have good, uh, results. Uh, but be open because you can create, uh, curated data sets and, and, and plug in your text to SQL on top of the curated data sets and also prepare, be aware that you may need to prepare those data sets to work with, with text to SQL. Um, on the user questions, um, imagine that, uh, the agent is gonna, if you're using Tesus SQL, uh, is gonna provide SQL outputs for your questions. So if you ask something that could not be answered by a SQL, you're not gonna get the answer. And when you are building the multi-agent, remember that you can add instructions and guard rails to that layer. Uh, we forgot. So the way you, we know that all the, the data is, is tweaked is because we added the instructions for the multi-agent, and the multi-agent applies that to all of the, all of the data. Uh, some of the user questions, uh, they are not gonna be, um, they require additional training or guard rails, so you can't put an instruction saying like if you don't have complete data, do not answer, uh, to the question. Uh, when you're building advanced analytics, uh, you may need additional tables and functions, uh, and check when you have a new use case if it's, uh, it's gonna be like an optimal solution to use text of SQL, or if, if you need something different. And the final one. So what, what we, we have seen, um, Uh, with this, we increase a lot, uh, time to value, so each of the individual groups are building their own agents, improving their own agents, their own agents, and moving super fast. Uh, we have, uh, senior executives accessing, uh, our data and our agents, and we look at the logs, we understand what's not being answered, and we use that as an input, uh, to new requirements. So we create like kind of a flywheel, uh, of adoption. Uh, we, we have like, uh, new requirements, better data sets, better, uh, new questions, uh, things that we cannot, so we do a new data set and, and that has fundamentally changed the way that, uh, most of our senior executives interact with the data. We see that before they were like looking at the dashboard as a freezing thing, and now they, they have the dialogue, and that really, uh, generates a transformation, on, uh, on how we interact with our data in the company. Craig, Thank you guys. Uh, With that, uh. 1, Give data bricks a try. 2. Uh, conduct, uh, work to ping us, and we're happy to come on site and do a workshop with you on these topics, you know, introduce the team and kind of show them agent bricks and walk through some of the best practices, and then 3, get some training solutions and accelerators, you know, you can. Uh, there are, there are online training classes as well as some accelerators attached to our blogs that help you, uh, get started on this, and, and 4, when you fill out your evaluation on reinvent, give us the highest score of any, of any session you went to. Alright, uh, so yeah, that's, that's it. Um, unfortunately we are out of time, so we'll do some Q&A down here for anyone who has questions, and then, uh, when we get kicked out, we'll move out into the hall. So, but thank you very much for joining us today.