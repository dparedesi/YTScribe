---
video_id: osY67gy-BT4
video_url: https://www.youtube.com/watch?v=osY67gy-BT4
is_generated: False
is_translatable: True
---

Alright, good afternoon, folks. This is the first session of Wednesday, uh, afternoon, so we're excited to talk about Nova Forge today. So my name is Mark Andrews. Uh, we also have Karen Banarkar, uh, who's a principal product manager on the team, um, and very excited to, uh, introduce Nova Catala, uh, from, uh, Reddit. So, uh, and without further ado, why don't we get started? There will be a reveal, a superhero reveal later, so that's just to give a, a quick, uh, kind of a heads up. So don't be surprised. OK, so, uh, just a quick agenda we're going to talk about, uh, Nova Forge today. Um, to start, we'll tell you about how foundation models are actually constructed. This, uh, hopefully will kind of give everybody a warm up with respect to. How, uh, foundation models are actually built, um, so we'll go to some visuals and kind of help you understand that. Then Karen will lead into building your frontier model with Nova Forge specifically. Um, we'll introduce again Rosa to talk about the Reddit experience. We're very excited about the Reddit results, and Rosa will go into those in detail. And then Karen will actually wrap up with additional customer stories. So first off, so, um, foundation models today of course super capable. It's been incredible with respect to all of the applications that have that have been built over the last several years. Um, however, one of the big deficits in foundation models today is many of you will have intellectual. property that you own that these foundation models will not be aware of. So essentially there's a chasm here. There is a divide where essentially, uh, you know, uh, bridging the gap between, uh, what the foundation model is aware of and your organizational knowledge that hasn't been solved. You do have a rag as one example, but that's merely essentially a search and retrieval experience. It's the intelligence of your intellectual property is not baked into the model itself. So just to recap, so we have um rag approaches which essentially allow you uh to, uh, you know, retrieve context to provide intelligent answers to models. You can also adapt models um with uh Laura adapters. This is like fine tuning just as one example. This allows you to enhance, uh, certain capabilities of models, but it is limited. Um, then there's the expansion experience which is down here on the, on the bottom left. Expansion essentially like, uh, continued pre-training. This is a great approach and, and some of you may have done this with, uh, with open weights models. However, you may also be aware of the risk of, uh, catastrophic, uh, catastrophic forgetting, uh, which is a real issue which we have solved through Nova Forge, um, and Karen will talk more about that later. Uh, the other thing you can do, of course, is building your own model. Um, however, this is enormously time consuming and costly, both in terms of acquiring the data to actually train a foundation model from scratch, plus the GPU hours required. So essentially, Nova Forge gives you the ability to fast track that in terms of developing your model from scratch while significantly lowering the cost of developing that model. So we're excited again. Matt Garman yesterday announced NovaForge at the keynote. We're super excited about this. This is like, we believe, one of the most amazing experiences we can give you all as customers to be able to develop your own foundation models, leveraging the power of your intellectual property at each of your companies. Just to kind of give a quick recap, uh, you know, Nova, like Nova is a family of models essentially. So we have the models that were introduced last year, uh, microlight and Pro. Um, we have, of course, the exciting models that were, uh, announced yesterday. We have Nova Nova Light, um, which is a super capable model. We have Novaro, which is our most capable, uh, capable model as early access, and Omni, which is a multimodal understanding model, um, uh, in, in preview as well. So these models have all been demonstrating super exciting performance results with respect to industry benchmarks, um. Comparable to many of the other frontier models in the industry like the latest and greatest models, so we are super excited to see that this is the foundation that essentially you can start with. So you will be building on some of the most capable models in the industry, adding your foundational data to that, and enhancing the capability of the of your very own model to basically produce value for your business needs. So, OK, let's talk about like how do we actually build a foundation model. This, this hopefully gives you a kind of a a a precursor into how how this works from scratch. So essentially we start with an empty model. This is essentially, think of this as architectural scaffolding. This is essentially the structure of the of the model architecturally. It doesn't contain any data. Uh, then we introduce, uh, uh, uh, pre-training, uh, data, and, and this is like extensive amounts of data to essentially help the model understand the world, like it helps it reason. Um, I like to use the the example of, uh, Grey's Anatomy. Uh, that's the medical textbook, not the TV show, just to be clear. Um, so, uh, think, think about all of the foundational knowledge in, uh, in, in Grey's Anatomy. It, it, it's one of the most, uh, elementary medical textbooks in all of history. It's been updated for the last 150 years. It's incredible foundational data to be able to train a a medical model as an example. Now then, let's say you, you have a company that's specializing in dermatology. This is where the mid training phase comes in, and you may want to enhance the model's understanding specifically for, you know, skin disorders and skin treatments and medical protocols for treatment and so on. And this is where the the mid training can come in here. And then the very last stage is essentially fine tuning. This is where you enhance the model. Like this might be your treatment protocols with respect to your company. Maybe you've developed some intellectual property around, uh, basically, uh, you know, uh, treating procedures and having an industry leading procedure, and this is where you can introduce that signal so that your model is essentially super tuned to the way that your business wants to operate. So this gives you kind of a, a relatively holistic understanding using this example. Um, and then just going into a little bit more detail, um, look, uh, again, starting with pre-training, uh, we essentially leverage a lot of web content, uh, long form context, texts, like example, like the Grey's Anatomy, uh, medical textbook, uh, textbook example, um. And essentially this is a this is a lot of unsupervised learning. So, so the model will learn essentially, uh, it's uh core world knowledge, uh, basic understanding of the world and, and how, and how to understand it. Then at mid-training, it takes the pre-trained model that we actually, uh, just, uh, prepared beforehand. Again leveraging the example I gave, this is where the uh the uh dermatology example comes in where you give it specific enhanced information about the dermatology context. Um, you feed that into the model. This gives the model much more competence in that dermatology domain which is, you know, the, the analogy is your business domain, um, and then, uh, the last step is, uh, is essentially, um. Uh, post-training, there, there are two main parts to this. I like to talk about, uh, or I like to think about this in, um, essentially dog training. Uh, if you think about dog training, there are typically two steps to it. Uh, there's the, you know, you, you go to the, uh, uh, dog obedience school, which is kind of SFT, the supervised, uh, fine tuning. Uh, this essentially is where the dog learns kind of rote experiences, like basic experience about how to behave and whatnot. But it's not really a real world situation, you know, obedience school for dogs is not necessarily the real world. So the next thing we want to do is think about, OK, well, in the real world, how do we actually help the dog actually understand, uh, reinforce good behavior. Like if we bring the dog to the dog to the park for the first time, there's loads of distractions, there are dogs, there's lots of humans, there are balls flying around, you know, we want the dog to essentially behave properly. Properly. So this is where reinforcement learning comes in, and this is where essentially we reward good behaviors. And you know, uh, like an example might be a treat for good behavior. Um, if, if, if they do something that we don't like, like they run after another dog's ball or something, this is where we reinforce it with no. And this is kind of just the example of how we essentially build that super capable fine-tuned model for your business case. All right, so with that foundation. I'm going to pass on to Karen, who's going to talk about the exciting details about how Nova works on NovaForge works on the inside. Thank you, Karen. All right, thanks Mark. All right. So this is the part where we actually start with a bit of a pop quiz, um, to decide how much you've been following so far. So everybody ready for an exam? No, I'm just kidding. Um, I think we're just getting into the fun stuff now. Um, so, OK, so Mark gave a really good overview as to what it means to build a foundation, Mark, right? At Amazon we build Nova. The steps that he described is what how Nova was built. Now we're going to talk about why the approach that we're taking with Noah Forge is such a game changer and why we believe it is democratizing access to frontier AI for every organization. In this segment, we're gonna talk through the five key benefits of Noma Forge. Um, I'll talk about the whys of each one. I'll give you the examples of why you should care. Uh, we'll get into some of the details as, as well. Um, and then towards the end of the session, we can sort of meet on the side for any further questions that you might have as well. OK, so first, Access to checkpoints across all phases of model development. Now, what does that even mean and why should you care, right? So going back to Mark's earlier example of with the slides, these models are essentially trained in 3 high-level stages, right? What we call pre-training, mid-training, and post-training. What we're giving you with Nova Forge is access to every stage of training. We don't want you to start from scratch. We don't want you to start all the way from the left. We don't even want you to start all the way from the beginning of pre-training. What we're saying is, depending on the kind of data that you have and the volume of data that you have, we'll open the training. We are creating, giving you a paradigm that essentially opens up the training for you to inject the data that you have in the right place for the model to learn sufficiently enough from it. So if you have instruction pair instruction response pairs for fine tuning, uh, where you have a lot of samples of what an input and a right output looks for, you can start all the way at the end in post training and do just fine tuning. Uh, if you want to do some more reinforcement learning, you can start all the way at the end from the post-training model checkpoint and do reinforcement learning on top of that as well. If the amount of instruction response pairs data you have is a lot, you can go one step further up. You're like, OK, I have a lot of data, even though it's for fine tuning, so I really wanted to learn from this. So I'm gonna start fine tuning from the mid-training checkpoint. Now, you might have some unstructured data. Now the unstructured data might not be a lot, but one of the high value aspects that we've seen as these reasoning models have come out in the industry this year, you might have chain of thought kind of data, where it's really high value data because you're actually showing these models how to think in your particular domain or think for your business specific use cases. So that kind of data, intermediate volumes of unstructured data which may not be chain of thought data or anything else, like if you want to refine the behavior on something like tool use, you can introduce that kind of unstructured data at mid-training point. But if you have vast amount of data, you're operating in an industry, a business, an area where either there's just no way the model has seen this data just because it's your proprietary data, or it could be in a domain where these models have been trained on to some extent because there's a lot of public data on it as well. But these models are general purpose models, so they just haven't been optimized for that particular domain. So if you have that kind of a scenario, then you can start all the way from the beginning of like a pre-training checkpoint. So what we give you is a checkpoint that's at the end of Nova's pre-training, Noah's mid-training, and Nova's uh post-training, so that you can introduce your data in those stages without having to start all the way from scratch. Now you might ask me, hey, Mark just showed me a slide, and it said that the pre-training and mid-training stage at the end of it is what's called a base model. Now, I do get a base model from Open Weights Models. So why should I really care about your pre-training checkpoint, right? Aren't you just giving me You know, is this all smoke and mirrors? You might have that question, and that's a good question to ask. So there, I think we need to get a little bit into the detail of what the training process actually looks like. So the way these training, so you know, we've talked about toss a bunch of data, these models are trained, right? But there's an aspect here that's important to understand, which is the learning rate, right? The analogy that I really like to use for such examples is think about when you go into school or college or any of those kinds of things, right? First, there's a warm up phase. This is your first day in school, first day in college. You're essentially getting the syllabus, the curriculum, the textbooks for the first time in your hand. You're looking at what this even is, who the professor even is, how should I approach the rest of the semester? Those are the things that are going through your mind on the first day. Imagine if I taught you the most important content on that particular day. You don't wanna do that. There's no way you're gonna learn any of it. So that's what we call this the warm up phase. This is when you actually activate the learning rate. Uh, this is more of a visual representation. Uh, different models have different what we're going to get into learning rates. Some do exponential, some do constant learning rates, but at the end of the day, there's an aspect or a concept of learning rate. The learning rate is essentially the rest of your college semester. Now this is the aspect where you're learning, right? Every day you get some new information, you learn from it, you move on, go to the next day, learn from it, and this is how the morals are trained. So the entire journey of pre-training or retraining is essentially the pre-training is with this learning rate because it's not a sprint, you really wanna learn everything from it. At the end of the semester, essentially what happens is what you call annealing. Now, annealing, the analogy I like to use for that, it's like the morning before an exam. Right, you're pulling out your notes, you're pulling out your flashcards, you're trying to focus on all the most important things because you're about to write just now walk into an exam, right? That's the process of annealing. In the model terms, what we do is all the if whatever is the most important data, what is the most high value data, it sees it in this stage of training and annealing, and the reason it's called annealing, and you see the learning rate drops, is because at the end of the stage is when we tell the model, all right, you're good to walk into the exam, you're done learning. But now this is where it gets interesting, right? Base models are available today, if you see where they are. That's the learning wave that you're operating with. So if you have high volumes of data, you really want to be coming in there. So that's the benefit of starting with a pre-trained model checkpoint. Like that's why this is important to you, um, and then the post-training, you know, we've talked about it in the past, fine tuning and all those other aspects, Laura-based adaptation techniques are popular in the industry, but at that point you're doing more post-training and refining the behavior. So if you have differentiated proprietary data. That's essentially where you want to introduce it. Now there's another aspect to this, right? So if you continue with the same analogy, you get access to blend, you get the ability to blend Amazon Nova Curator training data with your training data in all those stages, right? Now why is this important? Um, I think catastrophic forgetting is a term that's said a lot in the industry. So we get a little bit as to like what that means, if it's even real, and how Noah Forge helps you solve for it. Now, let's take an example. Let's go back to the analogy that we were just doing uh with an exam the morning before, right? Uh, you're about to walk into an exam in 3 hours. I come up to you and it's like, hey, I know you were preparing for this biology exam, but actually it's a biology per math, biology plus math exam combined together. Here's a math textbook. Learn everything from it because half a grade is based on that. That's gonna be a great feeling for you, isn't it? So that's essentially what happens when you're doing pre-training or mid-training, where you're essentially introducing a ton of new data late in the stage of the training. Now the problem is you're gonna try and learn as much as you can from this new content. The risk there is you're gonna start forgetting some of the things from the previous content that you weren't learning from. So essentially what we're giving you with the ability to blend Noah's data with your training data is we're giving you the biology and the math textbook as you walk in, so that you can not only refer both those materials, so as you're learning the new content, you still have an eye on the previous content that you learned, but it's also you're now with these two textbooks in front of you, you're able to connect the dots between those two materials better too. So what that translates into for foundation model development, if you have a lot of proprietary data, let's say you're bringing in data for the healthcare domain. You don't want to forget everything else. These models have been trained to reason. You want to be able to, you want these models to reason in your domain as well. You don't want to lose out on all the foundational skills only because you're introducing your proprietary data. That's the of Noah's data. So on the pre-training stage, mid-training stage, you get the ability to use Noah's data, mix it with your data, so that you can mitigate such aspects so that at least the general purpose foundational capabilities, you're not sacrificing that just to be able to build your own foundation model. And the same thing applies on the post-training side as well. An example that I like to give a lot is considering the fine tuning side, right? Is everyone here familiar with instruction following to some extent? I feel like. Sort of familiar? So instruction following is an aspect is, you know, you ask a model something, it follows your instructions, is fundamental for any large language model that's out there today, right? Doesn't matter what kind of use case you're using it for, you want it to follow your instructions, right? Like that's at the end of the day, that's what you're doing. So, so, when you introduce new data and fine tuning, a lot of data, yes, you wanted to learn from like what is the right output for the for a given input. But you don't want her to forget how to just answer Q&A, right? Like you don't want her to forget the basics even on the fine tuning side of things. So that's where, that's why we provide the ability to use Nova's security data across every stage of training, because it's important not to forget the foundationals with the new information that you learned in each stage. All right, so I just threw a lot of theory and concepts at you. You might be like, all right, is this guy just making stuff up? Uh, where's the proof, right? Uh, so I'll give you an example, um, internally, uh, stores Foundational AI, uh, this is the team that sits within the store's organization at Amazon. Uh, they're one of our internal customers as well. So we took this approach to them, right, to see, do we have anything here, right? Uh, so the store's foundational AI team, now naturally they work, they have a ton of use cases in the shopping domain. No foundation model out there has been optimized for a vast variety of use cases in the shopping domain. So they set out to sort of create a foundation model that addresses all use cases as possible, as wide as they can go in the shopping domain, right? They don't care about other domains. All they want is all the tasks in this particular domain, this model is really good at. We tried all approaches that were out there, all the way from simple fine tuning to continued pre-training and fine tuning and all those approaches that are there with open weights models as well. And then we took Noah Forge to them. What they found, and this is what I like to emphasize, is the two key dimensions. When they took this approach of starting with a checkpoint from Nova, and the checkpoint is the stages that I mentioned, right, so they start from a pre-training checkpoint because they have a ton of data, obviously. Not only were they able to improve the performance by about 10% on their current production model baseline. The MMLU benchmark for those who are not familiar is multitask language understanding. So across a wide variety of tasks, understanding the language of that, just understanding the language. So there's a benchmark called shopping domain MMLU for multitasks in the shopping domain and understanding. They were able to boost the performance by 10% on what they currently had with similar approaches with other models. And not only that, they were also able to boost the performance on just standard language understanding. So this is the example of when we talk about the instruction following and maintaining the foundational capabilities that I was talking about, they were able to not worry about regressing, but they were actually able to even boost the accuracy further, even on the general purpose aspects because you don't want these models to forget about things like instruction following. Now we've talked a bit about pre-training, mid-training, what Noah Forge has to offer for you there. A little bit on the fine tuning side of things as well, because you can use Noah's data there too. Now, on the reinforcement learning side of things, the reinforcement learning progress in this year is what's really been key for these foundation models to get really, really powerful on general purpose tasks, right? So, when we say we want to give you the flexibility and control and democratize AI, we want you to be able to introduce not just your data, but also your environments to train these models, right? So on the left hand side what I have is what is today commonly referred to as how we do reinforcement learning, just the industry standard way, right? Uh, for customers who are just getting started or still doing the light reinforcement learning, uh, reinforcement learning, the way it works, it is we are essentially trying to reinforce good and bad behavior, right? So you don't need a lot of good data, bad data, but as long as you have a way to curate some form of reward signals and rewards being thumbs up, thumbs down, this is good, this is bad, this is a 2 out of 10, this is an 8 out of 10. You can even just start with something like reinforcement learning, and there's a few different approaches or ways to go about it. It can be as simple as starting with a regX pattern, uh, because you might want to do some pattern matching and give some 2 out of 10, 8 out of 10 kind of scores in training. You might want to take another step further and introduce or use some sort of Python functions, right? And like write some custom code to sort of say, OK, if these situations happen, weighted this much, if these situations happen, weighted that much. Or if it's not something that's deterministic in that way, you can take the LLM as a judge approach, so you can go on the what we call verified and non-verified reward side of things. You can also do non-verified rewards, but it's not as simple as if this text matches this text, then give it a 2. If this text matches this text, give it an 8 out of 10. It's a little more subjective than that. You're getting into the nuances of if I ask for a summarization and the text is 4 sentences long, that's a 2 out of 10. But if the, if the sentence is 8 or if the paragraph is 8 sentences long, the summary, then that's an 8 out of 10. So you're trying to get into the nuances of that. So in the in this industry standard, you do have a lot of options to do reinforcement learning today that are really good. But when we talk to customers, we realized that that's just not enough, right? At the end of the day, all of this is in a managed environment. You need to upload your Regex code, you need to upload your Python code, and the training environment is all managed for you. But imagine you're a lab where you're doing, you know, drug discovery as an example, right? You, it's not as simple as I'm going to upload Python code to verify if the molecular properties that are being generated by this model are accurate or not, right? It's just not that simple. These scientists who are in labs, they have, let's take as an example, some sort of simulations or some sort of tools or chemistry toolkits that they will have in their own internal environment, in their own internal labs that they need to somehow now replicate in the form of Python functions. That's just never gonna happen. So what we're also introducing as part of this, as part of NA Forge, is we want you to be able to use your own proprietary environments, not just data, to train these models as well. So there's two ways to go about it. You can bring your own endpoint. So the simulation example that I mentioned, if you wanna just, you know, make an API call into your environment, get the reward calculated score there, send it back, you can do the training loops that way, or you can go something even more complicated, right? Especially in the world of agents, it's not as simple as one hop, right? But it's, it's not rewarding things on one step at a time. It's rewarding one function based on that output, the next output, and the next output. So thank you you're doing coding related tasks. It's not input and output. If you're doing robotics, it's not input and output, it's pick up this package and then move to the next package and drop it off somewhere else. There's multiple steps involved in this process as well. So Noah Forge what we're introducing is also the ability to bring your own orchestrator. So what this lets you do is not only plug in your real world environments. So if you have a robotic simulation environment, you can plug that in for sure. But we'll also let you use your own orchestrator, so you can actually control the rollout. Now, what does the rollout mean? when the output of the model comes into your environment, you decide what happens in your environment, send the score back, and then you can actually do reinforcement learning across multiple turns by being able to just use your own orchestrator as well. So, as you can see across all the avenues that you have, pre-training, mid-training, post-training, we're giving you as many keys as possible to essentially help you build your own foundation model using Nova as a base. Now, you might say again, it's like, cool story. wow, is this really valuable, which would be a good question. So, the example I like to use is from Cosign AI. They were our design partners. Uh, they're a start-up based out of London. You should check out their work. They're doing some really great stuff, uh, pushing the boundaries on Frontier AI for the coding space specifically. They were the ones who helped us design this because of the aspects that I mentioned. They have an internal tool calling harness that they use in their production environment to sort of generate code. Now they already have these tools to generate the code, so why can't, why not use those tools to do the training as well, because the tools already know what's good and what's bad. So we set up this multi-ttern experience working with them on what such a thing would look like so that in the training loop itself through an API-based approach they can orchestrate the rollout on their end. So, the call goes into their environment. They can call a specific tool, take the next step, call a different tool, take the next step, call 3 different tools, do some sort of nested learning. And then send the reward signal back that's used for training. So not only do we want you to use your own data for training, we want to be able to use your own environments for training as well. And this scales across industries, right? So this is an example in the coding space, but whether you're doing manufacturing, whether you're doing robotics, whether you're doing science experiments in the lab, across every industry, there's a scenario where if you're able to use your simulation environments, your environments in the training loop in itself, you can go a lot further. Now that's the training process, but Noah affords us a lot more than just access to access to checkpoints and data. The fourth aspect that we talk about the StageMaker Hyperpod recipes. Now what are StageMaker Hyperpod recipes? The recipes are essentially an abstraction on the training code in itself because we don't want you to have to be an expert in ML or AI to be able to do this, right? We want to democratize AI. We want to democratize access to Frontier AI. So what we do is we offer config files that sit on top of training code so that you can then actually configure every aspect of training and the training code in itself through these config files that sit on top that make it really easy to operate in these environments. Those are the push button recipes. And the other aspect is these recipes are optimized to maximize, maximize performance lift with Nova. Now what do these things mean? So the hyperpot recipes are quickly covered to make it super easy to essen essentially execute training training runs where all you have to do is select a recipe. A recipe is, you know, I, I wanna do pre-training or I wanna do mid-training or I wanna do fine tuning. You select a particular recipe for mid-training or fine tuning. You specify the training data in the config file or in the recipe that I just mentioned. And you hit run. It's as simple as that. We also know that customers of different types prefer different customer experiences. So if you prefer a CLI based experience, you wanna be in the notebook, you wanna be in the weeds, you can do that. We make it easy to do that with these recipes. Or if you want to execute a large number of experiments at scale, just, just in the beginning to quickly get. Started, right, the CLI experience is great if you wanna orchestrate things, um, you know, commit code back to repositories, maintain pipelines, it's great for that. But even if you just wanna execute these runs very quickly just to try a few different things, we want, we make it super easy for you to do this. So an illustration here is all you have to do is select the checkpoint that you wanna start with, enable the data mixing with Nova data. And these recipes already come preconfigured with Nova's data ratios to essentially help you quickly get started. And it's not just the training part. We want to make the end to end life cycle super easy. So in the same UI once the training run completes, you can trigger evaluation runs, you can trigger model deployment to an endpoint, or you can even continue customization with the model that you just trained. You fine tune a model and you wanna continue fine tuning that same particular model, you can do that too, all from the UI. Now, I said these recipes are optimized to maximize performance with Noah, right? Like what does that mean? This is also another big differentiator compared to what's available out there with the open models, right? Uh, yes, checkpoints are available, um, especially from mid-training and post-training, but what we're giving you, these recipes are built on top of the code that was used to train Noah in itself. Like this is the same code that was used in building the Noah Foundation models as well. So what that means is when you use your proprietary data with these recipes, these recipes are already optimized to maximize the learning from the data that you're now introducing. This These recipes are also refined in research collaboration with partners. And once we make these available, what I was just showing in the slide before, we do provide you with smart defaults, so you don't have to spend too much time optimizing the recipes in itself. Now I love giving examples. I'm gonna do that in this situation as well. Now what does that mean? Consider a scenario where you're trying to build a foundation model that's a, that's an expert in a domain specific language, right? So an example would be if your company has developed some proprietary coding language, you want this model to be really good at that. Let's, let's take that as an example. So in that particular example in itself, we actually partnered closely with the Computer Science and AI lab at MIT. To optimize the recipe for something like that. So they were trying to build foundation models that are really good at metamaterials design, but at the end of the day, the metamaterials are nothing but just proprietary code. Um, and what that results in Let's take Appian as an example. So Appian was a customer in beta. They have their own proprietary language for process automation. So this is process automation. Uh, their current production model was Sonnet 35. They've been experimenting with Sonnet 4, but what they found is that by fine tuning NA, not because of the optimizations that they've made, they're actually projecting exceeding the performance of Sonnet 4, but while benefiting from the cost and latency aspects of NA, that makes it cheaper and faster to essentially achieve the same kind of accuracy results. Last but not the least, it's not just the training, it's not just the experience, but it's also the safety and the responsibility aspects of these model trainings, right? We want you to be able to configure these to meet your business needs as well. So the training data that I mentioned that you get from NoA to involve in training, you do get access to the responsible AI and safety data that we make available that we use for Nova's training as well as part of it. You wanna evaluate your model on Nova's responsible AI dimensions, you can do that as well. We provide the same runtime controls that ensure that Nova is, we prioritize safety and responsible AI for Nova, so you get the same runtime controls to ensure you can do the same with your model as well. And it's not just the controls we allow you to configure the controls to meet your business specific requirements as well. So say you're a security firm, you're trying to push the boundaries of what can you do, uh, for say cyber testing, right? You wanna make sure that if you're testing for cyber attacks, you're able to do that. You want these models to be able to produce that. The general purpose foundation models that are out there, they just will block you, right, because they're trying to protect general purpose use cases. Or if you're in media entertainment, you might own some proprietary characters. These models would block you from generating that because generally they want, don't want you to block it. But if you're a company X that has a lot of proprietary characters, you want the model to be able to generate them. Like you don't want the models to be blocked. So even on the responsible AI and safety aspects, we want you to be able to adapt these models to your business specific needs. Next up, I talked a lot about the things and I try to give examples as much as possible. Palakam Rosa, who's been an incredible partner through the entire beta process in itself, will tell you why this mattered for Reddit. So, hi everyone. I'm Rosa Cata Catala. I'm a distinguished engineer at Reddit. And today I would like to share um what has been our experience. In rethinking online safety by building our own foundation model using NovaForge. So, uh, let's explain why, why we are here, why, why we were interested in partnering with the Nova team, uh, for our contmoderation and safety operations. So, one of the main goals that we have is to democratize online safety across the entire platform. The problem is, and I think is what we encounter is the coverage lack and the scalability in getting to that point. So The way, the best way of thinking is in traditional or legacy ML models, how they learn. They learn on history. Therefore, you're always playing catch up when you are facing a new emerging trend in the platform, new communities, new slang. The models have been trained on past data, and they remain blind until it's too late. Um, so, what is the solution to this? The solution to this is hyper personalization in the way we protect and we support our communities with our safety capabilities. But What that means. That means that we will need to train. 100, 100,000 models to serve our communities, more than that, in fact, because on on top of serving every community in the platform that's democratizing uh safety at Reddit. It will require also that you make these models really performance, so you will have also to invest on fine tuning, on making these models very performance for specific task. OK. So, we have a goal, we have a constraint. What is the role of Nova Forge in our journey to try to get at the democratized online safety that we are striving for? So What Nova Forge unlocks for us is breaking this trade-off between Um, between specialization and, uh, scalability. How we can inject our rich graph-based context that we haven't read it, about what users intent, what moderators need. Uh, how communities react. At every point of the training, the creation of your own frontier model, exactly as Mark and Karen showed, we can start using different levers to create a model that is an export but generalized to new events. OK, so. How we do that? So, the situation, let me explain you first where we start. At Reddit, we are, you know, uh, we are in a situation of maturity and safety. So, we are moved past keywords and simple rules. We use proprietary and sophisticated models to protect our platform. The problems are not the models, or even their performance. The model, the problem is how we use them. Because all those models are going to require a rich context awareness that they don't have because most sophisticated, uh, state of the art uh AI models have not seen our proprietary data. They don't know about the reactions and the interactions between users, moderators, communities, participants at the end of the day. But we have this data. OK, so that's. One gap that we have, and we call it the knowledge gap. Native Reddit, uh, or a model that speaks Reddit is not available yet. OK. The second is that, you know, can we reduce The dependency on fine tuning for more performance models. And The importance of doing this is 2, right? We need to avoid um The, the, I would say the very hard operational wall that is to scale all these nuance that we present to the models. The second, and I think it is the most critical from a safety, safety standpoint, is that we want to be able to protect. Our users at all times. If a new threat emerges, we detect it, we need to gather data. We need to train or fine tune a new, uh, model, an adapter, and then we're going to go and to deploy it. It can take days to weeks, and in that time our users are exposed. Um, at Reddit, we have, uh, adapters, we call it shields that protect our users from spam, from harassment. Violent content, and many more. Even, imagine if I want also to put the context of, for example, how that will play out with the norms of, of the rules of our science. This makes this incredibly complex. OK. So, Then we call the superheroes we call Nova. And we say, look, let's start with measuring performance. Can we use Nova, maintaining the performance that we are looking to protect our platform with the most high level standards. And What we need is to start with uh measurements and evaluations that we have ground truth. We have data that explains how moderation, how moderators in particular, how safety ad means at Reddit and how communities react to different types of content. Then what we also have is this grand truth that optimizes for the reality of Reddit, not for an external general benchmark. Once we have this evaluations or measurements, we go to the refinement stage. We started, we didn't start back with pre-training, we started with supervised fine tuning. Now, the supervised fine tuning was using um. What we call incremental learning. So we went and said, look, content moderation is incredibly complex and once. It's not a simple 0 and 1. So, what we did is to teach the model incrementally. Like the same you are in a classroom, you teach the model the fundamentals. And then you start increasing, graduating the model as it learns with more complex, moving into complex ones. And Then, this we said we said, OK, this is a first checkpoint that we're going to do. The second, the 3rd point for us was, can we now cover a knowledge gap? And the knowledge gap is thinking about pre-training, starting with a pre-training checkpoint and saying, can ready data get mixed with Nova data and we see that the model learns to become more capable of understanding, reducing then the intensity, the frequency of labels and fine tuning compute that you need afterwards. So, this is the program, uh, how we started to collaborating or partnering with uh the Nova team. I want to say that it's important for us also to think that Reddit is about humans at all levels. Humans that interact in conversations, humans that interact saying this is a content that I like and a content that I don't like. So we have tons of labels that are not just explicit labels but implicit labels, so that's where the unsupervised learning becomes so scalable for Reddit. And in terms of the fine tuning work, I would say also to say that what we are learning with Reddit with with Nova, is that we can scale our human in the loop operations. That what that means it means that when we extract. Um, answer from Nova, we don't, we don't aim in safety detection for complex generation. What we are looking for is for the classification and the representation of the data with uh what we call uncertain uncertainty awareness, so we can then rank all the um. The responses of the model and prioritize what our AI ops needs to review to provide feedback to the model, reinforce the model and use the post alignment in the most efficient way. OK, so let's talk about results. Uh, in the first stop of the journey to use on the left, you have the supervised fine tuning. Here what we are looking is how the model one has been fine-tuned with this curriculum supervised fine fine tuning and this uncertainty awareness, what we attain, right? And we compare that against our ready proprietary, uh, ground trust. And what you can see is that we were able to reduce the number of pipelines while maintaining or increasing performance. In fact, across the number of pipelines that we reduced, we were able to increase precision by with 26% uh percentage points and uh recall by 16%. That's pretty amazing. But only we're doing not only that, what we are doing is also reducing the amount, the amount of inference. We're going to make it, we are making it fast and cheap with this uncertainty awareness that I mentioned, but it's also you are reducing the number of fine-tuning compute and fine-tuning pipelines that then you have to call an inference. OK, so. Check mark here we were able to avoid the model per task bottleneck that. Uh, uh, fine tuning and export models create so we can go back to the idea, OK, we can democratize, um. Um, online safety. By using by gene by being um. Very expert, but with with a fraction of the cost of computing and uh calling these models. Cool. But that's not enough. We went then to the pre-training. Stage and then the pertaining stage, what we try to do is what I said before, can the model learn more nuanced context by going uh a step up back, right? And why that's important. Because all the implicit labels that we have read it. That can, the question here that we're trying to solve is, if we mix Reddit data with Nova data, because the Nova pre-trained checkpoint smarter for Reddit use cases. And the answer is yes. We were able to ground Nova on Reddit uh intelligence and obtain what we call a superior model for two reasons. It is able to, uh, 25% reduction in missed threats is massive for safety operations. It means that we are a more resilient platform. It means also, if you see the precision and recall uh trade-off also becomes more flexible. We have higher sensitivity. What that means? That means that the model now is not just guessing keywords, is understanding what uh content violation. Represents and means at Reddit. So I think now we are on a path in which we can combine the power of continuous pre training. And fine tuning, supervised fine tuning. And what we expect to do. With this or to obtain is increase increasing benefits compounding the benefits leading to this democratized online safety that supports scales uh to the long tail. Without drowning us on engineering that. So, I think we can go a step further though, as Karen was detailing just before me, what you can take now is these pre-trained models, these fine tuning models, and combining with the post-alignment phase. This means that now if we want to. Create hyper personalization that is already aligned with the policy. That we are learning from the ground up already with safety. We can create new, more exciting, I think, user recommendations. Ads ranking. And I think then we can talk about a Reddit Nova Frontier model. That's a journey we're on. We're very grateful to the Nova team to allow us to, uh, understand the capabilities of what they built, and it's really, really exciting. I think Karen can talk about other users, other customers that have been also already interacting with Nova Forge. Thank you. Thank you. Hm Thank you, Rosa. Alright, so, Rosa explained how and why Forge is Reddit, important for Reddit. I'll quickly get through a few other examples as well, just to show you that it's not just about one specific area or one specific domain, but in every domain, in every business operation that you're in, there's value that you can unlock by building a frontier AI model that's built, that's purpose-built for your, for your own business. So let's take an example of Nimbus Therapeutics. Their use case there is to build a drug discovery assistant, right? They're a small startup, they want to see how AI can help them scale, bring better medicines to patients faster. Now, the, the use case was to build an LLM that can help them with pharmaceutical R&D and drug discovery, and much more. The approach that they tried to forge was supervised fine tuning and reinforcement learning. And the results that they achieved was a little similar on theme from what we saw with Reddit as well. They were able to converge several of their graph neural network models that are actually specialized models for scientific tasks into one model that was built with NOAA. And not only were they able to converge those things, they got a model now that outperforms any other model out there, any large language model of any size for their particular use cases, but while giving them the latency and the cost benefits of operating at Nova's point. Let's take a similar example in a different domain, Financial services. I like this example a lot because it combines two things, not just expertise in financial service, but specializing in a different market as well. So, a financial services LLM in the Japanese market. Uh, Numura Research Institute was building a financial services LLM, uh, that's an expert for the Japanese market specifically. The approach that they took was continued mid-training, uh, followed by the rest of the post-training process combining their proprietary data with Nova's training data. The reason they were doing this was they were trying to evaluate this as an alternative to what they're currently doing with Open weights models. And the results that they saw was, yes, that they are able to do this. They were far able to exceed the performance that they had with a similar approach with open waste models. Let's get into a different domain. Let's take the Sony Group. The Sony Group was trying to, it has started uh to drive AI business transformation across all of their business units, as you can imagine, um, there's a lot of diverse businesses, a lot of diverse operations in a bunch of industries even within just Sony. So they want to build a legal research assistant that can help us accelerate some of the processes, uh, to help them scale the AI adoption process in itself. What they found was that they were able to just, just through reinforcement learning, and this is why I say it's like it's not about always just doing pre-training, it's, it's about entering the stage that's right for your business specific need and just through reinforcement learning for this specific use case, they were able to exceed performance of the larger language models but again benefiting from Nova's price and latency performance. Um, so in this case as an example, they were able to exceed all of their performance that were out there, the largest models available as well. And this was specific for a legal use case. This is a theme I hope you take away from here, where this is not something that's difficult to do. The end goal here is we want to democratize access to frontier AI for each and every business, for each and every organization. We've tried to make this the easiest and most cost effective way to do so with the Amazon Nova Foundation models. A lot of customers are already building with this. We hope to see you leave from this session and start building with Noah Forge as well. Thank you.