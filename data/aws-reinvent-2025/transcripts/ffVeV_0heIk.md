---
video_id: ffVeV_0heIk
video_url: https://www.youtube.com/watch?v=ffVeV_0heIk
is_generated: False
is_translatable: True
---

Hey, folks. Hope you're all having a great day. So, it's been a very buzzing morning. I think there are a lot of sessions going around. Uh, just to give a quick introduction, I'm Anand, and I'm part of the leadership in Manage Engine, which is one of the major divisions in Zo Corporation. Today, I'm here to talk about, uh, one of the most important and engaging aspects that impacts the day to day operations of most of the modern-day digital businesses, and that's nothing but AI. So at the end of the day. But here's the interesting part. It has two sides. So it has two sides, two perspectives, and only when you kind of bring them together and introspect a lot more on that. You'll get to get the real value out of it. So let me not begin with the definition to bore you, uh, but with a question. If AI is the watcher, who's really watching AI? So this has been stayed with me for quite some time. Uh, if you look at the systems, like, there are so many booths running here, so many networking done over here. Uh, they are no longer small or simple. It's pretty clear. So what did we do? Like, uh, we handed over some of the jobs to AI to maybe uh detect the anomalies that are happening with, uh, maybe a Wi Fi connection problem across any sort of a booth, and even fix them to a certain extent, like, uh, automate them in an autonomous manner. But on the hindsight, on the flip side, if you look at this, what happens if the AI itself goes wrong? So that is something that is kind of a lot more interesting. And when it does, in most of the situation, it doesn't give you a very big alarming red flag and all. It fails very quietly. So this is the reason, uh, we always think about this part in managing engine and a lot of products across the ecosystem, and we keep introspecting. And I wanted to share my thought process on both the sides of the story. So on one side, it'll be more on how observability is powered by AI and how it helps us to manage the chaos. And on the other side, how observability for AI itself is required, and it's more crucial so that we can keep AI itself in check. And on the due process, I will try to share some exciting stories or usual stories that you would have already heard, but closer to AI part, I will try to present my thought process and take this as engaging as possible. So, let me just rewind for a moment. I think that, that we have a lot of veterans over here. So if you rewind yourself, take yourself maybe a decade or two back, monitoring was pretty simple. So we had a set of monolithic applications that got deployed in cluster set up or grid set up in co-location data centers, and you have networking that is done across all the applications and bytes being captured, and you used to record a lot of things so that whenever there is a problem, you get the root cause analysis from the monitoring solutions, and you kind of go towards it, try to figure out what is the problem, and we kind of sometimes take the logs and debug it and fix it and life moved on. But if you look at the current scenario, it is no longer this simple. Uh, the reason being we have multiple cloud providers, apart from AWS, we have multiple cloud providers with multiple regions, and what is the problem is like you are being given the option to deploy in just a click of a button, and apart from this containerization, you have thousands of containers spawning up and down on a random basis, which sometimes goes out of control. And moving from here. You have containers calling APIs, and the APIs are calling other APIs in endless chains in the Agentic era. And finally, you have a set of users and behaviors of users who leave the app the moment it is spotted to be slow. So if you consider this entire scenario, it's no longer a system anymore. It is more of like a jungle that we are actually dealing with. So full stack observability is some sort of a solution that we are trying to figure out still. To kind of map this jungle. And if you ask me whether we can navigate this jungle easily by creating more dashboards or more alerts or more workflows, uh, the answer is, the answer is going to be a big no. It is going to be how efficiently we use AI to solve and automate this entire workflow as much as possible. So you, you see that there is a lot of ecosystem related problem in this scenario, but it acts like a co-pilot. So most of the people fail to realize the fact it acts more like a co-pilot to the existing humans in the observability ecosystem. So it scans millions of events that are going to go across networks, end user experience, servers, applications, and it scans almost all the events. Correlate all those events together and clusters those signals and helps us to connect the dots across every layer in the application ecosystem and sometimes it even helps us to predict what might break next. So that's the most important aspect that we actually rely on A for. So it is more of like if you check out this particular visualization, it acts like an air traffic control system in case of the modern digital world. There could be thousands of planes that are actually flying across the sky. You are facing a lot of delays right now in, uh, in, in, in flight, and there are a lot of cancellations happening. But if you look at the AI, it helps us to spot exactly what are the flights that we have to look into right now to make sure we give a convenient experience to the customer at the end of the day. So this could be a little bit like a gibberish kind of an example. So I'll just give you an air on air even routine that even that happens on a routine basis, uh, just before the reunion. I've been traveling here for a decade, so every time when I come here, I see Black Friday happening the week before. So, if you can just imagine that you're using an e-commerce app and, uh, you're actually kind of. a promotional aspect like say you're doing a marketing campaign for a discounted product, say there is a Nike Pressus premium or a premium Omera Premium that is being sent out for 50% off. Who doesn't like it? So a lot of users just come and bombard your app, and they all face a single checkout problem at some point in time when the load is going to be unimaginably huge. So with traditional monitoring systems, the situation could turn out to be a big chaos. So what you will get is like, you'll have a single pane of glass, like it's a common word, and you'll have CPU memory, or API response time. Everything will be spiking up and again, your operations team, uh, tensions will also be flying very high and they'll be coming to a single desk and they'll be collating all this data. But by the time they arrive at a solution, You would have lost all those users who are actually in a checkout process, and millions of dollars will be also out of your bank balance at the end of the day. So what you've got to realize is like, how can we do better with AI powered observability in this scenario? So with solutions that actually have AI powered observability. It kind of seamlessly brings together all the events together, correlates among itself, and gives you an efficient root cause analysis in a smaller time frame. So that is the most important aspect because if you're doing it all in a manual manner, it takes a longer time to uncover a problem than you do it with AI. So that's the best part you get from that. And once you get the RCA, maybe the RCA is kind of figuring out to a, a normal rogue query that is routinely happening, or else it can also kind of suggest to you capacity related issues and give you the suggestions on how much you've got a provision appropriately to get out of this situation. But wait, so AA is doing all these jobs for you, but what happens? The root cause analysis itself can drag you down to a different problem statement. So this, we used to face this more, more, more, more often. So like we have seen these problems happening in our own production ecosystem inside Zoa as well as manage Engine. Like it will give us an anomaly or else a false prediction which which takes our entire operation team towards a completely different direction. It's more of like a ghost hunting trial if you look at the situation. They will go towards one particular problem statement, and the scariest part here is like when AA is failing, it fails with utmost confidence. It makes You believe that I'm always right. I think most of you folks would have used chat GPT and you would have believed its responses. On the, on the hindsight, it's you, you, you may think that you might have a, a different assumption, but you won't question the assumption of chat GPT because it's having a huge amount of data to work on to give you the right answer. So you keep believing in that scenario. So imagine this side of the story as well. So I use a lot of weather apps. So, uh, on a routine basis, I rely on it to book meetings and go across zones to actually meet customers. So just imagine that I need to go to, uh, New York right now. So there's a huge snowfall happening in New York. So it is a given event. Say I plan about this almost a week ahead right now, and I'm planning to go to New York in the December 3rd week. My weather app states that there is not going to be any sort of a snowfall that is going to happen in New York right now. So the problem here is like, I take a flight, I go and land, I make a check-in and wait for 2 or 3 days to meet my customer, but suddenly there's a huge snowfall, and there is a pile of snowfall that is getting piled up, and there are machines that are trying to actually clear the snowfall problem for you. So my entire week is gone just without meeting the customer because they cannot come out. I cannot get to their place. And that is, uh, pretty much like a very big problem statement. Now, if you think whether the weather app is wrong, no, the weather app has been In use for more than a couple of decades, I can't question it, but the problem here is like the model that is used to forecast this weather pattern could have gone without any update, or else just consider the APA that the weather app itself relies on to actually collect the data to update. Models, maybe that has gone out of service. All these details are actually kind of hidden gems or hidden dragons which do not get uncovered in most of the scenarios, and this is where we could go for observability for A as such. So what do we mean by observability for A as such? Just like we monitor the CPU memory, all those infrastructure related metrics to make sure that everything is healthy and it is insanity, we have to actually have a close close eye or a third eye on top of all the AI-related workflows and its behaviors in a continuous manner. If AI is part of your tech stack, you need to have the same level of visibility and data collection that you have already had for an existing tech stack all the time. So how do we do this? Now, I will just take you through a classic example, uh, of how we do infrastructure-based auto scaling nowadays in most of the scenarios. Just consider that you have an operations team and it has actually created a blueprint for doing auto scaling that is aid-driven for your entire Cobonius ecosystem, and they have run this aid-driven auto scaling multiple times. It is bulletproof stress tested for multiple overnight scenarios. Your operations team has been loaded with a lot of work for the entire Black Friday. They are kind of exhausted and they want to take a Thanksgiving weekend without taxing them off. So what they do is like they turn on this auto scaling mode button and enable this blueprint, and they go out on a vacation for those couple of days. All of a sudden at some particular point, you see that a lot of resources get provisioned by this auto scaling board, and it is due to some sort of a pattern that is being misread by AI to be considering it to be an auto-scaling scenario, and and this particular spike, if you consider this pattern, sometimes there could be periodic spikes that happen. Within a particular hour itself. So that is a concept in the cloud ecosystem where if you rotate the resources on a continuous continuous basis within a particular hour, you get charged for the entire hour. So what happens here is like, say there are 10 auto scaling incidents happening within an hour and it continues to happen for 48 hours, you're going to end up with 500. Auto scaling events within the time your operation team gets back on a Monday morning. So they'll be staring at a huge cloud bill and I pity them. So what we could have done differently with observability for AA over here. So we could have identified this anomaly detection pattern by the auto scaling AA-based auto scaling system earlier, and we could have merged this context with traditional monitoring data to actually consider this to be a sustained peak in most of the scenarios, and we could have provisioned systems that could run on a permanent basis, and at the end of the day, we could have saved a lot more on your cloud bill. So this takes us to the heart of the subject. So measuring what really matters is going to be the agenda that you've got to have when you're taking both sides on AI powered observability and observability for AI. The first side is more of the classic ones, which is going to be more of observability metrics, CPU memory already repeated all those things. You already know about all those things, and this helps us to make sure that the system is healthy and available all the time. The second part is something that is going to be new that you've got to be a lot more interested about. It's going to be the drift, prediction rate, confidence levels, and last but not the least, cost. So these metrics will help us to make sure that we can continue trusting AI for making the decisions for us, and, uh, we should also consider another fact that at scale, whether AA will run at, at a rate which we consider to be a sustainable one. So sustainability is one more thing that we need to consider as a factor in case of AA. This is one of the reasons why we always feel that FinOs is one of the major players in the world, as we all know that we are never blessed with infinite budgets. Now, only when you bring these two sides, I spoke about two different paths together as part of a single coin or else maybe consider these two different aspects as a single entity, you will begin to see the real value out of it. So if you check out AI powered observability, it gives us speed, scale, and foresight in most of the situations, and observability for AI gives us trust, reliability, and accountability. And together you actually kind of get the full picture of observability, and it gets completed only when you consider both the sides, because going forward, it's never going to be about infrastructure and applications alone anymore. It's going to be infra applications and AI that unifies them into a single intelligent system. This is the reason, like, we have followed this as an expectation at Manage Engine, and we have built our IT suit with this exact thought process. We use AI to seamlessly integrate and correlate all the signals across applications, users, and infrastructure in order to reduce or cut the noise for the enterprises and help them focus on exactly what's needed. With a comprehensive suite of solutions that is going to be more than like 60+ products with complete focus on solving or covering all the aspects of enterprise IT management with an integrated suite, we follow a holistic approach to AI adoption where we kind of mix all the, all the distress signals from across the ecosystem and we create a value in a unified manner. So let me leave you with this thought process for the day. Future of observability is not going to be about humans versus AI. It's going to be more about humans working with AI as active enablers. At the end of the day, we all know that we cannot fix what we don't measure, and AI is going to need the help of humans to measure what's really needed. So I hope you got some valuable sort of information today. Thanks for coming over. I'd be more than happy to meet you guys in our managing engine booth, which is at 147. Have a great week ahead.