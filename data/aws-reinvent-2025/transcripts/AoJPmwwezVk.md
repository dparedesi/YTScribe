---
video_id: AoJPmwwezVk
video_url: https://www.youtube.com/watch?v=AoJPmwwezVk
is_generated: False
is_translatable: True
summary: |
  Mina Vembu Subramanyan outlines how AWS Transform uses agentic AI to de-risk mainframe exits by blending deterministic agents (for dependency extraction, code conversion, and testing) with LLM-based agents (for comprehension and documentation) in a single workflow that keeps humans focused on high-judgment decisions. She describes the three-phase journey: deep analysis (static code review, SMF-based activity analysis for usage and prioritization, data analysis and dictionaries), automated decomposition and domain planning, and multiple transformation patterns (replatform for speed, refactor for functional equivalence augmented by the Reforge multi-agent uplift, or reimagine via business-rule extraction and smart IDEs). Testing is treated as first-class: automatic test-plan generation, JCL scripts to capture precise mainframe test data, and automated test execution on both legacy and modern targets. Reforge iteratively cleans refactored Java to feel native—renaming cobalt-derived variables, restructuring classes, and now looping in functional testing to avoid regressions—improving maintainability without breaking equivalence.
  
  Vimal Brambhut from Fiserv (payments processing at massive scale: millions of merchants, 1.6B cards, 25k TPS peaks) explains their move of Host Data Capture off mainframes. Initial refactor via Blue Age produced cobalt-like Java, and manual modernization would have added a year. By adding Reforge, they expect to cut the 30-month program to roughly 18 months while preserving nightly processing (~$10B) and aiming to double capacity with cloud elasticity. The target stack replaces CICS with Tomcat, JCL with Groovy, VSAM/DB2/flat files with Spring Boot-based services, and retains operational outputs so users and SOPs remain stable. Reforge’s cleaner Java eases talent gaps by making code readable to modern developers, and automated testing guards functional equivalence across billions of transactions.
  
  Frank Guslop from BMW links the push to modernize legacy mainframe apps to the company’s Neue Klasse product wave and end-to-end digitalization. BMW already runs most applications and SAP in the cloud with 600+ daily AI use cases, but legacy workloads block process optimization and AI embedding. Using AWS Transform and Qiro, BMW separates technical refactoring from functional changes when possible, leverages Reforge for code quality, and standardizes cloud landing zones (augmenting with Glue jobs and Step Functions for batch needs). Automated business-logic extraction and test-generation compressed prep for one app from 10 days to hours, with automated test data reducing effort further. Results include ~75% reduction in testing time, up to 60% higher test coverage, and code-quality improvement from 2.8 to 4.1 stars.
  
  Subramanyan closes with patterns: choose modernization patterns that fit business goals; embed testing continuously rather than as a final gate; and use agentic AI loops like Reforge that self-test, iterate, and hand humans a head start. Early customers see >70% overall time reduction, turning multi-year efforts into months and making CIO-level approvals more tractable. AWS aims to lower dependence on scarce experts by letting AI do most of the discovery and uplift so specialists can focus on design and cutover. She invites teams to engage through an experience-based acceleration workshop to evaluate Transform on a pilot application.
keywords: mainframe modernization, AWS Transform, agentic AI, Reforge, testing automation
---

My name is Mina Weimbu Subramanyen. And I lead product management for AWS Transform for mainframe. We're here today to talk about de-risking your mainframe exit through refactoring by leveraging agentic AI. Joining me this afternoon, you'll hear directly from Frank Uslab, who's the vice president of Transformation Programs at BMW, and Vimal Brumbut, who's the senior vice president of technology at Pfizerve. We'll start the day today with some context that if you found your way here this afternoon might be a little bit familiar to you on the challenges associated with mainframe modernization. We'll talk about AWS transforms agentic AI capabilities with that context in mind. Next, we'll get to the really interesting stuff and hear directly from Frank and Vimal on, uh, their, their organization's transformation journeys. We'll end our conversation today with the key success patterns that we're seeing from both customers here today as well as across the board on the refactor pattern and beyond. Um Standing here towards the end of 2025 today, there are still over 220 billion lines of cobalt in production, and these lines of cobalt actually power 70% of critical enterprise applications. We're hearing from customers constantly that their teams that operate these applications are restricted from their ability to be agile and really adapt these applications to the changing business requirements as quickly as they would like to do. And when they do address the transformation process, what they find is that they're encumbered by multi-year efforts and a lot of risk in terms of validating these applications and getting them across the line. These teams well understand the benefits associated with modernization. They know that they'll see better costs often, particularly as their applications scale. They'll have access to modern and as well as open source technologies to innovate quickly. They also know that the talent conversation becomes a little bit easier and they have more flexibility as they start looking at uh a variety of different stacks moving forward. And with this combined they're able to keep up with the business changes and innovate quickly with their technology stack. However, these, despite all of these benefits, teams often find that the balance is outweighed by the risks associated with the modernization process. Uh, modernization requires investing in not just the, the transformation process and validation. But in parallel continuing to invest in the day to day operations of running your existing workloads, teams know that there are a lot of risk given the criticality of the business applications we're talking about here in doing that validation and switching over to that modernized application. And this process requires a unique skill set. You, you, you, you're looking for individuals that understand the legacy application, understand what the architecture should look like in the modernized world, as well as people at that intersection who understand both and can really drive that migration process. My background personally before AWS is in robotics and automation in the context of factories and Amazon's fulfillment centers. The thing I loved in that context was that ability to leverage robots for what they do best, high precision tasks, lifting heavy loads, uh, and highly repetitive tasks while combining humans into that process to do what human beings do best, the high judgment toss and the tasks that require fine dexterity and judgment at every step along the way. So in the factory context you might have a robot that is able to maneuver a heavy car door, but you bring the human being in in order to install install a minute wiring panel so that your end product is at a high quality and the process end to end is efficient. The thing that's been resonating with me in the past year is this ability with agentic AI to combine different approaches fluidly in one workflow. So what we're able to do now, which is starting to change the game, is leverage agents that have deterministic processes for specific tasks like extracting dependencies from source code or doing like for like uh transformation of code from cobalt to Java in order to achieve functional equivalent. We can combine those with LLM-based agents for understanding. Funding the source code and producing natural language documentation for teams to move forward with all of this can happen fluidly in one workflow, bringing in humans in the loop to make the high judgment decisions, things like figuring out how to draw the lines between different business domains to decompose your monolith into distinct uh applications that you want to move forward with in your modernization journey. With this we're starting to see the the balance shift over the past year. Connecting the ability to understand legacy systems, to understand the business logic associated with them, communicate that in natural language to both your business users as well as your technical users now really reduces the time that teams have had to spend in this understand phase of figuring out what that application does to begin with. This also really helps the experts that are working on this get a lot further and be a lot more effective in the amount of code and the number of applications they're able to process in the same amount of time. Enabling agents to interact with each other and constantly learn and improve and iterate on the process through a understand transform test loop that then again uh iterates on the process is helping us get a lot more efficient and reduce the risk associated with the output and the risk that's handed over to that that final validation team before you approach the cutover process. In combination, this AI first approach has really helped us transform modernization into something that is tractable for many more teams, many more teams across organizations. I wanna talk a little, tell you a little bit today about what we've been investing in with AWS Transform. AWBS Transform our, uh, for mainframe. Our hypothesis here is to bring this hybrid approach that leverages the right technology for every step along the way. We're with that in mind, we're gonna automate the entire transformation process from initial analysis and planning to that refactoring and that heavily intensive testing and validation phase as well. Our goal here really is to bring those multi-year efforts down to the order of months, and that's what you'll hear from Vimal and Frank about today in terms of what, how that's translating in their organizations. And in addition to this like for like functionally equivalent um refactoring that we'll hear from these teams on, we're bringing LLMs into the picture to improve the quality of that refactored code that you, uh, that are forward looking teams are going to be managing. We do this by leveraging a multi-agent process to, uh, what we're calling reforge refactored code to make it more readable and more easy to maintain for your teams that will be operating these modernized applications. Let me tell you a little bit about what the AWS transform journey looks like at a high level, there's 3 phases. At the first phase, you're really looking to understand the legacy application. This begins with code analysis to for to get a static view of the system. Next, we're also, uh, we recently introduced an activity analysis agent which looks at the SMF records in an organization. To get a dynamic view of the system, to understand things like the frequency at which applications are run, what the CPU utilization for applications looks like, and so on. Our goal here with this activity analysis is to give teams uh the information they need to prioritize workloads as well as to make architecture decisions. For example, if you have a medium frequency application that's very short lived of process that's very short lived, that might be an ideal candidate for an event-driven architecture moving forward. The final part of analysis involves data analysis where we look at for every data source in your legacy system we look at what the interdependencies look like and we look at what different programs might act on the same data sources. In addition, we provide a data dictionary that helps you at a field level understand what each what each data type is and what the function of each data uh data source and fields looks like. Next we take all of this and leverage our AI based agents to extract business logic as well as technical documentation based on the user persona that's working on the project on your team. All of this information together goes into an automated decomposition uh process that your teams can bring their own, uh, business context and input into to help decompose into distinct domains and create a migration plan. Following this phase, we get into the transformation journey. Uh, AOBS Transform supports multiple patterns for transformation. Some teams might have time constraints or particular data center exit timelines and are looking to move very quickly. They might choose to re-platform workloads. Next, uh, what we're gonna hear about today and spend more time on is the refactoring process where teams are working on highly business critical workloads and need for need have a very keen need for functional equivalent of that modernized application as compared to the legacy system. This refactor process is augmented by a reforge capability that I'll talk about in more detail. Finally, we also support reimagining applications where your starting point is that business rules extraction, which goes into can go into a spectrum and, um, forward engineering process leveraging smart IDEs like Hero. The last leg of the journey is often the leg of the journey that teams see the most risk and most effort and cost go into, which is in that testing and validation before you're finally able to deploy, um, deploy into your cloud or final destination. Here for testing we've introduced a few capabilities this year that we're gonna continue to add to. The first thing we've introduced is automatic test plan uh generation. Uh, which early in the process lets you get an understanding of for, for every given application what that testing scope and what the effort associate associated with it might be. I wanna talk about, uh, about a couple of the capabilities that Vimel and Frank's teams have been using extensively to provide the context, uh, while you see so before you see the results from these organizations. The first piece of it is this reforge functionality. After, uh, after code is refactored, we run it through a multi-agent process called reforge. Much like melting metal and reforging it makes it stronger and improves its properties, our goal here is to analyze that that refactored code to identify any cobalt semantics and structure that have been, uh, carried forward. We then improve on this code using LLM based agents to restructure it into uh more native uh feeling Java classes, uh, improve on things like variable names that might in the past have cobalt semantics to reflect more business, uh, business context terms for these variable names. The end result is code that looks much more intuitive and much more familiar to a Java developer. They're able to read the code and uh make connections to what the business logic being executed by that code actually looks like. The other thing we added recently is functional testing within this loop of uh reforging code. So our goal there is to ensure that when you have reforged code, we're not introducing any additional functionality changes that might encumber your path to getting to that functional equivalence proof point and finally getting your application in production. The next piece of what we introduced is is around accelerating functional testing itself. We talked about that test plan generation up front which helps teams very early in the process understand what the costs associated with testing might be and helps them also make prior prioritization decisions uh based on how many test cases and how detailed these test cases associated with specific applications might look like. The other two pieces we introduced today are scripts that help accelerate specific steps in the process. The first one addresses, uh, something that we know takes teams a lot of time, which is gathering the test data from the mainframe. When you have a test plan that was automatically generated, we also help you create test data capture scripts, uh, that correspond to this test plan. So what that looks like is JCL scripts that you can run on your mainframe to capture the very specific form of test data that you need to correspond to the test cases you've identified. Finally, we also provide fully automated test scripts to execute these, uh, these tests on the mainframe and on your modernized environment. Today, so far we've talked about the discovery process that and the acceleration we're bringing there to extract the broadest set of insights from the in the deepest manner possible. Next we talked about Reforge, which is uh which is our, uh, capability to combine the deterministic refactor process with LLMA based agents in order to produce more readable, highly maintainable Java code. Finally, we, uh, we also talked about our test acceleration capabilities that we've seen real results from our customers on thus far and it's something we'll continue to invest in. Now let's hear about some real world examples on how these features are being used in the context of real organizations. I'm gonna call up Vimal to come tell us the story at PIServe. Thank you, Mina. Good afternoon, everyone. Thanks for joining us. Uh, before I start, let me, uh, let me ask a quick poll. Raise your hand if you have, uh, finished 10,000 steps to make it to this conference. Awesome. Love it. If you can, if you can navigate this uh this uh uh uh reinvent sessions, I guess we can get through the modernization of mainframe. Uh, quick introduction, uh, Vimal Brumbert, I work for FISA. How many of my colleagues here who are from financial institutions, if you don't mind? Awesome, awesome. So this will be more relatable to you all. Uh, I'm joined by my colleague Amir Mohammad and uh AWS and HCL here in this room, who is Amir is running the, uh, this modernization for all of us. So, uh, let's, uh, let's get into the detail right away. Uh. Let me talk about FISA, what we are, who we are. I'm sure some of you have heard about this company. Maybe some of you may not know. So let's talk about who we are. So FISA is a financial payments processing organization. Unbeknownst to some of you, we process, uh, pretty much in the US, 3 of the economy in the United States. Uh, we are also a global company. We have a lot of APEC, AMIA presence where we help out our customers. Let me draw your attention to some of these numbers. We support 6 million plus merchants, and when you, when I talk about merchants, think about them as like uh starting from Amazon's all the way up to the mom and pop shop at the corner, uh, and anything in between. We support about 1.6 billion issued cards. This is through our partnership with the banks. We also have 10,000 banking institutions who use our software to run their banking course. And at our peak we process close to about 25,000 transactions per second. And I want you all to pause for a moment and Think about the scale I just talked about. At this scale, transforming mainframe into AWS or any cloud processing is not a small feat. It's a complicated, and I'm sure all of you are here because somewhere you have mainframe in your world and you understand the complexity. I have coded on some of these platforms myself many years back, so I have utmost respect and understanding for this. But those of you who do not know about what I'm talking about from the number perspective, let's talk about what it means in our day to day life. So here I have, these are just illustrative examples. Uh, of course, you all, we all have been here at AWS reinvent for 3 or 4 days, so this does not depict our reinvent journey, but this depicts whenever you go back, uh, this, this kind of shows our journey of everyday life. You get up, you, you are on your phone, you need to buy something, you, you make a purchase at an online retailer. And then you're ready to go to the office. We are 5 days in office, so I have to go to the office every day. Uh, you get your coffee, uh, on the way, you get your car charged or you get your gas. You make a payment through either your mobile phone, tap your card, insert your card, whatever it is. And then after that you are in the office, that subscription pops up that I have to pay for my subscription. You pay in-app purchase, then the lunchtime comes, you order your food, it gets delivered. Of course your kids wanted the new PS for your 5 or 6. You order that before you go home, spouse calls you that, hey, get some groceries from the grocery store. So you order ahead or you go to the grocery store and get your grocery. You reach home, uh, now you're so tired, you decided that I want to treat family with a good dinner. So you take them out, you go to the restaurant. There's the clover device, the white box which is shown there. We also have a point of sale solution which we, uh, a lot of businesses use. If you are at a coffee shop, uh, one of the famous coffee shops which was on the previous slide, they use this device, so you will know what I'm talking about. In, in general. I'm just explaining what we all do every single day in our life, and that happens about 350 to 400 million times every single day. 350 to 400 and during the peak season, we just are in the peak season as we call in the financial industry we had Black Friday, we had the day before Thanksgiving, we had Cyber Monday. These are the days where we considered it as a peak season for all of us. So I hope this kind of gets the idea about what I'm talking about payments processing. With that as a context, let's talk about how we got here in our journey with Amazon. So as a company we decided to kind of pivoted and we said that we want to be on cloud and we partnered with Amazon AWS a couple of years back. We started thinking about how do we net new buildouts we will do all on cloud. There are certain applications we'll start migrating onto the cloud, and there are some which are kind of lift and shift as well. So we have done all of these flavors of this, so think about this. We have a lot of applications running in AWS as we speak. A lot of them are net new. A lot of them are migration, and this last couple of years' journey has given us an opportunity to now think about doing this at a scale which is. As I explained, unparalleled to anything. I used to work for another bank before I joined here, and some of these big institutions have huge mainframe presence, and a lot of big workload processes on mainframe. And kind of people, people does the innovation around the mainframe, but not on the mainframe. So what you will do, you will take your DB2 data, VM data, replicate it somewhere. And build the services off of that, but nobody really touches the mainframe because it's hard, it's complicated. There are a lot of institutional knowledge is there. We don't have people who understand this. So that's the journey. So now let's talk about what particular application we are transforming here called HDC host data capture. I explained how payment works, but let me draw your attention to whenever you use your credit card, debit card, in-app tap, these are like 4 pillars of how transaction flows through. So all of us who are customers here in the first box, you initiate your payments either for purchasing online or car present, which is the in-store. Then of course wherever you are, whichever entity you are buying your stuff from, that's called Merchant. Then acquirer is where we are focused today. FSA FSA plays actually in acquiring network and issuing, but we are focused on acquirer, code switching and pre-settlement processing. Then comes the Visa, Mastercard, Amex, Discover, Star Excels. These are all the credit debit networks. And at the end, the card you have in your pocket, if it's a JPMorgan Chase issued card, Bank of America issued card, Goldman Apple issued card, that's where the final decision happens. So in this entity we are focused on the middle box where it says pre-settlement processing. So think about this when you buy something online and you go to your bank, it shows that you have a pending transaction. You would have noticed that on your mobile app or your statement which says pending transaction, and the next time when you look at it, the pending goes away and it shows up on your statement that this is the card. We are talking about that journey only. We are not even just a small journey between pending and how it gets cleared, so that's the focus here we have today. So let's look at the application itself, what it does. The application name we are host data capture, as the name might suggest that this is a pre-settlement processing application. It powers the ingestion and the pre-settlement processing for high volume data. This This application runs 24/7. So let me also give you perspective. When you buy something online before your order ships, there's a merchant needs to get paid before they will ship your order. So. When you make the purchase, there is an offline processing which happens where your order came in and now the merchant is asking for money, so we have to match and flag your original purchase with the merchant asking for money, flag them and make sure that it is all reconciled. So that's what the reconciliation means here 24/7. Just to give you an idea of the numbers you see on the right hand side, this application is responsible for processing close to $10.10 billion dollars plus dollars payment processing every single day. B with capital letter B, $10 billion between $150 to $200 million transactions every day goes without saying it's 24/7. So this is the scale of the application we are talking about where we have embarked on the journey of modernization. Given those stakes, uh, we also have to appreciate and understand where it's running today. So it is running on mainframe. 20-30 years of hardened mainframe, millions of lines of cobalt cod. I'm sure some of you are actually developing on mainframe today, so you appreciate and understand. Guess what these applications have done for us. Non-functional requirements. Response time is utmost critical for us because those merchants want to get paid on time. There is no delay. We can tolerate there. The capacity and the availability of these platforms, this platform has served us really well. So before we really migrate away from this and go on to the cloud journey, our standards, the table stakes are we need to make sure that at a minimum this functionality remains as it is and we do not break anything. Keep pace. The reason for so there's an interesting, I've been in an industry where there are a lot of mainframe applications and there are a lot of new builds. And the culture friction between those who are building new versus those who are on this mainframe type application, it's a very stark difference, right, because everyone is a developer, everyone thinks that I'm the best and I know what I'm talking about. Where we are missing out in a leadership position, I personally feel like. If we do not really innovate and if we do not transform, we are going to miss out on this whole agentic AI, what AI has to promise, and this is the critical aspect of why we are embarking on this journey. Quality has to remain as well, so the conventional path helps, but the scale at the scale, it really creates the bottlenecks. So. What we did was, as, as Mina actually described, I won't go in a lot of details, but we started working with AWS uh about 7 or 8 months back where AWS has this project product. Now it's called refactor, we called it Blue Agege, to convert your cobalt code into a Java code. Uh, and one of my goals is to make sure that I have those who are on a cobalt mainframe application. I want to make sure that I keep them around. I keep them interested in what we are doing. I also want their expertise because a lot of their knowledge is in their head. Uh, so what we did was we said, OK, we are going to convert cobalt into Java, which kind of looks and feels like cobalt 4 divisions, identification procedure, data, whatnot. So when you read Java code, they understand what it's doing. Soon we realized that once we do that, we would have to spend another 12 plus months to really make it a modern application, the API-based application, event-driven architecture, framework-based Java code. This is where Mina and team actually came to us and said that, well, we have this product before it becomes GA. We would like you to see if you are interested in trying this, which is called refactor, which is one of the agentic AI process where it takes the refactored Java code and then it builds the modern Java application by by using this AI. And because we were embarking on this journey, we decided that we believe that I think this is the right step. We decided to use Reforge. To really change it from Cobalt looking like Java to real Java, so we combined those two steps. And this is where again I think Mina covered a lot of these things. Our original journey would have been about 30 months, so we took this back. We said, OK, well, let's decide how we want to do this. Army and team actually got together. We said we will take a piece of application. Of course there are multiple modules, many, many lines of code, so we took one piece of application, we took that refactored code, ran it through the reforge. We basically made sure that the current team also understands. And automation, the testing piece, the automation piece, continue to make sure that we can test the functionality and not drift from the functionality. So all the results look promising so far. We are in about 2 or 3 months of the journey here. Uh, but we feel confident that this 30, 30 plus month journey we might be able to finish it in about 18 months, and we are 3 or 4 months into this, so we have about, we are a quarter of the way there, some ways to go, but we are very, very excited about this journey. So before I show you, and I think, um, did you show the code? No, you didn't show the code. So before I show you the code, how it looks like it's maybe an eye chart, let's talk about the a little bit of a. Tech portion of it. All of you know that we have Cobalt, VSAM, DB2, flat files or database. We are converting that into Springboard. CICS, if your online application goes into the Apache Tomcat, JCL gets into groovy. Again, I think our principle was to business logic must be preserved, functional equivalence guaranteed. So that is like table stakes. We cannot change what it does. We cannot change from $10 billion to 8 billion processing every night. We have to keep up 10 billion and make sure that we can process 20 billion tomorrow after this application is migrated. And of course leverage AWS's services once we are on the other side of the fence. Hope to remove the legacy tech dependencies there. Another thing, so we have some operational users who use the output of these applications to do the chargeback to reconcile some of the data, so they have screens and they have standard operating procedures. We don't want to change that. We don't want to retrain the entire organization just because we are modernizing our app, so that's another aspect that we are keeping up with this transformation. So let's look at the code quickly. I know it's eye chart may not be as visible, but what I'll say is on the left hand side is what you see the refactored code. This is using the blue edge. This is where we started. And if I show you the whole code, it basically feels like cobalt written in Java. It was good when we started the journey. We did not have reforge at that time, so reforge is there now. Now the right hand side of the code is the reforged code, and the beauty of that reforged code is that if you're a Java developer who has never coded in Kabul and start writing the code here, they would kind of understand the right side of the code much better because I think it does a tremendous job of building the modern Java with the variable names are meaningful unless on the left side you really need to know what you're looking at. So idioms are there, the, the data classes are there as well. So this is what it looks like, and I think we, we, we, we really want to go to the reforge code because here's one of the other challenges we have is talent challenge. I'm not getting any college grad coming out of college to come and code on a mainframe application. I hope that's the same challenge all of you are facing as well, so we have to spend time on training them, less interest, but if I get a college grad to come and work on the code which is on the right hand side. They all are familiar with it. This is what schools are teaching them today, so I think there are a lot of lot of benefits of uh refactoring this whole code with that, uh, so I'll I'll conclude the presentation. Our expectations when we are done with this whole transformation. As I said, our expectation is that we want to continue to do 10 billion. Well, our goal is to do 20 billion because now I can put in multi-regions. I can now spin up all the lambdas whenever I need. I don't have to rely on utilization. So continue to make sure that there are zero disruption. Tax stack. Text stack will be modern tax stack. Now we can leverage all the services, all the tooling. We can also be innovative in using the AI as well in payments processing, which, by the way, payment processing, there are some use cases for AI in fraud and risk, not in actual payment transaction processing. I think we are looking at some of those as well here. modern developer experience, you can use IDE for example versus you have to code on VX code on the mainframe. So a lot of, lot of good uplift as part of the transformation, of course, a number of months we will be looking to because we are using Reforge and again I think I cannot thank enough to Mina and team about introducing this Reforge to us that cuts down our journey by almost like 12 plus months. And when it's all said and done, had we stayed with the refactored code versus going to reforge, reforge is going to uplift our maintainability by 40%, which is another huge thing, right? So we had a choice of either staying with refactor or go to reforge code. 40% is a huge, humongous uplift, so. That's where we are. I'm sure no transformation is easy. I've done a lot of this in my career, of course, not at this scale. I've worked on these platforms, but this is the first time we are embarking on this journey, so I don't expect this to be flawless. There will be bumps. There will be challenges. We'll have a lot of lessons learned. We'll continue to share that with our partners as well. So in short, I think we had a car. We changed everything around that car. Now we are changing the engine while the car is running. And making sure that nobody spills their coffee at the checkout while the car is running. Speaking of car, I have Frank here who is going to talk about a journey for a car manufacturing company, BMW. So I'll hand it over to Frank. Thanks everyone. Yeah, thanks a lot. Quite an impressive number we've seen from Pfizer. So now let's jump from finance to automotive. So first of all, I would like to introduce myself. Uh, so I'm Frank Guslop, uh, leading our BMW group, uh, IT's cloud and modernization journey. So before I jump to our challenges on the mainframe, I would like to give you some insights and uh what makes us focus on these topics, and I would like to start with some insights from a product perspective. So I think most of you know BMW and our fantastic products. But now with our Neuer cluster we are not just taking a step ahead, we are entering a new dimension. The new design is clean, modern, and instantly BMW. The fully electric performance enables up to 400 miles range. And inside the panoramiciri and the completely new electronic architecture. Creates a smart and more intuitive digital experience. And with around 30% less life cycle CO2 and a higher share of secondary materials, the Neu Glasse also sets new benchmarks on sustainability and circularity. As the first model of a Neu Glasse, the BMW X3. It showcases the innovations that will shape the entire BMW lineup. Marking the beginning of a new era that will expand to 40 models by 2027. So if you look at that change on the product side, it's quite clear that that also means a massive change on the IT side. That new era on the product side is enabled by further digitalization of our end to end value chain, so we integrate AI into our core processes on the engineering side, on the production side, on the sales side, and on financial services. That's based on a cloud-first strategy. Where we have built new applications in the cloud and modernized and migrated our existing applications to move them into the cloud. We started a transformation program in order to do it and we try to be as fast as efficient as possible and in order to do that we copied we copied a lot of approaches which we have from our factories and started actually a transformation factory. And our clear ambition is to use automation and especially AI. As an accelerator. So we have been pretty successful so far, so the majority of our applications is running already in the cloud. And we also modernized our SAP landscape and put it into the cloud. And we have more than 600 productive AI use cases running on a daily basis. But in addition to our modern IT landscape, we also have some legacy applications. So typically in areas where there was no process change in the last couple of years, so there was no need to update or to migrate these applications, so we just keep them stable. But now basically a need if you want to optimize your end to end processes and you want to embed AI at some stage you also touch these legacy systems. And that's where the challenge comes up and it's really difficult to keep the process and IT knowledge for these legacy applications if things have not been changed in the last couple of years. So that's why we made the clear decision to modernize our application landscape and to migrate away from our mainframe. What is quite important for us is that with the topic we also want to master one of the challenges we see on the talent side, yes, so. It's not so easy for us. It's quite easy actually to get cobalt engineers, but it's not so easy really to get people who also have oppose this knowledge combined with the technology. So that's one of the big modern motivations for us to drive the change. When we started looking at how are we going to do the migration, we first analyzed our applications and found out they are quite complex, and we have a lot of dependencies and also documentation was not up to date, and we did not have proper test cases. So we came to the conclusion that we will only be able to master that modernization and to master the migration if we can do it really in a smarter way with benefiting from capabilities of. So what does it look like? We have explored a couple of ideas. And at the end we defined our modernization approach. In general, we try not to combine changes, technical changes with functional changes since that increases complexity and also slows you down. But there are a couple of areas where it's just the need to do so. In that cases we used AWS Transform together with Qiro, taking over the existing business logic as a basis and then adjusting it to be future ready. In the other areas we focused on the technical change with refactoring. Of course we did some code improvements and also performance optimization. But we kept the opportunity to compare the actual test results of the refactored application with the original application because we've seen a huge advantage in safeguarding the refactoring approach based on that technology. In general, getting testing on a new level was needed to really speed up, so doing like a code conversion in a very short time and then ending up with needing months for proper testing is nothing which looked for us to be the right way forward. And it was not an option, so we really focused on speeding up the the test, um, with all the testing activities from test plane generation uh to test datatration. So how does that look like in detail? Let's look at one of our applications and it's actually a pretty small one. In the past, only the process and the IT experts have been able to tell us what's really going on in the application and what kind of variants do we need to test. So for that application, it took the teams about 10 days to prepare 137 test cases and in addition about 2 days to prepare the corresponding test data. And the experts even missed some of the variants which later caused issues in production. With AWS transform, the business logic could be extracted from the actual source code, and the test cases have been created in just a couple of hours, including validation. And also the creation of the test data could be done in an automated way. That helps us to speed up the migration and also to safeguard the go life of our migrated applications. Looking at our landing zones. So for us it was quite important to get really rid of all of the dependencies we had previously on the mainframe. So that was already a huge benefit for us, but in addition, we found quite a good way forward to run these applications on our standard cloud platforms based on the template architecture. So we only needed to use a couple of specific topics, so like glue jobs and step functions to take over some of the batch functionality. But like Pfizer, we also made the use of the opportunity to optimize some of our coding with Reforge. For us now, after refactoring the applications, that's really a good starting point for further improvements and functional enhancements, including embedding AI in these kinds of processes. So what Have been our results if you're looking at facts, so we've been able to significantly speed up everything around testing, so it saves us about 75% on the testing side. Due to reduced time for test case creation. The test coverage could be increased by up to 60%, which is a significant number. And of course that leads in total also to a shortened timeline for all of your migrations. On the other hand, we've seen that we've been able to Improve the code quality and that also leads to better maintainability of our refactored applications from a 2.8 star rating to a 4.1 rating, which is a significant improvement. So what do you learn from it or what did we learn from it? I think although AI did a lot of heavy lifting, a lot of groundwork, we think it's still important that you have a good plan when you start doing your migrations. So we think it's important that you choose your migration patterns wisely and align that with your business owners and your stakeholders. If possible, I would recommend go with technical conversion first and then do functional enhancements and use the eye to first understand where are your dependencies and use it also to get a proper documentation that helps you to make informed decisions. Taking over elements for us from our production factories with a high focus on continuous improvement on standards and efficiency has been a key success factor for our for our migration. The team learned very fast and improved the approach and the tools with every single step within the migration. The close collaboration with AWS helped us a lot to speed up, and we've seen that the agents are developing very fast, so there is even a huge potential for further improvement. So to sum it up, we are now able to solve one of the biggest challenges in IT to master a mainframe migration, and that's really exciting and I think what we should not forget is at some stage when we mastered all of the big migrations that we also celebrate the success. So thanks a lot and back to you Mina. Thank you, Frank. Well, I'm gonna close today by connecting some of what we heard from Frank and Val with what patterns we're seeing across multiple customers. The first piece of it, yes, we want to embrace automation, embrace intelligence where we can. But using the right technology for the right task is critical to success. This is both the, you know, this to me is true day to day within AWS Transform and each agent we're introducing, each problem we're looking to solve. But in your organizations, as Frank just mentioned, depending on what you're trying to achieve with each phase of your modernization journey, it's important to select the right pattern that maps to what that business, what that team needs at that at a given point in time. The next piece of it is testing is not something that comes at the end as one big bang. It's something that needs to happen through the process. Now, at this reinvent, we've all heard the word agent a couple of times a day at least. What to me agentic AI means in this context really comes to light in the context of reforge. Last year, Reforge was one step that took, took your refactored code, improved it using your AI. This year reforge is truly energetic process that not only does that uplift of the of the refactored code but also tests that code to confirm functional equivalence when it notices errors, goes back and modifies that initial. Uplifted code to test again and continuously gets you to a point where the human being is 3 cycles ahead. The ball goes as far down the field as possible before you need to bring a human being into the process. That to me is what the acceleration we're seeing with the genetic AI. Finally, we know that modernization there is as much of a technology problem and perhaps more so of a people and process problem bringing the team along and ensuring that you're, uh, bringing humans into the loop and making the right decisions with the combination of, uh, techni technical input as well as this business context is what sets teams up for success. Through all of this we're optimistic and we're seeing early signs that we can see over a 70% reduction in what that total time looks like for teams and again this is now bringing the conversation from multi-year scoping down to the order of months where you can see results within the within a calendar year. And this what I'm hearing from teams is that this is actually making the challenge of bringing this up to the CIO's office and bringing this to decision makers a lot more tractable across the board. And like we say at AWS it is definitely day one. Even in the modernization journey you'll see continuous improvements as your teams are working on working on things and agents are able to bring in that learning loop to improve along the way. Similarly, what these agents can do is also going to continue to improve month over month, week over week at the rate that technology is advancing right now. Finally, our goal is to, we're still gonna need experts, but we're gonna reduce the dependency on the in the process as a whole on these experts. So previously you might have needed experts for 60% of the journey to really understand the goal, the code, and to, uh, elicit details from the code and the legacy. Systems along the way now AI can get them 2/3 of the way there so your same team of experts can do a lot more across projects than they've been able to in the past. So our goal here really is to leverage the AI to accelerate what these experts on your teams can accomplish. Thank you again for joining us today. I wanna close with, uh, thank you again, thanking Vimal and Frank again for telling their stories and leave you with, um. Couple pointers on how you can learn more about AWS Transform if you feel that your teams are ready for the mobilization to start exploring modernization projects, I recommend that you, uh, get in touch with teams to schedule an experience-based acceleration process, which is a 1 to 2 day workshop that we do where we work with your teams to do an initial assessment, pick an application, and run through this transform process with you. Thanks again for your time and for joining us at Reinvent.
