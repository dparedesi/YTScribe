---
video_id: 0Lz-yFQRHeQ
video_url: https://www.youtube.com/watch?v=0Lz-yFQRHeQ
summary: "In this engaging fireside chat, \"DraftKings & MongoDB: Supercharging Engineering with AI\" (AIM285), Mikiko Baisley from MongoDB interviews Jeff Singer, VP of Platform Engineering at DraftKings, to dissect how the sports betting titan creates a culture of high-velocity innovation across its massive 1,500-person engineering team. Singer sets the stage by emphasizing that for DraftKings, \"speed\" is the primary competitive advantage, but it cannot come at the expense of stability—especially when user traffic can surge 10x in seconds during a live football touchdown. To balance these opposing forces, DraftKings has aggressively embraced a strategy of \"internal platform engineering\" and the democratization of Generative AI, utilizing MongoDB Atlas as the flexible, multi-cloud data backbone that powers both their transactional betting systems and their emerging AI workloads. A central theme of the discussion is the empowerment of non-technical \"citizen developers.\" Singer details how low-code automation tools like n8n, integrated with MongoDB’s vector search nodes, have allowed marketing and customer service teams to build their own AI-driven workflows. He cites a compelling example where a marketing team effectively automated a complex, daily promotion workflow—tailoring offers based on the sports calendar—without writing a line of traditional code. To prevent this from devolving into unmanageable \"shadow IT,\" DraftKings instituted a formal \"Graduation Path.\" This governance framework allows teams to prototype freely; however, once a tool proves its business value and becomes critical, it is \"graduated\" into a rigorous engineering environment complete with version control, automated testing, and security compliance. On the core engineering front, Singer reveals counter-intuitive insights about AI adoption. Contrary to the belief that AI tools are a crutch for juniors, he observes that senior engineers are the heaviest power users, leveraging AI to bypass rote \"typing toil\" and focus purely on high-level system design. He shares the evolution of DraftKings' internal \"Code Review Agent,\" which began as a basic script and matured into a sophisticated service powered by Anthropic’s Claude via Amazon Bedrock. This agent now pre-scans every pull request, catching syntax errors and logic gaps in minutes, ensuring that human code reviews are focused solely on complex architectural decisions. Additionally, he explains how MongoDB’s unified platform—supporting both document storage and vector search—allowed a hackathon team to rapidly add \"natural language image search\" to their internal CMS, a feature that would have required a massive infrastructure lift with a traditional SQL stack. Singer concludes with a forward-looking perspective, advising leaders to \"pay down technical debt where the toil is.\" He argues that AI adoption isn't about replacing engineers but about removing the friction that slows them down. By embedding AI into the \"boring\" parts of the stack—like automated testing, code review, and data entry—DraftKings has unlocked creative capacity, allowing their workforce to shift focus from maintaining legacy systems to building personalized, real-time customer experiences."
keywords: Platform Engineering, Generative AI, MongoDB Atlas, Vector Search, Low-Code Automation, n8n, Code Review Agent, Internal Developer Platform, DraftKings
is_generated: False
is_translatable: True
---

Testing 123. OK, hi everyone, how are we doing? Day 3 of it's day 3, right? Not day 2, yeah, OK, awesome, um, well, thanks. At 2.5. OK, I love that. I love that spirit. Um, so thanks everyone for joining us today. Uh, my name is, I gotta do the clicker, my bad. I'm sorry, I'm all over the place. So, um, my name's Mikiko Baisley. I'm a staff build advocate Mogadibi, um, but I know you guys are really here to hear from draft. Kings, uh, specifically we have Jeff Singer who's a VP of engineering. Um, do you want to tell us a little bit more about yourself? Yeah, so I manage the product platform engineering teams at DraftKings, so that is our account, financial, marketing, customer service, and risk platform teams, and, um, I've been at DraftKings for about 10 years, so it's been a, a pretty wild ride over, over that time. Yeah, um, so could you tell us a little bit more about DraftKings? Yes, I imagine most of you, particularly anyone who has a TV in the United States, has heard of DraftKings in some, in some manner, um, but we're a digital sports entertainment company. Our products you probably have most heard of are online sports betting, casino, daily fantasy, um, we have a couple other brands that we operate as well, the Jack Pocket Lottery and, and Golden Nugget Casino as well. Yeah. Um, and specifically why we're here talking today is, uh, DraftKings, a Mogadibi customer. Um, they're one of our most successful, uh, customer stories, um, in an industry like betting and gaming. Um, we love those stories. Uh, so DraftKing uses Mogadibi across several systems, particularly the back end services that power their online sports betting platform, as well as multiple CMS style internal tools. Uh, so today we're gonna explore how DraftKings is embracing platform engineering and GM AI to dramatically increase speed, empower internal builders, and evolve their architecture with Mangudibi at the center. So, um, to just kind of start getting into it, um, so at your scale of 1,500+ engineers, uh, rapid product cycles, new regulatory and market pressures, uh, your team has had to rethink how to build with speed while still empowering internal teams. Um, can you talk to us a little bit more about that? Yeah, so I think for us speed is um the most important thing when we're thinking about how we build. We really want to enable our teams to move very, very quickly. Um, and I think what we've, we've found is that some of the new GII stuff that's come out has actually kind of enabled a whole other class of builders at DraftKings. You know, DraftKings has probably 1800 or so people in engineering, but there's another 3000 employees outside of engineering, and now we're trying to enable through building out more of their. AI platform those people to be more of builders as well themselves um but we've also needed to invest in the platform to enable developers to to build faster so you know some of that is things like better uh tools for AI that's also things though like the same no code tools that people are using um outside of engineering that engineers can use to make their daily lives better. Um, but it's also investments into the core platform on the engineering side to enable people to spin up a new database faster, to spin up a new microservice faster, to build new products entirely faster than we, we could before. And so we found that those investments have been really key in enabling us to move faster and faster over the past couple of years. Yeah, and especially with, uh, DraftKings like you guys have a DNA of, you know, shipping fast while still at the same time you have to have a certain level of resiliency for your um user experience so um when the kind of, you know, push for no code loco tool. Tools like first started coming up, um, what was that like internal sort of dialogue like in terms of both, you know, identifying what tools to use and also how to adopt them? Yeah, I mean for us I think we view our most important feature as up time, um, and I think. Uh, we've done a lot with live, uh, sports recently, and it's actually really, really important to have really great up time for those live moments. You can't have odds not available when a big event has just happened inside the game because that's when the customers wanna, want to be there. That's the feature that is gonna decide which app a, um, a customer reaches for first if they're, if they're gonna place a bet during the game. So that up time is super super important to us and the They kind of follow on to that is what can we build that. Isn't going to endanger that and so we focused a lot internally on our own work flows on the things that people were doing and sort of the toil that was happening inside our organization as opposed to immediately trying to build customer facing, um, things, particularly with like no code solutions and and things like that and the conversation uh was once we shifted to look at those work flows and that sort of toil there was a lot of excitement internally because that's a. That everyone likes to make their own lives better and I love how you kind of, um, you know, you emphasize the the very heavy, uh, metrics driven kind of perspective you need to take when you're looking at new technologies. Um, I think it's really helpful to for the audience to hear like what did impact mean inside your org you identified a couple key metrics, but were there some other ones that you guys had looked at and we're trying to see how you could achieve. Yeah, so I think Most of these cases where people are trying to apply AI somewhere, this is an existing process and so you can sort of measure how much human toil is going against this, this process as it exists today and if we apply AI, how does that actually change over time, um. But the other thing is a lot of our no code stuff is on NN as a, uh, workflow tool, and that also comes with a great ability to just measure how much people are using it, how much it's being invoked, things like that, which isn't, you know, that's not direct value, but that's a really great proxy for, hey, where there's something interesting going on here, where should we learn more about what this team is, is doing, um. Yeah, and it's interesting too. Like I wanna dig in a little bit on the um how you guys are balancing the no code low code kind of uh taskies like I've heard from like other customers, other users, uh, they'll ask questions like which do we use N8N or more agentic orchestration frameworks like Lang graph, and it seems it's a little bit like it's comparing apples to oranges. They have a very sort of different, um. Use case in key stakeholders, um, can you tell us more in terms of how you're using, for example, like Mongo DB as like a vector store and like pairing that with agentic frameworks versus like who's using N8N and how does that kind of feed into the development. Yeah, so, so there's definitely been some really good stories about devs reaching for an end just to try something. I think that is one of the things that have been powerful for us is it's a really, really quick way to try something and say like, hey, could this work? What would be necessary for this to work? But then I think as we start to see, hey, you know, this is actually would be a pretty production critical thing for us. That's probably a sign that we need a little bit more sort of rigor around it than what we can do in that that low code environment. Things like source control exist for a reason, and being able to reach for them and understand the versions of everything in a in a really mature way is really. Important if you're trying to be sort of fully productionized and so we've defined a little bit of a graduation path for things that have started out as no code that need more. Now some of it, if it's just like I'm automating a thing that Jeff I do myself every day, that's, you know, that probably doesn't need a whole lot, you know, we, we don't need to go reach for strands or ML flow or anything like that to, to automate that. But if it's something that. Um, is, you know, for the whole customer service organization to be using, uh, that's something where we really want to have a lot of rigor around it, and that's where we've invested a little bit more in, in graduating that up to a little bit more of a production. It also seems like a really nice way to um uh get buy in from let's say your non-technical uh users and well buy in from the development team first off that they have a place in this world uh but also buy in from the non-technical users as well that their their needs are being met they're not being prevented from using GM AI tools to do their work. Yeah, and it's, it's been really great to discover and I think we, uh, you know, we've done a lot of hackathons recently, um, enabling non-technical people to use some of these tools and we've had some great ideas come out of the teams themselves who really understand the workflows, really understand where the problems are and where there might be opportunities and. Um, I think that's also helped get buy-in on any changes that need to happen in those orgs sort of react to new tools being available if the ideas are coming from them and they're able to experiment and understand what the capabilities are themselves rather than having someone in an engineering team they've never worked with before come and say like, hey, I'm gonna come here and tell you how to do your job now that, that doesn't usually work well. Yeah, yeah, that's how you get shadow IT, right? Um, let's dig a little bit more in terms of, you know, how your engineering team adapted to working with AI powered automation in their day to day workflows. Um, can we talk a little bit more, for example, about like what are some projects or workflows we've seen go through that graduation process? Yeah, um, so I think there was an interesting example in, um, my marketing team where they had started to think about how can we make some of the operations that people are doing. To deal with promotions on a daily basis easier, you know, we obviously want promotions that are relevant to the sports content that's today, you know, today would not be a great day to do a really big MLB promotion because no one cares about MLB in November, um. And uh so it's very calendar driven daily task and the team started out they spent a week or two. Iterating on something in NNN and I think they started to get to something that hey this is really interesting and um a really a good thing that we could build out for for the team and now they're in the process of taking it even further and really building it embedded into all of the tools that the people are using today as opposed to some separate AI thing off to the side it's just gonna be. Part of the, the workflow for people going forward, yeah, and let's dig in a little bit more too about uh what the engineers are building for themselves. So one of the things you guys have built out, for example, was a code review agent. We've heard this is a very common use case. It's almost the first thing that a lot of the. Injuring teams um that our users and customers uh actually build in terms of agents, um, so curvy agent built with anthropic and AWS Bedrock, um, so what do you know how well has it been adopted and what did that process kind of look like. Yeah, so we actually got it started very early with this, uh, agent. I think it was back in late 2023, early 2024 when people first started playing with it and we built something and. It was able to provide code review comments on code reviews and I think that's probably the, the only nice thing that people would have said about the, the very first versions of it, um, uh, we started to iterate over time and I think we started to see, uh, it was a little bit becoming harder to justify the continued investment in it. Um, because the landscape was changing so quickly and we're trying to find an architecture that was gonna let, let us keep up with the latest advancements in what AI coding tools were doing without needing to be sort of our own research lab basically and so we transitioned over to using cloud code to actually run the code review itself and calling that via Bedrock, which was made all of our infosec and security people happy. Um, And that was a um a really big increase in quality partially because we're using much newer models but also because of the it, you know, actual context management that cloud code has that we could could take advantage of. Um, and that's been a really big success. Most of our repositories now have that available to them, and I think the, the quality of comments and, um, the actual time to code review has substantially decreased because of that because all of the obvious questions get asked within a minute or two of posting a PR without a person having to look at it, which really just speeds up the conversation. A junior dev who's made a silly mistake learns about it right away, fixes it before a human spends any time looking to find that that silly mistake. I like the fact that you mentioned that there are still junior devs on your team. I think that's awesome, um, and I think that's a common question that we get to because I think some companies are struggling a little bit with, um. How to infuse AI skills and talent into their existing or like do they need to hire some, you know, unicorns or can they kind of upskill their existing engineering teams? So I mean what skills or practices do you see and did see becoming essential for the engineers at DraftKings for them to embrace like AI? So I think that the most important thing has been. People just using AI coding tools themselves and experimenting with it and trying it and so we've done a lot to enable different tools and um. And just like as much as we possibly can enable engineers to have that option, I think seeing what the tools are capable of inside their own work and knowing what works and what doesn't work as far as prompting and it's kind of like understanding the window of of what's possible is a really, really important start for people to gain understanding and I think. That's where we've really centered a lot of this on the teams that are actually building with AI. We've kind of taken a hybrid of approaches, and we have a lot of data science, machine learning background people who are very excited about everything that's going on, and they're working on this and doing education of other dev teams they're working with. There's also just lots of engineers who are very interested in what's going on with this in the industry, as, and I think basically every talk at Reinvent so far has been about AI. Um, and a lot of those engineers are. Also helping to kind of spread some knowledge within their team and so we've done a lot of that. I think it's hard to hire too much external talent who knows this really well because the years of experience here are just very, very low for the most part. And it's interesting because um I think there is a lot of discussion about uh that boils down to you're not a real engineer if you use uh coding tools um we hear that a lot on social media, but at the same time let's let's be real, we are all using it in some way, shape or form. Um, so you know, like what's the adoption level within the engineering team? Is it like only the junior senior engineers using it, or do we see it at all levels of like engineering talent? I actually see our most senior people using it more than our more junior people. I think they find it easier to kind of get the leverage by writing what they want to have happen and spending less time typing, basically. And um the more junior people I think are able to use it, but they. I think struggle a little bit more with knowing what to ask for, what's important in the design. They've spent a lot less time giving design feedback to other engineers, which means they probably have less less applicable skills to give design feedback to AI. So, um, I would definitely say that. Uh, that the more senior people have adopted it more. And I, I really kind of like how, I mean what you're basically saying is in this case like automation isn't really reducing creative thinking amongst your engineers, um, but it is enhancing innovation like through speed, uh, through demand validation like does that sound about right? Yeah, I think we were able to see people quickly build something scrappy that would have taken weeks and hours. And that has really helped validate like yeah this actually is a project worth pursuing or or maybe it isn't. I think we've also seen people um I can remember an example where uh someone on my team came to me and they said hey I realized that we've been doing the same thing once a month. It only takes 20 minutes, so we haven't really spent any time working on it, but I actually just spent 45 minutes and I automated it. Um, and, uh, previously it probably would have taken a week or so to automate and it wasn't really worth it, but now, um, we can do that and I think that actually enables more creativity because you can spend more time on the stuff that really matters, less time on the sort of like rote, oh this is just a thing that we had to do that we haven't had time to automate. Yeah, I love that. And so let's actually go back and we've sort of been talking about the current state, um, and a little bit of the future state, but let's just actually go back in time, uh, for people who maybe aren't familiar with the, uh. Technical transformation of DraftKings engineering. Um, so you've lived through multiple architectural phases at DraftKing. Um, you know, what was the technology stack when you had started and what were those like various phases that you guys went through? Yeah, so when I started at DraftKings, uh, we were just kind of graduating away from a monolithic application and the only vertical we had at the time was fantasy sports. Uh, but we're already sort of seeing that this one monolith didn't scale very well in the face of very large peaks in traffic, you know, I think like 10x your traffic over the course of 10 seconds when a touchdown happens. Um, the monolith wasn't really scaling well for us there. We've then, uh, transitioned a lot towards microservices. From there there's a big migration to get all on Kubernetes because we're, we're a dotnet company. And so the actual the transition to Kubernetes was a little bit painful for us because we also had to move to Linux at the same time, um, when back when the company was founded in 2012, .NET was Microsoft, um. And now I think we're much more focused on moving to sort of be more data focused in the way that we're thinking. There's been a really interesting push in the past couple of years to really treat the data that teams are exposing as more of a first class thing. As opposed to, oh yeah, you'll use some kind of operational data store, be it Mongo or MySQL or Postress, and then some data team will come in and use change data capture and and suck that out, um, and then if you wanna change anything about your data schema just let them know and you guys can work out how that'll happen to actually sort of make that a little bit more of an explicit contract has been really powerful, particularly as we're trying to use all of this data for more and more things across, um, AI and ML use cases. Yeah, and you guys had started with SQL Server, right? Yes, yeah, um, so how, you know, what that look like transitioning from like a SQL-based database to going to like Mogudivia document-based data model. So that transition kind of happened somewhat organically through an acquisition where um we had moved everything to MySQL, um, at, at one point and then we acquired a company that was um. Depending on how you look at it, bigger than um our company, and they were a big MongoDB customer, and I think seeing some of the success that um they had had with MongoDB made it apparent that we wanted to be able to enable that in more places and that has been a a big transition for us as well as sort of allowing the engineering teams to not just pick the, the one blessed tool but having a real platform where people can use the right tool for the job. Yeah, and I think um it's interesting too because, uh, for example, uh, you had a data warehouse for batch based and all, but then eventually you guys had to kind of go to real time inference in customer flows um and then now like G AI has kind of introduced like new requirements um what were some of the most sort of compelling features of Modi before your Generative AI use cases? Yeah, I think one of the sort of coolest stories, uh, internally at DraftKings was there's a, a large, uh, CMS application that was developed in-house that, uh, governs a lot of the experiences our customers have, uh, loading the app, and, uh, it's a little bit complicated, uh, for people internally to know like hey what was. Customer actually seeing and why at a given point in time, so there's a team working on a hackathon project to sort of try to figure out how they, they could do this, and they realized, oh well, actually we're already using MongoDB for this, um, application. We can just, you know, turn on the vectors vector search and now. We can search the content that maybe was in the screenshot and find the relevant content with um with natural language and that has um was a really really cool unlock for the business and it was ended up being very low lift as opposed to if we were on some other data story it would probably have been a lot harder and probably not something that they would have been able to really experiment with. Yeah, and right now you have a couple key workloads in the sports book, um, that rely on Mango DB, um, and I think, uh, we talked about this before because, uh. Some engineering teams are sort of like still applying a waterfall approach to like iterating with their SQL databases, um, but it seems like actually it's unlocked, uh, both speed and reliability in terms of using something like MoDB for flexibility for the data model. Yes, yeah, I mean it definitely is helpful to not have to think about, oh well, if we add this new column, how are we going to deal with the scheme of migration and. Um, that is definitely a pain point that that we've had in other places. Absolutely and um. I mean, so what challenges or surprises did you encounter while adopting Lodi B Ellis? Was it smooth sailing or were there, were there a couple gotches? So we had a lot of experience running Mongo DB ourselves, um, before the migration to Atlas. I think for the most part, um, the transition was actually relatively smooth. I think, um, we had to work with you guys a little bit on making sure, um, everything was sort of right sized and we were, uh, not, um. Using more resources than we really needed, but I think we really, um, it was actually a relatively smooth, um, cut over. I love to hear that it was smooth, guys. Take note of that, um. Um, well, so if you were starting the journey today, um, again, what would you, is there anything that you would do differently or any lessons you want to impart to our audience? I, I think, um. It's early probably to do a real postmortem here because I think we're we're probably still looking back and seeing the starting line and don't see the finish line yet um but I do think uh what I was talking a little bit about with our. Uh, that graduation process probably would have helped quite a bit because there was times where people were starting out and they're, they're getting this thing and it's so close to being what they want, you know, um, they have this workflow built out in N 8N and they're calling into a couple of different LLMs and they keep tweaking the prompts and. Something it's almost working, but then something news breaks and I think investing more in evals and um really teaching people how to iterate on this in a way that is going to definitely improve it over time rather than maybe improve it over time um would probably have uh helped out some of the the early um adopters quite a bit. Absolutely. And so when you, um, had first sort of started building on top of MongoDB, uh, through that acquisition, right, um, Mongi was kind of only available like as like Atlas, right, as a, you had to be a developer to interact with it, um, but now we have the Mongo DB Atlas, uh, nodes and also the vector store nodes in NAN and we recently had a hackathon as well, um. I mean, what was your impression in terms of like some of the projects that come out? I mean, it's very cool and very creative and to see some people who are non-technical really be able to use a database and be able to use a database, uh, to, you know, store whatever information they need for their, their workflows and then do some deterministic things based on what's in that workflow and then send that off to an AI agent. That all has been um a really really big unlock and I think some of um the most creative ideas were really limited by not having that I think when you look at a lot of the um sort of processes we're trying to. Work on it's a lot of people working in Google Sheets or emailing a spreadsheet back and forth to each other or something like that, so to give someone a real first class data store is actually a really important step in getting something a lot closer to production and um that we're able to enable something so easy for people to use was um was really, really important. Um, and just kind of following up on that. So do you have advice for teams that want to innovate faster but are kind of feeling bogged down by legacy systems or slow processes? Yeah I mean I think you have to somewhat pay down the debt in order to do it and you have to find a way to make time. I think what I typically do is try to work with the, you know, the business who's asking for all of these, you know, usually you're not doing some legacy process just because you like it you're usually doing it because someone's demanding it of you and um. You can kind of work with those people to talk to them and and get to a point where the the process. Is Is no longer needed or is needed like you can get them to kind of co-invest with you and and make space for it and I think that's really the the the key unlock is if you can get buy-in from the the. From everyone involved, not just having it come from only engineering, yeah, for sure. And when I was an MOps engineer at MailChimp, um, We had the saying about meet developers where the toil is and just pay that down and I think that is a very excellent principle. Um, now looking ahead, uh, what's next for DraftKings, especially as AI becomes a core part of the engineering roadmap. Yeah, I think we're gonna look to find ways to move faster and faster and do more and more. I think the, the company is quite ambitious and uh we recently announced that um an earnings call that we're gonna enter into this new prediction market space, so, uh, we'll probably. They do more and more things and figure out how we can enable how we how we can use AI to enable that, but I think we're also gonna look more and more at how we can use AI to actually create better and better customer experiences, more personalized, um, more. Um, like faster responses from customer service, things like that. Yeah, and what I really love about that is, um, you're not compromising on the reliability of sports book like you're innovating, but you're still sort of maintaining that high level of user experience. Yeah, I mean we don't want to use AI because it's AI. We want to build something that's better for our customers and uh I think there's, there's certainly, you know, a chat interface is not the right interface for absolutely everything. Um, so we wanna do what's right for the customers and build the thing that our customers really want. Whether that be AI or not, awesome. And just to, um, just sort of paint the picture, uh, in terms of the role that AWS and Mog DB play as you continue scaling, um, what's that kind of tech stack look like for these folks? Yeah, so, um, DraftKings is very, very heavily on AWS, um. Uh, particularly, uh, my teams, we, we are multi-cloud. I know AWS probably doesn't want you to, to know that, but, um, we're very, very heavy AWS customers. We're heavy MongoDB customers, and I think like, like, like I was saying before, we want to enable people to use the right tool for the job, and I, I think, um, we'll kind of continue to each time we have something new we're doing evaluate what makes the most sense at the time. Um, that'll probably be, uh, a lot of Aurora databases at times when that's the right thing. It'll probably be MongoDB. It'll probably be other tools that are out there, um. And um you know I think we have really valued the partnership from both Mongo and AWS in helping us think about some of this AI transition. I think these both have been very helpful in educating the team on what's possible on, you know, being involved in some of these hackathons, um. Training people before them, helping to train some of the non-technical people on what was possible, all of that, um, I think has really helped us get more internal, uh, buy in on being able to continue to build with both AWS and Mongo. Awesome, very cool. Um, I guess any kind of, uh, last things the folks here should take away in terms of like entering at DraftKings or even just, you know, AI adoption. Yeah, I mean, I think one my pitch is there's actually a lot of really interesting problems to solve at um draftings engineering, so, um, if, uh, you have interest and opportunity to work with us, we, um, we're very often hiring, so, um, definitely, uh, feel free to look at the careers page, but, um. Uh, I think the other thing I would say is that in each of your own organizations really take a look at how you can enable more and more AI usage and just let people learn and upscale because we're talking a little bit about like how do you make sure that you're bringing in the right AI talent. I think you really need to be thinking about how can you generate the right AI talent internally. Awesome, love that. And um, yeah, so if you guys are, you know, looking for a new gig or just want a coffee chat, uh, Jeff did tell me that a lot of his team is here, so take a look at that careers page. Uh, he has a LinkedIn, um, uh, OK, maybe don't spam him on LinkedIn, but, um, if they do want to connect with you or members of your team, uh, what's the best way to do that? I'll definitely hang out for a couple minutes outside here if anyone would like to, to come say hi, um. And that's probably you can also add me on LinkedIn. I don't promise I get a lot of LinkedIn spam. I don't promise that I'll, uh, be super responsive there, but you should definitely give it a try, um, but yeah, I think the easiest way is to come, um, awesome, stop by right after. Very cool, yeah, so if you guys had questions that you did not want recorded, this would be a great time to ask them, um, but yeah, thank you so much, Jeff, for, uh, coming and like sharing your experiences and insights with this group, um. Just signing off, everyone, uh, my, once again, my name's Mikiko. I'm with Mong DB. Uh, if you have any questions, uh, also feel free to come hit me up, and if I can't answer it, I will definitely send your, send you to a MongoDB expert that can, um, so yeah, so thanks everyone, uh, have a great reinvent, uh, hydrate. Liquid IV is great, and yeah, we'll see you guys later. Bye.