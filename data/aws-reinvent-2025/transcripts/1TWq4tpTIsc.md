---
video_id: 1TWq4tpTIsc
video_url: https://www.youtube.com/watch?v=1TWq4tpTIsc
is_generated: False
is_translatable: True
---

Welcome, welcome to SEC. 211-S. so we're gonna obviously talk about security stuff. Um, my name's David Mills, and this is Nick AKA Nicholas Jackson, and um our goal for this session as it is for all the sessions that we deliver is for you to take away at least one actionable thing from the session that you could take back to your organizations and help improve your security. So, um, we'll try to make that happen. Um, and so obviously today we're gonna talk about agentic systems, uh, how those, uh, can be problematic, how they can do wonderful things, but also be problematic because you have so many non-human identities that are tied in, uh, with these agentic systems and often not well managed, either not tied to a real human, they don't have the right policies assigned. And where that can get you into trouble. Um, so with that, I am going to, uh, let Nick walk you through what the agenda items are and what we're gonna talk about today. So we're gonna, we're gonna look through, I think predominantly some of the, the risks and the threats that, that can affect agentic systems, the, the, the development life cycle, because I, we, we're gonna kind of look at that as a, as a potential threat in addition to the, the sort of the runtime of your, of your systems. How you can do things like protect systems. Predominantly what we're gonna concentrate on are looking at things like secrets. All genetic systems like microservices, like anything else you're building is gonna have a requirement for, for secrets, whether they are dynamic, static, um PKI all of those kinds of things. Um, and we're gonna look at this from a, I, I think like a cautionary tale. A Little bit of a scenario for you which, which looks at I think quite an interesting way, which makes an eugenic system a little bit more vulnerable than, than an ordinary system. And, and of course, how you can address many of these threats, and, and of course one of the most important things which which kind of comes out of a lot of this, which is looking at agentic identity and how to manage that. Alright, with that, let's get started. We got a lot to cover today, so we might move a little quickly, but um definitely provide a lot of good information for you to take away. So, most of us have seen the big news headlines about breaches that are happening. Um, a lot of them are happening for reasons of just not enforcing basic security practices which we're gonna talk about, but AI is involved in these, so McDonald's had exposure of 64 million job applications. There was an AI agent that was accessed, uh, uh, the records using a basic password attack. I think it was something like 123456, um, for their McHare platform. Samsung implemented a crackdown after, uh, somebody accidentally put. Source code in chat GPT and so this was some IP that got exposed via chat GPT and service aid was subject to HIPPAA violations and fines after a data breach breach was discovered, and this was related to an Elastic Search database that was exposed for more than 6 weeks. 483,000 patient records were exposed, and these could have been avoided using basic security practices, uh, being put into place. So, um, if you look at the top risks, just a few years ago, it was injection, so think sequel injection, um, and some of you might have remembered the memes with little bobby tables or drop tables that was being used, um, so basically just some really bad formatting to do bad things, uh, in, um, databases and. So over time, companies, organizations learned to be more careful about parameters and how they were formatting things to avoid this problem, but here we are again, and currently now we've got prompt injections as the number one problem, so it kind of feels like we need to learn those lessons all over again. So let's start by looking at what, what the attack surfaces, what the architecture looks like for an agentic system, and then I'm gonna walk you through some of the most common categories of those threats. Uh, we're not gonna dive deeply into all of them because that could be a separate session, but to give you some context for what's going on here. So here we have a system that has a user, they're obviously wanting uh. To do something with AI and they are accessing and asking agents to do things for them. Those agents are connecting to tools. Those tools then are accessing services to be able to do what they need to do. And so if you go from left to right, there's a lot of moving parts and we start thinking about the fact that these new agents are so autonomous and they start making decisions on their own. They're not just doing um making decisions based on predetermined answers, which is kind of where we started, uh, with some of the AI stuff that we worked with um they have adaptive learning, they're continuously learning and adjusting uh their behavior, and there's this expanded attack surface so you can see from left to right, there's a lot of different stages and a lot of different vulnerability points in this architecture. So, let's go through some of the major categories. Um, one is obviously identity and authorization threats. So something that you may have heard called confused deputy, uh, this is where you have a service with high privileges, more privileges than they should have, because those policies or privileges were not enforced correctly. So if the user that's using that agent has only read permissions, that agent should not have write permissions. So some of those things are really basic. If we look at um credential and secret management, um secret exposure and theft is a huge one. And there still exists a major issue with long-lived credentials. So, if you're not rotating the credentials, they're hardcoded, you've got a lot of sprawl, and the more sprawl you have, the more vulnerabilities you have. and integration and uh exploits. So we look at some of those tools and the fact that they're integrating with services, different things happening. There's something called a tool poisoning attack that can lead to sensitive data, exfiltration, unauthorized actions, and it's really about the API's not having robust authentication, um, and it makes them particularly vulnerable. Supply chain attacks. So in working with AI and working with these agents, um, most organizations are starting to adopt the model context protocol that makes it easy to integrate whatever your um agentic or AI platform is with uh your databases or whatever you need to integrate with because you don't have to make these. Bespoke AI integrations, uh, MCP servers can do that for you, but those MCP servers can also be vulnerable. Their server registries, their patch and update mechanisms introduce a new surface that can be a threat, uh, and that can be hijacked and do things like inject malicious code. Multi-agent systems, so in many cases it's not just one agent that you're leveraging to do what you need to do. There can be a control agent and there can be other agents that that agent is controlling for things that it needs to do, um, pulling records or doing other things that need that need to be done. So if you can inject or tamper with messages between those agents, then you can inject false information, and that propagates across those agents that are communicating, and get them to do bad things. Um, prompt-based attacks. Direct prompt injection is the one that I mentioned now. Uh, it's the number one vulnerability, and that's a, a situation where you can use carefully crafted commands that can override agent instructions. So a a recent example of this, sorry, I'm laughing. Uh, is when Chev a Chevy dealership's AI chatbot was tricked into offering a $76,000 Chevy Tahoe for just $1. Yes, that happened. I'd love to get that offer for a Porsche Tayan, um, but that's another conversation. Data data security threats, rag poisoning, uh, so basically you have retrieval, augmented generation systems that we're starting to rely on. Um, that's a technique that allows you to get retrieval-based and generation-based input to improve performance and accuracy of these agents and some of these language models. And the two biggest risks associated with the RAG systems are the poison databases, and then also leakage of sensitive data. Uh, in terms of runtime and operational threats, you've got tool misuse, and, uh, agents are tricked into calling tools with the wrong credentials or elevated privileges. So once again, it comes back to basics where you've got credential problems, and you've got, um, elevated privileges that you can, uh, take care of before this ever happens. Um, detection and guard rail evasion. There are some categories here that are, are very sophisticated. Sometimes just ensuring simple security principles are not enough. Um, multimodal attacks is an example here. So if you can exploit different input types to embed malicious instructions and formats that evade detection. Um, then that is a problem as well. So for example, adversarial text can, uh, use carefully crafted phrases, uh, and that can mislead the agent to do things it shouldn't do. These can be harder to detect because malicious content may not be distributed across different media types. So in the healthcare sector, multi multi-modal models are often used, uh, in critical diagnose diagnostics, treatment planning. Um, the systems may use contributions. Text-based, uh, medical records, uh, imaging like X-rays or MRI's, and then even real-time sensor data. So the multimodal part is they're getting input from all different types of formats and different types of data. So that's very complicated, uh, in terms of compliance and governance gaps, simply having audit trails is really, really important, but that's something that is not always in place when people are using agentic systems. So those audit trails obviously make it. Uh, possible to trace agent actions, uh, back to human authorizers and for you to do, uh, forensics when things like this happen and when things go wrong. So, as you can see, there's a long list of vulnerabilities in what we kind of put together in 10 logical categories. Um, and so that's a lot that you need to think about and that's a lot that you have to fend off. Prompt-based exploits account for 35.3% of all the documented AI incidents. Um, there's $100,000 a loss on average, uh, with losses that are being caused without writing code. So you have some of these. Text-based attacks that seem very simple, um, but very possible and that are being used now. Um, the zero-click vulnerability, uh, one that was known as echo leak enabled data exfiltration from Microsoft 365 co-pilot through pure text that was embedded in normal business documents. So the payload requires no code execution. Co-pilot behaves like it's supposed to, and then it processes this malicious prompt, uh, when the user. Opens in a seemingly uh innocent file or something that's innocuous. So with that whirlwind tour of all of these categories, um, security challenges don't just emerge in production so you need to think about this in development, uh, and where some of these things can be guarded against and where some of them get introduced. So Nick's gonna give you a dive into the whole, um, agent development life cycle and kind of what happens there and how you think about security. So as David's kind of said, we, we just looked at the landscape of your agentic applications running in production, you can see there are a number of threats on them. Some of them are, you know, fairly aligned to running something that you might see in a microservice system. But the, the software development life cycle or the agent development life cycle is equally important, and there's a number of threats which, Which, which kind of are um make your application vulnerable, so this chart here comes from a paper that IBM authored and was validated by Anthropic, and, and it looked at secure enterprise application development. So this is predominantly looking at the, the application development life cycle, and anybody who's looked at software um development life cycle will see that it's, it's very similar. So the area that I want to concentrate on is build and test. So let's, let's kind of have a look at this. So when you're looking at the build and the test phase. You, you sort of have to consider certain things, so the, the, the doc, the, the IBM document says that we should be looking at things like hybrid models by design, looking at hybrid cloud by design, looking at interoperability, building things which are tool centric. Importantly, secure by design, and I think this is something that we've, we've kind of learned over a number of years to kind of have that approach of just building secure by design as a, as a first principle of, of developing any new feature. But also we, we need to look at the, the kind of the, the, the blast radius and trying to look at our agents and our tools and putting them in a box, kind of really having them heavily restricted, so if something does go wrong, then, then that is um is constrained. Now, where I kind of wanna put a little bit more emphasis on this is looking at vibe coding. How many people here vibe code? Right? And are the rest of you lying or have you not tried it yet? Right, I mean, seriously, it, it's, it's a very powerful tool. I use it myself. I'm, I'm, I love using it as a tool because er um something for me as an application developer, it, it assists me to get my job done really quickly. But the key thing is when I'm looking at vibe coding, my mind is in a very different place than it is if I'm just writing plain application code, doing pair programming or writing on my own. I'm looking at things inadvertently, things like speed over security. I'm just kind of working through this, I'm just mashing away, right? And where this kind of causes problems is, it introduces new areas of supply chain attack, and I can have issues where maybe I'm not validating dependencies as tightly as I would if I was manually kind of authoring the code or going through a, A, a sort of a, a more formal process because this is a new world, right, so we're, we're kind of breaking the rules here to, to increase velocity. And the kind of the key thing I think around a lot of code that is written when you're, you're kind of using some, some wonderful tooling like Cloud and things is that you have functional correctness but you don't necessarily have security and where you, you kind of. This can can fall down, is let's, let's think of a little scenario here. So what we're gonna look at is a little scenario. So I am a junior developer, and I am gonna be using Cloud, I am empowered to write a feature for uh an, an agent, and the, the feature is gonna be that I'm gonna add a new endpoint to my um weather tool. Now. As, as a kind of a good practice, my company has provided me with a bunch of best practices that the agent is gonna use. All of the, the kind of the good development practices we've encoded into a document. That, that we, that the agent can understand and can use, so we, we start off and we're like, hey, OK, I need to add a new endpoint to the, the weather tool that can go and fetch the weather from open weather API. So we, we go through that, we type the prompt, and we hit the button to, to make it, make it do its thing. At this point I'm kind of sitting back watching a bit of Netflix, watching YouTube, you know you do it. Where, but my attention is switched off, right? I, it's not in exactly the same place as if I was writing this code myself, and it's not by any other kind of reason and it, it's just a different way of working. So Claude is, is going away there, it's using the best practices document, it's, it's generating the code for me. Um, it's, it's kind of spinning through that. It's, it's kind of written that, that end point, it's to, to be able to fetch the data from the, the API. And, and then we wanna go through and, and sort of test it, so yeah, it's just validating against the corporate best practices there. And then in a second, I'm gonna go through and I'm gonna test this, right? So I'm like. Well, how do I test this? I'm getting a little bit lazy, so I'm just like, hey Claude just go test this for me, so I, I stick my, my Open Weather API key in my environment file on my local computer. I hit the button, I go back to Claude and I'm like, you know, make sure this works. This is a a fairly sort of typical flow that I would take on a day to day basis. And Claude comes back and it's like, yeah, everything works, and I'm like great, right, this is, this is job done, I've just achieved. In, in a matter of minutes, what potentially could have taken me a number of hours, so. I'm just gonna like ship it, right? Like, again, the the the key thing is what I wanna kind of stress is that my mind is in a different place, like all of those skills and those things that I have learned. Over the years as an application developer, I'm kind of just forgetting about right now because this is great, this is all just working, that's functionally correct does not equal secure. Code nirvana. Right. So I'm gonna go a step further, I'm even getting Claude to, to generate me the Kuberneti's deployment manifests, I'm getting it to generate me the, the docker files, and it does it very, very, very well. But There are some problems, and. We'll kind of see this in just 1 2nd. The problem comes that again, it's about that attention, where is my attention? And my attention now is just ship it. So I've got the the secure pipeline, everything is ready, I get committed, I push it to GitHub, and everything is perfect, right, we're done, we can now. Put slack on Do Not Disturb for a few hours, slope off and do some, some other stuff. Well, until. Ready for it? Uh-huh, OK. OK, we're done with that, right? All right. We're not saying don't do vibe coding, right? No, we're saying absolutely do vibe coding, yeah, but you need to put guardrails in place, right? OK, that includes the ability to monitor. Unsecure secrets and other things while you're doing this. OK. So HCP Vault radar is a product that will go out and scan data sources and monitor data sources when unsecured code gets introduced. So I'm just gonna walk you through this a little bit. So this is an example of a tool you could use to solve some of these problems that we were walking through in the category. It detects over 300 patterns, uh, looking for secrets and unsecured data. It. For entropy and complexity, uh, that helps you find some of those more complex secrets, uh, and keys that are out there. It does activeness and version checks to, to see whether the secrets that you find are currently active or are they in get history, and it will assign severity and risk rankings to them. So it helps you figure out how bad your blast radius is from doing some of the things that you do. Uh, and, and letting unsecure secrets get out in the wild. It's currently supports get servers, collab platforms like Confluence and Slack, uh, and will even scan in your IDE currently supporting, uh, VS code to do that. Um, there's also integration with tools that can help you alert or automatically generate tickets and do other things. So when you start thinking about the front end of all of this, think about how. How do you number one discover all the uh secrets that are kind of out in the wild that might be long lived that are putting you at risk, uh, but also then how can you monitor these data sources to make sure if something is about to be introduced that you can catch it before that happens um I also wanted to talk about the fact that we have we have integrated Vault radar with AWS Secrets Manager so as. Much as you wanna find these secrets that are out in the wild and get them under control and being managed, sometimes people manage or sometimes people mismanage secrets that are currently being stored. So, uh, we are able to index AWS Secrets Manager securely with Vault radar. If you have a secret that gets out in the wild, you will know whether it's also being stored in AWS Secrets Manager, who owns it. And then go back to that person to be able to get them to remediate it and talk about how to better handle secrets and not let them get out of your secret manager. So it integrates with Vault, Hashior Vault, our product, AWS Secrets Manager, and you can expect to see more secrets managers being added, uh, that will allow you to do that correlation. Um, you are also able to get remediation steps that are customizable, so if somebody finds a certain type of secret in a certain type of location, you, they get instructions to consistently handle that the right way. Uh, whether that is importing the secret into Vault, which you can currently do, and then, um, basically you could use something like co-pilot to be able to create the code wherever it was hardcoded to point to Vault to make sure that it gets the secret there and it's no longer in the code. So you need a way to effectively be able to remediate the stuff when you find it. Um, and radar also will scan. Uh, as far left as your IDE platform, so you can get alerts if there's a secret that's in code. As soon as that gets saved, it'll pop up, gives you remediation steps, the ability to copy that into Vault. But we're also scanning in the CICD pipeline, and then, um, pre-receive and pre pre-commit phases as well. So with that, let's take a quick look at what Vault radar looks like to help you do this. So this is, I was gonna say nobody spotted my deliberate mistake. Yeah, no, they didn't. Um, so this is the overview dashboard where you can see all the data repositories that you're monitoring. Uh, you can see all kinds of helpful metrics about it. Um, you can see what are the most common types of secrets that are being discovered that are unsecure, who owns them? I mean, who are our biggest offenders in this dashboard, and all kinds of other interesting data. But ultimately, uh, I'm not gonna be sitting here just staring at the dashboard for this product and saying. Watching for a new event to happen or an unsecure secret to be discovered. So I wanna use the tools integration. In this case, I've connected it with Slack and I've configured a channel where I get alerts whenever something's introduced. And here I can see I have a high severity incident that was discovered, who the author was for that, what time it was, and a link to go directly to the source file where that was discovered, and I can see that um. Uh, where this is, where the file is, it's in my cat generator repo that I've been monitoring. I also can go back to the event that's in Vault radar, and I can see similar information and details about what type of secret it is. I also have that link to go see where it showed up in code or in the file. Uh, I can see it's my weather app. Uh, EV file and I also see that that's something that's being stored in AWS secrets managers, so that's good to know somebody has mishandled that. I also can click on a link for remediation instructions. So when I found this, I can go in and get the proper steps and make sure that people are following those steps consistently when they need to resolve that issue. So I'm just gonna go ahead and mark this as triage, and because I've configured our back for the product, I can hand this off to the proper repo owner or dev owner who needs to go and finish fixing that problem. So With that, let's talk about agentic AI a little bit more, and you have a cautionary tale for us, I do, Nick. So when, when I kind of was going through before and looking at that little demo of my, my vibe coding example, my inattention due to being kind of in a different way of working caused me to committing that, that environment variable. To uh to get a, a very simple sort of standard mistake that I've made before in the past and something that I'm actually fairly aware of right now, but again that that shift in, in, in sort of concentration. Now, when I was kind of looking at that, maybe there was a deeper problem in that vibe coding example because did anybody see the this when the, the code was created by Claude? So the, the requests library, that's, that's not necessarily a, a, a standard library. Um what about this one? Did you, did you spot this when I generated the Kuberneti's configuration? So I'm, I'm running host network on my pod, right? Well why would I do that? Well, I didn't. I didn't do that at all. Now I had best practices in the, the agent, the agent was using, so, well, how did these, these kind of issues end up in the, the source code? And the, the way that it happened was because we're looking at a very, what I think is a sort of an intelligent attack. From, from the militias, so a malicious person didn't decide to attack my source code directly, they didn't attack the production system, they didn't attack my supply chain indirectly, even though we we, we saw an example of typo squatting there. What they did was they attacked my best practices documentation. So the, the attacker has, has found a way to manipulate my best practices documentation that my gentic agent has used. That has caused the code to be produced, which included the type of squatted. URL, um, sorry, the er package, and also, it included the, the host networking switch on, and, and what that has done is that a type of squat URL will activate a, a packet sniffer whenever the, the weather server is running. So whenever that, a request comes in to that tool, a packet sniffer's now running now because that packet sniffer also now has host network capabilities. It's got the ability to, to basically capture any of the unencrypted traffic inside of my Cubernatis cluster. And unfortunately, I've made other mistakes by not looking at the defense in depth and and taking a full zero trust approach because I trust everything that runs on the server. So that attack, that sniffer runs, the credentials are detected, and then the attacker can exfiltrate those back to their own system. So the, the, the packet sniffer that's running inside the weather tool picks up the database credentials for post res for the customer database, a completely unrelated tool, and sends them back to be, to be used as, as is. And the way they did that was, was very simple. They just used context poisoning, they just injected this very simple statement into the, the, the, the doc the developer documentation that the agent uses now. It, it's just a kind of a backdoor attack, but it, it opens up a vulnerability that I wouldn't have been affected with had I myself been writing and authoring that code, because I would have, well, A, I wouldn't have used that library, and B, I probably wouldn't have been reading those documentation every single time. I've got it sort of encoded into my mind. And the, the, the second step is that they put another manipulation into the best practices. So whenever we are developing. Um, uh, Kubernetti's deployment, there is a best practice which says, well, hey, if you've used the requests library, then this requires host networking because of some bug in the library, right? So it's, it's a way that I've circumvented the, the, the complete sort of security of, of the system through something which is probably fairly innocuous, like, you know, it's something that's not necessarily used very heavily. So let's, let's look at that in action and see, see how that works. So we're just gonna kind of see this, so somebody goes into the, the UI and then they're just gonna say, right, we're gonna use the weather, the weather agent. What's the weather like in Las Vegas? TLDR, it probably sucks right now. So the, you can see that the, the agent calls the tool. Now, at this point, the tool has activated the packet sniffer. So that is now running in the background, and if we look at the logs, I'm just gonna kind of pull you the, the logs there of the, the pod which contains the pack er the, the weather tool. You can see there the sniffer's been running. An attacker is obviously not gonna be that obvious in the logs, but now we can see the, the kind of the, the, the, the, the database that they're gonna exfiltate those credentials out to. So when somebody now goes and uses the customer tool, I'm just gonna say, well, hey, get me the, the customer data, um, order details for um for an ID 8, right, so customer 8. That again calls a tool, the tool makes a connection to the database. To retrieve the order details. Which has caused a connection from the tool to be opened against the database, and what you can see is that we've, we've now got all of those credentials there now, again, there's a number of problems, the, the, there's no TLS. Um, there is very, very open credentials being used with the data store. We are not using a particularly strong database connection. We're using MD5 when we should be using Charsson. Very, very simple to sort of, um, to, to to to decrypt that using, um, Hashcat or something like that. And there's no attribution, we don't know who did it, we don't know when they did it or what went on, so there's like a number of problems that we need to, to fix, which David is, is gonna start to explain to us. Yes there is, so, um. Let's talk a little bit about some of the basics. You know how I mentioned at the beginning that there, there's a lot of sophisticated attacks that are happening, uh, based on agentic AII or leveraging that to do bad things, but really a lot of these things can be stopped if you're using core security best practices. So, um, every AI agent needs to have a unique auditable identity. There has to be user attributions. So who is the human, what is the human ID that is uh mapped to this agent, so that you can trace that back, and so you can make sure that you are not giving that agent any greater permissions than the human identity that is using that agent. Dynamic authorization, no long-lived secrets, nothing that's sitting out there for a long time. Imposing you, but you need dynamic authorization, uh, some kind of token exchange, not static credentials, and then you also need a framework for consent, so explicit time-bound revocable permissions. So these are all kind of core security things that regardless of having agentic AI or NHI's starting to outnumber, uh, human identities 50 to 1, 100 to 1. These should just be in place now, but they, they often aren't, so it's becoming a bigger problem because of what's happening with the agentic threat. So if I go back through those 10 kind of core categories of threats, let's look at what some of these core security best practices, how many of these problems we could protect against. So if we look at identity and authentication. Uh, or authorization threats, the solution here is really about making sure you correctly configure identity and access management policies from the start, and we can see the different phases once again where these occur for credential and secret management, Vault, we're talk about Hashiorp Vault, supports centralized secrets management and short-lived credentials. So why wouldn't you use those things. To solve a multitude of these security problems, um, with tool and integration exploits, the use of short-lived creds once again, helps with that. Also, PKI and certificate management addresses that tool injection problem because you're using TLS or you're using MTLS to make sure that things are being securely, uh, connected or communicated uh by that method. The supply chain attacks, once again, PKI certificates using TLS to protect against those supply chain attacks. Uh, the MCP server registry and update or patch mechanisms would be a good example of that. Uh, multi-agent system threats, once again, you need to be able to protect against agent communication poisoning. You can do that with using something like PKI certificates and having TLS or MTLS in place for those agents and sub-agents. Um, in terms of prompt-based attacks, uh, the related data security threats on the next slide, including this one, are gonna require a multi-layered approach. So it's probably not surprising. That's often gonna require a combination of things like, um, team processes that you put into place. So you talk about the concept of red teaming. This is just one simple fix for these types of attacks, um, because, uh, it's often gonna require that combination, and then also. Some purpose built AI security tools that we're starting to see evolve. That's because the attack surface of the AI applications is really different from traditional apps. The models are dynamic, behavior changes and all that, so you might want to see some tools or investigate tools that have the ability to do things like inspect and filter inputs to stop some of the malicious attacks, uh, monitoring for output anomalies, hallucinations, track. Govern model versions, uh, and then also requiring integration of security at the model life cycle level. So these are all kind of model changes that are come with that come with security thinking about managing these threats and going forward and so and what I'm saying is we don't have necessarily the lead the solution for all of these things right now and they're gonna continue to be a problem, but you need to think about these and be investigating tools that help in these ways going forward. Um, once again, the data security threats, that's another area where you need some of this proactive testing, a combination of security mechanisms and a layered approach. Um, in terms of layer, uh, runtime and operational threats, once again, short-lived dynamic credentials, uh, protects a lot of ground, uh, being able to implement that. Detection and guard rail evasion is an interesting one because it's similar to more AI native risk categories, um, and addressing these attack vectors is gonna require tools that can provide capabilities like automated red teaming, for example, or continuous security, uh, continuous security testing, so a little bit more sophisticated. Um, for compliance and governance, enable audit logs. Um, Vault has a detailed audit logs for any action that takes place, uh, within Vault, and having those audit trails makes it possible to meet regulatory requirements and also, um, trace agent actions back to human actors. So, um, identity brokering is critical to securely managing a genetic identity, and we talked about that disconnect between human, uh, and non-human identities. Um, and we've all seen the headlines about what happens next when you don't manage that well or you don't connect the two, or have the proper policies. So, NHIs, I think I mentioned that, outnumber humans 50 to 1. 80% of breaches involve them. Um, 97%, this is really bad when 97% of NHIs have excessive privileges, gotta solve the privilege problem, um, and, uh, most organizations don't even have a process to offboard API keys when they're out there and they get abandoned and they're sitting around for a long time, so. With that, um, Nick is actually gonna talk a little bit about this kind of authentication and authorization. Yeah, this is really important when it, when you start to think about an agentic system because an agent. Is doing something on my behalf, I am not doing the thing, it is the agent which is doing it on my behalf, it's, it's very similar to me just giving my credentials to David and saying hey David, can you go and, I don't know, like, check my email and, and tell me what my, my boss said. Now I trust David. Um, many people say I probably shouldn't, but I do. But the thing is, like, David is a trustworthy person, the agent is potentially open to manipulation. We've already seen how it's, there are a multitude of ways that that agent can be manipulated. So we have to really, really strongly think about identity in behalf of a, of a sort of a, a process that an agent is acting on. Now, there is a a kind of a a common sort of approach of called on behalf of, and what that allows you to do is to take a token like a JWT and to add additional information to it. Which, which tells you that it is operating on behalf of a particular user. So a, in this instance, what we're gonna take is a, a service token, an agent token, and we're gonna augment that token to say that this agent is acting on behalf of this user and this user has these privileges. Now, when we, we kind of go about doing that, it means that we, we have this approach of, of basically taking two tokens and creating a third. You can do this with a standard IDP as I say, on behalf of is a a a sort of a formal process of OIDC, but. That works great for the very sort of edge thing, but like from an internal service perspective, we, we kind of want to take another approach and, and actually we're gonna use vaults to be able to mint those internal identities, cos this is happening quite frequently, a number of different agents, a number of sub-agents, and we wanna be able to refine those permissions every single time to ensure that the, the agent is doing, Well, we don't know that the agent is doing what we, we want it to do, we're going to assume that it isn't, so what we're going to do is ensure that the agent can only act within a very, very specific bound. And if we don't do that, so let's just say, hey, we're just going to have the, the user identity. Well, if we just pass the user identity to the agent, then the agent can, can misuse this. The, the agent can kind of go wild, it can kind of change its direction, it can either be manipulated, or it could just be a bug, but it can then use my privileges to do something that it shouldn't be able to do. And if we look at that another way and we say, well, hey, well why don't we, we just use the, the kind of the service token, you have exactly the same problem. You know, the, the, the, the, the sort of without the agent identity, then you, the, the customer or the user can potentially trick the agent into doing something and elevating their privileges, so both of those are needed in order to kind of to, to restrict it. Agent identity is, is really important and, and to, to create an identity from your agent, you don't just need something which is just like an like a, a random ID you, you need to be able to have that audit trail and that audit logging, and by that you need to be able to have metadata which represents the agent. So the agent needs a proper um token which, which is similar to to what the human user would have. Defining its scope. Now with Vault we can go about that approach by using a Kubernetes token, we can create an identity and we can swap that for a more rich, um, token which has, has got all of that metadata in it. Again, we're putting that into the, the audit log now, so we're we're satisfying those things as well. The, the kind of the practice of that is, is fairly straightforward and, and in terms of the efficiency where we use a plug-in into the secrets engine for Vault, which, which enables us to generate those on behalf of, of, of tokens. And that kind of brings us to the, the sort of the approach of Cubinnati, so how are we gonna. Use this. How do we, how do we use Vault inside of Kubernetti's? How do we secure those, those secrets? That is a great question. So let's dive into this a little bit. Um, Vault has a capability with the Vault secrets operator to manage secrets in a native way with Kubernetes. So this includes being able to use dynamic secrets, PKI certificates, all the kinds of, uh, credentials that you would want to use to keep things more secure. Um, OpenShift OLM supports it for instant upgrades, so that also works as well. Secret transformation is also something that VSO can handle, so you end up with, uh, templating that looks familiar with the secrets on the Kubernetes side, and so that's very helpful. So basically, what happens is, whoever is managing these things and is familiar with Kubernetes, not familiar with Vault, they don't really need to know anything about Vault or how Vault works because this process is all very native. Um, in terms of identity-based access, in, uh, authentication of Vault is processed, whether it's human or non-human, uh, by providing identity verification, and you can see there's a wide range of different identity providers that will, uh, plug into Vault that you can leverage so you can use all of those, uh, those identity providers, and it also is really critical because most organizations are working in a very hybrid environment. You're not just working in. Uh, in often cases one type of cloud, one type of, uh, um. Uh, identification system, there's probably multiple that exist, so you need that to be able to be integrated with whatever you're using to centrally manage security. Um, so multiple auth methods are supported, and then before a client, whether human or machine, can interact with Vault, it has to authenticate. That's really important and so you need these auth methods. Once that happens, there's a token that's generated, and there is a policy that gets attached to that token. Uh, and so whatever entity gets that token, they can only do what they're permitted to do by that policy. And so right here, uh, Vault recognizes Nick's different authentication identities. It can create credentials dynamically based on that identity and then. Uh, create access policies based on that as well. Um, when we talk about uni unified identity in Vault, there's, um, an identity, uh, engine that exists in Vault that handles this sort of thing, and when you have a new. Entity or identity that is authenticating with Vault, it creates that entity. So it is that one, it has a unique ID, it is a unique entity to Vault, but what allows you to use this in a flexible environment is you can have aliases. So there might be different authentication methods that are being used for the same entity, and those are aliases that you have. You can also assign metadata, you can assign policies at that. At that alias level and so that gives you a lot of flexibility to make sure you have that one entity accessing vault and wanting to do something but you're locking things down and enabling things for the various aliases that that entity might have if that makes sense and this picture here is kind of uh. What shows that and being able to enable the RBAC for those more complex environments that you find yourselves in with the human and machine identity audit logs, um, that's something that is native to Vault. They're stored in JSON, uh, making them easy to query. Vault automatically hashes any. Sensitive data, so they're very secure logs with HMAC, uh, SHA 256. Um, there's a unique salt that's used as well, so extremely secure, and this allows you to have that audit trail for things that are going on within vault because that all gets logged very securely. Um, so let's talk about dynamic credentials a little bit, because we saw in multiple examples of the attack vectors, if dynamic credentials had been used, uh, it would have, uh, ameliorated that attack. So let's look at the first problem, and that was credentials. So security is all about layered security. Uh, if we stop that vulnerability, there would not have been any credentials leaked, sure, but if it wasn't that attack, it would have been another attack. So that's kind of how you have to think. So we should go ahead and assume the credentials will leak, and if they do, you need to ensure that the blast radius is minimized, and the only way you're gonna do that is to be able to set just in time credentials, ones that have time to live, that can be revoked immediately. To solve that problem, um, dynamic secrets within Vault are created just in time. Um, there's a unique ID that is associated with each one of those credentials. It's in a unique identifier, uh, that allows the secret to be audited, located, revoked early if you need to do that. Um, in every application instance or agent gets a different credential with a different time to live. In terms of the support for dynamic credentials, this is a look at the broad range of uh dynamic credential types that Hashi Corp Vault supports. So multiple different types of databases, uh, via the database secrets engine, cloud service provider dynamic credentials, LDAP, and then also security uh or certificates like I mentioned before for PKI and SSH. So there's no reason not to use dynamic credentials when you have all of that available to you. Um, this is an example of the dynamic secrets database engine, and you can kind of see what the flow looks like here. Obviously the secrets are created just in time, uh, and they ensure that access is automatically revoked at the end of the expiry time for that credential. And with that, I think we're gonna look at a quick demo of how this works. Yeah, so rather than doing like a bit of a um a, a deep dive, can you, um, we, we can kind of talk about these things if you wanna come over to, to the booth. I'm, I'm conscious of a little bit on time. But, but ultimately the way that you can configure all of this just using Kubernetes as an example, which I think is, is a fairly sort of common platform these days, is just through using the uh the, the vault secrets operator, which is um verified and compatible with OpenShift and and all sorts of things like that and just by using that configuration. Through, um, well, setting up the database secrets engine, but then injecting those secrets into Kuberneti's. We'll, we'll kind of skip over this one, for the moment, as I said, if you're, if you're interested in looking at a technical deep dive, come and uh come and find me, I'd be more than happy to, to run through those, um, schemas and, and processes in, in more depth. On to the next one. Yeah. All right, so let's talk a little bit about certificates. I mentioned that as well, and something especially using TLS or MTLS that's uh extremely important in protecting against some of these attacks. Um, in this situation, in this attack, if there had been TLS on the system, then the credentials would not have been leaked. Moreover, if there had been TLS on the system, the credentials would not have leaked in this way. And so that's really important too, the way that this happened. Um, so we need to do both things, and it's, it's not hard to implement with the right tooling to make sure you're using dynamic credentials, and to make sure that you're using certificates to enable things like TLS and MTLS. Um, Vault supports modern PKI management, uh, and what I mean by that is, uh, very automated, very scalable, and, uh, Vault is flexible too in the architecture because you can have multiple intermediate, uh, certificate authorities that you can configure, uh, based on your environment and what your needs are. It can act as. The internal root CA issuing X-509 certificates, um, it automatically enables you to revoke, uh, and distribute these certificates in different ways, and I'll show you some of the multiple methods, uh, that it can leverage. It also has a native support for Spiffy, so the Spiffy X 509 standard, extremely popular. Uh, open standard, uh, because it allows you to have very granular, um, authorization on certificates and gives you an easy way to manage and scale those identities, uh, when you're using certificates. Um, there's also service mesh integration supporting MTLS for service to service certificates as well. So let's take a look at what this looks like. There's some examples. So using the vault agent, this, this is where the vault agent is actually. Um, connecting to the service or the application, it's keeping track of the time to live on that certificate, so when it, it knows when it's about to expire, and then it will communicate back with Vault, and it will authenticate and it will request a new certificate. It gets a certificate and then it updates that certificate in the service. Vault meanwhile is keeping track of all. The roles that that are accessing it to get certificates um and then being able to use those it also works in a similar way if we look at the Kubernetes environment like we were just talking about uh the Vault secrets operator is what enables you to integrate with Vault and automate that certificate management and have that work in your containerized environment. So, um, there's different methods. If you look on the left, uh, those are established patterns using the Vault agent and then VSO. Uh, they're very opinionated, uh, but on the right you also see the capability to use less opinionated methods of leveraging this type of capability with Vault. There's the Vault SDK you can integrate directly into code. Uh, and then you can utilize the Vault CLI to authenticate and retrieve one-off certificates. So there's multiple methods, uh, when we're talking about flexibility to be able to leverage certificates with Vault. In terms of architecture and scaling, uh, like I mentioned, you can have an offline route CA you create an intermediate CA that's kind of your top of level wildcard domain, you can have, you know, a, a time to live of a year, you can create another intermediate CA. Uh, from the top level, it's got a shorter TTL so you can see how you can architect this and be very flexible with it. And then lastly you have your, your instance of, uh, intermediate CA that's gonna issue those leave certificates for your application or service and make that 30 days or whatever you need to do, uh, but extremely flexible in terms of performance, compliance, and scalability. Uh, there's disaster recovery that supports warm standbys that can be configured for easy recovery. Um, there's automated deployment, so if this is something that you want to deploy in an automated and scalable way, you can use Terraform to do that. Um, you have audit logging that exists, obviously that we talked about so you can generate reports for that purpose. Cross region support to meet, uh, applications where they are from a performance standpoint, and then things like path filters, uh, to ensure that secrets are not accessed or stored in vault clusters where they may be additional compliance so you think GDPR, uh, and that becomes important too. And if we put it all together, it's just an extremely scalable tier zero application. Uh, that you can leverage for PKI, and with that, let's go ahead and take a look at a demo of how this works. So again, from a, a, a sort of a stance on how you go about dealing with this, how do you configure Vault, it, it's fairly straightforward. If you've kind of understand how one of the endpoints work, they're all fairly similar. Conceptually, you, you have to enable an endpoint. So with PKI I enable the PKI endpoint, I can generate a root certificate, and then I can configure it. And once I've got all of those kind of things set up, that then enables me to, to use the Vault secrets operator to, to use those roles that I've configured, again, it's, it's linked through to the policy in the service account in, in Kubernetes, and it will allow me to inject that secret from Vault, dynamically generated into a Kubernetes secret, so from an application development perspective there's there's nothing different here. Now if we kind of look at all of those things, so if we look at the things that we've talked about where the vulnerabilities which were core in our, our demo were that had we had TLS and had we had dynamic credentials, the blast radius would have been far, far, far more reduced. Of course we're, we're looking at a very, very select problem in a, in a very select area, but that's a concept of defense and depth. It's not about just doing one thing. You, you really have to do all the things. With dynamic secrets and with um PKI in our agentic application, if we kind of look through and replay that attack, you'll see how, how things differ, so now we've configured the, the server. To use PKI again, the, the, the vulnerability still exists, so when I find out what the weather's like, um, and this time I'm gonna kind of ask what the weather is like in Miami, because it's gonna be a lot nicer than it, than it, it is here right now, unless you were in Miami last weekend and you realized that it just rained for two days, um, but. But conceptually that that same process has gone through, right? The sniffer is now enabled. It's now been sending the the credentials back to the, the attacker, and when we use the, the, the same thing using the customer agent, we'll say, hey, give me the customer order details here. What that is gonna do is the agent talks to the tool, the tool makes a connection to the database, the database authenticates. You can see that kind of running through in, in the application, but now when we look at the credentials, we don't see anything. And the reason we don't see anything because the connection between the, the tool and the connection between the agents and the connection to the database is all encrypted with a standard practice that you've been using for thousands and thousands and thousands of hours and months and years and. You know, since the, the dawn of microservices or, or any form of sort of secure system. So what are the key differences with eugenic systems and and microservices, and I think the key thing is that not a lot, and actually quite a bit. That's a, a really sort of ambiguous approach, but the, the key thing is that an eugenic system is very deterministic. You can't necessarily predict what it is going to do, it's, it has this kind of emergent behavior where it'll just act on its behalf, it is more human than it is. The, the kind of that traditional approach where you can just follow the code path through um either as a single service or a connection of services. The thing that's very much the same is that a lot of the problems that you've fixed in your microservice systems by just employing good sort of secure practices around coding standards, by employing sort of secure systems, still applies. There is nothing really, really different. What we. We have to be aware, we've got to be planning ahead, we've got to be thinking what are the threats, because some of them we just don't know. Like there are things that we know, but the, the attackers are becoming very, very sophisticated, and because of that emergent behavior, it's opening up new opportunities that just don't exist right now. So if you, if you wanna learn some more, then we've, we've got some resources here, you can kind of grab um our example Repo and uh you can kind of if you wanna run Vault in on your own or run Vault radar, you can kind of get a free, a free trial there and of course if you want a more of a deep dive on the technical side of things, please come and, come and find us in the, the Expo hall and it would be an absolute pleasure to. Chat to you about those things, but thank you so much for listening. I, I hope it's been interesting. Yep, thank you all for coming, hope it was valuable. Enjoy the rest of the event.