---
video_id: 7pkeTtMUmPo
video_url: https://www.youtube.com/watch?v=7pkeTtMUmPo
is_generated: False
is_translatable: True
summary: "In this panel discussion, industry leaders from PagerDuty, NVIDIA, and Okta examine the profound impact of AI and automation on enterprise resilience and incident management. Moderated by Rukmini from PagerDuty, the panel features Rama Akiraju (VP of AI/ML for IT at NVIDIA) and Dennis Henry (Productivity Architect at Okta), who share their firsthand experiences in operationalizing AI to transform digital operations. The core theme revolves around the evolution of AIOps: moving beyond simple reaction to a state of predictive, proactive, and eventually self-healing systems.

Rama Akiraju details NVIDIA's ambitious internal 'AI factory' approach, where they are building a comprehensive platform to enable 'agentic AI' across the enterprise. She breaks down the incident management lifecycle into distinct stages—detection, diagnosis, resolution, and avoidance—and describes how AI agents are being deployed at each stage. For detection, agents are used for anomaly detection and alert noise reduction, intelligently grouping related alerts based on topology and historical patterns. For diagnosis, agents correlate vast amounts of logs, traces, and metrics to generate hypotheses on root causes. Akiraju envisions a future where agents not only suggest fixes but autonomously execute runbooks and emergency response procedures, effectively 'shifting left' the operational knowledge into the development cycle.

Dennis Henry offers a complementary perspective focused on 'Human Factors' and productivity. He argues that while AI is excellent for processing massive datasets and handling historical context, the human operator remains essential for dealing with 'new and novel' problems—the 'black swan' events that lack training data. He emphasizes the concept of cognitive load management during the 'fog of war' of a major incident, suggesting that AI's best use case is to contextualize information so that human experts can make high-stakes decisions effectively. Henry also discusses the 'democratization' of AI at Okta, describing a 'guild' model where employees from various functions (including finance and sales) contribute to an 'AI gallery' of prompts and agents, fostering a culture of bottom-up innovation.

The conversation delves deep into the non-negotiables of this new era, with Security identified as the paramount table stake. The panelists discuss the risks of giving agents write access to production systems too early, advocating for a 'read-only' approach initially and strict guardrails around agent capabilities. They explore the organizational implications of an AI-first workforce, with Akiraju famously quoting NVIDIA CEO Jensen Huang: 'IT departments are becoming increasingly the HR for AI agents.' This implies a new responsibility for IT to recruit (build), onboard (contextualize), evaluate (monitor), and offboard (decommission) AI agents just as they would human employees.

Looking ahead to 2026, the panel predicts that standard AIOps platforms must include pre-built secure connectors to core data sources, robust pipelines for unstructured data (RAG), and a centralized registry for agent discovery. The session concludes with a call to action for developers and SREs to 'codify their operational wisdom,' treating the platform as a shared knowledge base that empowers both human and digital workers to maintain resilience in an increasingly complex environment."
keywords:
  - AIOps
  - incident management
  - enterprise resilience
  - automation
  - NVIDIA
  - Okta
  - PagerDuty
  - anomaly detection
  - SRE
  - agentic AI
  - human factors
  - self-healing systems
  - alert noise reduction
  - AI governance
  - productivity---

Yes, good morning, everybody. Uh, welcome, welcome to our panel. We were just discussing what we would ask first, so maybe show of hands who here is a pager duty customer? Who here is an Octa customer? All right, and maybe a few who knows Nvidia, who is not an Nvidia customer, who's not an Nvidia customer. We all are Nvidia customers now, right? Uh, so welcome. My name, good morning, Builder. My name is Rukmini. Um, I'm from PGDD. I'm just thrilled to kick off this session. I have some serious like AI ops brain power here with me. And how has Reinman been going so far? Anyone's feet tired yet? No, OK, all right, um, uh, please, please join me in welcoming these powerhouse panelists, you know, they're the world experts in driving platforms that power identity and trust at massive scale. So maybe, uh, Rama, Rama Akiraju, she's a VP of AI and ML for IT at Nvidia, and she's powering AI infrastructure transformation that we all depend and rely on and Dennis, who is the productive Dennis Henry. The productivity architect at Ota he pro Ota provides identity services to secure transformation. So our topic today and our mission is how AI is reinventing digital operations and incident management so we builders can ship faster, scale, smarter, and most importantly stay resilient, right? So quick wipe check. Let's do this. Who here is running AI in prod today? All right. Who is experimenting? All right, who is AI curious? All right, OK, we have a decent show of hands, so you're all in the right room. Uh, we have a few time. We are gonna have plenty of time for questions in the end, so please get ready. Keep thinking about what you wanna learn about. And so buckle up and, uh, let's get this started. So we can start with, like, I love Rama and Dennis. Maybe you can start in that order. Please introduce yourselves and your organizations to our audience. And we, it'd be great if you can give us a flavor of your remit and how you touch AI transformation. So Rama, can we start with you? Thank you, Rukminini. First of all, thank you for having me on this panel. Excited to be talking about this topic of AI ops, which is, uh, very close to my heart. Um, I lead the AI initiatives at Nvidia IT. My mission is broader than that though. It's AI at Nvidia, uh, essentially bringing AI to every corner of Nvidia with our. AI platforms and AI tools. So as part of that mission, my team and I, we build AI platforms, agentic AI platforms, and also several AI workflows in the spaces of employee productivity. I would say, developer productivity, uh, supply chain optimization, and also work with, uh, various business functions within the company, including our chip design teams, software engineering teams, sales, marketing, HR, everybody who is building their AI workflows to transform their own. Business functions and uh accelerate their agentic development and AI development workflows through the platforms that we built so it's an exciting mission it's uh it's an internal facing one and I'm also thrilled to tell you that uh uh it's uh this broader mission runs under our CIO Sonu Nayer who is here and our head of infrastructure Anu. Jay Devan is also here as well, so excited to talk more about these topics. Very cool, Dennis. What about you? Yeah, so I'm Dennis Henry. I see him pronouns. Uh, I'm just now, as 3 months ago, productivity architect. Um, historically I, I like to say I'm a recovering SRE, uh, because of. Worked in SRE and operations my entire career, but I had this kind of question and and conversation with, uh, our CEO and CEO about productivity at a more octa-wide level, um, so I wrote up, uh, a job description. I interviewed for that job, uh, and now I'm in the role and, and basically what it is. Is it's organizing productivity, um, and figuring out how to make everyone more productive at Octa. That's really my, my remit and obviously that has a lot nowadays to do with AI just due to the fact that it's a, a large part of everyone's job, um, if you're not using AI or LLMs in some way in your role. That might be a bit of an issue, um, so I have been working with a lot of, uh, leaders to really guide Octa's AI strategy within the organization. I'm a member of the AI governance team that evaluates AI usages, uh, and I'm leading an effort currently to democratize LLM usage across the company, so making it very easy for everyone to experiment with LLMs because the, the days of only engineers build things is long since passed. Everyone can build now, which is wonderful. You were showing me, uh, your, your kids' websites that they made on, uh, uh, on just that vibe coding kind of concept, uh, just last night. So it's something that I'm trying to really expose everyone to the, the possibilities that come from using LMs and AI. So yeah, I, you know, we discussed role blending, right? You know, and how all our roles are kind of almost shifting beneath us and how as SREs are recovering. Not or like developers or you know even product managers like it's like learning to use AI as part of our core. It's a part of our core craft now it's no longer optional, so I really love that. So switching over to AI operations in general, Rama, like what do you feel are the opportunities for AI in incident detection, diagnosis, resolution and avoidance, and what specifically are you doing at Nvidia that we can learn from? I would say the biggest opportunity with AI is to go from being reactive to predictive to eventually go to proactive ways of managing your IT operations and in doing so, of course, the ultimate vision is to build self-healing, self-monitoring, self-managing IT systems and let's look at you asked about incident detection. Diagnosis and all of that. Let's, let's go through this systematically, right? Uh, hopefully we have enough time to go through this a little bit in detail. Um, let's talk about incident detection. You have to be able to monitor everything that's happening in your environments at, uh, the entire full stack, right, from networking to infrastructure to the business applications that are running, whether they're running on-prem or cloud. Anomaly detection is a, is a, is a huge part of detection, incident detection. So, uh, generating alerts and detecting those anomalies, AI can play a huge role in that. And of course there is classic traditional ML AI that you can use to do anomaly detection, both from metrics, logs, traces, and all of that. Uh, but I'll also call out some of the, the opportunities with AI agents. Uh, now you can beyond doing anomaly detection and generating alerts, you can now start to think about what, why, why, and ask, provide the rationale and reasoning behind all of those things. Why is this alert getting generated? Is it because a particular threshold has exceeded? If so, um, what are the patterns that, that happened before and after. And provide all of that summary and context along with the alerts that are getting generated. So that would be one in I would say incident detection. Of course, once you have all of these alerts raised, then how do you reduce the noise with all of the alerts so that you don't inundate SREs with all of these alerts and they'll get buried with all these pager duty notices, right? So alert noise reduction is a is a big space where there is a lot of scope for AI. And also generative AI and agentic AI where you can now start to identify the patterns also in topology when you have the relationships between all of your devices and business applications where they're running and all of that, you can use that information to more effectively reason about and group these alerts to reduce noise and this alert alert storms if you will. Um, then in incident diagnosis, as SREs an incident happened, now you know this is an incident either level 1, level 2, level 3, whatever the priority is in doing better diagnosis, you need SREs need a lot of support on tools. What happened before? Have any changes happened in the environment? What, what actually caused it? Um, Again, being able to correlate all of these alerts and trends to generate those hypotheses on what might be the probable cause for a particular incident and being able to provide the context around it, there's a humongous opportunity. I mean, many of these things that I'm talking about are not new, but there are a lot of newer ways of doing things with AI agents now to provide the context to better correlate. And to also use all of the, the contextual and unstructured information that uh was uh not properly tapped into before. Now you can throw them all into a rag ritual augmented generation vector database and identify the patterns and do the correlations, right? So those are some opportunities in incident, uh, diagnosis, I would say. Now incident resolution is humongous opportunities, you know, we've had, we've been doing all of these run book optimizations and, and, uh, uh, scripts and all of that for a long time, emergency response procedures and such, but um. Now with the AI agents we can start to orchestrate these automations with instead of handcrafting these workflows we can now set up them as tools with MCP servers and or with agent to agent protocols and have the agents automatically figure out based on the hypothesis this is the root cause, probable root cause and. If I, I, if I have enough confidence, I, I, I can go ahead and automatically run this emergency response procedure, and here is the script automatically detect that and run it. And so those are some opportunities in, um, I would say incident, diagnosis and resolution. Then coming to avoidance again, huge opportunities we've all have been doing, and many of the tools, including pager duties, originals platforms, and others also have change risk management and change risk prediction. Changes tend to be the largest. Contributors of problems in enterprises for incidents, being able to predict the risk when somebody is deploying or putting those changes in is a huge opportunity. And so those prediction models, classical models exist, but also now you can go to the next level with AI agents by bringing all of the contextual information of prior incidents and do a much better job of providing support. So overall I would say shifting left, going to um. You know, the bowels of the engineering processes of development, deployment, and be able to predict and provide guidance to engineers on the the the problems that this could cause in in production is a huge opportunity. So I would say sum it up by saying shifting left and going from reactive to predictive to proactive to self-healing, self-managing IT systems are the biggest opportunities with AI in the entire incident management process. I love that and I think we were just discussing this like, you know, as an engineering leader. I almost am always. Like I love run books because they are so like, you know, disciplined, but run books almost get outdated immediately, right? Like the future, like future possibilities that we can think of is like us run books that always stay up to date because agents keep them up to date based on learnings, right? So that you can automatically generate those run books right based on the, the, the exact implementation and SRE has run on a particular incident and add it back to the knowledge base and let the go goes back into the, the rag vector database. Exciting times, uh, Dennis, moving over, you know, I think just a. Continuation of this conversation like we're seeing like incident management like you know as Rama described it's, it's evolved from like paging humans to orchestrating machines. So what's your bar for like closed loop in AI operation? like where do you feel what must be automated before a human gets involved? Yeah, so I, the way I look at all of this, especially when it comes to incident management and how LLMs and AI play into it, is, is just like LLMs have a, a context window, so do humans, and this is not a new idea. All have a context window of an amount of things that we can fit in our brain to be able to kind of diagnose or look at an issue and the way I've seen LLMs and AI most helpful in in incident management is being able to contextualize all of this massive amount of information that we get about uh an issue that's occurring and giving us some way of looking at it in a much more bite sized manner so taking all of the alerts that are fired, all of the the. Telemetry that has been gathered through various sources and giving a much cleaner way of looking at the incident has become really the key for me and for for most people that work in ops to be able to then look at it and be like OK I have the ability to fit what I've been given into my my context and then use my unique human brain to be able to then look into the new and novel concepts that that might be coming up because elements are great. Data at taking history and and looking at things over a very large amount of time and a very large amount of data and parsing through that, but the one thing they can't do, uh, until we get AGI, which please soon Rama, please work on that, um, is, is it cannot come up with solutions to new and novel problems. It just can't, um, so what we need to be able to do is give humans, the, the operators this knowledge in such a way that they can then go through that knowledge. Knowledge and kind of triage and use the the the abilities that they've been trained on and I I look at this all through I, I just finished my master's degree in human factors and what the way human factors looks at is how can the human cognition element kind of play into this massive amount of information that's being just absolutely shoved at people at the same time. How can, how can we get that into a bite size way that those humans can then use what they have which is. Amazing brain power to go through that that that element. yeah, I, you know, we also spoke earlier about this like we underestimate the importance of good communication during an incident and how some something as simple as like how we're communicating to our customers actually way more important than most other things we're doing but in a wartime scenario, pardon the reference, but in a moment when you're like so busy and like there's so much toil like AI can definitely help simplify your life there automatically creating stat. Status updates and catch me up summaries, things like that, yeah, the, the, uh, to go along that same kind of vibe that the, the fog of war, quote unquote, that, that kind of comes in when you're doing an incident and I've, I've been a part of a lot of major incidents over my time, uh, in my career, um, many 2 a.m., 4 a.m. where, where you're not really, you're, you're getting paged cold, you're waking up and you're just being like what, like what is even going on and having that ability for some. Some contextualized summary and something to kind of handle these nuances of the incident management so you can do what frankly you are most uniquely positioned to do which is to parse through and kind of use that that the ability that all of us have to triage is amazing and it it's one of the best uses in my opinion of of LLMs when it comes to incident management, yeah, like just like logging in and knowing that this incident may be related to these 4 other incidents that. Happened in the last two weeks or like you know you said talked about shifting left drama like if I'm in cloud code and you know I know I'm about to make a check in a service and it's like this service had 3 incidents in the last 2 weeks, do you need another set of eyes? Do you know what's happening? Just the importance of being able to meet people where they are in their own developer workflow, I think is really exciting and it would be even cooler if, if while the, the developer is there trying to put that, uh, particular merger request in. If a particular test case is missing, It's not only telling you that there are 3 incidents that happened, you may want to be more careful, but it automatically generates that test case and say runs it and shows the vulnerabilities in places where you need to fix the code and suggests that code changes automatically and helps you do the deployment test in a simulated environment. How cool would that be? And actually all those things are possible today. Uh, we just have to prompt it and build those agents, right? And building those agents is also. You know, you can do that with white coding as some of your 12 year old kids did as you were saying at dinner last night. Yeah, awesome. So you know, shifting to you, Rama, like, you know, in your role, how are you thinking of scaling AI for every SRE? Like, you know, Dennis talked about democratizing it. Like how, what, what's your process there? Yeah, and I also realized I didn't answer one of the questions you asked me earlier. What are you doing at NVDI? I'll answer them both now. Um, how, how do we scale it for SREs? So it SRAs, and I know I work with AU and team very closely who, who are in the middle of it on a daily basis. The teams are so busy doing, keeping the systems up and operational, right? They, they have a job to do. They, and they're so busy doing it that they don't have the time to step back and, and rethink the process or build some of these agents and, and, and help have those agents help them to reduce their toil, right? So having platforms, AI platforms that are self-serve with a lot of accelerators pre-built using which they know their problems better, they know their domain well, they know how to solve them, um, and what automations are possible, but they need all the tools to quickly build them, right? So having a platform team, engineering team that works with them closely to make it easy for them to self build those kinds of these automations and these workflows. Would be a great accelerator and enabler for SREs to, to, to scale. And one of the things that we are doing at Nvidia is exactly that, that is we are building this platform, uh, our internal AI factory. All the way from data centers on-prem or on cloud to the agentic AI platform that enables somebody to build the agentic workflows, deploy them, run them, operate them, secure them, govern them, monitor them. If all of these things are taken care of, the core foundational aspects of building an agent and an AI workflow is there now. You need accelerators. If I want a natural language interface, then I need a rag-based blueprint. If I want, um. To build, um, you know, a connector to my monitoring platform or to my logs, uh, streaming logs, I need these data connectors that are secure, or maybe I need MCP servers. So if the platform provides all of those things, the engineering team can quickly put together, bring all the data in, throw it into a rag vector database, and, and, uh, if you need be, you know, set some text to SQL pipelines and pull them all together with tools and build an agent. That takes their data and starts to now provide all of these insights right when an incident occurred, it's streamingly getting in a streaming fashion, getting the metrics, logs, traces, and it is generating its own hypothesis. It's doing its its own testing and evaluating these hypotheses, and it's providing these, these, um, you know, suggestions on what what might be the probable cause and all. Then SREs are really interacting and managing at that time with a bunch of AI agents right instead of. Pulling in when there is a problem, you know, 20 different people at 2 a.m. onto a car onto a bridge and, and, you know, actively, hey, do you have this information? Can you get me that information, this information? The agents are now pulling, doing all of that work, right? So there is a, a master SRE or somebody who's then really managing all these agents and getting the information they want to diagnose it. So we are building such a platform and we're building specific agents for our own infrastructure management for better alert noise reduction and um for incident summarization for root cause analysis and all of that. We, we, we, we have multiple names for it perceptor is. One intelligence is another one and so on different, um, chat agents and bots and um that are all built on this platform. That's very cool um over to you now like you know you talked about your masters in human factors. So when AI systems extend the blast radius into identity domains like how can we engineer automation, escalation and rollback processes that align with these human factor. Principles like keeping humans safely on the loop for complex high risk decisions, right? That's where we do our best work, but while also minimizing to Rama's point, cognitive overload and just coordination friction that just comes with the job of being an SRE or in operations. Yeah, so I, I, I look at the, the problem space as a, a very um. Very known problem like this is a lot of people like to look at the world of AI and LLMs like it's some sort of newfangled thing that we've never seen before, but it really isn't. It's just a new tool that is doing something that we all have needed to do before, which is learn how to communicate between multiple different things, um, and that all really starts with prompt engineering, which is something that, that I don't, I, I, a lot of companies focus on bringing the, the. AI tools to people but don't really focus on this concept of how to use them best um so we've been doing a lot of work um especially at Octa on how do we teach our SREs, our, our finance people, our GTM people, whatever it may be, how to actually talk with an LLM, how to, how to build that human and LLM partnership that really results in the best possible output because like you said, like just giving an LLM free rein to do whatever. We've all read news stories about how that has not gone perfectly in in many different uh areas, but what you can do is, is you can set up proper guard rails and controls where it can do read operations, not write operations, these types of things to therefore properly limit its capabilities and really teaching your people how to then communicate the goal properly to an LLM is something that, uh, again, making sure that people know, hey, maybe. Don't throw in a bunch of extra words when you're giving a prompt. You, you don't have to say please. I know you think that thank you are very expensive. It's going to save you and the, the robot apocalypse when, when, when Skynet takes over. It's not, but it's also potentially giving the LLM more room than it needs to have things like hallucinations and those types of problems if you just really kind of gear your communications properly to. Uh, communicate with a machine, not in the same way that you would communicate with another human, uh, because you can drop all the pleasantries and really just get to the natural language programming that we're all kind of in the position of doing that, which is what everyone is doing, so. How we, how we do that properly and build that, that human AI connection, that partnership is really how we can get to the point where we can have safe, secure, and automated operations across our organizations and companies that aren't prioritizing teaching their people how to work with the LLMs are missing the force through the trees in the essence that they are. Kind of leaving behind this really uh this really foundational concept and it's why like one of the things I've built at Octa is uh uh an AI gallery which allows for people to share prompts to share notebooks, to share, uh, Google Gemini Gems or chat GPT, uh, GPTs like to basically share out these ways that they have learned how to prompt and, and learn from each. Other how to how to better communicate within the organization. I love that that's where platforms play a significant role, right? So you can codify all your learnings uh and provide those repositories or registries of prompt templates of other agents or tools that are available that you can easily search, discover not only by humans but also by agents so that agents as. Get more mature and more progressive dynamically can detect some of those things and and build out new solutions. I think you know we also have very something very similar like we have like a repo where everyone shares their favorite prompts. We can all the way we've also made AI a core part of our developer workflows is like enablement, enablement, enablement. There's no such thing as too much enablement because when you think about it, we started with it's a part of our core craft. Like if you, if you go and you queried people who here has 5 years of machine learning experience outside of Rama, who has a lot of machine learning experience, I think the rest of us would say, oh, I went to school for 5 years for machine learning, and I'm now 1 year into my new job, so I have 5 years machine learning experience, right? It's almost, it's really a hard skill to find, so it's almost like a leveling. People are making it a core part of our craft. Like, sure, there's a great co-pilot out there or there's cloud code or cursor or whatever it is, but what does it mean in the context of my repo or like, you know, what does pay to duty mean in the context of my operations? I think that's where like we can add a lot of real value because you can enable people on your workflow, your operations workflow, your developer workflow. Goes a long way. So going back to again, you know, we talked about so many future looking things. What does the future for you, Rama, of SRE operations look like, you know, with AI as a core part of how we do work, you know, um, uh, our Nvidia CEO Jensen said this sign at one of the, the conferences said last year. IT departments are becoming increasingly the HR for AI agents. So it's, um, what is the future of SREs? What is the future of incident management? It, it's that everybody, it's not only in that particular space of incident management, uh, for everything. If I, if I, if a chip designer is designing a chip or if a software engineer is writing. Code if a marketing professional is writing a communication draft for everybody, there will be agents, AI agents, AI workflows at their disposal, and they're leveraging them in their work to reduce their toil, to improve their productivity. And they are really managing these AI agents and that's, that's how it is and hopefully with all of these things there we will get to our vision of self-healing, self-monitoring IT systems whether it is fully automated or not, uh, it, it's probably not as relevant as saying it really improves the productivity of people who are operating them, who people who are, who are doing their work, and if it provides 10x, 100x kind of productivity. Gains that's what we are looking for as practitioners, you know, pragmatically what we want is, is those kind of solutions in production that improves the productivity of people in those roles. Yeah, that's awesome. And you know, as we think of like what's the standard, I think Dennis, we can start with you, what standards should define the AI ops category in 2026? Like when you hear AI ops platform, what capabilities or what table stakes should we have? Yeah, and uh, uh, it's such an odd answer, but I'm gonna have to start with security because at the end of the day, like all of this, uh, moving in, in this direction of agentic workflows and AI is exciting, but we never can kind of like let go of the, the table space that that should be guiding us all, and that's the security of our systems, the security of our data. One of the biggest things that I'm consistently pushing for when I, I talk with vendors and such is. On prem is a great model for us just due to the fact that having everything served by uh an AWS did not pay me to say this AWS Bedrock uh is a wonderful kind of way for me to kind of center everything on infrastructure that I know and trust um and not having it go out to other places so I, I would say security is always gonna be that that table stakes thing is building out these agentic work flows in such a way that ensures that how it's communicating with other systems is secure. How it's communicating with other agents is secure. Uh, Octa just worked on, uh, launching cross app access, which is this concept of how these, these agentic workflows work across, uh, multiple sub agents to authenticate and authorize the, the actual like process of communication and making sure that what the person is doing they should be able to do or what the agent is trying to access something that the root person should be able to access and that kind of thing. So it all starts with this capability of ensuring that the process is done in a safe, secure manner and that again go back to the read only concept, preferably that we are not giving agents carte blanche to, you know, do right operations or more importantly destructive operations within our infrastructures and setting up these guard rails properly to ensure that we can go from where we are now, which is. The worst AI will ever be, um, and you can say that any day, uh, is this is the worst it will ever be to this, this Valhalla that where humans are really doing the things that humans are the only people that can do, which is think. Machines can't think in the way that we can think. Our brain is unique in that way, and it would be great if we would get to that point where, where humans are doing the things that truly make us unique. Individuals and and animals on this earth and getting to that is is where I wanna see us kind of uh move towards. I, I don't want AI just generating art. I want humans to be generating art because that's what we're kind of put on this earth to do uh is think and and create things and, and, and really have that beautiful interaction. Yeah, I wanna, yeah, I wanted to, uh, add a few things. So you're asking what are the table stakes for AI ops platforms, right? I would say first and foremost is you have to have pre-built connectors to all your core sources of data. Your logs, traces, metrics, alerts, and tickets, these are the core sources of data for analysis in AI AI operations management domain. So if you have connectors to those built ahead of time either with streaming, ingestion pipelines and servers, whatever with secure way, you are. Uh, you're set up now to start analyzing and programmatically leveraging that data for analysis. So that's #1. Number 2, I would say is, um. Uh, core features such as summarization, uh, root cause analysis, and the pipelines that are needed for processing both unstructured data and structured data, those should be foundational to the platforms because this domain has all three combinations. There is structured data that sits in various tables, unstructured data where people are conversing in a prior, you know, incident, and there's a lot of chat information. And a lot of useful information. There's knowledge articles this and that, and there, and there is semi-structured information in in ticket data, right? So you, you should have pipelines that can process all of these things and are able to generate insights from it. So those should also be foundational to AI ops platforms either it is in a rag pipeline or a text2 SQL pipeline or a semi-structured pipeline, pre-built them, all of them configured and connected to your data sources. That goes a long way. Then on top of it, you know, uh, all of the foundational classic machine learning, uh, techniques for, uh, anomaly detection for alert noise reduction, for, uh, ticket prior, uh, incident prioritization or alert prioritization. These models, they should be of course built into them and, and you build the agentic workflows on top of it. Then the platform should also allow you to have this ability to some blueprints that you can easily quickly build, uh, from which you can build off your agents. Say if you're building an agent for generating a situational report, um, you need a pipeline for that. And so this platform should have that, the ability to do that. Uh, which means you, you have configured, pre-built all of these pipelines of structured data, unstructured data, and the, the chat interfaces that go with them and, and everything that goes with it, the fine tuning, uh, of the various parameters and, and, and all of those. So these, these core foundational, of course, when, when new agents or these tools are built, how do you deploy them quickly? How do you run monitors? And monitoring for these, you know, to manage the incidents that come with the agents, exactly who watches the watchers, right? So you have, you have to have all of those. So these, so I, I would go back to this core foundational principles Building for a platform should have the ability to build, deploy, govern, monitor, connect, do the inferencing you have. To have a proper influencing mechanism to either use the external models or internal models, so having that, uh, streamlined way of connecting to all of the, the, the various LLM models and then of course monitoring, uh, and, and, uh, another important thing is having a registry so that everything that you're building is registered in there for human discovery as well as agent discovery. So all of these things put together. And last but not the least, the ability to have the, the human language interface to the platform itself, uh, to build it. These would be the core tenets of an AI AI platform, but also an AI ops platform. So in this world, in this environment, what operating model changes are not negotiable? We talked about all the things we have to do, but what are the things we cannot change, like, like SLOs for models, like how, how, how do we think about like. Yeah, so the. I think this is what I keep going back to when I because everyone kind of comes to me and says like, oh, like everything's just different now like like jobs are gonna go away and all this kind of stuff and I'm like. Let's, let's slow down a little bit and let's look at what the non-negotiables will always be and there always will need to be this concept of human in the loop at least until we get to AGI like sure AGI will will change the world, but it's a matter of having that that. Again, the human brain is unique and we need to be able to have people still be able to approve especially destructive tasks or even most right tasks just due to the fact that having uh an AI do that right now an LLM do that right now is just frankly. Too dangerous to to let go run amok and we we need to be thinking about that. We also need to be thinking about how much benefit and value are we getting from these systems. Uh, the, we used to have all of this concept of door metrics when we were when we were building out our, our DevOps teams 10 years ago, 20 years ago. That still applies. It, it's a little different nowadays, um, just due to the fact that we need to be looking at maybe some different metrics when we're analyzing things, but ensuring that we're, we're not just spending, uh, wantonly, uh, with our, with our tools and frankly the environmental impacts is something that, that is not really being talked about nearly enough, but door metrics or, or a form of that that analyzes how are we, uh, minimal. Normalizing our token usage to maximalize our output in such a way that we are, we are balancing the needs for, you know, Earth to be around for another 1000 years, but also to be able to get the benefits of these amazing tools that are available to us now, we still need to figure out and modify the approaches, but most of the, the tenets of, of operational excellence and analyzing. Speed to development and all these kind of things are still critical. They just have a different element to them as part of this, and resilience is really important, right? You have to be reliable and safe and secure, and those are non-negotiables. What you said it well, I, I think you captured it well, exactly that the core foundations of managing your operations effectively doesn't change. It's just the techniques and tools by means of which we try to optimize them for efficiency are advancing. That's all, yeah. Uh, we talked a lot about agents, and I wanna make sure we leave time for our audience as well, so we'll close out on a couple questions. Like, I'm curious, like, in this world of like, you talked about managing agents like new HR for, uh, you know, if you're a CIO you're probably new HR for your agents. I'm curious, like, maybe you can share a little bit with your audience, like how are your teams organized like for this AI first role I'd be curious to learn maybe Rama, we can start with you and then head over to Dennis and maybe what, how are you thinking of changing and evolving that, yeah. Yeah, I can tell you how, how we're structured, um, so at Nvidia IT, we, we have our, you know, infrastructure teams and, uh, uh, you know, uh, cloud management teams and all of that, uh, but we also have a centralized AI team which is the team that I lead where we are, we are building some of these core foundational platforms, right, so that everybody can build off of them and accelerate them. So, um, but in doing so until each. Of the functional areas organizations get to that level of maturity where they're fully able to leverage these platforms to build things on their own, there may be some handholding that's needed so where we work very closely with some of these teams to build out some of those agents or AI solutions or workflows to on top of the platforms that we're building to to test out the the pipelines and also to build solutions that are actually solving the problems and we did that in. In our own IT on the service management domain and also in the operations management domain. Uh, but we also broadly look at this as, um, you know, the, the, the function of, uh, an AI team that sits in IT has a bigger role these days with AI agents and, and exactly the reason why Jensen was saying that IT is the HR for AI agents, because these agents really need to be on boarded just like human employees do, wherein onboarding means you are bringing your enterprise context, your enterprise data, enterprise security, and all of that, and give them the context of the enterprise so that they can operate with it. And you need to then train them to make sure that they are able to operate within your security policies and use this data and are able to have the guardrails for your enterprise and all of that. Then just like humans have performance evaluations, these agents need to. Be evaluated for their accuracy, how well they are doing, are they meeting the business productivity goals? What is the usage like, and continuously capture that data and analyze to see what needs to be done to improve them, or at some point decide if they are not fulfilling their function, decommission them. And just like humans need feedback and and employees take that feedback from their superiors and improve, these agents need to, to look at all of that data and, and the agent workflow developers need to build those continuous learning loops to continuously improve them so that their accuracy is improving and they're not drifting from, from the original mission for which they are built for. And um uh and and build out all of these parts of the cycle just like you have a workday tool or whatever your favorite tool for managing your employees in the organization you need a registry where everybody can go look them up, what are their skills, what are they good at, and, and be able to find them and work with them automatically or to manually orchestrate them in other workflows and all. So, uh, the way we are organized, uh, going back to your question, there's a centralized AI team. That also apart from working within IT itself, we also work with all of the rest of the business functional areas within Nvidia. That's why we have AI at Nvidia. We have a working group of all of the functional leaders who are driving AI initiatives in in their own areas to share the best practices and to codify them. So our platform is actually an inner. Source platform. Everybody in the company who are leaders can contribute their their features and functions to it because everybody is building these workflows and are developing these insights on what the best practices and all and so physically and in a in a like human to human we communicate those best practices, but we also qualify them and and are trying to bring them into the platform. So hopefully when everybody builds the platform together it's something that everybody can use. So although there is a, there, there is a lot of, although there is some central team that is building the platform and such, the contributions come from everybody so that it, it becomes the platform that everybody can leverage, um, so hopefully, uh, but we're on a journey, you know, I mean, I, I won't, uh, uh, say that, you know, we have it all figured out and. It is, you know, we are, um, uh, in that journey. We are, uh, watching what's happening. We are building, we are deploying several things in production. We have many of these AI workflows in production today, but, uh, many in experimentation and, and still in early stages in development and, uh. Yeah, we're on that journey. Awesome. What about you, Dennis? Yeah, so we first of all, my wife is gonna be so excited about uh the HR comment because she has a master's in HR and she's always been like, well, where's all that going? Apparently she, she has a job now managing, uh, AI events, but, um, to the, to the question, I, I would say the way that we've kind of, uh, uh, structured things is we do have like a senator. Centralized governance and platform kind of organization which is where I am, but then we've we've done more of like a guild type set up where basically because of the fact that we really do believe that AI is part of everyone's job, um, everyone's everyone's an engineer now, everyone is a, uh, a builder of things that we, we've really kind of tried to open things up in such a way to say. It doesn't matter where you are in the organization if you wanna build things, if you wanna create new things, hey, join us, come, uh, and, and share your knowledge and share your experiences. That's why I built the, the AI gallery with OCTA is this concept of like, hey, the best prompt, guess what? It didn't come from an engineer, it came from some, some amazing guy in finance who was, who was struggling. Dealing with, uh, kind of creating a prompt to, to better work on his, uh, his own ability to grow himself, uh, we call them, uh, uh, octa reviews, but like the concept is he built a really great agent that, that helps him figure this out and he didn't have any programming experience, so it was making this concept of every. Everyone has this capability to to kind of be involved in the process, uh, like Rama was saying, making sure that everything's open like this is this is a place that we can all experiment so there are obviously teams that are a little more structured towards uh building AI and the product and that kind of thing but internally with internal productivity we. It's really in everyone's realm to work on, so we've, we've really tried to trying to guild guildify it, gildify it. I'm gonna make that a word now. That's, uh, that's incredible. We are very similar. We have a platform team, but the platform team's goal is to make sure everyone else knows how to do things themselves, right? And I think just how to build your own agent, enabling people again comes back to enablement, enablement, enablement, even with like I loved what you said. About the SRE, like, you know, even as I think of like SRE agent, you almost have to like onboard your SRE agent to your company. You have to give them like this is your 30 day goals, this is your 60 day goals, and hopefully 90 days later with all these patterns, this is how you're operating. So I, I, I'm gonna take that paradigm away. I think I learned a lot. OK, we maybe have like let's do like a few hot quick, quick answers on these like you said something about. New and novel earlier where we talked about new and novel incidents or new and novel disruptions and operations and but to humans new and novel is not new but to agents new and novel is new so can you expand a little bit on that? Yeah, the, the way I look at it is what we have written down and provided to agents is what has the knowledge to to pull from and that that's how it works and. And anything outside of that, if it wasn't documented or it wasn't kind of like put together and put into an organized fashion or even a disorganized fashion for the agent to be able to look into it is new and novel, but to us humans we have pattern recognition capabilities that are outside of the current capabilities of LLMs where we can see interconnections between incidents or between situations that. Frankly, elements just cannot see yet and so new and novel doesn't really exist to most humans because they will be able to find an interconnection to something else within their experience, whether it's even something they experienced within the current company they're at or maybe at a previous company or something they'll be able to pull from that wealth of knowledge that is only available to them because they are a human being. That the LLM won't be able to have, so those are the kind of things that really excite me about the future of the human AI kind of uh conversation because, uh, again I don't, I don't look at LLMs or AI as something that will replace people but more so be something that will augment us that will give us some capabilities that we did not have previously just another tool, um, not something that is just going to. Um, lead to, to, to mass, uh, uh, mass sadness with, with where people think AI is going. So Yeah, so a different question, um, for you, Rama, is like, does it make sense to train domain specific models for root cause analysis? Yeah, uh, as you're talking about actually humans' ability to. To take a whole new incident that has never happened before because you deployed a whole new brand application that LLM won't be able to help you with and to be able to uniquely reason uh with that human ability is, is interesting, but I'm, I also wanted to, before I answer that question, I also wanted to kind of observe that it's very interesting where we are today if you look at. The uh the ability of foundational models to predict the next token that was the and to generate human language was was so amazing but these days we can increasingly see that that that capability of predicting next token has gone into really being into the into a lot of creative domains as well so I. While I would like to believe, and I would think that that would be the case for the foreseeable future, probably where humans will uniquely be positioned to reason about newer things that they haven't seen. We're increasingly seeing the ability of these foundational models to even get into that, those creative spaces and, and surprise us from time to time. Of course, there will always be hallucinations, things that you have to watch out for, and so on. So coming back to your, uh, rein uh, whether, whether it makes sense to train, uh, models, the domain-specific models. Um, the answer I would say is um. Yes, but it depends. So because I wouldn't start with the training domain-specific models, say, let's say in IT operations, uh, domain on day one. I, I would start with all of the rest of the things like connecting to my data using the power of the foundational models to the best best extent possible to tune my pipelines correctly to get the right outputs and, and look at the outputs and where the, the mistakes are, the problems are, where the false positives are, and, and analyze them systematically and figure out if I need to improve my prompts or if I need to tune my retrieval better, you know, whatever the case may be. But when these systems are in production for some time, maybe, you know, uh, several months in production, there is enough data, trace log data and all of that, that there might be an opportunity then to, to uh, to, I would say, fine tune those models, not train from scratch, but use the power of the foundational models and do the fine tuning either with, uh, you know, parameter efficient tuning or with, uh, reinforcement learning and. Whatever the techniques, but generate some of these, you know, domain specific models and see how well they work, then there are, there are trade-offs associated with them. They might be good at if you're running out of your context length with a lot of data and you want the models to, the base models themselves to have the understanding of the vocabulary and the context of your enterprise and all of that, it might make sense. To train those foundational, those, uh, those, um, uh, models at some point, domain specific models, uh, and then, you know, use only the newer things that you have to feed to the context, context length, but I wouldn't start there on day one. Once you have enough data and you've tried everything else, then that might be a good, uh, you know, venue to go. The other time when you want to do that is when you have, um, you know, specific regulatory requirements where you have to run them on-prem. And cost is an important factor, and you don't want to use the, the, you know, the closed models that are very expensive for every call. So you may take smaller models and then you, you may fine tune them and, and you deploy them and they may work quite well, but you know those are trade-offs that you have to properly analyze and, and decide on the accuracy versus latency versus cost. Very cool. Uh, let's maybe open it up for audience questions. We have about 10 minutes left, so any questions from the audience? Yes, hi How are other business functions changing? For example, if I'm building a product, the product management function when I'm building for customers is very specific how we work backward from customer in his own way. So how is that evolving when you are building? Uh, these platforms when you are building areas in the platform. I think I'll repeat the question. So for the recording later you asked how are other job functions changing like product managers and if you're building back from the customer, how, uh, how is everyone's role evolving in these modern operations, right? OK, yeah, very, very much, pretty much every business function is can be reimagined and is already looking into, uh, way that it can be transformed. Let's take the product management examples that you talked about, right, uh, you know, generating. You get, you have to create roadmaps, uh, one of the functions of product managers, and, and how do you generate roadmaps? Typically, it's your market research, the, the feedback that you're getting from your customers, and the advancements, technical advancements that are happening in the industry. So you can have a deep research agent deployed that will go look at all of this data. What is the market saying about this particular domain, whatever you are building product for, what are the product feature function requirements that are coming from customers from Majira or whatever your source where you're asking your customers to ask those requests and other market information or internal information we've built internally. We have a deep researcher agent that takes connects to all of. These data sources and you know takes its time, maybe 78 minutes, 10 minutes or so and and generates you know what your next road map could be for example you could do that um you could also do the triaging of your you know your uh how do you prioritize your product requirements. You, you can throw in all of your Jira, uh, Zoom Jira or get whichever you're using into, into these, these tools again, whatever other contextual information you want and help you generate those, you know, triaging. Uh, you know, roadmap prioritization, uh, many of these things that you, you know, report generation or connecting to, you know, various functional areas, your bugs. What are, what, what are the bugs or the, the, what should I prioritize between bugs and feature requests, you know, the connecting to these, these bug management tools or your, um, you know, product, um, uh, feedback tools and, and all of that, and, and, uh, automating the, the, the analysis. That goes as input into your product roadmap creation. So those are just a few of the examples, but there are so many of these functional areas. Our chip design, for example, function and chip verification testing function has so many agents they are deployed and 300 plus agents are running. Our software development life cycle processes are completely functions are completely being reimagined with AI. Uh, being integrated into cursors, uh, as MC with MCP tools. So where, wherever engineers are doing it, writing code, they have, uh, access to all of these connectors, and they, they can get their work done there, uh, so that's in software engineering, product management, uh, program management, uh, you can pretty much AI think of AI workflows and AI agents to transform all of those function areas, our supply chain. Uh, planners use this to do, uh, what if scenario analysis of what if I, you know, what if there's a disruption in Hong Kong from my supply chain to my contract manufacturer? What would happen to my demand allocation? What should I do next? What are the alternatives here? You can ask in natural language, and the system will run what if scenarios behind the scenes. That's in supply chain. And, and so on you can imagine in every function area I think we talked about this yesterday. It's like what we, I call role blending, right? Like roles are like, uh, just the disappearing, the lines and boundaries between like I have David here who's my product partner. Hi David, uh, so PMs on David's team are fixing bugs and we're OK with that reveal. Like there's no such thing as too many hands when you have to fix bugs, but the demo. Critization of product development to everyone is really like it's an exciting time, right? It's also like I think it brings you closer to your customers in a lot of ways because if you're able to like you don't have to wait on the cycles it takes to be able to help your customer if you have all hands on deck and I think specifically in operations I think of like customer support liaisons right like bringing them. Up to speed quickly so they understand what's happening in the incident using AI to create like status page updates. It may seem like such a simple thing, but most of the time something so simple really is really hard, and I think using AI tools and agentic workflows you're able to take that toil away and make them more capable. Dennis, what do you have something to add there? Yeah, I think the. The thing that has really just really excited me a lot about about this whole revolution is this concept that people are bringing these really amazing ideas and then building them from all parts of the organization. And I'll give two quick examples. One was someone who was in, uh, um, kind of planning, and they were like, it's really hard to plan off-sites or on sites and getting all these people. So they came up with this idea of an agent that would go into Google Calendar, check people's availability, would then go into our travel, uh, system and check for flights and, and costs from all the various locations. It would then go into our office management system and see for conference rooms that are available and be able to kind of like commingle all of this data. Into a very simple like hey this week would be really good because these rooms are available in in the San Francisco office and all the people are available and flights are relatively cheap for this week and maybe if you do Tuesday to to Thursday it'll be optimal because they can fly in Monday and leave Friday like that kind of idea was just something that was born out of their head. I would never have thought of that because why would I know anything about that area? They came up with it all on their own and it was like one of those light bulb moments. For me that was like that's a great idea. I I wouldn't think of that because I don't really think of that as a problem to me because it's not a problem for me um but the the goal here being if we open things up people will come up with great solutions that that will change the way that we work and make our lives just a little bit better and that's the kind of thing that I, I love to see kind of being, being born out of these oh man this is a painful situation. I, I, I wish this was better to. I've made this better and it it's just revolutionized my job. It's awesome. I was sorry, I was just thinking on Rama's line of thinking that there is an AI agent that is a product manager. And in that case, are the product managers going to be specialized instead of. Back to date industrial product that's how, how we get an AI agent being product manager, how do you design that? Mhm. Very cool. We have maybe time for one more question, then we have to wrap up. Yes, please. Hi. In this next 12 months or 18 months, probably AIESRD agents will be the new normal. So how we'll handle a scenario where two AI agents of interdependent applications are not agreeing to each other by resolving a high visibility production incident? Ah. How we'll be having human will we be having the access to their chat, how they are reasoning with each other? That's, I think, critical. Like, how, how do we currently handle when two SREs disagree about a root cause? Like it's the same thing. They, they have to show their work and that's something that when I see someone developing an AI SRE or even any AI capability that is more black boxy than I prefer. I immediately walk away from the conversation just because of the fact that I need that show your work concept because that's how I would handle two humans bringing me competing theories. I'm gonna, I'm gonna expect the same from an AI to tell me and show me its data and say like, hey, I grabbed this graph from here and this RCA from here and this, this, uh, trace from here and because of these. Things I think it's X and the other one will do the same we'll say I found this, I found this, and maybe the answer is neither are right. The, the answer is somewhere in the middle like it almost always is, but that show your work mentality needs to continue as we move into this world of AI agents and all of this because without it we're just trusting which. I don't, I don't trust anything, um, and I, I, I'm a skeptical person, so from that point of view you have to continue to have that, that skepticism. Maybe you're not a recovering SRE after all, so I, I wanna be mindful of time. We're at 1.5 minute. I see the clock here, but I just wanna say thank you to Rama and Dennis for such a rich and candid conversation. On all things AI and the way we build and reimagine our operations, I want to congratulate Octa and Nvidia for being trailblazers. Like I learned so much today on how to operationalize AI at scale, and my key takeaway is AI is both an engine and also an environment for modern operations. And when we accelerate innovation, we are changing our failure modes every day and. The blast radius of things when things go wrong, right? So for developers, I think in the room it's our takeaway to codify. I think I learned that today, codify your operational wisdom whether it's in your repos, on your templates, on your libraries so you can make the platform better for everybody, uh, make reliability measurable, like show your work, show me your work, dear agent, like how are you interacting with others and you know incidents are not an if they're a when. And I think at the end of the day every incident is a learning opportunity. It's a, it's a learning opportunity to improve your human behavior, but at the same time it's also a learning opportunity to improve your models and your employee, uh, the base which is now filled with agents, right, and your run books and your workforce, digital workforce, like better get your digital workforce in line. But I think this is where, like, just what does pager duty do, like, you know, this is where. We can help like real time AI ops to cut noise to surface root cause analysis signal uh across like infra apps, AI, all the different layers of the stack we talked about. We have a lot of agents out like go check out our booth we're I think 11:34 is that our booth number? Maybe I got it right, but you can go learn more about all things, uh, pager duty there. But thank you everyone so much, really appreciate it. Thank you. Very nice summary. Thank you. Thank you.