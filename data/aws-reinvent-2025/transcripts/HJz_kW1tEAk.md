---
video_id: HJz_kW1tEAk
video_url: https://www.youtube.com/watch?v=HJz_kW1tEAk
is_generated: False
is_translatable: True
---

Good afternoon. My name is Steve Kendricks. With me today will be George. We are here to present a session today for you on building developer experiences with the model context protocol. So if you aren't familiar with MCPs, you're gonna get a great introduction as well as how to use MCPs in your daily work with our container services, Elastic container service and the Elastic Kubernetes service. We're gonna go through a few things, we're gonna go through, generally speaking, how Gen AI uh agents and LLMs have evolved and why we got to a point where MCPs are so useful. We'll give you an introduction to MCP just a little bit as a refresher for exactly what how we at Amazon tend to think about these things and particularly why container services benefit from using MCPs. And we'll talk in detail about the ECS and EKS MCP servers that we have released for your consumption today. OK, and then we'll have a demo talking about uh uh just demonstrating about what you can do today using these MCP servers both in the console um and through your IDE of choice such as Qiro. So let's talk about a little bit about MCP, the model context protocol. Let's talk about overall how we got here, and again this is gonna be a very fundamental introduction to LLM, but again I wanna cover some of the fundamental constraints so that you understand exactly why it is that we built what we did and how we went about building it. So let's talk about, let's imagine I am a grandmother trying to buy. Uh, children's gifts for my grandkids, right, that is my fundamental task, and I have heard all about these AI assistants which are supposed to help me with tasks like this, right? And so I have an AI assistant, I have an LLM, maybe I think those are exactly the same thing, um, right? I don't really necessarily know. All I know is that I can answer, ask questions, right? So here we go, we ask what is AWS or maybe I say, hey, what are some great kids guest ideas for Christmas? Right, and of course that that interface, whatever it is that I am using is going to come back to me and say, OK, here's the answer that I have for you, right, it's perfect, it is exactly what we need. Here's a limitation. Alright, let's get a little bit more specific. So I am, yeah, I'm a little bit more used to using these agents, I've used them for quite some time, so I want to go beyond just saying, what are some great gift ideas for kids, and I move on to what are the most popular gifts this year, or what is the must-have uh children's toy. To be used this year, my kids are super into Bluey, for example, or to other uh different toys. Different kids have different needs, so there's lots of different, maybe I wanna use the different STEM. I wanna have the best STEM toys for this year. And so of course the agent will come back and without anything in between it will say, well, I don't really have access to current data in a best case scenario and maybe it'll just say, well, I'm gonna give you an answer and maybe I don't know that that answer isn't fully correct. Of course there's other limitations when we try and make agents do specific skills. Of course if I want to actually do something with the agent, I want the agent to. Give me specific data not just about the world itself but maybe say go look at my Amazon purchase history and tell me what I bought. Of course the agent doesn't have access to that information. Or if I want the agent to do something like say specifically I want it to purchase something on my behalf, of course without anything intermediating the agent and allowing the agent to take that action. It's not going to be able to do that, right? And so of course here we have a message where somebody's tried to get fix a bug in the code and the LLM of course says I can't do that. LLMs of course, of course, you know, as we have played around, those of you who have played around with the LLMs to at least some degree are only as good as the as the specific context as we give them and they are allowed to access, OK. So let's summarize the limitation. We have two fundamental problems. We have an input problem and we have an output problem. LLMs do not understand and they don't know what they don't know because of course LLMs are trained on a point in time and they don't know anything that exists in the world outside of when they were trained. Now you could sit there providing that context in exquisite detail, and this is what many of us did when. Uh, the LLMs first became popular, we just said things like assume that the world is this way, right? Assume that the world in the last six months has done this, and then they would do a decent job, but that got tiring and often it would get it wrong or it would even say, well, I can't assume that because, you know, it's not in my training data or whatever. So then we came up with many different ways to try and address this workflow. So here is one, especially rag became popular shortly after uh LLMs became big. And rags were providing a way to give the agent context through knowledge bases. So instead of us just accessing the information directly from the model's training, what would happen is that AI assistant would take its prompt. So say for example, what was, what is the most popular STEM gift for kids this holiday season. Um, and it would then access that knowledge base first and inject that context into the prompt for the user on the user behalf, right, so we'd go look up the rag and it would go look up the knowledge base and it would pull that information into the prompt which would then be fed to the LLM, right, and then we would get a response. There are some limitations with this, of course, because the. The knowledge base has to be maintained by somebody. It has to be updated. It is only as good as the context that is provided into the knowledge base. And of course there are limitations about how much we can do. Prompt windows became very context windows became very, very large as prompts became larger and larger as the knowledge base information was injected. In many cases the entire thing was injected into the prompt for the user's behalf. So there's other ways, there's other ways to do dynamic uh retrieval and dynamic context, and this is where the introduction of things called tools came about, right, where the AI assistant can actually provide an action for you. The most common way to understand a tool would be. Something like web search, right, web search is an extremely powerful tool. So of course we go and we, we enter the prompt, right, then the prompt comes and the tool description goes to the LLM. So the LM says, OK, I know, know what I need to do, right? And there's a mechanism so for that. For that LLM to interact with the agent, call the tool in this case we're going to go search the internet for what the best STEM gifts are so that I can make my child happy, right? And then we get the tool result and the LLM consolidates that information and provides it back to the user. OK. There is, right, so we seem to have solved this problem, at least for simple use cases. The problem comes when we are dealing with more complex use cases, so, for example, if I'm an agent, right, and of course moving beyond just the. Christmas gift idea. Let's say that we have 3 different things that we need to have. We need the agent to be able to access a database. The agent has to access source code repositories so it knows if anything has changed. The agent maybe needs to be populating a CRM. This in the previous world that would mean that if I wanted to do that. Uh, if I wanted to achieve all these outcomes, I would have to create my own integrations, specifically teaching and training my agent to access these different systems. I would have to train and build some kind of mechanism and give it the correct APIs and give it the correct way to say this is how you use this tool, and it would be all very, very custom. And if I wanted to switch that out or share it with a colleague, we would have to, you know, work through all of these limitations. It wasn't repeatable, of course, so that is um. Just giving you a summary of some of the problems that we have for model tool interactions, right? This is an end to end problem, right? Every model of the tool connection required custom, uh, engineering, lack of standardized contact sharing. And stale knowledge over time because again the fundamental problem here being unless the agent was consistently calling and expending a bunch of tokens and knowing how and when to acquire new knowledge, very often it was still cut off from real-time data and of course the model is inherently restricted just by the nature of its development from new data sources. OK, so this is where the MCP came from, the model context protocol. It was introduced by Anthropic. Mono context Protocol is an open standard for integration between AI apps and agents that use tools and data sources, so APIs are especially, you know, if you think about it like. Uh, standardize how web back ends work. MCP is effectively a similar way to think about how, um, AI should be interacting with tools as well. So, so think about it this way. Uh, it's a, uh, you know, not necessarily 100% accurate, but it is useful as a way to think about how these tools interact. OK, so with MCP we can achieve standardized integration. I'll explain a little bit about what MCP is and how it achieves this, and then we'll explain about how our container services, um, have used these tools, um, to. Provide good results to you so of course with the we have different terminology when we start talking about MCPs we have the MCP host which hosts MCP clients if you think about an MCP client that is just simply the thing that the MCP server is running on. Um, especially if we're talking about a local MCP server installation, but we have the, a similar, we have an MCP server for our database, we have an MCP server for maybe Git, we have an MCP server for our CRM, and what that means is that the database host, the source code report, own, and then generally speaking, own and maintain that MCP. And the things on the left have a standard way to interact with external sources such that if we wanted to maybe replace our CRM system. We could do that easily without having to recalibrate everything on the left side. So that is effectively how MCVP operates again, here are the core components of an MCP server. We have the MCP client, which I explained what that is just the thing that is running the MCP is actually acting as usually it's your agent, right? Quiro would be acting as an MCP client. Uh, and then the MCP server. The MCP server would be, it has three components. It has tools, which is the most common thing that most people think about when they think of MTP servers. We have resources. And we have prompts, so I'll explain what each of these are, um, in just a 50,000 ft detail. So an MCP tool is what we call model controlled. The LLM is controlling the use of the tool through the MCP server. A tool is basically a function of how the model works. So if you think about back to my example of trying to purchase, right, having my agent purchase a or or just help me in my journey of purchasing a Christmas gift. One tool might be Christmas gift price lookup, right? Price look up for, price look up for different types of Christmas gifts or different types of uh toys or things like that, right? It might be web search, it might be something very specific, something very actionable, right? That's usually a tool. Other ways in your specific use case might be retrieving data, searching for a message, or maybe update a record. There's other types of things again, most people are very familiar with MCP tools. There are other types of things that MCP use or other types of categories that MCP use. MCP resources, they are application controlled. Your application, the thing that is actually trying to run, uh, you may be your service, maybe your web service, maybe your database that is controlled by the application. And what that is, is, you know, effectively things that used to be your knowledge base, so your files, your database records, right? My history and the context that is important to me when I have purchased things in the past, so maybe my purchase history might be an example of a resource. Prompts. Now prompts is a very interesting one because we usually think of prompts as the thing that we put into the agent, right? That's what we think of a prompt. In MCP it's effectively the same thing, but MCP prompt is a specific uh capability that allows the user to define. Their their MCP request and response. So think about it this way maybe if I own the MCP, I might say, here is a specific prompt which I know is going to provide very good resources. The user has the ability to discover those prompts within my MCP. And then and then use that prompt right and say OK great this is the prompt that the MCP has suggested that I use but of course I can modify that prompt. I can change it however I want. I can augment it and I can add things onto it. So those are the three different types of resources that MCP server. Has. Now, let's talk in detail. So I talked overall, right, that was a very rapid rush into how MCV, you know, the history of why model context protocol is needed and, you know, how we got to this point. Let's talk about the container services. So, um, generally speaking, um, if you are watching this, we assume general knowledge of our container service, the Elastic container Service, which is our AWS native, um, containerized, very simple container orchestrator, and the Kubernetes service, which is, um, our, uh, Kubernetes optimized container orchestrator, right, which we consider the best way to run Kubernetes in the cloud. Why did we launch MCP servers for an AWS service, right? If these things, especially things like ECS where we say it's very easy to use, what do we need an MCP server for? We believe that, as generally Amazon does, that AI is transforming how people work and build and ship and observe their code. Now, AI powered coding assistants are transforming developer productivity, and we believe that there is going to be effectively a new persona of user for our systems, right? The agents are not going to be generally very good at looking at our console, they weren't built for an agent to look at. They, they are good at using the CLI, but that doesn't mean that they optimally take advantage of everything that our APIs have to offer. They need an interface which is designed for them to extract the most out of our services, right? And AI tools lack real-time awareness. Let's imagine that, um, you know, a recent announcement that ECS launches ECS Express mode. We launched that two weeks ago. That is very unlikely to be in an LLM's core set of databases. Now we've set documentation up. We have documentation. These agents have the access to tool lookup, and so they can look up and they can use the, they can use web search and they can go say, OK, um, the user is telling me there's something called express mode, and so let me go look up and let's see what express mode is, and I can list all the resources that express mode has, and I can discover and it can funnel its way to a response. But there's two problems with that. Number 1, generally speaking, LLMs do good with a very robust set of information, and so it's going to stick to what it knows, especially using older features which maybe you all have spent time researching and writing and sharing about how. To use ECS and ETS together and so it it has a wealth of data in its training, uh, set, which means that it's going to trust that and it's going to be better equipped to use that even if it, even if it can see the new, uh, um, the new feature it may not know how to use it optimally right so that's that that is a that is a big problem that even the most sophisticated agents have. Right, and so there is, but there actually I should say there's also one other limitation which is the ability to know exactly the way that AWS intends to use things. You all through trial and error and maybe through some very sophisticated. Exit guidance we guide you into the experience of using our tools, but the agent doesn't really have that experience. They, it doesn't really have the ability to learn from trial and error in the same way that you do. And so we are need a way to teach it and say this is how you use it. So MCP has that opportunity to fix things, right? So because we are going to be able to give the agent updated up to the minute instead of using these APIs, use this set of APIs we just launched them instead of using this deployment mechanism, use this one. We can also provide guidance for the user. We can do things like improve troubleshooting and improve. Operations because we have a wealth of knowledge that would be very difficult for us to communicate to you, right? Nobody wants to read a 1000 page manual on how to respond to every single thing um that might ever go awry with one of the container orchestrators, right? Every single issue that you have, nobody has time to read that. The LLMs actually do a pretty good job of that if we give them the right mechanism to integrate with it and so that's the opportunity that MCP servers have. So we started off building these and we're going to explain how these work in detail. We started off shipping these locally, right? So there are two different kinds of ways to improve or to to to use MCP. You can just run these locally. And so, um, earlier this year we launched MCP servers for AWS containers and serverless, so ECS, EKS, Finch, um, and Lambda. Each MCP server has its own unique set of tools, and I will, we will describe more in detail about what all of these do, and they are available today to download if you so want from the GitHub repository, the AWS labs GitHub repository, right? You run these things locally on your local machine, um, and they're a great way to get up, started, and testing. Um, however, uh, there are some limitations with running machines locally once you start running them at scale, right? And so to answer those and to talk more in detail about how exactly ECS and EKS Github or excuse me, MC hosted MCP servers work, um, I'm gonna pass it off to, uh, George who is gonna explain in detail about, um, these. So George, take it away please. Right, thank you, Steve. So there are 3 main reasons or 4 main reasons why we launched the uh hosted MCP server. I'll get into the details in a bit, but one of the, the main features we have been, uh, the requests we have been getting is, especially the enterprises, they are not comfortable in getting their developers locally installing and running an MCP server. Their sec teams wanted to make sure that they had full visibility into what the users are doing. When there is a zero day vulnerability, they wanted full control of the ability to patch it. The other one was they wanted broader integration. So for example we have a lot of third party software as service providers or kind of building AI agents. These need the ability to interact with the EKS and ECS clusters, which again means that they need the ability to, they need an MCP server that's running and hosted in the cloud. And the last one here is that superior reliability and scalability that AWS has to offer. So 2 weeks ago we launched the fully managed remotely hosted MCP service for both Amazon EKS and Amazon ECS. They're available in preview. The rest of the presentation I'll dive a little bit deeper into each of these. What are the capabilities it offers? How do you get started with those? It it has also enabled a pretty cool feature in that you can now troubleshoot issues in the EKS and ECS consoles. We'll dive into that and finally we'll take a look at it, um, we'll look at it at, at a demo. I'll start with Amazon EKS MCP server. Before I dive into the details, I just want to give you a high level idea of what are you able to achieve once you have configured your AI assistant or your AI tool with the MCP server. Essentially you're able to use natural language to interact and manage your resources. For example, you can just type in in your, in your AI assistant. Let's say you're using Quiro, which is an AI coding ID from AWS and you can just type in show me the status of my production EKS cluster. And it's not just limited to EKS resources. You're also able to manage and interact with Cuban's resources, so pots, name spaces, so you could do things like show me all the pots that are not in a running state. Just type in natural language. You don't need the cue cuddle, which is the official Cuban CLI. You don't need to set up cube config. Just type it and you get the response. And we have also enabled the MCP server with tools that's going to help help with troubleshooting. For example, let's say you have a pod stuck in a failed state. Now just type that in. Why is my engine X ingress controller pod failing. And the last thing I want to call out is that these tools are not just read only tools, these also enable you to create resources. Let's take a look at, take a look at the request flow. This applies, this applies to both Amazon EKS and ECS. So these hopefully hosted in the cloud, they are available in all commercial regions. So this is available in preview in all regions except regions in China and GovCloud. And you can pick the region that you prefer depending on where your resources are. And let's say you have configured the MCP client. The MCP client here is an AI system, right? It could be keyro cursor client. It could be any MCP compatible tool. And once you have set that up, and I'll, and later on in the presentation I'll show you how you can configure that. Once you set that up, the way the request reaches out or gets to the hosted MCP server, the hosted EKS or ECS, these are two separate MCP servers. They have separate endpoints that are available in, in all the commercial regions. The way it gets to it is through a proxy in between. Now the question is, why, why do we, why do we, why do we need a proxy? Now, both EKS and ECS MCP server are AWS services, and the way you authenticate to AWS services through IAM. And the way IAM does authentication is through a mechanism called SIGV4 signing. For that SIGV4 signing, MCP protocol today doesn't support SIGV4 natively. So you need this intermediary which is now signing the request and then making a request, uh, to the hosted MCP. Once the request lands in the hosted MCP server, depending on the tool you're using, the appropriate um downstream AWS service is invoked. I want to give you a concrete example now. I know it's a little bit hard to read. Uh, in the demo I have kind of zoomed out, zoomed in, so you'll be able to see this better, but here I have Kiro, which is the AWS, um, AI powered coding assistant. Once you have configured the MCP server on the left, you know, this is just one time step you do all the tools listed out. So in the case of EKS, uh, which is a screenshot here, there are 2 tools. They're all available to you as a user like Steve mentioned earlier, you are not directly interacting with the tools. These tools are for LLMs, but it's, it's always good to know about them. Once you have configured, you've done the one-time step, you can just type in natural language in the chat window, hey, why did, in this case it's asking, show me the status of a particular EKS cluster. The MCP client or the LLM knows about the tool called um here describe EKS resource, which would then kind of return the response. Just, just wanted to kind of give you a high-level view of what you're able to achieve with uh with the MCP server. Now let's get into the details. The capabilities of uh MCP server can be kind of defined in terms of the tools we support. Now, and you can classify the tools we have in, in the case of EKS, um, there are 4 main categories. The first one is cluster management. These are tools that help with managing your EKS resource like creating clusters, creating add-ons, deleting them. These tools can, some of these are read-only tools, meaning that for example, the second one here is just doing a list operation, just listing all the EKS resources. There are tools like the first one, manage EKS stack, which is actually creating a cluster. You as a user don't really need to, you're not interacting with it, but it's always good to know. If you want to know more about it, our user guide covers the parameters it takes, which of those are um required as as such. The next set of tools we have are for the Cubanities resource management. So previously we were talking about EKS resources. Now we like Cubinities resources like pods, services, you can create them, delete them. There are tools for applying YALs. There are tools for generating manifests. The third set of tools are documentation and troubleshooting. I want to spend a little bit more time here. So Steve earlier mentioned like every, the, the, uh, let me take a step back. So initially when we launched the open source or the the version of MCP server, we did not, we did not have search EKS documentation. And what we found out during the development was the, the, the knowledge gap that Steve was mentioning. Any LLM version, if you go to the particular version, if you look at the documentation, they say there's a knowledge cutoff date. Basically that is the date on which that LLM was trained on. So if there is a feature that came out after the knowledge cutoff date, you know, it's not really trained on it might, it might be able to use tools and still get information, but it's not really trained on that. And we are finding gaps and we were trying to troubleshoot newer EKS features. We found that the LLMs were not really really doing a good job. Hence we build this tool. What this tool does is that in the back end it is connected to, um, uh, um, it is connected to an index of all AWS documentation. So all AWS documentation, all AWS what's new posts, all AWS blog posts are kind of indexed there, and this tool is able to kind of reach out to the index and retrieve the information. So now you're augmenting the LLM with some of the missing information through this tool. So that's the first tool. And second one is uh EKS troubleshooting guide. So this is actually a knowledge base we are hosting in the cloud. What this knowledge base is pretty much a distillation of all the knowledge we have gained managing millions of Cubans clusters. So over the years we have been managing a lot of Cubans clusters. There are a lot of run books we have internally, and some of these are, I mean these are all run books that are externally like can be shared and are, are useful. Now all these run books have been, um, added to this knowledge base, and this particular tool is actually reaching out to the knowledge base. So that you are now augmenting LLM with various run books that it can use for troubleshooting. This set of tools is related to troubleshooting. If you usually look at any troubleshooting runbook, one of the first two steps is to get more telemetry, right, getting more metrics, getting more events, getting more logs. So these tools are kind of providing those those needed telemetry back into LLM so that it can effectively troubleshoot an issue. And then we have a couple of tools for security. This was kind of introduced because we noticed a lot of the times the issues are related to IM permissions or the lack of it. So this tool kind of helps with that. All right, so now we looked at the capabilities. Let's take a look at some of the prerequisite, right? So like I said before, EKS and ECS, and we'll dive into ECS a little bit later. EKS MCP server, it's, um, it's protected by SIGV4. It's protected by IAIMs, there are certain permissions that you need to set up. The two key permissions are EKS invoke MCP. This is what allows the, so let me, so the IA entity, whether it's an IAM user or IM role that you're using to connect to the hosted MCP server endpoint, needs to have invoke MCP permission. That is what is allowing the MCP client to do a list call to understand about all the tools that are available. Then we have another uh uh permission called call read only tools, and this is kind of giving granting access to the read only tools. So if you recall before I said that some of the tools are only doing read-only actions like getting a or listing a resource, but then there are a bunch of tools that are actually mutating like creating in a cluster or creating a pod. So this tool, uh, this permission is ensuring that only read only tools have, uh, permissions, and the last one is called privileged tools. If you wanna, if you wanna allow all tools to be able to connect your. Uh, MCP server, then you also need to have a call privilege tool. So one thing I want to really call out and I want to emphasize is that especially in production start just with the read only tools, you know, LLMs have their own intelligence, right? Most of the time they do a good job. Sometimes they can hallucinate. I've been in scenarios where it inadvertently goes and deletes resources and which, which I didn't want them to do. So definitely start with just invoke MCP and call read only, at least in production, you know, you can use call privilege tool in your dev environment or test environment, but, but I would say start with the first two. So those are the 3 permissions that are required to connect to the MCP server, but once you connect to the MCP server, there are a bunch of tools. So if you recall, there were tools to reach out to Cloud Wash to get logs. So you need additional permissions that you need to configure on your IAM identity. Now we have a managed policy called EKSMCP rerollee Access. So if you go into your IM console, search for policies, just type that word, you can see the full like this pre-can policy available to you. It has the full list of permissions that all the read-only tools need. For right tools, we don't, we don't have a pre-can policy today, but it's kind of, uh, it's listed in the the user, the EKS user guide if you want to learn more about the permissions. All right, so, so we looked at what are all the permissions you need to configure on the IAM principle that is that you're using to connect to the MCP server endpoint. Now, let's talk about the proxy. I kind of covered it a little bit earlier. Proxy is what that is kind of the intermediary between the MCP client and MCP server which is doing the SIGV4 signing on your behalf or the on behalf of the request. The proxy is available in that GitHub repo if you want to take a look at it. Uh, the proxy is also available in the Python package index, so it's very simple to install. You can use, you can use UVX to install it. The good thing is that you need this, so this proxy is required to connect with any AWS first party hosted MCP server, not just EKS and ECS. There are many other MCP servers remotely hosted that are coming out, so you need to run this proxy, but you just need to run it one time, and then you can have different blocks to connect to the different, uh, AWS hosted MCP servers that you that you're interested in. What are some of the other configurations? Um, the, the first one is profile. So the MCV proxy is doing SIGV4 signing, and to do the signing it needs credentials, and it picks up the credentials from the profile you specify here. This is the, I'm referring to the AWS profile. So depending on which profile you specify, it uses those credentials to sign the request to connect to the uh remote, the hosted MCP server. Couple of other interesting things you should, you should be aware of is the regional endpoint. So like I mentioned, the remotely hosted MCP server is available in all commercial regions. In this case, I'm connecting to our Oregon region, so you would use US-West 2. And the servers here is EKSMCP. This is an important call out. Like I said, there are two ways in which you can ensure that the LLM doesn't take actions that you don't want it to do, especially mutating kind of actions. So one is I aim, like I said, in I, when you create the IAM permissions, make sure you don't have the call privilege tool. The second one is if you specify a read-only argument here, the MCP client gets access to only the read-only tools and not all the tools. Now, so I was talking so far about EKS. Now let's jump to ECS. A lot of what I said also applies to ECS, but let's take a deeper look. ECS again enables you ECS MCP server enables you to use natural language to manage ECS resources. These are just examples. I'm just, I mean, there's much broader than that, but just to give you an idea, you can do deployment monitoring. You're able to investigate the health of containers or tasks. You're able to troubleshoot issues and you're also able to look at things like network configurations. ECS classifies the tools into three kind of broad buckets. The first one is operational tools. There are a bunch of tools that help you with doing things like getting the status of your deployments or fetching network configurations. These are kind of very critical when you're trying to troubleshoot issues. You have tools for resource management. There are tools for tasks like getting more details about task definitions. You also have tools for troubleshooting. I think ECS has done a really good job at really pinpointing on what are the biggest pain points that customers have, and they've come up with, and they have come up with tools that are helping with troubleshooting some of the some of the most common common issues that I've seen. In terms of permissions, there's a key difference between EKS MCP server and ECS. All of ECS MCP servers are read-only tools, so you don't see the third call privilege tool kind of permission. But these are the two key permissions you need to configure on your IA principle that you're using to connect to the ECS MCP server endpoint. Uh, there are, if you recall, some of the, uh, tools like fetch network configuration is actually making calls to EC2 APIs. A bunch of the tools are called ECS APIs, so there are, there are additional permissions that you need to configure on your IM entity. You can learn more about it in the user guide if you, if you're interested in seeing what those are. Same thing like EKS, you need to run the MCP proxy. Uh, you don't need to run it multiple times. You can just have an additional block. If you, let's say you have a scenario where you need to connect with both EKS and ECS MCP server, you can just have an, have an additional block that is now pointing to ECS instead. The key difference between EKS and ECS, if you look at the endpoint here, it starts with ECS. So this ECS is similar to EKS as a regional endpoint. So you connect, point to the appropriate ECS regional endpoint. The service here would be ECSMCP, and the profile is where it picks up the credentials to do the SGV4 signing. All right, so now switching gears a little bit, one of the cool things that we have been able to do with the MCP server is really improve the troubleshooting experience in console, both EKS and ECS. In the demo, I'll kind of give you a, you'll get a better understanding, but just to kind of quickly walk, walk over it. Anytime or a lot of places where we surface up from an issue, an error in the EKS or ECS AWS management console, now you can see in context the inspect with Amazon Que button. So what we have done is we have integrated with Amazon Q and the MCP server tools to quickly help you triage your root cause issues and also give you recommendations of how you can go and resolve it. Just to give you an idea, I don't know how much of this is visible, but just at a high level, these are some of the various points in the EKS console where you have this inspect with Amazon Q integration. So for example, if you go to the observatory dashboard. There are various kinds of health issues for the cluster health issues we surface up now you would see there's an inspect with Amazon. So if you click on it, you have an Amazon Que chat panel open up where you can go and triage and resolve the issue. Similarly, you, you, you have other points like upgrade insights or control plane monitoring and node health issues where, where this integration is available. In the ECS console, similarly, there are multiple points in the ECS console where you are able to leverage its integration. In the for example here I'm showing the deployment. So this deployment is rollback. So you have when you click on that status saying rollback successful, if you click on it, you have an inspect with Amazon queue button that you can integrate and learn more about what was the reason and how you can go mitigate it. Uh, similarly for task failures, you can click on the status and you have that integration available. So before we talked about, we saw how your, how the, the request flow to connect to the hosted MCP server. Now with this Q integration, you also have another flow from the console you are able to kind of troubleshoot various issues, an AI powered experience for troubleshooting, which is in the back end using the various tools provided by EKS and ECS MCP server. All right, with that, let me move it, move to the demo. So this is a recording I took a couple of days ago with LLMs and Hallucinations. I want to make sure, you know, we have something decent show here. So it's a recording, but it's, it's real. I'm gonna start with two, I have two main sections in the demo. The first one is the hosted MCP server, and for that I'm gonna use EKS, but ECS is gonna be very similar in terms of the capabilities and what you can do. And the second part of the demo, I'm gonna show you the troubleshooting experience in console, and for that I'm gonna be using Amazon ECS. So we'll start with the prerequisites. If you, if you remember, I said there are two things you have to do. The first one is you need to configure your IAM entity with the right permission so that you can connect to the remotely hosted MCP endpoint. So we'll take a look at that first. And the second one is configuring your MCP client. So here I'm using key row, which is the AWS AI powered ID. You need to configure it one time so that the MCP key row can connect to the MCP server. So those are the two prerequisites. Let's take a look at that first. Alright, so I'm in the IA console. Uh, let's go to the policy. So I mentioned earlier there is a pre-can manage policy called Amazon EKS MCP read-only access. So if you click on JSON, you can see the full set of permissions that are required by all the tools. So these are all the read-only permissions that are required. And at the bottom you can see the two key permissions I mentioned that are required to connect to the EKS MCP server, the hosted endpoints, so invoke MCP and call read only tool. And above that you can see all the other permissions. So these tools are making a bunch of calls to, like, for some of the tools are making calls to EC too. Some of them are calling to Cloudwatch. Some are calling to the STS. So you can see the full set of permissions that the tools are tools need. They're all listed out here. Now, for the demo today, I'm gonna be using, I'm gonna be using both read and write tools, so let me go ahead and create a new policy. So we'll, we'll, I'm, I'm using the console here, so you can create a policy. Um, you can, you can click on Jason. Where you can, you now have the ability to fill in the policy. Now, it doesn't have anything. So I'm gonna switch to the user guide, the EKS user guide under tools MCP protocol. Um, this particular page on step 3, you can, the full set of permissions that you need for both read and write is listed out here. So, so just, just for reference, these are all the permissions the tools need. So you can copy that into the, the, uh you can use that to create your IA policy. And like I mentioned before, you can see some of the 3, the key 3 permissions that are required for EKSMCP at the bottom. All right. So now, let's go ahead and click next. I'm gonna name it EKS dash MCP Server. MCP server right MCP server right policy. You can verify all the permissions look good and you can hit create create policy. So now you have created the policy. Now we need to attach this policy to an IAM principle for the sake of simplicity of this demo. I'm just gonna create an IAM user. So I'm gonna create a new IM user. And our goal is to now attach the previously created policy to this user, so I'm going to call it EKSMCP server user. Now we need to locate the policy that we created in the previous step to search for. MCP and you see it at the bottom select it. And click next. If everything looks good, you can create it. So now we have the user created. Now we need to create an access key secret key for this particular user so we can go into the particular user, go to security credentials tab, and you can create um access key secret key for this particular user. And what you're doing is once you have created these credentials you're copying it over to your local machine, the machine where you have the MCP client set up. So in my case I'm using a MacBook, so I'm the access key key to my, uh, local machine and I'm gonna be, um, setting that as the AWS profile. So here I'm using Kiro ID. So we are done with the first step of the prerequisite of creating the IIM permission. So we have done that. The next step, the next one-time step you have to do is now configure your. AI coding assistant to connect to the MCP server. Here I'm using the AI coding assistant or MCP client that I'm using is Kiro. So if you go to Kiro, you can see that I, I do not have any MCP servers configured right now. So you can click open MCP server config. As you can see, there are no MCP servers. If you go to the EKS user guide, we have instructions for Mac and Windows. Since I'm on MacBook, I'm gonna copy the Mac section here, and all these applies to ECS as well. I'm just showing in the interest of time I'm just showing it for EKS today. So you copy it over, you can see the proxy. I'm gonna connect to the Oregon region, so I'm gonna update the region to be US West-2 since that's, that's the Oregon region endpoint. And my profile, if you recall, the, even though I did not show it in the demo, I had, I have a profile called demo-profile that has the access key and secret key that was created profile previously. So I'm updating to use that profile. And update the region to US West 2. Now when I hit save, notice on the left side you can see the MCP. The keyro is trying to connect to the remotely hosted MCP server. It takes a few seconds. It's using the, it's uh doing a CV for signing and it's connecting to it, making sure I have the appropriate permissions. And once it does that, you can see that it has found 20 tools. There are 20 EKS MCP server tools. All of them are listed here. As a user, you would not be directly calling them, but it's good to know you can hover over them and you can see detailed description, uh, but these are also available in the EKS user guide if you want to learn more about these. All right, now we have done both the, both the steps, right? We created the IAM permissions step one. Now we have configured my MCP client which is keyrow to connect with the MCP server. Now let's start using it. So I'm gonna try, let's start with something simple, right? Let's start with, um, like show me the status of my clusters. So I'm gonna open the chat window in Quiro. And then I'm gonna just type in the prompt. Show me all EKS clusters and their status. So I have 4 EKS clusters in my, in my environment. So Kiiro automatically detects that there is an MCP server based on the tool description. It, it figures out that there is a tool called List EKS Resources which looks like the right tool to get more details about the clusters, and actually it's also listed on the left side. If you see there's List EKS Resources, one of the tools there. And then, Uh, I've set up Quiro in a way that I'm not auto approving. You have the option to say auto approve all tool calls, especially when you're getting started. It's good to individually approve and make sure it is calling tools that, that you understand and the tools that you wanted to invoke. So I, I approve this request. So it's calling a few other tools. So it found out there are 4 clusters. It's doing a described tool, a described call for each of these, and in the end what it returns is. It gives me a status about the 4 EKS clusters. It gives information about the status of status of each of the one of each one of them, the version, when it was created, the region, all that information. So it was so easy. I, I didn't even have to set up Cube cuddle. I didn't set up AWS CLI. Only thing I needed was the AWS profile, the IAM permissions, and the MCP server configuration I showed you. With that and just a natural language, you are able to now interact and manage your EKS cluster. So this is a very simple case. Let's try another one. The next one is What I want to show is I'm going into one of those clusters which is Uh, the second one here, EKS ECR cluster. Now that is on Cubanis version 131. If you have worked with Cubans, you know version upgrades it's not a, it's a little bit of a scary thing. Cuban doesn't support rollback of versions. So before you decide to upgrade to a version, you want to make sure things all look good, that things doesn't break. So what I'm gonna do is that particular version 131 is not the latest. We are right. The latest version is 134. So I'm trying to migrate from 131 to 132. But before that, I just want to see, hey, I, am I ready? Am I good to go ahead and hit the upgrade button? So my prompt, if you read the prompt at the bottom, it's saying assess my EKS ECR test cluster, it's upgrade readiness, including support status, upgrade timelines, and any identify any blocking issues. That's all what I entered and I hit enter. Now Quiro now figures out that there are tools within the 20 tools that MCP server support which helps with with the scenario. There are tools like insights which gives like information about the upgrade readiness. So Quiro is actually thinking through it. It's actually making a bunch of calls. So it found something. It's doing a list EK, so it was trying to learn more about the resources it found. Let's just give it a few seconds here for it to complete its information gathering. And finally, it generates a a report here, right? I'll kind of scroll back up, I'll just finish it complete uh let it finish. So what it really, so it's, it's giving me this report, right? It's, it identified one blocking issue. It's saying that one of the add-ons that I have running on my cluster called AWS guard duty agent is on a version that's incompatible with the version I'm trying to upgrade to. So it's kind of flagging that for me, saying, hey, you have to go fix that. If you don't fix it and you upgrade it, your cluster is gonna be in a broken state. And then after that it kind of has a bunch of checks that that all looks good. It has um a few other checks which queue proxies cu cluster health issues, all that all that succeeded and that finally it's giving me a recommendation of the steps I have to do before I hit the upgrade button. All right, so let's do another, um, one here which is creating a new cluster. I don't know how many of you have created a cluster either using AWSCLR or EKS Cuddle. Cuba EKS cluster creation involves a few steps, right? There are a bunch of prerequisites you have to create. You have to create VPC. You have to create subnets, and then after creating them, you have to pass those to create cluster calls. There's a lot of work you need to do today to create cluster. But here you can see that with just a simple text line. I'm just saying create a new EKS cluster and that's it, and it figures out all the dependencies. It uses cloud formation behind the scenes to create the cluster. Now you might not create production clusters using this, but this is like if you have an idea you want to quickly try out, you want to quickly create a cluster, this is a great way to get started here. And even though this particular tool is using cloud formation behind the scenes, you can use other tools. Let's say if you want to use Terraform, you can always, as long as you're prompting in the prompters, create a new EKS cluster with Terraform, elements usually respect what you have specified. But if you don't specify anything, by default, it uses a tool which uses cloud formation at the back end. So there's a tool called manage EKS stacks. You can actually go to cloud formation. You can see that that particular template that's being used here. Uh, and so it, it creates a template and then it goes ahead and starts deploying the template. Now creating a cluster still takes around 15 to 20 minutes, so it's gonna take a while, but at least it gives you a, so here you can see that it started that process of creating the cluster and all the, the configurations associated with the cluster. All right, so I'm not gonna wait for that. Let's move to the next and the last scenario here. This is a troubleshooting scenario. So here I have a cluster called MCP demo cluster which has a load balancer which is kind of in a broken state. This load balancer service, it's a service object in Cubinities. It is in a pending state. It's not able to get external IPs. So I'm just typing in natural language. I'm asking it, hey, my load balancer is in in the default name space on my cluster MCP demo cluster is stuck in pending state. It's not getting an external IP. Can we help troubleshoot? This is where some of the troubleshooting runbooks and the troubleshooting tools I was mentioning to you previously are being used now. So let's see what Quiro does here. So Kiro calls the EKS troubleshooting guide. So Kiro is actually, it knows that there is a tool which is called Troubshooting guide. It process this error message as part as part of a query parameter to that particular tool, and it's trying to see is there a run book, um, that's gonna help me with with that issue. It kind of go through that cycle a couple of times, then it finds out that there is an issue with the service object, so it's making another call. Read Cubans resource to learn more about a service object. Then he tries to get the events associated with the service because obviously there's a failure. It's trying to understand. So it's kind of doing its own information gathering here, calling multiple tools. It's looking at the run book, it's following through the steps that that are defined in the run book and trying to figure out the root cause. Let's give it a couple more seconds here. OK. So, it, it figured out the root cause here and it's also giving steps to fix. I, I'll, I'll scroll back up to kind of um give you a second to read that, but So the main issue it found out was that one of the subnets that are associated with that particular load balancer did not have the appropriate cubin tags associated with it. So it's saying those tags are missing and it's also giving us steps to go ahead and how to, how you can go fix and resolve the issue. All right, so that was the last demo from the hosted MCP servers. I was just using EKS like I said, all of these capabilities are similar capabilities are available on ECS as well. You'll be following the same steps in terms of setting up, including IAM permission setup, the MCP configuration. Now I'm gonna switch gears and let's take a look at the troubleshooting experience we have enabled in the AWS console. For this, I'm gonna be focusing on the ECS scenarios and how uh we, we are kind of enabling troubleshooting there. So here you have a particular cluster which has stuck in delete and progress state. This particular task, task definition is clus is stuck. And if you've noticed before, um, there was an inspect with Amazon queue button. Let me see if I can just go back a little bit to show that. So this is a new interact that this this this button is something new that we introduced. So now when you click on the status message, you can have this inspect with Amazon Que, and that is the integration we have done with Amazon Que developer in the console. When you click on it, it automatically opens up the Q chat panel on the right side. And it's pre-populated with a prompt having context about the issue and everything that Amazon Que developer needs to go resolve and go figure out and troubleshoot the issue. So here you can say Amazon Que is now. Um, kind of calling Amazon Q has its own sets of tools that it, it uses behind the scenes, including the tools that are available from EKS and ECS MCP server, and it kind of lists out the root cause. The root cause here was that the tool is being used by, uh, running ECS services, and it not only points to the root cause, but it also gives you uh steps of how you can go recommended. One of the good things is that we, it is not automatically mitigating it, it's giving you the flexibility so that you can read through it if you think it's the right way to solve it, you have the, you can go and take the mitigation. All right, so, yeah, those are, those, that is the rest of the report here. So moving on to the um. Next, uh, scenario, so here you have a task that is stuck in a, in a stop state and the failure is that it's not able to pull a container image again like I mentioned, if you click on the stop status message, you now have this new enhancement where we have the inspect with Amazon queue. So now if you click on it, it automatically opens up on the right side the Amazon Que chat panel. And it has a prompt prepopulated with the context so that Amazon Qe developer can now go and troubleshoot the issue. So Amazon Q developer is now kind of calling various tools, including some of the ECS tools. It's trying to learn more about the task definition. It's, it's trying to get the task health data. It's Amazon Q developer also has a knowledge base. It's retrieving knowledge, and here you can see in between actually the calls failed, so it automatically retries. So trying to find the described the service status, it failed a couple of times, but the third try it succeeded. And finally it was able to get to the root cause. The root, uh, so the root cause was related to, I believe, uh, network configuration here. Uh, it's kind of, uh, listing out the factors that contributed to that, and then later on it also shows you how you can go to solve it. Cool. So that was the other, the second scenario I wanted to show uh in terms of troubleshooting experience you have in the ECS console. All right, that brings us to the end of demo and, and at the end of the presentation. Thank you all for your time, really appreciate it. Thank you.