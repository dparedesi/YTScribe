---
video_id: C4gIguFkxnE
video_url: https://www.youtube.com/watch?v=C4gIguFkxnE
is_generated: False
is_translatable: True
---

Good afternoon, everyone. Can everybody hear me OK? You've got to have your headsets on if you want to hear me. Good, all good. Thank you. Fantastic. Yes, you are in the right session. The session is accelerating incident response through AI ops. Let's start with some introductions. My name is Pratul Chakre. I lead the global worldwide team for cloud operations specialists. Uh, based here in the US, Andres, and I'm a sidekick. Uh, my name is Andres Silva. I'm a principal specialist solutions architect with the cloud operations team, and I focus on observability, so helping customers, uh, adopt observability strategies, and throughout the last year I've been focusing on AI ops, so we have a lot of exciting things to share with you today. And so today what. We've put together is probably the most high octane session that you will attend at Reinvent, and if that's not the case, please come back and see me and let me know so we can do better next year. When when Andre and I sat down and to talk about what do we do about this session, what do we present, we actually want to take a step differently and not just present all the cool stuff, which we will, of course, all the cool stuff that we have to show you, but we want to weave it into a story. And so when we were thinking about the story, we're like, what's better than the recently concluded Formula One at the Las Vegas Grand Prix. Any Formula One fans here? Show of hands? OK, there. OK, fine, so we'll have some work to do along this, we do. But what we really want to showcase was how Formula One has evolved using technology to get to where they are today, and they're continuously doing so and the biggest difference between organizations that are successful and organizations that are not so successful is how they evolve and embrace technology to drive innovation within their enterprise, especially in operations. So what we will be talking about today is the race strategy, right? A race strategy is what you put together to understand, uh, during the offseason, what are we gonna do, uh, during the start of the season, what are you gonna do, mid-season, and then on the day of the race, what are the kind of things that you'll be focusing on, right? So we'll talk about all of the AI innovations in CloudWatch, CloudWatch being our flagship AWS service for observability. We'll talk about MCB servers and ergentic frameworks. We talk about cloud watch investigations and but last but not the least, we will also talk about there is no session that's that's complete without talking about agentic AI and agentic frameworks, yeah, so we are going to talk about the AWS DevOps agent which was announced by Matt Garman earlier today. But first, and this is interesting because I've been with Amazon 10 years and I've spoken to hundreds, if close to about 1000 customers over my last 10 years, and every single time I hear, or most of the time I hear, I didn't know CloudWatch could do that. So what I wanted to do was just quickly talk about. Quickly talk about how the evolution has begun in terms of the innovation with cloudWatch. It started in 2014. With just the logs to where we are today, we launched Lifetail for logs in 2023, 1 of the most sort of sought after features for for developers who are uh infrastructure engineers to be able to look at the logs at near real time. In 2024, we of course made enough, uh, made further improvements to Lifetape, but we also launched database insights, so getting into specific. Getting into specific um uh curated views into the databases and then we also launched transaction search and analytics to today. Where we've launched a whole bunch of things, but I'm just gonna pick on a few things. Number one, we've centralized all of our logs across account across regions in one account or a region, right? This was one of the most sought after and asked features from our customers. We now have application map. Now this is extremely important for customers to understand their application level dependencies. I don't know why this is on auto, but application level dependencies. Across whether or not the application is instrumented, right, so you can actually see an entire application map across your across your application. GAI Observatory again something that Matt Gorman announced today um talking about you when you build your G AI applications whether it's on um tech problems whether it's on um Bedrock or whether it's on EKS self-hosted, how do you monitor the application or the agents that you're building across the enterprise, right? Some of the cool stuff that we've launched over the uh over the past year, uh, which is all the best, so CloudWatch has evolved a lot. And this evolution has helped us to monitor at scale, and I'm sure if you didn't know this, one of our biggest customers for CloudWatch or AWS observability is Amazon. All of Amazon, all of AWS uses CloudWatch for their observability. We support 17 exabytes of CloudWatch logs per month, 32 quadrillion metric observations per month, and 932 million canary lands per month. No, I don't know about you, but when it goes beyond gigabytes, petabytes, I kind of lose context on how many zeros are we talking about. So this is why I put that for my own reference, like a exabyte is 18 zeros, right? That's the scale at which we are operating, and that's, that's what we are supporting. So how are we doing that? How are we able to do that today? One of the things that we were extremely clear about, as we heard from our customers when we were talking internally, one of the things we were really clear about is number one. CloudWatch, well, AWS needs to be the home of all telemetry. If you are not able to get all of the data into a single place, you have disparate data sources all spread across your entire environment. It is extremely difficult to build a context. It is extremely difficult to get the insights based on that context from the data that is very disparate. So CloudWatch now is has now become the home of telemetry. Then building curated experiences, what an application developer might need is very different from what an infrastructure engineer might need or what a database engineer might want to see as part of their metrics as part of their observability, right? So building curated experiences in order to be able to help. The persona for the use case that they are responsible for is extremely important. And then last but not the least, implementing AI ops. How do you offload mundane, manual repetitive tasks to AI so you can focus on what's important for your business? Now let me take you back a little bit on the Formula One analogy, and I know a lot of people didn't raise their hands when we talked about Formula One. But this is a question we wanted to ask about, do you know how long an average pit stop takes? A pit stop is a stop, is a, is a, is a pre-planned stop that the driver takes in order to either refuel gas or change tires, which are the most two common use cases, in order to be able to keep the race running for the number of laps. So watch this video. There'll be a question at the end of it. Uh, Hamilton on Vettel, 81% now cos Hamilton's going faster. K1 K1 to gain more. Puss now, uh, racing two cars, push now. So this is the undercut, this is Hamilton going faster on that new set of tires than Vettel's able to cause he's on an older set of tires. Hamilton's just coming round the final turn as the Ferrari pit. Execute a very nice pit stop indeed. Medium compound tires going on to Sebastian Vettel's Ferrari. Lewis Hamilton goes past our commentary box at a rate of knots. Vettel at 80 kilometers an hour. Hamilton has got the jump on Sebastian Vettel by performing the over the undercut, and it's Hamilton now ahead of the Ferrari. Excellent. How many of you saw that uh Lewis Hamilton took 2.1 seconds as a spit stop? Yes, this time is so important that it actually can either make you win a race or not. It depends upon the podium position that a race driver could make. How many of you saw that there was a predicted gap analysis on. How long does Hamilton stop before Sebastian Vettel, who's another driver behind him, how far ahead Hamilton will come in front of Vettel? All of this is collecting telemetry, doing the analysis at run time, not even near real time, at run time, in order to be able to make the right decision of when to stop and when to make those changes. On an average It takes about 2.3 seconds, even though Hamilton did better on the average. It takes 2.3 seconds for a race driver to pit stop, right? But they didn't just get here. Over the years, Formula One has made progressive improvements over the years, going from when they would use hammers in order to change their tires to all the way down to AI prediction today. That has actually gotten them from 67 seconds back in the 50s. To 2.3 seconds today. That is 96% improvement in how they conduct a pit stop, right? That's the strategy. That's what makes or breaks a race. How do they do that? What did they do? What did they change? And it really revolves around three things being adopting the latest and greatest technology, what's available, right? So they went from hammers to pneumatic wheel guns that immediately gave them the 5 times faster in their ability to change the tires. They went even more data driven. They collect there are 300 sensors per car. They're collecting weather information, racetrack information, all the telemetry that they need to make the right decisions in order to win the champion race. And the process, the personas, like every persona is accustomed or choreographed to do the exact same thing every single time the car stops during a pit stop. They practice this like a symphony over and over again so that they don't make a mistake. At the time of when the time is really needed. So why shouldn't it any different for all of us, all of you, to also drive your cloud cloud AI ops implementation? Because the technology is now available, and we will show you how this technology can help you get there. It is data driven, so once you're able to collect all your telemetry across all your environments into one single place, you can make those data-driven decisions. And enabling the process of getting AI to assist you in making the decisions, what we essentially call as human-led AI assisted decision making, driven by data. And then continuously learning from past experiences in order to improve and further reduce your ability. To be able to drive, uh, to be able to drive, uh, the, the, uh, your MTTR or meantime to resolutions lower. No, Think of that pit stop as a planned downtime that we have, we all have in some shape or form. We practice it, we choreograph it, but what happens when an incident occurs in our world or in the case of Formula One, there's an unscheduled pit stop. An unscheduled pit stop happens because something broke off the car, needs to be quickly replaced, the tire came off or the tires were not working properly, they need to change again, even then. It is an unscheduled pit stop is only about 40 plus seconds. Now imagine your pager goes off at 3 a.m. Right, you now have an incident. I don't know, for some reason everybody loves a 3M. analogy for pagers going off. I don't know why, but here we are. Pizzer goes off at 3 a.m., which is your unscheduled pit stop in your world, in our world. That incident takes 4 hours to resolve. And now we've not lost, if not thousands, at least a few million dollars in realized revenue because your customers couldn't log in, they couldn't process their data the way they wanted to do any of that impact. So what if your operational pit stop, whether scheduled or unscheduled, could get into minutes or even seconds instead of hours? That's where AI ops plays a big role and with that I'm gonna hand it over to Andres to take us to the next set of slides. Excellent. So um we've we've talked a lot about the Formula One analogy which um if you didn't know how to recognize a Formula One fan now you know uh. But I think it's it's very good. But before we start diving deep into this, uh, I think it's it's fair that we define what AI Ops means, right? Because it could mean different things to different people. So, when we define AI ops, we're talking about using um artificial intelligence and machine learning to enhance, you can see there on the slide, accelerate. And automate the cloud operations process so it's to give you superpowers. This is not something that's gonna go and do all the work for you hopefully we'll get there, but we're not there yet but we're discussing AI ops in in that context uh that you see there so um. So that's the problem you were talking about that the slide doesn't come. OK, very good. So in the Formula One analogy, Bato did an excellent job in explaining how their evolution, uh, from, you know, the uh the hammers and all that has taken them to where they are today, where they can do a pit stop in 2. 2.3 seconds, right? Amazing. So you can see a lot of parallous things in the in their evolution and the evolution that our customers need to do in order to take advantage of this technology. The F1 started with uh telemetry. Uh they they then started doing simulations and strategy, um, then they went to uh making real-time adjustments, and I'll give you an interesting example later on about when that was implemented. And now we're at the point where they're making AI decisions. When something happens, you know, they can go in and tweak things. Super powerful. So in order to manage infrastructure in the cloud and adopt AI ops, you have to do or have to go through a similar journey. We all started with monitoring, right? And then maybe we started doing predictive analysis that has been, you know, available for quite some time, anomaly detection. Uh, Remember setting up that base pattern and then detecting anomalies. Um, now we're at the time where we can do auto remediation and we can do a lot of other cool things with generative AI and of course autonomous ops, you know, that's the holy grail, right? Like that's where we wanna be, uh, and, and that has to be the journey that we have to take to adopt and benefit from this technology. So, um, I'll just take a quick moment to highlight uh the partnership we have with Formula One, and their platform F1 Insights. It's a very good example of how you can continue to adopt technology and improve, uh, not only your operations, but in this case, their business, right? Which is the key thing. Um, so, in order to help you understand this and kind of create like a mental framework, uh, we decided to continue our Formula One analogy. And we're gonna talk about 4 main things, right? We're gonna, we're gonna define the pit crew. The pit crew is all those people that help you in a race to win. And um uh we're gonna talk about tire gunners. We're gonna explain what they are. We're gonna talk about jack operators, strategists, and then race engineer. We're gonna map those to different services and features that can help you in this journey, all right? Let's let's let's get started with tire gunners, right? So when we a tire gunner is not somebody that you know shoots tires. No, that's not it. It's actually the person that has that big pneumatic pistol and races to take out the big knot that's in the middle of the of the wheel and takes it out very, very, very quickly. In fact, if you go to the Caesars Forum now, they have the sports, it's called the sports forum, I think there's actually you can go in and actually play with a pneumatic gun, which is actually I think pretty cool. But it may seem simple, but it's foundational, right? And when we talk about foundational, we have to talk about some of the innovations that we've done with CloudWatch. Interesting, uh, note here that in F1 Insights, uh, the Formula One team uses, uh, CloudWatch telemetry to monitor their LL inference infrastructure, the infrastructure components, right? Uh, and again that goes back to the point that it is foundational, right? um. So let's talk briefly about some of the AI innovations, uh, the base layer innovations that we've done in AI. We're gonna talk about something that Matt Garman announced today, uh, in, in the last 10 minutes, 25 launches, right? That was very exciting, which is the unified, um, unified data story, unified telemetry for, for CloudWatch, and we're gonna talk about, uh, natural language, query generation, and a couple of other things. So let's dive into it and then I'll do a demo because demos are fun, right? So first of all, to set the stage, an F1 car. It has an immense amount of data, just one car, immense amount of data coming in that the teams have to process. So just to give you an idea, in a typical race, there's more than 5 billion data points that come in across all cars. Uh, and that is a lot of data and that's something similar that happens with our infrastructure, right? We have a lot of data coming in. We have infrastructure logs, we have application data, we have application logs, databases, streaming services, you name it. And right now what happens is a lot of that data that's coming from different places, it ends up in different places to be analyzed, which kind of becomes a hassle, right? And it doesn't empower you to do. to leverage artificial intelligence for operations because the data cannot be in all these places. You want to centralize your data. So we, we're very excited that this morning we launched and announced this is something we've been working with for for quite some time now. What is a year or something, yeah, easily, yep. So unified data management for CloudWatch. Uh, what does this mean, right? CloudWatch, you all know, uh, it's a very powerful, um, telemetry platform. It's the one that we use at AWS like Ptool said. But now we're creating an additional experience that allows you to unify these three main use cases operational, security, and compliance. So that means we're empowering our customers to bring all that data into CloudWatch. We're providing an enriched interface on how to query and search that data, and we're also providing features like the analytics tiers, the telemetry pipeline, and the goal of those is to allow our customers to put all their data in one place. And that's going to be the foundation. And then on top of that we can run effective AI operations. Does that make sense? Yes, absolutely. And here is why it makes a difference, right? I mean, just like we saw in the Formula One example, about 5 billion, you said 5 billion race, race, 5 billion data points coming from all different cars. And that's the part that we're trying to understand here. It's the same set of data but coming from different cars, but the telemetry being collected is the same. Similarly for our applications, whether it's security data, compliance data, or um um observable telemetry, it's coming from different instances, servers, Kubernetes, serverless, whatever technology that you use under the underneath the hood to power your applications, it's coming from multiple instances of those same applications and to be able to run. The level of analytics and decision making that Formula One does, it is extremely important to be able to collect all this data into a single location. Exactly. So some of the features, let me highlight. Don't worry, we'll make some noise later. Um, some of the features, um, let me highlight, um, it's the fact that now you can from a single place enable all the uh data sources. Uh, AWS vended data sources, right? Like I'm gonna give you a very simple example. You have an organization with 400 accounts. You wanna enable BPC flow logs in your accounts. You wanna do it in a consistent way across your entire organization. That's just one small part of what this new set of features does, where you can go in, create a rule that goes and enables all, um, BPC flow logs everywhere for you in a consistent way. Um, we are providing, uh, connectors for, um, for third party sources. So you can bring in your crowd strike data. There's uh we we launched with about 12 connectors and the goal is to continue to increase that. Now you have a full blown telemetry pipeline that allows you to ingest the data, transform it in the in the format that you want, so that then you can consume it. And along with all the analytics, uh, features that we would take the whole session telling you about, this is incredibly powerful and that's why we wanted to include it in this session, but the best thing to do is to show you a demo, right? Yeah. And before you, before you get into that test drive and, and the last but not the least is, is the support for open standards, right? What we've learned from customers over the years is that there is an advent of how many customers want to use open standards to store their telemetry. And that's exactly what we're supporting. So we are supporting open telemetry. We, we are, we do support open telemetry for observability data, and then we also support open cybersecurity schema framework OCSF for security data. So now you can pretty much send either of those formats to us in CloudWatch, whether it's security or observability. Go ahead, Anders. Awesome. So um. If you have used CloudWatch in in the in the logs console in the logs section here, you will see there's a new thing called log management. Before it used to say log groups. Maybe you don't notice there's a subtle difference, right? But now when you go in there, you're gonna have 3. Tabs that provide additional context into what's going on and the enhancements we're providing. The first one that I want to call out is data sources, and what this does is that it will show you all the different data sources that CloudWatch is tracking, right? So you can see here that I have um BPC flow logs, Route 53 logs, I have cloud trail events, right? So, as you add more data sources, either through enabling them. Uh, Through the centralized enablement or by ingesting the data from a third party, you will see your full list of, of, of data sources here. Um, the other thing you can do very quickly here, and this is something I forgot to call out, we are providing S3 table integration with uh with this new set of features. What does that mean? Does that mean you can take a specific data source and you can say I want to make, make this available via S3 table. Now you can. You know, read that data through Apache Iceberg, Athena. So imagine the possibilities of now taking all the logs that you have there and incorporating them into any, you know, you know, big scale analytics pipeline that you want or just using artificial intelligence for it. This is super powerful and something that we think is going to make a big difference. The other thing you could do here if we could scroll up. Um, you can add new data sources, and I'll just show you this quickly. I don't wanna spend too much time because I just want to whet your appetite so you can go play with it, right? Um, so, um, we can see here all the um all the um data sources that we currently support. As you can see, we have all the The vended telemetry there, you know, VPC flow logs, EC2 manage Prometheus, but if you go ahead and click on third party, you'll see that we're also starting with a large set of partners, third party integrations that you can bring in, right. OK, um, the other thing that is worth calling out is the fact that pipelines here. It's very easy to create a pipeline. You can just say, OK, what kind of source are we talking about from the list that you saw before? Let's say we select CrowdStrike. You give it a name. Right, and then you go next. And the integration is going to be done through an SQSQ. In this case, the different sources work in different ways. You specify an SQSQ when it gets our telemetry pipeline is just going to be pulling that cube and pulling anything that comes in new so they can ingest it. You specify. Uh, the, uh. Um, the, the, the data format, this only one data format at source. And uh the service role that is gonna be used, and that's it. It's as simple as that, it's super simple to use. You can also do uh transformations. As you're creating the pipeline, you can say, you know what, this, uh, to give you a very simple example, my cloud trail data, I want to transform it to OCFS OCFS, right? And we'll do that OCSF, thank you, OCSF. Um, and, and it'll do it for you. You can also do enrichment on the tele telemetry pipeline, uh, which is also super powerful. Anyway, let's get back to this is core for AI. This is foundational, but another thing that I wanted to show you, and I can go real quick to the uh. To the PowerPoint, but it's just for one slide because I'm gonna go back to the demo. Communication is very important in a Formula One race, so the fact, you know, that the that the team can communicate with the driver is super important in a clear way. So when the driver is instructed to come back to the pit lane for for whatever reason. You know they don't use complicated language. They don't use, you know, very intricated words or anything like that. They just say box, box, box, and he knows that he needs to go back to the pit lane, right? So why do I say that? It's a good analogy for what happens when you're trying to extract insights from your data, right? You don't want. To overcomplicate things and traditionally to get insights from our logs and our metrics we've had to learn these query languages, right? Log incense language could be SQL, right? Whatever is supported by the platform. One of the great things generative AI has enabled is the fact that now you can express in natural language what you want and the system can automatically, you know, translate it to what you need. And that's one thing that we're investing a lot over the last, uh, you know, couple of years. So let me just show you real quick how that works. All right, we're back to our demo here and I'm gonna just show you a couple of examples, one with logs and one with um. Metric, uh, metric insights, so I'm gonna pick a um. Uh, I'm gonna do it with log group name and I'm gonna do a cloud trail because cloud trail is, everybody understands what's going on with cloud trail. I don't have to, um, you know, explain a lot of things. So, what are we gonna do is let's just um, run, um, let me see, let's run this query. Oh, I'm sorry, no, I don't wanna do that. So typically you have to come in and write your query, right? Now we support. Also PPL and SQL as as other languages. You can you can craft your your your queries in those languages. And er what you can do also is use the query generator, which is right here. Right, and now you describe in simple plain English it actually works in other languages too, which is kind of cool. I was about to ask you that. Yes, you can some of the main languages it works. You can just say it, you know, in, in plain language. It'll, and it'll, uh, convert it into the, um, query that you want. So let's do this one. Oh I need to buy this product. Show me the. Top 20 API calls. Made right? So I'm gonna say go ahead and just a couple of things that happen here. It understands the schema of the data source and incorporates it into the uh into the request that is made. And using that information, it will go ahead and generate the query that you want. You saw I already did it over there, so I can go ahead and run my query. Right? And there you go. I have all the um API calls from Cloudra that have been made, organized. I can go in and refine the query. I can say, you know what, I'm, can you sort them by blah blah blah or add this detail? Very simple, very simple to use. The cool thing is that you can become an expert on these uh uh querying languages very easily, right? Um, I feel so powerful when I'm using it because I don't know anything about, you know. This, uh, you know, complex syntax where you go in and you say, oh, that's how you do it, so cool, super powerful use of uh of AI, um, what it really does, it takes away the need to have to learn a specific query language in order to actually get the insights, which is, which is what you want. You want to know what's in your data, what is your data telling you. Instead, the time is spent on trying to learn the query language in order to be able to get to that insight. And so with the natural language query querying, you will now just focus on the insight that you need and not worry about the query language underneath the hood. Yep, alright, very good. So I just showed you the demo. Um, now let's go to the second one, jack operators. Let's talk about MCP servers. Um, so MCP servers are super important, and the way we, we kind of fit into this analogy is, um, when you are using or you're trying to um leverage AI to do AI operations, you can ask a lot of questions, right? You can say, you know. Uh, you, you can get a lot of data, and, you know, we are familiar with a lot of systems that enable you to store the data in one place and then, you know, use some sort of vector database to organize it, and then you can go ask questions about that, right? Um, but there's a number of problems with that, tends to be very expensive and and other things. But an MCP server it kind of changes the whole thing and it's very similar to what happened with Formula One in 1993. So before 1993 they were always able to get, not always, but for a period they were able to get telemetry, the speed of the car, the temperature of the engine, a whole bunch of stuff, right? But in 1993 there was a team that introduced what they call two-way telemetry, which is basically now that we're getting data, but they can go and make adjustments. To, uh, to, you know, certain things in the car and that gave them a 0.3 2nd advantage per lap and they're able to win a bunch of championships until the other teams, you know, just caught on and started doing the same thing, right? So that that's kind of what MCP allows us to do because it allows us to communicate both ways with some of these things, right? Um, it's like the way that has been illustrated is like a USB-C for standardizing the connectivity between your AI models and any API, right? So, um, why do you need them and why they are important in AI ops? Well, the thing, like I said before, is that you need to get data from, from, uh, um, your telemetry, your, your observability platform, and you need to take action and uh and you need to do that in an efficient and safe way. Um, so MCP service allows to do that, and, and, and when we saw the potential of this and how important it was for, um, gentic workloads, so we decided to start building these MCP servers and providing them to our customers. So today we have 3, MCP servers for CloudWatch, uh, or, or CloudWatch and related telemetry, right? We have the CloudWatch MCP server. We have the application signals MCP server, and, uh, we also have the cloud trail. MCP service and when you use these, let's say with um and I'm gonna show you an example with Quiro, but you can use them not only with Quiro or you know VS code Q Developer, you can also build your own agentic you know applications that connect with the MCP server and allow you to read data, and some of them allow you to make adjustments too, right? Think about auto remediation of issues, right? Some, some customers are actually doing that. It's pretty cool. So let me show you how it works. Dude, let's go back here. So I'm gonna go to uh. Yeah, this thing doesn't wanna give up, huh? All right. Let's go to my, um, this is Quiro, right? And uh I have a, an application here. And let me show you first how Uh, you can figure this is very small and I'm so blind, goodness gracious. All right, so. There we go. So, um, you configure your MCP servers and you can see how the CloudWatch one is broken because the demo had to break, right? Because But we'll find another way of doing it. uh, so basically the way you configure MCP servers is by. You, you download um the set of files that QR code that I showed you before, I'll show you again. You can go is a is a GitHub repo where we have all of our NCP servers, not only the cloudWatch ones, all of them are there, and you can go in and there will be instructions on how to do it. Um, the instructions there are for running it locally, which is what most customers are doing today with like uh development environments like this, but you can also run them hosted and all that, um, so. The idea and the use case for an ID environment like this is you can think of it you're coding, right? You're just pushing a change you have your development environment you wanna see how it behaves you wanna tweak some settings so you can go right now here and say, you know, because I have mine configured and now finally it's working you can go here in the chat and say I just. Deployed A new version of the Nova image generate now you see why I was using that app, right? Generator. Um Can you check Latency Or Or if there are any issues. All right, the good thing that I don't understand my typos. um, so what this does is based on the on the MCP server, the MCP server has a set of API calls defined and it can reason which ones it needs to call and it will say, hey, you know, I need to run this so I can approve it. Um, you can actually auto approve things, but I have it here because I want to see what it's doing specifically, but it will ask me for permission to go ahead and and um. Run the tool. So it's going to go call the MCP server. There's a set of APIs that it's going to use and it's going to return back some information that's going to help me understand the the the state of my. Uh, application So it's doing audit service. This is the application signals. So it found some connections errors to Bedrock, which is interesting, right? There's a problem with the application so maybe when I pushed the code, uh, something happened, you know, um. You get the point, right? You can ask in plain, uh, English, you know, very intricate and complicated things. I remember doing a demo one time that, um, I said, you know, uh, look at my cloud trail data. Show me any unusual activity that happened yesterday, right? And it goes in and does the query, blah blah blah blah and then I said, OK, now compare that to the previous day. And create a comprehensive report for me and it gave me this amazing report with all everything that happened in one day compared it to the other one and it called out a few things that were very interesting that it never occurred to me that were happening in in in that account so I encourage you to test it out is super uh super powerful and it can empower you as a developer to get on top of things real quick, see how things are behaving, uh, and you have a direct connection to the um. Uh, to the telemetry before you move on, so a couple of things to notice here, of course this was you were in the middle deciding which MCP server to be used. Of course you can automate it, but there's also an element of trust to be built with the agent that you're working with before you can get to that point. But it allows you to get there. So that's number 1. Number 2, it also comes with recommendations on where you could possibly need to make those fixes in order to remove those errors. Right, so that ability to be able to get to that root cause, that those issues or identify them up front early on and make corrections is extremely important and extremely powerful. In order in your journey to implementing AI ops. Yeah, so I just issued another command. The application Signals MCP server um has a special API call called audit services that combines a number of API calls internally, and it's actually pretty cool because um what I just did was I said um are there any do you recommend any alarms for this um for this service? So what it does is it analyzes all the metrics and it it checks um uh metric density and other parameters. To figure out if this is a good candidate and the variations for an alarm and it would actually recommend me alarms which is actually um super cool so it's it's running that and at the end it will come and say you know what you should probably enable these 34 alarms here they're they're they're kind of critical so that's uh super super powerful. Right. And that thing, there you go, I'll go back to it and show it to you uh on my next demo. Hopefully it'll be done. All right, so let's, let's move on, um. OK, we're back there? Yep. Alright, so let's go to the next one, strategies, and this is my favorite application. I've been working with it for a year now. Uh, so it's cloud Watch Investigations. Let let me tell you a little bit about uh this tool. If you think this slide is busy and confusing, uh, we did our job, right, but this is how the process of responding to an incident looks today, right? You get a page, you go to go check an alarm, you review the metric, you, you know, you go to a dashboard, you call a friend, you know, all that stuff happens, right? And then you don't know, it's very confusing, right? So, uh, through things that we've learned internally at Amazon and all the feedback your customers give us, we, we, we, we said this, can we solve this problem? Can we help solve this problem, um, with generative AI? So we created Amazon Cloud Watch Investigationss. Now how many of you knew about CloudWatch investigations before today? Raise, raise your hand, raise your hand. OK all of you do. Now all of you do, all right. The reason I have a new tag there is because there's a new feature that is incredibly powerful. I'll, I'll tell you a little bit about it, but here's the thing what it is is an AI powered tool that helps you expedite the process of resolving incidents in your infrastructure. So it automatically surfaces uh when you open an investigation metrics that could be related to the incident, log uh queries that could be related or results that could be related to the incident, or um um traces, AWS Health. And also cloud trade data changes. There was one customer that told me, you know what, this is awesome, just so that I know if the issue that's happening is AWS related or is ours, because it does check is AWS held automatically and it will tell you, hey, we're having an issue with this service, so you can move on, right? You don't, you don't have to be stuck there spending an hour trying to figure out why your application is failing, so, um. It's multi-count ready so you can investigate across accounts and you can start an investigation from any cloudWatch widget uh or you can start it triggered by an alarm which is super cool because when the alarm goes off by the time you get to the console. The system will already have some information for you to act on, super powerful. And the new feature that we're introducing is now you can generate incident reports. These incident reports are based on what we use internally at Amazon that we call cause of error or COEs, and they ask the five whys, right? So this gives you very, very detailed information about why the incident happened, how it was mitigated, how many users were impacted, everything, and I'll show you one. It's better than me talking about it. All right, so here's how it works. You start an investigation. You can do it like I said from an alarm you can do it from uh uh from any widget. The most difficult thing when you're doing um incident investigation using telemetry in a central location is the topology of the application because think about it you have all this telemetry in a big data lake, right? How do I know that this piece of telemetry is related to this other piece of telemetry, right? That's super difficult. So the the team at CloudWatch did an awesome job and the first thing that happens once you open the the um the investigation is that we start creating a topology of that application. What do we, how do we do it? We use internal resources. We traverse the infrastructure using different APIs. We use special features that the cloudWatch agent has. It's called NTT. And we create a map of that. And now with that map we can start focusing on a subset of the telemetry to figure out what the problem is, and that expedites the process and makes it a lot more efficient. What's gonna happen immediately is the systems are gonna start surfacing. Observations. Hey, I noticed this. I noticed that. I noticed that. And through the console, you and your team, because this is a collaborative tool, multiple people can be collaborating into it, can add more data points to the investigation, can make notes to the investigation to make it better, add notes, or you can say, you know what, this is not related, discard it and it removes it from the investigation. So all those steps continue refining the process and then the system is going to come to a hypothesis. So based on what I see, this is what I think is happening, right? And not only that, it tells you how we came to that conclusion with full documentation. And what you need to mitigate the problem, what you need to uh uh solve it, right? This could be either uh it points you to documentation, it points you to knowledge base, best practices, or in some cases it will give you uh an SMS, uh, not SMS SSM I got my letters confused today, SSM automation runbook to fix the problem. So, um. Here are the benefits. It's interesting that the Kindle team internally at Amazon started using CloudWatch investigations of some of the incidents, and the result was 80% time saved in doing investigations. That's what we want to do. We want to reduce the complexity and all the. Um, issues that come up when you, um, start an investigation, um, the other thing that is actually pretty cool is that through this process you learn a lot about your infrastructure that you didn't know because there's this weird metric that surfaces and you had, it had never occurred to you, maybe I should keep an eye on that, right? And all of a sudden it just pops up, right? So it, it is a very powerful tool and because it has the human in the loop. It's not only expediting the process of you solving the issues, but it's helping you learn more about your environment at the same time. We think that's very, very important. You were going to add something Per too? No, OK, you got it covered for now. All right, very good. So let's let's let me show you a quick demo of investigations. Um, so, you see, I wanted to show you how um the system came back uh with some recommendations for alarms that I should do, right? So it's it's it's super cool. Alright, so I'm gonna go for investigations, I'm gonna go to this one here, and I'm gonna show you something that happened. So I have this uh application that I built, it's called the er um Nova image generator so it uses the Nova uh through Bedrock and you just type hey um create me this picture, you know it's the same thing that you can do when you go to Nova right? and Nova. Amazon.com and but what I have is I have in my in my um. Uh, here or here, I have a process running requesting images every so often, right? And then I have an SLO defined using application signals. If you don't know what that is, learn more about it. It's super cool. But basically, um, is, is keeping an eye on that metric and letting me know if there's an issue. So, and I have an alarm tied to that. And you can see here that the alarm fired off because I broke the application and you see how I broke it in a minute and what happened was the alarm triggered. I have the alarm configured to automatically start an investigation. So if I go here to AI operations and I go to investigations, I see that it already opened an investigation for me. All right, so if I go into that investigation, I can see what was the piece of telemetry, the initial piece of telemetry that it used to start the investigation is the metric that was backed by that alarm, which is in this case SLO. The SLO average is based on errors, so it spiked up. I, I, I broke the application when Paul was talking before it spiked up, triggered the alarm. So that's the first piece and then right here as this is happening you see that I have the agent queue here I can go in here and I can see what is doing is is constantly moving. I can see uh it's not a black box, right? It shows me what metrics is is doing. I can go in and read what's what's analyzing all the details. I can dive into it so I can see what it's doing and I have visibility into it. I can filter, you know, um. This in the back end is fully agentic so you can see that playing out there on how it's handling the investigation. Now if I go back here, what you will see, and I'm going to go here, these are the observations that I mentioned to you before. These observations are surfacing. I can read them. I can validate them. I can say, you know, I just, I don't like it. This is not related. I can also add a note and say, you know what, I think this is related to blah. You should check this. And the system will incorporate that into the investigation also. And this is, this is where it becomes extremely powerful, right? Imagine that the alarm went off, it kickstarted the investigation already, and it came up with the hypothesis that it believed that the agent system, the agent believed could be the possible root causes for why the alarm was fired off. So it's not like you're trying to go in and just figure out, OK, OK, let me see what went wrong where you already start at a position of saying here are the possible 2 or 3 reasons why. Why the alarm went off and then if it makes it makes sense for you in terms of why it could have gone off, you can accept the change. Now it keeps a record of every hypothesis that you've accepted. And starts investigating further until you get to that root cause, uh, faster, so you're not starting off in the dark, you're not starting off in the blind, you're not starting off saying I don't know where the problem could be to saying here are exactly 1 or 2 or 3 places where the problem could be. Let me go figure out which is in order of priority, which is more important. I'm sure you can imagine how much time that would have saved you already right on the front end of trying to figure out where the issue is. Yeah, the other cool thing that I like about these observations, you can dive deep into them and you can see what the system is doing. So this is also an excellent tool for learning the platform you see that message there it says pattern. Message and pipe to anomaly that's a feature that we released just for investigations and we call it um always on anomaly detection. You can actually um use this on your own you know on your own with any log. And it detects anomalies between two ranges. So if you select 1 hour, it compares two ranges. It does a pattern analysis, and it tells you if there's any anomalies in those two sets. So it's an excellent tool to learn also. Anyway, eventually the system will come up with a hypothesis, and here's the hypothesis you can see it, and it basically says that S3 bucket policy deployments that deny access to the Nova image analyze the lambda function at all causing immediate service failure. When the function attempted S3 operations, that's exactly what I did. I put a deny all policy on that S3 bucket for the role that the lambda is using. So now I, it, it found the issue very, very quickly. Um, it gives me a summary of everything that I found. It gives me a map. Remember I told you about the topology? This is the map of the topology of the application that it used to figure out what I needed to check, and it gives me also troubleshooting, uh, next steps, right? R book actions here. I could just run this if if I needed to knowledge based articles, so there's a lot of good information here now what I can do is I can go ahead and accept that hypothesis and once I accept the hypothesis, the system is going to start doing collecting facts, and those facts later on can be used to generate an incident report. So let me see if I have one that I can show you. Um, do do. I'm gonna go to this archive one. And I see if I remember. OK, so, um, Let me see if it, if it generates it um quickly. Um, if not, I can go to another one, Yeah, anyway, we'll wait, but basically what's happening on the back end is all the facts that were gathered about the incident like what pieces of telemetry were used, what is the connection between all of them, how would this impacted, all that is gathered and collected into this report, and now you have a very comprehensive report that you can use as a mechanism to document the incident and prevent it from happening again, right, because it has all the all the details that you need for that. You will see that once it completes here. There's a lot of information that may not be included because there's no way for the system to know, um, you know, like how many customers were impacted, right? That's information that is sometimes a little difficult to really figure out, right? So you can edit those in in the system you can go and say, you know, add these facts or update these facts so that the report is more complete. Anyway, you're gonna have to just trust me on the report. Maybe I'll show it to you later, but this is, this is, this is a feature that our customers that are using investigations love. But you saw how quickly we were able to get to the resolution, and this, I think, is what is a game changer for our customers, right? The fact that now you can get to the root cause, like Pul said at the beginning, not in hours but within minutes, very, very quickly, right? Alright, let's talk quickly about the last one. This one was announced today and it's called AWS DevOps agent. Um, what is this? So AWS DevOps agents is what's called a frontier agent uh that resolves and proactively prevents incidents continuously and improves reliability and performance of applications in AWS multi-cloud and hybrid environments. So now what you're gonna ask me what is the difference between this and the one you showed previously, right? The difference is how they work. This is a frontier agent. It's a new type of agent that you, when you let loose out there, it's going to start looking for issues that could be, you know, brewing somewhere, anomalies and things like that. The investigations is a cloud watch feature that we offer at no cost to our customers. So that's, that's the big difference, right? This is a full blown frontier agent that's gonna go out. It works with third party telemetry. It, um, it will go and do a lot of preventive work on its own, right? Where the other one you saw that it's designed for incident and, and finding the resolution with the human in in the loop, uh, which we feel is important, but I think this is a great first step so that customers can. Prevent incidents. Find out what's going on in the infrastructure, and I'm very excited about what the team is going to deliver on this. Yes, this, this AWS DevOps agent is just a start in the journey of how do we get to a nirvana stage of autonomous ops where a pitcher goes off. But the agent's already figured out what the root cause is, has taken the corrective remediation action. You just make sure that everything is validated, or you don't even, and you wake up in the morning and it just gives you a report of everything that happened last night and all the changes it made and all the fixes it made, right? That's where we all want to go. That's where we go. This is a first step towards that. Everything we showed before you all the way up to here is your base implementation, your foundations. And making that incremental progress, incremental changes in your operations to be able to get to that stage of nirvana, that's the journey that we are on. And I promised you I was going to show you the incident report. There it is, right? This is a very detailed incident report with, as you can see, metrics, all the definitions, everything that happened, what went well, the analysis, the detection, the mitigation, very, very well documented, structured with all the details you need, action items that were recommended, and you will notice that at the beginning here there are these fields that they need input. Those you can update here. And then they will update in the report so you can export the report into a PDF. You can copy it as markdown and you can incorporate it into whatever tool you want. All right, so. Let me switch back And Just say there you go, you have your pit crew, right? So learn more about this foundational things that we discussed the unified telemetry with CloudWatch. Learn more about how we're using MCP servers. Investigations is an awesome tool that if I were you I would just enable it. It doesn't, it doesn't cost you anything and it can save you a lot of time and we're very excited about the future, uh, what the future holds with DevOps agent. So take a look at it please. so you know awesome, Andres, thank you so much. So what we showed you here today was your race strategy for your season, right? Like I started this session by saying there is a preseason of setting, so you start using cloud watch natural language query and get your teams to start talking to their telemetry in natural language, right? Then in order to be better prepared, like Anders mentioned, please enable cloud Watch investigations. It's available at no cost. And it can actually get you faster to where you need to go in the case of an incident. It ought to be even more structured deploy MCB automations, right? I showed an example of how it's integrated with Quiro, and you can now essentially just at the time of development, at the time of coding, ask it questions to be able to tell you what alarms, what metrics need to be captured, what alarms need to be enabled, what level of logging, what kind of logging, how much logging is needed. All of those questions can be answered up front. This is during a development process. And then, but last but not the least. If you're ready today, go ahead, please, deploy the AWS DevOps agent for autonomous operations. You, you will be able to get to that stage of nirvana on on this journey, and you will be able to get to that championship finish. Uh, as part of your race, as part of your operational transformation race, right? Formula One teams don't just think about by winning, but thinking about strategy, but actually implementing it and what we did here today is we tried to give you all the tools and showed you how to use them in order to implement that race winning strategy. Here's the QR code. It's got all the information that you will need that you will learn that you learned here today and everything else that you need to know to get started. And but last but not the least, fill out that survey, please give us 5 stars. All right, please, please fill out the surveys. Give us 5 stars if you want to see us back on stage next year. That's the only way to do it. Thank you everyone. Thank you for taking the time. Amazing race, thank you.