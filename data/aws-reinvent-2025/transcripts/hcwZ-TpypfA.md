---
video_id: hcwZ-TpypfA
video_url: https://www.youtube.com/watch?v=hcwZ-TpypfA
is_generated: False
is_translatable: True
summary: "This session, \"AI Agents â€“ the new face of privileged machine identities (SEC226),\" presented by Vennu Shastri and Anat Eitan Devidi from CyberArk, argues that AI agents should be treated as high-risk, privileged machine identities. As agents gain autonomy and access to sensitive enterprise systems (apps, databases, infrastructure), they introduce significant security risks, including prompt injection, hallucinations, and rapid, large-scale compromised actions. CyberArk's solution, \"Secure AI Agent,\" acts as an enforcement point (gateway) between agents and their targets. Key features include dynamic, context-aware access policies (considering user persona, agent, intent, risk), human-in-the-loop approvals for sensitive actions, and \"Just-in-Time\" (JIT) access to enforce least privilege. This approach prevents excessive permissions and restores audit traceability by attributing actions to specific users or agents. The session also highlights developer tools like an open-source security toolkit for injecting credentials without code changes (avoiding env vars) and an MCP server for secure cloud access."
keywords: AI Agents, Privileged Access Management, Machine Identity, CyberArk, Least Privilege, Zero Trust, Just-in-Time Access, Security Gateway, Identity Security, MCP Server
---

Hello, hello. How is everyone doing? I realize this is day 3, and the only thing keeping between you and a happy hour is me, so I'll try and make it interesting. I know you've heard AI agents all through the conference, but trust me, this is gonna be really interesting. We're gonna be talking about AI agents, the new face of privileged machine identities. I'm Vennu Shastri. I'm a senior director of product marketing for Platform and AI solutions at Cyberorg, and joining me for the session is my colleague Anat Aitan Devidi, senior manager for product management, who's leading our secure AI agent solution. All right, so I don't want to assume that everyone here knows about cyberorg, so just a quick intro we are an identity security leader that offers a comprehensive platform for securing all types of identities humans, machine, and the new wave of autonomous AI agents all. To ensure that they have the right level of privilege control. Now some of you might recognize as a PAAM leader or privileged access management leader, but we offer way more than that, including things like identity and access management, threat detection and response, governance, comprehensive machine identity security, and so on. And the idea is that we provide all these capabilities to every identity, human, machine, or AI. Every time they are trying to access any kind of enterprise resource as an endpoint or infrastructure or cloud to drive all kinds of value right in terms of reducing cyber or so in terms of reducing cyber risk reduction, uh, enabling business resilience, ensuring compliance, and increasing efficiency. And in case you missed the news, uh, recently Palo Alto announced its intent to acquire Cyber Arc, uh, as a part of its broader platformization strategy. All right, so let's get started. Today's focus is gonna be on agentic AI right now AI agents are rapidly becoming the new face of privileged machine identities in the enterprise, right? You have heard a lot about it, so I'm just gonna quickly skim through the immense potential they. Have to offer, but I'll quickly get into why it is important to think about the identity security aspect of AI agents and then I'll have my colleague Anna talk to you through our secure AI agent solution before I wrap it up with summary and next steps. All right, so starting off with the potential now I know that Agentic AI is really exciting for a lot of organizations. It has the potential to unlock trillions of dollars across the industry. This could be whether it is software engineering, sales, marketing, customer operations, support, and so on. And early experiments have shown that it's not all hype. There is real measurable gains that a lot of customers are getting even as they start off on this pilot. But what is important is that it uncovers unprecedented risk, especially as these AI agents are given elevated privileges to access enterprise resources. Now, by definition, AI agents means that you're giving agency to the LLM to access and do things. And that's where the risk is, right? So these risks not just stem from external threat actors. We need to realize that we are still in the early stages of AI agents and they are prone to hallucinations or they might misunderstand the context, so they might end up doing things that they were not intended to do. So, uh, further what we need to realize is that as agentic AI adoption grows, the risks are going to multiply because the agents are going to operate at different maturity levels. Now for a lot of folks, AI agents typically means an AI assistant. Oh, I'm, I'm doing something with co-pilot and it's doing something on behalf of me. So that's where we are today in terms of uh a lot of the actual. Uh, agent agenting deployment in production, right, but as you go down this chain, it's only going to get more and more complex. You're gonna have organizations that are experimenting with completely autonomous agents with much broader access to enterprise resources. This may get triggered based on, let's say an event like a customer support call or a bank tellers and so on, right? And that's when you start getting more business value, but that's when the risk starts increasing. And within a year or less, take my word for it, you're gonna start seeing way more complex agentic systems you heard on the keynote today on the way we are progressing here, right? So that's when you have multi-level orchestrated agents in turn invoking other agents and humans to to do multi-step tasks across systems, OK, so that's when the complexity is going to increase the, the, the access to these set of agents increases and the risk goes through the roof. Unless you have already started planning towards that and that's where we come in, right? So now let's kind of talk about the AI agents, the fact that they are, uh, making decision, uh, they're taking decisions and they are able to reason, uh, that the elements are able to reason gives makes them really useful in the enterprise context, right? And then. Uh, as we start giving them more and more agency to access, uh, enterprise resources like applications, uh, machines, databases, and so on, a new, uh, standard has evolved. Like Anthropic came out with moral context protocol, and the first version of it did not really address anything around authentication or authorization. Again, things are moving so. Fast we quickly realized that that's not the way to go and so we, we are focusing a lot on, on how this can be improved. So the next version of the standard is coming out and we know that that is going to focus a lot on using OAT as a standard to kind of access these resources, right? And, and, and ensure we have a standardized way. Uh, to, to, for, for the, uh, agents to access those resources. Now the other part is in terms of what are the new risks that come out of this. Now OASP has done a pretty good job of trying to outline the top 10 risks, right? And each of these risks may be, uh, may be targeting a different part of the agenttic system. Some of them are, uh, targeting the components like the applications that they are using, right? So for example, the agent behavior one targets. Uh, the, the, uh, the LLM so that it can be manipulate that and, and do things like jailbreaking and so on, same way gentic supply chain, uh, it targets the applications that it does as a part of its supply chain, right? So there are different ways that threat actors can use it, but a common theme that you see across all of this is the fact that a lot of them are going to use the, the, the, the privileges that the agent has on those applications, and that's where the identity component comes in, right? That's where it becomes imperative. In fact, if you heard Swami talk about it today in the keynote, he specifically pointed out that identity is becoming a critical control plane for this. So now let's talk about that identity security imperative. I'll, I'll try and make it quick because I want to give enough time for Anas to get into the details. So what we see is that AI agents are really kind of this new identity class that shows some characteristics of human identity and some of machine, right? They are able to like reason, make decisions, and, and they work more like AI assistants, right? And so. A lot of immediate focus is that AI agents should be done like service accounts, right? But if you look at the autonomous agents, you, you, that's where the agents are behaving more like cloud native machine workloads. They, they're ephemeral in nature, right? Traditional MFA will not be an answer there. You need to introduce humans in the loop as a part of the process, right? So overall. AI agents should be treated as privileged machine identities, right, because they are, at the end of the day, they're still machine identities. They're highly privileged because they have all access to enterprise resources and they operate at machine scale and speed. So our belief is that the only way to solve this problem of securing AI agents is to combine these two, like, securing human and machine right aspects of human identity including credential management, zero standing privileges, session monitoring, isolation, and all of those, as well as securing machine identities which includes things like strong authentication, secrets rotation, certificates, PKI, workload access, spiffy, and so on, right? So we are really excited if you have missed the news that we will be announcing the general availability of the of Cyber Ars secure AI agent solution by the end of the year. Now the vision is to extend the same set of privilege control that we do for humans and machines to the world of AI agents. Now our solution is built to address all the top concerns that CISOs bring up. Do I already have agents running in my organization? That's a discovery and context piece. How can I ensure AI agents are operating securely? That's securing access and enforcing zero standing privileges. How can I quickly respond if my AI agent is going rogue or has gotten compromised? That's threat detection and response. And how can I govern AI agents to ensure compliance? That's governance and life cycle. So our solution covers all of these aspects. Now I realize that this is a lightning session, so we're not going to have time for all of this. So I'm gonna get my colleague Anna to get a little more details into the secure access part. The, the, the quick, uh, shout out I wanted to have here is because you heard about AWS Bedrock. So in fact that is one of the target, uh. Agentic ecosystems for our discovery and context so that gives you a way to kind of start utilizing the solution uh in combination with AWS Bedrock. Over to you Anna. Perfect thank you so much Vo and uh indeed we are going to review the solution and we are going to focus on the secure access piece and how we can ensure that we can, uh, uh, that we can secure the AI agent access. So let's start by understanding what it actually means. To secure an AI agent, so first of all we need to control what the AI agent, what the AI agent can do, and more importantly why the AI, what the AI agent shouldn't be doing. Now there are cases that bad attacker or even the AI agent itself can bypass those controls and guard rails. So we also want to ensure that the AI agent cannot do any unintended action, and the third challenge is, and from talking with a lot of customers, they see that as their first challenge as well, is how we can monitor, how we can audit who did what when working with with AI agents. So before diving into the solution, let's understand what is the complexity that uh uh that we see uh when they granting an access to an AI agent. So we have an example of an AI agent, a reporting agent that can be used by different, uh, persona in the organization HR, marketing, finance, sales, and so on. That reporting agent can have access to different databases within the organization. But we want to make sure that as an HR employee I can access only my HR databases. As a finance employee, only my finance databases, and as a finance manager, I might have different permissions uh on my uh finance database. And on top of that, even as a finance manager, if my AI agent is. is trying to attempt some risky or sensitive action. I want to provide the approval for that access. So whenever we are looking at the access of the agent, we need to understand that we have the same agent, different users, different intents of what that agent might be doing, and therefore we need to grant different access. So as Veno mentioned, um, AI agent identity is privileged identity by definition. It has access to the most sensitive resources in the organization, our SAS applications, the database where we stored our customers' data. Our environment where we run our solution, OK, so as an identity we need to treat them as the privileged identities and again, AI identity at the end of the day is a combination of a machine identity that behaves like a human. That's the reason that we need to take the controls from both identities and combine them into a single solution that actually addresses the unique characteristics of an AI agent, and with that, I'm happy to share that we are introducing Cyberra AI agent Gateway. Our gateway is an enforcement point between the AI agent and the tools and the targets that. That AI agent can access with the uh AI agent gateway we can actually control the access we can ensure to have human in the loop whenever needed. We also ensure that we have least privileged permissions and we will talk about why it is so important to control on the permissions to control the permissions and lastly we will be able to provide audit and traceability. So let's talk about the access. So the traditional access controls and policies that we have in place are too static for the dynamic and the complex nature of AI agent. We need to move to a different access policy and access controls for AI agents. It needs to take into consideration different factors such as the user that is using the AI agent, the agent itself. The risk, the context of the of the request, and much more. So that's the reason that we are introducing a dynamic context aware, uh, policy to address the access and to control what are the actions and what are the tools that AI agent can do or shouldn't be doing when accessing their target resources. So this is the first piece. So let's now talk what happened and how we can prevent any unintended um action. So again, as mentioned, AI agent um identities have uh access to the most sensitive environments and targets uh in the organization. Now we already know that excessive permissions is a huge problem both for human and machine, but we are not going to talk about that um in the session right now. But because of those excessive permissions and taking into consideration the uh the way that AI agents works, just, just imagine what will happen. If the agent identity is being compromised or the underlying human identity is being compromised with those excessive permissions, the damage can scale immediately. We can run thousands of privileged permissions in minutes and not in days because the AI agent operates at the machine speed. That's the reason that we need to control the permissions an AI agent hasn't. We need to ensure they always operates under the principle of least privilege. The permissions are granted just in time, only when needed and revoked afterward in order to ensure that we don't have any excessive permissions that someone can um abuse. Um, already today we have a solution for least privilege and just in time access for AI agents with our MCP server which is available in AWS marketplace. So let's move to the last target or the last uh sorry um challenge. So we actually want to restore visibility because again the current audit trail that we have today are not sufficient for the uh AI domain. We need to understand if we have an AI agent operating on behalf of the user who actually ran the action. On the target, is it me as an ad or it's my AI agent that uh worked on behalf of me? What was the actions that were run on behalf of the user or as an autonomous AI agent and most importantly, why? OK, so with our AI agents sitting in the middle between the agent and the tools, we are able to restore that visibility again. So before wrapping up, I wrapping up, I do want to share something with our AI agent builders. So we know that there is a common practice, it is not a best practice, where developers are actually loading API keys and secrets into environment variables, and that reduces several security risks. Among them is memory exposure and unintended leakage because. The information is available in those environments variable and we are exposing a very sensitive information, uh, using those, uh, environments. That's the reason that we are very happy to share our open source security toolkit with you. With that security toolkit, you're able to, um, reduce the risk and, um, integrate the the the toolkit with your AI agents. Without code changes, ensuring that the credentials are injected just in time, removed when they are not needed anymore, and we are integrating with the most common um security stores like AAS Secrets Management Manager, sorry, and Cyber Ar Conjure. So this is available already today at GitHub and I'm inviting you to use it in order to reduce the risk that we already have today. So with that, let's summarize. Sure, thank you, Anna. So, so I, I hope that you've all found this session helpful. Um, again, just to a quick takeaway, right? The fact is that AI agents are here to stay, right? And you need to start thinking about the about securing those agents today while the numbers are still manageable. And most of those agents are still not fully in production, right? So you need to start thinking about securing these agents today, right? The, the, the fact is that these are going to open up new attack vectors and as the number of agents increase and as the scope of access increases because these agents get mature, it's going to be harder and harder to control them. So the, the, the time to think about securing those agents is today. The way to do that is using identity security as your foundation, right? You ensure that these agents from get-go have least privilege. You're putting in tight privilege control. You're having just in time access and just enough access so that you are able to keep the surface uh attack surface minimal. All right, so what's next? Now our solution is going to be generally available the end of this month, so feel free to swing by our booths if you want more details about it or you want to talk to one of our specialists. We also have some interesting white papers. We had done an interesting study with McKinsey to look at how organizations are really adopting agentic AI and what are the type of. Risk it is surfacing, right? So and it talks about why identity is the foundation uh for for the defense of against these agents, right? So do download that white paper. The other one is a white paper that talks a more technical one which talks about the key requirements to securely manage these identities. So feel free to download this or or scan those QR codes. Now if you're not exactly fond of reading and you want or itching to try something, then we have some cool developer tools. Anna had said about why it is really important to shift left and start having those best practices as a part of building your agents, right? So here are the QR codes for a couple of interesting tools the Cyber Arg MCP server for our secure cloud access, as well as Cyber Arc agent guard. Both are available in the AWS marketplace to download so you can try them out. Thank you for your time again. I, I hope you enjoy the rest of this conference. We will be around to take any questions. Thank you. Thank you.
