---
video_id: Ea96YI1KKM0
video_url: https://www.youtube.com/watch?v=Ea96YI1KKM0
is_generated: False
is_translatable: True
summary: "In this comprehensive session titled \"Generative AI strategy: accelerating path to production\" (SMB307), AWS Principal Solutions Architect Rana Dutt and Senior Solutions Architect Hardik Wasa provide a detailed roadmap for organizations attempting to cross the difficult \"chasm\" between checking the box on a Generative AI proof of concept (POC) and deploying a secure, scalable production system. Dutt opens the talk by identifying the common pitfalls that derail projects, such as agent silos, unmanaged latency, and security vulnerabilities, before introducing the \"Agentic AI Application Lifecycle.\" He stresses that the most critical, yet often skipped, step is \"Value Modeling,\" where teams must rigorously calculate ROI by contrasting the Total Cost of Ownership (TCO)—which spans inference costs, prompt engineering, and staff upskilling—against measurable business pillars like customer satisfaction (CSAT), conversion rate uplifts, and operational efficiency. He illustrates this with a compelling case study of a sportswear retailer that projected over $10 million in savings by automating just 50% of routine queries, while simultaneously aiming for a 15% increase in conversion through hyper-personalized agent interactions. The core of the session shifts to technical implementation as Hardik Wasa presents a sophisticated demo involving the \"Every Step Shoe Company.\" Through this lens, he dissects three essential multi-agent design patterns that solve different classes of business problems. First, he demonstrates the \"Supervisor-Expert\" pattern, where a supervisor agent intelligently routes user intents—such as checking order status or finding promotions—to specialized sub-agents equipped with specific tools. Second, he shows a deterministic \"Workflow\" pattern utilizing directed acyclic graphs (DAGs) to handle rigid processes like product returns. Finally, he unveils the complex \"Swarm\" pattern, where multiple agents collaborate autonomously without a central supervisor to conduct deep research tasks, such as analyzing inventory levels across disparate supply chain logistics. Wasa emphasizes that these patterns are powered by AWS Bedrock Agent Core, a managed service that abstracts away the complexities of memory, identity management, and observability, while remaining agnostic to underlying frameworks like LangGraph or CrewAI. Current and future deployments are secured through a \"Defense in Depth\" strategy, which Dutt details as a multi-layered approach ranging from fundamental data encryption in S3 to sophisticated application-layer Bedrock Guardrails that actively intercept and sanitize prompt injections and PII leakage in real-time. The talk concludes by reinforcing the need for continuous evaluation using specific metrics for behavior (relevance, toxicity), cost, and latency to ensure the long-term viability of agentic systems."
keywords: Agentic AI, AWS Bedrock Agent Core, Multi-Agent Patterns, Supervisor-Expert Architecture, Value Modeling, Swarm Pattern, Responsible AI Guardrails, Data Strategy, Production Readiness, ROI Analysis

Welcome to this session on generative AI strategy, accelerating the path to production. Thank you for being here. So, here's what we've got in store for you today. You may have already built an agentic AI application. As a proof of concept, as a prototype. And you know, it looks great running on your local machine or in your development environment. But if you're struggling to take that POC. And moving into production. Then you've come to the right place. Because we're gonna give you a playbook for succeeding with your agentic AI initiatives. So that you can take it to production. And your application is going to be there and it's going to be secure. It's gonna be scalable, it's gonna be performant, and most importantly, it's gonna deliver the value, the business value that you expected. So my name is Rana Dutt. I am a principal solutions architect at AWS based out of New York City, and I'm joined by. Hi, my name is Hardik Wasa. I'm a senior solutions architect here at AWS. I'm based in Seattle. All right, so here's what we're gonna be covering today. First of all, we'll talk about the obstacles that many companies are facing, moving their agentic AI applications into production. And then we'll go through a business value modeling exercise. This is where we calculate the ROI. For your agentic AI project, very important step that a lot of companies miss, right? Um, after that I'm gonna hand it over to Harig and he's going to take you through how to build effective POCs, and he's got this really cool demo showing a bunch of agents that are all orchestrated by a single orchestrator and it's just completely uh animated and I think it's gonna give you a very good idea. Uh, of how to build a multi-agent system. So, and then we're gonna, uh, conclude with how you take that POC that you've built and deploy to production. We're gonna talk a lot about agent core. We're gonna talk about how you build in layers of security, and we're gonna, uh, talk about guard rails. All right? These are all components that you need to make sure that your application gets delivered with the business value that you had in mind. All right, um, how many of you have actually already built an application that uses AI agents? Show of hands. Yeah, OK, quite a few of you. So, you know, initially there's a lot of excitement, right? A lot of potential you wanna experiment, um, but then once you have that POC up and running, there's this chasm to get that POC into production that many people, uh, underestimate, um, and. Just some of the obstacles that we hear uh that customers are running into, uh, as they undertake the path to production is first of all, um, there's a lot of agent silos that happen. So maybe you've got one team that's building one agent, right, maybe it's a marketing agent, then you've got another team that's building another type of agent, and then the two teams don't talk to each other. So when it's time to integrate, right, you run into problems. So that's one area. Um, and then a couple of very important factors that are obstacles are performance and scalability. So maybe you start off and your prototype is performing pretty well, responding pretty well, but then as you throw more and more test cases at it, you know, the answers are not quite accurate. So you have to, you know, people stop and they don't test it enough, they don't evaluate. enough, um, secondly, they don't really expose it to hundreds or thousands of users, so it winds up not scaling properly. It winds up delivering poor response times, and so the project has to be abandoned, right? So these are two big factors. Sound familiar, right? These are two big factors, uh, that are preventing people from getting their pilots into production. Uh, two more important obstacles, uh, security and governance. So a lot of, uh, teams are building these agentic applications. They're not paying a whole lot of attention to security because they want to get something cool up and running, right? And then, you know, they send it to their uh security team and they expose it to a bunch of penetration testing and oops, they find out that there's a bunch of security holes that they didn't take care of, uh, and so it, it just does not pass security. It's, it's not in compliance with the governance, and so it doesn't make it uh into production. Uh. And last but not least, uh, take a look at, uh, the, uh, this meaningful business value, right? Sometimes you do get all the way here, but it doesn't deliver the business value that you expected and, and why? Well, you, you didn't do the ROI calculation, you didn't input all the costs, so maybe it's not delivering the business value that you expected, so. I'm gonna go through how you can avoid these pitfalls, right, uh, on the way to building your engentic AI application. All right, um, When you think about building your agentic AI application, you can think about it as uh doing it in a bunch of stages and phases. Uh, and we call this the agentic AI application life cycle, right? So, the first stage is what? I ideation. That's when some of your key stakeholders, they get into a room and they brainstorm, right? Ideas about how they can solve some of the important pain points that they have in their use cases and their workflows. Uh, they want to solve things where there's too many manual steps, right? Uh, so how can they streamline that? So they, so that's when, you know, you're going through the ideation phase. Pretty self-explanatory. Here's the step that I really wanna get into, which is value modeling and what this means is actually going through an ROI calculation, right? Uh, I went to a talk just yesterday and the CTO said, and by the way, this was one of our customers that actually succeeded in delivering an agentic AI application that exceeded all their expectations and what that CTO told me. Is that, you know, we didn't write a single line of code. Until we did our ROI calculation, we input all our costs and we put in what revenue we could expect after we calculated that yes. It's gonna be a good ROI then and only then did we green light the whole thing. Right? Don't skip this step. Uh, after the value modeling, then you have to look at your data strategy. So what this means is that um you'll have all various types of data sources that your agents need to access and maybe some of them can stay as is, maybe some of them are not quite ready to be consumed by your AI application, you know, they don't have the permissioning set up so you gotta look at all of these data sources. And look to see if they're ready for prime time. Are they ready for AI and the agent uh application to dip into that data source. So, gotta pay some attention to your data strategy, and I'm gonna show you some tricks and tips for, you know, thinking about your data strategy for energetic AI application. OK, now after you've gone through these 1st 3 steps, you know, you've greenlit the whole thing. Now you go and you build your proof of concept. Uh, we like to call this a minimum lovable product, right? Not an, uh, it's an MLP minimum lovable product. Um, and, uh, what you need to do then is after you've got this MLP working, then you should go through some evaluation. OK, is it really delivering the answers we expect? Remember, AI agents driven by LLMs are not necessarily deterministic, right? They could give you different answers, so you have to go through evaluation and keep iterating and make sure that the application that you've built is delivering the correct answers that can be trusted, all right. Um, and then let's say you deploy it in a very limited scale, you know, you deployed into alpha, and then maybe into beta, right? And try to get more feedback from a limited set of, you know, friendly users. So, um, uh, let's say you get some feedback, and now see there's this feedback loop going on, right? Where, uh, OK, you get some feedback, now you go back, maybe you have to refine your, your, uh, prompts, maybe you have to get more data, right? Um, it's only after you have, uh, been satisfied with some of the results of your evaluations, then and only then, you know, do you decide, OK, it's time to scale this thing, right, and actually get it out beyond beta and into GA. Um, by the way, you know, this evaluation step, we just announced this service, which is Bedrock Agent Core evaluations. So that's gonna help you, OK, uh, go through that evaluation stage faster. All right, underlying all of these phases is your security and governance, and I'm gonna explain what AWS services you can use to make sure everything is locked down and that it's compliant with your security objectives. So gotta keep that in mind as you're building this whole thing. Um, and then there's something called responsible AI, which means, you know, don't, uh, you, you can't leave something in there that exposes the application or your company to harm. Uh, you, you can't have someone come in and and abuse this thing and get information that would compromise the system, uh, and that would be, you know, not, uh, not something you'd, you, you'd want to happen. So, I'm gonna explain how you can implement responsible AI, right, with, uh, with guardrails. And you know, the, the, the loop keeps repeating, uh, and, uh, at, at, at, after you've gone through enough iterations, um, you can uh then go, go GA with your application. All right, so let's start um with the ideation phase. That's kind of like a fun phase because that's when you're really brainstorming your ideas, right? Uh, no matter what industry you're in. You can find some workflows or use cases that could be reimagined using agentic AI. For example, if you're an insurance provider or a company that provides software for insurance companies. That whole uh workflow for underwriting an insurance policy, well, that has a lot of manual steps, doesn't it, right? Couldn't that be, uh, streamlined, right? Uh, using an agentic AI application? Or what if you're writing software for a bank and you're getting all these people applying for credit cards and then you gotta go through all these, you process, you know, their W-2s, incomes, whatever that is, well, that's got a lot of manual steps too. Uh, what if you could do all of that in a, in a much more automated way, uh, using an agentic, uh, AI workflow. Uh, healthcare and life sciences, I imagine. Uh, generating a discharge report when a patient gets discharged from the hospital, imagine generating that automatically based on the journey, right, uh, during the hospital stay, or transcribing a doctor-patient interaction, you know, the voice recording can get transcribed, get thrown into agentic AI. The engentic AI figures out what's the chief complaint, the medications that were prescribed, and then it doesn't stop there, goes ahead and updates the MR too, right? So we're talking about action. We're not just talking about agents that are just answering questions. They're completing tasks, all right, that are very important uh to your workflow. Think about advertising and marketing. An agent that runs your whole marketing campaign, qualifies your leads, right? Uh, I could go on and on. Um, there's just so many use cases and in so many across probably every single industry. Uh, one industry or one use case in particular. Where we're seeing a lot of success with our customers is in the area of customer support. So, a typical B2C company will, you know, it'll have a context center with lots and lots of human, uh, customer support agents, right? And, you know, they're not answering calls or they're, you know, answering, they're responding to chat support requests and, and, and things like that. Uh, here's an area that we see a lot of value add by replacing some of the tasks that the human agent can do. Uh, you know, I'm talking about the mundane type of task, like, hey, you know, do you have any, uh, like someone calling into a retail store? Do you have any sale, uh, happening today? Things like that. So mundane, uh, everyday questions, right, can be answered, but then, it's not just answering questions, maybe you go beyond that and maybe, uh, the customer support agent can even, uh, complete an order, right, in the shopping cart. Maybe they can, um, process a refund if it's a small refund, right? Things like this. So, uh, we see, we are now seeing the whole customer support, uh, uh, vertical or that use case, uh, being transformed using agentica, and I'm gonna drill into that a little bit. OK. Once you have figured out what workload you're gonna transform with agentic AI now you want to go through the value modeling exercise, all right? So, let's see how this works. Uh, on the left hand side, you have to calculate your total cost of ownership, right? And, uh, so every time you ask the LLM to answer a question, well, that's an API call, that's a bunch of tokens coming back and you get charged per token. What is that charge? What, what, what are all these inference costs going to add up to, right? Um, one of our, uh, retail customers actually went through this exercise. This is a customer, uh, that's in the business of, uh, selling, uh, activewear and sportswear. They have some physical stores all over the country, and then they have online stores. Uh, they also have a whole bunch of human agents, right? Uh, so they went through this exercise and, um, they, they, they came up with, you know, maybe 25% of their costs are gonna be these API costs, OK? Oh, the, the cost for invoking the model. Um, and then you have some costs, uh, where you're trying to optimize the model. You're, you're iterating on the prompt, refining the, the prompt, making it better, right? Cause handling more use cases. Well, that effort to keep iterating and improving the prompt, you know, the thing that says, you know, you are an agent that is a customer support representative, you are, right, empowered to look up, you know, information about this, all of this, you know, that, that core prompt. Uh, the effort to optimize that, that could be 15% of your costs. Uh Then your infrastructure and DevOps team, they have to think about building, you know, a CICD pipeline. Uh, there's some effort in building that, so maybe that's 10% of your costs, right? Uh, your data strategy, remember I talked to you about getting your data so that it's in shape to be consumed by your AI agents? That could be, you know, 15% of your costs. By the way, these are just numbers that this particular customer used in terms of percentages. When you look at your particular agentic AI use cases, these percentages could be like completely different, right? So this is just for illustration only, OK? But it kind of shows you how you should think about calculating your TCO. OK, uh, talent and development, you cannot underestimate the cost of this. This is where, you know, you need to upskill your development staff. Because, uh, your, your developers don't necessarily know about, uh, the agentic libraries that they need to use all the tools, right? How to string all this stuff together. So maybe you spend some time, you know, sending them to courses. Well, there's some, you know, there's some cost to that, uh, and the cost to upskill your staff, you know, your, your development staff, your DevOps staff, that might be, you know, 20 that might be 20% of your costs, right? Uh, operations and support that could be 10% and then, uh, amount you spend on ethical AI could be 5%. Now, uh, that's on the left hand side after you in after, uh, plugging in all these costs, now you need to calculate, OK, what are my returns gonna be? Uh, and sometimes these returns are not dollars and cents. How many of you send out surveys to your customers asking them about their satisfaction score from a 1 to 5 rating? Right? So many of, some of you do that. Um, so when, uh, a customer gives you a, a, a rating that's kind of average, that's gonna motivate you to say, how come I'm getting an, how come I'm getting a rating of 3 out of 5 on average? I need to boost my rating, right? So you want, uh, if you, if your agentic AI can boost your CSAT score, that's a value add, right? Uh, boosting your employee productivity, you definitely, uh, that should be a metric that's a return and optimizing your business operations and of course, you know, the dollars and cents metric, uh, your agentic AI application, you are hoping that it's going to actually generate a significant amount of incremental revenue, right? Either directly or indirectly, right? So that's, so on the right hand side are the returns, so. This value model, this exercise then determines that that return on investment, right? Again, I can't emphasize how important it is to go through this exercise before you embark on your agentic AI journey. OK. OK. Uh, here's an actual set of numbers that remember that clothes retailer I was talking about with the customer support agents. Here's how their numbers panned out. They have something like 250 agents spread across the country working multiple shifts, each agent answering maybe 40 questions a day, 250 times 40, you know, they're answering 10,000. Questions a day. Um Let's assume that they're paid. The human agents are paid $30 an hour. Let's assume that this agentic bot that acts like a customer support agent can resolve 50% of those queries. And let's assume, you know, we, we looked at our inference costs and everything that the chatbot cost is 10 cents per query. OK. Plug in all these numbers and just purely from that perspective, there's over $10 million worth of savings if you can accomplish this, OK? Um, you got a 50% cost reduction versus the human only model, but now remember it's a caveat, I did not subtract all the other costs like the training costs and the other things that I mentioned. This is purely from the point of view of the hourly wage of the customer support agent versus what the chatbot costs you, right? What the agentic application costs you. Uh, so that's your ROI in terms of that. Uh, this customer targeted that, you know, we wanna get at least a 10% uplift in our customer satisfaction score, right? Uh, they also wanted the agentic application to deliver an incremental 15%, uh, increase in their conversion rate. What this means is that the agent is actually helping close a sale. Uh, you know, they're asking, do you have any, uh, uh, uh specials? Yeah, there's, there's a special. Here's what we have on sale, you know, and oh, OK, then I'll go, go, go buy this. That's gonna, that's a conversion, right? So they want an uplift in their conversion because of all these, uh, agentic interactions. Uh, employee productivity, maybe 22% improvement in task completion, and now, you know, you're not eliminating all the human agents, but the human agents are now answering a lot more complex issues and tasks, OK? OK, um, now that we have done the ideation and the value model, let's look at data strategy. So, um, here's the key here. Your data, the data that your company has. Is unique to you because it's the result of years of interactions between your customers and the services that your company provides, right? So now you've got this data about your customer behavior, what they like, what they don't like, what's succeeding, like for example, you know, you're collecting information about loans, you know, which ones are succeeding, you know, things like that. Well, you can deliver a tremendous amount of value. By building your agentic AI application in a way that knows your business and knows your customer, as opposed to building something that's just generic, right? So I think there's just a ton of value to be unlocked by focusing on your unique data as your differentiator and building your agentic AI application around it. So that's why your data is so important to your agentic AI initiative. So let's take stock of the different data sources that you might use in your uh agentic AI application. Um, the first type of data source that comes to mind is the obvious one, you know, all your transactional databases. Like SQL Server or Postgress or MySQL, right? Uh, that comes to mind immediately, that's something that your agenttic AI will wanna look into. But then there's stuff that's not so obvious. What about your semi-structured data? And by that I mean, your, maybe your emails have a lot of information, right? Uh, how about your application logs? Those are, those are semi, that has semi-structured data in those application logs. Uh, any data with tags like HTML, right? There's probably a treasure trove of information there that you want your agents to be able to, uh, make use of. Uh, and then unstructured data. This is the typical thing that's used in the retrieval augmented generation. So what I mean by that are documents, you know, PDFs. These could be documents about. Anything proprietary about your company like how you onboard new employees, right? Or, uh, human HR policies, you know, things like that, uh, so, uh, get, uh, so you, you, so unstructured data is a huge source of data for agentic AI applications because they can answer a lot of questions. Third party and SAS data, this is very important too. Um, how many of you are using uh applications like Salesforce in your, yeah, quite a few of you, um, and you know you could have other uh uh examples or things like, uh, Atlasian or Jira, right? Imagine building an engentic AI application that responds to a customer support request and automatically creates a Jira ticket. And then even attempts to resolve that Jira ticket, right? By triaging it and giving it a priority and sending, you know, uh, figuring out what the root cause could be. So, uh, third party SAS data integrated with your, uh, agentic AI is a very powerful combination. Uh, then you have your big data, you also have your data warehouses. This is where, you know, you might have a reporting database, right? Could be Redshift or some other type of reporting database. This has a bunch of data that you can use to query, uh, and look at trends and, and things like that. All right, so how do you get your data in shape uh for Agentic AI? What you're gonna do is you need to build like an ingestion layer. Now, um, let's assume that, uh, OK, you might have, you might have your, your transactional databases, that's fine. Your um unstructured data, all your documents. You need to build a pipeline to get those documents into a knowledge base like a bedrock knowledge base, because that's your vector data store, right? For agents to, to query into. So that's 11 part of your pipeline, uh, which is gonna result in that data processing layer. What about your um structured documents like your CSV files, right? You wanna ingest those CSV files and uh put them into a data lake so that you can query them using SQL queries, right? Uh, so, that's another uh thing that you need to put into your data ingestion layer. So, uh, and that, of course, results in the data processing layer on top. Now, what do I mean by this semantic layer that you see here? What I mean by this is that people will will want to do natural language queries. They don't know SQL, so they're gonna ask, you know, what was our best selling product last month in West Region, let's say. Completely a natural language query. How do you translate that to SQL? Well, you need some help by a semantic layer. This is a layer that looks at all your table names and column names and describes the schema, maybe so, you know, describes it using JSON, sticks that into a knowledge base. So now your agentic AI can translate natural language queries into SQL, right? This is what I mean by building that semantic layer, right? So these are just some examples of things that you need in your uh data pipeline so that your data then gets into shape for your AI agents and tools. Um, all right, so, uh, now that I've explained, you know, what happens, oh, by the way, yes, you have to have data security in mind across all of these, and you have to have data governance in mind as you do all of these, especially with S3 buckets, make sure that they're permissioned correctly. Um, now that you've done this and you've gone through these 1st 3 stages, the next step is to go ahead and start building your POC and Hardik, you can go ahead and take over. All right, thank you, Rana. Well, data strategy is never one and done. It is an ever evolving thing. But once you have the data foundations in place, it is time to build a POC. Let's briefly talk about an agentic workflow first. So when you think about an agent. What the the few moving pieces to it. It all starts with a goal that you give to this agent, what problem it is trying to solve, or a task it is trying to reason and execute. And it does that by the help of a few key inputs. It can have memory of past interactions. It can use tools to enhance its capabilities. And it can draw upon data sources that it has access to. Once it has all the key inputs. It is then sent to the large language model which is at the center, which is the reasoning engine. The response from large language model, um, the agent doesn't just act independently of that. There is this guard rail and observation layer that makes sure that the response is a secure. It is reliable. It is answering the user's question. And that it is sticking to the policies defined. This response Is translated into actions. And his actions are sent back to the user. And this is sort of a loop that continues. So if you are building an enterprise agentic AI. Workflow, where do you start? Let's again take the same example that Rana went over. We'll pick a retail use case here. Let's imagine that you are running or managing this retail business and you are tasked on building this customer support agentic workflow. You would start with something small and focused. So what would you do? You can plug in one microservice and let it um answer questions related to um orders. So your users can check order status. They can cancel orders, return items, and track shipments. Nice. That works well. You get reliable responses and consistent responses. So what do you do? You released version 2. And you add a knowledge base to it. And this knowledge base will answer questions related to returns and order policies, so this is no longer transactional, but it's also answering the why behind it. And this works well. So you release version 3. You add another action group. This time you're allowing your users to ask questions related to products. So users can find products. Your application can recommend products. So now you not only have the pre-purchase step. But at the same time you have the post purchase services. This works well. So you release version 4, and now you add a bunch of additional actions. Backed by their own microservices, so now you have a few more knowledge bases. You have account actions, and you have support actions that your users can interact with. But this is an issue You just created an agent monolith. You'll run into a few challenges like the code gets complicated. Your prompt gets longer. You're using too many tools. And If you try to make changes. It's likely that you'll break something in the process, so there's little governance in the process. So what do you do? Well, one way to address this challenge is to break it down into This patent called supervisor expert agents. So now you have a supervisor, and then you have a bunch of expert agents behind them. And each expert agent is proficient in its own domain. So now when you get a question like when will my order arrive? The supervisor agent is relaying this information to the orders expert agent. And then this expert agent is responding back with the information. Similarly, if the user is asking about returning an item. Now the supervisor agent routes this to the product expert, which in turn is routing this to the knowledge base, and then you get back the response. Lastly, the user is asking about promotions and offers. This time the supervisor is sending the request to the promotions expert. Which in turn is calling the knowledge base. And that's how you get back the response. So you've sort of created a hierarchy of agents as one way to approach this agent monolith. All right. Let's take a look at the demo. We'll see this um agentic pattern in action, and we'll also see some other agentic AI patterns, specifically that pertains to multi-agent collaboration. OK, so this is a busy screen, so I'm gonna explain what's going on here. So as the name suggests on the top, this is an every step. shoe company, which is in the business of selling shoes. They have various types of shoes that they want to sell online, from running shoes to trail shoes, hiking shoes, yoga shoes, and so on. Some pretty good collection. And they do that Through A bunch of stores that they have, you can see that in the drop down menu here. On the left hand side bottom of your screen, you can see that there are some frequently asked questions, and this list keeps evolving as your users are asking more and more questions, right? Just below that, you have some one click workflows, and we'll go over this in just a moment. So everything you see on the left hand side is something that you may want to expose to your end users, right? Those are interfaces. Now, on the right-hand side, at the very top, you can see different agentic AI patterns. We'll go over all of them in a minute. The very first pattern is what we just looked at the supervisor expert agent pattern. You have a supervisor agent. And then you have a bunch of expert agents that it integrates with. Here, for example, we have the product expert, we have the stores expert, we have the payments and promotions expert, and so on. Each of these expert agent has one or more tools. Next to each tool you will see an icon that represents the AWS service that it integrates with or the API call that it's making. You can see that there are some Amazon Bedrock knowledge bases here, there's some Dynamo DB, there's some MCP servers, and so on. So let's move on to the chat interface. We're all familiar with Asiantic AI chatbots. What I'll do is I'll just start by asking a simple question. There are many stores, and I would like to know what amenities does the store have. On the right hand side, you will notice that this invoked the supervisor agent. Which in turn is now calling the sub agent, the store's agent. And now the knowledge-based tool within that subagent was called. And the user gets back a response. And you can see that it listed some of the store amenities, like some stores have Wi Fi, some stores have kids play zone and whatnot. Pretty cool. Let's ask another question. It's a shoe business. I want to purchase a shoe or a pair of shoes, so I ask, what shoe size should I order online. Because I know my shoe size, but it's always difficult to order something online, right? This time, on the right hand side, if you notice, the supervisor agent is calling the items sub agent. Which in turn is calling the item's knowledge base. And you get back the response. And this explains, you know, for what shoe type should you go a size up or half a size up, how should you measure and when should you measure your shoe size, and so on. This is all coming from the life knowledge base. All right, let's ask one more question. Before purchasing a pair of shoes, I would like to know if there are any ongoing offers and promotions. So I just ask, what current offers and discounts do you have? Now if you notice on the right hand side, it's calling the payments and promotions expert agent. It's thinking through the right tool that it should be calling. It eventually calls the list promotions tool. This is the MCP server that is deployed on Agent Core. And then you get back the list of all the promotions. Now this is just a POC so you don't have to have pretty responses and bullet points and and numberings and so on, but it gets the job done. These were simple workflows. Now let's take an example of a slightly more complex workflow. We want to do some back and forth with the agent. This time I'm going to actually purchase a pair of shoes from the store, so I say I want to order running shoes. I'm being very vague. So what it does is it reaches out to the tool, fetches a list of all the shoes that are available um in the running shoes category, right? It lists them for me, it lists the prices of those shoes. I've already looked at the air running shoes, for example. I, I, I like, um, that specific shoe type, so I'm gonna purchase the air running shoes. So I'm saying I wanna purchase the air running shoes and I'm giving some information like men's size 10. Color black. It's taking all of these inputs, converting into structured Jason objects behind the scene. Using the right tool and providing me with a confirmation that this is the total cost of purchasing this pair of shoes. It's asking for a confirmation. Remember, there's a human in the loop. It's a very important step. Once I confirm that you should go ahead and place the order. On the right hand side you'll notice this time, it's called the Place Order tool. This is a Dynamo DB action. And then it placed the order for me. Right, so you can see the seamless integration of selecting the right subagents and then selecting the right tool for that agent. Now once you place the order, Ideally, the retail business would like to invoke an asynchronous workflow to fulfill this order, right? Let's take a look at the graph workflow. This is the workflow with graph pattern that will allow us to fulfill the order. So I'm gonna hit a one click workflow for the sake of this demonstration. And you can see that on the right hand side, it invokes some series of steps. Some steps were done in parallel. And my order is fulfilled. It created a very detailed report at the end. That you can use for tracking and audit purposes. This acyclic graph pattern is very, very powerful if you have a series and parallel steps that you want to invoke. All right, I've purchased many pairs of shoes. I'm just Loving all the shoes that they sell. One of the pairs of shoes doesn't fit properly, and I would like to return the shoes. So I would typically ask that I would like to return the shoe, uh, a pair of shoes. Which will in the back end asynchronously trigger a workflow. This use case is more suitable for a workflow pattern, where all the steps are determined. You don't have any unpredictable outcomes from one step to the other. So as you can see, it runs through a series of steps. And allows me to return this item that I have, sends me notification, generates RMA, and so on and so forth. So this is the workflow multi-agent collaboration type. Now this Every Step shoe company is getting very, very popular. Lots and lots of people are using it. You would have a requirement to Do store sink or item sync or even better, understand if one of these queues or items is running low on stock. And in a given store. This is something that is not predictable. There are lots of variables and inputs that have to go into this process of determining. Um, how to replenish an item that is running low on stock. This is something that the swarm pattern can solve. So you can see that I'm, um, triggering a workflow and I'm asking, I need help analyzing inventory across all the stores. So what the swarm does is it invokes an agent. And that agent hands over the control to the other agent, the next best agent, according to the process. So you can see that it runs through a series of agents handing control from one agent to the other to the third and so on. There's no supervisor here like supervisor expert agent patent. This is purely agent to agent research that's being done. It can go back and forth. It's looking at logistics. It's looking at supply chain. It's looking at pricing and margin. And after completing all the steps, It would generate a report that there was a critical issue identified in one of the stores for one of the queue. And it created a detailed analysis and plan to replenish that stock, um, or that shoe type in that store. So when there's some research involved, Within this agent system is when you would use a swarm pattern. The last pattern we'll look at is A2A, agent to agent. You may have heard of this pattern. This is where the agent directly communicates with the other agent using an A2A protocol. So here, I'm using the same use case of syncing stores and their inventory list. You can see that all of this agent independently um hands over the control to the next agent. They are sinking and you can see a report was generated that shows The final outcome. A2A is typically used when different stores in this use case are developing their own agents. And one agent Is not required to access the back end data sources of the other store's agent, right? so they want to keep the agents independent but at the same time allow them to securely talk to one another using the A2A protocol. The idea is to use the right design pattern for the right use case. Now that you have seen the POC stage, Um, you know, and you can see that you, you can build something pretty powerful using this multi-agent collaboration. But powerful doesn't always and automatically mean that it's production ready. That's where this evaluation stage comes in. There are 3 key pillars to evaluation. Behavior just suggests how the agent is behaving. In doing so, what is the cost per transaction or cost per query? And what's the latency of completing a given task or series of tasks? There's no one model or one system that can give the best of all worlds across these dimensions. It is an agreed upon. An acceptable threshold for each dimension. That you have to use based on your use case. Let's quickly look at the behavior dimension. If you are evaluating a large language model, There are several metrics that you would want to quantify against. This includes accuracy, robustness, toxicity. Even brand voice. One of the key metrics here is relevance, how relevant the responses are to the question or the prompt that you are sending. If you're evaluating retrieval and generation systems, rag. There are key metrics that would be important to you, like context coverage, or context relevance. There's also faithfulness here that you can quantify. You can layer that on top of the responsible AI metrics like harmfulness, stereotyping, and refusal. If you're still not satisfied, you can create your own custom metrics, and you can do all of this by leveraging Amazon Bedrock model evaluation feature. All of these metrics are available to you today. When you use model evaluations or rag evaluations, you get a score from 1 to 100. So it tells you how good it performed against that specific metrics, and it also tells you why it gave you the score that it provided. For cost and speed, like any other AWS service. Amazon Bedrock and Amazon Bedrock Agent Core has tight integration with CloudWatch for metrics, traces, and logs. So now for your gentic AI systems, you get information on a per model invocation basis. You get traces for how your multi-agent systems are doing. You also get logs and metrics on a per session of your agenttic system. All right, so now that you have built a POC, you have evaluated, you move on to deploying this in production. You may have heard of Amazon Bedrock Agent Core. Bedrock Agent Corp provides you with a runtime to host your agents, gateways to host your MCP servers. It does have other primitives like memory, observability, and identity, so you don't have to code them or integrate them yourself. You also have additional model capabilities like access to models. Um, identifying cost and performance, customizing those models. As well as a fully managed knowledge base that you can integrate from within Amazon Bedrock. And Bedrock Agent Core does support open source uh protocols like MCP and A2A as well as frameworks like Crew AI, Landgraph, um, strands agents, and so on. So it's uh framework agnostic, it's model agnostic, uh, it's pretty powerful. So before I conclude, I wanted to quickly talk about the reference architecture. So if you are building these agentic AI systems, you would create a front end or you would leverage an existing front end. The front end cannot directly or it is not recommended that the front end talks to the back end directly, so you create an API interface. You surf this front end through a load balancer. And then you have your static content on a CDN like Cloudfront. You want your users to be authenticated, or you, you, if you have machine to machine authentication requirement, you can leverage Amazon Cognito for your requirements. Now you would host this multi-agent system on Bedrock agent core runtime. If you have to integrate these agents and let them talk to the back end data sources, You can do so securely using. You would host this service on agentco Gateway. And that would interact with the services. It could be AWS services, it could be external services, it could be external third party SAS APIs, what have you. So this is really a framework for designing and deploying. And gente AI application on AWS, but how do you do that at scale? How does your enterprise deploy many, many agents and tools on AWS? Um, I'll hand it over to Rana to address that. Thank you. Thanks, Hardik. All right, so that showed how you can deploy a single orchestrator, agent and sub agents using agent core. What if you have dozens of agents, right? Uh, the best way to architect that is to do it in layers. So your first layer. Is your LLM layer, where you're using Bedrock and Agent core, right, to deploy uh a particular orchestrator, agent and sub-agents. You've got your data layer where you've got your S3, your data lake, your uh databases, and so on. And then you've got your semantic layer. Remember, that's the one where it describes your database schema for natural language queries. So these are all AWS services down here. Uh, at the top is your application, which could be a web app, it could be a, a mobile app, right? And then your application is calling the backend API. Typically, you'd implement a REST API. And then that API layer in your back end is going to get authentic it's going to support authentication and authorization. Um, Agent Core supports OAuth. It supports JWT tokens. So Cognito is a service that can store all your users, uh, and authenticate through, uh, that layer so that your APIs are authorized. Um, and then at the API layer, you're going to invoke your agents, uh, and MCP server. So this is a good way. To scale out to dozens and dozens of agents, right, just to build it in layers like this. Uh, of course, you, uh, agent core also gives you the observability layer so that you can figure out exactly what the agents are doing, right? Um, and then let's talk about, uh, implementing security. This is extremely important. Uh, let's start with the bottommost layer. Uh, defense in depth means. Uh, implementing your security in multiple layers, right? So at the bottom layer, you wanna protect your data in S3 by encrypting it at rest and encrypting it in transit, right? Plus, if it's in a data lake, you wanna use lake formation and have the permissioning. Then the layer above that model hosting, you wanna make sure that you're using Bedrock to access the model because that's gonna guarantee that your APIs are gonna go over the AWS private network. You don't want anything to go over the public network, right? So that's an important layer. And then prompt injection and output monitoring, the way you guard against prompt injection is you use Amazon bedrock guardrails. I'll, I'll explain how you're gonna use that. The layer, uh, there's a couple of layers above that. There's the, you have to secure your API APIs and you have to do your agent access management in a way that users are permissioned to access your agent and The way you implement these two layers is you use Bedrock Agent Core, just like Hardik mentioned, right? Uh, because again, as I mentioned, Agent Core supports the OAuth protocol to make sure that your APIs, uh, can only be accessed by people who have the, the, the OAuth permissioning and the identity provider. And by the way, Agent Core also supports IAM, so that's another way to secure your APIs. At the layer above that, this is familiar to everybody who has dealt with application security to secure your application at the network boundary level, gotta use VPCs, use your WAF, use security groups, right? Uh, that's table stakes for setting up your application. Uh, at the very top layer, you've got your responsible AI policies, uh, and guardrails. This is where you want to make sure that you're not exposing your application to harm because of users asking, you know, uh, uh, impermissible questions. Uh, I wanna actually give you an example of how, uh, let's skip this one. I wanna give you an example of how bedrock guardrails comes in and protects you from having your information be compromised, right? Not only is it gonna guard you against these prompt attacks. You will be able to specify a set of denied topics. So for example, if someone says, hey, dump me the whole JSON scheme of your whole database, right, you can say, nope, I'm not gonna allow you to ask that question. Um, and the way this works is the guard rails intercept the prompt before it goes to the LLM even. So it examines your prompt. It says, oh, this guy is asking something that's a denied topic, right? It's a denied topic. So I'm not even gonna send it to LA. I'm gonna come back right around and I'm gonna say, oh, I'm not gonna answer that question. And then the guard rail also comes in between the LLM. And the application, so the output from the LLM gets inspected by the guard rails. And it could get sanitized, for example, uh, PII redaction, you know, you got somebody who's asking, hey, I want, uh, I want Joe's credit card number. Well, you're not so, you know, you're not supposed to have somebody else's credit card number. So the PII redaction, uh, uh, you know, the LLM is going to come back to the guardrail. The guardrail says, no, I can't expose credit card numbers. Gonna redact it, and then it comes back to the user. So your guardrails are intercepting. This prompt flow both between the user input and the LLM and between the LLM and back to the application. All right? Your guardrails are operating at the, at those two stages. Uh, OK, remember that, uh, store that was, uh, replacing all their, uh, you know, their human agents, uh, and remember they went through that value modeling exercise? Well, what was the outcome? Before they had agents handling all of the chat volume, they had long response times. It typically it took like 12 minutes to resolve a customer query, uh, high operational overhead, and, you know, uh, the, and there was limited after-hour coverage. You can't have people working at 2 o'clock in the morning. So, after they implemented the agentic uh solution for customer support, they found that 30% of the queries could be triaged by AI agents. So they actually saved $6 million of costs by doing this. Uh, 15% was, uh, they had got a 15% improvement in their CISA scores and an 8% increase in their conversion rates. Much faster response times, scalable support, and, you know, um, their, their knowledge also improved with usage as well. That's another benefit you get from these applications. All right, so to recap, um, here's the playbook. Go through the ideation phase, look at the pain points, look at the steps that have a lot of manual processes, uh, and use that as a target for agentic AI application. Then go through the value modeling exercise and the ROI calculations. Once you got the green light for that, go through the data strategy, and then you build the POC according to whatever you, uh uh framework you want. And then send it over to Bedrock uh send it over to Bedrock Agent Corp for secure and scalable deployment in production. Make sure you use the guard rails and make sure you build that those layers of security that I showed you. Uh, I hope this session has been productive. Uh, we will be outside in that area to answer any questions you have. Please fill out the survey. You can use your app to fill out the survey. Uh, their feedback is very important to us. It helps us, uh, improve our sessions. So again, I hope this was productive, and I thank you all for being here.