---
video_id: 7nXXHuxtVVM
video_url: https://www.youtube.com/watch?v=7nXXHuxtVVM
is_generated: False
is_translatable: True
---

Hey everyone, thanks for coming. Welcome to Best Practices for performing custom code transformations with Agentic AI. My name is Morgan Lunt. I'm a senior product manager on the AWS Transform team, and I'm here with Venue. Hey, I'm Vennu Vasudevan. I'm a senior specialist solutions architect with the NextGen Developer Experience team. This would be helpful. So what we're gonna talk about today is the challenge of technical debt, which I'm sure you're all very familiar with. I'm not gonna spend too much time on that, um, some scaled remediation options, uh, things that you may be aware of and some things that you may, uh, may be new to you, uh, some best practices that we've discovered internally in AWS when managing tech debt at significant scale, um, and then the thing you're all here for is the, the live code demo we'll actually show you the, the tools that we use. So the problem with tech debt, it's big, it costs a lot of money, it takes a lot of time, it slows down your innovation, it prevents you from, um, being able to deliver new features to customers, um, it prevents you from being able to hire developers that really understand your stack and can contribute to it properly, and it may bring security vulnerabilities and all sorts of bad things. So generally speaking, tech debt bad. Different kinds of technical debt you can have security and compliance risks, especially if you're in a compliance oriented industry like healthcare or finance, uh, but even for any company, a security vulnerability can cause massive PR issues, monetary loss, all sorts of things that you probably don't want to happen. Uh, maintenance burden, sometimes it can get to a point where you're just doing feels like you're doing patching and addressing vulnerabilities and CVEs, um, and you're not actually spending time developing things that your customers want. Performance limitations, um, so your things can get slow, they can get crafty. You can have large applications built up over 1020, 30, 40 years that when they were initially built were well designed, but after, you know, caking mud on the ball for, for many, many years, um, it becomes unwieldy, and this can also cost you money in terms of being more, uh, expensive to run on bigger VMs. And finally, strategic, uh, misalignment. So a lot of customers that I've spoken with work at companies that were acquired by other companies, um, and companies that are acquired by other companies may use a different text stack than the rest of the companies in the portfolio. So there's often a desire within corporations to have some sort of, uh, standardization and internal alignment for the text stacks they use, the libraries they use, the APIs they use, the vendors they use, which are gonna have their own different APIs and all that fun stuff. So these are some customers that I've worked with pretty closely over this last year. Uh, Air Canada has a big issue with thousands and thousands, I think tens of thousands of, of lambda functions running on deprecated versions of node and deprecated versions of Python. Um, and due to, um, compliance and internal standards they desperately need to upgrade these, and it takes a lot of time and a lot of manpower to go through every single lambda individually and try to upgrade it to the latest version of Node or Python. Uh, Twitch, our, our friends inside of Amazon. Uh, have a lot of Goland code. They're kind of unique in, in Amazon. Not a lot of people use Go, but Twitch does, um, and a lot of it's written using AWS SDKV1. They want to migrate to AWS SDKV2. They have over 900 applications. I think they projected originally 11 developer years of manual effort to do that. QAD is a major ERP vendor. They make software for, uh, manufacturers that make products that we all probably use. Um, they have a piece of software, um, that's evolved over 20 plus years, and their customers have built customizations on top of this ERP software to do, uh. Things particular to that customer, uh, super useful if you're a customer and wanna augment this, uh, this off the shelf ERP with your own functionality, but over time this builds up, uh, craft and makes it very challenging for, for QAD, for the vendor themselves to publish new versions of their ERP because everyone's got kind of a one-off special little thing, um, and so they, they have this challenge of moving these customer done customizations onto their common, uh, customization framework on their newer platform versions. And then Mongo DB, um, they and their customers have a lot of Java code. Um, a lot of this Java code is on Java 8, Java 11, um, they really wanna get it up to Java 21 or, or later versions, um, and, and that's easier said than done. So there's a lot of existing approaches for um for doing code modernization at scale in an automated fashion. Um there's good old rule-based automation so this is uh stuff like AST GREP uh managing abstract syntax trees using something like open rewrite, and these are good tools if you can get them to do what you want. They'll do it deterministically and they'll do it reliably, but they can be kind of brittle and kind of inflexible if you, um, introduce a new piece of code that isn't. Exactly following the same conventions as the ones that you wrote your transformation recipe with, it's probably not gonna work, um, and it takes kind of some specialized expertise to to write these sorts of recipes. You have to know how to navigate an abstract syntax tree. You're kind of like writing code to manipulate code and dealing in this kind of conceptual higher level and it's a it's a little tricky if you haven't done it before, um, and because of that there's a bit of a higher startup cost in in using approaches like that. General purpose coding AI has gotten really good. The Quiros and the cloud codes of the world are awesome. You should all use them. I, I love them. I use them a lot, um. But one tricky part about doing large scale code modernization efforts with them is that there's no easy way right now to um enforce consistency across a bunch of developers trying to do the same task using those same tools. Um, I might ask uh Quiro to to do uh upgrade a Java runtime and it'll probably do it, but it may follow different conventions and different patterns than a venue does it, and we're gonna end up with disparate code that may not follow the standards and use the right libraries that my organization wants to use, um. These tools tend to be designed to be run with a human in the loop, with a human sitting at the keyboard driving it, watching what the agent does, poking it this direction or that, um, which again fantastic if you're doing something once, not so fantastic if you're doing it 100 times, 1000 times. That human cost, even though it's a significant acceleration from um someone sitting out and doing this work themselves with no assistance, um, is still real. There's still significant cost of, you know, clicky clacky driving a coding agent on the keyboard. Um, and another issue with doing, doing it this way is that teams' learnings remain siloed. So if over the course of an API migration you discover, oh, there's an incompatibility between these two particular versions, I had to do this workaround, you know, you learn that, you discover that, but some other team, you know, on the other side of the country, on the other side of the world that's doing the same migration in your organization. They're gonna go out to discover that themselves. They're gonna run into the same issue and unless you're really good about updating wikis and looking at those wikis, that, that learning is lost like that that you're gonna run into the same problems several times, and that's, that's not as efficient as can be. Um, so what do we need? We need a code transformation, the scalable code transformation mechanism that has a low barrier to entry. It's easy to get started with, doesn't take a lot of specialized knowledge. Um, it's designed for automation. It can be scripted together and, and just kind of set up to run in a, in a headless without human interaction fashion, um, something that you can teach once and you can run it everywhere, and that gets better every time, so you don't learn these, lose these learnings that, um, individual developers are, are coming across. Enter AWS Transform custom. This is my baby. I've, I'm the p.m. on this product. We've been working on it for the last year. This was released GA on Monday. Um, we're all very excited and proud of it, and that's what we're gonna be showing you in a minute. So, um, AWS Transform custom is intended to discover, to learn from you any sort of code pattern, API upgrade, runtime upgrade, framework upgrade, you know, I have people doing things as wild as converting VBA script embedded in an Excel spreadsheet, uh, to maintainable Python code, and it's working OK for that, or rewriting bash scripts to, to Rye, which is a breast-based scripting language like. The, the more I learn about how customers are using this, the more scared I become because there is some weird stuff out there, um. Because you can teach it your own custom code transformation, you can do your weird stuff with it, which is cool, and because you are teaching the agent, if it's doing it wrong, you can tell it to do it different and to do it better until it does do the right thing and it does it consistently enough that you feel comfortable to start running it at scale. Uh, continuously learns, it gets better every time. We'll show you how that works in a moment, um, and it's easy to, to run at scale. So the main components of AWA's transform custom, um, is our is our CLI that you'll see in a moment which you interact with using natural language so you tell it, hey, I wanna blah the blah from blah to blah, and it's gonna say, OK, cool, uh, what the heck is a blah? Do you have some documentation on blah? How do I go from blah to blah, um, and we've encoded all these best practices that we've discovered internally at AWS for doing scaled code modernization. Into the agent so it's gonna know the right kinds of questions to ask you if you say I wanna do an API upgrade, it's gonna say cool, do you have the swaggers? Do you have the, the API documentation? If you say you want to add a whole bunch of test cases, it's gonna say, OK, can you give me an example of like the kinds of style that you like your test cases to be written in or if you wanted to emit metrics in a different way, it'll ask you for the schema, um, so it shouldn't take like a whole lot of domain expertise to build this transformation that you're gonna want to apply at scale. Um, once you've built something that you're comfortable with, you're pretty happy with the performance. You've tested it on a few repos. Uh, executing it at scale is really straightforward because it is a CLI. It's a CLI that can be driven by a human talking to an agent like you're all used to doing these days, I imagine, um, or it can be driven by a machine. So our syntaxes. It's totally deterministic and machine drivable. You put a bunch of commands, a bunch of arguments in the command telling it run this transformation on this repo following these conditions and blah blah blah, um, and it'll just do it. So it's really easy to write a shell script to pull down your code from wherever it is GitHub, Gitlab, GitHub, Bitbucket, uh. I don't know what other places and, uh, transform it and push it where it needs to go. Send it for code review, send it straight to prod. I probably wouldn't recommend that, but you do you. Um Continual learning, uh, both during execution of a transformation, um, an agent is just gonna record notes about what it encountered, so if it goes down like a really deep self debug path trying to deal with some weird incompatibility it discovered during execution. And then I had to backtrack and try something else. It's gonna remember that next time and try the shorter path. Um, likewise, if you do an interactive transformation sitting there and watching the agent, which is an option you can do, um, and you see it going off the rails, you can tell it, hey, don't do that, do this, it'll remember that and hopefully not do it next time. So how does the process work? The first thing you do is you have some sort of expert. They could be on a centralized team. They can be someone that owns a particular service that a lot of other teams are consuming, um, someone who kind of knows what they're doing, um, about this transformation. They're gonna sit down with our agent and they're gonna describe what they wanna do and go through that transformation definition building phase. Um, a transformation definition is this term we invented to represent. Uh, the agent's understanding of a particular transformation, so it's a combination of some markdown files, a rag, um, and a database of learnings that the agent's encountered during its executions, um, and this is something that we consider to be your IP. We don't look at it, we don't learn from it. If you wanna sell it, if you wanna keep it secret, if you wanna open source it, that's none of my business. Um, the transformation that you build is yours, um, so someone's gonna create an initial transformation definition. They're gonna execute it a few times on some local repos and they're gonna look at the output and they're gonna tell the agent you screwed this up, you missed this edge case, you should do this differently, and it's gonna update that transformation definition and then you run it again and then you run it again and hopefully after 3 or 4 times and not 30 or 40 times it's starting to get to the point where you're like, OK, this is like doing what I want for the most part cool. At that point you're ready to share your transformation, so we make that really easy because we have this notion of a transformation definition registry, um, which is just something within an AWS account, um, if you give someone the right IM permissions and, and the transformation definition is just a, it's an honorable AWS resource we're not reinventing the wheel here with permissioning and resources, it's the concepts you already know and you're used to, um, you can make the transformation definition available to other users in your organization. They can pull it down, they can execute it on their code, they can propose changes back to it, and everybody is happy. And once you have the application owning teams somewhat happy with the quality, um, you can start running it at scale and you can do that in the form of a push campaign if you like where, um, some central team pulls down a whole bunch of code from a whole bunch of teams, executes a transformation. And sends the resultant code out to be reviewed by the application owning team or you can do it poll campaign style where you tell the application teams, hey, you must blah the blah, you know there's a top down mandate that you must blah the blah, um, but I'm gonna give you this thing you could try running it hopefully it does most of the job for you and makes your life a little easier. And humans verify and the continual learning goes back into the transformation definition. Super cool, right? Um, we have been eating our own dog food as we do at Amazon. Um, we've built a whole bunch of transformations that we thought were useful using this, and we have done some pretty comprehensive benchmarking on them using internal AWS code and some open source code, um, and so we have this little menu of transformations here, um, notably Java, Python, and node runtime version upgrades, um, AWS SDK version upgrades for those languages as well. Um, that we are confident in that I'm putting my name on that we believe are pretty good and we give to you and you can just run them. You don't have to create a new transformation at all if you're trying to do Java, Python, or node runtime upgrades or AWSSDK upgrades, just use these and they should get you most of the way there, um, and if they don't tell me and I need to fix it. Um, beyond that we have a couple of early access things that we've also released, um, so a tech debt analysis slash documentation transformation. This one's pretty cool. Um, it'll go through all of your code if you've got something really old and poorly documented and generate what Veno and I think is like a pretty comprehensive documentation set of it, including entity relationships, sequence diagrams, lots of pretty images. Um, full dependency trees and stuff like it's like every way you could think of to represent code without having the code itself we try to, to capture in here and as a bonus it gives you a little report in there that says hey you're using a super outdated version of this and that and this and this is vulnerable and like you might wanna check these things out. Um, and then we also have an upgrade that we're working on with the Graviton team in AWS, uh, to, uh, convert Java code that uses X86 that has dependencies on X86 libraries, uh, to Graviton, that's early access, doing pretty well on benchmarks. We'll probably mainline that one pretty soon. These are not set up for you. They're validated by us. We have a pretty comprehensive benchmarking infrastructure to try to get the quality on these really good. Beyond that you can build custom things. You can build VBA to Python. You can build, you know, I don't something crazy and unholy if you really want to, um, I would recommend using it for API upgrades, language version upgrades. You can use it for language to language conversions, but I would caveat like in a localized context if you have like a. 500,000 million line of code old .NET app and you wanna reimplement it in Java, you're probably not gonna have a great time. The models aren't quite that good yet, but if you've got like a whole bunch of scripts that you wanna convert from one language to another that are relatively self-contained, it'll work pretty well for something like that. Best practices because that's what we're here for that's like the title of this thing I think, um, pilots start building a transformation it's not very hard and then just run it on a few things at small scale and that's how you get a feel for the efficacy that's how you get a feel for what it's going to cost. So pricing for this is entirely usage based. It's based on, uh, agent minutes which is just kind of an abstraction on top of our cost for providing the service. Um, it's 0.035 cents per agent minute. Um, a typical 1000 line lambda costs about 1 buck, I think a 5000 line Java runtime upgrade costs like 4 or 5 bucks. Um, we really intentionally priced this thing very low, um, to make it up on, on scale. So we want to incentivize y'all to create transformations that do what you wanna do and unleash them, um, and, and just build a lot of scale. Um, Plan, refine pilot. I think you all, you all get the picture there. And another best practice is use your current workflow. There's a lot of code transformation products out there that I've seen that kind of ask you to onboard to a totally new way of doing things, and I think that's lame. Um, so we've intentionally built this to be a CLI that has very minimal dependencies, that has a dependency on node, a dependency on Git, and a dependency to have an external connection to our, to our service, to our AWS, uh, servers. Um, if you have a machine that has a Linux environment, um, Mac OS also works. WSL also works. Ben who's gonna demo this on WSL, um, has those dependencies. You can, you can run your transformation. So people stick it in pipelines, people stick it in docker containers, people stick it in AWS batch jobs. People stick it on laptops in their basement. Like, I don't care how you run it, um, whatever works with your current way of doing code modernization and doing deployments and stuff, it's designed to be minimal and just slot in. And I would be remiss if I did not plug our AWS Transform web application. So if you heard about AWS Transform last year, um, this is all there was to it. We didn't have the CLI, the CLI and custom is the brand new thing this year. But there is integration between the CLI and the web app. So if you are a program manager, a campaign manager, you're responsible for doing a bunch of code transformation at scale, and you want a place to get pretty charts and graphs to show your boss and stuff. Um, all of the status of the campaign that you're running, um, in the CLI is automatically populated in, uh, in the AWS Transform web app where you have pretty charts, pretty graphs. You can see what repos have been transformed, which ones have been validated. Um, and of course you've got the agentic chat there so you can ask questions about the data. You can say what proportion of them, you know, fit these criteria, how many got done in the last week, which ones had failures, whatever you want to ask it. All right, now the fun part. Cool. Yeah, thank you. Thank you so much, Morgan. I have a question for you before I get started. The customer asked, Can I do Fortron to Python? What's your answer for that? Um, how big is your for trend? How that that's that that's the question, right? If, if you have like you can do hello world any language to any language and beyond that the complexity, you know, it varies. I don't, I don't wanna like over promise to anybody, um, we have a customer using some weird esoteric old language called progress that I had never heard of before that we didn't know if the model was even going to understand, and it totally groks it and they're putting like 100,000 line of code repos in there effectively and making changes, so, um. Again, I, I said best practice pilot before. Just try it. It's cheap and easy to start and try. We made the installation as easy as possible. It's one curl command, um, to pull down our, our CLI and, and start trying it out. Oh, thanks, thanks for that. OK, let's now do some coding, live coding, right? Um, so, um, the way that I've set up is, uh, so Morgan talked about the built-in transformations as well as the custom transformation. And doing it at scale. So let's uh see if we can do all of them, right? So let's start with the out of the box transformations and um let's see how it works, right? So the first thing is, I mean, um, this is a command line interface CLI you can install it on your laptop so I'm gonna use a WSL environment on Windows, uh, Mac and Linux is supported, so I've already installed it and um I'm just gonna start with uh the my first command. Um, so like Morgan mentioned, this can be run as an interactive mode as well as non-interactive mode. Non-interactive is basically a bunch of commands. You say, hey, ATX, run my transformation on these repo. We'll just go do it for you, or you can interact with this, give some feedback, and do it interactively as as well. So we'll show both of these, uh, uh, modes right now. So first thing, uh, I'm gonna list, um, it says, hey, ATM ATX custom, that's AWS transform custom. Uh, definitions list, OK, List all my definitions, right? OK. OK, so I have a bunch which I've built, but let's go through the AWS managed ones, right? So we have 8 AWS managed transformation which are out of the box, 0 setup, you can just get started. The AS AWS SDK V1 to V2, Node JS Python upgrades, uh, PO 2 to Porto 3, Python version upgrades, lambdas and non-lambdas as well. Same thing with Node JS. And early access we have the comprehensive code base analysis which Morgan talked about and Java version upgrade again it supports Ma cradle uh build systems and X86 to Gravita and these are some of the user transformation that I built, um, for, uh, demoing to customers and, uh, for my personal use as well. And this is the registry that, um, you see so it's basically published to the registry. So once you publish it, any user in your AWS account who has access to this, uh, CLI and, uh, IM proper IAM permission should be able to view it, just download it and, you know, run with their project. You're better than me when I demo it. I just use the AWS internal registry and it shows like 350 transformations, which is good. A lot of people internally are using it. Yeah, so awesome. So let's start with the first one, right? So I have a lambda function here, um, it's basically a to do, uh, application. So let's start by running this transformation on this lambda function, right? Um, so. And this is the command that I'm gonna use, right? Let's, let's put this and then probably explain what I'm, what exactly I'm gonna do, right? So this use case is basically, hey, you're just gonna use out of the box, you know what you're doing. You have a bunch of lambda function go run it right again zero setup just go run it without creating your own transformation, right? So I'm gonna say, hey, ATX custom exec exec is execute, and this is minus P is the where is the where is my lambda function located the file path on local disk, yeah, local disk. And uh minus N is, uh, the Python version upgrade that you saw from the out of the box list. C is, uh, I mean, the build command that needs to be used. So in case of this Python, I'm just going to use no operations, but for Java you'd use a MVN clean install or something like that, right? And the configuration is basically additional context that you could give, right? Uh, that's the, uh, basically what validation command I need to use, right? Hey, you can say, hey, I'm gonna just run P test to make sure all unit tests pass, and you can also give, it's basically free form you can give additional context here, uh, of running this execution, right? And I'm gonna say, hey, since this is very generic, um, it can go from any Python version to any Python version, so I'm gonna say, hey, go to Python 3.3. Minus X is basically non-interactive, which means, hey, go run it, uh, and then minus T is trust all tools. So in case of interactive mode, you might need to trust tools to write files, read files, all those things. So I'm gonna say, hey, trust all my tools, go and execute it, OK? So let's execute this. All right, so it started, uh, the transformation right now. Let's see what it does right now. Um, so basically the first step it's going to create a conversation lock where you can track all the progress and monitor all the progress on the conversation log, and you can resume these conversations as well. Accidentally your network got disconnected and uh you control Ced. um, there is a conversation ID you can just resume this conversation. That's a neat feature because I mean uh sometimes. Things happen, right? Internet works down and, uh, you know, you, you have to uh reconnect. You can do that here, right? OK, so let us do this job, uh, right, uh, and I'm gonna show you an output what I did earlier, uh, in the day for the same transformation, uh, how it is going to look like, right? So I have a dry run folder here. I just ran the same transformation earlier in the day. So basically it ran and uh it. It created the plan, it created, uh, the, completed the changes, and, um, it basically converted my Python function from 3.8 to 3.13. And let's see some of these changes, right? Because this transformation might take anywhere between 10 to 15 minutes. I don't want you to just start my screen, so we just, we are working to make it a little quicker, but we figured it's better to be slow and right than fast and wrong. So we optimize for right now we're gonna optimize for fast, yeah. Cool, yeah, so this is the, uh, same, same project, so it did a 3.8 to 3.13 migration and, um, so basically did a runtime upgrade and, um, daytime, uh, was modernized in this, uh, uh, new versions and it also added, um, 17 to 32 passing test cases and, um, again it documented what it did, uh, it also did, uh, improved interpreter performance. This is all built in. I, I didn't give any instruction. It is all built in, right? So, and it did not change any business logic, no braking changes. All those things are, um, you know, um, uh, kept. OK, so it updated the read me. These are the files changed. Uh, I just did a get diff. So what it does is once it makes the changes, it actually creates a local branch for you and commits all these changes. So which means at any point in time you can go to the commit ID, rollback, or, you know, you can just compare and then review it and then check it in or push your code changes. It's especially useful if the agent like does the right thing for like the 1st 3 quarters of the transformation and then goes off the rails and you're like I don't want all that work to be wasted like you could just revert to a previous. OK, so some of these files, it basically changed all the time zone things and uh the main lambda function, it changed a few of the functions and also requirements.t and it also changed the template. AL. This is, uh, I think, uh, this is a cloud formation template I had, so it changed from 3.8 to 3.13 for deployment and, um, it also uh it changed deprecated APIs, documentation updates, all those things. So again just to summarize this. Just go run this out of the box transformation if you have a very similar use case for your project, right? So, yeah, that's the first thing that I want to show, right? Um, anything you wanna add in out of the box? No, I think that's good. OK, let's now come to the fun part where, how do you want to create your custom transformation, right? So, So here I wanna show um an internal library that our internal team used um the same product for migrating it um internal ticketing system so we had something called Fluxo which Amazon's internal ticketing system uses that's very old, not uh not uh very hard to maintain so we wanted to change to something called Ticking that's also an internal system but that's more API driven and, uh, more, uh. Performance performance oriented so that's why we wanted to change all our projects which uses Fluxo to T a library, right? So that's again Java based, but uh this is very specific to Amazon, um, not the, the large language models does not have pre-trained data on these things. So that's where the power comes in where you can feed in data or context from your organization. To teach the agent how to do this stuff and then so it can do that migration at scale you've got some weird proprietary library that no one else in the world uses you know that's what we're trying to trying to show here. So, let's go to this one. OK, so. Let's go here. OK, the other thing I want to, um, also mention here is, uh, this connects to MCP servers, which means that you can pull in data pretty much from anything, right? So I have this, um, uh, Fluxo, um, ticketing migration guide which we have prepared, uh, like, uh, and then I'll just put it into my GitHub repo. It's a private report, so I'm asking, um, uh, ATX custom to pull in that information from my internal repositories. And then use it as part of your creation of the, you know, transformation definition, right? So I'm gonna do this in an interactive mode. I'm just gonna say ATX, um, that will open an interactive shell where you can interact with it. So I'm gonna create a definition based on the migration guide that I have and then review it. Give feedback then execute the transformation on that and the cool thing about this guide, by the way, is if if this is that guide I sent you, this is a guide that was written for human users in Amazon published to a wiki to go and do this work like someone already wrote this guide assuming developers were gonna have to do it, so we're just giving that to the agent, no extra effort, yeah. So I'm just going to say, hey, create a new transformation. OK, this is the interactive mode. OK, so it's gonna ask you, hey, what do you wanna do, right? Language upgrades, framework migration, library upgrades, all those things. I just wanna say, um, internal. Library migration. From Fluxo to. Ticketing. Again, the large language model does not know what, what, what the hell is fluxo or TT, right? That's where I'm going to give more information, right? First, it searches in the registry. Hey, somebody already created this, um, definition or not. If not, it's going to create a new one, right? OK, so it's asking me, hey, what kind of application libraries it has? What are the main functionalities, what programming language it uses? Hey, do you have any migration guide, documentation, example code that you can give me that I can learn from it, right? I'm gonna just say, um. OK. And he referred to this, um, uh, you know, MD file using my GitHub MCP server. It takes a bit for connecting and, uh, getting the right information. Basically started using the, uh, you know, MCP tool. Again, trusting this tool. You can also just give it a local file path to a pile. Yeah, you can download it and give, but I just wanted to show the power of, hey, you can connect to your existing environments. OK, so OK. Always fun with the Live demo, but yeah, it's, it's doing it. OK, while, while this is running, I mean, um, I think I was talking to one of the customers here, they had a use case for a. I have a prompt already written using Quiro, uh, for increasing my unit test coverage, right? Can I do it on thousands of my repositories? Yeah, absolutely. That, that's where the power comes in. Hey, you already solved this problem, automation problem once with your existing AI tools. Now you want to expand it or scale it to all other teams, you could definitely do that with, uh. Creating your own custom transformation. Another scenario I've heard of from customers that I thought was pretty cool is if you wanna make your code AI ready, like you wanna write a cloud MD, a Kiro MD file, um, for every repo under your ownership, and you wanna follow, follow certain conventions but incorporate aspects of the, of the code there, um, you can define how you want those agent guide files to look in Transform custom and have it go just write all of those files for, for all of your repos. One thing is, uh, when you have multiple problems and the emergency and sequential one. One from. The other That another problem which that's. As Mr. K. So it's a sequential execution of multiple. Um, it's kind of a. Right, um, so. So it's not exactly a sequential execution of prompts. There's, there's, um, several agents under the hood. There's a planning agent and an orchestration agent and execution agent, um, so the first thing it does when you execute a transformation is it's gonna look at the transformation definition which itself has some steps and guidance. It's gonna look at the code you're asking it to operate on and it's gonna say, OK, given. These instructions in this code let me develop a plan for doing this execution on this particular piece of code, um, and it will show that to you if you like and you can approve it or tell it to make changes and then it's gonna go through those steps and each of those, um. It's kind of sort of like a prompt, but there's there's sub, it's not just a single one shot there's substeps in between it because after each step the agent is going to call a validation agent. It's gonna make sure, hey, does this code still build? Does, um, what I, the action I performed in this step actually fulfill the original intent of this step based on the plan. I. So do we, do I need to remove one? I see. And the reason why you are validation is that. I. Validates what it does, right. If, if I'm, you know, if I'm doing data transforms. I'm doing it, so do I need to Reduce the from So what I would do is I would take that prompt. I would give it to AWS Transform during the transformation creation process and just tell it, here is a prompt I wrote for Quiro to do blah, and it's gonna say, cool, let me look at, you know, this prompt, and there should be aspects of it that are directly applicable, and I'm just gonna incorporate that into my transform transformation definition. Um, there's aspects that may ask for your clarification on, um, but it's gonna take that kind of raw information and put it in, in a structured way that that it knows effectively executes transformations with this thing. That's where the refined part also comes in where you saw, right? Once it generates basically converted your prompt into its own, you know, uh, what we call as the definition that's where you can review it, you can edit it or you can just give feedback saying that hey, I really don't like this validation step can you add more right to this phase? It should be able to accommodate that. It would be if I had 3 prongs right I need to sequently. I. I, I mean that that's, that's something you need to experiment, right? Uh, first I, I would start with one, how it creates it if that's not what you wanted, maybe split it into multiple parts if everything can be, um, you know, contained, yes, multiple prompts, but again, as Morgan told it's basically a CLI so you create 33 transformation, execute this in a batch, should be able to do that as well. When in doubt, I like to tell people to break down problems as small as possible, as atomically as possible because you'll get better results there, but you know, for really simple things you can mash them together and it'll probably work and might save you a little effort. Yeah. OK, cool. It actually created a transformation definition, so let's look at the transformation definition. OK. Wow, it really It's very comprehensive. OK, so this is the transformation definition that it created, right, for the fluxo to Ty, uh, migration. So let me, oops. OK, so it has a clear objective. Hey, migrate code from my deprecated Fluxo ticketing library to modern ticketing, uh, SDK, and what is the summary? What exactly it's going to do? What is the entry criteria? Entry criteria is basically, hey, how do you want to take this code in, right? Um, so here it says code imports or uses the Fluxo Java client. That's, that's the entry criteria, right? Entry criteria is really cool, by the way, because that's how the agent knows does this transformation apply to this code. So if you point the agent at a whole bunch of random code that does not use Fluxo, it's gonna read it a little bit and be like this doesn't apply skipping, um, so in the near future we'll have an assessment capability where you can point, um, the agent at a whole bunch of code and it'll tell you before even transforming anything these transformations apply to this code and you can kind of stage it out how you wanna do it. And implementation step is basically step by step instruction, uh, from, it basically got information from the migration guide how to do this transformation. First, hey, step one, update the build dependencies and it basically broke it down into, uh, these projects. And client initialization, basically how to initialize the new client. And for basically covered for Python TypeScript, all those things as well and. Get ticket operation. All the APIs are also covered, right? So the, these, these are the implementation steps, right? This is where, um, you know, you as a domain expert, you can come in and, uh, say, hey, it looks good, it doesn't look good, do you want to change it or or not, OK? OK, the last thing is the validation criteria, right? Um. Yep, so the validation or exit criteria, what is the goal that it want to the agent wants to achieve? How, how am I going to satisfy? So this is where again we need to be, uh, very cautious on how do we define this validation criteria. It could be just simple as, hey, my build and unit test pass, right? Or it could be very complex as, um, so one of the customers is actually doing an angular to react migration. They actually use a playwright MCP server to compare visually. Hey, my angular and react doesn't look the same. So it could be complex as that, right? So you, you could, or it could be deploying into an AWS environment checking if it works or not. So, so that's where our your expertise comes in. How do you want to validate if this migration is successful or not. All right, so this created a, uh, a good transformation definition and as a human in the loop, you can view it, you can, uh, modify it based on the feedback or apply it or publish to the registry. OK, so let's apply it first for a sample project. OK, so now it's asking me, hey, where is your code repository? And I'm going to give this. This is again, one of the sample projects that I have which is in Fluxo that I want to migrate to Tikiti. OK, so I'm gonna say, OK, go ahead with this. Now, again, it's gonna do the same thing it's gonna um go analyze the entry criteria, all the project files and, um, you know, start the transformation project. So that as Morgan described first it does a planning so where it plans, hey, how am I going to apply this definition on this current project, right? What are the file changes that needs to be done? Again, here you have an option to modify the plan, uh, give some inputs. Hey, this step does not apply to this project, so skip it, right? You can do those things and then once the plan is approved, it goes onto the execution mode, OK? So let's see the plant creation. Anything you want to add to the planning or the steps while it plans. Um, the important thing to know is that it's totally optional to, to review the plan. You can tell the agent just, just go for it, um. It just depends on how hands on you wanna be. That's why I mean, as, as we've mentioned before, this thing can run in in very human driven like you're watching every operation that it does, approving every tool use that it does, watching every file manipulation that it does, and you can always control see it and pause it and tell it don't do that, do this, um, so if you've got something really complex or a piece of code that. Um, you know, you're very sensitive about it or whatever, you can watch it every step of the way and very carefully guide it, um, or, or you can YOLO mode it and just tell it do your best at, at everything, you know, it depends on how confident you are in the quality of your transformation, how risky this transformation is, is to you, and, and all that, so you can be anywhere on that spectrum. Yeah. And the other thing is, um, and, uh, while, uh, during the execution, it also the validation, right, it validates it and if there are any errors it self debugs the errors and fixes as well, right? We do have a self debug and, uh, uh, validation agent which does that automatically for you and if you can't fix them. We try very hard, so LLMs like to do this fun stuff where they really so badly want to say that they did the job. I mean we've tried to beat that out of the agent as much as we possibly can. Um, early iterations of this would delete tests to say all the tests passed, like all sorts of crazy stuff. It's, it's awful. So we've built as many guardrails as we could think of to prevent this sort of behavior and try to enforce some honesty here. So if the agent is like, I did, you know, 5 out of 7 steps and I had trouble with these two, and here's the trouble that I had like. We really try to make it honest because if you just go pop this into, into a cloud or something there's a good chance like you'll everything will look rosy until you dig into it um that's, that's something we've encountered previously. You guys are seem to be very focused on code itself, like, like language code. We have a challenge with cloud formation and modernizing the CDK. Is that the kind of thing that this tool could do? There's people doing terraform to CDK right now with this. The, the way I think of it is if you've got any structured text and you want to turn it into structured text that looks different, yeah, you could do that. And then you spoke a little bit about uh deployables right so like actually deploying into accounts and validating the deployments worked, being able to do green or or compare A to B between what was there and what could be there, right? I mean all capable. Uh, right, it, it's possible if you build the scaffolding around it, right? Like we're, we're giving you, uh, put in, put in text files and have different text files come out, and you can build the scaffolding around it to deploy it and return to the agent information about, uh, validation results and stuff with the glide tool being the, the sort of mechanism for interaction. So you're, you're scripting around that tool to get it to do the other things that you want it to do, but then turning to that client to, to do the transformation. Exactly and, and honestly like there's I've seen two extensibility approaches taken and it kind of depends on what's working better for you so you can, you can wrap our apply tool in your own stuff or you can tell our tool to call external shell scripts, external MCP tools, and, um, both approaches work. It just kind of it's, it's what's better for your scenario. The transformations importable export. a.m. Right, one of my core tenants when we wrote the product requirements for this was that they would be importable and exportable because as far as I'm concerned this is your IP. I don't want anything to do with it. Keep it secret, open source it, whatever that's, that's, that's the customers, um. They are fully exportable right now and they are 90% reimportable and the reason I have that asterisk is because, um, the rag, the knowledge items that that it discovers during execution, uh, rehydrating the rag database where we store those, um, is not something that we have gotten around to being able to do on the import side so you can absolutely export it and you can mostly reimport it and we're getting that to to 100%. Can you distribute this around an organization like I know you guys were talking about within an account, but, uh, I mean we're running this, we're running an organization, so could we have a central account where this stuff lives and then be able to distribute that out across. Cross account sharing is something that is on our list. It is not there yet, um, but in the, in the interim you can, you can export it literally when you export it, it comes out as a zip file with a bunch of stuff and then reimport it and you're not going to lose much and, and I can talk through what you'll lose and how to get around it. Yeah. Can they read from for the reason uh for the The Like show 8 to 170 transform. So can I exclude So you can view the plan that it generates for upgrading um your code with for doing that particular upgrade on your code um the actual transformation definition that we provide you um we had lots of fights with legal about this uh we do not share with customers at this time that may change if I get my way but we don't share that right now. But you can extend this. You can extend it with additional plan context and other things, but you can't really view it and modify it right now. It's a black box that you can tack things on the outside of, and I would like to have it not be a black box that you can modify, but um we'll we'll get there. OK, so this is the plan it generated plan again as I told it's basically how do I apply my definition to this project, right? Hey, first update the build dependencies, then do the client initialization and what files are going to be changed, uh, what is the validation criteria here, um, all those things again here as a human in the loop you can basically review the plan and, uh, you know, provide input here I'm gonna just say hey looks good. Receipt. So this will be able to uh do that. Again, in the interest of time, I'm gonna go to my completed one. I'm gonna show how exactly it did it and how it created a summary, right? So this is one of the things that I did in the morning and so this is the, um, migration summary it created. So what, what has been migrated to, uh, Fluxo from Fluxoso Tiketi. So the dependencies this Fluxo Java client has been removed. It added the TT client authentication, client initialization, uh, what it did, what are the changes. Again, get ticket operation before and after code snippet. Basically it completed all the changes that is required for, you know, documentation updates and, um, other things for migrating so. My proprietary internal library to another version or, um, to a different system. Cool. So just quickly going through, I have two more things that I want to quickly show. One is the talks that I talked about again, um, you saw in my, um, you know. Uh, in my list, there is a comprehensive documentation analysis, um, like I'm just going to do again. So that's basically um. Going through your code documentation, documenting all the code as well as uh creating the tech depth, uh, uh, you know, analysis for your code, so. So this is, this is an early access. So basically deep static, it does a deep static analysis of code base and then, uh, generating it, right? So I actually did this for one of the projects, uh, I don't know how many of you are familiar with Doom. Doom is a, um, you know, uh, gaming engine that I that we all love to play, and that's basically was, I think it's 1990, uh, it was created. And this is pretty much the uh documentation it had. This is the original documentation hey, go use Doom that that's about it, nothing else, right? So I ran my documentation, um, code base analysis on that and it actually created this documentation folder, right? Basically, um, created a complete read me what exactly this code does, you know, what are the quick stats, what are the documentation structure. Basically it created subcomponents. One thing I really like is it creates kind of this navigable structure where the markdown files you can click between them and it'll like navigate through them. It's like kind of a pseudo um. Web page if you will. Yep. So, OK, so project overview, it created a project overview. And the file inventory, um, how many total lines of code, what are the things. And from architecture, it basically created a components. What are the components are available. And basically created a dependency mapping tree as well, a main program, game systems, core subsystems, and then the utilities. OK, and what are the patterns this has basically analysis, architecture, system overview and behavior is basically the business logic like the use cases and uh behavioral documentation as well, right? Or what are the weapon properties, weapon mechanics which is used in the game, vision logic. Basically how the decisions are being made in the code, error handling workflows, what are the workflows. So basically, it created all the workflows for me. Make sure you see the diagrams folder too. I like the pictures. OK, I don't, I, I don't know. OK, maybe it didn't. Oh yeah, OK, maybe it created, yeah, there you go. So this is the component diagram. That's a main engine, main program, game render, sound network, play simulation. OK, and abstraction, foundation, external dependencies. Cool. And also the main thing is the technical depth. OK. So, basically it's some code from 1990. I found a few, a few things. Security or other security vulnerabilities, outdated platform dependencies. Carmac probably knows better than us, but. So, OK, 1990s C coding practices. So, yeah. OK. OK, cool. So, The last one I want to quickly show, I know we have 10 more minutes, uh, is the batch, right? Um, so. So how do you wrap this clay into a batch and run it across multiple repositories, right? Uh, again, I use Skiro to create a batch and then, um. Basically an ATX batch launcher. It basically takes the input of a CSV file which has my GitHub repositories, and I'm gonna actually run this documentation on multiple GitHub repositories and then go, hey, go run it, right? And you can also provide additional context. What is the transformation name, right? So basically this is the CSV file and I just wrapped my client into a batch script and um I thought let's run this, right? And I'm gonna run the script. I'm gonna say, hey. Launch launch this batch script with the CSV file in a parallel mode, maximum 10 jobs. You, you could increase it and this is the output directory to, you know, uh, this is a clone directory to download the clones from GitHub and then, uh, what is the output directory where you need to, you know, um, uh, do this. So let's do this. Oops. OK. OK, so I'm in a different directory right now. Give me one second. OK, so that's basically. Checking the version and Running these commands, starting uh like uh 13 parallel jobs, right? So let's, uh, OK, so it basically downloaded all the, um, you know, repositories for me and then started running this, uh, you know, um, and you can basically monitor the execution logs. It started creating it and you should be able to see the results. OK, yeah, so that's, that's the batch mode basically wrap up your the SEG execution or the ATX execution command and then go run it. Our code name was Super Elastic Gumby, so sometimes we slip and say Gumby or SEG. I was really sad marketing gave us a real name. Yeah. The final thing is, uh, probably let's. And we talked about knowledge items, so I wanna quickly show how the knowledge items look, OK? So I ran a bunch, so I have created a transformation called Java 21 modernization, um, for my bunch of Java projects that I had. So I'm gonna say, hey, I've run this multiple times on multiple projects. So I'm gonna say list KI, which is the knowledge items, which is the continual learning aspect where it learns from the agent execution. Um, let's see how that looks. So how we have designed this is by default, it will. Run with knowledge items, which means it will learn from the execution. That's by default. You can say do not learn as well if you don't want to learn and these knowledge items when they are created, they're disabled by default, which means a human in the loop can review it and if they want to apply it for the next time they can enable it. So here if you see some of them, right, um, like this is a Java 21 transformation, right? Hey, it's found hey sealed classes are incompatible with JPA hibernate lazy loading, right? And, um, some of them were very specific. Hey, SolarWins, that's one of the projects I run. It's very projects specific. It's not very generic. And, um, again, springboard virtual threads needs this, right? So, again, I, I'll go, I can go and, and enable it. So next time it runs the same transformation, it finds that it basically applies this knowledge item that memory is already there. OK. I'll give it to you for a wrap up. Yeah, thank you for your time. I, I think that's all we got.