---
video_id: 7e4UeHMMOXo
video_url: https://www.youtube.com/watch?v=7e4UeHMMOXo
is_generated: False
is_translatable: True
---

Good morning. Thank you all for attending Net 331. AWS Cloud WAN MCP server, um. I'm Andy. You can probably guess with the photos who, who's who with Jose, um. We really want to try and make this an interactive session, rather than just fly through slides. I'd like to try and take opportunities to. For you to ask questions, but you're not gonna escape. We've got questions too. Um, so just before we kind of get into this, I'd be really interested to know, um, just with a quick show of hands. From an audience perspective, who is into or is doing like core networking, core AWS networking? OK, and then who's doing more sort of DevOps work? Now, obviously my maths is terrible and trying to gauge it, he's doing both. OK, right, so what's really nice to see is over the last couple of reinvents that who's doing both is really changing. We're getting more and more people now starting to get involved in both sides, which is a which is a massive win. So how did we get here? What, what actually happened with this, I'm gonna go forward a slide and then go back a slide, is I ended up having a, a network similar to this, very similar to this, that I was trying to troubleshoot. And as you can tell, it's a complex network, um, dual. Core networks, multiple regions, inspection VPCs. Network function groups, you name it, it's got it. Um Ah, and going through this. Meant that It was very, very time consuming, and you know, going through each element was very error prone just to work out how do they get to be. What tools did I have to hand? Well, For my for my sins, I'm far too stubborn. Not to have an idea about something and then not at least try and get to the end of it and make it work. Plenty of coffee Um, and maybe a little help from Gen AI. I think the other thing which became really, really helpful is Collaboration So I was very lucky to be able to collaborate with Jose on this rather than doing it all on your own. It's really good to get a different perspective and just someone else to say, hey, hang on, have you thought of this? And I think that made a massive, massive difference. Of course we've been through the network of of hell, which I will call it. Um What options did I have initially to try to Kind of put all these pieces of the puzzle together so, you know, I could quite easily work out paths between A and B, well. AOS console You know, click cops are fine. But unfortunately I've got a really terrible memory, so I never remember where things are. And also it's very hard to repeat. I think click click, the console and click ops are great to learn a new service. AWSCLI if you start scripting the AWSCLI it can be quite powerful. But again, I tended up, I tended to end up having lots and lots of um more complex AWSCLI commands, I was stitching together with a a shell script, and it just became very brittle and, you know, not particularly pleasant. And then Python, uh, using BO 3. I'm certainly no kind of developer, but Jenny, I, you know, if you're using uh an augmented agent to help you with coding, they're very good at coding, and one of the things that I have found is that if you make a good stab at something, and then you will ask your er agent of choice, in this case it'll be Kiro, to say look, why? Why is this not working, and why is yours working, and then give me some output, actually provide some markdown, explaining it. And as you'll see later on in the slides, I'm a massive fan of uh markdown together with mermaid diagrams, and it really gives you some good sort of study material. So the strategic goal was to create something that all of those who who put their hands up for that for being a kind of core network engineer takes for granted, is trace route. So I just really wanted to see, look, from A to B, how do I get there, what's in the path? Not just from a routing perspective, but also security controls that might stop that connectivity. But rather than try and eat the proverbial elephant whole. Break it down into some smaller tasks. For example, I, I'm not gonna read them all out there, but break those out into kind of more manageable tasks. Use Python scripts to try and achieve that. Uh, get some help with an ergentic coding agent and then start taking these kind of discrete scripts and then putting them towards an MCP. A good example for me was. Creating a Python script that essentially found your global networks in your account, your core networks, all of your root tables. I am obsessed with the rich library from Python, it's got to be colorful, um, and therefore, you know, print out each of those root tables, so I can really easily see, look. In each region, in each core network, you know, these are the, the, the, the roots or the prefixes in each of those root tables. So I, from, from here, I wanna pass over to because they start talking more about kind of agents and the delineation between agents and and scripts. Yes, before we get to the actual code demonstrations, let's take a moment to talk about AI agent and MCPs so that we all understand what those are. So AI agents are applications that can reason and plan and try to accomplish a goal by leveraging LLM to do that, and they can also act, meaning that they can call, for example, external APIs. To get more information to accomplish this particular goal. And these applications are something that either you or someone else has created. If you look a little bit deeper, what actually happens in the application, and there is something we call agentic loop. And this whole process starts when it gets an input, so you invoke the agent and you give it some prompt, and this is the goal that the agent tries to achieve. The agent takes this input or the goal. And all of the information that was given to the agent beforehand, so this would be like the persona or any other information and also all of the tool information that it has uh access to through MCPs for example. The agent sends all of this information to LLM and then the LLM starts the reasoning process that can it accomplish the goal with this uh information that it has. If the goal is something simple like uh what is an IPV4 address, it most likely can find the information from its training data and answer back immediately. If it is something that it doesn't know, for example, where is this IP address located in my Aplus environment, it needs to do something else. And it will go to the tool information and try to find a tool that can get this information to it. The LLM then sends the control back to the agent with a specific syntax, specifying that it wants to use a tool with particular arguments. The agent, the application calls, for example, the MCP and utilizes the tool there with the arguments and gets the results back after it has finished. And then the loop starts again, so all of the information, the previous information, and now the new information is sent back to the LLM and the LLM starts the reasoning again that does it now have enough information to answer? If the IP address was not found, it might continue the loop and for example, call the tool again with different set of arguments like another AWS region. Or if the IP address was found. It can generate the final answer and return back to the user that yeah the IP address was found. And the MCP, which is short for Modal context protocol, it is an open source protocol developed by Anthropic. And it provides a standardized way for us to connect AI models to external data sources and tools. Uh, and it's, yeah, very widely used at the moment and of course used in the network MCP that we are demonstrating today. In the AI agent that for example you have created, you would have an MCP client running that can then connect to MCP servers that might be running on your laptop or somewhere remote. Let's take another show of hands. How many of you are currently using scripts to manage your A+S network? OK. How many of you are using AI at the moment to manage the network? There are a few, not that many yet. Hopefully we can change that. But yeah, both of these are still perfectly valid approaches. Scripts are very good in scenarios where you already know what you want to get as an output. So for example, if you want to find the IP address and you know how your network is built, you can just use a script and get the same answer every time and it's fast. But then again if the question is something that is more uh complex or you don't exactly know what you're going to be asking then AI is a really good tool for that. So for example, if you want to ask that can the EC2 instance that owns that IP address reach internet and you might have a complex network, so. And we will see this in the demonstrations. In the demo today, we will be using a live environment, uh, and this is the environment. If you have any questions during the presentation, we can try to do something live also. But behind the scenes there is an A+ cloud one network with two AA+ transit gateways, some VPCs, and uh A+S network firewalls in the mix. But yes, let's go into the code. So I think just before we go on to. The code itself, it's probably a good opportunity. Has anyone got any questions or uh kind of any thoughts at the moment that you wanna ask? Wow, OK. Alright, I'm, I'm gonna coax a question out of someone at some point. Can you switch over to the. Yes, so today we will be using Kiro CLI as our AI agent. And let's load that up. It will be initializing 2 MCP servers. We will be using the AWS Network MCP server and there is also AWS Knowledge MCP server available for us. And the first thing is I will be switching to a Predefined agent. So as I was mentioning in the start, so when we are sending the information to the LLM, we can have some information in the AI agent itself. So here we have specified some more detailed information what the agent should do and some networking examples there. And we can also take a look at the tools, so we can see that here is the interbus network MCP server and the tools that are available to us at the moment. And before going into the demonstration, let's take a moment and look at the code that is behind the scenes. And this is one tool that is uh within the network MCP server, and all of this has been built with the fast MCP framework. So the first tool that we are looking is uh get cloud one details, a pretty simple function, but uh this gives us possibility to look at the. Structure how it has been built, so there are 4 arguments uh in this uh tool. With two of our mandatory ones, so core network ID core network region. Core network ID is the idea that, OK, which we want to get. The core network region is one of the key design choices that we did for this MCP. So we wanted to be able to switch between regions and accounts as easily as possible, so all of the tools have this region capability within it. So the LLM can decide that it will call, for example, US West 2, EUN 1, or any other uh region that is available. The 3rd argument is next token, and this controls a pagination for core network attachments. There are basically two design choices that we could take. Either do the pagination internally within the tool and return everything immediately, or then let the LLM control if it wants to get more information. And for this particular tool we have taken the approach that, OK, the LLM can decide when it wants to have more attachments, uh, given to it. And lastly, there is the profile name, as mentioned, we want to control or keep the LLM control to go to different accounts so it can use the ACLI uh name profiles to switch accounts. Also important information is the description. So we are using pedantic, and the description field is one of the details that is sent to the LLM when it starts to do the reasoning which tools to use and how to use those tools. So the description set for the arguments, uh, is an important detail also. Moving on, we have the duck string for the tool. And this is again one of that information set that will be sent to the LLM so that it knows how to use it. We will first give some. High level information that you can use this tool to get the cloud one core network configuration and state. We have also given information when to use this tool, so for example, when the LLM is doing or asked to do troubleshooting or understand network topology. And this is part when we were testing out these tools, how to create this, that this really makes a change, how well the LLM can execute, for example, in complex scenarios when it's doing path tracing, and it needs to use multiple, multiple different tools. There is also information on workflows, and for example, depending on the tool, there might be a lot more information on the workflows that after calling this tool, what are the most potential next tools that would give it a good enough information. So for example, here it's stating that get cloud one roots or detect cloud one inspection might be good approaches after this one. And finally, we are specifying what information will be returned, so it's returning a dictionary containing the core network information, life policy, etc. Then the actual code itself. Kind of basic uh Python code. So we are using pore library for this to get access to the Aplus APIs. We have a helper method to get AS client which we will be using to get the. Or switch between regions and get the actual repository client. If there is the next token specified, we will just get the list of attachments and return immediately those attachment details and the potential next token. But then the core network policy and attachments, that is also one design choice that we did with this tool is that we don't want to create individual tools for individual API calls. There are other A+ MCP servers that you can use for that, so we try to combine uh and. Kind of like make the abstraction level higher. So for each of the tools, it would actually do multiple API calls, get more information immediately, and keep that back to the LLM. It makes the, for example, troubleshooting analysis faster because there are fewer tool calls and also makes it more efficient from a processing wise because we don't need to send the information back and forth for the LLM all the time. And then for all of these tools, we are capturing all of the exceptions. And we are not handling those within the code. But we are raising all of the errors back to the LLM, so we are using tool error from the. Fast MCP framework and for each of the error we are specifying some details like for example there was an error getting the Airplus core network details. We will also give it some information what to do next, like, for example, validate parameter information, and this might depend on the actual tool what information we are giving back. And then we are also sending the full error back to the LLM so that it can then reason what to do next. So if there was, for example, error with the signing uh to the AWS or something else. And lastly, if everything was good, we will return back to core network policy, life policy, and adaptments. Let's do one demonstration. So we have our agent, uh, and as we saw from the tool, we need to give it the information of the core network ID. We don't know it at the moment, so what we need to do first is, for example, list the current uh networks that we have. So we can ask List the core networks in US West 2, what we might have available. It is using a tool called Listcore Networks. And it found out that there is one core network in the US West too with just basic information, so we know the core network ID and state, but uh nothing else at the moment. Uh We can also ask to get more details. And now hopefully it will use and it will use the get cloud one. Details And after this call, we are now actually getting more details of the core network. So it's you creating the basic information in the start, what is the name ID, uh, and its date. It's also starting to pass through the core network policy. So for example, pulling information what its locations we have, what are the ASN numbers. Segment information. Which segments we have and which regions. And also more details, for example, from network function groups. And to control and the DPC attachments or all of the attachments that we have specified. And if we would want, we could then go in and ask more questions, for example, more detailed question on the attachments, what the each of the attachments are, and so forth. But what I want to show here also is the error handling. So what if we ask something that is not there, um, so if you, for example, ask to get one core network but that we know that is not valid. Uh, get, um, detail. OK, that shouldn't be there. It is again calling the tool. And now we get the error back that the core network ID is invalid and the core network must be following a specific. Pattern and this is the reason why we didn't want to handle all of the errors in the code but actually keep those back to the LLM so now the LLM can give us more information that yeah the ID was wrong and for example, do we want to use the valid core network that it already knew or something else, for example, list more networks. So, so we're gonna move on to, uh, let me just click PowerPoint, um, MCP and agent files. But before, before we move into that, just one thing that I kind of really wanted to emphasize. A design decision was taken really early on. So, Jose's gone through a couple of the, the tools that were used, uh, you know, live demos, demo gods have been good so far. Um, but. This really comes into scripting versus using an MCP. The idea was to. Use the actual agent and the LLM for the decision making, not turn an MCP into like this giant script, where all the logic is built within the script. So the tools and and any tool training that's done will pass the information back to the agent. The agent will then use the LLM to make decisions as to what to do next. And I think that's something that kind of is a really important paradigm to remember. Otherwise you do end up building out this huge. Script basically that just happens to be called MCP um and it, the, the differences are stark in in the the results. Now for the keen-eyed, Of you, uh, you may have noticed that when Ya I went into Kiro, actually there was a. Uh, a small line on there saying AWS network um agent. Why are we using an agent as well as an MCP? So what we found through through a lot of trial and error. Uh, and also trying to build some of the additional logic into the MCP that makes it become huge and, and quite complex is. To actually use an agent, an agent file I should say. It doesn't actually alter the capabilities or the functionality of the MCP server, but it does, it does give you a few things that. Are very, very useful, not just for, for this MCP server, but literally for any. Um, it'll give you a stable persona. So in this example, AWS Network, MCP, we gave the persona of a network engineer. So the, the typical kind of rules that an MC uh sorry, that a network engineer should follow. Um We gave a tool usage policy, you know, when to use which tools. And provided some more guided prompts to provide specific outcomes that we wanted. Uh, what we really found from this then is that, uh, the agent itself. Has a context first, so it looks at the context before it starts making calls. It orchestrates those workflows, and it will provide some sort of overrides and specialization in terms of knowledge and prompting. So the same. Uh, queries or or prompts that were given to the MCP server would have worked. It's just that by using an agent, we get back exactly what we, what we want in the format we want it. So it gives us a lot more control over the. Kind of how the MCP works and and the data that we get back. So from here we're going to go on to. To some videos that that actually will do some demons, so go for it. Because the symmetric. Is that a custom view or is that something that can be I, I do, I do apologize. I didn't quite catch the foot. You use a tool, right? Yeah. Yes, of the The, the MCP that we're talking about today started life as Cloud WAN MCP because it was very geared towards a just the AOS Cloud WAN. But what we found is that if we wanted to do things like uh trace route for example, you know, it goes through VPCs, cloud WAN, network firewall, transit gateway, it touched on a far more technologies than. You would find just in cloud uh cloud, a cloud one. So we renamed that as AWS Networking MCP. Now your question, just to paraphrase so everyone can, who may not have heard it, was the core network tool, is that a specialized tool? Yes. So what you'll find within the MCP server itself, it consists of a number of tools, and those tools are written specifically for that MCP server and get core network. Is a tool specific to the AWS networking MCP server. Um, the AWS networking MCP server was released yesterday, so by all means you can go and have a look at it. Uh, there'll be a link. It's in GitHub AWS Labs, and you can actually walk through and see all of the tools included, plus all the source code. Ultimately this is open source. There's nothing proprietary about this. Jemma. Yeah, you're gonna, yeah. OK, go ahead. Question for you. Yep, the agent also open source that you have wrapped around the MCP server. So the agent, well, the agent that we're actually using, we're using here is, is Kiro for obvious reasons. But um we've also tested it with claud code, uh with VS code, with kind of uh kind of the usual suspects. So that the, the, the most commonly used agents we've tested it with to make sure it works. So it should work with kind of any standard um coding agent. What that coding agent uses in the background, you can choose sometimes. You're, you're limited in choice, but other times you can choose the actual LLM itself, the agent's using. Uh, so for this we'll we're gonna do, um, a demo. Let me just quickly work out where we are here. Yeah, let's do it, I think. OK. OK, let's try. So what we're gonna do here is we're gonna go through and one of the things, look, if you're, if you're using kind of a cloud WAN or you're using any other network service. IP addresses are pretty much common to everything. So Where's my IP? Someone gives you an IP address, where is it? So what we're gonna do is live code, um, a find my IP. MCP server. So, just like when I started originally doing this, not being kind of from a developer background. I did use, uh, you know, Kiro to kind of help me create the initial Python. As a proof of concept to make sure I can get what I'm, what I need to. So you can apply the same principle here with putting in what you want that MCP to do. This is very specific, it's finding an IP address. So we've asked Kiiro to create an MCP server to find an IP address and given it some parameters around that. Kira will now go off and and kind of work its magic, and you'll see here. What it's actually creating, it will create the find IP address MCP server. It, and going back to your, your question earlier, uh, it will create specific tools in the MCP server to find the IP address and there's some additional kind of details that will find as part of the MCP. What it will then do, it will also provide you the JO that you'll end up normally putting in, like yeah MCP.JO, for example, which means that we can actually, Once it's finished building it, we can add it to the MCP or Jason and and and try it live. I need to get the IP address. Uh, with tool. I don't remember what the to name was. With tool AWS IP search with a profile network. So this shouldn't take, it shouldn't take too long. And because, because they didn't provide a a region. What the MCP will actually do, it'll look at all of the um regions your account is opted into and then use an a parallel async function to search all the regions and then stop all of those threads or all of those functions once it finds it, otherwise, you know, it's gonna keep searching all of them. So you can see from here, it's found the IP, the region. The ENI that the IP address is associated with, the sub the subnet. The instance that's associated with the ENI. And um just saying that it's a, it's a private IP address. I mean that literally took what, 3 or 4 minutes to create. Personally, what I think is quite a, quite a helpful tool, um, but that gives you an example of you don't have to be a kind of a a core Python developer, one sec, a core Python developer that's built MCPs in the past. There's a really easy way to get started, uh, using kind of a an ergentic uh coding assistant. You know That pool looks like it was built. To to specifically achieve that goal of finding an IP address is that. The approach that you would recommend rep versus like having MCP to discover information and then. Trying to like You know, piece together like the more generic, like buying all your. All your different accounts and things like that. Yes, just to make sure everyone kind of got the question and please correct me if I if I paraphrase it incorrectly. um the tool here that was built was very specific to find an IP address and then provide some information around the IP address. When you're building a larger MCP server. Is that the approach that we would normally take, or would we look at providing building tools that are far more generic, um. I'll give you my view on this, and then also hopefully we, we, we've got a similar view, but I'll also pass it over to uh Jose to, to kind of give his view on this. So 4 MCP servers. If you take a look at the source for example, of the AWS networking MCP server, you'll find that there's a lot of tools in there. So what we've actually done is there's kind of two ways to do this. There's use a monolithic servado pie, which has got everything in it. But that then starts to become really big, really quickly. Or you can create logical groups of tools in the file system and dynamically load and register those, which is the, which is what we ended up doing. So The tools that we've built are to achieve a specific purpose. So find IP address. Find all of your core networks in your account. Find your global networks. Find AWS network firewall and policies. And then by giving the Information back to the agent. And of course we've used like an agent file to give it some further direction. What we what we should then do is Here, say to the agent, look, here's all the information that we've got, how should we proceed? And then it will, it will then choose the tool training to put in place for specific information. To almost analyze the hop by hop, if you want to do trace route, for example, or if you've got a much more complex question to ask it, it's how to break that down into subtasks and choose the tools that it should use to build that up, to achieve the bigger, more complex picture. If I expand on that, we will see an example of path trace next, but exactly when we were creating this tool, we tried to avoid two specific tools and large tools like path trace. We could just write a script for that, but then it would be a script, so we tried to get or try to hit some wagon of balance that there is a higher level of abstraction, but still that. Yes, we could get enough information to achieve higher goals or more complex goals, and I think the last thing on this that goes back to something I said earlier is When you're using an MCP server, it's being used by an agent that's got access to it. Use that intelligence, use the intelligence and the capabilities of the, the language model, which is very good at taking like tons of data in. I Abs pulling out the data it needs and then doing something with it. And we, we're gonna go through past trace in a minute or trace route, um, and you'll see that, you know, it touches so many different technologies from AWS that if you were to try and build that into one, sort of big monolithic tool, you'd have to cater for every use case where what we're doing is. By calling multiple specific tools. Getting the agent to make the decision about what to do with that and what to do next. Specifically what the find the IP address example and that tool is that based on how you build it, is that why we're getting that output? And for example, if I wanted to include something like account ID would I have to build it into the. UNCP have that context if I were to ask that as well. So because it Because the find IP address itself, you know, has to look through the accounts, look through the regions, um, if you were to ask it something. That By doing The kind of lookups that it's got to do would have the information to hand, it will, it will give you that information back. If it's something that hasn't got anything to do with any of the lookups that it's got, then it wouldn't. Yeah, and that's really why if you build smaller discrete tools and then use the intelligence of the agent slash LLM to stitch those together, you can get a lot more flexibility from that. So you could ask, say, you know, find this IP address and show me the security groups associated with the incidents. And then obviously the um the the agent and the and the LLM would say I can find the IP now what tools have I got available to me to find the security groups? When we go through the, the, the videos here, one thing I'm a massive, massive fan of, not just for these MCPs, but just generally when you're using um an agent is. Get the agent to give you a report in markdown, but also provide. Mermaid diagrams to make things visual, and you'll see why, um, it really does give you a lot of information. So for for this particular one, Do you wanna run the, do we run the path trace first? Yeah. So we've got, what we'll do is um. We'll go, go to the, we've, we've got a recorded path trace because it takes a long time and we've cut out all the thinking parts. So if we go onto the PowerPoint, we get it from there. Yeah, I I just find the oh you've got the clicker. And I think this really kind of brings it, brings it together. Here we go. Uh, right. So what I've, what we've done here. This is the Path trace, and what we're doing from here is we're literally just saying, can you provide a, A path trace between two IP addresses, using the AWS network MCP. Now, this is, this kind of reiterates what we've kind of said around. Small specific tools that provide a specific uh output. That then can be used to chain tools, and the intelligence is all done by The actual agent and LLM itself. So what it's doing here is it's going through a hop by hop, how you would How you do a trace route normally. Which is, there we go, sorry, my apologies, I've er. Just clicked in the wrong place. Oh, is that not? Here we go. So you can see from here, um, once it goes through and it finds your. Source destination, it runs through literally hop by hop what your infrastructure composes of and will record all of this information. Now, what I've done at the end of this is The video's not playing particularly well. Um I've asked it afterwards, please can you provide me a report in markdown with mermaid diagrams to explain what that path trace looks like. This is the path trace report. Now again, whenever you're doing a report with Mark Down, sorry. Ask it to include MCP dia uh sorry, mermaid diagrams, cos it'll produce diagrams like this that actually show you a breakdown of. In this case, the path trace, exactly what the path it took, and it even puts a nice little emoji on there to show an inspection of EPC with a firewall. But it'll literally walk through each component, showing what's there. But then it'll go into more detail. OK, we, it's hard to see from here, but it'll show you each of those hops that it takes, what that's composed of. But as From a network engineer perspective, as we know, the return path is equally as valid because if it's not symmetric, you're going to have a problem. Firewalls are not going to play nicely. So, once it's done that, if we keep going down, It'll give you an overview of what the cloud by and architecture itself looks like. Where the segments. I got to use network function groups. And if you keep going down, it then starts showing you your root tables, we can just kind of gradually go through the rest of it, um, if you just scroll down through the rest. If there's anything really pertinent. So it will also show you your security control analysis. That's network ACLs for anyone who uses them. Firewall. Inspection VPCs, does the policy allow that connectivity? Any particular issues that are identified. And it will also show you your security groups. And then the nice thing is it'll give you a connectivity matrix. Now this is nothing more than saying. Provide a path, path trace. Now because as we kind of said before the questions, that causes a lot of discreet. Tools, and each of those tools provides data. What it's now doing is it's taking all that data and it's creating a, a markdown report for you, but it's using mermaid diagrams as well to give you the visualization where that really helps. So I think um On this one, what it also does, it just provides you some CLI tools if you want to not trust what it says and kind of validate for yourself, uh, you know, kind of each of the parts, each of the hops itself. It'll provide you that uh the the AWS CLI tools. The next one Yeah, go for it, um, on the, on the side, you know, when you went through this, you bringing up this, uh, demo here, it said that you there's a lot of trial and error. Any key learnings of what you tried that? Learn from and not to like when you're building this. Oh wow. Oh wow. Well, first of all, when I had hair. Um, yes, lots. So I'll give you just a couple of the ones that I found that were really key, and then, cos they obviously, uh, add some more in there because. He's got a much stronger kind of development background than I have. So, first of all. If you rely too much on an energetic um coding agent. It ultimately did provide a a a cloudware and MCP server that gave me what I wanted, but it was really full of, for want of a better term, bloatware. There was a lot of things in there that weren't needed, it didn't clean up a few things properly, um, and it didn't give me a lot of control, so. The, the standard in the ADWS labs. MCP servers, bar this one, just because of the size of it, were very much put everything in server PY so you'd have kind of one monolithic file with all the tools in. And we soon found that, you know, once you start touching on Cloud WA, you know, VPCs, firewalls, firewall policies, etc. etc. etc. that that soon becomes huge. And it also means that it's not that extensible. So by breaking that down into logical groups on the file system for Cloudwand tools, network firewall tools, um, it means that, Later on, if you wanted to add some tools in specifically for DPC endpoints, for um. I can't think of anything else, VPC lattice, you know, whatever the case may be. You've got dedicated tools within a directory rather than forever expanding this massive server PY. So I think that was um a key learning. The other one was Test with real infrastructure, often. What I found is when I used mock infrastructure or mock data to test with, er often. It would be left in there and then you'd say, you know, is that, is this particular tool working properly? Yeah, it's great, look. And it says, look, it works perfectly. And when you look closely, it's just using mock data. So I try to, this is just me, I try to avoid using mock data when I don't need to. With the one of the benefits of. You know, doing this in the cloud, we can spin up a Test environment, if it's cloud ra, please then spin it down afterwards, um, but you can test it against a known good architecture, just test often against something, making sure you get the responses you want every time. Yeah, I think that's one key learning also was the error handling. So as LLM tries to be as helpful as possible without good error handling and good information giving back that if something failed, that what it needs to do next and for example validate so we have a lot of information in the tools and there is a specific tool, for example, just for path trace that gives information on the methodology of what needs to be done and in which order. Without that, it tries to be helpful and for example if something fails, it doesn't have access to something or or what it might be, it can just like AI can just go past and say that OK, everything is good and it's working even though it didn't actually verify it. So I think that the error handling is one of the key, key details here just to make sure that you get that right. Can I add just one last one on this is, uh, even before we started using agent files on this. We use an MCP resource to provide a persona. To the MCP server, literally saying, you know, you are a network engineer or network operations, and these are the guidelines. So if you know if if partial data comes back or something, a tool returns data that's not complete. Don't assume it's OK, everything's life is good and everything's OK. Stop, use error handling and report back. Otherwise, you know, it can just la la la, it's all good, carry on, and you know you've got a, you've got a core decision that's led you down potentially a very dark path to try and troubleshoot. Yes. I said issues identified? Is that based on the general guidance and best practice, or is that? Is that included as output when you're trying to troubleshoot? That that's actually included in the output from the particular tool that that found where there was a potential problem, so. That's further enhanced when you use things like a persona or you use an agent file to give it very strict direction, but generally, um, if the, the tool provide returns data where it thinks there's a problem. It will, it will get there automatically so you don't have to go overboard with regard to try and thinking of every use case, kind of every corner case. Correct, correct. I saw that there were a couple more questions, but due time I think that we need to finalize this one and if you have more questions, uh, we will be around here after the presentation. So yeah, what I would encourage just really quickly is that we're gonna be around. Unfortunately, we love talking about this stuff, so um if you wanna sit down and have a coffee and have a chat now or or anytime during the week, just give us a shout. Both of us would love to sit down and talk with you, um, connect offline. So one of the tools that I found was. Very, very useful, because trying to do this manually. It is hard So I tried to explain this to a customer once and I, you know, with I wrote some Python to try and do it and it was very difficult to do. So the, the prompt that was given um to the MCP server was please explain the core network policies. Always plural in case there's more than one. Explain the network function group configuration if it exists, and the almighty, please include mermaid diagrams, where that is, you know, where it's viable. And as you can see from here, it'll actually break down. The policy, it'll show you all of your segments, the segments that are isolated. The segments that I've got. Direct connectivity, which you'll see, uh, you'll see here, because they've got route sharing configured. So it'll actually show you. Not just which segments have got connectivity, but you'll have arrows on there to show you the direction as well. It'll build out a connectivity matrix. And then the really handy thing is if you go down a bit further, it'll actually explain to you, sorry, you go up a little bit, it'll explain to you why certain routes are blocked. So, as well as giving you the diagrams and the explanations, it'll also say to you this is why things work or this is why things don't work. Now the hardest one is the next part, is the network function group analysis. So it'll take the next network function group configuration in a policy. And then build out. Mermaid diagrams to show you each of the network function groups. And their capabilities. So as we go down, you'll see the attachments. The patterns that each of the attachments have got. Send to and send via, and if you keep going down a little bit further. You'll start seeing that for each of the network function groups, you get that visual explanation around how it works. So if you're troubleshooting something. And you're, you're not quite sure if a network function group is doing something specific. You can actually look at the document which will give you a a I say a verbal, a written explanation of how it's configured, but also provide mermaid diagrams to show you how things are configured, where things are blocked, where connectivity is blocked by design, where there's isolation. Now getting that. Just from a JSON document that is returned from cloud one is very difficult to do. If you go down the last little bit, It'll show you the configuration uh of the, Neurofunction group, and it'll give you some of the information in in Jason as well. But using A question, asking it to provide the output in a markdown document with mermaid diagrams will save you so much time. And for learning, incredibly helpful. So as I said before, just to kind of recap quickly, and we've got a few minutes for questions. This started off as AWS Cloud RAN MCP server, but after we realized that it touched so many network services, and the fact that we want to make this extensible to. Any network services. We changed the name to AWS, a network MCP server. That's been released, it's available today for folks to use. It's open source, so if you're, if you're doing something on. Path trace or you're looking at something about, I don't know, getting the policy, and you think I've got a really good idea. Do a PR. Add to it. You know, if you're doing something on. On a, a service that's not there already, so say one of the services that's being announced this week, or um VPC lattice or one of the services you, you heavily use. Do a PR. It'd be really good to, to kind of get community involvement. So that's kind of it from what we were going over today.