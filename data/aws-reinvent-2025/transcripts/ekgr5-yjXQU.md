---
video_id: ekgr5-yjXQU
video_url: https://www.youtube.com/watch?v=ekgr5-yjXQU
is_generated: False
is_translatable: True
---

Hello and Warm, warm welcome to our session on modernizing Mercedes-Benz global ordering system. With Rocket on AWS and also using Gen AI. My name is Manuel Breitfeld. I'm heading the delivery for Mercedes-Benz Germany, uh, at Cp Gemini, and I'm very, very excited to be standing here today, um, with Christian. Thanks, Manuel, and a warm welcome also from my side. I'm Christian, Christian Kleme from Mercedes-Benz IT based in Stuttgart, Germany. And happy to be here with Manuel to make you familiar with our big project which we call Go to Cloud because it's about the application global ordering, in short, go, that together with Capgemini and more partners, we move to the cloud from the mainframe. And I'll actually start by making you familiar a little bit with the dimensions of this application. On the left hand side of this slide you can see the process, the process that is supported by this application. It's if you want the lifeline of our sales operations at Mercedes-Benz. And we always visualize this by using the letter Y because it's the processes that are behind it. If you look from the right hand side, there's all master data creation, so this is how we set up more or less our product portfolio inside global ordering, and this is where the orders come in based on that master data. From the left hand side you can see what we call volume planning or sales planning. This is where we more or less determine how many cars we want to sell, in which market, which type of cars we want to sell, in which period. And then all this data comes together in global ordering and based on this we do the ordering and we also serve production with. The orders, so you can imagine, and that is stated on the bottom of this picture, each and every car that we sell, that we produce, goes through the system landscape, and this is why I actually said this is where the heartbeat of the company goes. And to give you some numbers, only selected ones, I'm not going to read you through the entire slides. We talk about an application that has more than 20,000 interfaces in all parts of our company. If you look at the size of the application in terms of lines of code, we talk about 5 million lines of code in Java and Goal and more or less the same size in the other language. We have a huge workload, at least for all dimensions, so around about 50% of the mainframe workload is with global ordering. And technically spoken, we support more than 800 cues. We support more than 5.1 billion messages per year, and we have 4 450 batches running on the mainframe application, and by this we support more than 8000 users in 150 countries. So it's quite impressive and for us it's super important and this is why we decided not to refactor the application but to go in more steps to start with the replatforming and this is what we want to present today. So how did we tackle this program or this project of re-platforming this important application for Mercedes-Benz? You can see the steps right here, and we started already more than 2 years ago. Once having the idea, then going through the rapid assessment together with the provider Rocket Software, who provides this assessment as a standard service for all applications for all workloads that are supposed to move from the mainframe to the cloud. Having this assessment done, we then looked at the results and initiated the mitigating measures for the trouble or for the issues that we found. And of course we had to calculate the business case which at the beginning already showed us significant cost savings compared to what we have as cost on the mainframe today. And this is more or less also how we initiated the entire mainframe exit program that is running now at Mercedes-Benz, so the entire company is about to leave this platform in the next couple of years. How did we tackle it from a team perspective, so In the end we decided for Gemini Gemini to be our general contractor. So as you can imagine and as we will show later, there's a whole team and a whole a whole number of partners that are acting together here to make this happen, but we chose for Gemini to be our general contractor who manages for us the relationship between the other partners, namely AWS AWS, of course, as the provider of the cloud, the cloud platform. But also Rocket as being the one serving us with what they call the enterprise server, so the emulation for mainframe workloads on the cloud. And of course we as customers, we also are part of the game together, IT and business, which is also one of the key success factors. So then in 2025 we finally got the goal to start the project. We have strong management involvement, of course, which is important, top management involvement. We also applied AI in first some pilot setups but later then also for larger workloads, and Manuel will be speaking about that a little bit more in detail in a minute. And also from our perspective, a clear factor for success is that we go in stages. We start with parts of the application. In this case, we even start with a stateless part of with some stateless services which are part of the application to make sure that we can really run this in parallel on the old platform and the new platform in parallel to be sure that the new implementation on the cloud then also serves. Yeah, to the same levels of service levels as as the old application. And for 2026 we have still a way to go, so we will then migrate the full size application. We'll have to cancel all our legacy contracts, also make sure that the business case really is implemented and realized and the savings really come, and of course set up the future mode of operations on the new platform with the new partners and finally fully dismantle the mainframe, which is super important in terms of getting rid of the cost. Another key success factor is what we call the global ordering facade, and what do we mean with that facade. It's also based on a standard product that we buy from Woolsoft. It's a gateway which allows you to direct the workload that comes from our web clients to either The cloud backend or the mainframe backend, which is of course a very handy feature in terms of testing. But also allows you a very quick way back in terms of trouble and of course that's the most important part, prevents all your consumers from doing huge changes when interacting with you. They simply have to call another URL but will not be impacted by what we do in the background when migrating the application. So this is how we believe we can migrate this huge application with the highest speed. At the lowest risk, also fully integrated in the existing Mercedes-Benz landscape. Being then ready for the future from a technology perspective but still having All options open in terms of modernizing the application and towards a more modern and coordinated infrastructure. One more thing that is important in our project is the platform that we move to. It's not an AWS native landing zone that we're going at. We have mentioned Rocket as one of the software providers many times now. Rocket software is and their product, the Enterprise Server, is more or less the landing zone that we need to emulate the mainframe on the cloud. And this landing zone is fully managed by AWS, so not something that we have to manage from Mercedes-Benz or Germany's side, but we just buy this as a service from AWS. But more than that, Rocket is only the mainframe part. We also have a JavaStack on the cloud. We have some services for batch processing, but also of course for database services. Messaging is an important part. And then all the things that you need on top, of course, like monitoring, like financials, and so on, and the storage part is all combined in this landing zone what we call this platform which we call the Helios platform. It's a Mercedes-Benz internal product that combines some of the services that we need on top of course with the standard services that you find on that landscape that I have just shown. So that's about all, but most important not to mention last but not least is the partnership that we have set up to make this program successful, starting of course with us as the customer who are the ones who want to realize this project. But moreover than the general contract that we have with Gmini. Supported by the two main partners, AWS as the cloud platform provider and Rocket as being the inventor of the enterprise server, the emulation of the cloud of the mainframe in the cloud. And with this, I'm happy to hand over to Manuel, who will make you familiar a little bit with the Genei part of the story, which is of course the most exciting one, so. Go ahead Manuel. Thank you Chris thank you Christian. Um, before we come to the Gurney I topic, um, maybe let, let, let me walk you backwards a little bit. Um, if you're familiar with the topic of legacy modernization, you might know, um, those phases. So typically, um, when we go into mainframe modernization, we look into 4 phases, um. And with those 4 phases we try to find the best solution for that specific problem. So typically you want to start with the assess phase where you look into the whole landscape and now with Mercedes-Benz for global ordering we've also done that, but also C Gemini is doing that application for over 25 years, so we kind of knew already what's at stake. We kind of knew the application. We kind of knew. How it's integrated into the landscape. Christian said it's about huge, huge interfaces that we have to deal with, so we knew that if we don't know it, we, we help ourselves with tools. CAP 360 is one of them. Brad is another one that is also using AI. To determine how do the application structure, how does it look like and how do interfaces look like. So as soon as this is clear and as soon also the client is clear on what the strategy is, Christian mentioned for global order and we've chosen the re-platforming or rehosting, some call it re-platform, some call it rehosting, so basically kind of an emulation on the mainframe with Rocket. As soon as you have that, you decide, OK, this is our strategy. You see the familiar 6 hours, some have 5, some have 7. Here it's 6. Basically, what is your migration strategy for global ordering? We've chosen to go with a re-platforming approach. We wanted to keep the application as untouched as possible and also be sure that the interfaces we have a good way to deal with that. But also, and this is where I'm coming in with regards to AI. At the very beginning we already knew there might be some cases. Where we go where we want to go refactor because at the same time the see dispensers doing their sales operation is refactoring parts of that already so it does make sense from a business case perspective to look into global ordering at once, but also see if there are some slices that would make sense to refactor them. So that was the idea and when we went into the migrate and modernize part. We actually identified the parts where we felt like those would be good elements to to refactor. Janre wife is mentioned in in in the bottom. I'll come to that shortly and obviously not to forget, operate and optimize. We are not at that stage yet, but we're just starting to have first services available where we where we learn how to operate operate and how to optimize them, but definitely a big, big part of of of the story. Um, if we look into the AI and G AI, um, effects of that faces, those are the elements that we at CP Gemini, um, use. So for the assessment I've mentioned that earlier, um, we use a couple of tools that help us. Identify what is the inventory, how is the code looks like, and also what is business cases, what are business rules that are being included in the application. This is where we use Brad, CAP 360, or also Chan Insights tools that just help us to get a bit of an idea on the on the application. The other part is agentic AI refactoring, and I mean if you listen to some of the sessions today and probably also coming this week, that's a big, big story. It's also a big story here. So with Gen revive, which I will come to later in the talk, we have a multi-agent set up based on agentic AI that does transform legacy code into the new world. Obviously we also use coding assistance, so all developers, um, and we've heard it in the keynote as well, like all developers happy to use some assistance while coding. This is also true here. And then when it comes to testing, we also have tools that help us identify was the test successful or is there an error in the testing. But as I said, I want to come to Ja Y, um, and, and this is what we have been implementing in the last, um, basically this year within global ordering. And the headline states kind of the key message we don't just use AI, we want to combine it with with our expertise and our strength. So on the left hand side of the picture you see this is what we, what our team currently still does. And where I believe it's fully essential that they do it, so it's about having. An analysis of the application knowing what do I actually want to refactor. I need to know it Also providing documents. What are the documents that are helpful for the AI to be able to transform the code, right? It's not only the code, it's also documentation that exists. It's test cases that might exist. So all the things that you have that do help the AI to better transform, that's helpful, and you need to provide it. And obviously you need to specify what to do. Like in this case it's we want to migrate from cobalt to Java. So I need to tell, I need to learn, I need to train the AI, how it's done and to be able to do so in January we call it cookbooks. I need to explain. I need to see like, look, this is how you would typically transform that module into that part in Java to give the AI kind of a feeling on what's right and what's wrong. And January. Then in turn has It's, it's similar like a software engineering team. You have the agent being the software engineer. You have the agent being the software reviewer. You have the tester, you have the DevOps engineer, and actually you really have roles you assign to the AI look, you are the agent, you are the engineer, and that agent does software engineering. It doesn't do testing because there's a different role for that. So what what they do. They they they kind of build a software engineering team that is then orchestrated by a human, um, and this is kind of the basis. And while it might look theory on paper, it's actually already in production and has been able to transform quite a number of code from Mercedes Benz. Now looking into that specific case, so I call it within Go to cloud and within go within the application at Mercedes-Benz, there is one service called pricing service consisting of 1.3 million lines of code, 1.3 million lines of cobalt code. And what you see in that on that slide, it's I mean it's kind of the rough architecture it's running on the mainframe. It is split between a Java part which is running on IBM WebSphere. And cobalt part which is on IBM kicks. Both parts accessing the same database. And Java calling in cobalt as well. This is what we have today. And what we've decided is We want to migrate the cobalt part into Java and have just one application after that. So the outcome you see it on the right hand side is Christian mentioned the Go facade. This is kind of the layer sitting on top, this is where all calls go in, this is where we can check, is it a successful. Test case Or is it unsuccessful? This is where we can also route certain calls. So should that call already go on the new Java part, or should it stay on the mainframe? This is kind of retooling that allows us to do testing, that allows us also to control the go live. And also what Christian mentioned earlier is it allows us to minimize changes with all neighboring systems. They should not do a lot of changes. In fact, they only change the URL. And then in yellow you see the new Java stack. So everything which is on the two boxes on the left hand side, we have the cobalt part, we have the Java part, everything is now moved into Java with with general YF, and there is still one problem. Like the cobalt part and the Java part, they have been accessing the same database. And it's a pricing service, but in fact it's kind of, it's also part of the whole global ordering system, so the data in that specific case is still existing on the mainframe. So what we've used is precisely as a tool, precisely is able to basically sync data, lots of data, basically in real time. So what we're doing is to be able to have that data accessible on the news service we use precisely to always sync that data in real time. And with that we not only have the new service. More than in your new target language, we have been able to reduce mainframe costs at the same time and have also been able to actually increase the speed for for the for the neighboring systems. So that's the core concept and I've talked a bit on the story already, but I just also want to walk you through that again. I feel like nowadays with people talk about Gen AI it always. I think it's always better if you show how it actually, how it actually went, um, and it all started with, with a, with a problem. um I think beginning of the year that, that pricing service that was on the mainframe. was was not capable. Of executing as many calls as Mercedes Benz would need for modernizing parts of their new system. So, um, The problem was what to do. Should we up the mainframe infrastructure and try to just make it Bigger to be able to handle those calls or the the other solution was try G AI. And in fact it was kind of drying Jenny I not. Not fully knowing if it would succeed. So that was the beginning of February. But we've decided, OK, let's let's let's try that, knowing that the number of lines of code with the 1.3 million is quite a challenge, but in March, if we look back, there is actually already the first commitment to the GitHub repository, and not too much later in May we had the first version which was deployable. So really in a very, very short time we were able to transform the 1.3 million lines of code into a Java application. And just recently, because so many people are asking now how does that code look like, are you able to maintain it, just recently we've looked into the code and You're not able to distinguish is that code written by a human. Or is it the EI that has written that? Also, to be frank, there are some parts, um, and you see it in the in the additional performance tuning, there are some parts that we did adjust manually. So Especially coming from legacy, coming from the mainframe, where in this case database access is just very, very, very quick. And everything is in memory, obviously that's not the case on AWS and it shouldn't be like that. So there are parts that you need to tune and that the eye in this stage does not know that it should be tuned. So what we did is we looked into all the database successes and this is where we've done some fine tuning to be able to max out the speed that we needed to do. Also, all the infra setup mainframe now is running on AWS and the precisely data string also fully functional then in September and not long ago, I think almost. One month, 1.5 months back, um, there was a big, big go live pharmacy dispense of that that whole system. The pricing services is a part of that and went live successfully actually is is faster than before with with that Gen Y use case. Now having having that in mind and also having that success story checked, we are currently evaluating together with Mercedes-Benz what are other parts where we feel like we will find a similar success story, where are parts where we feel like, OK, we don't want to just. Refactor. We don't want to just rehost. We want to re-factor and we want to use the benefits of Gen AI. So summing that story up, it's 1.3 million lines of cobalt code. It's also 500 megabytes of database database records that are kept in sync in real time, so it's really, really a big achievement. Now one last thing that I wanna come to is the the facade or integration layer that we also call it. Was is now in production. And was really a key element to be able to test. The whole service but also to be able to bring it live so while we did. The the QA phase, the testing phase, the UAT phase, we were always able to use the integration layer. And route calls to mainframe, but also route calls to Java. And because precisely it was still taking care of the database, so it was really clear like from both worlds you should get the exact same result. So this is what we've did in testing we've we've monitored all calls and we've actually looked into the integration layer and it was a simple check like the result that you get from both systems should be the same, right? and and this. Reduce the testing effort. Enormously because it was not only able to check it manually, we were also able to test with real data. It was not like someone who needed to sit and test certain systems. We were able to use and capture real data and just run it, just run it against the two systems, and then be able to go into production with a good check. And it turned out well also in production. As soon as we went live, we were also able to test the both, both of the systems and, and we were able to compare all of those um those results. Moreover, it's not only a functionality that we use and that I think you should use in the system to compare results. It's also something where you can monitor what is your latency, what is your throughput, what is how is speed looking, are you, are you achieving against SLAs or not, like all those NFRs that you that you certainly have in your in your applications, you can also check that if you have something like an integration layer, something like a facade. And what is written on the right in the outcomes section, control cutover, we've said that already, like you can control the systems, when should they change, and then it's your decision. To turn over it's not their decision. You can control it. You have your automated quality assurance because you are actually doing all the tests with with the facade and in this specific case, obviously all of us, all of us very proud we actually didn't have any incident on go live for such a big system which again was migrated with AI and and lastly on on that screenshot. Yeah, it's it's the colors are visible here too. You see what the result is. Yellow is the mainframe system that was running before the pricing service on the mainframe system in Cobalt. Green is the one in Java, and you see it has been running in parallel for quite a while. It's just the testing that I've said. And then at a certain point in time we were able to just cut it off as we've seen it, the performance is just, just better all the way and even, even spikes, um you can handle much, much better on AWS obviously than you would be able to handle it on on a mainframe system. Yeah, and, and with that um we we are done with with the presentation for today um we would be very happy to answer a couple of questions if you if you have them we we stand right by and happy you listened here and um see you then. Thank you very much.