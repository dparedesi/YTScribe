---
video_id: vYXunsSxeR4
video_url: https://www.youtube.com/watch?v=vYXunsSxeR4
is_generated: False
is_translatable: True
---

Welcome, welcome, welcome everyone, thank you so much for coming to our session. This is SEC 340. IM access analyzer deep dive from configuration to remediation. Quick question before I get started. How many of you, is this your first session of the conference? Can I see some hands. Yes, thank you, thank you for making ours the first. And for those of you who well already attended something else that's great too thank you for going and supporting whoever that was. Uh, my name is Jeremiah Dunham. I am a senior software development manager here at AWS. I'm on stage in front of you talking about IMX Analyzer because I lead the IM Access Analyzer engineering team, so my team builds this product. And my name is Mitch Beaumont. I'm a solutions architect based in Sydney, Australia, and I get to work with customers on a daily basis, helping them figure out how to assemble the AWS building blocks like IAM Access Analyzer, and hopefully I can bring some of that uh here today and share with you to, to take home to your own organizations. Yeah, oh, sorry, sorry, jeez, I got a little button happy there. Uh, so, Between Mitch and I, as you, as I'm sure you gathered, right, so I understand what's going on behind the scenes of IMX Analyzer, build the product. Mitch works with customers who use it, so between the two of us we should be able to cover pretty much anything you want to know about it. Um, this is a code talk, so we're gonna get into some code and some demos and things like that for you, but first we want a level set, so you're gonna have to listen to me talk for a few minutes and for that part, here is the agenda. I'm gonna talk a little bit about journey to lease privilege, give you an overview of IMX Analyzer. I'm gonna talk about this much about automated reasoning, and if you don't know what that is, that's OK. Hopefully you'll know by the time I'm done. And then I'll turn it over to Mitch and you know let's code kinda in fact before the session I was joking with Mitch that now that we have Kro I mean who writes code anymore anyway you just tell the agent it goes and does it for you. All right, so I am Access Analyzer. The, the goal of IM Access Analyzer as a service is to help you get to least privilege, and we talk about the journey to least privilege, uh, because, well, it's, uh, it's really a moving target is what it is. And so, um, Access Analyzer is there at all the various stages of the permissions life cycle, uh, as they evolve over time to help you continue to refine and scope things down. Our mental model for doing this. We think of the permissions life cycle as there are 3 phases set, verify, and refine. Those are pretty self-explanatory. Basically you create some permissions, then you use access analyzer to verify what permissions you have created, make sure that is what you intended, and then finally if it isn't, you go and refine it, which takes you back to the beginning and so on and so forth. We have a bunch of different features in Access Analyzer to help you do this. Um, there are 5 of them listed here. I'm gonna talk about each of these in a moment except for policy generation. I'm not gonna talk about too much, so I'll give you the TLDR on that which is you basically create a star star type policy for your application while it's in test. You let it run, you let policy generation, analyze the logs, and then it recommends a least privileged policy based on the actions that your application took in test, and then you deploy that to prod. So you don't deploy the Start thing to prod. Please don't do that. He deploy the least privileged policy to to prod. Um, but for the rest of these, uh, I'll get into those in just a second. All right. Uh, our secret sauce, uh, one of the very unique things that we do and IM Access Analyzer is we use a technology called automated reasoning. Um, it's funny, you know, sometimes people ask me like, hey, is that like AI? No, it is the opposite of AI actually. It's kind of interesting. They both use advanced math, but it's kind of the opposite. So where AI uses probability to predict what is, what will come next, automated reasoning is deterministic. We use mathematical proof to tell you definitively yes, something is possible or no, something is not possible. All right. Uh, that is literally all I'm gonna say about that because it's a super deep topic, so you have two options if you wanna go deeper. Probably the easier one is the one I'd recommend, which is scan the QR code and go read up on what's there at that link. The second option is go get a PhD in formal logic, so. Alright, the features that I'm gonna talk about that are part of our Access Analyzer, we have 3 analyzers, 3 different types of analyzers, and so these come in at the verify and refine stage. So you've already deployed permissions. These are like detective controls, OK, so they'll look at all the things that you have already deployed and then give you some findings. They'll tell you, you know, what's going on. The first, and this is the granddaddy of them all, is the external access analyzer. Um, this is a free feature, so please, if you do nothing else after this session, go turn this on. Please go turn this on, it's free. And what External Access Analyzer does, you set the scope, either organization level scope or account level scope, and it will tell you, are there any resources inside either the account or the organization that have permitted access outside of that zone of trust, either outside of the account or outside of the organization. And it will produce all those as findings and you can go through and uh you know, take some action either change the scope to remove that or archive the findings say yep, that's what I meant. Uh, we have the next analyzer that we launched is this is a has a little bit different flavor. It's called unused access analyzer. This is the Marie Kondo of analyzers. It helps you get rid of the things that do not bring you joy. What are those? Unused permissions, permissions that nobody needs that have actually been granted but that are not used. So this one's pretty simple. You turn it on, you can set the scope. Similar to the other one, and what it does, it looks through all the principles in your account or organization, whatever scope you've set, and it will tell you for any given principle, are there any unused permissions. It will also tell you about any unused access keys, uh, yeah, unused access keys as well, or just if you have whole roles or whole users that are have not been used in some period of time, it will tell you about those. And yeah The other nice thing that we do is for the unused permissions one where it's like you have a role and there are just certain permissions in there that have not been used in a long time we actually will using automated reasoning we will recommend here is the policy that you can replace the permissions with. And that will now be a lease privilege. Great. All right, and the most recent analyzer type which we launched that reinforced this year, so about 6 months ago, is the complement to external access, which is internal access analyzer. So for this particular one you want to set it on only your most critical AWS resources like S3 buckets or Dynamo DB tables, basically things that only a very, very small number of roles or people should have access to. And what it will do is it will produce a full report of here is everyone inside your organization that has access to that resource and the nature of their access, meaning like what conditions can they access, what are the particular operations they can perform, all that stuff. Uh, again, only on your most critical resources. This is a very, very computationally expensive thing to do, so it costs money and it's, you know. There you go. Um, OK, and finally. So that was on the verify and refine side of the equation. So you've already deployed things and you wanna look at the things that have been deployed, clean them up. What if you want to prevent unintended things from getting into the environment in the first place? So this is at the set phase for that we have custom policy checks. OK, so custom policy checks, the basic idea is they're, they're a set of static APIs that you feed your policies into. And then the APIs in the case of validate policy, which is a free API that runs a bunch of AWS best practice checks, it's kind of like a linter for your policies and says, here are all the things that your policy does that it probably shouldn't do. Go clean those up. For the other three APIs, the ones that start with check, these are things that are your best practices, so your organizational standards, you would say, hey, you know, I don't think that anybody should have, I don't think this, this, uh, roles should generally have access to S3 delete bucket. That is not something we typically do, so most people shouldn't have access to that. So what we're going to do is we're going to use something like check access not granted. We pass in the policy and we see does the policy attempt to grant S3 delete bucket. If it does, That check fails. And then you can take the appropriate action, but if it doesn't, then it passes, good to go. All right, so they're the options. That's the overview. Wow, I know you don't wanna hear me talk anymore. Now we're gonna let Mitch jump into some code, some demos, woohoo, all kinds of things. It's gonna be great. OK, can you see if the stream deck works there in the way we expect it to, oh, that's awesome. Magic, excellent. Right, we, we were trying to figure out if it's best for me to stand up, sit down, hunch over. I'm gonna try sitting down to start with, um, let's see how that goes. If I start standing up, you'll, you'll know I'm not enjoying it, and hopefully. Right, so you've seen and heard from Jeremiah about all of the different analyzers uh that are available to you. What I'm gonna walk you through now is the configuration of those different analyzers, um, and then uh Jeremiah as the engineering leader for, for the team that builds these things, he's gonna provide a bit of color and depth on how these things work underneath the, the hood. Uh, and then we're gonna share some best practices for each of the analyzers when it comes to configuration, managing all of the signal that gets generated by these analysers, and, um, some of the things you can do when it comes to actually responding to and remediating the findings that get generated. We're gonna start with um external access analyzer, um, and if Jeremiah said before um whilst he was presenting up there, there was one thing that everyone needs to, to do when they leave today, um, if nothing else they remembered. Does anyone remember what that was? Beautiful, good. They're listening, they're listening. Excellent. So do that. That's probably lesson number one. So external analyzer. OK, hopefully you're all familiar with the uh the AWS management console. This is an S3 bucket. Um, it's been labeled uh external, um, because it made it easier to find it in amongst my, my 700 S3 buckets that I've got here. We're gonna look at this one and. So I'm in an account at the minute that ends with 4447, that's the end of my account. What we can see here in the bucket policy for this S3 bucket is it has a principle in the principal uh property here that is not my account and essentially is allowing S3 get objects and list uh list bucket on the, the resources or the objects that are inside of that. That's not really what I want, um, and that kind of pattern, well, maybe it is, uh, let me take a step back there for a second. There are some valid use cases for having cross-coun access. For the purpose of today's session, that's not what I want. Um, and you can imagine as you create more S3 buckets, if you're in a large organization with many hundreds or thousands of AWS accounts and each of those having their own S3 buckets, you would want to understand and know when and where there are these kinds of configurations that would potentially permit access to your S3 buckets from entities or principals that are not within your, your zone of trust, so either not within your immediate account or not within your own organization, uh, your AWS organization. So we have an issue here, how do we, how do we scale the detection of this kind of thing, and that's really where um Access analyzers external access comes to play. How do we configure an external access analyzer? Well, this is a code talk. I'm gonna paste some um command line into here, so it's kind of code, forgive me, um, but this is how you configure it from a command line perspective. We can also configure this from the uh from the management console as well or using the SDKs, whatever your, your preferred approach is here. Some really simple configuration options, uh, I wanna create a new analyzer, I want to give it a name, and I want to define the type of analyzer, so is it an account scoped or an organizational scoped. The difference being, if it's account scoped, it's gonna let me know if anything outside of my. Current account can access my S3 bucket or my resource. Uh, if it's organization scope, it'll let me know if anything outside of the boundary of my organization can access that resource. And then I define the, uh, the region that I want to deploy it into. I'm gonna hit paste and I'm gonna hit enter. And very quickly I get a response back uh with the arn of the uh book, the analyzer that's been created, and if we go over to the um console here now and hit refresh, hopefully we'll see an analyzer created, which we have, so that worked, that was good. Whilst we wait for a few minutes just for this to start gathering some findings, what I might ask Jeremiah to do now is perhaps provide a little bit of detail on how this works under the covers. Yeah, absolutely, so. Basically, the way we generate findings, there's, as you heard, there are kind of two interesting pieces to this, um, you can't grant cross account or cross organization access to a resource without writing a resource policy. So the analyzer starts by pulling the resource policy and in the case of like S3 buckets where they have some kind of legacy things like access control lists and stuff, we pull all that stuff as well. And then we run our secret sauce automated reasoning right to basically deduce does this thing grant external access yes or no and by external we mean either public so we have made some potentially big configuration error and we've granted any untrusted principal access to the bucket or also grant uh anybody just another account access. Um, so the second piece to this is like Mitch said, we can also create an organization scoped analyzer and so in order for us to know is the is the access that has been granted within or outside the organization, we also have to fetch all of the organization related metadata like the organization structure and all the OUs and accounts that are within the organization so we can determine is this just granted to another account in the org or is it granted outside. Awesome, there you go. And that brought me just enough time then for the analyzers to start gathering some information for me and as luck would have it, uh, one of the very first findings that got generated through the analyzer, now it's running and you saw interactively, right, this was live in in a matter of seconds we started getting this information. The external bucket that I mentioned that I'd misconfigured uh came up as, as one of the findings straight away there, so we can see now that uh it's telling us that there is an external entity, so this is the, the principle that has access. Um, we can see that the sharing has been done or the access has been granted via the bucket policy, and we can also see the different types of access that has been granted through that policy that it's looking at there. As well, so really quickly we can start to really figure out, OK, like, do I really want people to access these resources, you know, in this case it's an S3 bucket. It also can be things like IAM roles as well, and we can see down there that we've got some uh super special roles that are down here that, um, that are accessible via an external AWS account over here, so outside of my, my current scope. Um, now. One of the things that I, um, over and above just making sure that you enable external access analyzer when you leave here today, and there are a few other best practices that are worth keeping in mind when it comes to configuring this, uh, and managing it on an ongoing basis. I'm gonna hit refresh again, you can already see we've got 55 findings that have been generated here now. Um, you can, this is a single account, I don't do much in this particular account, and I'm, I'm probably gonna burn it when I've finished here today. But, you know, in an organization with hundreds or thousands of accounts, you can imagine that all of this can be quite overwhelming, that the signal to noise ratio gets very, very high. So one of the things that is quite effective at helping you zero in on the things that are most important is to go, well, there are perhaps some things down here that I know, I expect to be configured in this way, maybe some buckets that I do want to be cross-account accessible or some roles that I have allowed external third parties to to assume so they can do things inside of. My account. So how do I remove some of that noise so I can zero in on the things that are most important? Well, the way that you can do that, and this is best practice number 1, is to create an archive rule. So these archive rules allow you to archive certain types of findings that you don't want to worry about necessarily, because you kind of know that they're supposed to be there. So you can see now I'm going through here, I'm gonna create an archive rule. The first thing I did was create uh the name and make the name correspond to the thing that I'm trying to archive, just because it makes it easier for the next person that comes along and takes my job when I leave to go, ah, OK, that's what that rule does, so now I understand what's happening here. Um, the next thing is, uh, I'm gonna set some criteria, so, um, I want to archive only if this public, if public access is false. I never want to accidentally archive something that is a public, is publicly accessible. So I always leave that criteria in there as well. And then the last piece of the criteria is to enter in the name itself of the thing that I want to um. To to archive, so, and, and my role is super special role as you can see I had, I had a few, few of those floating around and they're all part of my administration set up, so I need people to be able to assume them from different accounts. So I've got 61 findings that have been generated or discovered as a result of this archive rule now, so I can just create that archive rule. And what we find then is if I go back to my findings, I get a lot less findings now, so I've dropped down from whatever it was, 70 odd, probably, probably more, down to 31 now, so straight away I can start to zero in on the things that are most important to me as well. I'm gonna jump over here, I'm gonna put this on the screen because I wanted to have something for you to perhaps photograph on your phones that might be useful for you to take away, but when it comes to things like external access analyzer, as we already said, start with your external access analyzer. Now it's free, uh, it doesn't cost anything, and it can give you a whole bunch of useful insights. Create those, uh, archive rules to help you really zero in and remove some of the stuff that you don't need to worry too much about. Make sure you're using good naming standards, both for your archive rules, potentially for your analyzers, but also encourage your colleagues who are creating these IAM resources to give their IAM resources friendly names. If I hop back to the findings again, and I look down here at some of these findings, am I on the right, yeah, I am. If I look down here, if I've got anything here? Is there anything? In here that perhaps, so look, here's, here's one. This one's called loads of random something. I mean, that doesn't mean anything to me, like what, what does that mean? If my colleagues had given it a name, perhaps this role is a special high privileged role or something like that, then at least I know what it is and I can go and take some, you know, action, or I know who to go and have a conversation with when I'm trying to remediate those roles. Um, inspect the findings, so if I take a look at that particular one there as well, the, the, this more random roles, if I click into this. And I'm oops, let me move my code shell down here a second. So I can see this is the finding that's been generated um for this particular role. So the role can be assumed by this external entity, it's the SDS assumed role permission. Um, the name of that role is, um, is this uh super special role itself. So if I go down here, if I go and find, right, if I take the name of the role and click on this one here. What I can see is that this is the role itself, so this role is able to be assumed by some external principle. Um, it's the external analyzer analyzer has, has told me about it. So should I be worried about that? Well, this role was created on October 13th. It's never actually been used, and it has some kind of random permissions down here. I don't know if they're necessarily, um, super useful or not. But at least I can see that the the role itself hasn't been used, so it gives me a good next step. Let me go and speak to the person that I think owns this role. I can also look here at last access uh privileges, and I can see that nothing's been used here at all. So there's a good chance that I can go in and I can actually delete this role, um, but I should go and check with the person that owns it first, but I can delete it to make sure, uh, sorry, to, to remove one extra finding from my external access analyzer. Um, which is, which is great. The other benefit to that is that by inspecting a little deeply, understanding whether that role has been accessed recently and whether it's used any of the permissions that's been granted, I can potentially remove that role and save myself 20 cents when we look at enabling the next analyzer, which is the unused access analyzer, um, which is where I'm gonna talk to right now. By the way, we will take questions, but we'll do this at the end if that's alright, so that we can get through the kind of content first and, and also Jeremiah and I will hang around at the end outside if you want to come and speak to us as well. So that's internal, sorry, that's external. Let's look at um unused access analyzer now. I've already created an unused access analyzer, um but I'm gonna quickly just show you the console experience for doing that so you understand what that looks like. Um, so it's a principle based analyzer as Jeremiah said. Uh, I'm gonna give it a name, again, back to the naming conventions, I get pretty hung up on this, but it's really worth calling these things what they are to make it easy for the next person to come along who, who picks up your job. Um, and, uh, understand what you're intending to do there. So I've called it one day, unused access analyzer for one day. So this is gonna look at anything that has permissions or any IAM resources that we're looking at, so principles that haven't been used in the last one day. I've set that to one day because, you know, part of the demonstration, we just want to make sure that we can see things and, and activities. I've given. A name of one day, I've set my tracking period to one day as well. I've specified the region and the accounts. I've also got the opportunity, if I wanted to, to exclude certain things from this. So there might be management accounts that I want to exclude from the analyzer if I'm in a big organization. There also might be a series of IAM roles or principles that I expect to have unused permissions, maybe they're service account related or they're associated with deployment pipelines, that kind of thing, and perhaps they don't run every day or perhaps they run once every 3 months, that kind of thing, so I want to exclude those from my one day analyzer. So I can add tag metadata into here to say exclude these particular ones from you. Through the process, hit create and then it's gonna go ahead and create my external, sorry my unused analyzer for me. Now I'm gonna open that up, uh and whilst I open that up and we wait for the analyzer findings to magically generate, which they have, I'm gonna let Jeremiah provide a bit of background on how this analyzer works. Yeah, so As it turns out, in Access Analyzer, there are two very special things that we do. So one is automated reasoning, which I already talked about a little bit. The second one is what powers this analyzer, which is we actually process every single access log, so every IM access log and every cloud trail log we process so that we can figure this out. Um, so it's a lot of data. As you might imagine. Um, also worth noting, uh, there are some, uh, last used APIs in the IM name space. Those APIs also use this index that we build from processing all the log data, so. Right, so Because we're we're, we're good little demo people, we, we pre-staged a few things here to try and generate some useful and interesting findings. One of those is a lambda function um that we created that has a whole bunch of excessive permissions and really only uses a handful of those, if, if any. So I'm gonna look at my lambda function here quickly and I'm gonna look at the permissions here and we can see this lambda function has like all the permissions to do all the things really. Actually all this lambda function does is list S3 buckets, so it doesn't need to do all of these things. So what I'm hoping for in a minute is if the, if the demo gods play nicely, we should be able to see uh a good example of the power of the unused access analyzer. I'm gonna copy that name there and take it across. Um, so the finding experience is very similar to what we saw with the external analyzer, so you can see there they have finding IDs, we have all of the different finding types, so whether it's an unused role or unused permissions, or, um, that we also have unused access keys, and I'll talk a bit more about that in a second. Um, but what I can do is I can do finding type, um, contains, uh, or actually I'm gonna do finding type, I'm just gonna do unused permissions, let's go here. So what we should see. Um, if I scroll down my list here somewhere, do I find my, uh, my, it's not there, let me close that again. Let's go resource contains pop. OK, so my, my lambda function for some reason isn't there today, that's, that's good. Uh, we can try this one here. But what we can see is we've got these unused um unused permissions that have identified in this particular role here. So if I go over to here, have a look at the unused permissions underneath this particular um underneath this, this particular role, um, what I can see is I've already got a list of the permissions that this particular uh role hasn't used. So it has a series of permissions, it doesn't do any of the things that are listed there. So in addition to telling me that there are a series of permissions that it isn't using and making some suggestion that I should probably refine those permissions, it also gives me a policy recommendation that I can look at and potentially apply to uh to the, to the role that we associate with, with this or this particular role um that I brought up on the screen here. So if I look at preview policy. It's looked, as Jeremiah said, at all of the access patterns, all of the logs, and it's said, well this is your existing policy, here is the recommended policy with all of the actions that you're actually using or that this principle is actually using, um, so it's really more of a refined set of permissions, ideally it's, you know, it's the least privileged, and as we go through this journey, um, over time, it will start to understand more about what I am and what I'm not using and I'll continually get that refinement of, uh, of policy right down to something that really, Uh, is, is as least privileged as it needs to be for the thing to do that it needs to do. Now I talked about creating this at a 1 day interval for today. What we generally recommend customers do is start with a fairly large, uh, tracking period, so probably 1 year, 365 days, and the reason for that is because there's gonna be a lot less things for you to clean up, hopefully, that haven't been used for 365 days or more. Do that, start there, look for all those things that haven't been used for that long. Long, it's gonna be easier to, to, to check, check, check things off the list. Um, once you've done that and you've got rid of everything that is, hasn't been used for, for a year or more, wind it down to 270 days, wind it down to 90 days, and take that iterative approach over the remediation process right down till you get to the point where you're at your, your happy place. Maybe that's 90 days, 30 days often catches people out because there are some processes that use these principles that perhaps don't run. Every day or week, maybe it's a 30 day cycle, and you do have to be super careful when you're going through the process of remediating some of these roles because, as I said, there can be processes that use these principles that do not run on as frequently as you're running the the the as the tracking period is is defined. So you know there could be a pipeline that deploys patches or updates or transforms data that maybe only runs once every 30 days because it does batch ingestion. You don't wanna start deleting roles um from, from the account or removing privileges, only to find out a month later that some critical data transformation pipeline has broken because you've removed those permissions. So best practices um for for when you're configuring these and feel free to take phones out again. Start with that one year period, really important, uh, iterate over that and consider putting that time series into the name of the analyzer, because when you're looking at all the analyzer findings, you can actually filter by the different names of the analyzer, so you might go, well, I, I wanna look at what hasn't been used for 30 days, what hasn't been used for 70 days or 90 days. Um, exclude those accounts that you know are probably going to generate findings that will save you some money, uh, and obviously remove that, uh, the, the noise from, from all the useful signals. Um, when it comes to finding types, we generally recommend that customers start by looking at, um, the most, Challenging, uh, areas or problematic areas should I say, if that's the right way to say it, unused access keys is a really good example, right, and I just showed you quickly there how to filter that. So I can look at an unused access key here, this unused access key, you know, appears to not have been used in the last day, at least, probably longer. Now it's not uncommon for engineers to create access keys for demo purposes and testing purposes. But it's good to know they haven't been used because we can go back to those engineers and say look, we, we get you used it for a reason, for part of your project, but let's remove that now cause we don't need it to be there anymore. So you can filter these different finding types, really zeroing it down until you get to the point where you've only got what you need. Um, getting rid of those unused principles, those rules, those unused permissions, uh, sorry, rules should I say, and unused permissions, ultimately again saves you money because it won't get analyzed the next time the thing runs. I already mentioned about being careful when it comes to deleting these things because someone might have a principle that is only used once every month or so. And depending on how you're using this, um, how, how you wanna use the output and the information, you might consider just running this once every 6 months. I mean if this is part of an input into an audit cycle you're doing as part of your risk and compliance, this is, you know, this is a compensating control, it helps you understand where your risks are. So if you're doing. Part of this, part of this is a, as a, as a review with with auditors or, or quality assurance people. Consider running it every 30 days or every 90 days or every 60 days, or even every month, uh sorry, 6 months, um, get the results, provide them to whoever needs them, and then delete the analyzers because this will, you will get charged for this, you know, it runs every. Every month, so you get charged per per resource or per principal per month, um, so if you're not gonna use that information and look at it every day, you know, create it, get the information, delete it, pass it on to someone else. The only thing to keep in mind when you do that is that the archive rules, when you delete the analyzer get deleted along with it. So if you spent a bunch of time creating some really nice archive rules, you'll have to go back and recreate those, so it's a trade-off, but if, you know, if cost is, is something that's really important to you, then you should think about taking, taking that approach as well. And that kind of brings us on to the last analyzer of the analyzer family that that Jeremiah talked about here, which is the um internal access analyzer. Now this is one that I've pre-created for you, um, again, just because we wanted to get some findings that are generated. Now what we've got on our list of S3 buckets over here, let me just filter these again, as we've got a critical bucket. Now Jeremiah said. Internal Access Analyzer is really aimed at those critical resources. It's, it's a computationally intensive analyzer and it has a cost associated with it as well that you should definitely keep in mind. Not only that, it generates a lot of findings because it looks at each resource and it tries to understand every access path that that that a principal can make to that given resource as well, so. In my account it's not too bad, but in an account where, or maybe in an organization where I've got hundreds of thousands of accounts, there is a lot of information that is generated there. So if you're trying to find that needle in a haystack, it can be quite challenging. So keeping it to your most critical resources is, is super important. This one, for example, is probably my most critical S3 bucket where I've got some holiday photos of Jeremiah's here and I don't want people looking at these. I wanna make sure I know who has access to those photos. I'm sure you'd agree with that, right? Agreed. I gotta keep people out of that. So with our, with our internal, uh sorry, our internal access analyzer, as again I've already created it, but I'm just gonna quickly uh show you um the process so you understand what it looks like here, um, I've got this, um. I'm gonna call this JD's photos here, so I'm giving it a name. Again, make sure you make it nice and friendly, and then I can choose the resources that I want to add here, so I can choose all resources from a given account. I can choose specific resources by specifying the Amazon resource name or the arm for those resources, or I can choose or upload a CSV that has a list of uh um resources in there as well, that will then get analyzed by the, the, the internal analyzer. And then I just go and hit create and hopefully then my analyzer gets created. Now if I go into here uh and look at my findings. Even for this one single bucket, we can see already that there are a lot of findings in there that um that have been generated. You can imagine, you know, en masse this, this would for lots of buckets and lots of accounts, this could become uh a lot, a lot harder for us to try and understand and troubleshoot and when we're looking for specific information in there. Jeremiah, maybe you could share with our wonderful audience a little bit more about how internal access Analyzer works. Yeah, uh, so this one, it's kind of funny because the original, uh, external access analyzer we launched. I'll just say a long time ago because I don't wanna get it wrong. Many years ago, but the internal one we just launched like 6 months ago and so I'm sure some folks were like, huh, like what, like why, why was it, why was it so different? Well, it turned out we had to actually make some new science. Like it was, it was really hard, um, but what, what makes it so challenging is. Um, one part of it is to actually bring together all of, if you think about it, in order for us to know who inside has access, it's not sufficient to just look at the resource policy. We have to look at every identity policy. Uh, we also have to look at all the SCPs and RCPs, right, all the organization control policies, permission boundaries, right, on and on and on. So it's just a tremendous amount of metadata that we have to pull in. Combined together and then run through like a fairly sophisticated scenario analysis again using automated reasoning um yeah and so. It just takes a lot of computation is what it boils down to. Um, yeah, that's it. Yeah, uh, uh, if you, and if you didn't know, I, I can't remember if we put it on the slide earlier on, but it does cost $9 per resource per month, so, you know, it's, that's why it's, it's something that does require a bit of consideration and really it's, it's designed for your most critical resources. Um, so what have we got from our internal analyzer? Well, similar look and feel to what we got from the others, the findings that have been generated. Um, one of the interesting things that you find when you enable this for your, for your resources, for your critical resources, is that you, you actually see, OK, well, I mean, there's a, there's a role here, or an IM user here, a test user with all of the access. I mean, I, I don't know what that is, and I'm pretty sure that person doesn't need to see Jeremiah's holiday photos, so. If I can click on that and and go and inspect a little bit more to see what's actually going on there, that you know, we've got this, this, this principal, um, this IAM user called test user, he's got access to all of these things here, but you know, probably doesn't need to see those photos, so again, similar to how I, I went back into the IAM um console earlier on and had a quick look to see if I could find a bit more about this individual, I can see, right, well here's the user. Well, actually. This user, by virtue of the fact that at some point in the past I happened to give this user S3 star access, which isn't good practice, but I did because I was probably trying to troubleshoot some issue or help someone move forward with a project. Um, I've inadvertently granted them access to Jeremiah's critical holiday photos now, and that person probably doesn't need access to that, so, um, I can probably go away and go, well, you know what, this actually. Created in October, uh, hasn't logged into the console before, um, and I can look at the last last accessed API actions as well, and I'm fairly sure it's gonna come with no access to Estuary whatsoever. So it becomes, you know, a potential attack path, um, a path for data exfiltration or access that I wasn't intending, and I hadn't created it intentionally, it wasn't malicious or nefarious. It was just because I had created. A role or user at one point and granted them S3 full access and now the internal analyzer has helped me understand that there is, there is a way that that particular account IM user, if it fell into the wrong hands, would be able to access Jeremiah's holiday photos and who knows where they would end up. True that not good. So let me bring up my best practices here again. I think we've kind of harped onto this one a little bit more on, on, on the uh internal analyzer, but you know, keep in mind this is for your, for your um for your most sensitive of resources. Um, there is a lot of noise created um for each of those, sorry, I'll, I'll read. Phrase that there's a lot of signal created. You need to determine what's what's noise and what's not, um, and if you're analyzing an S3 bucket that is accessible from accounts and principles, uh, in, in a large organization, it can become quite overwhelming to really prioritize where do you focus your attention when it comes to cleaning things up. Um, we can import, um, lists of ARNs and use CSVs to help you automatically specify what you want to analyze. And as we talked about, right, this looks um pretty uh intensively at uh resource policies, principal policies, all the different ways in which a particular resource can be accessed by all the potential principles that can access it as well so. Great if you need to do user access reviews. Um, I work with financial services customers in Australia and a big part of their internal control, uh, for is user access review, and that can be a very complicated, time consuming manual process. If we can optimize that even just a little bit by providing this information, mathematically verifiable information to their auditors and their compliance teams, it takes a whole swath of work off of their plate, so super powerful from that perspective and but you know it's it's the, It's the the the cost trade, uh, the cost benefit trade off that they need to think about there. So we've talked about the analyzers, these are all in the, the, the kind of verify and refine stage, um, you might be then asking yourself, well, you know, maybe I should be doing things that actually stop, uh, these misconfigurations ever getting into the environment in the first place, and I go, yeah, it's probably a really good idea. So. Just so happens, I'm glad I asked myself that question because we, we've we've built something um to show you that that kind of helps solve that problem a little bit. So, what we've built is a, an example of a pipeline, we're using uh AWS code pipeline for the purposes of this uh demo today. This pipeline has been integrated with the Access Analyzer custom policy check capability that Jeremiah brought up on the screen a little bit earlier on. And what we're doing there is we are defining an organizational security standard that says um S3 buckets should only be accessible to this account, the account that you're deployed into, um, if, if it's, if the policy, the bucket policy defines any other access path for a principle that is outside of. Uh, this account, then that's a, a finding that that should block the progress of the pipeline, we should get some feedback on that, and, and the developer or the engineer who was writing the policy should be able to go and fix that problem. If everything works well, then we should be able to deploy the stack, and this is an infrastructure as code stack, it's in CDK as you'll see in a moment. Um, but one of the bits of feedback that often I've heard from engineers that that are building IEM policies for their applications is I'm not an IEM expert, and like I've, I'm an expert in my application, right, I know what my app's supposed to do, I know the permissions it needs, well, I know what I want it to do, I don't know exactly how to craft the very nuanced, uh, IEM policies that are, that are often required to get the outcome I'm looking for. So if you're gonna tell me something's wrong, tell me how to fix it as well. That's fair, that is fair. Um, but it's not scalable for a security engineering team, often, of which there are many fewer of those than there are software engineers, to be able to go and work with every single engineer and help figure out how to solve their problems. So what we've done in this scenario is we've actually plugged in Bedrock because Watson and AWS talked during reinvent without a bit of generative AI in there as well. And we're using Bedrock to take the results of the finding and take the policies that we've got and actually provide very prescriptive guidance and recommendation back to the developer in the form of a automatically generated GitHub issue that will get pushed into the into the project for for the developer, um, so they can then take those actions and go and remediate their uh their their policies. So that's how it should work. Let's hop on over to um and this is where we do actually do a little bit of code, code code code. Let me find the right Kro editor, which I've got about 3 open at the minute, it's not that one. It's not that one, it's this one. There we go, sorry, I just gave myself motion sickness there flipping between all of those. So, here is my CDK project, at the minute it's set to this account, so it's gonna automatically add the accounts ID of the, the, you know, whichever account I deploy into, to the, to the, to the bucket policy here. This is my, uh, this is the account that I don't really want to have access, so I'm gonna paste that into there. What I've also got as part of our pipeline is this reference policy. So this is my organizational guardrail that says when you create an S3 bucket, uh, I want to make sure that, uh, the, at a minimum, um, that the, uh, this account, so this is my current account, this account, is the only principle. Uh, or principles within that account that can access my S3 bucket, and these are the only actions that it should have. S3 star against, um, any other kind of any, any S3 resource. So if a policy that I attempt to create through my CDK project is anything other than a subset of this policy here, I should get a blocking finding, and it will stop my uh infrastructure as code template from being deployed. Should. So let's hit save. Let's then, uh, let's add in my file. Let's commit here. uh, it's easier probably to type commit. Git commit minus M, adding cross account. Accounts hit. And then I'm gonna do get push. This is where it all could come crashing down. It didn't, it worked. OK, cool, so we've get pushed. Um, what we should see, sorry again for the motion sickness here, is if we go over to our pipeline. So our pipeline in in code pipeline is, is kicking into gear. Now this might take a, a, a few minutes to run through, um, but what it's doing is, uh, when it gets to this stage over here, I've got 3 different custom policy checks configured. One is, uh, check no new access, so this is looking at my policy. To determine whether or not I am uh to make sure that the policy I'm attempting to create is a subset of that reference policy, and if it's not, it will uh it will block and I'll get a failure. Check access not granted, um, I may have, I haven't in this scenario just to keep things simple, but I may have defined a set of IAM actions that I do not want any policy to grant uh principal access to, um, and I could list them in there, so I could list, you know, maybe. Uh, S3 delete bucket for example, I don't want anyone to do that, so I could add that as a list and it would check those policies, uh, and block if, if it found it. You can also specify resources there, so again, maybe I might take the arm of Jeremiah's holiday photo bucket, add that to a list of resources, and say if any policy that is being created could potentially grant access to that bucket. Block it, stop it, I wanna, I wanna go and remediate that. And then finally we've got the, the, the, the good old um check no public access, which checks to make sure that the resources I'm creating do not grant public access to uh to the thing that uh that I'm I'm trying to create. If all that goes according to plan and and works in the way we expect it to do, then this will just deploy. But because I added that uh that that cross account account ID in there, what I'm hoping will happen. Is that this will, uh, this will fail and we will then see a uh an error, uh, sorry, a a a GitHub issue automatically generated that then I can go and pass to my developer and go and troubleshoot. So we've got 2 of these through now, I'm just to Play some elevator music and make it a bit more engaging and interesting, I thought I would bring up the logs, so you can see there's a lot going on here, um. And I'll give you another Easter egg towards the end of the session where you can go and learn a bit more about this, uh, and what's actually going on here, but what essentially we're doing is we're, we're synthesizing the CDK project, um, we're, we're extracting all of the IEM resources out of it, so, um, so the, the, the principles and the policies, um, we're then passing that over to, uh, a custom Python script that we've created that will then analyze, um, the, the, the results that get spat back by the, uh. The, the custom policy checks, uh, and then hopefully we should get a failure. So we're gonna, so, so check access not granted and check no public access is good so far, which is what I expected. Um, if I then hop over, I'm just gonna jump back into here a second. Let's go down, it should be getting pretty close, da da da da da da da da da da da. There's a lot of noise in here. Cool, and it has actually finished, that's good. And it failed. So failed, hopefully because of the fact that uh we got a, we've got an issue. Um, so here's the GitHub repository, hopefully you can all see that. I'm just gonna, you'll notice we've got one issue listed in there at the minute. If I hit refresh, that should turn to two issues, which it did. And if I go into here now, so here's the issue that just got created automatically in the pipeline, from by the pipeline, should I say. I'll zoom in there a little bit just to show you what this looks like. So this is, um, this is all powered by, by Bedrock at the back end we've we've we've essentially passed, um, the reference policy, so our, our super set of permissions, um, we've passed the, uh, the particular statement ID from the policy that Access Analyzer determined to um violate what we're asking it for. Um, to both of those have been passed over to Bedrock, um, along with a, a fairly prescriptive prompt that says that that guides it to what we want, uh, what we want it to create, um, so we, we're essentially building a dynamic prompt. We, we're giving it a, a, a structure and then we're passing in elements to, to flesh it out and add more details into it, and we've said give us some very prescriptive guidance on what exactly it is that we need to do here. So we can see it's given us the problematic statement. So if you've ever run Access Analyzer custom policy checks before or against a policy, you may be of the opinion that the feedback you get isn't always super. Prescriptive, um, you will usually get the name of the policy, um, that has violated the, the rules, and the statement index ID from zero to whatever, um, and you know, if you love groking IM policies, then that'll be great, you can just dive in there and figure it out, but if you're normal and you don't, then it can be a bit tricky to try and figure that out. So what we've done is we've found that for you, we've taken that information from the analyzer outputs, we've passed, uh, we've, we've then groped the policy. The statements ourselves, we've taken that particular problematic one out and we've passed that over to Bedrock as well. So it's given us this, um, it's outlined the reference policy, and then it's also given us like the specific guidance here, so it said right there, you know, your, your problematic statement allows access to perform these things, but the, um, but the reference policy only is configured to permit this particular account. So there's your problem, here's what you need to go and do to fix that, so step by step. Go, go fix that, walk through that and remediate that problem. So if I go back here now, I'm gonna just take, in fact what I'll do is I'll go back into here and I copy and pasted these just to make it a bit easier. And if I go back through here and get rid of that, paste that in there, that should work. And I'm gonna add. Uh, gets commits. And get push. And you know, hopefully the, the, the cycle will continue, we will, we will get the, the pipeline kicking back into gear again in a second if I find the pipeline. And this time because now um I've used the, the, the, the placeholder value there for um for the ID of this account, it will auto populate with the account ending 447 and the analyzer check should pass, the template should get deployed, and we've really. You know, if I was the engineer that was writing that policy, trying to just get my application out there, if you think about the time, the feedback cycle we've just significantly shortened, because I don't know if you've ever been involved in that, that, that tango between the engineer and the security engineer. The security engineer has no context of what you're trying to do. The engineer just knows he's trying to get her thing out there. It's backwards and forwards, it's backwards and forwards, and it can take days, sometimes weeks to really figure out like, yeah, I'm, I'm intending to do this and here's the reasons why. Now we've been able to give almost instantaneous feedback to the engineer to really help them move much more quickly through the process. So ideally. The analysis that we we went through a little bit earlier on, external, internal, unused access are really there as additional compensating controls to try and capture anything else that happens to get through the gaps that that we weren't expecting, um, we've because we've implemented these, these preventative or these set controls uh a really long way left in that deployment life cycle to make sure that none of these bad things actually get out there in the first place. Um, so I think that is probably worked as well as I thought it would and hoped, and we can probably flip back to the slides now. OK. Great. OK, and yeah, if, if you are interested in learning more about this, uh, in particular these like proactive preventive, uh, kinds of checks, there are two different things that you wanna check out here these two QR codes. I'll continue to wait for a second. Sorry they're so big, um, just a, a lesson learned from a session I did a while back is I put about 5 or 6 of these on one slide once before and no cameras could focus on any of them, they were all over the place, so we, we went for big QR codes this time. OK, and if you want to go see, uh, a good example of this with an actual third party integration, basically a, a more full like walk through of, uh, what Mitch just showed using GitHub actions, there are two sessions. So popular that we even got a repeat for that. Mitch will be there. I won't. Yeah, yeah, and, and we're gonna go into a bit more detail of the actual flow and the construction of that dynamic prompt in this session. We're gonna show you how we integrate it with GitHub actions as well, so you can see a little bit more under the covers of how we got the AI generated analysis and prescriptive guidance back to the engineer. So, uh yeah, if you're, if you're in the area on those days, please, please come along. And that is it for our content. Thank you all very much. We would, um, we would be remiss if we didn't mention that, um, feedback is a gift. So please, if you get a chance to fill out the survey, if you enjoyed the session, let us know, um, that would be greatly appreciated. Um, uh, a score of 5 is always, you know, it's a good place, we're happy with that. Um, so yeah, let us know, we'd, we'd really appreciate that. Hopefully you've found this useful. Uh, we've got a few more minutes left, so we're happy to stick around. Um, we can answer some questions either here or or outside works for us, but thanks. Hope you enjoy the rest of the conference. Yes, thank you all very much.