---
video_id: eLyFTbVtY64
video_url: https://www.youtube.com/watch?v=eLyFTbVtY64
is_generated: False
is_translatable: True
---

Uh, so hi everyone. Uh, welcome to Accelerate Multi-Step STLC with Kiro. Uh, glad to have you here. My name is Derek, and with me is is Kieran, and we both work on the developer agents and experiences team at AWS. Um, we've both been on the team for the last year or so. Uh, it's really exciting time, uh, to be in the space. Uh, we work with, uh, our agentic software development products including Quiro. And then customers all around the world, uh, who, who are using these products to develop software, uh, we've, uh, our team is former software developers that are now engaged with, with other software developers, uh, around the world that are, uh, that are adopting these products. Uh, I'm curious, show of hands, who in the room is a, is a software developer by profession. OK, yeah, at least maybe half, OK. Uh, who's vibe coded? Who, whoever's, who's vibe coded before? OK, some of the same hands, some other hands, um, vibe coding is obviously a hot topic using AI to generate code, uh, these tools are getting better and better all the time, um, and I think vibe coding is a great start, but the conversation we're having a lot with customers is, uh, beyond using AI to do the build step, how do I use AI, uh, at every step in the software development life cycle and not just the build step. So that's the purpose of, uh, the talk today. And this is a coding session, so I'm gonna do a little bit of talking up front, try not to do too much, uh, but I just wanna set the stage for a few things here. So we'll talk about the software development workflow that we're gonna use with uh with agentic uh tooling, and we're gonna talk a little bit about how we compose agents, what, what they're made up of, how the agentic loop works, uh, and how we can configure them, uh, in Kro CLI. Uh, very important step before we go into actually, uh, um, using AI for software development workflow. So we'll do that up front and then, uh, as quickly as I can, uh, I'll hand over to Kieran, uh, who's gonna do, uh, a bunch of live coding, uh, today. We're not just gonna write code, we're gonna start at the beginning of the SDLC we're gonna do requirements we're gonna do system design, we're gonna make some decisions and eventually we'll write some code and hopefully we'll have a working, uh, game to play, uh, by the end of the session here. Uh, live coding, uh, live, uh, AI coding's always gonna be a fun time. So just a level set. I think any of us could draw a picture of, um, the software development life cycle and there's lots of different ways we could express it and if you ask different folks, they'll have different opinions about which steps there should be in which order they should be in and how fast you iterate on the different steps, um, but broadly speaking, we need to have requirements we need to do a system design, we need to plan, we need to build, we need to test, we need to package, and then we need to, um, deploy and operate. And when we talk about vibe coding in my opinion, we're really just talking about skipping to the right code step, which can be great for prototyping, uh, or for trying something out or maybe just scratching an itch in a language that you don't know or something, uh, but when it's time to actually do professional software development we don't wanna skip steps and so the question becomes how can we use AI for for all of these steps. Um, there are a few approaches for this. Uh, we've got two Quiro products now. We've got the Quiro IDE, which just went into GA, uh, in the last month or so, and then we also have the Kiiro CLI, which we'll be using today. The approach that we're gonna use for the, um, live coding session, you could use in Kiro IDE or Kiro CLI. This is really a preference thing in terms of the user experience that you like. Kiera and I are both a bit of console geeks, and so, uh, we're gonna invite you all to be console geeks with us for, for Kiro, uh, CLI, uh, today. Um, so the framework we're gonna use is called AIDLC, and we wanna show one way that you can approach this. This is not the only way CR ID has spec-driven development built into it, and so that's another way that you can approach, um, using AI powered requirements and system design and planning. AIDLC is another way. It's a little bit more granular than what you would see in the Quiro IDE. And uh this is uh something that we've actually open sourced and released uh on GitHub in the last week or two. So, um, I, we won't go too much into the details of AIDLC. It's gonna be in the background sort of guiding us along as we go through the steps, but we have a slide at the end that has a QR code and a link. So if you like what you see and you'd like to try out AIDLC for yourself and some of these prompts, you're welcome to do so and, and we'd love to hear your feedback. So AIDLC rough roughly speaking, has this concept of an inception phase where we're going through the requirements and the design and the planning, a construction phase where we're doing the building and the packaging, uh, and then an operation phase. We're going to go through the inception and the construction phase today and get hopefully to a working game, uh, by the end of the hour here. So I want to spend a few minutes on agent composition. Before we jump into the coding. So this I think is a commonly accepted definition of an agent. This is Simon Wilson's definition. An LLM agent runs tools in a loop to achieve a goal. Very simple, uh, the simplicity is, is what we like. For today's purposes, I'm gonna modify that a little bit. And I'm gonna say an LLM agent runs tools in a loop while building context to achieve a goal. And I'll elaborate on that in a minute here, but what we're finding is managing the context and the tools are critically important to getting the results that we want out of this agentic software development process. If we skip this step or if we don't get it right, we're not gonna get the results that we want. So this becomes an important step in the workflow to making sure that our agent is configured correctly. So here's a diagram. Again, an agent agenttic loop is nice and simple. Um, the user, in this case, we're using the COCLI we're gonna ask it to do something as input. It's gonna take that into its context. We're gonna pass it to the LLM to decide what to do about our goal. The LM is gonna come back and say, I want to take some action using a tool. We're gonna go call that tool, whatever it is. The tool is going to return a result that goes back into the context, and we go back to the agent again and we say, OK, we ran the tool. What would you like to do next? We'll keep iterating until the agent decide until the LM decides we're done and we're ready to give a response back to the user. So let's talk about each of these parts briefly. Starting with LLM. So for today's purposes we're gonna care about applied AI and not the uh gory details about how LLM works. So for our purposes today, I'm not going to try and talk about the semantic relationships that are in the model weights and and dimensional vector space and all that stuff. I'm sure some of the folks in the room are, uh, uh, experts at this stuff. Uh, what we're gonna say is an LM gives us reasoning. Uh, we could debate the how it gives us reasoning or the details, uh, but if we ask it to reason about something, it will do that and it will come back and come up with an approach for a problem. Um, we're also not gonna talk about auto regression and multi-head attention and all that stuff. What we're gonna say is. The model has knowledge embedded into the model weights, what we would call latent knowledge that's been trained into the model during the pre-training step. It knows stuff, right? Um, how it does the recall, we'll, we'll leave for a different session, uh, but our LM is gonna give us the ability to reason and it's gonna have latent knowledge, facts that it knows about the world. So that's great, but next we need working memory for the model to be able to understand what it's doing and keep track of where we're going, and that's the context window. So, here's a very simplified sort of mental model of the context window. It's everything that's in the model's working memory, right? So starting with system prompts that are behind the scenes, guiding the agent's behavior, any context files that we've loaded, we're going to see an example of that here in a minute. The history of our chat so far, so we, we've opened up our chat window, we're going back and forth, working on a problem with the agent. That's all in the context window. Any source code that it's pulled up and looked at, if we're working on an existing project. The output of all the tools that we've called so far. And then hopefully some free space so that we can keep going and so managing this context window is extremely important for us to get the results that we want. If I'm asking the agent to, uh, work with some custom library that I've developed and it doesn't know anything about that custom library, we're gonna get a very different res result than if I were to load up the documentation for that library into the context window. So we wanna make sure that we get this right up front. And then finally for this section, tool selection and tool execution. MCP has taken over in the last 6 months or so as the de facto standard for tool use with agents. Um, for those of you who aren't familiar, I think of MCP as the USB protocol for agents. I can take a plug, it'll plug into any agent, and it'll let me plug skills into the agent so that it learns how to do something new. It'll let me give it access to reading resources, uh, from another location that it needs. Uh, and possibly give it the ability to take action, so almost like an API where it can do a mutative or or make a change on another system. And so getting the MCP tools right again is another critical piece of getting ready for us to go do our agentic software development. If we need access to Jira, if we need access to our internal wiki, if we need access to go search the Internet, uh, we need to make sure that that any of these tools that we need, uh, are, are plugged in. So we talked about the agentic loop and how having the, the right LLM model to do reasoning. The right context window, uh, content in order for it to have that in its working memory, what it needs to know. And we talked about having the right tools plugged in. These are all the ingredients to having the configuration that we need. So today we're going to be using Quiro CLI to do our, our live coding session. And in QuiroCLI we have this concept of a custom agent. And a custom agent is really a bundle of all of those things that we can store, we can share with our teammates, we can publish internally if we want other teams to be able to use it we could just save it for ourselves, but it gives us the ability to combine our model selection. What context we want in the context window. So system prompt, static resource files, hooks, which give us the ability to do some dynamic context. And then tools, which MCP servers do I want to be using? Within each MCP server that could be exposing multiple tools, which ones do I want to allow the agent to use? Maybe not all of them. I can alias them if I want to give them different names. So all of this goes into one file, which Karen will show us here in a minute, that lets us build our custom agent. So we're gonna do that first. Karen's gonna walk us through building our custom agent, uh, and then we'll come back briefly and talk about, um, what we're gonna go build. So with that, Karen, over to you. Thanks everyone. I'll do the uh Not sure that's worked yet. The joys of a live demo. Yeah, good fun. They will. I saw a flicker. Yeah, I worked 2 seconds before we started as well. Do you want me to unplug and plug it again? Yeah. Hey, there we go, reboot, yeah. OK. All right, so the first thing, um, hi everyone. So the first thing we're gonna do today is, uh, configure the custom agent and, um, so you can see exactly what Derek was talking about on those slides. So, um, diving right in, I'm just gonna go straight into that. There we go, into the Kiro CLI. And as Derek mentioned, we have a, um, an IDE that you can use as well, but for the purposes of this, we're gonna use the Kiro CLI. So the first thing we're gonna do, I was, um we're gonna configure our custom agent before we actually go ahead and build the game. So in order to do that, I'm gonna go um agent. Uh, list out the agents that we've got. So when you first start off, you have a Kiro default agent, you can see they're in green. And then I've got a flappy Quiro agent here that I've uh built specifically for this demo. But if you want to build your own, you just go, um, agent, uh, oops. Um, so it's agent, uh, and then it's create. Give it a name, and we're gonna call this demo agent one. Now, this is your agent configuration file. This one's empty. Um, I'll show you the, uh, the populated one in just a second. But this is where you will configure all those things Derek told you about, your MCP servers, the tools that your MC MCP servers have access to, and we should have called out the acronym Enforce Use, I don't think we did, a model context protocol. Um, the tool aliases, as Derek mentioned, in case you want to um give those uh differentiating name. The tools that your agents are allowed to use, and the different resources. So what we'll do is we'll quit out of here and show you what that looks like. Oops, uh, I've got the prompt saved here. I thought I had it. There we go. Wrong one. Uh Uh there we go. Sorry about that. So, for this particular, um, uh, agent, we've got a couple of MCP servers configured. So I've got a mermaid MCP server, so that's gonna help us build diagrams for the requirements and um the business requirements that we're gonna do, as well as the implementation plan. I have a fetch MCP server to go and fetch things off the internet for us, and that's cause. When we build the Flappy Hero game, I wanted to be able to go and fetch AWS services from the internet and use that instead of normal, um, a normal flappy Bird game and um make that a little bit more interesting, maybe use a Halloween and a Vegas type theme. So I've got a some tools that I've got loaded here as well. Some I've also some read and write tools as well. And the reason for not um putting all the tools that the MCP server has access to is, um, as Derek mentioned, you've only got a certain amount of um space in your context window. So you don't want to overwhelm um the agent with tools that it doesn't need. So I've locked it down just for specific tools for it to do that with. And then I've got under the resources, the AIDLC workflow. And as we mentioned, we'll link that in a QR code towards the end of the uh of the presentation. But it'll give you a list of all the um the different components of the AIDLC and all the different questions and answers and how it all works throughout there. So I've told the agent to be able to access that as well for the purposes of uh building this out. Um, and then hooks, as we mentioned earlier, that's something for you to, uh, for the agent to take action on. So really good for sort of CICD pipeline type things that you might be doing. We're not gonna do anything for that in here, um, we're just going to, um, focus on using the MCP servers and the AIDLC and the resources configured with that. Um, so with that, I'm gonna switch to my agent, um. And we're gonna select that one, and that's gonna give us the agent that we're gonna use to actually build out the game. So. Yeah. Thanks Karen and you know just to emphasize, uh, this is a relatively simple thing to configure uh but by pulling in those resource files we're gonna dramatically alter the behavior of the agent as you'll see in a minute here from what we would get by default and so there's a lot of power under the hood that we can have here by developing custom work flows specific ways that we want the. Agent to work, uh, and that's something that teams can work together on and refine over time and we're seeing libraries of these emerge within customers as the different teams kind of maybe build their own um repo internally just to refine these files get these better and better over time so there's a lot that you can do here by just loading in a a few context files and a few tools. So we're gonna spend the rest of the the time here, um, building and the goal here is to build a game called Flappy Kiro by the end of the session we'll see how it goes. It's live, so, uh, we, we have some backup plans in case things, uh, uh, we have some kind of problem, but, uh, I'll try not to jinx us here. Um, Flappy Quiro is, uh, is a game where, um, Kiro, the, the ghost, I think his name is Ghostie actually we decided. OK, so Ghosty is going to, uh, be able to scroll through a side scrolling game, and when we push space bar, he'll flap up in the air when we let go of the space bar, he'll drop down and he's got to avoid obstacles and get a score. Um, the point here is, is less about the implementation details that we pick or what language or hopefully the game actually works, uh, and whether it's good or not. Uh, what we really wanna do is, is focus on the workflow and focus on how we can use AI from the very beginning to help us get our requirements and our design and our thinking about our plan, uh, and, and our testing and everything that we need to do in order to build, uh, production grade software. So while we're not building production grade software today, and we're going to sort of speed through some of the steps, I hope that you walk away today, um. Maybe inspired a little bit to go try some of these techniques yourselves, um, and try doing, uh, an end to end, uh, you know, uh, task or story from your backlog, uh, using, uh, this process and using AI from the very beginning, uh, of your project. Um, so, uh, any, anything else I should do to tee up Flappy Kiro here? I think it's a, it's a pretty straightforward game, and we'll get into some of the details. Yeah, yeah, we're gonna try and get it to work on here as well as a mobile phone, so we'll switch to the development tools and see if it works on a mobile, but we'll try and get it to work first, and then we'll go from there. All right, let's see how we get on. OK, let's see if this works. Oh, great. Yeah, it did. Great. OK, so to build this, um, we're gonna just use one prompt. Um, so this is the prompt I'm gonna use. I'm gonna walk, spend a little bit of time going through it. So the goal is not to do any prompt engineering or have any secret source baked into this. We're gonna have one clear prompt, and then we're gonna go through the AIDLC process, which has been shortened to fit into the session today. So, the first thing we're gonna do is we're gonna use um Derek mentioned in the presentation, a lot of the LLM's trained, um, you know, the latent knowledge that it's got when it was trained. So a lot of this, it's aware of, and it can actually make a lot of assumptions based on this, but we still want to guide it with proper requirements, business requirements, um, you know, functional requirements, non-functional requirements, and then implementation plans. So the first thing is, I'm gonna say, I wanna build a browser-based game called Flappy Hero for a live demo at AWS Reinvent. We're gonna follow the AI DLC methodology and workflow. And we're gonna ask the LLM to ask us clarifying questions so that it can then um provide the answers as inputs for each phase. Um, I wanna show you some, uh, mermaid diagrams. So when it actually builds out the file structure and the implementation plan, you can see what that looks like. And if you look in the IDE it actually gives you a really good visual of that. Um, because we're doing this in the CLI I'm just gonna use a, uh, a mermaid, uh, webpage that we've got, and we'll show you all the architecture diagrams that it does. Um, so we've streamlined the process, obviously to fit into the session today. When we run this with our customers, it's usually a, uh, a one-day workshop, sometimes two. Um, but we're gonna get this to work in 45 minutes. Um, and then we're gonna maintain interactive questions and answering throughout the process, and we wanna save the files in the working directory, so it doesn't put it everywhere. So I'm being quite specific with it, but, um, we still have to, we're still gonna do uh quite a bit of guidance and give it themes and everything like that. Are you any questions as you go or not? Uh, the question was, are we, are we using questions as you go? Take questions as we go. Um, I think, uh, while, while the agent is thinking, I think we'll have some time, yeah, yeah, especially through the bill phase, it takes a good 5-7 minutes, so we can take some time then, OK, so we're gonna go ahead and execute this and, um. Fingers crossed. So the first stage is gonna be the um the analysis phase where we're gonna gather all the requirements. Um, in the real world, this will be your business requirements that you might have within your organization. I give this agent permission to do that. Um, so it'll be things like, um, you know, what sort of third party systems do you need to use, what sort of, um, Uh, logging or anything like that that you might have, if you have any security postures that you need to follow, things like that. That will be part of your business requirements. Um, so, here we go, it's gone and created a, uh, Alright, and I will make this bigger. And Mm If anyone has any suggestions, we can take them as well as we go through this. Otherwise it'll just be me uh filling these out as we go along. And um, as Derek mentioned, each time we run this, we get a slightly different result, so it's not always the same. The questions do come back a bit different, but when you use the full AI DLC you get very specific and then you tend to get um. The the correct response just to elaborate if I, if I can Karen, um, I think what we find is that the, the frontier models, the LLMs, they're eager to please, right? And so if we're vibe coding, uh, often the model will sort of take, take what you've asked it to do and start running with it and start building stuff, uh, rather than sort of stepping back and thinking critically like, you know, maybe a senior engineer. Might step back and say, hey, before we build this, I've got like 15 questions about hey, what did you think about security? Did you think about this, you know, what about this edge case, right? And that's kind of the, the conversation that we wanna be having and so really, um, what we've got loaded into the context here is a lot of specific instructions saying hey don't skip any of these steps if we don't know the answer yet, let's get the answer before we keep moving. And so the first step here where we've told we've told um Kiro hey I wanna build this thing is OK, I've got a bunch of questions please answer those for me before we continue so uh we'll we'll fill those out here but um it should keep asking us until it's clear. Yeah exactly yeah and. These questions are predefined ones, um, this isn't like a final list. If you have something when you're doing this for an enterprise app, you can go and actually put those in there. So if there's a question you feel that your, hasn't, you know, met your organisation's needs, that's something that you can just insert in there too. It doesn't have to be, um, it won't freak out, and I'll show you an example of that, so. The way I answer these questions, I'm supposed to fill them in down here. I'm just gonna say yes, no, and then for this one, I'll fill them all in down here for question two, and we'll go through it like that and see how the agent deals with that. So, um, for the first question, uh, we want it to continuously fly and, um, or it is, or only, uh, when clicking, um, when, when pressing the, the spacebar. So I'll say, um, yeah, um, press. I'll just say a button. Press a button to fly and then for the easy, difficult, um easy, medium or hard, I'm gonna say uh easy has, Large, uh, larger, yeah, I could say larger. Obstacle gaps, um. Getting harder. As the game. Progressives. There we go. And um should the game speed increase over time, I'll just give that a flat yes. This takes quite a bit of time when you're building out an enterprise app, but uh hopefully we'll get through this quite quickly. Um, so the, then we get to the, the visual sides of this too. So what I wanna do is, um, I'll change this a little bit. We're gonna use say maybe um, Uh, some of the AWS colors, I'll go with, uh, orange and black. I'll go with a Halloween theme. I think it was recently Halloween, um, and, um, say Las Vegas. Theme as well. Let's see how it deals with that. A lot of typos today. OK. Um, do you want the Kiro Karo to be a simple shape, bright, or custom design? So Kiro is a ghost, so we're gonna use a, say purple, purple. Ghost. Character. Um, should the obstacles be classy, um, you know, the classic, um, obviously, it's got that latent knowledge, it knows exactly what that game is. So let's go with, um, AWS themed. And um It's got that from the prompt that we did with uh saying that we're doing an AWS reinvent presentation, and then we wanna say uh use say AI and. Coding services. From AWS. There we go. And then scoring and leaderboard, uh, what kind of scoring features would you like? Um, I'll take suggestions if you want to shout them out too, otherwise I'll just fill these in. Um, so we'll, so, uh, simple score, or do you want to use a leaderboard? So we'll just go with simple for now. And then, um, here we're just gonna use local storage cause we don't have anything like that configured. And in, in the real world, obviously, it's looking for, you know, if you're using an API gateway, um, you can use something like Cloudfront if you want this game to be globally available, closer to your customers in different regions. That's something you'd specify over here, but for the purposes of this, we're gonna do this. Uh, we'll say yes to that. And then, um, how long do you want it to be? I'll just go 1 to 2 minutes. And um I'll say yes to that. And on a mobile phone, test that towards the end. I like the ambition level here. You're adding a lot of features. HTML and Java, let's use those two for the purpose of this. Single file, I think we'll use multiple files, cause I wanna have proper structure for this. So in case we need to go back and change something, or we wanna document any of these decisions and come back and ask why we did that, it's all nicely documented. So we'll go with multiple files. For that. Yeah, yeah, good catch. It's pretty good at picking up all my bad typos, so I'm in that. Yeah. I'll see how it deals with that one. I'll leave it alone. Um, any AWS services you wanna showcase? Anything? Should we do that? Should we do, um, I don't think it knows about Kiro yet. Mind you, it's got that MCP server to go and fetch, fetch things like that. I'm a prouder, but uh, it's probably not work. Uh, so it's not appropriate here. Sorry, Amplify? I can do that. Let's see what it does there, and I'll put maybe bedrock, since it's gonna be running on that. Um, OK, let's try those. And then um start string instructions, so we say uh yes with um. I would just suggest Karen for amplifying bedrock maybe just make a note that we need a way to test locally, um, since we're not gonna have time to deploy to an AWS environment so. Cool. Alright, uh, restart button, I'll just say yes and then we'll move on to the next phase. Uh, mobile support, um, sorry, support for mobile. Uh, browsers, I think. Um, and then maybe wanna use maybe Chrome and Firefox, I think those are the two commonly most used ones, Chrome and. OK, great. And that's it. So we'll go ahead and save that. Close that up and then we can say done. And again, we're still using that single prompt, and it should now go ahead, read those answers, and um come back and start building out the um the design phase. Um, and the whole purpose of this is we're bringing the um the agent and the LLM into the decision-making process. So, um, yeah. So, sorry about that, saving a lot of time. And just to note that we were just doing a lot of what I would call classic product manager work and less software development, uh, but it's very important obviously and one thing that we're finding is that, um, getting together cross functional teams that maybe not might not work together next to each other day by day but getting the product managers and the stakeholders along with the software developers maybe QA ops right getting that cross functional team that's gonna be responsible for this thing. Sometimes physically together or at least on the same call and working together on answering these questions can help teams get this right up front and skip a lot of back and forth that we might traditionally do where we need to email or cut a ticket to someone to find out uh and so if we're able to do this collaboratively up front, uh, we can dramatically cut down on the time needed for us to get all of this right. Uh, and the, and the agent in this case is really our, um, our helper to make sure that we're documenting it properly. Yeah, thanks. So, now we've um moved on, moving on from what to build, and now we're going on to how we're actually gonna go ahead and build that. So it's taken some of the suggestions of Sage Maker, Amplifier, I saw that there in Bedrock. And um now it's gonna come through and ask us, you know, how are we're gonna do these. And if you think about, these are now your more, your technical requirements. We've defined the business requirements in the first phase. We're moving on to more of the technical stuff right now. So, um. Earlier on in here, it's given us um using that uh agent that we configured, um, we told it to have the Mermaid MCP server, it's gone in and actually built out some mermaid diagrams for us. So I'll show you what that looks like. Hopefully that looks good on the screen. There we go. So it's actually um already documented and drawn out what it thinks this is gonna look like. And um do you remember that one prompt? Do you want everything in a single file, or do you want it split up? And it's gone ahead and split that up for us as well, with specific files for different things. So, we have JavaScript files and um HTML files, so you can go there and make changes later. Um. So this is really useful for things like that too. So I just sorry. Come back there. OK, and then um if we look over here, so let's have a look at this one here too. It shows you the different components that we've got over here. Sorry, I left my mouse at home, it would have been a bit easier, wouldn't that. There we go. So, it's showing you the different, um, you know, the different layers it's gonna build out and, um, and how that's gonna look. Does that look good on the screen? Go a bit bigger. Mhm. So we find this really, really useful. Our customers have told us that, you know, this saves a lot of time with the documentation and, um, you know, and, and how that's gonna look, and they can use that for all their different change controls and, you know, when they're submitting tickets to have this all built out. So we're getting all of that, uh, you can, you remember I said local storage only, we're not gonna deploy that to anything else, so that's done over there. We already talked about how we're gonna do the obstacles, it's gone and filled all that in, the scoring, I said do that as we pass the obstacles and um the difficulty controller from the uh easy, medium and hard. So all of that's all in there already. OK, so let's go back in and fill out that uh. Fill out the rest of that for the technical requirements. OK, so the first question it's got is which AI coding services should appear as obstacles. So um I'm just gonna say, use all and um use them randomly. Go. Um, how should the difficulty levels differ? Um, now I've found, when I've been building this out, testing this, is, uh, it usually, the gravity is way too strong, so the board just falls like a stone, no matter how quickly I press, uh, um, the spacebar. And the, um, the gaps are way too short, so I can never get past the first couple of hurdles. So I might go in here from my uh previous knowledge and tell it to, uh, be, um, to be a little bit better with that. So I'll say um start slower, uh, larger gaps, and uh less. And less gravity. Um, and then I wanna use it to use 60 frames per second. And then, um. Now we've got the visuals, so shall I generate a simple CSS canvas, or do we have any image assets? I start with a normal simple CSS canvas, but then you can go back in, download specific assets or um any audio images that you've got for the game, and you can put that in. But it does a pretty good job of filling the, uh just, you know, coming up with stuff itself. So we'll go with um CSS. And then um ghost animation. Do you want a static, bobbing, flapping wings? Let's um animate the ghost. Um I When it was flying. Um, let's use official. AWS icons. I don't think it's going to be able to do that unless we actually give it to them, but it's going to try and draw them up and then typically it use emojis or something like that too. Um, sound effects, um, I'll just say use or suggested effects just with the interest of time. Um, here we go. And then this question here, the Bedrock integration, how should Amazon Bedrock be integrated, uh, dynamically, AI power difficulty adjustments generate. What do you think? This is quite interesting. I think those are all future, future, uh, enhancements, right? So it probably doesn't matter for, for this demo. Yeah. And then here's the file structure that it's gonna go ahead and create for you. So, instead of creating that one big file, you saw that diagram, it's gonna go ahead and break these down for you in the different files that you're gonna use, and that means you can come back in and put in your own images and your own sounds when you want it to do so. I'll just say. OK. And then we're going to just set that. So again we're we're almost kind of like speed running through the steps and and almost vibe coding in a way right by not engaging more here and uh doing a much richer discussion in the interest of time but uh you know again I think you can imagine um this is where I in my opinion the interesting work is gonna happen is around these decisions uh that we're making around technology selection and. Uh, what should we do first and what can, you know, what's a P0 versus a P1 feature and, uh, what's our, uh, architecture gonna look like, um, you know, this is where we as humans, uh, should be spending our time and if we get this right up front, the actual implementation phase is almost the easy part hopefully because we've already done all of this hard work up front. Uh, and so if you're not already, I, I would encourage you, uh, if you try AI DLC, um, you know, spend a good amount of time up front in these phases, um, get this as refined as you can, and then see how the implementation step, uh, works out for you. Did you get to do this in phases just by saying I wanted AI DLC. Yeah, so, uh, we'll, we'll link at the end to the GitHub repo, but, um, our teams have, have put a, a good amount of work over the last few months, uh, again working with lots of different customers to refine this, um, we're using, uh, conditional context loading, um, because we have a finite amount of context window space. Um, there's a, an initial context file that we loaded that kind of kicks off things with the agent and tells it, hey, you're using this workflow, you're gonna use these very specific. Steps and then depending on what you're doing, if you're doing green field or if you're extending an existing application, if you want to do microservices, there's a bunch of decision trees that it'll make and say, oh, we're using a, we're gonna extend the legacy application. It'll actually load in additional instruction sets to make sure that we're, um, doing things in an orderly way. So there's a lot behind the scenes here that's getting loaded in as needed. Yeah, yeah. There's the, just the one markdown file is the entry point and it has instructions that says conditionally load these other files depending on, on what you're doing. We found that approach, uh, works well to keep the context window, um, not, not too busy. Yeah, and then to your point, the other thing you can do is you can have different agents for different phases of your development as well. So, you know, if you're doing front-end development, back-end development, you can have different agents with different MCP servers, different resources, and that way you can do, and they can just switch between those agents as easily as I showed you there and um, yeah, and that way that's a good way of getting a project done without loading everything up. So yeah. OK, so now, this is the part where we move to the um actual implementation phase. So we still haven't written any code yet, but now we're gonna, you know, this thing, you can start having it cut, you know, Jira tickets for you, and you can have your junior developers go ahead and run this based on the architecture diagrams that your senior developers or Quiro has built for you. So, um, again, Um, we're just gonna go through this real quick and um see what we can get from all of it. So approved to implement. Um, yes, we're just gonna go through, uh, the, the resolution size, link all the modules together. Um, and then here, if you have any specific styling that your organization might use, um, this is a, you know, a good place where you can do that if you're building an enterprise app. So that's something you can do there as well. And if there's anything, you know, you'd be sitting with different teams across your business, going through all of this and figuring out, is this the right thing to do. If it's not captured in here, you can obviously add it in there and change some of those files as well. And we'll go through that as well. Yeah. So we are gonna use JavaScript and HTML. I think we decided that was gonna be the best thing, so we're just gonna go ahead with that. It's just asking for that final verification before we do anything. Are there any Jira MCPs or integrations? Yep, there is a Jira MCP and so I, I was just thinking the same thing. Like once you get to this step in, in, in the real world, each of these might be more, more complicated and take more time. So you can imagine each of these becoming, uh, a story that goes on, onto the Jira board and gets pulled down for sure and that could be as simple as us taking this file and saying, hey, go, go create Jira stories for each of these, yeah. I'll be honest, this is uh different from the other ones that I've done before. Normally, it's another bunch of questions, but here it's just basically saying, you've provided me enough, um, and just give me the verification for that. So just answering yes. We'll have a look at this diagram that it's given us. This should be the implementation diagram. I, I didn't grab everything there for some reason. I thought I had it all. Yeah, I did. Didn't like that. OK. Try it once more. I suggest Karen, in the interest of time that we, yeah, we are running short keep going. OK, and you can see when it gets to this part, the agent's already thinking about how it's gonna generate the testing, so it's gonna have functional testing and any sort of unit testing and stuff you might wanna do for your code. It'll generate that in the, in the next phase too, but it's already thinking ahead, how am I gonna test this end to end, you know, this is quite a, you know, obviously the different, I've said to it, use of, you know, uh Firefox and Chrome because it's gonna go on mobile phones. It's figured that some people are gonna have iPhones and it's put Safari in there as well, which is great. Um, Chrome mobile, Chrome desktop, so yeah, so we'll go ahead and save that. And OK. Now it's gonna go ahead and create all the uh the different uh files for us to actually build the project up. And there we go. It's gonna create the assets file, the CSS files, the JavaScript files, and hopefully, we'll get a working again. So this is where it takes a few minutes, 5 or 7 minutes if it works, and, and we spent a lot of time on requirements, design, technology selection, not coding, right? Uh, we've got 16 minutes left in the hour. Uh, we'll see how we, how we get, uh, on, uh, but again, um, this is sort of the almost the opposite of, of vibe coding and starting with build. Uh, and, and, uh, this was really the, the thing that we wanted to impart is, um, it's, it's time well spent, um, doing this upfront. AIDLC is one framework. Um, uh, again, there are other approaches. You could build something yourself. Uh, you might consider forking what we've got if you're interested. Uh, in fact, send us a merger request if you, if you find, uh, a way to do to improve on the process. Um, but the idea is to have a plan. Uh, going into the, into the process, uh, yeah, I'm working in a similar way. Process, uh, but my, my struggle with that it's always very linear, so you've had everything, all the details. I feel some of the questions we have seen seem relevant at this point in time we don't really care. Um, and then when it starts building, you realize, oh wait a second, actually I want to change my mind and and change things, and it's very difficult to go back because you're forcing not only the model but also yourself in this linear process. Do you have any experience with that? It's more like, uh, looking for like a more iterative development, like, like build a very simple first version or whatever, and then I'll extend it when, when I've seen it. Yeah, to, to summarize the question, this, this process, um, has been linear, right, where we do all these steps in order, uh, and in reality, in, in real life, we might start implementing phase one and say, actually, I changed my mind. I want to change, tweak the requirements. I think, uh, you certainly can, uh, go back to one of the previous stages, edit the the requirements and then ask the tool to update, uh, the design, for example. Um, I don't think I have any, any real shortcuts for that. Uh, I think there, we've got to pay the price at some point. If we, if we want to change the requirements, we're going to have to go through those steps again. Um, I think that the. By getting the right people in the room upfront, we can hopefully minimize that, that back and forth in terms of what the requirements should be. Uh, in terms of iterating on the design, um, and the implementation, um, one of the benefits is, um, we can move pretty quickly, uh, here. And so the it iteration step, whereas, you know, in previous lives, that might be like a whole sprint that we just used to build something, we've got to start over again, uh, we could potentially. Make that cycle time quite a bit shorter. But I don't, I don't have a way around, you know, needing, needing to go back and, and, no, no, it's fine to go back. It's more like the, the, like the context is blown up, etc. if I wanna go back, so I'd rather like build the like an MVP thing of this game, document what you did, then I'll look at it, change my mind, and then like review everything that we have specified so far and maybe change the specification and so it's like a, like a cycle process. Yeah, you start with fresh context just with the key learnings from cycle one going into cycle two with more space in the context and starting from there. So just to repeat the question, the question is about, um, being able to, um, save the context and go back and edit it later, uh, and be able to iterate based on what we've learned so far. So, um, we're writing all of the. the design decisions into, into markdown files, uh, all of the Q&A and all of the descriptions of the, um, requirements and design and such. There's also an audit log that automatically gets written of all the questions and decisions that were made, um. One thing that, uh, we've seen is just taking all of these files and attaching them back into the JIRA tickets. And so anybody that wants to go back and understand why did we make this decision, uh, or, you know, what was used to, as input here, uh, we can go back and, and reproduce it. Um, we've also seen, you know, the, the context window can get full and so in between each of these steps, we've actually cleared the context and then started fresh again and that kind of proves to ourselves that everything that's needed to reproduce what we've got is stored in these, in these. Marked on files, uh, yep, and, and that's, that's in our custom agent, yeah. And then so in theory, we should be able to go back to any step at any time, uh, use one of these as artifacts, make a tweak, and, and move forward from there. How is this different from using the Cara IDD because I use it and it follows very similar phases where like I believe we have the design requirements and tasks, and here you have analysis, design, and implementation. Do you think one is more powerful than the other, or depending like if we, you did, you did your own custom agent, so it's like in that case, would this be more powerful than the spec. The question was, uh, which, which is sort of the better approach. CO ID has spec-driven development. We're doing this AIDLC workflow in the CLI, um, they have similar bits of functionality. Um, we, we're, um, Moving fast in all of this. Um, the IDE I would say spec-driven development, um, is less customizable at this point, but you're going to kind of get what you get. And for a lot of customers, they really like it and they're using it. Uh, this is much more configurable. Um, this, the ADLC, uh, approach or an approach like this gives you the ability to tailor this process with your developer development teams over time and make it as granular and specific. Always do it this way, don't do it that way as you want. Um, in return, the process is, is more complicated, right? It's gonna take more time. We're skipping a bunch of steps. Uh, if we were going through the full thing and, and we hadn't told that we were doing a demo, it would be documenting tons of user stories and asking what persona should we be doing and so it'll go a lot deeper than this and so I would suggest that, um, maybe as a starting point or, uh, for features that, um, are a little bit more. Um, I don't wanna say straightforward, but, um, I, I would say uh Kiro ID is a good starting point, um, but if you're looking for more, um, ability to customize, uh, or the ability to get, uh, a few levels deeper into the requirements, I would suggest that this is a good approach. But I also think that you'll see over time we'll continue to build out that spec driven workflow in the IDE, and that'll get more and more features as well. Um, how, how are we doing here? It, it built actually quite quickly. There was no, uh, contention on Bedrock. I think, uh, I think we're good there. So yeah, I have to see if it works. Yeah, well, that's, uh, yeah, so it did, um, it did build us a, um, an the implementation plan, and then let me close that down and bring up the other one. So yeah, we got all, you know, all the coding was complete. You get a, a, a full report of everything that was done, how much code was written, all the features that were implemented, the stuff that we walked through in the beginning. Um, and, um, yeah, it tells you how to test it, and, um, and it also gives you, um, a whole testing plan as well. This is quite a basic one, obviously, but, um, you can obviously imagine what it'll produce when you do a, uh, a proper document. So yeah, with that, it's uh let's see what happens. So I think it's just this, this file here, we can go. So there we go. We got the start screen. Um Looks all right so far. This is the worst part. I go easy. There we go. Actually it wasn't too bad. OK, nice. The bedrock thing wasn't as, uh, impressive as I thought. I think that's a Pac-Man ghost. Yeah, yeah, it doesn't actually look, a thing that, but it's picking up scores and I, I don't know if there's any sound on here. I, I, there's no, I think we said no sound. Yeah, they said no sound, but there should have been. I can unplug my Mac in a sec. Oh no, I mean when we set up the stage we said no sound that was our mistake. That's actually better than I thought. A lot of them, um, just didn't work. It just plunked like a stone, but yeah, cool, nice. We've got 8 minutes. Um, happy to take more questions and discussion about the process. Also happy to take, uh, modification requests to the game if we wanna try that, uh. Yes, uh, yes, I will put that up, uh, right at the end here. I'll do some crowd work here. We go. So our team recently did a test where we went like full hero and just had it kind of go crazy and make a whole web app. My issue with it was that a lot of it was like inaccessible and like had like there was like window to open things and things like that, and I'm just wondering what recommendations you have. Like, is it like adding a front end MCP to the front of it? Like what would you recommend to help make sure it kind of followed what guidelines? Uh, so you're talking about accessibility like 11, OK. Uh, how specific were you at the beginning about your accessibility requirements and what was must have nice to have? I'm not sure I have delegated the I got it, got it. So I, I think that would be my answer, right? The more time we spend up front, again, if this is a web app, talking to the UX folks, the stakeholders, the product managers, getting really into the weeds on what are the non-negotiables for accessibility, and if we can get all of that, you know, decided up front and documented into one of these markdown files, I would expect that we would get, you know, better results there. Is there a way to, like, there's like WICA guidelines, like, is there a way to like more easily integrate. That even just as a base because there's like actual specs and whatnot, yep, um, so you know one thing is, as you're developing your, you know, version of this for your teams, uh, again you could imagine having a repo of these context files and a custom agent that you publish for the teams and say hey, use this when you're building a web app and in that custom agent in the context you could say the following are kind of company standards for accessibilities like. Thou shalt make sure that you hit these versions of uh these WKCAG requirements. Um, the model is gonna have a pretty good understanding of those requirements baked into its latent knowledge, but if you wanted to really make sure that you nailed it, you could say, hey, I'm guessing I, I would be willing to wager that there's a WCAG MCP server where that you can go, where you can go and grab the actual spec. So that would come at the cost of more context, uh, that you'd have to load, but you could, uh, I could imagine saying, hey, as part of our, um, verification, um, I want you to go, I want you to make sure that you that you've built all of this in and, and actually go test it, um, so I think you get as sophisticated as you wanted to and you know I would suggest starting by adding that up front into the context, um, and, and having it build that in. Thanks. Uh, you have had one over here. You go. Uh. I work as a manager of a developer experience team in our company and we have like 300 engineers as a whole and uh one of the difficulties that we have is like how we standardize the AI knowledge because people like to to use Qiro some of those like to use cursor cloud code whatever and uh when I look at this uh it's kind of like. A little bit more concentrated on Quiro or like uh how is the difference with like HSMD for example that's kind of like a standardization uh independent of the tools like that's that's a little bit of my question here is like how, how we can make that reusable instead of the tool that developer is choosing so probably it'll make it easier to to adopt. Yeah, um, so. Um, We're seeing a lot of innovation in all of the tools in this space, so things are moving fast. Agents. MD seems to be a de facto standard that's emerging. Um, that, that's good. Uh, the different tools have different ways for specifying, you know, this, this concept of, of custom agents. Um, this workflow, the, the AIDLC is, is just a bunch of markdown files. So, you know, it would work fine in clad code or cursor or what have you. So this isn't meant to be specifically tied, uh, to Quiro. Um, we think that Quiro is a great platform for, for doing this, uh, but we're not trying to sort of lock it down to one particular, um, tool, um. But ideally you're able to bundle together, um, the AIDLC or the, the context files that you have that you want to steer the behavior of the model as well as your list of MCP servers, uh, together and I have a way to publish that out, uh, to other folks, uh, in your organization. Um, so with KOCLI, that's just a JSON file. And so that all that could be is a, an internal repository where you say, hey, if you're building web apps, use this custom agent. If you're extending this old legacy app, go use this agent. Uh, and that combined kind of collective wisdom of how to operate around those different domains is, is baked into, to those agents, yeah. I saw one more. uh, uh, come over to you next. First of all, thank you for that great presentation. Um, when you have, you have these, these different stages in the AI DLC and, um, in the, uh, agent definition there was this, this line model that was null, so you leave the, the, the selection of the, of the, uh, model to use to to the automatic or would you suggest using different models for different tasks and stages in the AI DLC. Thanks for the question. Um, so by default we now have an auto mode in Quiro and that's gonna allow us to select the model, uh, and give you a discount, uh, in terms of credits, uh, and our goal with the engineering team, and they're spending a lot of energy on this, is making that auto mode work great so that you as a user would never have a reason to change the model, uh, because you're very happy with the outcome. Outcome. So that would be our recommendation is start with the auto mode, uh, hopefully you get great. Uh, if you're not sure you're getting great and you want to say no, I definitely want Sonnet 45 or, uh, or whatever the, the latest model of the day is, uh, you could switch to that and see if you get different results. Um, but our hope and our expectation is that you can start with just not defining the model, use the default auto mode. Yeah. I want to take one more here and I know we're just wrapping up on time. So first of all, thank you so much for the presentation, the demo, and I just try the Qro app and also the COI as well. They both work really fast. I really like it. Yeah, I like the product. But the things are, you know, I know a lot of independent developers. They try so many like AI coding agents, cursor, cloud code. So actually I want to get more insight that how to differentiate differentiation from Kiro and those another coding agents. For example, are we going to have more integration on AWS or you know, do some more, you know, integration work on enterprise integration? Yeah, thank you. Uh, we're right in time, um, but I'll say. Um, in terms of differentiation, we want care to be a great product regardless of where you're developing, even if it's not an AWS, and so our intention is, uh, to just focus on a great developer experience. Um, of course we wanted it to be really good at, at AWS as well. Um, so that's the thinking, um, you know, differentiators, there's a lot of smart folks that are building other cool tools in this space. I think it's a, a good time for end users because that competition is, is having folks kind of leapfrog each other and capabilities. I expect that's gonna continue to happen. I'd say one nice thing about Kiro is, um, when you subscribe, you have access to both the CLI and the IDE for one subscription. And we see a lot of folks that like to switch back and forth between those modes or maybe even use both at once. So I think that's a nice thing. Um, and I would say the spec driven development in the IDE, uh, which we didn't look at today, but, um, we've heard a lot of great feedback that that's a good way for developers to sort of structure, um, their, their approach. So I, I would encourage you if you haven't to try both. Try the spec-driven workflow in Cro IDE, uh, try the AIDLC, which is a bit, a bit more in depth, and, and see which one suits you the best. Uh, so very brief answer to your question, but I know we're, we're right at time. So, all right. Thank you all. Thanks, Kim.