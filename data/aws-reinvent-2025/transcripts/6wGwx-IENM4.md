---
video_id: 6wGwx-IENM4
video_url: https://www.youtube.com/watch?v=6wGwx-IENM4
is_generated: False
is_translatable: True
---

OK. Hi, good morning everyone, and thanks so much for joining our talk today on what cloud resilience really means in the new era we're in today, the AI era. I'm Dev Rishi. I'm general manager of AI here at Rubric joined with Adam, uh, the director of cloud specialists at Rubric. Today I'm gonna be spending some time talking about how Rubric thinks about resilience for AI. Adam is going to be talking about how Rubric protects some of the most important data aspects and workloads that are running in an increasingly cloud native world. Now at Rubric just about a month ago we announced a new product that we're putting out, and the real orientation for the product is to underwrite one of the biggest enterprise trends that we've observed coming up over the next 18 months, and that's really the rise of agents and Agentech AI. Over the past 3 months I've had a chance to speak with over 180 different organizations uh at the security and enterprise IT level to understand what are some of their key initiatives when they're thinking about their deployments around AI in 2026 and beyond and what are the key concerns that might be holding them back from being able to tackle those initiatives. Consistently, one of the main trends that arises when it comes towards the actual application of AI inside of an organization. Is the use of the term agentic. If you've been walking around reinvent this week, you've probably seen your fair share of agents and agentic AI as well. And I think that it often helps to be able to start with a definition for what do we mean when we talk about agentic AI. We define agents in gente AI as LLMs with access to tools. What that really means is models that can take action on a user's behalf. It's clear why we think that this is going to drive a lot of the enterprise productivity going forward as we think about workflow automation and productivity gains as some of the greatest areas that most enterprises have for being able to achieve business transformations. But the rise of Agentech AI comes with its own risks. AI agents in many ways are superhuman. They can operate at a much faster speed than a normal user might be able to, but that also means that they start to operate at an area where you can do 10x the damage in 1/10 the time. Additionally, AI agents operate with non-human identities and credentials. They operate within an enterprise ecosystem that was not necessarily set up for the AI generation. And I think we've started to see one of the biggest blockers towards enterprise acceleration when it comes towards the deployment of agentic AI. Is a fear of risk or another way is a lot of IT leaders I think that I've spoken to have put it, the lack of understanding of all the different things of what could go wrong. And these aren't hypothetical risks we've seen examples of these already in the early days of Genech AI all the way from moments in which a chatbot might be recommending things like a competitive product or even inventing things via hallucinations like refund rules. All the way to more dangerous types of actions like coding agents that have gotten access to production databases in order to be able to make change and affect change and have decided to be able to go and actually do something to optimize a subroutine that involves dropping the production database. One of the biggest questions that I think organizations ask when I speak to them about the promise of what generative AI and agentic AI can actually achieve is how they're supposed to think about being able to guard rail it and also what happens in the cases when things inevitably go wrong. One of the key aspects by definition that we think about with agentic AI. Is that it gets your AI agents organizations to your enterprise applications, tools and data. It's really what makes AI agents unique in terms of their capabilities. We're going beyond this ability to just do knowledge retrieval, better chats or search, and actually going into the world where an AI agent can update that opportunity in Salesforce, help you draft that email in Office 365, or even be able to help you update configurations inside of your AWS account. But the real trick that I think a lot of organizations uh deal with is what it looks like to be able to maintain and manage this new AI and enterprise digital workforce that might be spanning across different production applications that were invented well before the time that these AI agents actually started to get rolled out. In speaking with 180 enterprise IT and security leaders that I've had a chance to have conversations with over the last three months. Here are some of the key sets of concerns that we've really heard relatively consistently that organizations really tell us that they lack the single pane of glass that gives them starting number one, an answer to just the simple question of what AI agents are even actively running inside of my ecosystem. I've spoken to leaders of Fortune 500 organizations that talk about how this is a board level mandate, but the way that it's done today is manual. There's a committee, there's an intake process, or somebody is manually checking where all these agents are and creating their own registry. The next thing leaders are concerned about is what are the types of tools and data that an AI agent can actually access. Again, oftentimes a board level compliance mandate to be able to make sure that you have a data use policy in place. But how does this actually get enforced when you have agents that are built in ADLS Bedrock Agent Corp, Copilot studio, your own custom agents directly calling OpenAI, all the way down to the concern around how do I actually recover from an AI mistake. From my experience, AI agents have actually never been easier to build. The long pole and adoption towards AI acceleration in organizations is no longer the difficulty of being able to use AI. At this point, building agents can take days or weeks, but the deployment process and the approval process is actually what I've seen take months. I spoke with one Fortune 500, uh, leader in financial services who said that they weren't too worried about the risks that AI agents might pose in their organization because they know it'll take at least 9 months for that agent to get approved, and that's not really the formula for what I think fast adoption can look like. We saw this firsthand even at Rubric ourselves as we developed agents at the beginning part of this year to be able to start to automate more and more of our internal workflows. What we saw was that building initial proof of concept was done quickly. Our developers, our IT teams, even business users were able to build an initial proof of concept, just a prompt and a collection of like some LLM tools within days or weeks. What came next though was really I think the long pole. You needed to be able to create design docs and go through an AI committee for approval. The AI committee is oftentimes cross-functional across IT, infosec, and legal. By a quick show of hands, who here works at an organization that has an AI governance committee already set up? About half the room, uh, or so. One of the things that I think we've consistently seen, and I sit on our AI governance committee as well, one of the things that I insist, uh, consistently see from an AI governance standpoint is a real friction between the people developing AI and oftentimes the governance that's supposed to be in place. One of the things that we experienced was that each time we needed to go through this approval, it would take 2 months or so. Uh, and that was really before we started to get into the place where we were actually ready to build a production ready agent, so this entire lens started to get extended from the 2 weeks that we needed in order to be able to build that initial proof of concept to now multiple months to quarters in order to be able to get something that is actually production ready and pass these initial sets of checks. This is frustrating for us because each time we had to go through the review process we were essentially going through a checklist and trying to make sure that each of uh part of what we were doing was correctly litigated. Instead, what our developers and AI agent builders asked for is define a framework, define a playground and a policy environment where I can actually go ahead and build agents, and as long as I'm building according to the framework that you've had, let's cut down on some of this initial roadblock piece that allows me to actually accelerate the pace at which I'm adopting. And really get to my end goal, which is an AI agent deployed in production as quickly as possible. To me, the biggest observation to really entering into this space is that the real inhibitor to both ROI and AI as well as acceleration AI is no longer the difficulty of using the tooling, but the risk that comes with the tooling overall and the lack of good and effective frameworks to be able to tackle that. That's why Rubric has decided to get into this space and unify some of our core competencies in data and identity with this neogenic future. Now my name is Dev. Before I joined Rubric this summer via an acquisition, I was co-founder and CEO of a generative AI start-up called Pretabase. We worked as an LLM infrastructure platform and the backbone for a number of leading technology companies deploying large language models at scale. We joined forces with Rubric this summer because we see a real opportunity to be able to take our AI platform and mix it with what Rubric does best in class across data and identity to bring the enterprise wave of AI adoption here sooner. Rubric's core has always been in data backup and data resilience. It's a company that understands data and metadata incredibly well, providing data backup services for some of the world's largest, uh, and most regulated enterprise organizations. Rubric layered on an identity solution on top of that underlying data layer to be able to actually target some of the most compelling areas where organizations might see things like cyberattacks and others that require data resilience. And with the Predabase acquisition we've brought in an LLM and AI platform that helps us understand how to be able to build for an agent future. We've combined these three core competencies around data, identity, and an LLM platform for agents into a single area that we call our agent operations platform, and the key question some of you might be wondering is what do I mean by an agent operations platform? What does actually entail? To us, the agent operations platform, the product that we've come across with, we call the rubric Agent cloud. The Rubric Agent Cloud is Rubric's newest product. It essentially combines three key capabilities that we've heard consistently from enterprise organizations they need if they're going to actually accelerate the production rollout of AI. It always starts with monitoring and observability. You can't improve systems, you can't govern systems, and you can't remediate systems if you can't see them. So the first thing the rubric agent cloud does is it hooks into your environment and automatically discovers AI agents across the different places that they might be running so that we can actually populate an agent inventory that shows you what are the agents that are running, who's created them, what are the credentials that are associated with them, and what are the tools and data that they have access to. Earlier this week I'm happy to announce we also announced our integration with AWS Bedrock Agent Corp, so any agents that you're natively building within AWS automatically get discovered and added inside of our AI agent inventory as well, and that provides that first level of visibility that many organizations need when it comes towards AI agents. The 2nd challenge and the 2nd pillar for what we think about we call governance. Now governance like AI agents can mean a lot of different things to different people. But the thing that we've consistently noticed about half the room raised their hand when I mentioned AI governance, uh, committee, one of the things that we consistently notice is that organizations have governance policies that are intended to dictate what AI agents can or cannot do. For example, AI agents should not be able to get financial advice or mention competitor products, or AI agents should be operating in read-only mode by default. No write agents. Oftentimes what we see is organizations have these types of policies. But no real hooks or teeth into how to be able to enforce these policies or even know if that they're being enforced really at production scale today in most organizations this is done on people and paper. With the rubric Asian cloud, we're actually translating this into software, so policies become configurations and policies that actually get defined inside of our system either using rule systems or natural language and small models, and they can be deployed for governance in real time in any of your applications. And the third and final pillar of rubric, agent cloud, is something we call remediation. Rubric as a company with its real background in resilience for the cyber era has had a quote that I've liked for a while which is called assume breach. Assume that with all the good intent that we put in front something will eventually go wrong. And in my experience, I think that this is more likely to be true in the gentic future than not. And so with Rubric we've also released a feature we call AI agent rewind. What AI agent rewind allows you to do is undo a destructive action that an AI agent might have taken on any rubric protected property by allowing you to go ahead and restore that um uh action from a previous healthy snapshot that rubric maintains from backup. So rubric is already snapshotting your production environments if you're a rubric customer at a, uh, at a frequent cadence that allows us to be able to offer business resilience. And what we've done is we've cross correlated that with the observability and governance layer that we have in the rubric agent cloud and allow you to one click rewind any time an agent's taking a destructive action. So if you think back earlier to that dropped database example, the real beauty is. You are no longer stuck in the water if you actually had an incident like that. Rubric's AI agent rewind allows you to remediate quite easily. These 3 core pillars make up what we believe is one of the real accelerants towards the adoption towards AI in a lot of enterprise organizations. And I think sets us up for really the identity that I associate with Rubric the most, which is an organization that really has evolved as or uh as enterprises have evolved across different business transformations. When Rubric began as a company. It was really oriented around data backup for traditional business continuity and resilience reasons. Used to be that the biggest threat that existed out there was natural disaster, fire, flood. A number of years later, the next series of threats came in which were cyber disaster, cybersecurity, ransomware, and others. Rubert continued to layer in data security and identity security features in order to be able to help on this. And now we're in the AI enabled disaster um uh era. And this is where Rubric wants to be able to continue its trend of helping organizations adopt the next cutting edge technology by setting them up for a successful AI adoption cycle. But as I think we all know, AI's core is really in being able to manage and be able to use your data effectively for any of the tasks that you're doing. That's really what makes generative AI special inside of each of your organizations. And in order to be able to actually have that data, it relies on the integrity of that data, and the availability of that data, which is increasingly in many organizations living more and more in a cloud native universe. And so with that I wanted to hand it over to my colleague Adam who's gonna be talking more about what Rubric does in the world of cloud and cloud protection. Thanks so much, Dev. Hey everyone, um, yeah, so I think to piggyback off of what what Deb's, uh, talked about here so far today, one of the biggest challenges I see talking to organizations as they're moving more and more of their footprint into into cloud and expanding significantly is really answering a fundamental question of who is responsible for data resilience now I think. This is a fairly familiar diagram to most in the room. It's a shared responsibility model, and, uh, you know, it states AWS is responsible for the security of the cloud. You're responsible for the security of your data itself. But this has a push and pull, I think, with a lot of organizations where there's somewhat of a meta shared responsibility model. So when I talk to a lot of organizations on their data resilience strategy, depending on what which part of the organization I'm talking to. Um, what usually ends up happening when I ask the question of who's responsible for your data resilience is something like this, right? The platform team thinks it's the security team's responsibility. The A dev team says it's the platform team's responsibility, and then both teams are pointing at security for anything cyber related because they're spending a lot of money on cybersecurity tools, so they shouldn't have to worry about remediation in a cyber event. That's security's job. Um, this is a big, big challenge, especially with as, um, disaggregated as a lot of cloud organizations are to build efficiency, right? So there's a lot of different lines of business who all have different needs, and a lot of this also comes down to taking a step back and really thinking through what that mental model for resilience is and what you're trying to achieve with that resilience for your applications. Um, there's a traditional high availability which you get right out of the gate with, um, a, a cloud provider like AWS where you're just trying to build for that, um, resilience for common failures, operational outages, um, having, you know, uh, multi-writer, multi-reader nodes and, and databases, um, things that, you know, you're, you're designed to build for that failure. Then there's additionally disaster recovery where you're planning for things like those natural disasters or maybe regional outages as well. Part of that is also cyber resiliency. So how are you protecting your data from cyber attacks and making sure you can recover effectively. And these are all things that organizations need to build into a continuous improvement, making sure their CI, um, CD pipelines are able to, to achieve this, making sure that they have observability across the board too to make sure their, um, availability is in place if there is an outage that automation kicks in to remediate that outage, um, and really driving towards the ability to constantly test, um, for these types of scenarios. And now with data resilience, it's not one size fits all, right? So every issue you're trying to resolve has a different mitigating step. So one of the common ones most organizations use is just local snapshots. So PAS databases, Dynamo, EC2 instances, being able to have snapshots on those that are local. So if a Windows update goes bad or if a database corrupts, you're able to quickly roll back those changes in a couple of minutes. Um, something to keep the application highly resilient, um, but doesn't meet the needs for all use cases. The second one is more for human issues. So one common occurrence is not only just accidental issues that might happen from an automation. Uh, but things like accidental deletions, and that's where, um, a lot of times organizations need to build their application resilience strategy to handle for this. So it's not a matter of just having a local copy of the data. If you disable continuous backups on your Dynamo DB table, all of your snapshots are gone. How do you handle for that? So that's also an area where this is not only protecting against. That human element but also a regional outage too and having a copy of your data in a secondary location so then you can do a failover if you need. Um, not to be complete, uh, confused with things like replication for high availability use cases and resiliency, so having an S3 bucket replicating to, uh, another region to have lower query latent or things like that, but really more for that availability in the event of a disaster. And then finally, the thing that a lot of, uh, uh, organizations aren't thinking of top of mind is how do you recover in the event of an actual cyber incident. So in the event of a cyber incident that local snapshot you have is not usable because there might be malware on that last snapshot you took earlier in the day. So if you restore from that, you're just reinfecting the environment and that's really where, um, organizations need to have this cyber resilience strategy where they have a copy of their backup in a true cyber vault where nobody can touch it. It's immutable. You can delete it and then you can then recover from it in the event of an incident. So AWS talks uh pretty regularly about this 32,110 principle for that data resiliency strategy, something that I encourage all organizations to look at, to think about if they haven't already, but what this ultimately means is you have three unique copies of your data. That's not counting the primary copy that you're using for production use cases. Two of those copies, um, one will be remote, so you have it in another region, and then, uh, another one is going to be that air gap cyber vaulted copy, which is kind of your copy of last, uh, resort when you need to recover from some sort of cyber incident. And then in addition to that, you still have that local copy as well for, um, fast recovery for those operational instances. And then the most important thing is the zero. 0 issues found on recovery, and this is one that a lot of organizations tend to miss out on. Simply because they're not doing regular recovery testing, so they're finding zero issues because they're not doing the testing in itself. The last time you want or or the last chance to find an issue is when you have an incident and you can't recover. You don't wanna find the issue then, you want to be able to proactively find that issue. Now, I'm not here to say you should apply this to every single workload and every single um different uh application you have across uh your cloud environment. It really also comes down to this next step that um is pretty often missed uh by organizations as well, and that is really uh tiering your data based on its importance. So, uh, if you have an application that's very, very critical to the business and minutes of downtime equates to millions of dollars, uh, lost for the business, it's a mission critical application, right? It needs to be as resilient as possible, so you need to have that local copy. You need to have a highly available. Regional copy of that data to recover from and you of course need to have a fully cyber vaulted copy as well so you're protected from all different failure scenarios. Your tier one workloads still hugely business critical, but maybe their um downtime impact is measured more in hours as opposed to seconds and minutes. That's where you still need that local copy. You still wanna have a remote copy from, and there's some optionality or, uh, as as it goes to that cyber resilience. So sometimes it's workload dependent. Um, we highly recommend, um, at Rubric that this should also be a cyber vaulted copy. It's mission critical. The downtime for these types of cyber events is very, very immense. So even though it's, uh, not that tier zero, tier 1 still has a lot of business value and would create a lot of business pain in order to recover. Next is that tier tier 2 workloads, a lot of like internal ITT apps that um are probably very, very critical to the overall business. You're still gonna wanna have a local copy of that. You're still probably going to want a remote copy for that, but that is where that cyber vaulted copy, um, tends to be a little bit more optional. I see often with these organizations, um, once again this is one where we do recommend a cyber vaulted copy, but I see organizations sometimes combining these so they'll have their cyber vaulted copy in another region for these applications, so it does eliminate one additional copy, but they're still protected from both of those use cases so they can recover from. The event of a regional outage with that cyber vaulted copy in the other region and then last, your tier 3 workloads. These are the workloads that are a lot of the downstream dev test environments, things that are very, very easy, easily to reproduce. Babi is, um, a bunch of ephemeral infrastructure as well, things that if there's a bad day. It's not the end of the world. You can basically repave the environment, right? So you can tear down that whole AWS account even if there is a cyber attack and then just redeploy, um, through something like infrastructure as code and a brand new AWS account. So this is really, really critical to have a good strategy in place for classifying, um, and tiering your workloads to support the, the resilience that they require. One of the other blind spots, and probably the biggest blind spot I see in organizations is with S3. So S3, the data just continues to grow exponentially year after year after year. I'm always excited coming to reinvent to hear all about the new S3 announcements, S3 tables, vectors. S3 is, you know, transitioned so much, um, in such a short period of time from an archive and backup use case to really it's almost a cloud database. It's not even just storing unstructured data anymore. It's truly storing structured data with data lakes, um, all of the AI, uh, related workloads and ML workloads as well, and the growth is just massive, which means there's a lot of sensitive data in these S3 buckets. And there's a lot of potential areas where not only bad guys can get in, but even um we're talking about AI, AI agents, a lot of accidental deletions, and this means that the lines of business that are reliant on these S3 buckets need to know where that sensitive data is across all these new environments. They need to know what data actually needs to get protected as well. Um, they need to know what is the recovery scenario look like. And more importantly, a lot of these buckets nowadays are just petabytes and petabytes of data with billions and billions of objects. So it also becomes a scaling issue of just breaking the laws of physics in some way of if you have a 5 petabyte bucket and billions of files, how can you recover that in a timely and effective manner that isn't. Weeks to months of just restoring that data. And usually when I talk to customers, they say, I'm not worried about S3 because I have versioning and replication enabled. Um, and versioning and replication just isn't enough for the types of automation accidents we see nowadays and the type of cyber incidents that we see nowadays. Additionally, because this data is continuing to grow in these S3 buckets, there's a lot of additional sensitive data that ends up in the buckets that may not be intentionally put there. So that is all an additional risk to organizations because they don't know where their sensitive data is and what buckets, and that is a place of exfiltration for the bad guys. There is that deletion risk as well because your latest version you can recover from and depending on your versioning life cycle policy it's very there's a lot of scripting work involved um to try to get that to recover and going back to the the bucket that might have billions of of objects in it, say a data lake, um, just think about the time taken to try to recover. 10% of those objects to 12 o'clock yesterday. Who knows what that looked like at 12 o'clock? That would be a massive lift, so it's not a true kind of backup solution where you can go back to a point in time easily. That also leads to some threat blindness as well, um, because one common scenario we tend to see in S3 is there's a lot of buckets out there that may have something like a PDF that external customers download. So if an attacker can get access to that bucket, they can replace that PDF with a malware version of that PDF and then that extends into the environment. So that might not be something that's easily found, but then, uh, once it is found, you need to be able to not only recover, but recover back to the clean version of that so you're not reinfecting your environment. Um, and that also leads to some of this recovery uncertainty with just the fact that these buckets are growing and growing, and you need to be able to recover quick so you don't have an elongated downtime in these large massive S3 environments. So that's where rubric comes in. I think one of the biggest things we help customers do, um, especially in their AWS estate in general, but even with S3, is helping with some of that data discovery because you don't wanna slap a backup policy on every S3 bucket that you have in your organization. You just might not need it. There's a lot of S3 buckets out there that don't have a lot of important things in it that have easily reproducible data from maybe an Aurora database that's already being backed up. Um, but it becomes really, really hard to figure out which ones have that sensitive data and it might have low hanging fruit where you do need that extra level of resilience and a cyber vaulted copy. We also help with that resilience from protecting against that deletion risk. You can actually see not only, um, detect anomalies if there's a mass deletion event, one that may be malicious or accidental, um, in our product by default, but we also provide an immutable air gap copy of that back. Data. So a lot of the, the bad actors, what they do when they, um, get into any environment is to go directly after the backups. So the backups aren't immutable, they can be deleted, and then that means that a ransomware, I mean it's easier for that ransomware attack in the, um, uh, the ransom to end up being in a rock and a hard place where organizations might want to end up paying that because they have no other recovery option. Additionally, too, when we take each one of those backups, uh, we already are pre-calculating hashes on all of the backups so we can actually see malware as it comes in as it's backed up. We have, uh, uh, thousands of indicators of compromise that we're updating daily. So as we take a backup, we know in stream of that backup if there may be some sort of bad actor involved in there, in any sort of malware. Part of that too is helping us detect 0 days. Because it's a 0 day, so we might have been backing up that bad file weeks ago, um, and that impacts a lot of the recovery. So whenever we see something bad in the environment, we'll auto quarantine it, so you're not reinfecting the environment in the matter of a restore, but, um, additionally, uh, we're taking all of these different threat feeds and then we have the ability to, uh, scan all of the backups we've ever taken, um, and see if that zero day has impacted other parts of the environment. So you might have uh a security tool pop and say, hey, there's an issue in account one, and it might have already had an issue in account 34, and 5 that the security tools haven't picked up on yet. So we can help across the board recover to that clean point in time in a matter of minutes. And what we do across our platform with the rubric is really tie this together in one single platform, so. Uh, from the ground up, and I'll talk about our architecture here momentarily, it is very cloud native focused architecture. So all the different AWS workloads you see on the left, um, we protect under what we call, uh, rubric Security cloud, which is our overall SAS platform. It helps with agenic AI. It helps with, um, automation. We have full automation AAPI capabilities on top of it. We're protecting data and identity, and then we're doing data protection not only of cloud resources, data center resources. We also protect identity. So if you think about it, if your identity is compromised, OCTA, um, enter your ID. In the event of a cyber attack you can't even log into anything, um, so that's often one of the areas where we're protecting so you can do a quick recovery of that before you move into the the traditional production workloads as part of all that too we help customers identify the sensitive data in their environment through data discovery and classification that makes sure they're backing up the critical workloads in the environment, um, and not having any blind spots in their overall data resiliency strategy. And then on top of that, as I mentioned, we're doing anomaly detection and um threat monitoring and turbo threat hunting on all backups that we take um so that's all on by default um and not something that you have to regularly manage so that's all in one platform and then in addition to that we have third party integrations with a lot of other um uh cybersecurity companies out there to really bring that all under one umbrella in one platform. Now, as I talked about earlier too with classifying that tiers of data, one of the um coolest things I like um about our product is uh a functionality we have we call it cloud posture risk management. So before you take a single backup with a rubric, um, you can plug in all of your AWS accounts and we'll. Uh, immediately, uh, give you feedback on, say you have 800 cloud objects, you know, EC2, S3 buckets, whatever they may be, we'll tell you which ones are currently backing up with, um, you know, snapshots, uh, today. Additionally, on top of that, um, we can get, uh, a sense of if there's any sensitive data in any of these cloud objects. So if you have 800 objects, maybe 500 of them are, are protected with snapshots today. And the remainder though, the other 300, maybe those are test dev workloads, maybe those are things that just are blind spots and you're not protecting today. We can see maybe there's 100 of them that we have uh found some indicators that there's sensitive data in there, and that's a way for these lines of business to quickly realize, OK, maybe there's sensitive data in a downstream dev environment that shouldn't be there and let me delete that altogether, or maybe this was a science experiment that quickly turned into a production application that now is running customer data we don't even have snapshots in place on that, so we're, we're not even doing the basics of local recovery, let alone cyber or disaster recovery to plan for. So something very quickly in these large sprawling environments to try to um you know uh have a good starting point of finding those uh blind spots in the overall clouded state. Now talking about how we're built from an architectural standpoint, um, so we do everything with a lot of automation, especially when I'm talking to, um, AWS customers, they wanna do everything automatically, so we make that very, very easy for our customers. Um, so you have Rubric Security Cloud that is that SAS platform, that one platform that everybody logs into to manage everything from M365 to data center to cloud to AI agents. Um, for AWS we have a dedicated, um, AWS account for each one of our customers under that, and then everything in, in pink here is, uh, customer managed environment. So to do our install, and this can all be done via Terraform, we also support cloud formation, um, and just native APIs as well. Uh, we will deploy a cross-count IAM role. Now these roles are least privileged. Um, and we also, uh, support role chaining. So since we're doing a cross-count IIM role to perform backup and, and restore operations, um, that role chaining allows, uh, organizations if there is some sort of incident and you want to quickly cut off access to, uh, rubric for some reason, uh, you can just impact that one, cross-count role, um, that is chained, and then that will eliminate all access to the other hundreds of accounts you may have connected to rubric. And then each one of these other uh cross account roles, um, over on the left here, uh, they're fully lease permissive model. So in that top box there we have EC2 RDS and S3, but there's no dynamo DB so you can have that, uh, IAM role say rubric has no access to any dynamo because we have no dynamo ever planned in that environment. Um, making sure that we are just adhering to that lease principle. Over on the right, there's two special accounts. So first we have a restricted data processing account. Uh, this is where we're doing all of our data processing for backups. We want that to be restricted. We want that to be, uh, very minimal access. We don't want other applications running in there because this is doing all of the, the heavy lifting. So we wanna make sure there is nobody with, uh, physical access. Access to that, uh, to interrupt backup and restore operations. The way we're actually processing all of this data is through something we call exocomput. So that uses Guernetes under the cover, so stateless workload when we're not performing backup and restore operations, it's a footprint of zero in your, your cloud environment. But when we are performing backup operations, this means we can scale very linearly as well. So if you have one thing to back up, we have one pod. If you have 1000 things that need to be backed up, we'll spin up 1000 pods. Um, so very, very efficient as we scale to meet large cloud environment needs. And then that, uh, below that is what we call our data bunker account. So this is gonna be another restricted account, and this is gonna be where we would store the backup data. So it'll be in an immutable S3 bucket. One of the other things we're able to do here as well is tier off, um, the different storage classes. So instead of having everything in an S3 stor, uh, standard storage class, you can tear that down to, um, infrequently accessed or even glacier depending on the use case. So this is an immutable environment. Where, uh, nobody has access to it, so, um, if there is a malicious attack, your backups cannot be impacted whatsoever, and you'll always have a clean point to recover from. We do also offer, uh, what we call rubric cloud vault. So this is a logically air gapped environment. It looks very, very similar except that the S3 bucket is in a rubric-owned AWS account. So that means it's in a completely separate security domain altogether from your primary, um, environment. Now how do we automate from here after the the initial setup and that is through um tag-based um, so, uh, going back to that classification we talked about, uh, earlier in the, the, um, tiering, um, a lot of organizations will have what they call we call SLAs which are backup policies. So gold, silver, bronze just for, for simplicity for developers adhering to this Gold may be, uh, a copy goes to another region, you also have a cyber vaulted copy. Silver is just a remote region one, and then maybe bronze is just that local local copy for fast recovery. So as application developers build their, uh, infrastructure, the platform teams that they help support, they can just tell their developers this is mission critical, this is tier 1 or tier 0, make sure you put, you know, backup equals gold as a tag on that environment and we'll automatically start backing that up. So the application team don't have to get involved too heavily in managing their own backup and restart if they don't want to. Um, they can offload a lot of that mental burden, but everybody still knows in the organization what is backed up, what is not backed up, what is protected, and at what level. Um, this goes to the next step as well. Whereas new accounts uh get on boarded into the environment, we can place that um cross account IAM role as part of a deployment pipeline and then any new resources created in that new AWS account, assuming that they are um tagged properly, will automatically start backing it up. We do also have automated role-based access control, so if you do have an app team that does want to self-service their backup and restore, you can limit their access in um the Rubric security cloud environment so they can only see the AWS accounts that hold the data they care about and not the entire enterprise. Um, with all of this as well, this is also how we can integrate from, uh, uh, infrastructure as code standpoint for recovery. So if you need to recover to a net new environment, you simply would deploy that code pipeline, new AWS account or cross-count IAM role is in there, and then you can instantly start recovering. Now, I talked a lot about terraform infrastructure is code, and I think that leads to one of the next big blind spots I've seen over the past probably 12 months. Automation is kicking off more and more across the environment. Developers are developing more and more, and one of the next biggest gaps is, uh, the DevOps environment itself. Right, there is a lot of news in this space, um, recently with the overall DevOps platforms where that code repository is, and these are really critical workloads for organizations. Not only is it where the crown jewels of code lives, the metadata around all of that code, and then also a lot of the collaboration tools and productivity tools that these app teams leverage. So it is, uh, the work items, the wikis, right, the, um, IAC, uh, pipelines, the ML pipelines, those are all included in these DevOps workloads and things like GitHub, GitLab, etc. And uh if you start thinking through this a little bit more and more, this becomes a pretty key area of downtime um if there are any issues in this environment, um as it impacts each, each one of these areas here. So from that developer collaboration standpoint with things like wikis and work items, well, if there's an issue in that part of the environment, guess what? Engineering planning comes to a halt. Um, there's no more PRD reviews. Uh, what is the next thing I need to do for this project? You know, until that's recovered, they're, they're, they're dead in the water. Um, if you're pushing out a new update, maybe there's a large marketing event and you're planning on pushing an update, well, if your CICD pipelines are down, you can't push that out, or maybe there's a critical bug that needs to get fixed. Your AIML pipelines too, when those models are paused because there's issues, that means there's a lot of potentially expensive GPUs going to waste during that time period. And then going back to what we talked about originally here, that cloud inframan, so your infrastructure is code. Well, if you have a cyber incident, how can you repave that environment, um, and redeploy if you can't access your infrastructure as code, um, state files. So that's why, um, as a result of this too, uh, or apologies too. So, uh, the way that is typically protected today as well tends to also fall down. So there is native version history, right? So a lot of time, um, with some of these, uh, native tools you have about a 30 day recovery window, a little bit of a recycling bin, but that's limited retention, and then, uh, there is that vulnerability to permanent loss because you can empty the recycling bin and then there goes the data, um, so that leads to a resilience gap. There's also a lot of manual scripting you can do to do your own form of uh backup for a lot of these that creates a lot of operational overhead and who's monitoring all of these scripts, so that means that I've seen time and time again where uh organizations thought the process was working, but the script needed an update that never got updated. The monitoring wasn't in place, so they thought things were being backed up and they didn't realize it wasn't until there was an issue. And then there's the other option of, hey, I also, my developer, I'm a uh I, I have my code also sitting on my laptop as well, right? So hey, the code repository goes away, I have a copy of it on my laptop, we'll just recover from that. Not only is that uh um. A governance nightmare for many infosec teams, uh, there's also a recovery gap. Whose laptop is the code on? What version of code do they have? How am I gonna recover that back for all my other developers? And then lastly, there's a lot of point solutions out there as well to handle some of this. The part of the issue with point solutions is that's just another tool in the environment of ever growing tools, um, which means oftentimes too there tends to be compliance gaps where these point solutions aren't meeting the needs of a more enterprise organization from a compliance standpoint. So recently, uh, we, we just announced, uh, our own DevOps protection. So we're able to protect these code repositories, all of these pipelines, and ensure that in the event of an outage, you can recover these, so then you can recover your cloud infrastructure as part of it as well. Um, it helps with the automation, it helps with, um, uh, ensuring that resiliency, and most importantly too, this is all integrated into that general rubric security cloud, so you're not managing multiple tools. It's all together in one single platform. So with that, I did wanna give everybody in the room some homework, um, so. Because who doesn't love a little homework, uh, so when you go back to meet with your teams, um, and I know often there's, uh, the, the team meeting after a reinvent of, hey, what did you learn at reinvent? So I think some things you can pose to your internal teams to get some of the gears, uh, going too is do you really have a clear strategy to govern and protect against destructive AI agent actions that Dev talked about. Additionally, too, has the organization defined a cyber RTO? So RTO recovery time objective. That's something that's been around for a long time, right? If the business can sustain 4 hours of downtime, you need to restore the application within 4 hours. Cyber RTOs uh really translate over to if there is a malicious attacker in our enterprise, what is the recovery time from that ransomware attack. Most organizations don't have this defined because they've never tested it. But when you ask anybody, they usually go, it's going to be a long time, and the impact of a lot of the recent ransomware attacks and cyberattacks we've seen. That have had elongated downtime. It's not because they didn't have backups in place. It's that they couldn't find a clean point of recovery to restore from. So they're getting in this repetitive motion of let me restore from the latest snapshot, go run a bunch of security tools on it to make sure it's clean. If it's not, rinse and repeat that process. If you do that across thousands of cloud objects, that becomes a massive lift and elongates downtime significantly. And then additionally too, how are you safeguarding that DevOps, uh, environment? It's now a tier zero application. I walked through all the potential scenarios that can cause massive, uh, uh, compliance issues and, and resiliency issues in, in the, um, development life cycle. So how is that being handled today if there is downtime? And then lastly, and still one of the things that I think is most important, when's the last time you've actually ran a test? Can you recover if there is an outage? Be it cyber, be it regional, be it operational, is there actually a true, um, way to recover? So with that, thank you all. He's the QR code, um. I think we have a little bit of time for Q&A too if uh all right we'll be hanging around if there's any other questions after this, but thank you all thank you all very much.