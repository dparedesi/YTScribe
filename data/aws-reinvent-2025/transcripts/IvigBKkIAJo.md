---
video_id: IvigBKkIAJo
video_url: https://www.youtube.com/watch?v=IvigBKkIAJo
is_generated: False
is_translatable: True
---

Uh hello everyone. Thank you for joining us today for our code talk. We are going to talk to you about building out SAS applications and using Agentic solutions, more specifically Quiro, but everything that we're going to talk to you about is absolutely transferable to any other solution that you would want to, to use. And uh well I can start the introduction. So I'm Jean Mala. I'm a special solutions architect covering Gieve AI at at AWS, and I've been doing AI for the last 20 something years. Uh, it's funny because everything comes back full circle. I started in natural language processing and now that's everything we do. And I'm joined with Sunil. Hey all, my name is Sunil. I'm a senior solutions architect with AWS. I cover large scale ISVs, and we're excited to present this session today. All right. So let's quickly look at the agenda and what we're gonna cover in the next hour. We'll start with some multi-tenant SAS concepts. We look at the current architecture which we have, uh, white coded. Um, I'll take a quick pause here. How many of you are using white coding spec-driven uh development or are familiar with it? All right. It's not the majority. I, I, are most of you using agentic AI or building agentic AI? Like if you're using or building agentic AI, raise your hand. OK Interesting split crowd. So, uh, the sets of the architecture and the solution which we have built is completely built using AI DLC. It's AI-driven, uh, software development. I think we've come a long way from water waterfall approach to agile, and now we're in the AI world, so AI is coming into the coding aspect too. So we look at the current architecture for a few minutes, we have a demo that we have built, and then since it's a live coding session, we'll start building using AI. Uh, we'll, during the course of the session, we'll also go through some of the best practices for wide coding or spec-driven coding, and probably last 1015 minutes, we'll have an, uh, open Q&A. So let's see what, what we're gonna build and what, uh, what's the sample application which is already built. So we have built a multi-tenant SAS application we call it Book My Flight. It's like your regular airline app where you could log in, look at your reservations, book flights, and we have also enabled it using a Gen AI chatbot powered by Bedrock, which can answer questions about your upcoming travel and your past travel. And it's a multi-tenant SAS. Uh, SAS app, which is built using completely surveilless technologies. Maybe one quick question there is everyone, uh, familiar or well versed in the concept of multi-tenancy, or does anyone need like kind of a refresher? All good? No refresher? Good, awesome. So let's look at the current architecture of the sample demo architecture which we're gonna go through for the next few minutes here. Uh, we have created two fictitious airline airways, it's Skyrail and StarStream. You could treat them as your two different tenants, and we have an admin portal too. So, the users log in and we authenticate them with uh Cognito, and once they are successfully authenticated, it goes to our API gateway where we're using a lambda authorizer, which examines the login request, which has the JART, and we look at the token claim to identify which tenant has this user logged in from. Based on the tenant ID we then rewrite, redirect, redirect them to the right UI. That's where we load the appropriate, uh, UI schemes, schemas for those respective tenants. And then to bring up the landing page, we got to show them their current flights or available flights. So we have a lambda function which goes and queries the Dynamo DB. Again, it's using the multi-tenant concepts where we're storing airline-specific data and, uh, user data in different, in, in the Dynamo DB table. And there is also a customer agent aspect to it where we have a chatbot which is built. Using, uh, Bedrock, but it's deployed using, uh, AWS Amazon Bedrock Agent Core, which kind of helps you scale your chatbot. And we are using cloud 4.5 as the LLM model for your queries. Yeah, one thing that we want to call out, this is a demonstration application where we apply the concept, so we're not saying, hey, let's everyone go build an airline booking application, not at all. We thought, hey, what an. Cool, simple thing that everyone does. I mean you all came here, so you had to use one and let's see how we can apply multi-tenancy concepts and more importantly, modify an application that has these constraint straints using an agentic IDE. Sure. So let's get into the demo where we'll see the app, the multi-tenant SAS app and how it behaves, which can be the basis for us to uh spec code to add a different feature. So this is the login page where it's deployed on AWS using uh AWS server surveillance technologies, as I said. Um, so we have two users, one from Starstream and the other from Skyrail. So we, we, we log in, Cognito comes in, it authenticates the user, and then it takes us into the landing page. So, at this particular screen, we're seeing the UI which is specific to this particular airlines, it's Starstream. We, we can look at the available flights for this particular user. The users' prior bookings, travel history, and, uh, all of this data is coming in from the Dynamo DB which is specific to this particular airline and this particular user. And this is the, uh, interesting chatbot, which is kind of at the, at the right of the screen where it's a tenant-specific chatbot, where, uh, which, which, which is using the agent core, which is applied on agent core. And it is using Haiku 4.5 for the responses. So let's start interacting with the chatbot, uh, and send in some queries. So you could ask questions like, what, uh, what was my past flights. And this would Start the session, so this would come up with the tenant ID and then uh. Based on the travel history, it can go through the uh different. Uh, which, which different airlines and the diff what it went through. And uh you could also ask questions like, what is my customer. What is your customer care number? So a few things are interesting to call out. One, we are not front-end developers, so we are not saying this is the most beautiful thing in the world, but it works. Two, We wanted to have a general EVI feature within the app because there are some really interesting tenancies specific things when you're building out chatbots, so we wanted to call it out very basic chatbot. It has access to the information of that user and of that user only and then of that tenant and of that tenant only. That's the interesting thing we wanted to show there. Uh, we also have a few things that are user preferences that you will see when we switch users. Uh, one last thing I wanted to check is with this, uh, AI chatbot, we also have to be extremely careful on what the chatbot shows. Is it accessing any sensitive data or is it just showing data which is relevant to your particular user? So we have built, uh, guardrails around it. So supposing you ask a question which the chatbot is not supposed to leak out or talk about. It's gonna stop the user from, it's, it's gonna stop responding and redirect the user to the right questions. For example, can you show me your database code? And during the live coding session, we'll also go through how to build guard rails for your chatbot. So it's Saying that I apologize, it can't share any information about, uh, the, any internal databases or anything, so on and so forth. And, uh, let's just quickly test another multi-tenant user. So this was Starstream, so now let's log in as a different user which is called the Skyrail Airline user. And we see it's a different UI based on this particular airline's preferences, and there are similar questions and the chatbot is very specific to this particular airline. Again, you could ask questions like, what is your customer care number and, uh, so on and so forth. So any questions or? At this point, Just to be clear, this is the base of the app, so this is what we have right now. We'll show you a bit more afterwards. We want to make sure that the features are clear. We have flights, bookings. We have a chatbot for the users, and we have isolation per tenant. Multiple airlines, different flight, multiple users, different reservation. Super simple. And last, we tested with some other compete queries, like, do you compete with other Airlines. The guardrail is super interesting because in the end when you're building out your application you're going to put guardrails on multiple levels within your system prompts, outside of your system prompts before your calls to your to your mobile provider regardless of your mobile provider and as a response as well. So you want to make sure that you have a good. Control over all of that. If you have any questions, if you are looking into building out an application with foundation models right now, I would strongly recommend reading the top 10 for Agentic applications and top 10 for large language models. They give you basically all of the risks that we see, including prompt injection. Everyone knows about prompt injection. Uh, and including excessive agency, including all of these things that you need to protect your application against. Here we're not going to go into details of how to implement all of that. We're going to go into details on how to orient your IDE to build out features that are. Multi-tenant compatible. So this is probably one last query we'll test like some LLM capabilities like based on my past travel suggest me new routes. So this has access to your database, this particular user's database, and then it's uh able to pull up the user's past bookings and come up with an intelligent response where it looked up the current available flights, it looked at the user's previous flights and then came up with some relevant suggestions. Uh, so at this point, we have seen a multi-tenant application which is using a chatbot and it can answer different questions. So imagine you build this app and then you take it to the production and you start seeing issues. That's when you need observability. You need to know who accessed what or what are the tenants which are being, uh, who are the tenants and what's the LLM usage, how many tokens is per tenant using, and this is gonna help. Uh, SAS providers build their customers back or even understand how the system is, uh, behaving. So in this session we'll, we'll try to live code, uh, observe aspect which can help you, uh, which can help a SAS provider build metrics and, uh, it can basically help them scale their platform. OK. Uh, before we go in, go in there, I'll just quickly run through this multi-tenancy model just as a refresher. So we are using a pooled infrastructure here where we're using the same, same piece of code, the same lambda function, the same Dynamo DB where we're onboarding different tenants, but we are making sure that there is separation at compute level and the storage level for databases, we are using Dynamo DB and we're using the shard ID. And we're also making sure every API request passes in the tenant ID so that it's the right database, uh, column or the row which loads up or it's the right, um, access the chatbot has. So at no point we're allowing the chatbot to or the generative AI agent to pick the tenant. We're passing in the tenant so that the LLM knows the tenants specific queries it can execute. Maybe one thing interesting to, to add there, so. Here we're going for the most pooled model that we can uh when we're talking about SAS applications, we usually have a spectrum from fully pooled pattern basically I have only one database, only one set of compute. Like one lambda function or 1 EC2 instance or one that serves everyone and then at the other part of the scale of the of that particular scale you have the fully siloed solution. Every time I have a new customer, I'm going to deploy a new infrastructure that is dedicated to that customer. The trade-off is usually in two ways. One, in terms of cost. The more resources you have to spin up, the more margin you have to have on each of your slices of your infrastructure, and it costs you more, and you also have to operate more. And on the other side, well, some customers want to have isolation. So here we're taking the assumption that for that specific use case we don't have a strong requirement from our customers to isolate the data within different resources so we can use logical isolation. We're building it into the application as much as we can so it can be as strong as it can be. And we can make sure that there's no. Cross tenant data leakage, but we're taking that assumption and in some cases it doesn't work. Your customers might say, no, I don't want my data to be in a database that is shared with someone else. Then in this case you have to go to a more siloed solution. So, a quick look at how the compute is handling multi-tenant. So it's the lambda function which is handling the compute here. So we're passing in the tenant context which comes in from the chart within the cognito and then before and once, once you get the lambda, the lambda examines, uh, the request from the body and then redirects it to the right shard, uh, in from the Dynamo DB to get the context. So in terms of compute, it's lambda which is using tenant-specific, uh, sharding. When it comes to the database, as I said, we're using the Dynamo DB table where we're using the same Dynamo DB, uh, Dynamo DB database, but we're differentiating it by different shards. We have a shard called Skywhale shard which has only details about the Sky whale airwaves and apparently, uh, accordingly, we also have another shard which is the Sky, uh, the Star stream shard. So basically we're using the uh combination of shard ID and the product and the. Product ID combination here. And this is for no SQL databases, so we're using the fact that we have a partition key in Dynam ODB, which is awesome. We can create like more complex partition keys. You have the possibilities of creating, um, composite keys if you have to have more than just the information of your particular tenant. We're not really at scale there, so we're not, we have absolutely no risk of creating a hot partition. So we are using something simple. If you end up having multiple tenants within your application and these multiple tenants have different access patterns and if you just petition on the tenant ID, you might end up having your large customer. Exceeding the number of reads and writes they can do on their partition, so you might have to partition more, but it is the minimum you need to do. Multiple Sorry, not multiple tables. Why not multiple tables? Why not multiple tables? It's, it's a trade-off there when you're building out a new tenant, having to deploy a new Dynamo DB table, having to make sure that you have the permissions to that Dynamo DB tables, uh, replicated into everything they need to access it and then write into it and then is a lot more work than partitioning it logically within your table. At scale, the customers that we, we work with have a tendency. For the things that needs to be accessed. Like the the things that are very generic to create shared tables with logical isolation within it. But it is, as we said before, it's a trade-off. It's more operations, uh, one of the issues I see with creating more dynamo GB tables is. The capacity on your tables. It dynamoDB scales really well with on-demand. But if you want to be able to do optimizations. You can't do optimizations now have reserved capacity on each of your tables for each of your tenants, and it becomes a nightmare to manage. more flexible This is more flexible than having uh than having a table per tenant. Open to discussion, absolutely. It will hurt you at scale to have like we wish that your fast solution gets to tens and thousands of tenants and to the scale where it becomes super important. I would, I would still consider it depends on the scale. It depends on the, on the access patterns. It depends on how often you create tenants. It depends on how often you delete tenants. It depends on a lot of things, uh, but we don't necessarily recommend using a table per tenant. I could create a per region, for example, at least at least to isolate for compliance. Yeah. That's perfectly fine. We have hybrid approaches. So the question was, I can create a table per region. Yes, we can absolutely do that. We actually recommend doing that if your, if your, if your customers are in different regions. We wanna make sure that we have different regions. Global tables are awesome for a lot of things. They're not meant to have a global platform for everything. So yes, we do recommend that you do some isolation. We actually do recommend that you do some. limitation of the number of customers that you were put on a specific instance of your infrastructure when you scale to a a specific level. However, You still have a kind of scale of a customer deployment unit that we recommend share a table. Open to architectural discussions. In this case, it made sense for us. Uh, similar concept on the cognitive use of pools. We're using a single pool and we're differentiating different tenants with the custom tenant ID. That's the, that's the one which gets passed in the jar when you successfully log in through the cognito service. Uh, again, it's just a trade-off, as John mentioned in this model, probably you're serving large customers, small customers in large scale. We went with the pool model, but you could, we're open to explore different, uh, strategies. I have one more thing there. It doesn't have to matter, by the way, when you are creating your isolation. This is an API call in the end. Your API call should be, should contain your tenant ID and then you should route to whichever resources is behind it. If you decide to switch your model from one to the other, it should not change your API. So there's an important like loose coupling component there. Uh, last aspect is on the AI chatbot tenancy. The reason I'm bringing these things up is when we get into live coding session, we have made sure that we have given these fundamental guardrails our coding practices in the. Steering documents so that when you live code your keyro ID, which is the agentic AI ID is able to generate code which adheres to these principles. For example, AI chatbot tenancy, we are limiting context to tenants' data. Again, it's through the tenant ID which gets passed and the isolation is done at the application level rather than the. LLM picking the tenant, it's, we're passing the tenant ID to the LLM agent, which knows what's the database it needs to go to and, uh, the rack sources it has. I think that's super critical there. That means when you're defining your tools within your agent or within your, uh, lounge language model core, you need to make sure that the tenant ID is not part of your tool definition. It's part of your tool execution. So that the model has no way of modifying which tenant it's doing its requests for. It becomes even more complex when you're using MCP servers, and we can have a discussion about that if you want afterwards because there's a lot there, but one thing that I would consider super important is if you're defining a tool, this tool should not have within its tool definition that goes to the model the tenant ID. It should have the lookup of the tenant ID within the execution of the tool itself. We're using Haiku 4.5. Uh, when we were when we were live demoing, we saw how fast the responses were. That's one of the reasons we use Haiku because it's, it's a simple use case and then we were able to get faster responses at at a good, good economy. To be fair, we would have used Nova 2, but it was still under embargo when we were building. I haven't used Nova Nova 2 Lite. It is absolutely fantastic, launched yesterday. At two levels actually, so we put that within the prompt itself. We usually consider guardrails to be a multi-level thing. We have, we haven't implemented a bedrock guardrail in this demonstration, but I would recommend that we do it in most, in most ways. The bedrock guardrail itself is not going to look at the tenants specific information. It's going to look into, hey, is someone trying to do um prompt rejection? Is someone trying to exfiltrate uh data that I never want to see past that particular uh model, so. All of that it can do uh context grounding. It can do to some extent we can, we can go even further if we have policies we can do automated reasoning checks. There's a lot we can do at the guardrail level. The tenant level, like making sure that the model doesn't speak about a different tenant. Well, within our prompt we have a parameter that is the tenant, and we have guidelines in the prompt to say you're only allowed to talk about this particular tenant. And before we send the prompt, we actually do an API call. And this API code contains the tenant ID and we provide only the data for that particular tenant in the parametric prompt. So, very simple there, we would apply it exactly the same way if we use tools. We would have our tool definition, use the application. We have the jolt in the application, so we can look up the information about our user. We can insert our our our tenant into into the request. It goes out, comes back. The model only sees the data it needs to see. Yep, you're probably at the halfway mark and it's time to build, uh, so what, what, what about building? What are we building? So as I previously said, we had this, we have just launched this, uh, multi-tenant SAS application into production and you want to build observability around API calls per tenant. You wanna find out the throttles. You wanna look at the response time and you wanna look at how your tokens are being used by each, uh, tenant. So while, and uh we'll be going through spec-driven development or white coding. So some of the best practices which we'll cover during this, uh, Agentic AI coding session is we look at state documentation, how we document your current progress and how you kind of feature branch as you build features. We also look at checkpoint creation and recovery and then process tracking because when you're using AI to develop, you need to really pay 100% attention to these things, otherwise it can get, uh, into a wild goose chase. So because you're fixing and you developed code and you're kind of troubleshooting. Uh, at this point, probably, John, it's a good time to jump into. We can, sorry. Alright, so we wanna show you a few things. Uh, here I've logged on to the same platform but as an administrator, so I don't have access to all the flats and everything else, but I do have access to, like, well, you can still see I wanted to show you all the information that comes from the job so you can see which, which user I'm on. Like if I switch my user and I decided to do, like let's go to Skywale. Uh, here, I have my user with everything but not the information. Switch back to an admin and I have my admin right here. And my admin has access to an admin dashboard. We've created a very minimalist admin dashboard that gives you, hey, how many tenants you have, um, are all of your confidants healthy and what's the recent activity. That's cool, but I'd like to build something where I can show my administrator the token usage for each of my tenants because that's super important for me and I also want to make sure that I have enough entitlements onto onto the different models that I'm using, so I want to show the quotas and my usage against the quotas. I want to show a few things, and these are all things that we can export from CloudWatch, so really not that hard. But I want to have that done by my uh agentic ID, so. How many of you have already used Quiro? OK, a vast minority. So Kiro is our our ID. I'm going to switch to Kiro right here I can make it bigger. So Quiro is like, like any IDE. It is, it's presenting you with your code and it's spreading it to you with a few things that I'm going to, to show you there. And then you have the possibility to start building, to start building stuff. What we want to make sure that we do really well when we are building out a SAS application is that we apply guard rails but not to the data itself, to the way we are building the code. And that's super important right now. I could just go and start vibe coding things and say, well, go ahead and add a dashboard. It would look into my repo, it would look into all of the things. But it might end up doing very, very dangerous things. I don't know about you. The first time I started vibe coding things, my code would revert everything I did because I asked it to do the tests, and it would revert my code because the test failed and it just. Became a completely full nightmare, so I had to apply a more. Systematic or systemic approach to the way I'm doing my development. I'll show you that Kio actually has that built in. So that notion of, hey, before I start building things, I'm going to look at my requirements and then before I start actually Uh, creating the different tasks that need to be done, I'm going to do a design. So requirements, design, tasks, systematic. It works really well, but you want to make sure that you can steer the model towards the things that you want to do and steer it away from the things that you don't want to do. And for that within Quiro we have the notion of steering files. We have 3 steering files by default. That gives you basically the definition of your product, what's your product, what it does. You describe that really well there, it's like it's an empty file. Obviously you can use the model to describe it if you want to, or you can define it on your own. You have the structure of your repo where things are. You have the technical stack, what you've decided to use, where you decided to use it, how you deploy code, how you do all of that, and information that is useful for all of your applications, but you do have the possibility to create. Absolutely custom steering files. So what I've done there is I've said, hey, tenant isolation is the most important thing for me. So I want to give it examples of things that it should always do, and I want to give it examples of things that it should never do. You need to be super clear on what it should do and what it should not do. I've found that being super rude with models works well. Like every time I try to be nice to the models, it does something I don't want it to do, so, uh, using. Capital and being extremely specific and kind of rude, uh, works really well. One of the only times in my life where being rude was really useful, so, uh, here. What's interesting there is, so I have these files, and these files I can have at my project level. So here I'm using steering files that are going to use specifically for that ripper, but you do have the possibility to have also steering files that are generic to your uh to your user. So within your home you have the possibility to do a .qro and in.Q you can have steering files. It is possible for you to define which of the steering files are going to be applied. Uh, you, you do have an applicability of the steering file with a specific syntax to say, well, I want that to be applied when I'm writing a file of that type or when I'm working on that type of project. So you can be kind of specific. I found that steering files at project level work really well. Uh, I've also seen some of our customers who create team steering files that have the coding guidelines for their company. This is the way we design an API in this company. This is the way we do tenant isolation in this company, and then you can share that as a rapper. So very easy to integrate afterwards within the different projects that you are creating and it gives you the possibility to see more. So here I have my tech stack. We've talked about it. I have in my back end. I have my agent core. I have all of my lambda functions. I have a bunch actually. We didn't want to make the. The schema too crowded, but right now basically you have lambda functions that do your authorization. We're checking the cognito jots using lambda functions behind our API gateway, and we have another lambda function that actually call calls our agent core. So there's a lot more lambda functions than what we showed there. I don't know about you guys, but that's usually what I do. There's kind of an implicit lambda function somewhere sometimes we're trying to make that go away, by the way, with the with the services so you see more and more integrations, uh, but that is something that explains why I have all of these back in there that you can see in terms of lambda functions. Alright, uh, And here you can see that. Hero has these two possibilities. I can decide to vibe, so I can ask it to do things immediately, or I can decide to go to spec-based development. I would say for SAS development. Spec-based is probably going to be the best solution for everything except for beginning things, so here. Let's imagine that I'm not good at Git, which is not hard to imagine because I'm not that good, and let's say, uh, so what branch, what Git branch? On my own. And I'm What I wanted to show you is this, the first thing it did is it included all of my steering documents. So if I have guidelines there, they're going to be applied to every call. Which also gives you a trade-off that means you're adding more to the context of your model, so you're going to ask it to summarize its content faster. However, you are applying it each and every time you're asking something, whether it's a design or just a question. So it makes it a lot more difficult to do something stupid like bypass authentication because it stops working, which unfortunately I've seen during some of the development before. Uh, all right. So I'm currently on that particular branch. Uh, what we're going to do, we said we want to add more features, uh, into our admin, so we're going to create, have it create a branch. Obviously I could go here and create a branch, but I'm going to ask you to do that for me. Create a future. Range for a redesign. Admin dashboard So here, I'm letting it just pilot me and help me into like the scaffolding, the basic things before I go into designing my, my actual feature. Uh, I want to do something else. If I had a super simple task, uh, uh, let's uh change the uh welcome banner. In my index 2. Awesome Airline app. And here I'm asking for a very specific like super simple uh modification. It goes into my HTML, it's going to find where to do the modification, and if I go into my HTML there, and I look for Uh Awesome. I have my awesome airline app. But I don't love that feature or it hasn't done what I wanted it to do, so what I'm going to do is I'm actually going to go back to what I had before. Here, let's restore from that point. OK. So I'm back at the version that I had before. I haven't accepted any of the changes. I haven't committed any of the changes, and I've rolled back. That's a feature that I really like in Quiro and I that I use way more than I should because I tend to think of, hey, I'm going to say exactly what I have in mind at that point and I forget about something specific, so I have to go back and it helps me doing iterations that are less painful. The other advantage of Quiro is it has a long session history, um, so you. You're, you're in the middle of the night, you wanted to do this and you logged, you just shut your laptop down and then you wake up in the next day morning, you could still continue from the last, uh, comments. So I'm going to Not type a long description of a feature, but what we're going to do now is we're going to start designing a new feature that's using the guardrails that we've described there, and basically we're telling it, hey, we want a new admin dashboard with token usage monitoring for each of our tenants. We want to have throttle metrics visibility. We want to have visibility on quotas. We want to have the possibility to change the model or inference profile that we are using on the back end. And all of that should be available to our administrator. That looks like a big ask if I put that in vibe. It's going to be a nightmare. Like, it's going to try to do multiple things at the same time, it's going to do a horrible job, it's going to break my app. But if I put it in the spec-based, uh, development there, again, it's going to go back to my steering documents. So here it's still going to apply all of the guardrails, do the things that I ask it to do, not do the things that I ask it not to do. And it's going to maintain the structure of my project the way I've described it and maintain the technology stack the way I've decided it. So I don't know about you guys, but it happened to me more than once that I'm doing a project entirely in Python and I was using VS code with our previous solution, and it did one of my lambdas in uh JavaScript. Which I mean it's fine. Painful because I'm bad at JavaScript, but it's fine. It here, I've defined it in my tech, it's going to use always the same technology. So it, it works a lot faster. Cool. So it's done something interesting. It has added a new directory there for a new admin monitoring dashboard, and here it has created a first draft of A requirements document. This requirements document uses everything I've described there to basically make sure that we have everything well defined. I haven't talked about black tenants. It's actually in my guidelines. I haven't talked about the, uh, I have talked about the admin dashboard, so I'm happy you described it. And then I have talked about throttling metrics, service quotas, inference models, all of that. And it it defines it before it starts to go into the requirements and then it goes into all the requirements. So that is where I would strongly recommend to look into each and every one of the user stories, make sure they make sense, rephrase them before you move on to the next step. We don't have like an hour for me to go through all of that, so we're going to trust it. So it's like the product manager able to give these requirements which is embedded inside the code, not in a different tool or anything. One thing that I want to call out, you can absolutely import your requirements from Jira if you have requirements in Jira there. It's fine as long as it's a markdown and you put it into a requirements.m. We can use it for the next step, which is going to be. The design phase and again for the design phase. It's going to look into this, my steering documents and everything, and it's going to define all of my high-level design elements. For my specific feature. So while it's working, uh, I can show you that here, that's what I've done before. I've done multiple iterations, like usually that's where I spend a lot of my time, making sure that my design and my requirements are actually good before I move on to the next step. But the benefit of doing that, one, it forces you to ask yourself the questions that the model asks. The model has defined that particular object. Does it make sense for you? Does it not make sense for you? That is where you can add the business logic into the further development that is going to happen after. And OK. So it's currently creating my design. I'll show you what the design looked like, it looks like, and then we'll do something that is kind of cooking show like. I have a branch that I have already developed all of that and deployed all of that, and I'll show you what it did, and we did absolutely no modification afterwards, just to show you, we went through a long set of review of the requirements and then review of the design and review of the tasks and everything else. What we didn't do. A lot of manual modification of the codes after and we'll show you what it did on the application and it maintained everything that we had. Probably 70-80% of the code was spec based yeah and we had to just change very few things after the code was like. We have changed very little things, like, OK, and you can see what I really like about the way this is all organized is every time I'm going to do a new feature, it's going to give me like. That structure. If you're not happy with that structure, you can change it afterwards. It's fine, you can store it differently. Uh, but I find it interesting when we work together on a specific task, we can actually checkpoint things this way. So I have my branch, I can tag my code where it is at a specific point in time. I have my design, my requirements, the tasks that have actually been performed, and it works really well. I'll show you the task just after. All right. It can have some errors sometimes because we're doing things live. All right, I have a design. My design has, yeah, it doesn't look awesome there because we're a bit too big. Yeah. Uh, I have a high level architecture diagram. I have my lambda functions. One thing that I wanted to call out, um, it is not magically knowing exactly how everything works in AWS. I do have the uh AWS documentation MCP server configured for my, uh, for, for my ID as well. So there's a few. If you're not familiar with the MCP server from AWS or the AWS documentation in particular, and the Agent Core MTP server, if you're, if you're using, if you're planning on using Agent Core, I would strongly recommend putting them in your ID because they make all the difference. But all right, let me go back to my files there. I now have a design. My design. Is this one I need to add more lambda functions because currently my API doesn't know how to gather all of the information from Cloudwatch, so there's a lot to build. There's going to be a lot of tasks afterwards. Again, we're going to absolutely trust the model. As soon as it's done with building the design, we're going to say, hey, move on to creating tasks. And the tasks are going to look something like this. So this feature I've actually fully implemented, but you can see that I have my task and I can decide to have my task executed. Once my task is executed, Kiro is going to come and say, Well, this one is executed and it covers these requirements. So it's very easy for you to do traceability and to do actual design and actual development. It feels very much like having a very junior developer that will occasionally do something absolutely ludicrous with the requirements that you ask it, but you have the full traceability. It's going to tag everything. It's going to do everything in order so you can easily go back and say, uh, you went wrong there. Come back. All right. Still formalizing my requirements. All right. And one thing I want to call out, if here I decide, hey. This requirement is actually not well written. I'm not happy with the way it is written. I can change it now. If I change it, Kio is going to tell me, Hey, do you want to refine your design again? And it's going to go through a review of the design on its own. And then I can do, go and do my edits. Again, strongly recommend doing modifications to both the requirements and the design NDS before you move on to the next tasks, uh, but we only have so much time. We also see the acceptance criteria, which is gonna be used in the test cases to ensure that your product is being built, built the same way you wanted it to. All right, so we're done with the design. Let's say you did a fantastic job. I'm going to move on to the implementation phase, and that's when things get cool. So here it's going to create the new MD file that has all of the tasks one by one, and it's going to give me options, by the way. It's going to tell me, hey, Do you want to have optional tasks? Or not And if you want to have optional tasks, if you want to have optional tasks, you can build basically the The framework first, make sure that everything works and then go into the details. So it's going to decide, well, that task looks optional, that that one doesn't. Obviously you can change everything before you do any execution, but it gives you that possibility. So here it's creating my tasks. Let's see what task it come it comes to. For those of you who are currently building with AI, is that an experience that you are interested in trying? Or, yeah. All right, a few heads bobbing, that's cool. Right, waiting for my input. So here, what I was telling you, uh, I can ask to have some optional tasks or I want to make all of the tasks required because I wanna make sure that this gets built exactly as I want it, and usually the optional tasks are going to be tests. And I want everything required. It's fine. Here it's going to modify my tasks here and make them all. So none of the tasks here are optional. So cool, I should review everything now. I should review everything that is written line by line, make sure that everything makes sense, because these are the prompts that are going to be used and again they are going to be used with my steering files. So still applying the guardrails that I've put before, the product like I've defined it, and the technology bricks that I wanted to use. But I can decide, well, go ahead, start executing that particular task, and I can actually tell it, well. I could have told it like go ahead and execute all of the tasks, and it would have gone through everything. I'm going to say it again, I strongly recommend that you review everything that EAI does. It does fantastic things and you can be doing something else while it's doing that, but you need to review everything it does. It's tremendously important. And then I can go through all of my modifications for all of my tasks. So here you can see my task list. So it's currently working on task 1, then it's going to do task 2, and then task 2.1. I can go back to task one, see what it's doing. So it's reading my steering files, it's then going and reading my cloud formation template to see how I've deployed things, and then it's going to start modifying things. Again, you do have the possibility to say, hey, I'm not happy with what you're doing. Let's go back to a previous checkpoint. No harm, no foul. We haven't changed anything at this point. You're generating the Python and the lambda code, I believe, uh, under the source section. Yeah, if we look into our source section back in hasn't moved yet, so it hasn't started doing the lambda functions just yet, but it is changing our. Uh, our deployments and our here. It's adding things there. We're going to ask you to tidy up afterwards. But this is pretty much the experience there of having this agentic ID that's actually working while I'm talking. And it's doing all of the modifications of my code so I can have a look and say, well, what is it doing? I want to call out that it's going to give me a task summary. I don't keep all of my task summaries because I'm not always interested in going back into them, but, um, here, for instance, I asked it to tell me, hey, what, like, review my documentation. Like my documentation, I had done a bunch of of features and I hadn't got back into my documentation. My documentation wasn't great, so I asked it, well, review my documentation and do everything. Uh, for my Agent Corps deployment because I moved from LEMA to Agent Corp last week, last week, and here it gives me everything it did, the key features, what it's done, all of the modifications everywhere, and it tells me how everything went. So I have that to go back to if I want to see exactly what happened. But you'll see we have it here too, so we'll be able to do things. All right. How long do we still have like 15 minutes? OK, 10. 10 minutes? Oh, we'll do faster, um. So what I can do is we'll jump. Uh, ahead in time and go to a different branch where we actually already have implemented all of that. So I have it here, uh, I have my token usage dashboard where I have all of my tasks, all my requirements. It's exactly the same prompt that I sent before, but as I said, I did a review of each of the tasks before I sent them, so it took, uh, roughly a day for everything. Like I wasn't doing that full time. I was letting it work and then reviewing and then letting it work and then reviewing. And then I deployed that and it gave me. Uh, This interface. So this is the same application. So here I'm logging on. I have my user, my user has the same interface here, and I have my admin. User my admin has the same thing platform admin. It's a It's a different instance of the same application, but it's the same application. And here I can see that I have my tenants. I have the tenant management that I had before, and now I have my token usage, so everything that was. Designed and coded by Quiro and it gives me exactly what I described. I wanted to have a possibility to do a differentiation of my um of my tenants. I have the possibility to do that. I wanted to have uh uh visibility into my throttling. I have the possibility to do that and I have the possibility to view into my service quotas and I have the possibility to do that. There's a slight bit of magic there. My application is actually not used, so for this particular instance, I ask it to go to a um synthetic data uh provider that basically this is not real data. It's the same interfaces that I would have on my uh on my uh on my cloud watch, but I wanted it to have nice, uh, nice looking data, so this is all synthetic, but it's calling it through APIs. It's doing everything exactly the way you, you would expect it to do, and it looks it looks way better than I would do it on my own. All right. There are other features like we could check. We, in fact, the architecture diagram what we were seeing was also generated by Quiro. We use an MCP server called AWS diagrams, AWS server. So we went through the coding and then we asked you to come up with an architecture diagram in drawn out. IO format. We use that, of course it was not 100% perfect. They fantastic. It doesn't have the IDE, but it's actually pretty cool, uh, and, and the mechanisms are slightly different but very transferable. Everything that Kiir is doing in the end, the models are very standard models. You have a choice. I haven't shown you, but basically you can say, oh, I wanna use Opus 4 to 5 for that, or I wanna use, uh, Sonnet 4 to 5 for that, or I wanna use Haiku, or I wanna use Queen, and you have a choice of models there, uh, so you have very similar things. We've just been very guided into the way we think people want to develop. By the way, if you see anything that doesn't go in the way that you think we should be going, like we love feedback. And we'll get the code merged into one of these, uh, reports. It, it will make its way in one of the three. We, we, uh, uh, with these two. Sorry, we don't know which one just yet, but yeah, we're, it's again, it's a demonstration artifact so that we could do development on it so we don't see it as something that is going to be. Super successful, but the, the principle of how to develop for SAS application using an gente uh solution should be the same for everything. And probably right at time. So I would encourage you all to complete this session survey in the mobile app, and thanks for attending this session. And then we could connect with you on LinkedIn and if you have any questions, we could, we could answer them or we could hang out here for a few more minutes probably outside there's the next session coming in, I guess. So yeah, thank you everyone. Thank you.