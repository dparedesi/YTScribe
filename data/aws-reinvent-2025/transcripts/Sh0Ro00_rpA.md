---
video_id: Sh0Ro00_rpA
video_url: https://www.youtube.com/watch?v=Sh0Ro00_rpA
title: AWS re:Invent 2025 - Make agents remember with Amazon Bedrock AgentCore Memory (AIM331)
author: AWS Events
published_date: 2025-12-02
length_minutes: 48.8
views: 2777
description: "Intelligent agents with memory capabilities can deliver smarter, more personalized interactions—but implementing memory in production is no easy task. In this session, we’ll cover how to build context-aware agents using Amazon Bedrock AgentCore Memory. Learn to manage short-term and long-term memory securely, structure agent interactions around user history, and scale memory. Hear from Experian on how they are reimagining conversational memory architecture across their AI ecosystem. Learn about ..."
keywords: AWS reInvent 2025
is_generated: False
is_translatable: True
---

Hello everyone. And I welcome you all to our session on making agents remember using Amazon Bedrock agent core memory. So before we begin our session, I'm Mani Kanuja. I'm principal generative AI specialist solution architect at AWS. Very excited to be here with you today morning. And before we begin, can I have a quick show of hands, uh, for people who are aware of, uh, the memory concept in the agentic AI world. OK awesome so we have many folks who are aware of and we also have a few of the folks who will be hearing about the agent memory for the first time and what role does it play and today I also have with me, uh, Jay who's our, uh, product manager and Imran uh who's from Experian, uh, you know, sharing the stage with us. He's the senior VP, uh, head of engineering, uh, from Experian, and he'll be sharing. Uh, the journey and how Experian has been using agent core memory for building their applications. So very excited to be here and I hope we all have had your coffee so that you're all awake. Is that true? OK awesome let's get started then. So the main thing about the memory when it comes to agentic AI applications is providing the right context to the agent at the right time and that's what we see the agent applications without memory lack and by the end of this presentation, I promise that you will understand. And also see a good demo on how it can make the difference when you are building the agent AI applications. So let's talk about the context first, what goes into the context of an agent and what really this agent is. So when I think about agent, it's literally a model that has access to some of the tools. It can take actions on your behalf based on the tools that you provide. Now those tools could be some data APIs, real-time APIs that you want the agent to give access to, or it can be access to your knowledge store where you have your organization data. Or it can be instructions and system prompt is super important because system prompt is what makes the agent understand what it's supposed to do, right? So there's so many things that goes into the context of an agent and that's where we have seen that memory is often overlooked. But imagine you're in a party. You have been talking to few people. And suddenly, after the conversation is over, and you're like, oh, what's your name? Right, so we don't want our agents to be in that situation, especially when they're interacting with your users. You also want to give a good user experience or customer experience in addition to providing relevant and accurate responses, and that's where memory plays a big role and it's literally is, you know, bridging this gap. So let's take an example. So obviously like for this presentation we had to build our presentation right? the slide deck and then when we were discussing uh we were like OK why not take this example and uh share how you can build slide decks so we build a, a slide deck agent that can do a lot of things. So I started with a very basic agent with no memory. It was good it was able to do the work. If I provide a big prompt, I give all the instructions, it's able to generate the deck. I have to give some tools, such as I'm, I, I love Python, so I provided some tools like Python PPTX and all of those, and it did a good job, no doubt about that. But then I noticed every time I have to mention, oh, for technical presentations, use this style. I'm in AI and um responsible AI is close to my heart, so in all of my presentations, I want some angle about how people use this AI responsibly, right? So those are my preferences, which I wanted the agent to remember, but with this basic agent, I always have to provide these instructions over and over again. So how do I overcome that? That's where I created another agent with memory. Now this agent could understand my preferences over time. When I was building a lot of slide decks, it learned my preferences, and then. After a while, I just say, oh, for tech presentation, uh, this is a tech presentation on this topic, and it will just do the job. Not just that, because I know when we are talking about it, we make it sound very simple. So that's where we will show you this demo up and running. So stay tuned. It will be at the end, so you have to stay for that. And also, I want to make sure that you understand the fact that how memory bridges this gap when you are interacting with the agent. So when the user is interacting with the agent, there is conversation, there is a lot of context that agents need to remember, so we have to make sure that that context we are providing to the agent so that they give response in an accurate, reliable way, relevant response, and also give good customer experience. You don't just want your agents to remember stuff, you also want them to be smart, and they can only be smart if they're able to retain that knowledge, if they have the full context of your application or the job that you are asking the agent to accomplish. You want the user preferences or maybe the facts or maybe the summary of the previous sessions to be remembered and retained by this agent, or maybe the agent should be able to call those things. So those are the things which are very critical. For example, you had a long conversation with the agent, and then you come back and you what you want to do is basically resume from that conversation. That's a very common use case. But imagine if you're storing the entire conversation history, it will go so big, right? So. You might want to summarize it, and maybe when your user comes back. The user, the agent can say, you know what, last time when we interacted, you talked about these topics. Do you want to continue with these topics or you want to start a new one? So those are the things that you want your agent to remember, right? It would be so cool. So that's where you want your agent not just to be, to remember but be smart about it, be able to recall those, uh, things, and that's where we are going to show you how would you do that. Now let's talk about this demo sneak peek that I talked about, right? So the first thing when you're building an agentic application, you need. The interface, your UI should be attractive, should be nice, but at the same time you need some kind of a framework to build your agent. So in our application, I'm going to show you two agents, one, the agent without memory. Second, the agent with memory, and you will see the difference. We are going to give the same prompt to both of these agents, and I'm using strands framework, uh, to build these agents. Then of course the main layer we are talking about memory we want agents to remember, right? So then for this pres uh uh demo I have the memory hooks. So why memory hooks and what are these hooks, right? So within these, uh, frameworks when we are using to build agents there are two ways. One, you can use memory as a tool or you can use memory as a hook. So why we use memory as a hook if we want. To make sure that agent calls the memory at a specific time in their life cycle, for example, on every message added, I want my agent to add it to the short term memory, and then there is a long term memory which agent needs to retain the key specific facts, right? Maybe I can use that as a tool because whenever the agent needs it, it can retrieve from the long term memory, right? So that's how you need the memory hooks, and sometimes memory as a tool, depending upon your application. Memory hooks is a more deterministic way of agent, making sure that every message added goes to the short-term memory. Then you, when you are using these frameworks, there is a session manager that you might need, and this will become more clear when we'll, you know, go through our presentation. Then there is a configuration like what gets extracted from the short term memory and goes into the long term memory, so you have, you should have control over that, right? So we are in my demo I'm using the memory config where you can literally override the prompts, figure out what gets extracted, and we are using user preferences for this demo and all of this will become clear when we'll do a deeper dive on uh how, you know, agent core memory will help you out. And the last but not the least, I want to mention what the services that we are using. So I'm using Amazon Bedrock, uh, Anthropic cloud, uh, 4.5, uh, Sonnet 4.5 model. I'm using Agent core memory and of course security is super important. So with IM permissions and integration with memory makes sure of that. It makes sure that I'm only giving the permissions that the agent needs to do its job, nothing more than that. This helps me in reducing my blast radius. So one of the key principles of security, the least, the principle of least privilege, so that's what this does. So now you have looked and you have got some idea about what this demo is going to look like, but now imagine you have to build all of this on your own, the whole memory system. I'm not even talking about building agent and deploying it, just the memory system. Imagine you have to do all of this on your own. What would you need? So short term conversations or the short-term memory should have everything as is, like some raw messages, some storage, and you should be able to give, let's say, last K turns to your agent, so that will maintain your conversation history. So there's the short term memory, right? Short term memory is literally like. Raw messages I should be able to retain. I should be able to call, so you need some kind of like a database or a key value system which can store these messages. Now, long-term memory is that the agent should remember, for example, if we're talking about user preferences across multiple sessions. So I need a different type of a data stored over there. Why? Because based on the query, the agent should be able to semantically retrieve the information. When I say semantically, I mean based on the meaning of the question, it should be able to extract the right information. So I need maybe a vector store for that right now these two storage systems I have to make sure that I'm managing. There is a memory refresh all the time. My data is refreshed. I have automatic pipeline whenever there is a duplicate, uh, user preference, it's consolidating. It's updating. It's not really, oh, you know, adding new preferences without, uh, consolidation because imagine. If I tell you that I'm a vegetarian and I'm a non-vegetarian. What will you serve me when I'm, you know, with you? Nothing, because you are confused. But because I was a vegetarian earlier and now I'm a non vegetarian, it makes sense for me to order non vegetarian food or the agent to give me, uh, you know, uh, recommendations of the non vegetarian food for example, right? But if I give both those things, the agent will get confused oh what do I need to do now, right? So the consolidation, uh, logic becomes very important so you have to do that on your own and you have to do all of this in a very secure way. And not just that, imagine something happens while your user is interacting with the application and you need to troubleshoot or you need to debug, you need to build and integrate observability into your system, so all of this becomes really, really a lot of work and heavy lifting. So that's where we have Amazon Bedrock Agent Core to help you out so that you can focus on doing what you do best. Is building applications for your customers and we take away all that heavy lifting from you and and you should be able to quickly integrate memory into your agentic applications. Now to go deeper into this now I'll invite Jay, who is the product manager for Agent Core Memory and the best person to talk about it. Thanks, Bunny. I think in that case with the meal, I'd probably go vegetarian just to be safe. All right, so we built agent core memory, as Mani mentioned, to ensure that your agents have the right context at the right time. It's a fully managed service that addresses many of the traditional challenges associated with agentic memory. Let's look at how it works. So we're gonna do another thought exercise here. I want you to think about a conversation that you've had in the last week or so. You probably remember that conversation pretty well, maybe even word for word. Now, why don't you think about a conversation you had about a year ago. If you went to reinvent last year, think about a conversation at reinvent or a presentation at Reinvent. If not, maybe, maybe last Thanksgiving or last Christmas. Now for that conversation, for that interaction, you probably don't remember it super well. Your brain probably remembers the most important details and generally what happened. And you might have used that information to inform future conversations or future interactions. That's how your brain works, and that's how we designed the agent core memory as well. It all starts with your memory, memory resource, excuse me. That's this uh blue and slightly pink box. Surrounding your short term memory and long long term memory here within the memory resource which you set up in your AWS account, we have short-term memory that's your raw interaction history, that word for word that you remember more recently and that persists for from 7 days to up to 1 year based on your configuration settings. And then we also have long term memory and your long term memory are that important information, those key insights that persist throughout and you can your agent can retrieve both short term memory and long term memory in order to complete the job at hand. So let's start by looking at how short-term memory works. In short-term memory, your agent interactions are captured and sent to the memory resource in the form of events. Events contain an actor ID so who this is or maybe who it is combined with what the agent is. And a session ID which is generally your specific interaction. And the actor ID and the session ID can be used in conjunction with the events with that raw information for easy contact context tracking. Events can contain your conversation history. They can contain metadata. And they can also contain blob payloads, so images or audio, things like that. This is most useful for hydrating your your agent with the recent conversation history and the recent interaction history. This is sort of the baseline at this point, and this is that example Monty gave of having the conversation and then someone comes back and says, Who are you? You know, no one wants their agent to be a goldfish is what we say, and short-term memory is really good with that. It has a few other uses as well. And for that, I'd like to talk about a topic that is near and dear to me. Unsuccessful so far and that topic is. Convincing my family to get a golden retriever puppy. So, I've been unsuccessful so far and I'm thinking about a new approach and that new approach is using the. PowerPoint builder agent to create a PowerPoint convincing my family to get the puppy. So I'm going to tell it to include a bunch of cute pictures. I'm going to tell it to include some of the pros of getting a puppy. Getting a dog in general, which include that it teaches responsibility, that uh statistically people who have dogs are shown to be happier. And I'm also gonna ask the agent to do a bit of a financial analysis to address some of my family's concerns that maybe costs are an issue. So, I've put in a lot of effort here, gone back and forth with the agent, and the most annoying thing that can happen. The screen goes blank. Let's say I quit by mistake. Now, it can be really painful to get back to that exact point. It can be a lot of effort. With agent core memory, conversation history can be stored and also interaction state can be stored. And what that means is that you can go back to the exact spot where you are, and hopefully, I'll keep you posted. Next year at Reinvent, we'll have a, we'll have a puppy. Agent core memory supports a few other advanced features for event organization with short-term memory. One of which is branching. Branching is useful for going back and editing messages or editing events. And it's also useful for concurrent event streams. So what that means is let's say I put in some effort for this presentation and I wanted to get the agent to go off and build me one presentation on getting a golden retriever puppy, one presentation on getting a Siberian husky puppy, and you know, maybe one presentation on getting a German shepherd puppy, though I doubt that last one. Uh, Agent Core can do that with branching. And maintain logical separation. So that's short-term memory, and now we're gonna look at long-term memory. With long-term memory, your raw interactions from short-term memory are automatically transformed into structured and persistent insights. Unlike short-term memory, where the interactions are full interactions, your full conversation history is captured. With long-term memory, we only pull key insights that you're going to need over time. It's a multi-step process to capture these interactions and write them to long-term memory. And as you may have guessed, we're using large language models for this. You may also be wondering how we know what information to pull into long-term memory. And the answer to that is by choosing a memory strategy. We have 3 built-in strategies, summary, user preferences, and semantic. And it's very simple to add those you go into the AWS console or add them via API or programmatically you pick the strategy you want, you add it and information automatically starts flowing from short term memory into long term memory. So really easy we really like that. The, the strategies themselves are pretty self-explanatory. Summary condenses down your interaction, condenses down your conversation, and uh saves that. User preferences captures the user's preferences. So for me, for that interaction we talked about, it might be the user prefers golden retrievers and Siberian huskies to German Shepherds. And then semantic captures facts about the interaction. So that one might be user has a family and family wants a dog, hopefully. You may also want a little more control over what you send into long-term memory, and that's what those bottom two strategies are for. So with the override strategy, you can choose which large language models to use and what prompts to use to send information into long-term memory. Self-managed gives you complete control over the extraction process. So what we do with that is we deliver the events to an S3 bucket and notify you of those. And you can pick up those events, bring them through any sort of processing you want, and write them to long-term memory as memory records via dedicated APIs. All of these strategies can be, uh, memory records created from these strategies can be retrieved semantically, so based on a query search. And memory and strategies can be combined as well. And if you think about it, it makes a lot of sense to wanna summarize your interactions and also capture facts about it. So if you're creating an agent, summary and semantic might be the way to start and then if you want more control over time, think about looking at override or self-managed. So let's put all of this together. We're gonna start on the left side here as we remember, interactions, conversations are captured and sent to the agent as short-term memory as events. Depending on the strategies you've configured. Those events are sent into long-term memory as memory records. Both short-term memory and long-term memory, both events and memory records can be retrieved by the agent to complete whatever task it is that the agent's completed, completing. You may have also noticed we now have agent 2 and agent 3 up here. Multiple agents can write to and read from a single memory resource, so that's an option you can make and we can support multi-agent use cases. Or we can support just one. Yeah, so that's, that's agent core memory. It's a fully managed service with built-in observability and enterprise grade security features and now I'm going to pass things over to my friend Imran at Experian to talk a bit about his organization's experience with agentic memory. Need that. Thanks, Jay. Um, I'm Imran Shah. I'm here today from Experian to talk about what you've heard from Mani and Jay in terms of putting this into perspective, uh, with the likes of an organization and enterprise scale, um. So, um, I'm here to talk about Experian journey of how we have, uh, moved from a short term memory to a unified memory, um, architecture and especially using agent core memory to simplify our direction within Experian as all of you can experience today. The whole AI across enterprise is a rapid evolution on a daily basis it is changing, and that is how Experian was thinking before Agent Core in terms of short term memory as money said we talk about something we introduced with that name and I forget who you were. That's short term memory. Um, so we have actually pivoted our roadmap with this whole agent core long-term memory, uh, architecture, and we have adopted that in the pilot mode with Experian, and I'm gonna take you through that journey today. Um, a little bit about Experian, uh, as you know, the credit bureau, um, all across the globe we have credit bureaus. We are an innovative global data and technology business, um, and we, our main aim is to work towards the financial health for all. Uh, we have around 1.5 billion plus consumers across the globe, uh, and we serve both small, medium, large, 201 million+ businesses across the globe, uh, across the geography. From, from a richness perspective, we serve 25,000 employees across 32 countries and from a domains wise you can name it as you can see cable to credit, uh, not only credit but also data solutions, automotive healthcare. And we are delivering this hole with a 99.9% accuracy of data across, across multiple domains. Now let's talk about Experian agent core journey. Um, as you heard, uh, from Manny and Jay, we started our journey with a short term very product specific memory implementations and very quickly we realized that's not the way to go, uh, and we changed our unified approach to more conversational context and moving towards long term, um. What Agent Core has also brought us is rethinking our road maps in terms of how Amazon Bedrock agent code memory, we are actually moving to more time to value simpler journeys and pivoting our roadmap towards that, uh, and we'll talk in subsequent slides about how we are doing that in perspective. So as you can see in this diagram, our current memory implementation is across uh products in, in two different ways. One is managed memory where you have assistants which are using tools like OpenAI, uh, providing thread level memory. In this in the right hand side we also have custom memory implementations which are some of the agents leveraging OSS open source frameworks again providing thread level memory. In the contrast, as you can see we have a managed and we have a custom both coexist which creates a lot of user frustration and confusions across teams. So, from a short-term memory perspective, as you can see, it works, but it doesn't scale into the enterprise world. A, a very small company with even 500 employees or 200 customers, even in that regard, short-term memory has some limitations. Starting with the first one, which is more around continuity and persisting, uh, the long conversation histories. The second one is more around performance and cost, which is very important to all organizations at any scale levels. We also have cross-product recall issues which leads to a lot of user frustration where no memory recall happens across the threads or products. And last but not the least is the compliance, which is and regulatory where it is difficult to meet your regulatory or compliance needs where you have to go back 2 years and represent any, any retention requirements. It's very difficult to achieve that with a short-term memory. If we now move on to more context orchestration and how unified memory has changed our whole implementation in the roadmap with this, as you can see, there are two planes of context here. We have an authoritative context which is more around knowledge bases, APIs. You have databases, the things which, which are kind of your knowledge ecosystems. And you have a conversational context which has short term memory, it has long term memory, and it also has the agent state. When you combine these two planes of context into a more context workflow, it becomes very impactful for an organization which can scale from an enterprise perspective. Your LLM reporting can be much more efficient, and your user personas can give you the user context which is required by a user. Before Free agent core, our planned architecture for unified memory looked like this. Like any other build scenario, a classic build scenario where you have a conversational manager which stores and retrieves all your conversations, you also have a memory manager which stores and retrieves memory records powered by a typical memory store or a vector DB store, and your ETL pipeline is kicking off periodically in order to feed this. So it this model had a lot of I would say significant operational uh complexity due to managing multiple uh custom components. So this was pre-agent core. Now let's talk about what was after we have implemented agent core a long term memory assumptions into our roadmap and into our architecture as you can see it is. A lot more simplified both in direction and also in terms of the architecture. With this, you have a fully managed conversational store, you have a fully managed conversational APIs, and you have zero ATL overhead for your, uh, extraction of your memory. What it brings to the table for an enterprise-wide scale is faster time to value. Improved operational efficiency and a lot of increased functionality. In this scenario, our engineers focus on building agents and not worry about the infrastructure. So, this is how we have simplified our direction and we are still in the process of improving, uh, towards a better scale and a better roadmap for Experian. Our core design principles which are underpinning all of this architecture you have seen, the current state and the two-state is leveraging these four pillars, evaluation and test frameworks, which actually continuously evaluate your memory extraction processes. We also focused on cross-agent memory interoperability so that we can enable agents to share memory across different agents because then they can orchestrate with each other and give you a very informed opinion with the context in mind. We also have shorter targeted context windows with this, uh, which keep it very purposeful and concise. And name space-based isolation which every enterprise would need in terms of achieving multi-tenants architecture where you can serve multiple tenants with the same master shared kind of uh architecture. So these are some of our core design principles which are not only met with this whole design but also we keep this on a, on a, on a daily basis. Now, this is where um A design for privacy, transparency, and control comes in. Um, the whole memory governance service, which we have designed with this, it's a unified first way to manage long-term AI memory. What it allows is a user can selectively delete their own memories if they don't need it. And an administrator would be able to will have an ability to purge it on a periodic basis when it is required so it gives the control in the hands of a user and also in the hands of administration if if they need to take some action in terms of purging. The whole approach actually enhances great user experience, trust, and more importantly, it ensures compliance for guidelines like GDPR or CCPA, and these, these are very important because at the heart of Experian we believe in security, compliance, and user experience all together. So I think agent core memory architecture is bringing all that to life for us. It's solving multiple problems in and also giving us a way to scale at an enterprise AI wide. With that, I will also thank our partners who have helped us doing this implementation from Tiger Analytics and AWS team and at this time, I'm more than happy to hand it over to money to take us through a very um impactful demo. With that, thank you so much. OK, I'm back. Hard to get rid of. OK, no worries. So now that you have understood about agent core memory that Jay went deep into the constructs, the components, how it works, and specially I would like to thank Imran on sharing how Experian has been using it in their products and how it was able to simplify their implementation. And also scale, it is so important to make sure that your agents and your applications can scale and when we are building agent core memory, we are taking that into mind because that's what our customers like yourself are have been asking us, right? So with that, I know it's time for the demo, which I promised you, uh, in right in the beginning. So, are you all ready for the demo? OK. So this is the demo that I built using agent core memory. So I, as promised, there are two agents, the basic agent, which has no memory, then the memory with the agent and a comparison thing. And as you can see, I have some slides that I've already built out using this, so my agent now remembers, should remember my preferences, but let's see the basic agent first. You can see there is like it doesn't have any memory. I can build some prompts provided it's a full running application. And I have to provide the prompts. I have to mention that I like the blue theme, or if I don't mention anything, it will just use the default. But when I go to the memory enabled system agent, then as you can see, it can remember my styling, like for technical presentations, I like the purple theme. I like the technical font. So because I've already built out presentations using this agent, it's able to capture it in the long term memory and also some real world use cases that it should include in all of my presentations and also it shows my obsession with AI so it's capturing that, you know, the user likes to build the AI, uh, presentations. So it literally shows that I'm, I'm into it. And then you can literally create uh a smart presentation and now I don't have to specify my preferences over and over again, but who am I to say that? Let's see it in action. So with this agent comparison thing I'm going to give the exact same prompt to both of these agents at the same time. And as you can see, I'm not going to provide my preferences. Even this prefer and clean, let's remove that. Let's just make it simple, what type of presentation I want, the key components. So now this is behind the scenes what haps, what's happening. So you can see my prompt behind the scenes, it calling the basic agent first. It gave the whole prompt. And after this, now you will see that it is also calling the memory agent. Let's take a closer look and the. The topic and stuff so that it can search the long term memory behind the scene. And find the relevant preferences. Related to the content, but I also need preferences related to the styling. So then it's again making a call for my styling preferences and finding and searching and retrieving. The right memory, which might be relevant to build this presentation. And then it is applying those things, as you can see in the back end. To Build my presentation. So it's all done. Now let's take a look into and get back to our UI. So there are two comparisons, and it's also giving a good understanding and a summary what these two agents have done based on the styling, based on the preferences. So, with the basic one, it is using blue because that's the default theme that I've provided, but for the styling that it has applied to the memory agent is the purple theme. Yes, I'm obsessed with the purple color. So, now let's take a look again at those, uh, preferences, because I want you to remember those, because when you'll see the actual slides, you are able to correlate. This purple theme tech font, uh, AI ethics. I'm obsessed with AI it shows everything, so my agent knows me, right? That's the main idea behind it. So now let's take a look into the deck. Now you can see there is AI ethics tech added to it. Let's take a look at the basic one. Blue Theme as it's a default one because I never provided what I want, no styling preferences. It is still doing a really good job, as I explained to you earlier. It is giving the slide, the format and everything. So now let's take a look at the memory agent. Look, my style purple color tech font. uh, this is basically the, the font that you see while you do the coding in one of the IDEs so I like that. So now you can see, uh, those concepts into the presentation. So it's not just about my style and the preferences, but even if you look closely at the content, you will realize that it has incorporated those things, the content that I prefer in my deck. Obviously this is 25 slides. I couldn't go through all of them, um, but I'm showing you some of those, uh, ideas. And if you are interested, this is, this demo is actually in our GitHub repository. If you search agent core samples, GitHub, under memory, you will see this, um, uh, full, uh, demo code and you can try and play it yourself. OK, so now that we have seen this demo. It is using agent core memory. I'm simply, I was able to integrate, uh, based on the APIs, my existing agent. I built, I started with the first basic agent and then I integrated this, uh, with the memory. I literally called some of the APIs. It took me a few minutes to do that. But then there are a lot of other use cases as well. The example that I gave you is literally related to the content creation example. Uh, so you have this on the slide, right? But there are way more use cases than these 6 of them that I'm showing you on the slide deck. Because obviously there is not much space and not, not much time to talk about all the use cases in this hour. So, let's take an example of some of the other use cases that might be relevant to you. So, a quick show of hands, have you used coding Assistant to build your code, like wipe coding? OK, I see a lot of them on the left side, center and the right, so you are aware, OK, have you noticed this when you are using the coding assistant and you provide all the instructions, it generates the code, then you run the code there's some might be some issues, right? And then you give some additional instructions. And there is one instruction specifically, that at least I give when I do, when I use the white coding, uh, thing, is make changes using minimal lines of code. Do not create any new files if they are not needed. Because agents usually, when you ask them to fix anything, they will create a bunch of test files. So that's like every time. You have to type those instructions. If your coding assistant doesn't have a memory. So have you noticed that one? Or is it just me OK, I do see some nodding heads. Absolutely. So that's an indication to integrate your coding assistants with agent core memory. It will make your job easier. You don't have to type these instructions over and over again. And whenever you are making an edit, you're just saying, oh, edit this file. How cool will that be? So that's one use case on how you can build a really smart coding assistant which can uh which can literally remember your preferences, your style. Maybe you love coding in Python, so it should not generate code in Java, or it should not continuously ask you which language, for example, right? So personal to you. Understanding your experience, giving you a better experience, and this is exactly what you want for your customers. So another example, let's talk about a customer support agent. Now, with the customer support agent, you would call the customer support for a specific issue, for example, talking about a refund or maybe something else that you don't like the product, um, and you want a replacement, for example, or you just want to complain that it took so long for the product to arrive. So those are some of the queries on the customer support for an e-commerce thing, right? We all do online shopping. So I just thought, let's use that. Now, what you want is you want this customer support to remember the past issues. Why? Because you want to understand your users better. Is this customer having the same issue over and over again? So what's going on? Maybe it's time that you might want to update something, or maybe for the agent who's on the other side can quickly look and say, oh, you know what, this is how the, how we fixed the issue in the past. Let's do the same thing again. So those information becomes those type of informa that that type of information becomes critical to providing good experience to your customers who are on the, on one side, and to your agent, who's actually interacting with the customer and providing. A better experience so memory becomes important because that shows how much you care about your customers because you are remembering their preferences you're not just giving them the accurate and reliable help but also remembering them that's the thing that you want to give to your customers. So also I want to make sure that next whenever you're building an agentic application. Think about not just the accuracy, relevancy, those are very important absolute must things to have, but also think about your customer experience also think about how you can minimize uh these number of calls that the agent has to do, because that will save you the cost also, right? So providing the right context to the agent at the right time. You have agent core memory as one of the components that will help you without you having to do too much over lift, uh, heavy lifting, because we are taking care of that on your behalf. So, with that, there is a next step that I really want you to do. What we have presented today. Is actually the beginning. It's not the end of the presentation. It's literally the beginning. There is more to come and more to be seen and heard at this reinvent. So I invite you to join note by Doctor, uh, Swami, who will be talking about the new features that we'll be launching across our agent core line of products or services. And also, I want to, uh, also I want to invite you to build one of these use cases, connect with us either on LinkedIn or shoot us an email or reach out to your account teams, and they can connect you with us. And I'm so excited to hear your stories and understand what you are building next. So with that, thank you so much for your time today, early morning, and I know it's difficult to get up. But you are here, so. Thank you, thank you, and thank you for that.