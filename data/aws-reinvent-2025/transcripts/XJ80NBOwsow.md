---
video_id: XJ80NBOwsow
video_url: https://www.youtube.com/watch?v=XJ80NBOwsow
is_generated: False
is_translatable: True
summary: "This session, \"[NEW LAUNCH] Deep Dive on AWS Lambda durable functions (CNS380),\" introduces AWS Lambda Durable Functions, a new capability that allows developers to write stateful, reliable, and long-running workflows directly within Lambda using familiar programming languages. Eric Johnson, Principal Developer Advocate, and Michael, Product Manager for Serverless, explain that while traditional Lambda functions are stateless and short-lived, Durable Functions enable \"durable execution\" by allowing functions to suspend, checkpoint progress, and resume from where they left off. This addresses the challenge of application logic orchestration without the cognitive overhead of managing complex distributed systems.\n\nThe speakers detail the \"superpowers\" of Durable Functions: checkpointing progress to recover from failures, suspending execution for long waits (up to a year), and replaying execution to restore state while skipping completed steps. They demonstrate these concepts with a \"Serverless Espresso\" ordering app, showing how code can wait for external callbacks (like a barista accepting an order) and handle retries or cancellations. Key features include an open-source SDK, new \"Express Mode\" for simplified console setup, and integration with AWS services like EventBridge and CloudWatch. The session also addresses the \"elephant in the room\"—when to use Durable Functions vs. AWS Step Functions—advising that Step Functions is best for cross-service orchestration and visual workflows, while Durable Functions excels at code-centric application logic and keeping business logic \"single-pane-of-glass.\""\nkeywords: AWS Lambda, Durable Functions, Serverless, Application Orchestration, Durable Execution, Checkpointing, Replay, State Management, Step Functions, Application Development\n---

Good morning. How are y'all doing? All right, the 5 of you that wooed, you may stay. The rest out. Hey, we're so glad to see you here. My name is Eric Johnson. I'm a principal developer advocate for, uh, AWS, and, uh, I talk about Servius, and I love Servius, and I have to tell you this is one of my most favorite announcements I've ever done, uh, but we'll talk more about that in a little bit. I'm gonna turn over to Mike. Mike, tell him who you are. Hey, good morning, everyone. I'm Michael. I'm a product manager in AWS for the Serveist organization. All right, I'm glad to have you here. I have to be honest, I'm really honored to speak with Mike. I, I, I, he's one of, you know, you have the folks, he's one of the good ones. I love him. So, uh, so we're super excited you're here. How many of y'all heard about this announcement? How many of y'all just followed the crowd? OK, that's fair. All right. How many of y'all have heard me speak before? OK. Oh, a good amount of you. All right. Do you know the rules? OK. All right, for those of you who didn't raise your hand, I'm gonna tell you the rules real quick because you gotta understand the rules when we're doing this. So these are the rules they're fairly simple. Number one is this is any number I want it to be. OK? Now there's people coming in later and when I. I say 5, they're gonna be really confused, but that's a 5. And I'm the only one that gets to do this because you look silly doing it, OK? If you say there's 25 of us, they'll be like, that's a 5. All right? So the second thing is these are quotes, not apostrophes. I know that, OK, because this looks better than this, OK? And finally, these are thumbs, because this will get you beat up. So those are the rules to help you out. Also, I'm not listening to a football game or music, uh, unless I am. I use these for hearing aids. I just realized I still have them in. Oh yeah, I was wondering. So yeah, so I'm, I'm catching some music, stuff like that. But anyway, listen to the story. Uh, so anyway, those are the rules. I do tell a lot of one finger jokes. I wasn't. But I didn't wake up this, I was born this way. I didn't wake up for the first time today like this, so if I did, I wouldn't be here with you. So I'm very comfortable you're gonna hear those jokes, however, and I really do mean this, if it makes you uncomfortable. I'm comfortable with that as well, so I'm gonna be fine this morning regardless. I'm good. So all right, so we're gonna jump in and we're gonna get started here. We have a lot to cover and we want to show you. Normally I would do a lot more jokes, but we want to show you this. We're super excited. We have a lot to cover. So you ready? I'm ready. All right. You timing me? Yes, right, I'm already watching. He's watching. He's already stressing. Move it, Eric. OK, all right. OK. This is the first time we've gotten to speak together. We actually just met for the first time this morning. You are John, right? Yeah, yeah, yeah, exactly, yeah. All right, so let's jump in. Today we're going to be talking about, hopefully you've heard about this, the AWS lambda durable functions. Now before we could talk about this we gotta kind of talk about evolution, right? So in the beginning, think of it, do you wanna sing? Can you do like mysterious music? OK, alright, that was good. I like that. All right, so in the beginning there was. The monolithic. And here's the truth, we love the monolith, right? Or at least as developers, we like developing on the monolith because everything was in one place, right? It was all on a single screen. I didn't have to go over here to this room to do this thing and then run over here to another state and zip code to do this thing. It was all I'm hearing people going yeah yeah yeah yeah so and then so it was all one place so that was the but the the problem or struggle with this is that it, it was coupled right? we had a problem if we wanted to scale this, it meant we were no longer developers we were operations people scaling large computers and dealing with that and you know, so we needed to change that. So then we came with the microservice and we love the microservice, right? Because microservices give us this ability to be detached, to be decoupled, to work on independent things, and we love that. However, with every good thing comes a little struggle sometimes, and we have this complexity, uh, in coordination that that could happen, you know, with cascading failures and, and it was cognitive overload or overhead, but I say overload to make those work, right? So AWS came out and said we think we can help you do that. We have a lot of practice running large scale applications. Anybody ever heard of a little startup called Amazon.com? OK, that joke kills every time. Yeah, I'm still laughing. Good. I'm glad to hear that. We appreciate that that you use that, but we're good at this, so we said we want to help developers do this, so. That's why we brought out Servius. And so if you think of the servius journey, we started with AWS lambda, and this was really the first time that the word servius was used in mass quantity because while we had servalus services before, the lambda function was the first time we introduced it as compute. And you could do compute servously, and we loved it. We were so excited about it, right? But it was stateless, short lived, and those aren't bad things. But we found we really need a little more orchestration for some things because I don't know about y'all. Anybody else the master of the if then. For the switch and bad code, right? My, my title is developer advocate. It shouldn't say developer. I'm a hack developer, right? So we said, you know what, we wanna be able to orchestrate things. So in 2016 we came out with AWS step functions which gave us orchestration without infrastructure. It's a service way to orchestrate things together. We were very, very happy about that, right? This is perfect for AWS service integration. as we're doing that, and it gives you a visual orchestration of infrastructure services along with that. So you've got this orchestration we found we needed to be able to choreograph between these domains, right, between these running orchestrations. So in 2019 we announced Amazon Event Bridge, which is event, uh, driven architecture without infrastructure, and this allowed us to easily or more easily decouple our architectures, right? So this was the journey that we were doing, however. We still have this question the developers ask us all the time, and I as a developer is asking, and that was, what about application logic orchestration? How can you help me do this better? So here's what I think, alright, I think, and, and here's what developers think, and I call myself a developer. There's many in the room who'd argue that. Developers wanna build like you're building monoliths. But you want to deploy. Microservices, right, we want the old days of a single screen. But we want to be able to. Use the decoupled architectures that are out there without the cognitive overload. I think that's the question that we're having. So, yeah, can I, can I just interrupt you for a second? Well then, I'm just gonna suspend you. OK, can you give me this please? OK, all right, so I was wondering, Eric, as you were talking, what if you could build even the most demanding applications like auto processing, payment systems, and user onboarding. Directly on lambda, which means using your FEMA processes and tools like programming languages, IDEs, and even LLM agents these days to build, test, debug these applications locally before deploying to production. And if you needed to even to pause the execution of those functions in your applications, for example, if you have long running operations like human in the loop processes. And so I'm excited to tell you and everyone in the room here as well that yesterday we announced AWS Lamberdable functions. Thank you. So with durable functions you write your reliable business logic as simple sequential steps, almost like the good old monolith days, just cooler, and that means you use a family programming language JavaScript, Python, TypeScript, you name it. You can even suspend the execution of those functions when you needed to wait for extended durations. And lastly, as you know, it's lambda, it's fully managed, no servers to deploy and operate. So I'm gonna pause here for a second as well because I wanna say thank you to our AWS cust uh customers, partners, heroes, and my amazing AWS colleagues who contributed to this launch so this wouldn't have been possible without you and also not without Eric. Thank you so much. OK, yes, thank you. This is for you. So I talked a bit about what these functions can do for you, but not so much how, and I think this is a deep dive, so let's go a bit deeper. First and foremost, and maybe that's the the biggest thing you should know from this talk, is durable functions are regular lambda functions. It's not a new resource. It is literally the same function that you know today. That means your processes don't change. You have the existing event integrations, the tools, the things that you use today. However, durable functions have superpowers, and so Eric created this little superpower logo there, and I think there will be stickers at some point. So I'm rooting for you. Do this by hand. Oh yeah. Um, so what are these superpowers? One is dual functions let you checkpoint progress in your event handler. It's almost like hitting the save button as your event handler executes to persist the progress the function has made, and this is useful for two things. One is if there's a failure, there's a crash, you know where you can recover from, but it's also useful to suspend the execution of a lambda function when you need to wait. So checkpoints are useful for the progress but also for suspension. Well then the question is if we have these interruptions or suspensions, how do we recover from them or resume from these um points and this is where replay comes into the picture replay runs the event handler, your business logic from top to bottom again, but it skips over completed checkpoints, so it's not gonna redo the work or the side effects that are already completed. But in order to simplify that for you, for you as a developer, we offer you a new open source SDK that abstract these lower level primitives like checkpoints and replay into higher level operations. um, some of them are called steps, some of them are called weights you'll see more uh in, in the demo later. Generally this concept of checkpoint and replay is known as durable execution. So durable execution gives you these like checkpoint replay capabilities expressed through the SDK and therefore you will see durable execution in our API in the console and the SDK as well. So in a nutshell, durable functions are regular lambda functions that use durable execution to make reliable progress and suspend execution. OK, how do you get started? And this is I'm, I'm super happy about uh the experience here. So in the console there's this new little toggle. It's almost like a little innocent when you create a lambda function you can just enable the durable execution capability in your function. That's it, you just set it there. You can also do it through the APIs, which means infrastructure as code tools, cloud formation CDK. You will see that there, and you can set two new properties. One is the execution timeout for the whole execution of the lambda function as it executes multiple times. I'm gonna, I'm gonna, uh, add something here, please do. So, so when we say API, you're all developers, you probably know this, but for me myself, this is also IAC, so infrastructure is code, so. We'll talk about it a little bit, but this is, it's literally as simple as adding these two configurations, correct, and off you go. And one is even optional, the retention period. So the execution timeout can go up to 1 year. So the whole life cycle of this durable function can be 1 year with suspension points, and the retention period is for the checkpoints. How do you, how long do we want to persist the data, the checkpoints after the execution has completed. And this is configurable. Next, in your event handler or in the lambda function, you import the durable functions, durable execution SDK. I'm showing TypeScript here, um, and you will have two new primitives. One is the wrapper, that with durable execution wrapper, which you wrap around your event handler, so it upgrades the existing event event handler that you use in your durable in your function, and you get access to this new durable context. The durable context has these superpowers. And with the durable context you get then these steps that let you persist or checkpoint your business logic progress so anything in white here is literally existing code that you would write anyways in your function. The blue things are the new superpowers that you just use as you write your business logic in in lambda. And we also have weights, different weight capabilities. I'm just showing here one, the context weight where I can say I'm gonna wait for 5 seconds, and what happens here is it's gonna be make a checkpoint as well and then terminate the function and after 5 seconds bring it back to life, run the checkpoints again, and then move on. So let's talk a little bit more about the checkpoint replay behavior but because it's fundamental to how durable functions work. So I'm just gonna use a very simple auto processing example here. It has 4 steps that we want to go through. Obviously your example would be bigger, but I couldn't fit more on uh on the screen here. First, what we do all of our like the business logics, the steps that we want to run, we put them in these steps, context step and then whatever you wanna do inside those right with your uh with your code. So steps are used for checkpointing so we keep track of the checkpoints in this example, but we also keep track of the benefits that we gain from these different primitives as we go through the example. So let's start with the one your event handler starts running, it's like triggered by an event maybe from SQS or from another upstream. So it runs kind of the first step, executes validation phase, that's fine, cool, succeeds, moves on to the next, next one and does the checkpoint. So we get this progress checking, that's kind of fundamental. Now the the event handler moves on, hits the next step, which is the reservation um of our stock, maybe reserving it. Here we have an issue, it blows up whether it's the downstream is not available or the function has some issue, um, whatever, and in this case, um, if you put a step around it, we get automatic retries back off and jitter. So I'm not saying you can just write happy path code, but we remove a lot of the boilerplate um that you have to put in your function to make it resilient with automatic retries. We also give you deduplication or item potency depends a little bit of how you wanna frame it because let's assume this function crashed and the upstream caller, whether it's an event poller or a a user clicks on retry because something happened it's not really reacting. What do we do here? Well, behind the scenes a durable function will not spin up another durable function for another request, so we have inbuilt built in item potency and deduplication logic on the front end to ensure only this execution is running once. Now replay kicks in. This is when the system tries to recover from this interruption. Replay first makes sure that the um the invocation when we run the function again uses the same, the exact same version that the Drupal function used for this execution. You might have had code changes in between the bug fixes whatso on replay makes sure it always replays on the version it was started with, so the life cycle is kind of guaranteed and pinned to the version. Then as the event handler starts processing again we are gonna skip over the completed checkpoints we already did. We're not gonna redo them and that's very useful for example if you have steps in your code that are either expensive or latency sensitive um or have side effects that you don't wanna redo again if you completed them, we just skip them. Next we hit the reserve point because we didn't really complete it the last time so we're gonna rerun the reservation step again to ensure it works and let's say this time the downstream is available and we don't crash and so we have a checkpoint here cool. So you might have noticed that the payment step was not wrapped in a step and it was for a reason, because the payment here should signal in our code that is it's waiting, it has a weight capability we wanna express that we need to wait for someone to click a button or swipe the uh the credit card through so we use one of these weight capabilities that our context provides weights are also checkpoints. And then when a checkpoint, when a wait point is hit, the function terminates. This is literally when it stops executing gracefully because you indicated that you want to stop here. Now it's suspended. It's not running. The function is suspended. The question is now how do we bring it back? Like what wakes up the function again, and this depends a little bit on the weight that you use. Uh, a typical weight would be context, wait 5 seconds, so you have a timer-based wake or you can do wake me up in a week so I can send an email to someone else. But we also have callbacks where you can send a callback ID or token to a downstream service like a payment system which then uses this token to complete this callback. Once completed, the function will resume. Another one is conditions where you can pull external APIs and say every 5 seconds, please call this API, but between the 5 seconds when you don't do work, just sleep. So we have different weight strategies. But more important, sometimes you want to cancel a weight, and if you've done this before in other architectures, cancellation of sleeping or pending resources is really hard in those systems. Withdrawal functions is literally just a feature or a configuration that you put on the weight when you say cancel this in 5 seconds if you don't hear back from the other system. OK, let's assume we have a cancellation here because the user didn't click the link or it didn't swipe the credit card through. Through through cancellation we will bring back this function. It's gonna go through the replay process again, it's gonna skip the wait obviously because we've done this, we're not gonna wait again. And now we might wanna do some compensation. We might wanna go in a different path in our code that says, oh actually the user didn't click, so we have to roll back undo work that we did before. Undoing work or often called saga pattern where you have different services that you wanna undo um in a distributed architectures are quite simple with durable functions because they're just steps you put them in steps, try catch and in your catch code base for example you just run these steps to undo work and because they are steps they get the same reliability guarantees that we discussed before. Steps are also then checkpointed for these undo operations. What I cannot show you here on the slide is local testing and observability, and I think this is a good segue into your demo area. So let me now a couple caveats here. Eric Johnson coding, we already talked about that most li liability code in the house is mine. So you're gonna get to see me. I have one finger and I have fat finger worse than anybody. So, but I'm gonna try some live coding today. We're gonna see how it happens. But uh for some of this I'm gonna show you on the screen. But first of all, how many of y'all have heard of Servi espresso? All right, a few of you, how many of you have had the coffee? Alrighty, so if you wanna go over to the expo hall, get a sort of espresso, coffee's on me. Not really, but you know what I'm saying. But we're gonna use this as an example. What I decided to do is this is a really well known application that that is based on step functions, which we love, uh, but I wanted to see how well could I do this in durable functions. So just to kind of give you an idea, the durable function is kind of the hero of this application. Real quick overview and this isn't really about architecture, but this is kind of what the architecture looks like uh it is an event driven architecture that I'm using and the durable function is, is pausing and restarting and doing things in parallel and child context, all the things crazy, yeah, yeah, it is crazy so. Let's take a look here. More importantly, I want you to see kind of what do the, what do the steps look like. So if you look inside the durable function, this is what's going on. We've got the order placed. We've initialized the order, then we validate the order, and, and, uh, when we're validating, we're doing that kind of parallel. So let me show a couple of these. So when we initialize the order, you can see in the blue here I've got the context.s step, and this is the initialized order. So this is how it shows up in my name in my uh. When I'm looking at my console, and then the durable function has a context, right, the step context, and then in there I can use the step context to get access to different things, and I've, I've kind of abstracted away the Dynamo DB code. It's probably bad anyway, but that's, you know, we do code to talk to Dynamo DB to write the data. Then we're going to actually do the logger. So we're going to write that out. Hey, here's what's going on. And when you see me run this letter, I, I logged everything so you can see that going on. Right, so finally I'm gonna set a retry strategy. Now I can set this once and apply it to all, or I could set different retry strategies, but I can tell it right in there, hey, I'm gonna have you try retry twice with the with a certain amount of jitter with the, you know, different things. So there's a lot of, a lot of aspects I can change on that, and I have a lot of control over that, and that's a lot better than trying to write that in my code. Let me just place that Eric, just to be clear, all the stuff back, all the stuff in white. Is just pure business logic, yeah, anything, it's what you would do in any other lambda function, right, or anywhere else. So that, and that's how I think that's a really important point to make is we built this specifically to work in a lambda function, not to have to learn. I mean, yes, there's an SDK and you're gonna learn those steps and things like that, but. It's easy to use in a lambda function because it was built on top of all the lambda function stuff already. So, all right, good. All right, here we go. Awesome. So the next thing we're gonna do is we're gonna validate the order and in this one I'm actually gonna run some things in parallel, right? So I wanna do, there's no sense me doing this, then this, then this. I need to grab a couple of things and get that information. So I'm actually gonna use a child context here and so you see I've got the child context that's being delivered by the. Parallel step, uh, and in there I'm going to fetch the event config which will tell me is the store open? Do I have capacity, do I have the menu, whatever, right? And then I'm also gonna check the amount of orders to fetch the attendee orders because here at Reinvent, uh, if you've been over there a lot of times we limit it to 1 or 2 per day because wow, coffee in Vegas is expensive. Right? So, OK, so then I'm gonna add my recharge chart. That's, that's gonna be on recording. I'm gonna be in trouble for that later. So, all right, there, there we go. OK, so. We got a retry strategy and then I'm also adding another thing here. I'm adding the Mexican currency. How many times or how many do I want running at one time, right? So, uh, I, I have control over that and this is super handy if I'm trying to protect downstream services, uh, and different things like that. So really important. So the next thing we're gonna do, we're gonna skip a couple of these, and we're gonna do, uh, a wait for barista acceptance. So this is where we, uh, it's all powerful, but this is really cool. So what I'm gonna do is I'm gonna call a wait for callback and I'm gonna pass it, uh, I'm gonna get a callback ID and then I can store that, uh, and, and, and, and so then I can, I can do some different work and then I'm gonna pause, right. I'm gonna suspend the lambda function until that callback ID, so somebody calls the API with that callback ID and said this was successful, this was a failure, and so on. OK, so that gives you an idea of how that works. I'm gonna actually get to the code here, uh, so we can do that a little quicker and then again I'm setting a specific retry on this, or I'm sorry, a specific time out, uh, how long do I wanna do that? Some other settings I'm gonna do is I'm actually catching this. So if someone, if it times out because I have a 2 minute timeout, if it times out, I wanna catch that and say, oh, it was canceled because the barista didn't pick it up on time or the user canceled it. That was the undo topic, the saga compensation that we, exactly, it's compensation. Some of you might wonder now, OK, how does the callback come back and how does this work? We added new callback APIs to land, uh, to land APIs so you can complete or fail these callbacks as Eric just mentioned. That's right. All right, so I'm gonna go ahead and switch over the demo we should see that. OK, good. All right, here we go. All right, first thing I wanna show you is this is a SAM template. This is built into SAM, and the only thing I'm doing is if I scroll down just a little bit here on line 676, you can see durable config. Is that big enough for y'all in the back? Can you see it? All right, perfect. All right, I see thumbs up. I think that's now you're just bragging. OK, all right. So, uh, so that's the first thing I'm gonna add. Now down here is I'm adding a statement, and these are two new permissions. You don't have to add this if you're using SAM. Uh, it'll add it for you, but I wanted you to see that. So, so what am I doing? I'm adding the permissions to checkpoint durable execution and get durable execution state, uh, and then I'm, I'm scoping it down to my, to the particular function I'm gonna use that gives you an idea of in SAM, but let's actually see it in action. All right, so we're gonna refresh this. We've got a coffee in there. Somebody scanned my coffee when they saw the QR code. All right, but I can play that way. Too early. OK, all right, so that's gone. All right, so I'm gonna go ahead and I'm gonna first, because where do we start as developers? We start locally, right? So I'm gonna go ahead, let's clear this out real quick. We won't clear it out because I can't spell it. So I'm gonna do Sam local hold on that's a comma invoke that comma. Alright, here we go. I'm gonna stress Michael out, you watch it. But it was a single tick comma. Yeah, yeah, he's, he's gonna lose it because I, yeah, if you had to watch me, alright, so we're gonna move on. So I'm gonna go ahead and start this. So this is actually locally invoking the, the, uh, the lambda, the durable function. Right, and so it's gonna run through this, um, and now you can see, and I'm running through it synchronously. I could do this asynchronously as well, but one thing I'm gonna do is I've come to a point where it needs a response from me. So this is that first callback, and what it says is, hey, I've hit a callback. Here's the callback ID. What do you want? do well for this we're gonna do a happy path we're gonna say go ahead and send a call back success and here's my results and you notice over here I've got a uh uh some coming in here somebody else is ordering coffee. You're gonna see this one be accepted there it goes and now we're gonna go ahead and complete that and so at the time this the uh the durable function is pause and waiting for my interaction. So now I'm gonna go ahead and complete that. And you'll see that go away. So we were able to interact because I'm using. I have already deployed this, so I'm able to interact this. However, what if I haven't deployed that? Well, one of the cool things is I can go in now, uh, I'll, well, actually let me show you this first. I'm gonna do a Sam local and I'm gonna get the execution. So if I'm local and I wanna see the results of this, let's just paste this here. I'm moving fast here, Michael. Keep me honest on time. You're good on time, my friend. All right, so there's the res there's the results of that one. Now what if I want that full history? Well, I'm gonna copy this. And I'm going to paste that there. And now I've got the full history, and I want to actually blow this up so you can see this. Look at this table here. So in here I can see everything that happened. OK, now if I wanted it, I could also add a format JSON and I would get back the, well, there's no reason we can't do it here, so we'll do format JSON, and this will actually pull that and again this is all stored in the container or stored stored in this local, and here's all the information that I need that I can use to debug. All right, so this is great, but what if I haven't deployed it yet, right? So is, is I'm right now I'm using environment variables to talk to services in the cloud, but as a developer I wanna run local tests, no problem. So I'm gonna go into my. Uh, lambda function, which is in the coffee orders, and then I'm just gonna run MPM test and I'm gonna use the test runner that's provided in the CDK that's actually going to run this and it's gonna, and I've got all kinds of assertions that I can make and we won't go through all this. I actually have a blog that I've put out that'll show you a lot of this, but this allows you to test these through mocking without having to talk to the to the. Cloud and you can fully wrap a test suite around that, yeah, just to briefly correct you, not not in the CDK in the SDK. The SDK comes with a test you did you you because you love CDK, but I love the SDK. So it is in the, the SDK gives you a testing kit now where you can run and mark these unit tests use DNA as Eric just described it to run the function locally for some more integration testing against the cloud and then later deployed, which I think you did, right? I did, yeah, so, all right, so now I'm gonna get you to help me out, get your phones out, so we're gonna see how this goes, all right? I'm gonna let you order coffee, although some of you jumped ahead, we'll have words. All right, so let's throw up this QR code now you'll see you should be able to see this, and I should see orders starting to pop in. If not, Michael built this. Wasn't it Kro? It was Kro, yeah, let's be really honest, uh, Kro and I did this. All right. More Kro than you, I guess. Yeah, yeah, yeah, exactly. All right, so here we go. We got orders. Oh my God, whoa, whoa, whoa, whoa. OK, go warn the baristas. All right, OK, so we're gonna take this off because you're killing our baristas. Alright, so if I go in here now, these have a 2 minute timeout. I'm gonna try really hard to get to all of you in 2 minutes, but I'm probably gonna cancel some of you. But. Let's look what's happening under the hood. So here's the lambda function, and we have a new tab called durable executions, and you know it's new because we put the word dash new in there. So there's the new tab, all right, in case some of you couldn't find it, look for new. All right? So when we go to new, you're gonna see a ton of these running. Now I've got one that we may have, that I may have, oh, this may have been one that I canceled earlier, but these are all running. So if I go in here, let's actually, let's actually read this and look at the output. Uh, and, uh, yeah, canceled my, oh, someone ordered it and canceled the attendee, so I'm able to look at the input and the output here. So let me go back and you can see I'm on version 99. I've been doing this for a while here, um, so I'm gonna go into one of these and you'll see here that we are sitting in. Wait for a callback in the we acceptance so it's actually uh gone in here. Hold on a sec Eric, can you, can you pull up the steps again the durable because this is, this is easy to miss in his code Eric is using step names so you can provide names to these steps which then we'll visualize in this table here. Um, so for example, generate time stamp so you have full visibility in your code if you provide step names and then you also see the logical sequence, uh, of your operations including parallel. Yeah, parallel is there as well. Yep, that's right, yeah, I've got Parallel going on. So here you can see the parallel what's going on. You can go in here. Here's the fetch event config. Here's the, you can see the outputs I got from that. Um, now you can see here, and now that you've talked, I'm not going to get to some of these coffees. Yeah, so there's the blame, right? So you can actually go here and you can see the callback ID that's going in. What else do you want me to show? Well, in the console, if you scroll right a little bit, you can even complete a callback in the console if you want to. It's, it's in the actions. You see the little buttons, so you can even complete those in failure. That's right. So you do that right in the console to see how that works. All right, now I'm gonna go in here to the bar barista. I'm gonna accept a few of these, and we'll complete a few of these. And so what's happening is the lambda functions are coming back up. They're starting that replay model, they're skipping over everything they've done, and they're continuing on. And, and you'll see what you're gonna see is a lot of these start canceling out. Oh yeah, we've had a lot canceled out already because I'm sorry, I'm, I'm barista as fast as I can. All right, so we'll, we'll, oh, they're going. I feel a lot of pressure, Mike. All right, so, so we'll complete. I'll say I completed a few, um, and there you go. Uh, the other thing I want to show you real quick is we'll go into cloud watch. You can see on this, uh, let me go back and get the most recent. And you can see here that I've got all my structured logs. I can pull this, uh, as I need it, much like what I'm seeing in the console. So good, awesome. All right, great demo. Turn back over to you. No, I think it's you. That's still me. That's right. It's OK, so let's go to there's that code again. So I'm gonna be taking this down today. So there you go. All right, so production really a reality. Let me talk about what this means. One of the really cool things I wanna throw out, all kidding aside, I'm not a strong developer. I'm an average developer. I probably represent the average developer. And so when I decided to build this, of course with the new code assistants, we're able to move very fast. I was able to build, take away all the wrestling I did with types and bundling because I struggle with those things, but I was able to build this application in roughly 6 hours, OK, using Quiro. So the reason that's so cool is. Coding assistants love durable functions. They love code, right? They understand the code. Uh, there are many references available. Obviously we're pushing a lot more out on ours documentation, but load up your steering docks with the documentation with the references, and Quiro really, really rocked on this. I was so proud of this. I bought him a hat, so they moved quickly. All right, so let me, let me, the other thing is the durable function unit test framework, right? So you've got two. Testing modes that you can do this. This is really slick. You can do local and cloud, and I have a working version of this I'll be posting probably, probably early next week. Complete execution inspections, storage options for storing to take that, uh, testing strategies, uh, local test for business logic, cloud test for integration staging, and then you focus on the outcomes on this, right? So this is just an example of what it looks like. I have a whole blog on testing that I'll be posting later this afternoon as well. All right, so the last thing I wanna talk about here is infrastructures code, which you already saw this in effect, but, uh, we are going to be obviously Sam is is and the version of Sam is coming out actually as we speak they're deploying this, so, uh, that'll be out, uh, but this it it allows for local and remote uh invocation, execution invocation data execution history like we showed you. You could do callbacks. You could stop the execution, and you could get the logs, but Sam's not the only one supporting this, as Michael said. We're going to be cloud formation. If Sam supports it, cloud formation supports it. That's how it works, right? And so cloud Development Kit or CDK is coming out this week in Terraform. Yeah, it's merged already. I'm sorry, it's merged already. It's already, it's merged already. Michael's way ahead of me, so. That gives you an idea of what's going on with IAC. Michael, I'm gonna turn it over to you. Awesome, thank you. Yeah, you bet. Give a, I think we should give an applause for the demo so that this was very brave, very brave. Thank you. Well done, Eric. Thank you. All right, let's talk more about the key integrations and lambda features that you can use with durable functions. So first, runtime, durable functions support at launch Node JS 2024, 22 and 24, and Python 313 and 2014. And also OCI OCI can be used for bundling the SDK. We'll come back to this in a second. We have more developer tip if it does node, it does typeScript. Oh yeah, good point. We also have everybody knew that a good call. Yeah, thank you and thanks for interrupting me, but I'm, yeah, you got it. It's what I do. Yeah, OK, let me replay then. OK, sorry, no, uh, so for runtime we have more, uh, languages planned in the pipeline as well. Event sources, it's a lambda function as I said to you before, so it works with all your event sources that you have direct synchronous invocations there the lambda durable function is limited to 150 minutes of execution because it is the way synchronous invocations work in lambda today. You would not want to hang on for a year on a connection. However, there are some cool features even with synchronous invocations. One is if you. Have a synchronous invocation that let's say fails after 5 minutes like the caller terminates, does a network glitch, you can now reattach to a running execution if it's still running. If it's completed, you get the result back so we have item potent behavior if you pass the execucution name parameter on async and Vox, which will probably be the most common use case, you get up to 1 year execution. By the way, I forgot to say in direct sync you also can use weights. So we have heard yesterday from a customer who said that they have a synchronous invocation, but then they need to wait for a callback on the external back end. Now with synchronous invocations, as long as you stay within the 15 minutes, which you usually do on a sync, you can even use weights in between, and the caller won't even notice that someone is like terminating and sleeping behind the scenes, so that's pretty fancy. Next, this is the item potency way, like if you invoke a durable function through uh sync or a sync, you can pass execution name, and that gives you this deduplication uh effects that uh we, we spoke about earlier. We also have not shown in the demo, is invoking other durable or non-durable functions. You will likely have a lot of existing lambda functions, so in your context you can do context invoke and invoke non-durable and durable functions. While those are running, your durable function will go to sleep and suspend, which means function chaining now becomes somewhat of a less anti-pattern because you get the reliability and you don't pay for the weight while the other function is executing. Obviously, lambda functions support event source mapping, so dural functions do so as well. However, event source mappings today also invoke your functions synch synchronously, which means you're bound to the 15 minute execution duration. If you want to go for longer, you can invoke a non-durable function, for example, and just dispatch on an async path, but that is just the way event source mappings work today, and that's that's for. Reason you might want to use SQS as a buffer with concurrency controls in your lambda functions. They do still apply. Therefore, with a synchronous behavior in this sense, we still keep the promise of concurrency control. Alternatively, if you have FIFO order-based event sources, synchronize ensures that the processing remains in order for the system. So we didn't want to break you in this way. And all the other integrations S3 EventBridge, whenever you can pass a function on, things will just work. Versions and aliases are not just supported but also very important for durable functions, because the replay behavior, the checkpoint replay behavior requires that your code remains deterministic when it's re-executed. Therefore, we don't allow unqualified arans, and this is a safety behavior that we put into the system because unqualified arans are kind of, I don't really care what's going on, but if you tell us you don't care, we also can't really care about your code because we don't know what version of the code you want it to be executed. So replay becomes hard in those scenarios. Therefore we only support latest as kind of a, you only live once mode if you really want to do fast prototyping or proper versions and aliases because they are strict, like they are kind of required in the replay model of durable functions. Yeah, I'll throw this out that those are also with the IIC like Sam, they're gonna handle a lot of that for you. True, yeah, and it's kind of a best practice to be honest, to know what code is executing in production. Um, X86 arms, I'm just gonna skip through some of these kind of things that letter queues are supported, uh, and you might still want to use them. For example, if an execution fails, you wanna, uh, or like it can't be executed, you wanna put it in that letter queue. Layers and extensions are supported, but we couldn't test all the layers and extensions out there, so there might be some things, technologies, SDKs, integrations that, uh, might not be aware of the durable functions, so we have to work together with the. To make them aware of durable functions of this replay behavior, BPC attachments, running them in private networks, concurrency settings. I already explained, especially for ESM sources with SQS, quite interesting. Snapstart works and Power tools. Power tools doesn't just work, we really worked amazingly together with the Power tools teams if they are in the room or watching in one of the other broadcast rooms. Amazing folks, great support, kudos to you. Awesome. We've got more covered in the lambda developer guide. There's a big new section on durable functions, so it has all the details, so please take a look there. On the security side, we introduced a new managed policy because while you might not want to distinguish between non-durable and durable functions in the future, we still want to make sure that you can gracefully adopt this technology. So we introduced a new IM conditions and resource policies so you can gradually. Roll out durable functions and also prevent access or control gate the usage of durable functions. Therefore, we have these two new checkpoints in the system. There are more APIs that we offer like the callbacks, for example, or the durable invokes. They are not part of the managed policy for security reasons. You can just adopt and amend them. On the encryption side, data encryption at rest, we support the existing customer managed KMS keys on lambda function for code ASM filters, and environment variables. At launch, we only use like support an AWS owned KMS key for the checkpoint encryption. I'll come back to this in a second. For monitoring, we obviously integrate with Cloudwatch logs. You've seen this. Anything that you log in your function will just be locked. However, we have this new context locker which is replayware, so it will suppress locks on replay so you don't get spam in your system. However, even that loger can be configured for some testing. You might actually. Want to see the duplicate logs printing out so that's not a big change on CloudWatch here. Cloud trailers supported and we also emmit new cloudWatch metrics for like how many durable executions are there running in my system, which one have failed, and all the operations that you create like checkpoints and and weights. X-rays also supported for tracing. Something that's really cool and the person is even in a room who kind of uh worked on this as we now have uh notification support with EventBridge, so durable functions emit execution status change events to EventBridge so you can capture execution successions uh or is it called successions? No, it's not successions, completions, succeed when they succeed, when they succeed, and even when they fail through Event bridge. So here's an example of an uh a running execution so you can, you can. Um, even, uh, see the, the progress of those executions through event bridge events in the system. Uh, for quotas, there are new quotas we are introducing for durable functions. Um, some of them are also to support, protect you and your, and your workloads. For example, the number of running open executions. We have 1 million here, but you might wanna adjust based on your needs and a couple other quotas as well, uh, for the system. Quotas should, by the way, be high enough to cover most of the use cases. Please discuss them with us, uh, if you need more. OK, let's move to best practices. I think the biggest one here is and this we've we've discussed it with the community before is start simple like don't build these gigantic, even though the monolithic experiences is great, but what Eric was not saying throw like all your 1000 lambda functions in one gigantic lambda function. Good coding practices, I think that's what you did not want to say, correct? OK, awesome, yeah, just wanna make sure because you're not a developer, you say I'm not, you're just a drummer awesome. So coding best practices still apply, and with the durable invokes and the callback patterns and so on, you still have good ways to compose your applications through multiple lambda functions, including non-durable functions. We also recommend, because the SDK SDKs are super fast moving, so while it's easy to get started on the console with our um SDKs that we bundle with the runtime, please use your favorite packet manager to bundle the SDK from the open source GitHub repositories, because they move much faster than the runtimes are providing those new features, new features. OK, it's good for getting started in the console, but please use the the SDK directly. Uh, Quiro was super helpful for you, and that's true. However, all those agents were based off knowledge that before durable functions existed. So therefore you might have to prime your LLM agents a little bit, uh, before like running them through our existing code based examples, the blog posts Eric and the community is putting out to make sure they understand what a durable functions is because otherwise they're just gonna make stuff up as, as this evolves and uh the context has been added to these LLM agents, it will naturally get better. because I said this is still a lambda function, your timeouts that you can put on a lambda function still apply, so we have kind of two timeouts now that you can adjust and knob. One is for the function event handler execution for the single kind of loop that it's doing, and one is for the whole execution duration which can span multiple of these invocations. So do make sure that your function timeout allows for sufficient time to actually get through, uh, like a a successful execution. Now let's go a little bit more into code. We, we talked about the checkpoint replay and the versioning behavior, so because your code can be re-executed multiple times, although we skip in some places, make sure that any non-deterministic code like UU IDs generating UU IDs, time, time stamps, uh, math rant, and these kind of things, you put and wrap with steps. Any non-deterministic code needs to be in within these like step bubbles because otherwise they're gonna lead to different outcomes on the replay which you don't want. Uh, we covered the logo already, so you can switch, uh, replay on and off or use your own logger. With the SDK has its own concurrency primitives to also ensure reliable, uh, replay. You might know in TypeScript or JavaScript, for example, Node, where you have promise raise, promise all, and so on, we provide deterministic, safe, uh, versions of those to ensure that even on replay they behave correctly. Now I mentioned this in the same case section for encryption. The steps also allow you to provide your own serializer and deserialiser for the checkpoint data that we actually do, and this is for a couple of reasons. Sometimes you might have a very complex object that you want to checkpoint, and therefore you can provide your custom serializer and deserialiser, which will be used to process the data like eventually in the in the back end. Also, if you have large payloads exceeding our checkpoint sizes, you can use your custom serializer to offload to another data store S3 or so, and so on replay, we will just use that to retrieve the data. And lastly, the serializer can also be used if you have very specific encryption requirements so that you can encrypt, including CMK, your code before it hits the the back end. What we didn't really talk about is that within those steps we talked about steps and checkpoints, you control what you checkpoint. There will always be a checkpoint when you use a step which will just be the name and only if you return something from a step it will be persisted in the system so we have full control actually about oh I don't really want to return anything from my step I just want to see it in in the observability like in the execution history and that's perfectly fine but you can obviously also return something which then will be part of the checkpoint. And there's much more, including details, examples, and best practices in our developer guide. OK, let's talk about pricing. For pricing, we wanted to achieve different use cases and requirements. We wanted to make durable functions work for any scale, whether it's your little hobby project like Eric opening a coffee shop or you're running this at scale in your payment processing system. Pricing should also be flexible and transparent, so if you don't persist state in those steps, you should. Charged for persisting those states same for if you have different duration and retention requirements, the system should adapt. Therefore, we introduced new three new dimensions for durable functions. One is the number of operations, checkpoints, like steps and weights that you perform in your system, and this is $8 per million. Prices are all for you each one. And then we have two storage dimensions. One is for the data that you write within these checkpoints. I mentioned before that you fully control that process. If you offload, sideline, or don't even return, there's no data written in the system. And then there's the data retained for the data that you persist within the durable functions back end which you fully control. Note that existing lambda compute charges do apply, so when a function runs, the compute charges still apply. Oh why, what, what is this? elephant an elephant? What, what is the elephant? So I get to talk about the elephant in the room. It is not me. But, uh, the elephant in the room and we get this is choosing a service. How many of y'all are wondering that? When do I do step functions? When do I do durable functions? I don't know. I do know, I have some opinions on this. Well, here's what I would tell you is we unapologetically offer this out. Uh, we, we think these are both fantastic services, right? We think different people use things different ways and they have some different, different things, and we have a little guidance we wanna throw up here, uh, you know, if you're looking at your primary focus is, is workflow orchestration across AWS, I'm, I'm orchestrating a bunch of different services, batches, things like that. Some functions might make more sense to you, right? Whereas if I'm doing, uh, application code orchestration. Uh, then durable functions make more sense. But again, that line is super fuzzy, and I'm not gonna read all this to you, but you kind of get this idea of, of, here's kind of some things that we thought about. But in reality, like I said, unapologetically, we know that you can do a lot of things with either one of these. So it really comes down to how do you think about it? Do you, do you wanna use orchestration to cross AS service? Go with step functions. You wanna do it in in an app, durable functions. If you want a visual builder, step functions. So it really comes down to what do you want and how do you approach it, right? And so there's, there's a lot of different things. So the reality is, what do you prefer? What do you wanna do? They're both gonna be there, they're both available, and we're full-time pranking on both. So I encourage you to, to let us know your preference. I wanna hear back from you on that, uh, because, uh, you know, there's, there's, we wanna know, right? OK. The future is durable. We see more and more needs for this, uh, and so we, we encourage you to, uh, check this out. We want you to play with this. We wanna hear feedback. Twitter, LinkedIn, let me know what you're thinking, um, but here's a couple of things I would, I would, I would give you to, to kind of walk away with. First is build like a monolith. Now, back to what, what we were saying, I'm not saying build a bunch of, I call them fat lambdas with a PH or lambda. We don't know if that's working or not, but I'm not saying go out and build those, but what I'm saying is get everything on a single screen if you can. Build like a monolith, deploy with microservices. Enjoy that single pane of glass. No more choosing between simple and reliable, you have both. Either way you go, however you wanna do it, right? Choose the right tool for the right job. Again, it comes down to that right tool for the right job. How are you going to do that? How does your preference weigh in, right? And I, and I love that statement because so many times every good technical question, hey, how do you do this or how do you do this, has a solid anybody know the common answer? It depends. It depends. That's right. Did you say that? No, it sounds like that was awesome, yeah. So it depends. There's always a bunch of different ways to do things, so I encourage you, uh, to do that. So use your familiar programming languages with this, focus on business logic, uh, yeah, we, we absolutely encourage you to do that. Sorry, Mike. So, all righty. And finally, uh, how to reach out. AWS forums, support channels, feedback mechanisms, we wanna hear from you. This is just the beginning. We're going to be cranking on this. Michael and team have done a fantastic job. And with that, one sec, go ahead. The SDKs are open source, so issues, contributions are very welcome. Yeah, yeah, yeah. With that, Michael, thank you for letting me speak with you. I appreciate that. You're the democrat. Give us feedback, tell us how we did, what can we do better. I hope you have a great rest of the half of AWS that's left. We'll see you later. I'm talking about step functions later today, both ends of the spectrum. Thank you so much.