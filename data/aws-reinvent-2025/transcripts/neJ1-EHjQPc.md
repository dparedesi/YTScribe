---
video_id: neJ1-EHjQPc
video_url: https://www.youtube.com/watch?v=neJ1-EHjQPc
is_generated: False
is_translatable: True
---

Yes sir. Hey, um, welcome to NTA 319. I'm glad you were able to join us today and this morning. I know we're up against Swami's keynote, so I especially appreciate, uh, you being here and maybe the overflow rooms were full. Uh, everybody having a good reinvent so far? Yeah, yeah, um, I was looking at my step counter. I was just shy of 24,000 steps yesterday. Can anybody beat that? Anybody beat 24,000? Did I, do I win? Uh, what about 20,000? Anybody north of 20,000? Uh. Lost counts. Yeah, yeah. Were you counting manually? Well, I respect that to another level. Um, well, welcome to NTA 319. My name is Mike Garner. I'm a, a leader of a solutions architecture team within AWS, and I'm joined today by Josh Smith, CTO of Spretail, and Shri Adari, a principal solutions architect within our retail and CPT CPG, uh, group, and we're gonna talk to you today about Spree Tail's, uh. AI journey to to incredible value. Um, so we'll start with a little bit overview of who Spretel is and what they're all about, um, talk through three of the use cases that they've implemented to realize $50 million in business value. We'll talk about what the path from POC to production looks like, uh, to, to really realize that value and then. And share some lessons learned, uh, and, and how you scale this. So a little bit about, uh, Spretail. Spretail was founded in 2006 in Lincoln, Nebraska, uh, and they're a leader in the e-commerce technology space. You might have interacted with some of their technology if you visited any of the marketplaces. Like Target or eBay or even Amazon.com, some of their technology powers marketplaces that you find uh within there. They really stand out from their competition through that technology platform that they've built through a very advanced, um, and innovative, uh, supply chain and then having data-driven, um, operations. And of course all of this runs on the AWS cloud. That's why we're here to, uh, to talk about that. They leverage AWS for the security, the reliability, and the scalability to bring their technologies to over 600 vendors and across 18 of the most prominent marketplace, uh, uh, locations. So I'm gonna hand it off to Josh who's gonna talk us through how we got to value here. Appreciate it, Mike. Good morning. Like Mike said, appreciate everyone joining, uh, and I know that we're up against the keynote and being able to, you know, see your faces at least here is, is helpful for me. So I'm not talking to any empty audience. But just so show of hands, uh, I wanna kinda get a feel for where y'all are from. So if there's anything specific I can call it that's helpful for your industry, how many people are in e-commerce that are act that are in the room? I don't think that there would be too many. Um, what industries are y'all in? Just curious, what are you in, sir? Insurance? What else? What other industries are present? Sorry, lending, OK, so financial services, payments, financial services, OK. Sorry, Travel, OK. Manufacturing makes sense. Any others? Public sector. All right. The the reason I'm curious about that is uh a lot of folks have asked how we've been able to generate this much value so quickly since AI is, is evolving, you know, uh, very rapidly for those that are in the space, you realize on a day to day basis you wake up and then all of a sudden there's something new that changes the paradigm of how you approach things, startups that are. You know, coming out of nowhere and then failing out of nowhere because, you know, the, the foundation that they built their company on shifts overnight, right? And, uh, to be honest, part of it is I'm lucky to be in an industry that has less regulations, uh, and one of the things that coming into my role, I'm relatively new to my role as a CTO came about a year ago, a little over a year ago, was, uh, talking with the board directly and being like, hey. If you're looking for someone that's gonna be, you know, every time we talk about how we progress things, that's gonna ask about what's the risk profile first before actually the business value, um, you're hiring the wrong guy. So, uh, two of the kind of key factors for me personally, just being honest, so being able to drive that is e-commerce is a, you know, a bloody game. It's all about how fast you can move customer data, all that's not really heavily regulated, right? So the concerns as a company that we have is maybe a little less than maybe some of the industries that you're in as far as, uh, we're still cognizant, but the use cases that we can apply could be very forward thinking, right, and forward leaning. Uh, and the other side was just being strategic, you know, as a, as a leader coming in and being like, hey, I'm setting the ground rules as far as, you know, I'm gonna be pushing the needle and, uh, got alignment that I'm not gonna get fired for moving fast. I would get fired faster for not moving fast. It was kind of like the, the foundation I laid. So if I really attribute, you know, just, you know, wrap all this up about probably 30 to 40% of. Uh, my, our team's ability to do this was because of those things, but I wanna talk about maybe some of the controllables that, you know, you guys can be thinking about that might be in a different industry as well. So, uh, one of the things that, uh, as a product leader, as a, as a, uh, team leader, as an industry leader that you always have to think about when you're talking about the value add. Uh, that you're gonna create is, is coming from the customer lens first, right? And so for our customers and how we interact, um, kind of falls along this value chain, right? So, uh, we basically monitor the market, right? We, you know, build for the, uh, the ability for us to like actually develop technology, right? We market to our customers and to our brands, right? They contract with us, right? Then they plan with us, you know, and if, if it's not clear where we kind of fit in the e-commerce spaces, we work a lot with other brands and vendors and we essentially buy wholesale from a brand. And because of our expertise of how to sell online, we accelerate their volume through the largest channels in the world, right? So we actually take the inventory risk, we have our own fulfillment network, we, we work directly with their manufacturers, we bring it into the US if it's overseas, right? And then we basically have skin in the game when we're trying to accelerate that volume and we make the margin difference. That's part of our business. The other part of our business, as Mike mentioned, is, uh, leveraging that infrastructure to support, you know, marketplaces and brands, uh, in an omni-channel lens like what they're selling in a D2C side or infrastructure. Is, is such that we can deliver next day to 90, about 92% of the US, um, in some cases because of our specialty in big and bulky, where Amazon is specialized in parcel, we're actually faster and cheaper than Amazon when it comes to big and bulky, uh, because their whole network is optimized towards the parcel, right? And so because we can optimize towards big and bulky, which is our niche, right, we can, we can do things a little bit differently and faster than they can do at the scale because they're, you know, it's hard to move a ship like that, right? So when we work with our brands, right, um, we plan with them around, OK, what is our business plan? How are we going to, uh, how much are we gonna buy from you, how much we, are we gonna just service for you, and then accelerate throughout the through, then we go sell it, then we ship it, then we support it, we do the, you know, the, the customer. Experience, so if you buy a sauna on Amazon and get it delivered the same day, which you can technically do depending on the part of the country that you live in from us, uh, you know, and you, you know, if something's broken or you wanna call and the rare cases that that happens, right, we're actually the ones also answering the phone calls you're not dealing with Amazon, you're dealing with us as the seller, right? Um, and then we go scale with the brand. So across this value chain, right? I, I'd put directional, uh, percentages around that's 50 million. In value number where we've achieved that across this value chain, right? Um, we're gonna deep dive on these pink ones, right? These are actually the use cases that we're gonna blend, uh, that, uh, dig into, but I'll talk first about some of the, the other ones just so you'll have a, a broader sense of, of what we've done. So the demand sensing, uh, this is basically looking out in the market and collecting a ton of data around consumer behavior and trends. And looking at, you know, competitive keywords and search patterns and consumer indexes and all those things to understand what are the emerging trends that are going on within the broader economy that impact kind of our niche area and so, uh, where we've applied AI in that space, right, is really related to. Uh, leveraging that data, uh, well, one, creating data, so, you know, if there's, if there's information that is in the visual format, pictures, um, you know, video, things like that, converting that in a way that we can actually analyze that data at scale in a more, you know, contextual sense, right? Uh, and then the other thing that we use the AI for in that particular use case is helping to guide the next actions, right? What AI is really good at in some cases, if you have a good strong data set is, you know, if you with some guidance, being able to say, hey, what would you do? Well, like, what's, what's the actions that you would take if you feed it enough context, right? It can provide good recommendations that you can scale an expert's mind across a number of people. So, uh, that's that use case. I won't dig into it further than that, but just wanted to give some context. Um, business plan scoring, so one of the things that we found. Where AI has been very helpful is we've kind of called it like AI as a judge or it's basically a scorekeeper, right? So we feed it context and we ask it with a framework of how to score a process. In this case it's our joint business plans. How good are the joint business plans that we're coming up with brands in order to optimize how much we're selling, what we're gonna be selling it for, and the speed at which we're selling that through these different marketplaces. That's a, uh, a manual, not a manual effort, but it's a human led effort, right? But we use an AI to score all these plans at scale that are happening on a daily basis, right? And so it's just basically giving us the ability to understand where there's deviations from our expectation and where we're doing better or worse, right? And where is there coaching opportunities in real time to improve these business plans, uh, which before having that capability, you would have either had to do one of two things. Manually have your experts review them or create a uh a machine learning model that basically like knew what good and bad look like through structured data and provided kind of human in the loop feedback, right, to continuously improve that model. It's much easier at scale now with the use of AI to, to do those types of scoring because you're just providing the framework and then it's a directional score, right? Um. Jumping into damage detection, so this is more image recognition, right? Uh, when a delivery driver takes a picture at the front door, right, we get that data for every delivery, and we're doing some automated proactive damage detection, trying to mitigate that proactively, uh, and the intent there is to reduce the number of returns, um, by, and the cost of those returns because shipping a sauna back. Uh, when you've delivered it for free, can be expensive, right? And so achieve some, some savings there from a proactive damage detection perspective, not just at the delivery, but as it leaves the warehouse as well. So we're trying to manage, uh, through the supply chain side. Um, support automation is probably the one that people hear about the most, right? So, you know, how can, with the use of AI answer emails maybe a little bit better and, and faster, and so trying to drive ways that when people are calling like, where's my order or emailing, where is this, we just have ways to minimize the, the manual touches, you know, in the, in the process, right? Uh, last one in white there, risk monitoring. So similar to the, the business plan scoring. You know, applying a set of rules, guidelines, sets of expertise and context to some business monitoring happening across our organization to say, hey, where is there potentially something that we might wanna look further into. Uh, our company is actually pretty forward thinking in the ability for us to, for instance, everybody uses a tool called Read AI which is kind of like a live transcription tool that is on every email and the like, um, and you can basically Do some sensing of that data just to not look at an individual and say like, hey, someone said something, but like, hey, are there like as leaders we get an email update every week, right, which is basically like, hey, here's maybe the things you should think about for this week, right? Um, not any specifics, but here's some directions to maybe go focus, right? And so that's helped us kind of achieve some, um, uh, some specific use cases within that that we've been able to, to achieve some value. So with that I'm gonna, we're gonna deep dive into some of these, these pink ones. And in reality, they, they, they summarize in three things, right? Um, picked one, where, uh, called our Smart shelf tool, which is actually a product suite of capabilities, right? That is customer facing, that is, well, we have two types of customers. We have brands and then we have the shoppers. This is the brand. So this is like brand facing technology. This is what our differentiation is in the market. So I'll kind of talk about that, that covers a variety of the value chain that I shared earlier. We're gonna talk a little bit more internally focused, like internal baseball, how do we use AI for sales and marketing capabilities, right? And then the last is really focusing on enterprise productivity. How have we as a technology organization, uh, which I also own IT in the organization, I'm, I'm not just the CTO but I'm also the CIO, so I own the IT side and the product and engineering side of the house. Um, how are we thinking about the power of those two being underneath the same function and scaling the rest of the organization? Through enterprise productivity to do a strategy that I'm implementing called scaled innovation, which is essentially turning everybody in the company to an inventor, um, using some of the emerging AI technology, right? So, uh, the first one, digging into Smart Shelf. So this is actually a product suite of 6, currently 6 different solutions and tools, uh, where we are helping basically optimize the e-commerce funnel, right? So if you think about when you go shop on Amazon, right? When you search, right, you have a particular product potentially in mind. or you're doing some discovery, right? And so that market monitor is looking at, hey, what are people searching for and that's in the bottom right how what are people searching for? What are they actually clicking into? What are they, um, who are we when we appear in a search one of our products when it appears in a search, who are we next to? What's the, what are the different groups of pricing that people are seeing? And where is there an estimated demand volume occurring at different segments, price segments, uh, based on each search term result, and how does that actually, that information actually influence what we go look at and where do we actually need to make advertising changes, price changes, um, maybe develop new SKUs entirely, working with our brands to say, hey, we're seeing this trend in the market. There's this growing demand for a pink pool, believe it or not, we did that happened this year where I don't know if everybody saw the TikTok trend. Uh, there's like all of a sudden people started talking about pink pools, and we didn't influence the trend, we just happened to like ride the wave where we worked with one of our manufacturers who is one of the largest sellers aboveground pools, told them, hey, we need to work, we, we should probably go build a new like pink pool, and it was right at the time where that kind of went viral and we rode that wave and like owned the pink pool market for a minute, right? Um, so all that's through this like digital shelf monitoring which the AI component of that. Is really around image classification type so it's all image AI so it's like, hey, uh, how do we determine, you know, what's good and bad in an image, what is converting well, what's not, what are the rules around those things, um, and how does that feed into the broader market awareness and how it's driving clicks, um, from the broader what we call digital shelf, which is who you compete against when people are searching on Amazon, right? Uh, that goes, that bleeds into listing doctor, which I'll actually skip because Sri's gonna kind of get into the architecture aspect of that and kind of talk about that use case, uh, even more deeply. Promise Pro, uh, is around the ability for us to surface, uh, next day, same day, uh, delivery promises across marketplaces at the same, like all synchronously, right, which believe it or not, the, the marketplaces don't actually make it easy to do. Uh, and, uh, you would think that they'd make that really simple for a seller to promise that, but it's, uh, it's the level of sophistication required to do that at scale to determine, hey, who is actually buying this product, where are they located, and, uh, what promise can you actually achieve, right? Especially when you get to the same day, next day is actually a very difficult and complicated capability, uh, that we have to hack some of the marketplaces in order to enable that for shoppers because they don't make it necessarily easy. So we use AI to basically. Um, feed that information into Amazon, um, in a way that they don't don't have just a direct API to, to do that. Price pulse, this is how do you know prices are the right way to maximize conversion but also maximize margin. Um, not a whole lot of AI in that one, I'll be honest, but, um, you know, because we haven't needed to, key point, don't just put AI where it, it's not needed, right? Um, so we haven't done a lot there, um, but ad lift, this is, um, uh, being able to maximize the impact of ads. There's a lot of kind of AI models in the background there to try to determine. How can we use ads strategically to drive organic rank? So there's when you use ads and you click on an ad that actually influences uh like all the marketplace's algorithms of like, hey, you know, how valuable is this product and where should it appear in organic search results. And so we have a lot of, uh, both, uh, what do you um. Both unstructured and structured AI models working together to try to balance out how much are we, you know, advertising for what keywords and the like to maximize our organic growth, right? So it's actually using ads strategically to drive organic growth, um. So I'm gonna hand it over to Shree for a minute and talk a little bit about uh listing Doctor and uh the specifics that you. Thanks Ma. So, uh, Listing Doctor is essentially an AI powered tool to generate product listings, um, and, uh, it basically diagnoses and optimizes these product descriptions which are generated in various e-commerce channels such as Amazon, Walmart, Target, etc. So, um, back in the day, how this process used to happen, it's retailers, there are content creators. What they would do is they would take the product description or the product documents provided by the manufacturer along with, um, some internal keyword databases and basically create the title, the description, search keywords, etc. um, in a, in a manual approach, right, which would take a few hours or days to do it, but With this architecture, which is very straightforward, the listing doctor architecture, we have two sets of users. One is the external users, which is retail brand partners, and we have the internal users in the form of retail merchandisers, and there's a web application which is hosted on Cloudfront. Appointing to an application load balancer, uh, which in turn calls different services which are hosted on Elastic Cubanity Services ACA EKS, right? And a couple of two, key KPIs, uh, over here is, um, the listing doctor, uh, um, the API, right? So what that does is it takes the, the product, uh, manuals which are provided by the brands, uh, along with, uh, the keyword database details. And it generates the, the title, the description, the bullets, the keywords, and all that, right, for, uh, to host it in the e-commerce channels. Now you might ask me, right, OK, generative AI is generating this uh content. How is it effective? How do we measure that? So that's where the Federity Service comes into play. And what Federity Service does is it actually compares the, the product listings which are generated by. By Bedrock with by Amazon Bedrock, um, or generative AI with the internal retail catalog, right, to see if they're effective and this particular federity service in turn points to um retail listing quality service. So what that service does is it basically scores, um, how effective that listing is, right? Um, so it takes things like the guard rails which are, uh, provided by the these e-commerce. Panels like the title should not exceed so and so length, um, and also it compares with internal, uh, retail guard rails, um, and it looks at the images if they're appropriate and all that, and it comes up with a score based upon how that particular listing is, you know, being effective in the market, like is it coming up top in the search results, um, is it driving additional sales? So based on that it comes up with a score. And it works like a flywheel mechanism. So as it as in, as in when it is comparing, it is, you know, it'll optimize the listing. And also there's a human in the loop, um, over here where, you know, it generates the listing, as in the generative way it generates the listing, and there's a human in the loop who would actually review the content, and he would, uh, um, he or she would approve that, uh, content. So that's net net, uh, the whole architecture, right? Yeah, I appreciate that, Shari, yeah. Ari mentioned what's interesting about What AI has been able to unlock for that particular use case where if you think about it, you know, most use cases that people talk about are content generation, right? It's like, you know, more marketing, more or less, so this was a, a kind of a square fit of where we felt like it was easy to, to apply, right? We should be applying it, we'd be behind if we didn't apply it, uh, but we've done some interesting things that we feel like are different than maybe some approaches that others are taking. One example being, um, we do constant testing around what works and what doesn't. And we can embed that as part of the guardrail mechanisms into what teaches the AI to how it develops certain content down to like when you search for aboveground pool, right, if you search for a pool versus aboveground pool, the search results are gonna be different, right? Your intent is different potentially, right? And so depending on those types of search patterns, right, we, uh, will test what content performs better. And then we will come up with, hey, for um for this type of product, right, where it appears most in search terms, right, the, the structure of this many bullet points if there's a sizing aspect to it, what, where in the, the description. Should it be? Where in the title should it be? We're constantly using AB testing at scale from a content perspective to understand what is that, and we can we codify those rules, you know, and we feed it into the AI model and so it abides by those rules, and then we use another. AI to judge the output to make sure to abide by those rules, right, so we're constantly flagging and scoring how did it, you know, achieve the initial like objective, uh, and then we use a human in the loop to go review every single thing to make sure that it's like actually but it's helped, you know, generate. Uh, scale for us as we look at how do we continuously improve content, uh, on an ongoing basis. What we're exploring now with this use case, which I'm really excited about, is we're actually going to have like a red team blue team concept where we're using one model to, uh, we're actually having a champion model and then we're having competitive models underneath it that are continuously testing the efficacy of the improvement of can we drive better conversion by this model versus this one. And so the hope is is that we can generate an ongoing testing capability through AI where they're actually competing and we're using some reinforcement learning concepts to basically make them want to win and encourage each other to basically compete further so we're using. You know, various models embedded within AWS and outside of AWS to say which one's actually performing better at this level of the um category tree when you search for Amazon, right? Um, and then using that continuously, so that's kind of in development now and we're pretty excited about that. Jumping into the next use case, which is more internal baseball, which might be a more relevant for, you know, the variety of industries that we have, uh, we've started embedding, uh, not just technology but, um, AI accelerated technology into our sales and go to market process, right? Uh, one of the, there's actually a, a wide variety of use cases in here, um, and she will, will deep dive on one that we're using for brand prospecting. Which is basically showed the results of it, the user experience is shown on the screen. Imagine, um, being able to plug in all of your transcripts, all of your email communication, um, deep research over individuals within kind of that company leveraging LinkedIn, all the like, compiling that together, and then again the scoring concept, being able to score our pipeline based off of multiple factors. Here I'm showing kind of strategic fit and opportunity. Right, uh, and each dot here is an individual prospect within the pipeline. And then imagine having the ability as an executive, as a manager of the pipeline, etc. be able to see where, like where are our prospects fitting, right, uh, along the strategic fit and opportunity based off of all the structured and unstructured data that we have available, right? Um, this is where MCPs actually made a significant advancement in us being able to leverage something like this, uh, compared to when we first built this back in March of this year. Uh, it, we're kind of having to hack our way, and I'll, I could talk about that a little bit in the lessons learned, um, into getting this, but it just accelerated our accuracy there a little bit. And then in this experience, right, you can click in, you can see the most, you see like a one pager of the brand of the summary of where it's at in the pipeline. You see, uh, some of the most recent communications, some red flags around, hey, uh, there's, you know, a negative trend here where the prospect has gone cold, right? Or things like that. So it gives kind of managers of the sales pipeline or executive team, the ability to understand where things are sitting and how are things progressing, right, in a, in a singular view. Other use cases that uh we've kind of applied AI in the space um in sales and marketing we've got a tool that we call Sales Hawk. Which is pretty cool. Uh, we imagine a live recommendation engine sitting as you're on sales calls where, uh, it's actually listening to the calls in real time and providing feedback and guidance on where to drive the conversation next. We had started this down the path of like the sales process, like how to improve the sales process. We actually flipped pretty quickly, uh, to more relationship building focus. So the AI, what we, what, what our sales team has is in the background when they're on calls. It is an AI that has done deep research and continuously has context around the individuals, family members' names that have been mentioned on previous calls, things like that, and it's suggesting relationship building moments throughout the call to build a tighter connection with the brand, um, since 50% of sales for those that you're in sales know that it's all about building trust in the relationship, the other 50% is actually like what value can you provide. And so, uh, we, we pushed away from the, the like telling a salesperson how to do their job better because everyone was like, screw you, I'm not gonna, uh, like I'm not gonna listen to that. I don't want that on my calls, but everyone, the mentality switched when it's like, no, OK, we know, we believe this person is a fan. I'm from Austin, uh, you know, a fan of UT. They just beat Oklahoma, they just beat A&M, right? now drop an Aggie joke, right, uh, type thing, right? So it actually is. Is providing these signals to help the sales people during the call think about building better relationship moments, right? Um, so that's been a really interesting use case, um, and complicated, right? Can you imagine processing real-time transcripts at scale to provide real-time recommendations in a call, um, pretty neat. Uh, other things here, but I'm gonna hand it off to, to Shri to kind of talk a little bit about the, the prospecting use case. Good, um, thanks, Mitty. So, uh, the good thing about this use case, this is a classic example of how AI can augment, uh, human productivity, right? So Spretail has a lean team of business development personnel and, uh, identifying which targets they need to go after. Um, that's very, um, important, right? So that's what this use case does. It's an internal facing web application. And if you look at uh the first stage, the key targets, so what um uh we're doing over here is um utilizing perplexity to identify the key contacts of the key customers, um, you know, uh, shortlisting them, and from there, what it does, it basically pulls up the detailed profile of the persona whom you want to target using LinkedIn, right? So that's step one, where you identify the key target. And the second step is where Um, you look at the various conversations as Smitti was mentioning like, uh, previous chat conversations which the retail business development personnel has had with the brand, right? That is one, data point. Then, um, there is HubSpot over here which is the CRM database which also has all the, uh, information which maybe one particular business development personnel had with the brand. Maybe it could be a net new business development personnel, but they need to know. The history, right? So that's where it is basically inputted into a retrieval augmented generation, um, and then what it does is it analyzes all of this and gives them, um, you know, insights, deep insights out of these conversations, right? And how it is helpful is it'll basically identify the strategic fit as to, you know, what are some talking points they can, you know, utilize to prepare for a meeting when they're going and talking to a customer. So a couple of challenges which we faced when implementing this use case was, um, say you're asking a question about, you know, what were some conversations or what is a strategic fit for this particular brand. So what was happening is there's a score which is generated and sometimes it was giving a score of 60. Sometimes it was giving a score of 75, so the output was kind of nondeterministic, as in every time you ask a question to generative AI it was giving a different answer. So in order to eradicate the challenges, a couple of approaches were taken. The first approach was utilizing Bedrock. Uh, knowledge-based metadata filtering wherein, as in when you're providing all these chat transcripts or or or you know, all the conversations you basically augment the metadata. For example, say I'm talking to an electronics manufacturer, update the metadata with, you know, that particular document with an electronics tag so that it knows that when you're asking a question, it pulls the right information, right? Um, and then Landgraf orchestrator, where that was helpful is to basically separate out the concerns, right? First of all, full, do all the data analysis in step one, and then build the next service to validate the data, uh, out of this data analysis, and then utilize AI on top of it, which led to deterministic, uh, um, results. So that was the approach which was taken to actually eradicate that. And the outcome, um, as Mitty was mentioning from a strategic fit standpoint was, you know, they get a detailed document when they're going for a meeting instead of like looking at, you know, HubSpot and understanding the information, spending hours and days, they get a very nice document with the chronological order of all the discussion. Points of the history which were happening with the brand along with that, um, you know, some 70 data points on you know what are other things you can discuss or the business development personnel can discuss with the brand anything you want to add? Yeah, I mean the one of the biggest uplifts in this particular use case was. We spend the executive team, right, uh, like the leadership team, so I'm CTO or, you know, CFO, etc. we have a responsibility as actually a desire to help influence our sales process. So like I have certain accounts that I will like jump in because we know that they're more tech forward or interested in, you know, what is our technology platform and so I jump into the sales process, uh, which is awesome for me because I don't have the sales metrics, but I get to like help be the, the closer, right? Uh, but, uh, coming into a deal, right, and you know, I have the ability to go understand. And get the context around the history. What is their, like, what are the key opportunities within the space, which is historically required someone, a BD person who's really, really good at keeping notes, right? in the CRM which for anybody that's looked inside of a CRM before, you know that that rarely happens. Um, so having the ability for me to query a system through natural language, uh, and get an understanding of like that brand. You know, within a couple of minutes before the call helps me kind of reset the context of like what it is and then you can even, you know, just like most LLMs ask like recommendations and, you know, provide some callouts, you know, uh, depending on how much context and, and everything that it actually has, those are more hit and miss, but getting up to speed, um, and, and working with an assistant, right, to, uh, think about the prospecting process, uh, has been helpful. So the last use case I'll talk about is actually uh one that fits a broader scaling mechanism of how does AI impact enterprise productivity at scale, right? And we've developed and actually we're in the process of patenting this and I've gotten clearance that, you know, this is actually gonna break down into a couple different patents, um, well what I'm calling the scaled innovation framework and so this is the concept of, uh, an end objective of turning everybody inside the organization, uh, to become an inventor. Uh, I've got engineers are expensive. I've only got so many on my team. We can only move so fast, and I don't like being a blocker to the rest of the organization. I don't like being a blocker to business value. And so, uh, the intent of this is to enable the use of AI to develop self-service tools along different innovation rhythms across the organization. Here I'm labeling it as core. We think of core as like a, a typical engineering team, right? A product team. Think of Edge as maybe like a business owned low code, no code technology enabled team, and think of self-service as as it sounds, we call them scouts, um, but like tech enabled individuals that have a knack for technology. Right. And in the past, what, what, when I've done this before, what you had to do was re-platform each time you are thinking about drawing, taking a valuable use case on the edge and centralizing it, right? So someone develops, you know, an Excel tool, uh, that is very valuable for the company, right, and then all of a sudden, you know, it's hit a scaling constraint. Right, uh, or risk constraint, and you say, OK, well we actually wanna turn that into something that works. Maybe if you do have an edge team, maybe they're, you know, they're in Power apps or, you know, whatever version of low code tech out there, they might take that Excel file, redevelop it right into something that's maybe a little bit more sustainable, not a, not a full scale technology platform, but something that's, you know, can actually serve the business need and then maybe when that hits its limitation, then you kind of redevelop it into a, an app. And so that's actually a model that I've deployed at a, at a couple different, uh, you know, organizations that I've worked with. And what's different now with the use of AI is you're having like vibe coding is a thing everyone's heard of that, right? Um, where people, the, the lines between, you know, developers and non-developers is thinning. Now you could speak to the efficacy of like depending on how much context and things like that, uh, how good are those applications from an underlying infrastructure perspective. But that's the problem to solve, right? How do we actually enable speed, right, at different layers of the organization with different requirements through this, you know, through the use of AI to where it's faster to enable folks on the edge, um, or the scouts to develop something that solves the problem that can plug into a centralized ecosystem, uh, very, very quickly, right? I think of it as like a service-driven architecture type concept, right? Uh, and what we've been building is this foundation. layer behind the scenes to where individuals that have access to kind of these prototyping platforms that we're developing don't know the underlying, don't need to know the underlying architecture, they don't need to know the security constraints, they don't need to know all these things that as a developer you look at when you go look at the underlying code base and you're like, whoa, this, this is a piece of crap, it doesn't account for these things. Well, that's not the individual's fault, right? They don't know any better. So how do you actually enable them to do that in a way where they don't have to think about it. But if you, if, if you want to, if that, there's a, we have a concept of virality, right? So we create a viral score over these tools where it's like, hey, it, a certain level of the organization is using it, maybe an exec is using this tool on a daily basis, has a different risk profile, right, a different value proposition, uh, compared to only two people that are maybe, you know, newer or younger in the organization, right? Uh, if there's a large number of people that are using a tool, right? So all these things go into the virality mechanism of a, of a tool, right? And so how do you use that and embed that at the back end so you can monitor what is actually being prototyped and used across the organization. Right? And then centralize when it makes sense because each of these layers have a different expectation of investment and return, right? A core team, it might take months, you know, to develop a full scaled, highly kind of sophisticated workflow application, right? That has all the bells and whistles that it needs, you'd expect that to last years, right? Maybe an edge team, you'd want that investment to be a little bit lower, but you have to also expect that that longevity is also lower, right? So maybe it takes a couple weeks to develop something and you'd expect that to maybe last months, right? And then the self-service, you're hoping that they can do something in a couple of days to solve their immediate problem, but you're not expecting that to last maybe more than a couple weeks, right? That's, those are just different innovation rhythms that we, we have to lean into. We have to as an as a technology. As technology leaders we have to enable that right? because there's so much business value left on the table by trying to say no you have to centralize this and there's only one way to innovate, right? And so this mechanism is how do we actually enable the development of these guidelines to move out across the organization. And then let that innovation happen in a market driven approach and using that virality score to determine where are those valuable prototypes that you can then centralize and scale, but they can be plugged in very, very quickly because on the back end it actually fits into your data architecture on the back end actually fits into your security profile and all those things that the, the end users never knew that it was actually, uh, that's how it was developed to begin with because they never think like that, right? Their focus is on value and so. Uh, there's a couple of complex components in here. Uh, we'll talk with the, I'll hand over to Shari to kind of talk about, but, uh, really interesting kind of capability for us as we look to drive the impact across the organization. Sure, thanks Mary. So, um, again, like, you know, um, how do we drive AI adoption across the enterprise? What really stands with this scaled innovation approaches a couple of things, right? The first one is IT teams are quite lean, um, and, uh, business always has. You know, some requests as to, hey, I want to do this use case or some other use case. But what stands out of this, um, approach or this architecture approach for enterprise AI is business users are empowered to experiment, um, you know, without like leaning, uh, heavily on the IT teams, right? And Once they see a potential value in a particular use case, then they can pass it over to the edge and the core teams who can actually productionize that use case, uh, right? To take an example, say, um, uh, you know, like, uh, Spretail had this, you know, like a business user who want to basically have 10 personnel and they want to allocate shifts to those 10 users. They could just upload a spreadsheet and ask generative, hey, how can I allocate, allocate these personnel into different shifts, right? Then taking it to the next level, uh, with the edge, they can integrate with, with, with other systems over here so that they can integrate with single sign-on, so that, you know, um, so that they can, you know, take it to the next level, used by 50 users or so, right? And then at the core team you can even make it more enterprise-wide adoption by integrating that uh thing with the payroll system so that you're basically managing the end to end uh workflow, right? So this approach, um, empowers the business users and also the agent core teams also know that whenever a use case comes to them, um, they're working on a use case which has potential business value, right? And now. How do we keep governance in all of this, right, uh, because, hey, we want them to, we, we want to give the power to the business users to experiment, but how do you keep the governance in the sense that, you know, how do you define those standards, right? So the first thing is that's where the retail way guidelines come into comes into play, where retail has defined uh spre forms which are guidelines for how the UI should look like. They've even come up with standards, uh, in the sense of API guidelines as to how I can. Make, uh, uh, you know, API calls, um, right, uh, similarly, they have developed a, uh, retail, uh, specific MCP server, um, right, where it has all the foundational kits and now the agent calling and all those things could happen, right? So that's how, uh, you know, the scale innovation framework works wherein, you know, uh, you have all these guardrails defined in the speed railway guidelines and the different sets of layers are actually, you know, innovating in their own respects, right? And from a techno technology tooling standpoint. The self-service team basically get uh hands-on experience with the chat interfaces and you know how they can ask questions with that. And with the edge team they can utilize the web web coding uh with natural language they can like develop applications and all that. And then in the core team is where the spec driven development, um, utilizing um Amazon Kiiro. Uh, wherein you know, you develop the requirements first, then come up with the design document and then create a productionized, uh, uh, application, right? So that's basically in a nutshell how this overall framework works. Thanks. And before moving on to our kind of like fireside Q&A portion, well, last thing to mention on this that has been an interesting evolution for us is when we've sat on this journey initially, uh, with this strategy. Uh, it was a kind of a separate team. It was like, hey, we need to stand up a strategic team that's focusing on, you know, uh, developing these capabilities. And what we found is it's actually just an evolution of DevOps, uh, in a new skin, right, of being able to enable developers, uh, to like execute faster it's just now that the scale and the scope of what DevOps is doing is a little bit larger so we've actually brought those teams back together and it's a single, it's our DevOps team that's actually owning this capability. And it's their strategic impact on the organization and where they can be felt across the org because it's extending beyond just the core development team, right, to enable them with AI assisted development and other things, but also supporting everybody within the organization with DevOps minded concepts that are meant to make it easier for the DevOps team to manage these, these products as they kind of come into the, the core. So that's been an interesting strategic shift that we've learned is, yeah, it's just a, it, I believe this is the next evolution of DevOps essentially. Right. Um, so yeah. So that, yeah, perfect. Well thanks. Tell us how, um, Josh, tell us how Spritto was able to deliver value quickly using AI. Yeah, I, I mentioned a little bit earlier about the, you know, luckily in the industry, you know, what we, the, the where I play that that was an advantage, right? But, uh, the key focus for us well it just goes back to the, to the business value aspects, right? Uh, you hear about, you know, how to do business cases and the like. Uh, the key thing for us was really oriented around mapping out the impact of the organization. Uh, it was really about what are the things that matter the most, how do we codify that into metrics, and then how do we make sure that there is extreme ownership of those metrics across the variety of teams, um, into something that, uh, I've, I've kind of called and labeled as like value causation trees. Right, um, and a, a value causation tree really is just a, uh, a level of metrics where it says, hey, here's leading indicators that lead up to management metrics that lead up into enterprise metrics, um, and we're able to allocate and assign those metrics to individuals to then be extreme owners and then just push them as an expectation of like you need to add more value quickly. Does AI help and you have the freedom and flexibility in the budget to accelerate however you seem possible with or with without AI, um, but it's giving people the, the freedom to explore and own kind of that journey for themselves that was super critical for us, um, and again it was maybe a little bit easier because you know the risk side to it. Uh, we, we, we're concerned about and we have controls around, but it's not the first question that comes up when we talk about pushing the needle at scale. Yeah, yeah, maybe dive deeper on that and share your mental model here that, that you and Spretto used for. For deciding where to start, yeah, uh, no, so this is a, this is a great example, right? This is a procurement example of that value causation tree or value ladder concept. Now, uh, the way that this is structured as a model across the organization, there's 3 layers like I mentioned that top layer, um, in, in procurement is, uh, purchase profit. So if you think about our business, it's how much profit are we making on a purchase of a brand's inventory. Right? And so that is the, the thing that if you imagine one more layer above in procurement has the biggest influence on free cash flow for the company. And every North Star for a company, right? If you go back to your finance classes, there's free cash flow, right? Uh, and so, uh, in this domain in procurement, we said, OK, well, free cash flow is the company North Star, right? What is the thing, what is the North Star for procurement that is the top most important metric, right? And so that was purchase profit. It's ultimate profit of the purchases we're making of the inventory, right, that we're procuring. Then there's a layer down, right? These are the kind of the management metrics that you think about, uh, in the organization who's responsible for, you know, uh, inventory return. So that's how, uh, how much inventory are you buying and how fast are you actually selling through that inventory. Right, uh, and then you wanna offset that with maybe some other metrics because it's just not, you don't wanna just not only buy one product and you sell through it really fast, right? But you're losing sales because you don't have enough, right? So you need kind of some offsetting that's, that's what effective loss sales is. It's like, well, how do you balance how fast we're turning through inventory and how much opportunity we're losing because we didn't buy enough, right? And then you wanna layer in a free cash flow, a cost component to it. Um, and so we still have kind of, even though free cash flow is kind of like the company North Star, we still have kind of free cash flow at the, at the underlying level too. But then the, the critical thing about that, um, is we look at that layer and say, All right, well, uh, if purchase profit is our North Star, what is our business expertise? What is our SME thought on the influence of these underlying metrics on that, uh, and the impact that that has on a 100% scale, right? I'm showing here 40% inventory importance, 40% effective loss sales importance, and 20% cash flow, uh, and the, the influence of those metrics on the, uh, the, the North Star metric, right? So that's a heuristic that we have in our mind to say, hey, if we're gonna go tackle a use case. We should probably go tackle use cases and inventory turn and effective loss sales within procurement, um, that have because that is likely to have the biggest impact, right? Um, and then you go one level deeper you get into kind of the leading indicators what are the things that on a day to day transaction level basis are actually drivers of those management those middle metrics, right? And then you break that down again. What is the percentage of importance? Again, this is heuristics. It takes less than 30 minutes to, to have a workshop and have somebody map this out. You don't need, uh, it would be nice to have the data to support this, right? And we've got certain areas where we'd actually have more causal inference models where this takes place, but it starts out with just get an SME's expert, like, you know, perspective, and that's helpful to then say, hey, all right, well what does our roadmap currently look like against that? You know, I guarantee you it's not gonna be one for one focusing on the most important things. Right, um, and so this is just a visual way that you can do for every process that you have across the organization assign ownership to, you know, some of these metrics within that domain and then ask the question, what are we doing to actually influence the most and what are the business cases that we're trying to drive to, to do that and that's, that's a, that's a framework that works regardless if this is AI or not, more of just business impact and then you ask the question, you layer the question. I was, OK, well how can, how does this change with AI in the fold, right? Like how could you accelerate that even faster. So we've got a use case identified. Now let's walk through how we march that to production from POC to production. Um, what you mentioned earlier some data challenges. What role did, you know, getting your data ready play in this? So this is interesting because with AI's use of data develop like it could generate new data, right? Uh, we. We're going down this path of, well, do we need clean data like uh the, the biggest blocker in like analytics is clean data, right? And so we started going down this path of can we actually use AI to close gaps that we have and actually not necessarily clean the data in some cases clean the data. But in other cases augment the data with more information than we currently had and can we use that to actually accelerate the development process? Can we try to use AI in the modeling components to generate data for us that actually sped up our ability to move fast because we didn't have the perfect data, um, but we didn't need it, right? And that worked in some cases. There's, there's definitely some cases where that works well. Um, the challenge that we that we had was in these AI models they need a strong semantic layer. Uh, so you need the ability to not just say, well, here's the underlying data, but you needed the data dictionary components, right, that are telling and giving context to the models as far as why this data is important, what goes into making it, you know, what are some of the, uh, the. Uh, gaps that might exist in the data, that's actually really important like listing the positive and negatives of in that data dictionary which traditional data dictionaries don't have, um, and so having that semantic layer, uh, is super important. So you basically have like a lookup table and the raw data table and that lookup table is the, the data dictionary and you're feeding both into now we do it with an MCP in the, in the past before MCPs became. Uh, available, we were, it was, we're dealing with like vectorized searches type capabilities and different like, uh, like temporary rag type models if you know what that is, uh, from for those technical folks in the room, and it just wasn't fitting as well and the accuracy of it, uh, we're, we're struggling with, but we're continuing to find ways to hack our way into it and then MCPs came out and we're like, oh shit, OK, that solves that problem. Uh, let's, let's go, uh, and then. So that was, uh, that was really helpful, right? Uh, and then another interesting thing on the data side that we tested that was. I wasn't expecting as a technology leader, I'll be honest, was that some of these models are better at understanding visual data, so graphical information compared to the raw data. I would have 100% told you before we did this test that the, the underlying AI models would be better at analyzing the raw data, right, than they would a snap, literally a snapshot of a dashboard, and that's actually not always true. Um, it, it has the ability to look at kind of the visual trends and the graphs and come up to some very interesting insights that it wouldn't otherwise have had had it been looking at the raw data. And so I encourage folks that are like using models to do data analysis to explore that concept as well, uh, because we were surprised at how performant it actually was, um. So we got the use case identified. Data is ready. This is a vast and rapidly evolving marketplace, you know, how talk to us about vendor selection, which tool, which vendor, which use case. Yeah, the, I think everyone's seen it. There's folks that come out of nowhere, they're like, oh, they're doing something really interesting, and then, you know, two months later a new technology came out that completely switches the paradigm. I kind of mentioned that earlier and that that vendor is no longer. You know, not necessarily around they built a business, but they're, you know, their approach isn't the best approach anymore, and they sometimes aren't fast enough. They've already steered the ship in a way where it's harder for them to flip. And so, uh, the thing that what we've leaned into is just identifying what the team is already using, right? Uh, our, uh, how we kind of just accelerated speed. It was less about we're gonna find the perfect fit tool it was more about I'm gonna go tell finance that if we really don't wanna move fast, I'm gonna go tell the board if we really wanna move fast, we're just gotta accelerate what people are using because I guarantee they're using what they are today. We just need to, and if it's a variety of different providers, let's just find ways to scale again, market driven approach to scale what we have and then, uh, basically optimize from there. Uh, sometimes when your speed is at the sacrifice of optimization. And so we're still on that scale where we're kind of like divergent thinking of just like adding value as much as we can and I'm working with finance to make sure the costs don't get too out of control, right? And then we're gonna figure out what works and then we're gonna consolidate from there and so um leaning into doing a scan and looking at what people are already using because I guarantee you. You got people using repl already. You've got some people on the edge that you've never even heard their names before that are developing little tools, um, because the, especially the, the younger generation like that excites them. They didn't go to school, but now they've got this opportunity to kind of invent, uh, and, uh, or they didn't go to school for engineering, classical engineering. They went to school, but, uh, but this ability is something that they're excited about and so you're seeing that adoption, um. One of the things that uh we. Also that I encourage is like try before you buy. A lot of these emerging AI companies are, you know, they're relatively young. Uh, they, they'll make claims to things. Everyone knows marketing is, you know, everyone, everything is being repositioned as AI first, uh, nowadays is, yeah, do whatever they will offer a trial thing if you just, if you make it a like a requirement, they might not say that up front, but you wanna test these models before because depending on their approach. Of how they actually solve the use cases, uh, you're, you need to see how, like how does it actually fit your use case because whether they use like semantic rags or MCPs or whatever it is kind of connecting the data in the background and. it so you can do like you can position the data right um based off of the search intent and the the query intent you need to make sure because they're all each method is a little bit different than how it supports uh the the end use case and make sure that it fits the one that you, you know. Great. Well, bring us home with some lessons learned. You, you, in working with you, you shared kind of two spheres of, of where to apply AI to the business. Walk us through that. Yeah, I, I think so. You're right. The way that we think about it is two concepts one, build with AI. And because if you think about development like, OK, well how does AI support your development, right? And so some lessons learned there is, uh, I think most people that have tried it, it's really easy to get to a prototype, really hard to scale, so that 1st 80%, much faster than it used to be, but then making that, you know, scalable, uh, you know, there's a, there's a gap that you gotta close there, um, the weekly paradigm shifts are now the norm for assets and development.kiro just announced some advanced, some really cool advancements at reinvent. Uh, that again cause us to internally think, all right, well how do we, how do we actually leverage this, right? And so the engineering shift, the engineering mindset shift, uh, has been one of the biggest hurdles that like we've been focusing on crossing and then, uh, yeah, the, the last bullet here, uh, we learned the hard way of, uh, the chat-based interfaces. It's really hard to get that right, um, and so as you're thinking about developing your own capabilities, what we found to be most effective. Is actually having a traditional UI that allows the person to go pare down the the portion of the problem that they're trying to solve and then you could turn it into a chat-based interview face or a summary with some Q&A capabilities, but starting with a blank slate of like, hey, here's a business development prospecting tool, you know, go at it. It's like, well, I don't know what to ask. Uh, I don't know like what can it do, and I asked the question and it doesn't fit what you've trained it to do and then now I think the whole thing doesn't work, right? So staying away from that as much as you can, at least for now, um, I think user experience is still getting into that paradigm shift where users are still better at, um, working through UIs and then leveraging, you know, AI at like at the, at the seed level like where, where after they've gone through the user journey is important. And then on the other side, this is like the developing AI itself and what are the lessons learned there. Um, the, yeah, if you've, it's the same way in breaking down a problem if you thought you've broken down the problem enough, continue breaking it down. Same thing with agents. Continue making them more and more specialized and having a specific role. Uh, if anyone's used like spec kits, uh, that are like open source spec kits for, uh, vibe coding and things, uh, they do a pretty decent job of this where, uh, you have basically individual specialists, you have orchestrator agents, uh, you. Have judge agents you've got a scorekeeper agent. You've got all these these all these like specialized agents that do a specific job and then you got an agent that creates new agents, uh, that are working together in tandem to then develop kind of an outcome. And so the same thing when you're kind of developing AI, you wanna continue to break the agents that you're that you have into the system down to a part where you know they have an individual expertise and their, their degree of variability is less. And then, um, yeah, I mean, the, the key thing is, uh, when you think about use cases, I always think about value creation over value automation. A lot of folks think of AI in the sense of we need to like, uh, we need to like reduce our SGNA costs and things like that. Uh, you actually achieve much more value by thinking about how, how much faster can you move bigger needles through the use of AI, um, will lead to better business outcomes, right? So that's kind of the, the key focus of how where to add value quickly. Great. Well, well done and congratulations. Um, thank you, Shree. Thank you, Josh. Thank you to all of you. Thank you. Enjoy the rest of your. I appreciate it. Enjoy, enjoy Vegas, and yeah, thank you guys for, for making the time.