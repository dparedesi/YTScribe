---
video_id: 8JQUek4V2uQ
video_url: https://www.youtube.com/watch?v=8JQUek4V2uQ
is_generated: False
is_translatable: True
summary: "This session, presented by Kinman Lamb from AWS and Ike Benyon from Vizier, addresses the problem of \"orphan data\"â€”scattered information across multiple systems that hinders effective decision-making, particularly in HR and workforce planning. Vizier, a leader in people analytics, demonstrates how they leverage the Model Context Protocol (MCP) to unify this siloed data and provide actionable insights directly to managers.\n\nIke explains that while generative AI is powerful, it requires context and tools to be productive. Vizier's solution involves an MCP server built on AWS (using ECR, EC2, ELB, and Route 53) that wraps their existing API layer. This allows AI agents (like Claude) to access Vizier's cleansed and standardized workforce data.\n\nA demo illustrates a manager using Claude connected to Vizier's MCP server to identify high-risk flight risks among top-performing engineers. The agent not only identifies the employees but also diagnoses the drivers of retention risk (e.g., compensation, career stagnation) and suggests specific actions, such as scheduling 1:1 meetings. This empowers managers with ad-hoc, data-driven insights that were previously difficult to obtain.\n\nLessons learned include the importance of observability (as agents often fail silently), the critical need for clear tool descriptions to guide agent behavior, and managing potential costs through rate limits. Looking forward, Vizier plans to enhance their MCP implementation by integrating their own specialized LLM to provide richer context and exploring ways to better visualize data within agent interactions."
keywords: Vizier, People Analytics, Model Context Protocol, MCP, HR Tech
---

Hello. Hi, my name's Kinman Lamb. I'm a senior senior solutions architect here at AWS. Um, welcome to ISV 319. No more, no more orphans. Bring your work and your people data to decisions with MCP. So you are tasked or you've been asked to form a new team of existing employees for a critical project. Great. Who's interested? Who has the capacity and the bandwidth? Who has the skills to ensure that this project is a success? Many managers and leaders make decisions without the full picture because data is scattered across multiple systems. That's the orphan data problem. And it's costing you the ability to make better decisions. Today, we're gonna learn about Vizier and how they leverage AWS Model context Protocol or MCP to unify siloed data and surface insights when you need them. Joining me is Ike. Benyon Ike Benyon is the VP of product management at Vizier. Ike has a rich history of product development, strategy, and go to market and is a recognized thought leader in the HR analytics space. He's contributed to the success of Cornerstone on Demand. Higher view and in structure. He's passionate about data and using it to make intelligent and equitable decisions, leading him to join Vizier. Vizier is a global leader in AI people analytics, workforce planning, and compensation allocation. Founded in 2010 by business intelligence pioneers, they're trusted by 60,000 customers in 75 countries. Vizier gives you the ability to understand the relationship between people and their work. How to boost productivity. And adopt a change quicker. Ike, I'll hand it off to you. Thank you, Kinman. Um, appreciate, uh, not only the introduction but also the help from AWS and making this MCP server that we're gonna talk about today a reality and to also Adam and Peter and Sonia, the others of the team appreciate a lot the support, um, and then also I have my dev counterpart, uh, Vincent Chu who of course without development this would not be a reality and so excited to have, uh, him as well too, uh, for this session and I will defer some of the questions over to him undoubtedly about MCP and enablement, um. But to start us off, uh, and, and from the great introduction, uh, by Kinman, um, I'm excited to introduce to you, um, sort of how we thought about this as a case study and also highlight a demo, uh, a use case of, uh, the power of artificial intelligence, the MCP server, and our tech stack together. Because it wasn't too long ago, um, 3 years, it's, it's hard to believe when our collective minds were blown at our first LLM experience, and we're living in a pretty remarkable time and businesses and people were immediately tantalized by the idea of not only can we put our pets into various costumes of various historical periods and timelines, but how can we also make this productive? How can we take the mundane day to day and automate it through an artificial intelligence? And just like any person that you would hire off the street, you can't just immediately set them to work. You have to give them the right information. You have to give them access to tools. You have to give them access to workflows to actually drive productivity. It's not enough to just be intelligent. And so that's where MCP comes in. That's where the natural inclination from wow, this is a powerful new technology that we can use to this is a thing that we need to now enable with specific context, tools and workflows. And so with that again in the session, excited to talk more about that with you today. So our general flow that we're gonna walk through um is is up here. We'll talk through the challenge of why this is key, the solution that we implemented to give you just a flavor, a perspective of how you might approach a similar uh implementation, and then seeing it in action. So we'll do a demo with you through Claude, uh, one of our favorites in using with our MCP. We'll talk about our lessons learned so that you can hopefully not trip over some of the same things that we have experienced and then lastly think about what it means for the future, how we're thinking about evolving our current implementation into new horizons of opportunity with MCP. So as Kinman did a great job of highlighting, there is a lot of disparate information in various places that could be useful in the decision making process. It's, it's contrived. It's very contrived to say, oh yeah, everyone believes that everything should be more data driven, but it doesn't happen as a reality of these three problems. First is that silo data across the ecosystem is a major issue still today after even. Decades of trying to consolidate it all into one place and this is a big opportunity of missed impact. The second is the time challenge is that a lot of pre-built processes have ingrained development of data for decisions, but for ad hoc, which is a lot of the decisions that are made every day with people, it's not there. It doesn't have that data available to help support managers and leaders, users in the time that they need that data. And then lastly, there's a struggle with data literacy itself, the data that's available, how to use that data, how to think about the definitions of different metrics and relationships across data, and it ultimately comes down to the challenge, the decider challenge of helping them to become more literate and capable with that data. And all of these three things, as you'll see through the presentation, have a big opportunity to be fixed in different enterprise implementations of MCP and agents, as you'll see through our presentation. So this is where Vizier enters with our MCP server and so as Kinman did a great job of of introducing, let me give you just a double click. So as you can see here in the bottom, we take data from various sources across enterprise ecosystems. So you're at HCM, ERPs, EDWs, and then we ingest it into our semantic layer to, or excuse me, our our data ingestion layer to help reconcile, cleanse that data, prepare it for use. We have a semantic layer that has thousands of metrics, concepts, dimensions that are ready to go for any organization to open up the box and start to use to answer questions across the entire employee life cycle. And then we have a caching and distribution layer because if you've ever done analytics, working on a huge database like that requires a lot of horsepower. It can mean delays in wanting that data and getting that data back, so we put a lot of effort into making sure it's speedy and then ultimately that's where we stack our MCP deployment on top of. Is using some of those APIs that are already existing from that caching and distribution layer. So to break down what exactly we we did with the help of AWS is this is basically like any other server that you'd be familiar with. We took the open source code, modified it for a specific use case, and then built a server using, of course, things like the Amazon Elastic container registry to manage our MCP server containers for release. And then those containers are deployed on EC 2. For each of our global regions and availability zones, and then we use Elastic Load Balancer, an auto scaling group to manage the EC2 instances as demand changes. And then finally, since we're a multi-tenant hierarchy, so each organization has their own environment, we use Route 53 to manage domain names and Amazon CloudWatch to observe to make sure that we're seeing the performance, the up time, things like that that we need from our servers for MCP. So let's actually look at what this looks like. So this is a recorded demo, mostly for the fact that, as you know, of using different agents, there's a lot of thinking time. And so for our benefit here of not watching an agent think, I cut out a lot of that but left everything else so that you can see the full experience. And again this is going to flow through to what we need to do in the future and lessons learned. And so I intentionally kept warts and all in just to give you that benefit. So let's imagine that I am an engineering team lead. And I had a very notable exit of somebody who's a high performer, so that's startling to me, of course, and I wanna make sure that we're keeping all the key performers that we need. So I go to Claude. I input my my prompt and then as you can see here Cloud has gone to Vizier's MCP server and it started to pick up tools and that's one of the notable things about MCP versus using an API is that MCP allows you to put additional context for what the tool is for and The agents should use it, which causes better behavior for many of the APIs that you might be thinking about, but then also makes it more stable over time so you can continue, continue to build against the MCP, improve your APIs without having to go back and reconfigure every integration that you have with agents across your ecosystem. So as you can see here, it's picking up different tools like searching or analytic objects, um, filtering down um those objects, things like that, and then, uh, getting down to the organizational level, and then a few minutes here we'll begin to see it spit out a um output. Of who are the top 5 employees that we have, what's the risk of exit across next year? And then ultimately it will start to feed into observations that are really critical and key of what can actually be done, but I want more. It's not enough for me to know. It's more important for me to know what to do as a result. So I go back and I ask for the drivers, what is actually causing these people to be at risk of exit according to Vizier's predictive model. And so now the agent goes back to work. It'll be a little quicker this time. It's taking those 5 high risk engineers and it's now going to look for those key drivers and then, um, as you can see here, still picking up tools, still thinking, and then it will start to return back the result. Now the thing that I haven't shown you here that I actually am really impressed with in the MCP open source protocol is that authentication for end users is actually pretty straightforward and easy. So we use and have implemented OAuth, and so you literally just authenticate like you would into Vizier every day, and then it hooks you up. You can choose which tools you can use. It gives you a description. It's really easy to manage even for end users, and so it's a really straightforward, easy protocol to use. Uh, at least for the, the end users you're trying to serve. And so as you can see here, it's ticking through those engagement risks. It's identifying career stagnation, and here comes back that result again. And it's showing you, OK, here's who is really at risk here. There are compensation issues, career stagnation, poor manager relationships, performance concerns, and so now I'm not just having a poke around in the dark trying to figure out what's the problem. Now I have something that I can really drive, and I can even, this is also one of my favorite parts, go ask for agendas. If you hook up your Google Calendar, you can have Claude set up your meetings for next week to say, hey, what's going to cause you to stay. And so it's a really powerful tool to help managers to again have a higher elevated literacy into what they can do with data. And so you can also imagine this and the real value proposition here that organizations have come to us with is they want to hook up MoveWorks with ServiceNow. They want to hook up Atlassian. They want to have all these other systems that have MCP servers so you can start to pull data from across the ecosystem into a single workflow, which is really powerful for a lot of use cases and making that data more usable. So lessons learned. So as you saw through that use case, we we wrapped APIs, which isn't an uncommon approach, but APIs were built for a specific use case, and this use case is fundamentally different in how agents approach those. And so the first thing is that one, depending on who you're. Users hire you for what they hire you for and how your APIs are configured, that's the first thing to know is you're probably going to have to do some work on giving additional tools through APIs, consolidating endpoints, dividing out different MCPs according to use cases to help make that, uh, use more straightforward. The second is that, uh, agents are not friendly and giving you back what went wrong. And so if you're thinking that you can go just find that within your typical interfaces, you're not going to. It's more helpful to have observability on the API side, so make sure that you have all the answers that you can to not only make sure that it's behaving as appropriate, but it's also delivering predictable, high quality results over time through the MCP server. The second tool descriptions matter a lot. Again, this is kind of the net new thing in my perspective of what makes MCP really interesting and uh the error you saw in that demo, you may have, may have seen it, kept warts and all, is because of a dependency between two APIs. And the best way to help that is to provide better instruction through the tool going forward, but it's also important to note that even as you improve and think about these instructions, if you have a multi-agent landscape, what we've observed is that agents pick up and use those tools differently inconsistently across all of those agent use cases. So be strategic in how not only you're implementing, but if you're serving customers, how they're implementing as well, and what to look for. Third is potential cost is a big consideration. So Vincent and I talked about this quite a bit about how to anticipate this and how to ensure that we're not incurring anything unnecessary in terms of new costs. And so what we did was more of a preventative measure is to mitigate until we could, uh, to mitigate with typical things like caps, rate limits, things like that, so that you didn't have an agent, for instance, that errored out and then caused performance issues on our servers. And so make sure that you're also considering that in advance because the only way to really see what the use case against these APIs are going to be is to do it and even still, as we've been working with enterprises, everyone's still sort of in the pilot phase. There's a lot of promise. There's a lot of valuable use cases, but in terms of actually going live, there's still a little bit of work to go on everybody's part. And then luckily we've been able to see a lot of really good uptake and feedback to drive us forward into the future. Which brings to what are we going to do next. And so first we're asking ourselves questions about how do we move towards other ways of widening out the return that we provide to agents because as you know they're very pinpointed and direct many times in what they're trying to get from your systems which may actually limit the value that the end user receives that would be different than if they were coming to your UI. And I think this is an inevitability of the future that we just need to be prepared for given the attitudes that many enterprises organizations have towards agents and MCP. So what we are thinking about is how do we take our own LLM that we've built that's really smart on our data, the context of our users, what they're asking for, what to ask them about to ensure that we're providing a wider value proposition back and so that the agent has the right context to provide a better story around the data that will help managers. The second question, as I mentioned, we are still seeing a lot of pilot use cases with our enterprise partners that we're working with our enterprise customers, so we're already asking the questions, trying to use our crystal ball to look into the future of how do we see a scaled use case world, how do we see both the number and diversity of customers and MCP serving a broader audience in true in the wild use cases. And lastly, what are the implications of using tools beyond even the ones that we've surfaced up already a part of our as part of our original API landscape to things like providing tools for visualization and other things alongside a simple query? What does that look like and how do users digest and put weight of authority against the output of an agent with those additional tools that we provided? So it's a really exciting opportunity and again one that we're really focused on not just providing a wrapper but also thinking about how do we create a new value proposition through MCP and the agents that our customers may use. So in conclusion, we are always eager, as you can tell, to work with others in trying to learn more about what this landscape and use case looks like. And so if that's you or if you'd like to learn and understand more about how to use data with your own teams, please visit us at vizier.com/demo. Or of course I'm happy to answer questions and my Kinman as well, as well as Vincent. Thank you so much for your time today. Thank you.