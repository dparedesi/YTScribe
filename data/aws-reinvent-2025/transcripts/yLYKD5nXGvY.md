---
video_id: yLYKD5nXGvY
video_url: https://www.youtube.com/watch?v=yLYKD5nXGvY
is_generated: False
is_translatable: True
---

Welcome to MAM 217. Technical deep dive. We're gonna talk about uh building composable AI agents. Uh, for partner solutions with AWS Transform. My name is Murtaza Chowdhury. I lead uh product management in the AWBS transform team. And uh I'm going to be joined by. Two esteemed colleagues, Alexi and Ravi. And uh later in the presentation, we'll also have a partner join us and show how they have worked with us to build composable agents. Here's the roadmap for today. We're going to talk about the journey with AWS transform and uh how we have uh started with. Several point solutions that we had at AWS, we combined them together to provide a centralized experience with consistency across the different migrations and then how we are extending forward to bring partners along with us so that there is one unified experience for customers. We're going to talk about the components that enable composability. Will cover use cases. We're also gonna touch upon uh best practices. That we recommend to our partners. And uh we have several demos in this, uh, in this session. Uh, so, and, and if you want to take pictures, please feel free. Here's we are where we are with ADBS transform. We made the service, uh, generally available in uh May of this year. If you're following the announcements that we had this week. The current state of the service is that uh we have several specialized agents for some of the key workloads that we have identified based on customer feedback which starts with uh migrating on premises data center workloads to the cloud. Which involves. Mapping the technical artifacts on premises to what it means in the cloud. Like identifying things like which applications, which workload should be grouped together, the servers, the applications, the databases. Figuring out the mapping between the networking topologies on premises and in the cloud. And that's what constitutes our migration agents for for VMware. Then we have modernization for mainframes. There are mainframes that have been uh built uh several decades ago, and customers have asked us to help them identify. Uh, what those applications do, comprehend those solutions, so we have capabilities like, uh, extracting business rules out of legacy mainframes, generating documents which help them understand what those applications do, and taking the step forward. In terms of modernizing them to modern languages and migrating them to the cloud. Then there are Microsoft Workloads, Windows. We started with uh .net workloads, .NET framework-based applications which are Windows bound, and customers asked us to provide them the ability to make them compatible with open source frameworks. So what we, where we started is helping with agentic experiences to convert .NET framework-based applications to .NET Core. Which can be run on Linux-based either VMs or containers. And this week we, we expanded that experience to become full stack. We included the SQL server modernization there so that when you are looking at Microsoft workloads as a whole. You can modernize not only the application but also the databases along with them. The 4th pillar that we have here that we announced this week is custom. AWS transform custom. We understand that the Variety that you have in workloads and your needs in terms of frameworks, applications, APIs. Uh, cannot be just handled with specialized agents. We, we want to provide you the ability so that you can scale based on your needs. So what we offer with AWBS Transform custom is a set of out of the box agents for use cases like, uh, Java upgrades, node upgrades, or Python upgrades. And in addition to that. You can build your own transformations using AWS transform custom by providing input output samples or documentation. And you can create them centrally. Provide them to the practitioners in your organization. And have them run that at scale. In addition to that, we revamped the entire experience. We have a new look and feel in the, in the user experience. So what I'm showing you here is a glimpse of the web application for ADBS Transform. We also have IDE-based plug-ins for use cases like uh .NET and Java. So what you see here, let me walk you through the information hierarchy here. To start with, we have workspaces. Think of them as the security boundary or a collaboration space where your teams can work together and you can assign different roles to your team members based on how your teams are structured. There can be administrators, there can be contributors, there can also be read only users. And within these workspaces, your practitioners can create different job types based on the capabilities that we talked about earlier. And uh you see there are 4 workspaces here, one for VMware, one for Windows, one for mainframe, and one for custom. You can, you can have them together as well if you have, if you want to have multiple job types in the same workspace or keep them separate depending on how your teams are structured and within workspace are jobs. That's where you can execute those transformations and how jobs work is that it. Assesses what your needs are. It assesses what your environments have and creates a job plan for you. And then goes and executes those steps in the job plans. And the job plans comprises of several task agents that we have in, uh, in fact, across all the specialized agents and custom transformation that we have here, there are dozens of task agents that come together to provide you this seamless unified experience. And then we have the chat experience. The entire experience can be led through chat where practitioners, you yourself can chat with the agents and the chat can recommend you next steps. Human supervision is an important aspect. Whenever there is something to be reviewed. The chat agent recommends and and take help takes help from you to take the next step. We also have artifacts here. Think of artifacts as the common place where your digital footprint of migration modernization are stored for your team members to work on it together. And you can manage collaborators there at a workspace level. We also have connectors. As you're migrating and modernizing your applications, you will need connectors based on where your workloads are either it is on premises or they're already running on the cloud, and the connectors both on the source side as well as on the destination side so you can manage all of that in the boundary of a workspace here. And an important aspect of all of this is that there is a continuous learning loop as you execute your migration and modernization jobs in that secure workspace, the agents learn from what your practitioners do and the next steps that it recommends is based on that learning that enriches over time. The more and more you use it. We have come a long way when we started, we ourselves at AWS had. Dozens of tools that were specialized for specific tasks like we had a separate tool for migration we had a bunch of tools for modernization for rearchitecting for mainframes so when we launched AWBS Transform we brought them all together and what you see in AWBS Transform now is a consolidation where all agents and task agents work together to provide you that seamless experience. And Uh, what we have now, uh, while we have a singular experience for execution of migration and modernization needs, we have partners, uh, which most customers leverage, and the partners have their own tools. So we still lack uh a single governance layer across the partner tooling and the tooling that have uh at AWS which which uh in many cases led to duplication and friction. So what we bring you here today with AWB's transform composability is taking a step further. To what we did with our tools now taking a step further to bring the partner tools and solutions together to have a centralized experience for the practitioners and the customers. So if you are a partner who is a migration or a modernization competency provider, you can integrate your tools, your agents, and your knowledge bases if you have specialized domain rich experiences on specialized industries, you can bring them together to build a cohesive experience in AWBS transform. How it works together is that there is AWS tooling, there is partner tooling, and then there is a personalized workflow which is customized based on what you want to provide your customers and the practitioners and the customers no longer have to go to multiple places. They see one seamless experience, one seamless job type, or an augmented knowledge base that they can execute centrally and bring down the time and effort to modernize and migrate. Where we have come here is from fragmented tooling to unified agents. Not only is this bringing together the experience, it is also providing a singular governance and security layer. And our approach to this is that we want to go innovate with partners. So if you are a partner you have a solution in mind you have a functionality in mind you have existing tooling or if you're already in a journey of building agents, please talk to us we are, we're going to work with you and co-innovate and bringing those together and providing a central experience to customers. And the benefits are both for partners as well as customers. So if you are a partner, you can differentiate yourself with your specialized IP and your domain knowledge and create that personalized and customized workflow and for customers it is faster migration and modernization. So here is what it looks like from a partner standpoint, you start by telling us what you want to build. You can reach out to us either via your partner development manager or partner SA. Or you are, if you're a partner, you're already familiar with Partner Central. We are starting an experience there where you can lodge a request on what you want to build with your with your business case and your solution and and how you want to differentiate yourself and then we build together and then you can publish the agents that you build with us. And you have the flexibility in how you publish those agents either within your own account or within your customer account or if you want to make it broadly available we also have the ability to integrate with AWB's marketplace and provide a SAS-based delivery from there. And from a customer standpoint, it's as simple as plug and play. Customers or practitioners if partners if you are also a GSI or an SI you can simply enable those published agents and put them to use. I'll show you what the customer experience looks like once the agents are published. So the starting of the AWBS transform experience is, is configuring and enabling it in the AWS console. So here we have a new experience called partner agents where any new agent that is collaboratively built by partners will be seen once it's published. And from a customer standpoint, It can simply be enabled. And once it's enabled, it starts showing up in the workspace. What you see here is uh a set of workspaces uh that you might have and once that agent is enabled it shows up as a job type. It also depends on what the use case is. If you, if you want to create a new job type, it'll show up there. If you're augmenting a knowledge base, it will, uh, personalize an existing job type. Or if you have another use case, you know, that'll, that'll be seen here as well. Now that you have seen at a high level how this thing will work, I want to invite on stage, uh, my colleague Ravi, who will talk about the components of it which makes this possible. Ravi Thank you Murtaza. Before we dive into the components, let's basically take a step back and look at what it means for you to integrate your tools and agents into AWS transform, because that's the basic thing that you need to do before you can take advantage of the composability components. So for that I'm going to start small, right? And here I, I've actually built a simple tool agent, right? This tool agent is similar to what tools you may have your source, right? Where this tool agent is helping with network file conversion, right? It is a, it follows a multi-step flow to be able to get its work done. It helps with converting the network files which are stored in an S3 bucket. It analyses them after downloading it, and then it verifies for the proper content, and then goes ahead and converts them and finally uploads it into another location in the same S3 bucket. You don't have to worry too much about the network file formats and everything like that because that's not the the focus of what I'm going to go for. You, the mechanics and the overall experience and outcome doesn't change whether it's a simple agent that I'm demonstrating here versus something that you have yourselves like from a tools and um agent's perspective. So let me kick start the. The agent here. So what I have here is a local development environment, right? And this is my agent. I'm just gonna start running it. And the agent is running through its paces, the tool agent, and you can actually see what it's doing. Let's pause here for a minute. Once it's completed, you can actually see all the text output in the terminal. As you can see here, it's very hard to follow what the agent actually did. There's no easy way for you to know what are the distinct phases that it actually went through for you to know whether it's performing properly or not. So now, let's go ahead and think about what you can do with AWS Transform. To do that, what I've taken, done is taken the same tool agent, right? Integrated with our AWS Transform package, right, which comes with base agent modules which allow you to easily integrate with the AWSS Transform primitives. So here, As we continue, you can actually see that I'm gonna start running the, the AWS transform enabled. To lesion. You'll quickly identify that now you have a listening capability added to the agent. This, this is enabled by default when you actually integrate with the base agent module capability that is provided with the AWSS transform. And it also leverages the AWS Trans SDK and the other capabilities that help you to integrate your tools and agents into AWS Transform. OK, now this is on my local development environment. If I want to really see how it actually looks in the web application, I'm gonna switch into the web application. I'm firing up a browser and I'm going to the, the URL which basically will take me to where the agent can actually be seen. This is the first time I'm running my browser, right? And so, uh, this agent, the browser connecting to it. So you'll actually see what's happening is that it says, OK, you cannot do it, right? And you first need to go ahead and make sure that you're properly authenticated. It's gonna throw me into the username password input mechanism, right, for the identity provider that I've been integrating here with. Once I give the credentials, it's happy with it and it's going to go ahead and redirect me back after signing me in, right into the actual page which corresponds to my agent's job. This is where it is, um, so I just want to reflect on something you're probably seen Mutasa slide show all the white background based theme. You, you'll see here that I'm actually showing a dark mode. Uh, it's your preference. You can choose whatever you want, right? We now have all the capabilities of being able to switch between the teams, right, seamlessly. I'm a dark mode person, so I like this, right? Um, so now let me go look at what's in the job plan, uh, pane that, that we typically talk about, right? Oh wait, there's nothing in here. Why is that so? So what happened here is that we basically kickstarted the initialization process of the agent locally, but we've not still given a command to it to be able to say. Started execution, right? So how do you do this? You do this by enabling the capability that comes built in, right, to be able to take JSON RPC or HTTP commands. Uh, and this is all documented in the guide, which is actually accompanying with the uh Airbliss transform integration package, OK? So, to avoid like long command lines, what I've done is basically created a small script, right, which allows me to just go ahead and, oh sorry, shoot. OK. Um, Apologies for the, the mix up here. Let me, let me show you the um. OK, I'll, I'll have to go through the demo, all from the beginning. Sorry about that. OK, while it's running through the paces, uh, I'll probably just go through and, and explain what it's gonna do, right? So, the first thing you, you, you do is you initialize your agent, right? The next thing you basically do is start running your agent. And for running your agent, you have to use JSON RPC or HTTP commands, right, which, which are basically documented as part of the, the package that you received in the documentation guide. And when you do that, then you can go back and see your agent in execution uh executing, right, in the web app itself. And um here it's actually going back again to the login page because I'm rerunning the demo for you. But pretty soon we'll get to the point where you'll be able to go ahead and see the agent in action. OK, we're back at the place where we started, right? The job has been initialized, but it's not been executing yet. So I'm gonna run my script, right, which basically allows me to go ahead and kickstart the JSON RPC command I talked about, right? And now I'm gonna switch back, right? Now I'm going to open back the. The job plan, right? The job plan is a place where you will be able to see what is the thing that the agent is gonna do, right? As you can see, it quickly populated it with what it's going to do. This is the plan of execution of what the agent is gonna do by itself, right? So you can crisply see what all the salient phases it's actually going to go through to be able to get this job done. So now as it keeps executing more and more, you'll actually start seeing that it'll go and complete one step at a time, as you can see here, just completed step one. Let's look into the artifacts, um, work logs, right? So here you have the work log which basically allows you to see the progress of the, the job as the agent is executing it, right, one at a time, um, and also you can refer back to it like what happened if you're not in front of your computer. So as the agent is running through, well, let's keep, uh, go back and we'll see that it's completing multiple steps, um, and again we'll go back into the work log and you'll see that it's, it's populating the work log entries. What it's actually helped you do is to be able to go ahead and say that I have a very crisp. Understanding of what my agent is actually doing, right? And if something goes wrong, I can go back and look at what went wrong. It was much harder for us if you think about the, the case we started with, right, where you have a terminal and you have all the log messages all interspersed. You could probably say, oh, I could probably go ahead and integrate it with some other tool and look at it, but it takes time, right? And, and effort to be able to do that with AWS Transform, you get all these, right, uh, in a very easy integration package. So, now that we've looked at some of the capabilities, let's go look at what all does AWS Transform help you with, OK? Security. Security is the underpinnings of AWS Transform. As you've seen, no one can easily connect to the agent without being authenticated. By integrating with AWS Transform, you enable your tools and agents to seamlessly integrate with the enterprise identity providers. Every action in A bliss transform needs to be authorized. And we all know how hard it is to be able to deal with credential life cycle management. Getting the credentials, refreshing them, renewing them at at the right interval, and also handling revocations is a critical but painful aspect of being able to manage connectivity. AWS transforms built-in capabilities offload this pain of your development, right? So that you can actually focus more on your business logic and not worry about all these other things that, that basically are painful, right? And you've actually seen some of the capabilities where you can look at what the agent has been performing and you can actually get audit trails. So Mutasa talked about AWS Transformed being built for collaboration in mind, right, by using the workspaces and the roles you can delegate job responsibility among your team members while approvals provide the critical oversight for very, very. Uh, large blast radius based actions, right? And by integrating with AWS Transform, you get to leverage a secure artifact storage which has data encryption at rest capabilities built in. It also allows you to take an optional customer manage key, right? By integrating with KMS which is uh uh Air key management service. And Your agents can Help you prevent and detect abuses, right? By leveraging the built-in capabilities from AWS Transform. We all know how painful it is to be able to impose this on our customers, so we don't want to do that. And so by integrating with AWS Transform, you get all these for very, very easy integration effort. The next aspect that we want to talk about. It's basically how you can actually seamlessly see the workflow from the agent being executed. You saw the job plan being orchestrated, right? And how easy it was to follow what the agent was doing. The job plan management or orchestration capabilities of AWBSS Transform span the entire life cycle of the agent, so it enables both single agent-based workflows for orchestration and also multi-agent orchestration flows. AWBS Transform helps your agent gain human to agent interactions by enabling the human in the loop or the Hitle pattern, which is the most common pattern for human to agent interaction, and also agent to agent interactions. So, once you're ready with building your agent, you've tested it, all this good stuff is done, right? You want to go ahead and deploy your agents. So how would you deploy agents? Normally is you, you probably accure uh uh acquire compute and then you have to provision them and you have to go ahead and, and plan for the capacity. Here this transform comes with built-in integration with Bedrock agent core runtime. This allows you to use the On-demand capabilities to be able to seamlessly scale your computer requirements. The optional autonomous mode. That you can enable can allow your agents to run without human intervention if your agents need that. The agents can also harden themselves against faults, right? And be resilient to failures by leveraging the checkpointing capabilities that AWS Transform provides you. And as you run your agents and production, one of the things you want to do is to be able to monitor how they're doing and also respond to events. AWS Transforms built-in integration capabilities help you get the appropriate logging, the tracing, and the metrics that you need to be able to monitor and put together like robust dashboards and set up alarms so that you can react to events. So thus far, what we've seen is how you can take your existing tools and agents and how you can integrate into Ali transform and light up your capabilities to become more enterprise friendly. So now let's look at how you can Use this to be able to build more. Complex composed workflows to be able to achieve larger transformation outcomes. So what, what does it actually mean to have a composed workflow? In the composed workflow, your tools and agents work seamlessly with other tools and agents, right? Both from AWS and from other partners to be able to achieve much more complex transformation outcomes that you can cannot achieve in yourselves, right, with just your tools and agents. So that's the advantage of having a composed workflow. So, the, the topic of my section is components. Now we're gonna dive into what are the different components that you can use to make this composition much more seamless. So as we talked about earlier, like we have the base agent modules that are shipped with the AWS transformation package, which allow you to seamlessly integrate with AWS transformation, transform capabilities, right? Like the, the work log, the artifacts store, the job plan plan management, and so on and so forth that we talked about. You can supercharge your agents with domain-specific knowledge that is very, very, very important for your businesses, right? By integrating with the built-in knowledge-based integration capability. And we talked about the Bedrock Agent core runtime integration, which allows you to deploy your agents in a secure VPC-based environment even with private networks. And finally, when you're ready to be able to have the agents consumed by other agents or be discoverable by other customers, you can actually use the agent registry mechanism that's provided for you through Airbliss transform. So, to get you quickly started right on the overall transformation flow, this is how it looks like. We started at step one, where we were at the dev build environment. We use the AWS strands agents and the agent core SDK and using the base agent modules to be able to light up the, the core capabilities of what it means to integrate with the ABS transform. We were able to test it on a local environment. And then once we are happy, the next step is basically to leverage Amazon's ECR capabilities to build an image which you can just go ahead and upload and into your own Ali account and run on Asian core runtime. And what this has allowed you to do is to be able to go test as if it's gonna run in production in your customer's account when it's deployed there. And to be able to make sure that you can interact with this agent, you need to go ahead and use the agent registry to make it discoverable. We talked about it earlier. Once you're Done with this, you're good, right? You can go ahead and use the chat capabilities that Mutaza talked about earlier to be able to interact with the agent or your other agents can seamlessly discover the capabilities of your agent and be able to do agent to agent interactions as well. So in a nutshell, this is what the overall agent building experience looks like. We started with the build capabilities where with Airbliss transforms, life cycle management like memory and the knowledge-based integration, everything, how you can build a very integrated and supercharged experience for your agents. We did some local testing, right, and we tested for correctness. The next step is automatically to be able to go ahead and deploy it for your customers use. As Murtaza mentioned again, right, you can use AWS Marketplace as one of the distribution channels to be able to get it out to your customers so that they can use it. And we also touched upon briefly on how you can operate and monitor your agents when they're deployed at scale. Now that we have talked about how you can take your agents and integrate into AWS and start building a composed workflow. Let's look at how we can do more in terms of what You can scale your development environment, experience, and also to be able to walk through some of the use cases that you can achieve that we've been able to achieve with partners for that, let me invite Alexi on stage. Thank you, Robbie. So when we started thinking about composability, a few questions popped up to our mind. Typically, can we do better with our agents? Can we enable more capability? Can they actually start to have their own kind of thinking if we provide them with more knowledge? Um, because it is true that us as human beings, the more knowledge we have, the more reasoning we can do. So that is one point that I would like to present to you today in the upcoming demonstration. Another element is assuming we want to be able to build more capable agents, how can we give you the capability to deploy your own agent and own knowledge bases in existing workflows and transform or build your own workflows with your own agent? Um, The third question that we ask ourselves is, can we actually drive business and technical transformation simultaneously, because when we do a migration, we do generally, we generally do it for a business reason. We are not migrating VMware or business intelligence reports or mainframe or .NET application just because we want to get rid of the technical debt. It's a reason, but there is always an expected business outcome, so we need the agent to be able to help us assess priority, risk, do wave planning, OK, so we want our agent and your agent to be able to develop those imaging capabilities. So that leads us to another question. If we consider that Egypt is a group of digital people, what makes a group smart? So usually, uh, when it comes to aging, people are going to say, well, they need tools, uh, they need knowledge bases, um, they need memory. But the reality is that if we look at how we manage teams, a group is smarter when people can communicate together, when they know how to share knowledge. So the use case I'm going to present to you is about, I would say, flexible reasoning. It's not based on a study graph. Agents are going to communicate directly one to each other, share information, and come up with conclusions and create new types of data that did not exist before. So they are developing emerging capability. So, in this use case, I'm an application manager in the financial industry. I'm owning a set of, of, I would say, um, banking applications. And I'm based in Europe, and unfortunately Europe released a new regulation this year, the Dora Act. So now, if you're operating in Europe, you must prove that you're managing your system properly in case of fatal outage. If a transaction goes well, you need to be able to notify your customers. Uh, so when I look at that, uh, my first reaction as an application owner is, well, how can I know that my system is built properly? How can I do that? And can I actually automatically detect if my application is compliant with that new regulation? If not, how can I remediate that? And I'm unfortunate because it happens to be a mainframe application, so it makes my life even more complex. So in this scenario, uh, I'm going to create a new agent, uh, the Dora agent here. Oops, sorry about that. Uh, I'm going to reuse an existing mainframe agent, the BR agent, which is extracting business holes from code, and I'm going to use Qiro, uh, for both building my gente system and for doing the remediation automatically. The way it works, BRA is going to extract business tools from the legacy source code. Um, I have created, and I'll show that to you in a moment, a knowledge base, uh, Dora knowledge base, which basically described the Dora act, uh, and I have created, uh, steering files for Qiro to actually explain how to create a proper architecture for transaction management or for managing uh customer accounts and, and similar examples. So I'll take you through the first demonstration, which is the building of that agent. So I am in Qiro. Uh, we have an MCP server that can guide you and automate the building of something we call base agent, which is basically what Ravi uh introduced you to. And in these examples, I'm just asking to Qiro, well, what is an adverse transform and what is a base agent? So, you can ask any question from within Qiro, and you can be guided step by step about what transform is, what are the capabilities that uh Ravi introduced you to. Um, so in that case, uh, it's saying, well, it's basically, uh, a foundation where you have different agents that can communicate one to each other, uh, they can interact, uh, you can deploy them to agent core, uh, and you have a registry of agents who have a marketplace-like experience, and it's based on something called base agent, which is basically, um, An improvement over the vanilla strands agent so that those agents know how to communicate together and make usage of the artifacts or the human in the loop that Ravi presented you with. So from there, I can interact with Kro and ask follow-up question, and I'm going to ask like what is a base agent, uh, what can I do with a base agent, and how do they interact? How can I equip a base agent with tools? Uh, so Kro is going to answer all those questions. I'm going to go through a few of them. Like typically at the moment, uh, I don't know if you can say it. But uh Kiro is giving more information about what base agents are, and basically we have two types of base agents. We have orchestrator base agent, and we have uh sub-agent. So the orchestrators are there to be able to do the reasoning part at scale, basically, while the sub-agents are most task specific, OK. And typically, uh, to declare uh a sub-agent, all you have to do is use a tool decorator from strength, uh, register the tools into the agent, and you're done. Everything that Ravi explained to you is, you don't have to worry about it, basically, because you're inheriting from the base agent. Uh, it is the same thing for an orchestrator. So, uh, in the next step, I'm going to ask Carro to implement an orchestrator, and I'm going to ask Ciro basically to explain how the messaging and communication happens between the various agents, right? So Ciro is generating an example for me at the moment. Um, and it generates an orchestrator and a few subagents, and basically it's going to explain with me, to me with a diagram, how the communication works over here. So if I'll do a pause for a moment here, we see that basically I have my, uh, I have two tools which are used in the orchestrator. One is basically a tool to contact the registry that we spoke before. Uh, which allows that agent to retrieve a list of sub agents and other orchestrators it is allowed to talk to, so you have control over the visibility of agents, uh, and the second tool which is going to be used is the send message, and basically you're allowing that agent to talk to other agents, and that's how you have control over your communication between the different agents and their capabilities. It is as simple as that. So moving on here, um, the diagram explains the same thing and how the messages are going to jump from one agent to uh or for in API and then be redirected to another agent based on the agent name. OK. Um, In order to save time, I'm going to uh go to the part where I'm actually asking, sorry about that, Kro to uh generate the entire system for me. If I can make it happen. OK. So I'll stay here for a moment. I'm sorry there's an issue. So tech I've been asking to Cairo to take the example I provided to to it and basically take me through the different steps to basically uh package the agent, create an SCR image, push the SRR image to agent core, register the agent, and Caro implemented the pipeline end to end for me. So I don't have to basically know how um those APIs works, uh and I can actually automate the making and deploying of an, of an agent. The 2nd demonstration. Is about the creation of the Dora agent. So basically, what I've been doing here is I have created three different sets of data. One is the translation of the Dora Act into um. Uh, YML file over here which describes each and every act, uh, their, uh, I would say main functional features and capability. Uh, it has been done automatically, uh, using an LLM and, and the Dora act itself. And from there, uh, I have described the Doro act per business domain and per feature. Once this has been done, uh, we create, uh, an equivalent knowledge base for the remediation. So it is a set of Kro steering files, uh, with a Yammer front matter, same, same trick, where we actually describe the features and capability that we want to be able to interact with or to develop with Qiro. And then we have a longer description of the remediation when we want to use Qiro for, I would say transforming the code that we currently have in our application. OK, that agent is completely generic. Uh, if you have different kind of knowledge into it, it will be able to automate the remediation of your application based on the additional rules. And now, I'm going to use that new door agent into a subset of the existing mainframe workflow. So I'm selecting, as we speak, as I speak, sorry, um, the cobalt files that I want to investigate in that application. Transform is going to extract the business rules. It's going then to let the Dora agent connect to the BRE agent. They are going to have a discussion together. And basically the Dora agent is going to get back to us with a list of recommendations, so it's doing similarity analysis between the Dora Act, which I put into a knowledge base, and the extracted business rule from the source code. So that allows us to do, I would say, a functional similarity detection. And here is the result that I'm having, uh, in this case, uh, where, um, the Dora agent detected 24 rules that are completely aligned with transaction management in the Dora Act and is recommending to modify 20 of those, OK, um. The detailed remediation are saved into the artifacts store and can be used by the by Qiro, but I'm getting a report in the chat which basically tells me which Dora regulation should be enforced in the application, and then in the next stage, I'm getting the list of business rules that I should actually enforce, and I'm getting a link to every Kiro steering file. That has been produced automatically by the agent to automate the transformation of the code from within Q. I'm going to So basically, um, the use case was developed based on the existing BR agent from mainframe, the code analysis agent from mainframe, and the new door agent. And then we push all of that to cure. We could have included more agents like the SMF agent to know, uh, I would say like the usage of those transactions on the real system and see their criticality and get more, I would say recommendation because maybe that transaction is highly critical or is used only once a year and I have more time to do my remediation. So the best practices when, when you're developing agent is you need to think about them as intelligent modules. So, you want to, they expose their capability as skills by using the two-layer character that we've seen previously, uh, so that they can negotiate how they are going to interact, uh, basically. Um, when they need to share data. You want to make sure that the way the data is saved in the artifacts store is known to the agent, so you can basically create the skills where they describe the schema of their data so that they know how to interact, or you may want to do like I just did, put the data into a knowledge base, because then the retriever is going to enable the agent to directly exchange data, OK. Um, I'm now inviting Muthanza to introduce us with the next use cases. Thank you, Alexei. Several partners have been working with us as design partners to build new capabilities. And one such capability is BI migration to Quick Suite. I'm going to invite Naveen on stage to talk about Wavi Data Solutions and how they have been working with us. Naveen. thing, yeah. Good afternoon, everyone. I'm Naveen Venettapati, uh, co-founder and managing partner at Bavial Data Solutions. Um, you know, we work with the enterprises to help modernize and build composable data platforms. And uh one of the ways we have taken this to a new level with the Transform is that we have combined our proprietary accelerators and the powerful orchestration layer AWS Transform brings. Um, we have combined these two to build specialized agents uh that can help our um AWS customers or um other AWS partners to be able to leverage the specialized, uh, uh, specialized agents to be able to drive the modernization at a. Incredibly high velocity and uh low lower labor arbitrage to be able to drive value to our customers very, very quickly as well. um one of the things that the AWS Transform gives us is the capability to not only build these specialized agents at a very fast paced way. But it also helps create a very, very flexible customer experience on a very simple, um, chat-like interface as well. Um, I invite my colleague Ananta to demonstrate our specialized agent and how we have built this on the AWS Transform, uh, platform. Thank you. Thank you. So, um, hello everyone. My name is Anantha Chopali. I'm chief architect for AWS, uh, practice within V Data Solutions, and, um, by partnering with AWS Transform team we have been able to, uh, take advantage of the platform's inbuilt capabilities where, uh, we can, we are now able to bring our solution which has high impacting and high value for our customers, uh, for quicker adoption by the customers. In this case, uh, a BI migration solution that helps customers migrate from their existing BI legacy platforms over to QuickSuite and specifically the Quicksite part of it. There are several advantages that we have seen working with AWS Transform team over the last several weeks where we have seen that we can actually accelerate innovation without the procurement delays. What I mean by that is that we are able to bring our solutions to the customers very quickly, uh, which is the customers would be able to adopt very fast. And without having to go through longer procurement delays, um, which could take several cycles and are, uh, requires heavy, uh, paperwork. So if you are a partner or a customer, you, you know what, what I mean by those, um, think about. Non-disclosure agreements, master service agreements, uh, statements of work, uh, and not to mention any change requests and so on. So all of those can be eliminated because the solution is now easily accessible in a self-service, uh, self-service manner. Another advantage that I would say is enhanced security posture. While Vivial as a premier consulting partner brings best in class solutions to our customers rooted with best practices and well architected framework, there are often concerns from customers about their data. So, uh, there are data concerns, uh, leaving their network and, uh, data, uh, security and privacy-related things. Not anymore. Uh, V Solution now runs on Bedrock agent core runtime, uh, which includes uh the security poster that's offered in built, as well as. Now customers can take advantage of running the agent core runtime 100% within their environment. So this means there is no need for additional risk assessments or infosec reviews because their data does not leave their network. So you know what this means. What happens to their data stays in their environment. And uh lastly, um, our offering is available through the very familiar marketplace uh deployment channel that, that means customers do not have to navigate through newer uh uh procurement uh channels. They are, they can get the access to the offering through Marketplace with the, with the same channels they are very familiar with. And uh the next advantage I would say is a rapid time to value. Uh, for POCs where customers can take advantage of doing quick POCs without having to think about the paperwork, and this actually helps them validate the product fit for their use cases before they can actually think about full-fledged migrations. And lastly, I would say this actually helps customers unlock better, faster, cost effective way and self-service path to ROI. What I mean by that is customers can actually do the entire BI platform assessment that typically takes several weeks to months, in a few minutes to hours, and once they have the exhaustive report, something that we will look at shortly as part of the demo. Uh, they can actually, uh, use that information to come up with an ROI, uh, which they can take for internal approvals, and, uh, all of this, once they are ready, they can either if they have the skill sets internally, they can use the self-service mechanism to migrate all of their reports and dashboards to Amazon Quick Suite or Quick Site. Alternatively, they can use the white glove consulting engagement by partnering with their existing SIs or GSIs or even reach out to V Data Solutions because we have done it several times over and over again. So with that context, let's take a look at the demo and in this particular case, before I Move on. We'll be looking at the Power BI analyzer, uh, where, uh, we, uh, we'll be first looking at the Power BI uh interface if you're familiar with that, the Power BI reports and the workspaces, and we would look at how we can use the guided self-service AWS transform approach where customers can. With the help of a natural language, uh, inter, interact with the transform platform and help analyze their entire BI platform. So with that, Um Like I said, uh, first we will look at the Power BI. Power BI workspace and workspace in Power BI is very similar to a folder in a quick site and in this case we have 3 reports in the Power BI. So one of them, uh, the first one is a low complexity dashboard, in which case there's 1 filter. There are a couple of different types of charts, and there are a few KPIs and metrics that we have. The second report is a high complex report, and the complexity is based on how many objects are used in creating those dashboards. And as you can see here, we have different types of charts from heat map to pie chart and bar charts, and there are some custom actions that once someone clicks on it, it actually does something specific. And lastly, uh, a very high complexity report where, uh, again, there are several, um, uh, different types of charts, uh, that customer has and think about this in, uh, the multitudes of hundreds of thousands of reports in an enterprise setup. So migrating one or two is easy, but when you want to do it at scale, uh, AWS Transform and vehicles offering BI migration offering would help. In this case, uh, the customer would navigate to, to the AWS transform, select the right offering for the Power BI analyzer, and create a job. What this does is it actually starts the agent core runtime within the customer's environment to set up the environment, and then, uh, you, you can actually start interacting with the transform platform where you would ask it to analyze your Power BI. Workspaces and um either you can actually provide new credentials or use connectors that's uh pre-set up to connect to your Power BI service and ask for uh all the Power BI workspaces that are available. Once you see all the Power BI workspaces, you can ask it to select a specific workspace that you want to focus and then you can either analyze one or all of the reports within that workspace. And as we can see, it actually does a quick check uh to the S3 because any intermediary log files and all the data gets stored in your S3 bucket. And while this actually connects and performs the activity of analyzing your Power BI workspaces, uh, it would, uh, it would go through and show all the details uh for you for complete transparency. And once you have all the details and the data is uploaded to S3. Uh, the, uh, it would actually generate and report in an Excel form, which actually is your complete analysis and inventory details that is ready for, uh, use to do any ROI or TCU analysis. In this case, this is an example, a report where you can see there are several tabs, and this particular tab shows all the calculated fields that were used in your reports and the formulas that were used, so you can easily translate that with a click of a button when you're converting them over to the quick site. Next, it also shows those types of charts that are not natively supported in Quicksight and automatically provides suggestion to the native supported Quicksight chart types. And once those are configured and you're OK with it, you can actually continue with the migration process of converting those dashboards. Lastly, it shows the confidence ratio of how much it actually thinks it can actually convert it automatically versus those case scenarios where it would require some manual intervention that may need to be looked at case by case. With that, I, uh, there are, I'll try to wrap up with two quick things. First, uh, with the help of AWS Transform and Vehicles offering, you can unlock insights to your business intelligence platform. Accelerate migration and do it faster, better, and cheaper. Lastly, we are available at our expo at booth 611. In case you have any questions or would like to have a, uh, a demo, please feel free to reach out. We are also available on Badata.com should you have any questions. Thank you. With that, I would reinvite Murusa. Thank you, Ananta. You saw how Wave Data Solutions is, uh, extending the migration capabilities of AWBS transform. And we are also working with other partners. Here's what Accenture is doing. For mainframe modernization where it typically targets uh regulated industries like uh financial services or health care or telcos. There are mainframes that were built several decades ago. And uh while migrating and modernizing those workloads, especially for the regulated segments, the practitioners typically have to consult domain and industry experts. So instead of having to talk to an expert separately while performing migration. What Accenture is uh doing with AWB's transform composability is that they're augmenting the knowledge bases that are available in ADBS Transform and making the chat even more powerful so that the practitioners instead of going and talking to. Domain and industry experts separately, they can do it directly within the mins transform interface via the chat experience. Additionally, They're also extending the components that are available in database transform like uh business rule extraction and catering them to what the industry specific migration needs have. Another partner who is co-innovating with us is Cap Gemini. Cap Gemini. Is another use case for simplifying mainframe modernizations. One of the key aspects of mainframe modernization is that many a times is it requires understanding of what the current applications and workloads are doing. Extract the business rules and then take a forward engineering approach. To create the application again. Reimagining it, keeping the business rules and business logic intact, and creating the entire architecture in a modernized form, that's where Cap Gemini is leveraging AWB's transform composability. Well, these were the design partners. We'd like to hear more and uh if you want to build with us on ADP's transform you can reach out via your partner development manager or partner SA or tell us what you want to build in Partner central. The link is available via the QR code here. Thank you so much uh for spending the time and attending this session.