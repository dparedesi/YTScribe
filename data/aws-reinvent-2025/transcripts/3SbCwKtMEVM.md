---
video_id: 3SbCwKtMEVM
video_url: https://www.youtube.com/watch?v=3SbCwKtMEVM
is_generated: False
is_translatable: True
summary: "In this session, Jeff Hunter, Field CTO at Ninja One, discusses the evolving role of AI in IT operations, specifically focusing on \"Autonomous Endpoint Management.\" Hunter highlights the challenges modern IT teams face—managing a sprawling landscape of remote devices with limited resources—and proposes AI as a solution to automate routine tasks while streamlining complex troubleshooting. He introduces Ninja One's approach to AI, which includes features like **Patch Intelligence** (using sentiment analysis to warn about problematic Windows updates) and a vision for **Agentic AI** that can autonomously resolve help desk tickets or pre-emptively remove bad patches from deployment queues.

However, Hunter strongly cautions against blind reliance on AI, citing risks where generative models might suggest catastrophic actions (e.g., formatting a drive to save space). He advocates for a \"human-in-the-loop\" philosophy, where AI serves as a conductor's baton rather than the musician, augmenting human judgment rather than replacing it. The talk outlines three key AI categories for IT: **Generative AI** for scripting and answers, **Agentic AI** for executing routine fixes, and **Predictive AI** for forecasting device health. Hunter concludes by urging organizations to implement rigorous guardrails and continuous training, ensuring IT staff are equipped to question and audit AI-driven decisions to maintain security and trust."
keywords:
  - Ninja One
  - Endpoint Management
  - Autonomous Endpoint Management
  - Patch Intelligence
  - Agentic AI
  - IT Operations
  - Human-in-the-loop
  - Predictive AI
  - One-touch Automation
  - IT Security
---

Let's get started with our first topic. Very interested if if folks aren't familiar with Ninja One, very cool software can help with IT operations for your organization so I'm excited uh for our next speaker Jeff Hunter talking a little bit about how to get it right as it pertains to leveraging AI and AI in the context of operations in a scalable format. So without further ado, Jeff. Thank you very much. Hello everyone. Uh, my name is Jeff Hunter. I'm the field CTO at a company called Ninja One. I'm always curious, uh, who has heard of us? So just a quick show of hands, who has heard of Ninja One, maybe knows what we do. Bonus points if you're an actual user. OK. Uh, Ninja One makes all the tools that you need to manage devices. IT teams need to manage devices. And so this could be to patch your devices, this could be to alert whenever there's some sort of issue, this could be to patch software, and it can be to remotely access uh devices via screen share so you can help solve problems in real time. And we do that across Windows, across Mac OS, across Linux, across iOS, iPad OS and Android devices. Uh, and having a platform to manage all of these devices is really important because businesses run on endpoints more now than they ever have at any point in modern history. We're all used to an endpoint that could be a typical laptop or a server, but they could also be manufacturing equipment in factories. They could be ticket kiosks. They could be the digital billboards that you see on the side of the road, and in my own personal experience, they are the movie theater projectors that we see movies on when we go to the cinema. And on average we're touching about 4 or more of these devices every day just as a part of our regular work lives. Uh, and these devices all need to be secured and they all need to be supported over the course of that device's life cycle. Now to compound this issue, the last 5 years have been the biggest, most seismic sea change in the IT industry ever. Overnight, organizations had to accommodate to people working remotely. Not working in an office, being all over geographic, different geographic locations, and it has been a slow journey to put the toothpaste back in the tube on that particular front. We still see a ton of hybrid and remote work persisting even more than 5 years after it first really begins in earnest in 2020. And as always seems to happen, this means IT teams have to do more with less, uh, so more users to support, and those users are also spread apart geographically in a way that they have not traditionally been, uh, and there are more devices to cover as well as those devices being of more varying types of devices, not kind of the traditional laptop and server that we're very familiar with. And this is all happening in an era with a ton of merger and acquisition activity, shifting compliances, different auditing standards, and those all need to be adhered to and accounted for. In my experience, it seems like IT teams almost have to massively overproduce in order to meet whatever their goals happen to be. Uh, I would compare it to trying to roast a marshmallow over the campfire, except you're 50 ft above the campfire. You have to produce an enormous amount of energy just to get a little bit of the heat to go to the right spot. Uh, now the solution for inefficiency is being more efficient, groundbreaking, I know. Uh, but really what we wanna do is, uh, bring that marshmallow a little closer to the fire. I promise I'll abandon that metaphor now, uh, but really we wanna take our more. Easy issues and we want to automate them entirely, we want to take our more difficult, time consuming, and multi-step troubleshooting processes, and we want to streamline them. We want to minimize the need for human involvement as much as possible. And so now we introduce AI into the equation. I have had conversations with thousands of IT teams over the past 5 years, and there are certain themes, you know, common needs, common questions that start to emerge as a part of. Those many conversations uh and one of the questions I think I've heard more than any other is what are you doing with AI now fundamentally what that question is asking is how are you taking this uh new and exciting technology what I view as fundamentally a new tool, and how are you applying that to the product's specific area of focus. Now in the early days of AI bursting into the mainstream, my question was, what would you feel comfortable putting in the hands of an AI? Because there's a ton of potential for applying AI-based systems and methodologies into endpoint management. Ninja One's very first foray into an AI feature was scraping public data from the internet on the sentiment about different Windows patches. Whenever somebody has a big uptick in complaints about a particular Windows KB, that's a sign that that patch is causing problems. So what we do is we summarize all of that data in a brief description right in the right in the menu where you actually approve those patches. So you have a quick and easy way to be able to tell is this patch going to cause more problems than it's actually able to solve. This is a great application of AI. We all know it's great at taking a massive amount of data, condensing it into an easy to digest snippet. But there's also the possibility of AI taking more direct action. Uh, now that's the ambition, that's the dream that AI is going to be able to perform autonomous endpoint management where you're able to have the first touch responding to an issue come from the AI or from the system that's been set up, and the first touch is not necessarily a human being who has to be directly involved. Now again, that's the ambition, that's the dream, but AI is of course a brand new technology, and with any new technology, quite honestly any technology period, there is a lot of risk. It's just that as that technology evolves, we tend to view the risk as more of a known quantity. Obviously an AI is only as good as the documentation that it's trained on, and if that documentation is wrong, if the information it's trained on is out of date, uh, if the data set is incomplete, the AI is going to draw the wrong conclusions, and then the human being who is using that AI is going to amplify those wrong conclusions and spread misinformation. Uh, in my experience, correcting that type of misinformation is really difficult. People latch onto their first impression, so what they hear first, it sets in their minds like concrete, and it can be very, very difficult to chisel it out. Now this type of risk, if we apply that to an endpoint management platform, I think we're magnifying the potential for undesired outcomes in a pretty substantial way. Uh, at a core level, this is a marriage of a very powerful tool which an endpoint management platform has to be by design, and the marriage of an AI that gives you the ability to make decisions very quickly. I would say we probably all agree in this room, it's a bad idea to make bad decisions quickly. That's the last thing that you want to do. Um, for example, there are other endpoint management tools that give you the capability to actually generate code, generate scripts inside of the platform. This can be really convenient, but think about deploying a script generated by an AI to all of your devices, and the AI decides that the shortest distance between A and B when it comes to freeing up additional disk space is just to delete stuff, just to run the format system drive command. It's about the the last thing we would want to have happen. And so when using any AI tool we have to ask ourselves not just one question but many questions. For example, is there a repeatable process in place to make sure that we're able to update the information that the AI is making decisions on on a regular basis? Going to my earlier example, the Ninja One patch intelligence AI feature, obviously when we're scraping for data on patches, that's going to fluctuate over time and so we need to be able to take that. Account that the sentiment might not be negative when the patch is first released, but as more data comes into the system, uh, we are more aware that the patch could be bad. Now we also need to plan for what is the worst case scenario that could arise from misuse or a bad implementation of AI. And as a part of that planning, we have to ask ourselves. What guardrails are in place to ensure that that does not happen and if something does happen that is undesired, uh, what is the how is that decision making process tracked? How do we know how we, how can we track an audit to know how we arrived at that particular decision so that adjustments can be made to prevent that in the future. I want to talk just briefly about a few categorizations of AI use in terms of how that's applied to endpoint management. I'm sure we're all very familiar with generative AI. Everyone here has used Co-Pilott, Gemini, Chachi BT at one point or another. We've all asked it to do something. We've all asked it, uh, to, you know, answer a question of some sort. Now flipping the switch, we have agentic AI. So this is then taking action, uh, performing actions, performing a routine task, ideally without the involvement of a human being. For example, maybe a ticket comes into a help desk and the ticket is recognized as a common problem with a known solution. If we automatically apply that solution to the problem to the ticket, uh, as a first step before we actually escalate to a human technician, that is a great way to streamline and save time as a part of the help desk process. However, the danger becomes a lack of adequate guardrails around the action that you're taking. Uh, in my example, I mentioned applying a known solution to a problem, and I say a known solution because the danger of an. Ad hoc generated on the spot AI based solution is pretty great. Uh, when you do that, you could be exacerbating the problem more than you're actually solving it. Uh, I don't know if anybody's ever tried to ask an LLM the same question multiple times. You often sometimes get five similar answers, maybe a little similar. You might get 5 answers that are really different, but it's pretty rare to get the exact same identical answer every single time you ask that question. I don't think anybody's getting 5 out of 5 on that. And that's of course because that answer is being, you know, generated in real time. and then on the predictive AI front, uh, this is obviously taking a massive amount of data in and then giving us insight into what the future health of the device looks like and helping us prevent future problems from occurring. And so in action we see this uh in terms of uh taking a ticket summarizing the ticket that uh that we were seeing there and then potentially even producing a potential answer to that ticket. uh, in Ninja one we see this with our AI assistant it's called Katana because we do everything ninja themed, uh, and so that is uh an AI assistant that we have that's in a beta right now. Uh, we also see it in the form of that patch intelligence AI feature that I mentioned earlier, uh, which is surfacing data about patches when there's problems so that you know about it. But then we take it a step further in terms of more of an agentic AI approach to. Where we're actually taking those patches that have negative sentiment and we're removing them from the deployment queue. So they're actually not going to even deploy those patches, it's going to reserve it so that a human being can look at it and decide if this is actually applicable to my devices or not. And then of course we can predict what is going to happen to devices in the future based off of historical trends. And so we have we're working towards a world where we can track historical data for CPU for RAM, measure the digital user's experience on the endpoint, and then give a stop light system. So green, everything is good. Yellow, maybe everything is not so good on the device and then red, the digital user experience is severely degraded, that gives us insight into how all of our end users are being impacted by the performance of their devices. Now there is certainly a narrative around AI that I've heard a lot of, uh, which is that it is about replacing people. Uh, of course there's always the extent to which that's going to be true in certain jobs and in certain industries, but I would also say that a true replacement of a sizable chunk of the workforce is against historical trends. The industrial revolution was a long time ago. There's been a lot of invention since the cotton gin, and we all still have jobs, you know, we're just not farmers. Uh, the the invention of the assembly line that may have looked at the time like that was going to be a process that eliminated the need for people to be involved in things like manufacturing cars and different goods. I think we now know that that is not necessarily the case. Uh, so, at Ninja One we definitely recognize the tremendous power of AI-based tools, but we also strongly believe that the value of those tools comes from being tied to the human beings who are actually going to be using them. Uh, because if we look at the different categorizations of AI that we've discussed, what we end up with is the potential for a really powerful automation engine. Again, where that first touch is not going to be a human being being involved, it's going to be trying all the attempted solutions, the, the possible solutions that we view as safe, uh, and seeing if that fixes the issue before we then elevate to a human being, uh, and the goal is to help scale with business growth. The goal is to improve the device footprint, the number of devices that a technician can effectively manage. But human beings are fundamentally an intrinsic part of endpoint management, even as automation and AI uh might change the day to day duties for those who are working on the help desk. And so in this context we need AI to be a reliable tool. When somebody picks up that tool, we need it to work. Not every AI is created equal and not every AI is going to be equally adept at your real world workflows. If you give somebody a Phillips head screwdriver when they need a flathead, you're pretty close, but it's still not quite right. And in the same light using a generic LLM is not likely to give you the good experience that you are going to get from something that's purpose built for the specific specific area of focus that we're working in in that given moment. Uh, quite honestly, people don't don't use tools that they don't trust, and in the very least they tend not to use those tools very well. Uh, and so it's important to know how did an AI come to a particular decision or outcome. The air handling of an AI, its auditability, its trackability, I view that as just as important as the overall capability of what an AI is able to accomplish. Without that risk mitigation and without that transparency, there is not going to be any trust between the human who is using that tool and the tool. At the end of the day, a human being is always going to be the one who's on the hook for a decision that is made by some sort of AI-based tool. At the heart of AI success, long-term AI success, I think that's built at the intersection of this new emerging technology and the human beings who are going to be using it. A key part of adoption of any new technology is the humans who use it. If you give me a saw, if you give my dad a saw and you ask us to build a table, his is going to be better. He is better at that, uh, type of tool making. It's always important to remember there's a human being at the other end of software and so consistent refresher training as this new technology continues to develop, this is uh paramount for critical ongoing, it's critical to ongoing success. And so as AI becomes more integrated into IT workflows, into endpoint management workflows, organizations have to be proactive in preparing the people who are going to be using those tools to not only use them effectively but to oversee them and manage those tools effectively. There is a human layer that is necessary there to understand, to interpret, and to question AI driven outputs so that we can use these systems not just efficiently but also safely. Uh, I think we envision a world where endpoint management becomes less in terms of human skill set, uh, you know, to use another metaphor, it's not so much about playing the individual instruments of the orchestra, it's about conducting the entirety of the orchestra at large. And so IT staff need to be trained to understand where and how AI is being applied. They need to understand how to interpret AI outputs as well as question them. I would argue that the time to question them is always. Uh, because blind trust in AI decisions does lead to significant risk, uh, much in the same way that web designers use dark patterns to influence where our eyes are drawn and where we're most likely to click, in the same way that, uh, early versions of iOS, maybe before it was actually called iOS, had sort of a textured look to it, encouraging you to kind of interact with the screen. A lot of the times LLMs give you overwhelmingly positive responses to. Anodyne milk toast queries and suggestions, uh, and so questioning, uh, and that's all done of course to you know create this positive feeling in the actual user uh so that they come back and they want to use it more, which is not necessarily the goal that you might wanna have when managing endpoints and trying to improve business efficiency. Uh, and so given the quickly evolving AI landscape, uh, continuous skill development is critical, ongoing education, best practice groups, regular meetings for cross-functional knowledge sharing. I think having, uh, maybe a weekly or a monthly meeting where a portion of that is what is the best thing, best suggestion that you had from an interaction with AI, and then what is the worst thing that happened, the worst thing that an AI suggested to you this week or this month, and that helps level set, uh, that helps level set, uh, amongst, uh, the team. Uh, now, in conclusion, integrating new technology is really difficult. Uh, AI is new, it's exciting, it's having a momentous impact on how all of us work, but it's also having an impact on how our individual devices are managed. It's important to remember that tangible long-term benefits resulting from the integration of any technology are going to come come down to how we align human expertise. Sorry, I don't know why this is, I'm waving this around too much. I think it's a little too sensitive. And, so training should always emphasize the importance of a human being in the loop model, sorry, uh. Where AI is augmenting human knowledge and judgment, not substituting it and not replacing it. And so this is where Ninja one is headed autonomous endpoint management, lessening the need for human involvement for the most common and the most annoying tasks, freeing up those resources so you can work and think more strategically. Uh, taking a less experienced technician, allowing them to operate at a higher level and putting up those guard rails to prevent dangerous, uh, solutions, dangerous decisions from being implemented through the power of endpoint management. Uh, thank you everyone, uh, for being here. If you wanna chat a little bit more about this, come visit us at booth 1216 right over there. My name is Jeff Hunter, and, uh, thank you very much for being here. Take care.