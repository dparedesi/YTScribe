---
video_id: SF-fxd9fzpo
video_url: https://www.youtube.com/watch?v=SF-fxd9fzpo
is_generated: False
is_translatable: True
---

All right, hello everyone, uh, welcome and thank you for attending today's breakout session. My name is Laurie Knapp. I'm a principal product manager at Amazon AGI where we are building Amazon's, uh, one family of foundation models and services called Amazon Nova. 2025 has been called the year of agents. We're making a transition from models that can generate insights to models that can take action. But to make that transition we need models and systems that have a broader set of capabilities. In today's session we're going to talk a little bit about the evolution we're seeing with our customers going from these uh model outputs to agentic systems and we're gonna talk a little bit about the various foundation layers that make that transition possible. Then I'll go into a little bit deeper, uh, view on what types of capabilities you should look for when you're picking a model for an gentech workflow. Then my colleague Rob will talk a little bit about um Amazon Nova Act and specifically how it's designed to make browser forward agent workflows extremely reliable. Um, next section, Michael will cover multi-agent systems and how you can use things like strands, uh, and various different specialized models to, to enable more broad complex workflows. And then we'll wrap with some Q&A. So to start, uh. When we think about customers adopting Genna into the bus into their businesses, we typically see this clear evolution. They start with things like generative AI systems. These typically take the form of chatbots that might pull information from various, uh, internal systems. They're able to generate insights, uh, maybe be brainstorming partners, create reports. But they have a specific limitation. They aren't able to actually act within your systems. And that's where agents come in These are task oriented purpose built AIs that don't just provide insights, they actually complete work. They're really bridging that gap between intelligence and execution. Now as we see this continue to evolve we see it going towards these more multi-agent systems they'll be able to take on more complex tasks, coordinate, uh, delegate tasks, work towards a common goal together, but to get there, um, we need models, uh, and systems that have these capabilities that can allow them to complete end to end workflows reliably without human intervention. So to make uh this a little bit more concrete what this looks like, here's a few different examples of what it means to go from kind of answering questions to taking actions. Encoding, it's like going from explaining this error, what's going on with this code to actually generating a whole code artifact to then an agent that is able to write the code, run tests, and actually deploy fixes in your systems. In enterprise, we can take the example of a customer service uh use case. You might start with uh having a model that analyzes customer complaints, summarizes the the top issues that are going on, um, and pass that to a human for analysis. Um, to moving towards a chatbot that is able to interact with the customer, um, and provide that, uh, first line interface to then an agent that not only takes in the customer issue but it is able to look into your systems, understand your policies, uh, and specific frameworks, and then actually triage that issue and provide the customer a rev uh, a resolution. And consumer, it's going from what should I cook for dinner tonight to actually creating the shopping list to an agent finally that is able to order those groceries and they arrive at your door without your intervention. So now that we've talked about what agents can do, let's talk about what makes them work. We think about 3 primitive layers, uh, when we, when we think about building agents. The first are the agentic primitives. These are the building blocks that actually allow your agent to interact with the world. So you can think about things like tool orchestration, uh, capabilities, memory so that they can effectively manage context, uh, and observability capabilities so that you can monitor your agent performance and understand what the agent is doing. At Amazon we offer Bedrock Agent Corp which provides tools and systems to allow you to operate and deploy agents at scale in a secure fashion. The second key layer are the models themselves. Not all models are equally capable of agentic workflows. You need a model that is able to reason through, uh, complex tasks, break down a plan of action, and actually call tools reliably to, to complete work. Our Amazon Nova family, our latest models which we announced yesterday, are designed specifically for agentic workflows, and I'll talk a little bit more about that in, in a little bit. And then finally are the multi-agent frameworks. So as we get to more complex real world use cases, It's often not enough to have a single agent performing the end to end workflow. You need multiple specialized agents working together. Agentic frameworks like strands provide you the structured approach to enable this type of multi-agent interactions with things like uh built-in orchestration patterns. Now a lot of customers choose to mix and match across these layers and all of these options are mixed and matchable, um, but we also offer more end to end solutions. So Amazon Nova Act, it combines the primitives, the models, the tools together to provide you not only a simple developer experience but higher reliability. Rob will again get into that in a bit more detail later on. For now let's talk a little bit about the model piece. So as a quick intro, um, this is what we announced yesterday, 4 new Nova 2, foundational models. Uh, the 1st 2, Nova 2 Lite and Nova 2 Pro, are our multimodal understanding models. Uh, light is, you know, you can think of it as a workforce model. It's great for everyday production workloads, uh, where latency matters, cost matters, um, and you wanna scale use cases. Pro is a version of the model that's highly intelligent, so when you have more complex tasks, um, you would upgrade to something like Pro. Um, we also announced Omni, which is our first unified multimodal reasoning model, um, where you can take in any modality and output image and text. And then finally we have a Nova 2 Sonic, which is a speech to speech model. So as you're thinking about various, uh, gente applications, each of these models is designed for specific use cases, um, and you might wanna check it, check them out, you know, if you have a speech forward customer service agent, Nova 2 Sonic is great versus kind of these everyday workloads. Nova 2 Light is a great model. So now let's talk about the capabilities that we've thought about to make these models perform it for agenttic tests. So I think there's really 3 key things that an agent needs to be able to do. The first is calling tools. These are the capabilities that allow your agents to interact with your systems that could be querying a database, uh, it could be, uh, interacting with an API navigating the browser, um, executing code. Without tools, agents really cannot complete work in your systems. The second key thing is multi-step reasoning. So this is what allows a model to effectively break down a task, uh, understand, plan and approach, and adapt when things go wrong. And then finally is extended context. When we think about real world workflows, you often have a lot of data that you want the agent to be able to understand to actually complete the task. And so, uh, extended context allows the model to take in that data and really parse through and understand what's relevant in the moment. So to dive a little bit deeper into each of these capabilities. When we think about native tool use, um, the model needs to be able to do things like reliably select a tool at the right time for the right job. It needs to be able to, uh, pass through the right parameters to that tool so that it calls it effectively, and it needs to be able to understand the output it gets back from the tool and plan the next step. With Nova 2 we've designed it for fast and reliable tool calling. So it's able to properly generate uh the formatted parameters and call these things effectively um and those are common areas where other uh other models might trip up and break uh gentech workflows. We also um have enabled it to intelligently chain together tool calls so this could either be from um uh operating in sequence and we'll see an example of that in a little bit, um, or calling a tool in parallel to get multiple responses back to formulate the best answer. Our models also now come with built-in tools, so two in particular are, uh, code interpreter and web grounding. Code interpreter allows the model to write some code and then actually execute it to get a response back, and web grounding allows it to collect real-time information from the web, um, to better inform answers. So I wanna show an example of how easy it is to use a built-in tool with Nova, um, so you'll see on the top left is a tool config. All we need to do here is set a parameter that lets the model know it has access to this tool. So in this case we're letting it know it has access to Nova code interpreter. We don't need to write anything to to create the tool. We don't need to have a dedicated sandbox. We just let the model know it has access. So in this example we'll give it um a question about what is the square root of this very large number and you'll see what it does is it understands that in this case it would be helpful to be able to execute a piece of code to get the answer faster so it calls that tool, uh, it gets the response back and then it uses that response to inform its final output, letting us know the square root is also a large and complex number that I will not attempt to read. Um, but this, so it's as simple as just giving it that parameter and then it knows when to use that at, at the appropriate time. Now, not every question that we have is as simple as a square root. Um, when we think about complex workflows, uh, what really matters is the model's ability to break that down, understand all the different steps it needs to take to actually complete, um, a task, and this, uh, involves, you know, choosing the right tools in the right order. It involves adapting, um, so you know, sometimes it'll choose a tool, it's not the right tool. It needs to understand it didn't get the output it needs and go back and try again. And so this is where reasoning becomes really important. Our latest family of uh Nova models are reasoning models and what we've done is we've given you uh control over how much reasoning you let the model do for your use case so basically that allows you to uh choose the right performance and efficiency that you want for your use case. Um, you can choose between no reasoning, low, medium, or high reasoning depending on how complex that use case is. So I'll show two examples here of like when you might want to think about using low reasoning or no reasoning versus um maybe medium reasoning. Um, in this case, we have a chat application, latency matters a lot, so we want the um answers to be fast, uh, and typically it's gonna be more straightforward questions. um, so play the video and share what's going on here. So we're going to ask, uh, what did Andy Jesse say about AI developments in this shareholder letter. We've given it access to the two tools that we have, web search and code interpreter that are built in. It knows it it wants to search the web for this, so it uses the web, uh, the web grounding tool. It pulls from various sources, and then it provides a formulated answer here, and you'll see little citations where it's telling you where did they get specific information from. So very fast, uh, simple tool call that it's able to do without reasoning. In this next example we're gonna show um making a more complex change. So in this case we wanted to update the GitHub repo for our Nova 2 light model announcement um and so we gave it a workflow to understand the issues, understand where it needs to make uh changes, and actually make those code changes for us. So you'll see here it's gonna make about 15 to 20 tool calls. We won't show all of them here, uh, but we'll kinda walk through it, reading the issue, understanding what it needs to do and then calls a tool to add a comment about what its plan is to actually make the changes. It goes and searches for the files it needs to make the change. It makes the code updates in those, uh, files appropriately. It then creates the pull requests and it ends with another comment that says that I've completed the task we're ready for merge. So this is a much more complex problem, but it's able to kind of reason through step by step. It's going through the file logs it's trying to find the right file. It needs to make a change and it's really adapting to the environment as it goes. So the last key thing that's important when we think about uh agentic workflows is extended context. In your enterprise real world workflows, we often need to understand a lot of information. Um, this could be anything from processing long documents, understanding large code bases, or just understanding all those tool calls back to back and not losing track of where you are. What we're really excited about with our new Amazon Nova family of models is the longer context length, so up to 1 million tokens. And so this enables the agents to process things like uh up to 1000 lines of code. Documents that are 400 pages or even videos that are up to 90 minutes long. I think that's really exciting, um, in terms of enabling enterprises to actually pull their information and allow the model to to really act on it appropriately. So let's quickly share some of the relevant benchmarks that relate to these capabilities, um, for our latest models. Um, we'll talk about tool use, reasoning, and, um, information extraction from documents, so kind of correlating to those three capabilities we talked about, um, and what we're excited for is that both our light and pro models are performing really well across these, um, areas when you compare to key image competitors, um, so definitely, you know, worth, worth giving a try as you're thinking about your own gente workflows. But I think what's more important than even the benchmarks is what we hear from customers because these models, uh, you know, they, they can be great at benchmarks, uh, but if they don't perform for real world use cases it really doesn't matter. Um, here's an example from a customer, Trellix, uh, who was one of our early adopters of Nova 2 Light. Um, Trellits provides security solutions for organizations, so this is things like, uh, endpoint protection, uh, network detection, and, uh, threat response, and they had an issue where they get a lot of, uh, security alerts, and each one requires a human analyst to dig into their systems and kind of triage and understand, is this a genuine threat? And for low level alerts, their analysts don't have the time to do this work for every single one. And so what they did is they gave Nova a set of kind of pre-vetted expert rules, um, and they gave it access to their systems so that uh it can pull from, you know, their databases, their endpoints, um, their network logs and create a uh a full fledged report and ultimately what it's doing is giving a report and then a final assessment is this a genuine threat or not. And I think what's really exciting about what they've seen is really high reliability on tool calling so you'll see here they've seen no failures on tool calls, which is, I think a key core component of what makes an agent great. Um, they've seen a higher accuracy from Nova 2 Light on, uh, threat classification, and they've also seen much more in-depth analysis, um, so super exciting for these early results, and, uh, we're really excited for you all to try these out with your own agentic workflows and, um, see what, see what works best for you. So with that I am going to pass it off to Rob who is now gonna talk about the more integrated end to end solution uh with Nova Act. Awesome. Thanks, Laurie. So as Laurie pointed out, there's a lot of components that go into a powerful and flexible system, the model, the orchestration, the memory, the compute, and we found when working with customers that in addition to that flexibility and power, a number of use cases really need high reliability. And so we built Nova Act and I'll talk through what kind of drove that decision as well as where we found the biggest return. Here we go. Across the wide range of workflow automation, you can imagine a lot of different use cases. Things where you're calling tools or APIs that are fairly well structured that are producing code that are verifiable, the path to reliability is a little bit faster. You can quantifiably identify whenever there is, for example, a failed tool call or when there isn't. When you're doing something deterministic, it's a little bit easier to get to that high reliability that's needed for production workflows in the UI. It becomes a little bit more complex because you're doing a multitude of different steps to accomplish a single workflow and each of those may have a much wider range of possibilities. You can click anywhere on a screen. You can enter almost any value in a field. Now that doesn't seem like it's that much more complexity, but when you're doing 2030, 50, or 100 steps to complete a workflow in the UI, as we all do day to day in our SAS applications, you end up compounding the risk. And so reliability becomes a much more critical focus in getting one of these workflows. Uh To be a production scale. When thinking about what the key components are for workflow automation in the enterprise, we think of three things. The first is reliability, which I touched on, and we'll go into a deeper dive on. The other two are scale and control. Scale because in reality you can give a co-pilot to any one of the employees at your company, but you're just improving their productivity. That's completely different than a full system automation that can run at scale in parallel without anybody needing to oversee it. That's the power of true reliable automation that you can run, say, 1000 QA tests all at once. You can start running automation that people don't need to oversee directly. But as soon as you start taking away that observability and a co-pilot concept, now you need to figure out how to bring back in human reasoning. You need to be able to ensure that a person can exert judgment at the right time and place, so not only are they adding value, but you make sure that an agent is accomplishing the right task in the right way and you're not breaking it into smaller and smaller chunks that are just being handed back to the human. So ensuring that you have the right observability as well as what we call human in the loop, where you can pull a human in to exert judgment at the right time and hand back to an agent to complete the rest of the task. This is how you start building a very powerful system that can be really useful and drive ROI. So talking first about the reliability, going back to this concept of the UI versus more deterministic API calls and MCPs, most LLMs today out of the box don't have any understanding of UI elements. So a date drop down is the first time they've ever seen a date drop down in an image. That becomes very complex when you think about having to navigate UIs that we all take for granted, and I say that taking for granted when we all know there are very unintuitive UI's out there, despite the fact that we've had decades of experience seeing every permutation of the date drop down. So imagine doing this blind as an LLM that's never seen any of this before. So step one is looking for a model that has been introduced to these concepts. Nova Act does this. We do SFT where we provide examples, we human annotate, we basically add training data to the model so that it can understand natively where to look for a date drop down or a search box or a tab for navigation, the building blocks of understanding the UI. On top of that, The complexity becomes helping the agent learn the cause and effect. And so thinking about this from the agent standpoint, most LLMs that are powering these agents today are built on imitation learning. If anybody watched Swami's keynote, we'll cover some of the same concepts in a second. But imitation learning basically gives you an example from a human or from another system to replicate, and LLMs are very good at that. The problem is, as we all know, UI flows are not, uh, they're not a small subset of, uh, distribution. There's a wide range of things and any single step that goes the wrong way could lead you to a dead end that's very hard to get out of. And so understanding cause and effect of each action is critical for an agent to be both flexible and reliable. And so what we do is we train using reinforcement learning, and you can think of this as giving it a task to escape a maze. This could be booking a flight. That's the example that everybody loves and along the way we create these synthetic environments like these mazes that have rewards and penalties. And we let the agent run against these synthetic environments at scale, 10s of thousands of times to learn what was a good decision, what was a bad decision. Now you might think great, it learns how to get out of that maze, but when you start applying that to the UI it starts understanding patterns. Why would I go to a search field as opposed to look for tabs, right? We all know that there are certain sites that you go to the search because it's an amazing search experience. You also know what it looks like when you hit that search experience and your results do not work, so you immediately back out and start trying to navigate a set of files or tabs. The agent learns something similar and so it becomes much more generalizable and understandable when it tries to do the same thing in a new environment. And so we've done that at scale. We've built hundreds of gyms that simulate both public and enterprise environments. We then give them thousands of workflows. Those are tasks to accomplish across each of those environments and let them run. And that builds up this generalized knowledge of how to navigate and what the cause and effect is of making one choice versus another that on top of the understanding of each of these UI elements makes them very powerful and flexible to get work done in the same way that a person might when there is no MCP or API to call. And what you get at the end of this, whether it be our system or any other, is an agent that can navigate complex workflows in non-deterministic UIs. And do so reliably for us reliability doesn't mean that the first time out of the box the demo works flawlessly. What we really mean is once you've taught it through prompt tuning, context engineering and instructions, it does it every time because that's the same as what you'd expect from hiring an employee. You teach it how to navigate your systems you teach it the outcome that you're expecting, and then you expect it to do that work over and over, and that's how we've architected the Nova Act. Now in terms of use cases, we see 4 categories of capabilities that start to compose all of the common workflows in the enterprise. The first being form fill. This sounds simplistic, it's like, oh, I've got a web form, let me go fill out a survey. But in reality, most SAS tools today are a combination of data being entered into fields and buttons being clicked to forward a workflow. The same can be applied to an agent. So if you think of CRM ERP systems, actual forms to file uh with external parties, these are all core components of a strong agent. Search and extract, you think of as search, but in reality a lot of enterprise information is locked behind credentials and so if you can provide an agent that can act like an individual, it can start accessing information that would not be available otherwise. It's not public web, it's not behind an API, and nobody's gonna take the time and effort to wrap an MCP around a 1 or 2 time use. So this is the power of an agent that can go navigate, understand what it's looking at. If you think about deal diligence for an acquisition, you don't need to teach an agent how to navigate a deal room, you just tell it, go pull me the relevant information from the PDFs, and it logs in, pulls that information, and can retrieve it for you. A more complex version of that is a booking and checkout flow. I used the flight search example earlier, everybody loves that one. That's essentially a very complex version of form fill, navigation, sometimes search and extract and executing on the customer's behalf. In flows like that, we really like encouraging the use of the human in the loop to either verify payments, verify before checkout, um, answer questions about variations. This allows you to have a generic agent that can still do 80 or 90% of the work and only bring the value judgment to the human who's involved. So in that case you don't need to have an employee who's doing all the work, but maybe they just choose their seat because they've got preferences that you don't want to try to program. And the final one is QA. QA is very powerful because the way that we teach this model, it uses visual perception. So we're not looking at HTML in a typical unit test, we're actually looking to see what the customer would observe. And so you can start walking through the same concepts of checkout flows and booking and you can identify things like revenue leakage. We've got customers who have identified that the search function or the booking function in their customer facing UI has breakages. You can run these QA tests at scale all the time and be proactive about this because the agent is flexible. So at the end of this, what we've built with Nova Act in particular, we focused on both academic and real world stats. I keep coming back to this reliability because this is what we really think matters in the enterprise. This is what we hear from customers all the time that it doesn't matter if it worked the first time, it matters if it works every time. And so out of the box is not the goal, making it very easy to debug, deploy and configure, that's the goal. And then once you're confident that it's working. You should be confident that it works every time. So we're seeing with customers right now, our early design partners, over 90% reliability, meaning every time it runs, it is highly likely to succeed in its task. This is not availability of the system, this is accomplishing the goal. And on top of that, we've scored state of the art in common benchmarks for agent use, and we're very proud of that. But really the reliability is the one that we think is most important. And I'll give you an example here Uh, the PGA Tour. Was an early design partner who worked with us to manage a QA process. Their challenge is that when they have sponsors who are supposed to be displayed in certain contractual ways with each of their scoring sites for every event, 40 events 4 days a year, all year, they have to ensure that each of these elements is displayed on the page correctly and meets all of their SLAs. Seems simple, and it was. You had a human who unfortunately had to get up at 2 in the morning local time to go check this before the event started and then check multiple times throughout the day. This seems like a really simple task, but at the same time it had real revenue implications. This is the primary source of revenue. If they violated one of these covenants, they don't get paid. And so they were struggling to maintain their quality while scaling up their team and allowing them to focus on the fixes and be more proactive. They worked with Nova Act to automate this, and now they can run it with increased coverage, the same reliability, and they can focus all their time on fixing bugs and being more proactive towards other areas of the site. It's a real success case, and again the real value here is that reliability. They don't need to have a person getting up at 2 in the morning to check if the agent ran. They're just getting pinged if there's a problem. And that's the big step change. That's what we're really looking for. So these are small examples of uh workflows that are in the UI by themselves. I'm gonna hand over now to Michael who's gonna talk about how you can combine these systems into a multi-agent workflow to get even more power out of this. Thank you. Thank you, Rob. So, we've heard from Laurie about how to build agents using Nova with built-in tools, using an MCP server. We've heard from Rob about how to build reliable browser agents with, with Nova Act. I'm going to talk about how we bring that together with multi-agent. Now there are lots of different ways that you can build multiple agents. One offering that the AWS has is. The open source SDK called strands. Now this is built around model first and it's also model agnostic, so you don't have to use a Nova model, although I will say that we have spent a lot of time optimizing Nova to work well here. Um, and it doesn't even have to be a model from, from, from Bedrock. Uh, so it's really flexible, uh, and allows you to bring in different agents and different models to get the task done that you need. So, before I dive in too much, I want to set the context here of why multi-agent matters, why this is important, and why I recommend that you think about this framework for your use cases. So by a show of hands, how many people here have had to make. A call on hiring someone. How many people have had to build a team, whether it's on the playground or fantasy football. Just about everyone here I think has had to think about building a team and when you do that you're not looking to just build a team of point guards or a team of marketers or engineers, you need a mix of talents so that the team works together to get a common goal done. And that's the same sort of. Of Approach that multi-agent brings rather than using a large monolithic model that might be very capable, um, you break it down into multiple agents that can be multiple models tailored to each task and the research backs this up as well. Using multi-agent frameworks, improve outcomes in complex tasks by up to 70%. That's a big difference So let's dive into really what those benefits look like, and there's 3 main things that I'm going. To focus on. So first, specialization. Now this gets back to building the team, right? Um. There are so many different tasks that make up a workflow. You might need to generate code. You might need to generate. I An image, you might need to summarize a document. All of those things could be done by a larger model, but maybe not at the cost that you want or at the latency that you want, or even at the accuracy that you want. And so being able to apply a particular task to a model or an agent can help make major improvements. Um, the, the other area here that we announced just yes. Today, in addition to the Nova 2 models is Nova Forge. So Nova Forge is a way to deeply customize your models with your own data. And so this can be really effective for more niche use, use, use. Cases and then there's other ways as well to customize where you can fine tune a model, you can dis dis dis dis dis dis distill a larger model down to a a micro or light sized model, and this is really effective to get the mix of accuracy, cost and latency that you need for each task. So number 2, scalability and modularity. Think of this as like the microservices design. Um, I'm sure many of you have worked with that in a past life, um, but it really applies here as well. So when you need to add another component to the workflow, you can just add another agent. Rather than have to worry about completely rearchitecting or rewriting the prompt or having something else change that prompt that you spent weeks, maybe even months trying to optimize, you add this other agent into the workflow and you put, you put a dedicated prompt with that, you, you have dedicated tools with that. It's built to work as part of the broader system. And the same thing here applies if you want to upgrade a model. Um, you know, I mentioned we just, uh, uh, Laurie mentioned we just launched Nova 2. Nova 2 is much better than, than our Nova 1 models, and it's also backward. Compatible, so it's very easy to, as new models are launched. Swap them in where it makes sense. Again, much easier, less worry about having to rewrite prompts and, you know, have to, have to deal with that pain of trying to optimize something to work uh just right. And then 3rd is latency and efficiency. So there's two major points here. When you have a larger model, tasks have to be done sequentially, generally. So it's, I'm going to first um. You know, tackle task A, B, C, D, and so on, rather than looking at those tasks and where you can, executing on them in in parallel. This. This piece by itself will save you lots of time. And it also ties really well to the point about using models and agents that are tailored to that task. So you don't need to use a large model to summarize something. Uh, you're going to spend more money than you need, and it's going. To take longer than you need, you can use a smaller model like Nova Micro, and it's going to do quite well at simple tasks, but it's going to do it faster and using fewer tokens and at a lower cost than a larger model would. So both of these things. A parallel execution and being able to use the right model for the right task is going to vastly improve your latency and efficiency. So let's take a real world example here as well. Sumo Logic is a company that's really focused on trying to solve cyber threats for their customers. Now this is only getting harder and harder in today's world. There are more complex threats, and it seems like they're happening more and more often, so. Nova comes in To play here by helping to power their agents, they have a series of agents, part of their, their dojo. AI that is focused on security operations, so Nova does things like. Like coordinate triage between issues, uh, translate the natural language request into Sumo Logic's query language without, so you don't have to memorize the syntax, it will just work, um, trying to analyze data, bringing disparate threads together. All of these are separate dedicated agents that work together to accomplish this task of identifying the threat. And doing so as fast as possible, and the result of this is that with Nova, Sumo Logic has been able to reduce their their. Resolution time by 75%. That's a, that's a big difference when it really matters and there's the chaos of an unknown threat that's impacting your enterprise. So I want to leave you guys with some takeaways here as well. There's no doubt that the future is agentic. You hear this, this, this buzzword all the time now, agents, like what does it even really mean, like it's mostly about getting things done in the real world and doing so effectively. We talked about several different ways of building agents with Nova, from the built-in tools that come out of the box to bringing your own tools or MCP servers. We talked about building highly reliable and useful browser agents with Nova Act, and then we talked about bringing that together with multi-agent to improve latency, reduce cost, and lead to better outcomes. What, what, oops, what has really made me excited is how many customers are already building with Nova today, and many of these customers are building agents with Nova. It's great to hear the positive feedback and see the ways that Nova is helping customers solve these really challenging problems for their customers. It's one of the things that I enjoy most about my job. But I want to leave you with a call to action to try this out yourself. You know, we just launched these Nova 2 models, they're highly capable of using tools at building agents. Um, one of my favorite things that we just launched is this, um, uh, sort of builder playground. So Nova. Amazon.com. Slash Dev will will give you the opportunity to build an agent just you know using a very easy UI so it's a it's a little bit less intimidating than having to, you know, go to the API and, and, and, you know, build it out that way and then you can actually deploy these agents. See how they do Make changes to the prompts all using a very easy user interface and see how it works and then when you're ready, we'd love to have you guys actually building on on on Bedrock and and seeing how Nova models can help you accomplish your goals. Uh, so thank you very, very much. We'd love to take questions, uh, probably just right down here. Um, so we'll be around for a little bit longer if, if anyone wants to, uh, to chat with us. Thank you.