---
video_id: j5TOWVNJx50
video_url: https://www.youtube.com/watch?v=j5TOWVNJx50
is_generated: False
is_translatable: True
---

Good afternoon. I think it is good afternoon by a few seconds. If you're in the walkup queue, congrats on making it in. That was quite a line outside. Note to self for next year. Need a bigger room. Uh, my name is, uh, Jonathan Allen. I'm an executive in residence at Amazon Web Services. What on earth is an executive in residence? Uh, well, I've been with AWS, uh, over 8 years. Uh, before that, I was actually a customer. I spent 8 years at Capital One Bank. Uh, my final role was as a divisional Chief Technology Officer as Capital One moved everything into the cloud. I learned a lot of lessons, uh, running teams in cloud on that. And in the last 8.5 years, I and my colleague Stephen, who'll introduce himself a little bit later on, have spent time working. Uh, with over 1000 different customers, and of course, in the last year, in particular, last year in particular, uh, the big conversation for us in, in our executive engagements has been like, what is happening to our people? Because as a leader, which you all are, because you're in this room, as the senior leaders track, what is gonna happen and how we are learning to build these agentic systems is, is absolutely crucial. And certainly one of my biggest learnings being a CTO was, it is all about the people and where we're going on this journey. So let's get started. Um, it's no surprise, of course, for us that know the cloud. If cloud is peanut butter and uh bless you, strawberry jam is agile, then of course they go together. And of course AI is coming along to use and use this powerful mechanism to make this, this great sandwich, of course. And uh but there's a hell of a lot more to it than that. All of us in this room, I'm sure, have used large language models by this point in time. Uh and we're well aware of the uh the rise of the vibe coder. Uh, and certainly the biggest epiphany I, I, I, as I work with customers that are pre-cloud still, and those that are customers who are in the cloud, the biggest realization for those in the cloud is, oh my gosh. Like the large language models instantly can generate my cloud formation or my terraform script or however I want to instigate instigate my, my cloud setup. Uh, but I need to do this in a, in obviously a very disciplined, disciplined way. So let's go all in into Agentic, let's look at building our teams. And immediately sort of time out, this, this comes with a challenge. A huge challenge for us as leaders. And this is a mental model challenge, because certainly all of us, and especially those like myself that come from regulated businesses, such as banks or financial services industries, today, whether we like it or not, we have optimized, largely since the industrial revolution, if we're honest with ourselves, for determinism. We want a predictable output. And while agile and cloud have enabled a completely different way of working, largely when I was running agile teams building on cloud, we're aiming to meet a business outcome or a goal in what we're doing. This changes, this changes. And now we've got to deal with the fact that non-determinism in these agentic systems is a feature, not a bug. And the truth when I speak to executives like yourselves and other leaders, this is distinctly uncomfortable for us. Distinctly uncomfortable as we're managing this. And this is not that different from managing any of our folks that have really high agency. Those folks where you agree a goal with them, maybe at the start of the year, and you know they're gonna find that right path to get through it. And certainly we're used to moving ideally away from gates. To guard rails. So we've put our teams together and we've got this hopefully straight road. It's never a straight road as we know. But there are certain quality markers that we're looking to get through this, toll booths is the analogy. Through to these teams now, where we've got agentic systems. That have got memory requirements, short-term, long-term, context requirements. This is more akin, as I was kind of looking for the right mental model for this. It's like a river that busts its banks continually and reforms. How it's gonna do that is a very different shape. But if we're really honest with ourselves as leaders. If we're really honest with this. There's a quote here that I think is very poignant from one of the world's leading advertising executives who actually is really good at understanding how human psychology works, and he says most business is probabilistic, but if that everybody in business wants to prove and pretend it's deterministic, so every spreadsheet is in some way an act of pretense because it is past information which you pretend has wonderful predictive value. And we have been doing that. And we do know what high agency looks like. But as I know, As a CTO who was booked from 8:00 a.m. to 8:00 p.m. running from crisis to fire, because that's just the nature of the job. I am juggling a whole lot of balls in the air, from legal to scale, to ethics to control, to security and HR. Now I've got to deal with the emergence of agentic Systems and my executive team, who is very determined that we're going to get value as appropriate for our business outcome. So we look at the people. And those of you familiar with Professor Scott Galloway may have seen this quote. AI won't take your job. Somebody using AI will, which sounds great. And then you read this analogy. And I sure wouldn't want to be the horse. So how do we take control, both of ourselves as leaders, and to help our folks who have delivered these business outcomes to be aware of this journey on agentic. And one of the things that Stephen and I have been putting this presentation together is to focus actually on what is really going on in the world and to use the research, not just hyperbole. And those of you may have seen this report from MIT NADA. And this report, there's a link on the on the on the page coming up. Despite 30 to $40 billion in enterprise investment into Gen AI, this report uncovers a surprising result in that 95% of organizations are getting zero return. Now you can argue on sample size and and methods used to correlate that data. Um, we don't want to be in that 95%. We want to be in that 5%. So let's look even deeper at the data. Let's look at this report, and by the way, all of reports used or referenced in this presentation are 2025. There really is no point in this world using data that's older than that because its relevance, as we know, just changes continually. And this one's a really interesting one, which uh economic tasks are performed with AI? Evidence from millions of clawed conversations. I don't expect you to read that, of course, I've summarized it here into visually stimulating content for you that 37.2% from anthropic. Used for computer and mathematical tasks. No great surprise for those of us that have used it. 10.3%, arts and media, 7.9, office and administration, 9.3%, education and library, 6.5%, life, physical, social science, 5.9%, business and financial. Now, I do not extend, I do not expect to talk about the next detail, but I know and I've been asked, having already done this a couple of times, people want the next level of detail. So this is up there purely for you if you want to take a picture of it. So how does that translate into actually what's happening in the US jobs market, because that's where we have data. So we can see here, uh representation relative to the US economy. OK, farming, fishing and forestry, yeah, not really being disrupted, no great surprise there in the, in the atomic world. Legal and services was lower than I, I actually thought when I looked at this, and so on and so forth through to computer and mathematical for our industry. If you're coming here as a developer or a leader of developers or a CIO or a CTO or even a CEO, we have many attend reinvent, then yes, the disruption. And usage is profound. Certainly for me, who used to be a hands-on coder for 15 years, to be able to use Kero again to get back into coding without having to memorize all the individual syntax has been groundbreaking for me to actually produce business outcomes again. So when we look at this, that, yes, the disruption is real. And the next epiphany as I work with customers is this. Change versus run models don't make sense in a cloud world. And now the truth of the matter is, many people still have a change versus run. And what do I mean just for those that aren't quite with this metaphor, means I normally have a part of my business that is for change, typically in a projects context, and people are there to do that, and then I have a run, and then when something finishes in change, it moves over the fence to run. Now, largely, cloud has broken that model down completely. Agentic destroys the old model. Why does it change it? Because now we need observable systems. These changes, we need to be on top of what is going on. We need to be looking at the floor limits that are occurring. We need to understand the trust. We need the context area and engineering of these agentic systems. So the big mental model to think about is if you're still in a change versus run, it is not gonna work for you in an ergentic world. Customers are now organizing around business outcomes, specifically. So if you are really organized like this still, And I put this purely on the screen for how I see people organizing themselves who aren't on cloud yet, and have put into silos. I've operated in this model. What you actually see in this model, by the way, is a lot of escalation and matrix management of resources. And while it makes so much sense for us on one level to put skills into teams like this, I mean, I've, I've used to be a network engineer, I've done software engineering, I've I've worked in the client-server team, and I was in a siloed team before cloud, and after cloud that changes completely. So you've really got to challenge yourself that this model will not get you to that agentic world, because we're moving from that world of, you know, just in 24 months, 36 months, you know, going from autocomplete all the way to agents. And we're seeing that massive acceleration. Every 7 months, we're seeing at the moment the doubling of size of of execution path of an energetic system at the present time. So that brings us down around to 5 questions that we're gonna lean into in this in this presentation. And we're gonna lean into the first one. What tooling do I need for the teams? Now this is not a tooling presentation. But the two absolutely, which we're seeing out there, are addressing this problem. I don't know if you saw the little animation of the red eye on the Raven, by the way, took a little time to do that. Uh, proof of concept lasted 4 weeks, but you know what, hey, it worked on my laptop. Right, we need to like get away from that. If it works on your laptop, awesome. But production systems don't run on laptops. Production systems do take a team. And if you're on holiday, And it doesn't work, somebody needs to be around to support it. And I think Quiro, which you'll hear a lot about, of course at Reinvent, and I'm not deep diving into Quiro. But the epiphany for customers I've worked with that use this is that the drive to spec-driven development. Immediately gives discipline to the execution of how we're using these new systems to actually generate purposeful outcomes on the back end aligned to business outcomes that need reliability, that need to understand disaster recovery, that need to understand the element of determinism that we still strive for, that we do want our system to be online, we do want it to meet requirements that we've thought about. So Qiro has absolutely changed the game. And of course, I'm sure you've already heard about Agent Core. So Amazon Bedrock Agent Core. Everything you need for getting agents to production. The big thing, the big thing for my customers is that final model on the right-hand side, observability. What is going on? Because of course we're striving for that determinism, still, of course we are. It's a human nature that we want predictability. But we're dealing with a high agency system when we're building it. So that observability thing really coming through very clearly. So cool, I've got Kiro. So how do I structure my teams? Well, before we lean into that, again, another mental model that we're moving from builders to orchestrators. This is tough. I'm privileged to have worked in IT for 30 years. I started coding when I was 9 years old on a Commodore 64 in BASIC, for those of you that did that journey. Um, I was very used to being a builder, how to build software. We're now moving to a world with this tooling which we are orchestrators. And that's a tough mental shift. For our techies, that's really tough. Because, again, that fear of replacements drives through. But that Scott Galloway quote of, I actually want to be in control of this is something as leaders that we've got to really double down with our folks to say far better to lean into this. Not be a victim to change, but be in control of that change by being informed. And then people ask me, well, in the cloud and agile world, typically I've had this mental model that I've had different folks, whether they're, you know, finOs experts or software development engineers or security or data or cloud developer DevOps or folks that are focused in UX and UI which we've seen certainly since the rise of web apps and, and uh mobile apps. And then typically I've got this product management, maybe business analysts coming in at the side, and they're like, well how do I, how do I organize these? Well, typically, no great surprise, when I had teams like this, I would structure them as the business outcome needed. There was no massive strict formula to how many SDEs were in a team, or data engineers, or cloud engineers. It was as the business problem required. Although I did take the liberty to put security engineers outside of the team, because there's never enough security engineers to put one in every team, and typically they are a matrixed resource where you end up with a security engineer assigned to multiple teams to do app sec review. And typically, yes, most teams now do have a person in a business outcome team running cloud and Agile to focus on that. This isn't really massively changing for Agente. So when you, you know, you look at this as a leader going, I've got all these teams, how do they work on agentic systems? Hey, I've got Quiro, I can do spec-driven development. Well then you start going, hey, I can just have a small team now. I, I, I can just have maybe a product manager who might become a product strategist, a business analyst, maybe one or two software development engineers, and agentic software engineer seems to become a very emerging title for these folks. And then suddenly you hear things like, hold on, business analysis is now an agent, so actually design lead in this small team, hey, now I can, I can get to a market. And I'm here to say, hold on. Not quite so fast. Because those of us that are used to running production systems at scale. It takes more than this to run a team, and more than this for a team to be on call looking after agentic systems. And the really thing, the thing that when we look at production systems, it's really important that we actually think about 24/7 on call for these eugentic systems. Now right now I don't see anybody putting in charge banking systems with asset-based transactions with Agentic, but they're building agentic systems around that, in fraud, in customer service. In Mobile And there's a lot of value there, but you still need to support this. And that traditional on-call structure of human gets paid, human investigators, human fixes is changing right now. 2 AI agent gets alerted, AI investigates, proposes maybe an RCA, heavy language, and a human will then get involved. I, I have not yet witnessed a customer's passing over to fully allow that, but that is surely being challenged right now. And we are seeing phenomenal usage of AI on log analysis. So rapidly drawing logs in and helping the engineers hypothesize on what is going on. That's having a dramatic impact positively on meantime to problem finding. And this is also shown from our own usage inside Amazon, this sort of dramatic analysis improvement, detecting that signal to the noise and then allowing humans to make that decision. And of course, when you transpose that to maybe your P0 P1 matrix, I see most customers still doing this. We send leaders to The data. And this is the area where I see real focus. The Data not only remains an organizational challenge for most customers. But its importance increases exponentially in an ergentic world. This isn't just about having databases in your operational data store or your warehouse or your, you know, your data lake. Uh, it could be PDFs and typically is PDFs in my experience, it's still in people's heads. And the truth is, and, and don't feel bad about this in any way, a lot of customers still struggle even to create a unified data catalog in their business. And quick bit of advice, if you're on that journey, business owner, technical owner for every bit of data you've got is required. Put your data catalog back to the nomenclature you use every day is the parlance in your business, super, super important. But data engineers are where the real need is right now. Data engineers are becoming more important. And this is almost this critical missing layer I'm seeing. And when you look at the research, uh, the North American IT leaders report from IDC leaders reporting 55% difficulty finding data engineer roles. So you want to look Again, this is always true, by the way, in human history. When any general purpose technology gets to a position where we think it's going to displace jobs, it creates more jobs. And there's always this painful learning curve. But data engineers are required, you know, to build the pipelines, to manage those vector databases. Yes, of course, we're looking for self-managing vector database stores. S3 is a is a miracle service in my mind. But someone's still got to make sure that the context of that data. I was talking to a customer recently and they had 18,000 tables in their warehouse. Goodness knows the actual line detail, the column, the table detail of all of those. But somebody needs to know what that value is and what it relates to. And by the way, typically, humans have done a really poor job of labeling those because the context of that data changes massively. So we still need humans to work alongside these agents to help understand that data. And then there's another paper, which is really interesting. For me, and small language models are the future of agentic AI. Um, interesting, this one from Nvidia. And I do see this playing out. So large language models are incredibly sophisticated. We've all used them But when you're building an agentic system, Actually, there's tremendous use in having a small model. One of the customers I've worked with actually built a 20,000 parameter. Now we're used to talking about trillions of parameters now with these large language models, but a 20,000 parameter model to do something reasonably predictable for them that they've trained in Sagemker AI. It was so efficient they could run it on a CPU, not a GPU. And it did what they wanted it to do. And I, this is the rise that we're seeing in customers. So you're going to use a combination of what agents are created appropriately for you to solve a business outcome. So actually the real challenge for most customers is still a lot of locked-in legacy systems. Complex ETL transformations. I mean, when I'm speaking to most of the really big FSI institutions, they have ETLs or extract, transformer load jobs in the hundreds of thousands. And typically, whatever product they're using to release their ETLs, that, that team is normally a bottleneck team in their mind. So actually when you look at urgentic and what's going on, this focus on data is still very legitimate. Again, a lot of the data is still stored in incompatible formats, subject to data governance. Um, spoiler alert, we don't like sharing data, by the way, very easily. Like, heaven forbid somebody gets to my data and finds something useful in my data that I didn't know about. So again, we've got to deal with that in organizations of how do we get over that? How do we set up, and, and yes, a lot of the principles in Data Mesh, huge fan. Uh, of the approach from the author who originally came out of ThoughtWorks and proposed that, because a lot of it doesn't care about the technology, it cares on the human nature of sharing that data, but still understanding the governance of that data. And of course, we don't want to create duplicate copies of that data, it needs quality monitoring, and this is where the challenge still lies. So a lot of times when people are putting together these production agentic systems, data scientists, understanding how do I create that small, if necessary, 20,000 model to solve a task. Might just be a calculator that you want, that does a particular uh calculation that you want to be done over and over and over without invoking a really large LLM each time, because of course that's a hell of a lot cheaper for you to invoke that. You know, millions of times than a a large LLM. Data engineers have always mentioned getting that data from A to B, breaking down those human silos, understanding how we release it, absolutely required data analysts. A lot of people say data analysts have gone away. Not really. Because context. And the rise of context engineering, super important in ergentic systems. Super important. And again, while LLMs can help us with this, we need the humans to truly understand who owns that data, what's going on with it, these 18,000 systems, 18,000 tables. And, and again, a lot of customers are still struggling with ETL. So when you think about building your systems to solve that business outcome, data. Remains crucial. Crucial, and that's why for now for a number of years at Amazon, we've been focusing and investing heavily on this zero ETL approach that's helping you get away from the ETL longest pole in the tent. A customer used it for me the other day, which I thought was very poignant. Longest pole in the tent, because it's always the slowest thing. It doesn't matter how much resource that they seem to put at it. So moving away and getting away and simplifying that cost and resources and near real-time insight is super, super important. So let's look, and, and, and this next slide comes with a health warning, by the way. It comes with a health warning, because it entirely depends on the business outcome. But what I do see, and, and Stephen and I have looked at this quite closely, is yeah, so we do see teams that are building agentic systems and supporting multiple agentic systems here. Are putting together teams that have a product manager, a business analyst, software developers, data engineers, data scientists as required, and typically in an Amazon, we will normally have a principal software engineer. So in Amazon, we call these P engineers. Um, we don't have architects inside of Amazon, by the way. We have, uh, solution architects, which, uh, uh, handle your interactions as an Amazon Web Services customer. But inside of Amazon, we actually have P-level engineers, which is a very senior role, and each team has a P-level engineer, and it's their job to basically ensure that the goals, technical goals of that team are being met. And they also have a lot of responsibilities over making sure that new software development engineers coming into the team can ship code and the right problem. And when we have a, a problem that requires multiple teams to interact, you know, we actually get a bunch of pieces together and they'll solve that problem. Now, not everyone has that model. So it's probably far more familiar to people to have something like this, where at the end you've got an architect doing that. And these job titles, by the way, are incredibly fungible at the moment, incredibly fungible. And of course, multiple agents are helping this team do their job. They're going to build and are already building agents to help. Now, typically I've talked about the delivery team. When you are touching an established process and, and bringing some magentic side on there, you'll absolutely have a sister or a brother team coming alongside that, that says, well, what's my business process experts? And if you're touching a really complex flow, that's gonna occur, you're gonna have business process experts, you're gonna have, again, an architect, you're typically I'm seeing every customer put a legal representative in there. A financial analyst, a data owner, and again, a software development lead who's an interfacing leading that technical side that I talked about in the previous slide. So it's almost like a two in the box model for building these agentic systems is what's coming to the fore. This model in particular, talking on an established product. My colleague Steven's going to talk to you about Amazon, about how we think about different stages of product development and how we put different teams together. And yes, these teams are gonna use different agenda, different agents or create their own agents, absolutely. Absolutely. We're seeing that occur immediately. Because they're using agents and realizing they can build these small agents in Sagemaker AI to solve things for them, to reduce their cognitive burden so that they can focus on what really matters. Because the world is really changing quickly. I mean, this was a Venn diagram I looked at a little while ago of the congruence between software engineer, data engineer, data scientist, and data analyst. And that sort of middle bit of the Venn diagram there, that blue where it talks about SQL, Python, cloud services, no SQL. I think a lot of us are seeing where that becomes the top of the T shape, if you look at how you skill yourself. That bar of cross-functional knowledge. And this is actually coming to the fore in context engineering. So I need to understand the context of the urgentic system. And if you were at the presentation before where Ishit Bakranjani talked about a leader's guide to agentic AI, he talked about this in more detail. If you missed that presentation, it'll be online, hopefully in the next 48 hours on YouTube. You can look at that. Um, he talks a lot more about context engineering, and we absolutely see that role emerging right now. These systems have got to understand that linkage for data. So again, data is is becoming that critical, critical pole. And actually what we do see is a role emerging, and it's interesting, I was looking at how thought works, think about this. This is Martin Fowler, he's one of my heroes. He came up with a strangler pattern. for deconstructing monoliths, and he talks about it like this. As computer systems get more sophisticated, we've seen a growing trend to value deep specialties, but we've found that our most effective colleagues have a skill in spanning many specialties. We're just starting to explicitly recognize this is a first class skill of expert generalist. And that is emerging, particularly for context engineering. You need to understand what is going on in the system. And if you want to go and look more at Martin's work, which I fundamentally always read when Martin has a blog, he talks about these expert generalists emerging. And I think this for context engineering and agentic systems, again, another emerging role. Prompt engineering, I don't think any of us ever thought that was going to be a role. Context engineering absolutely is. Absolutely is. And with that, I will hand over to my colleague, Stephen. Thanks Jonathan. Um, so I'm Steven Brosovich. Uh, I joined Amazon in August of 1999, so that was a little while ago. Uh, the world has changed a ton since then. Um, we've spent a little bit of time now thinking about how agentic AI is gonna be impacting both the work and the roles in our teams, and you might be sitting here as a leader going, but what does that mean for me? How about my role? How is that impacted by this work? And uh so I wanna frame the question a little more clearly, um, as leaders, right, we all know we're trying to generate value, and we have a limited amount of time, attention, budget, and talent that we can allocate towards the work, right? Uh, in his book The Day After Tomorrow, uh, Peter Hinson talks about different categories of work we can be thinking of the work of today, which actually leads to current value. Then there's the work of tomorrow, which is gonna lead to value in the future, and then there's the day after tomorrow, right? What's that thing that we're doing that contributes long-term value to the organization? And as leaders we know we're all supposed to be thinking about these and prioritizing appropriately. We gotta focus some on today, but gotta make sure we take care of the day after tomorrow. Now reality is. Today tends to insert itself uncomfortably. It's that pile of emails we wake up to that we weren't necessarily expecting or that next meeting. Today tends to dominate. Now we know we're supposed to carve out time for tomorrow, right? So we take additional time to figure out how do we write that 3 year plan, or work on next year's budget. And we still intend to think about, but we know we spend far too little time actually doing those activities of the day after tomorrow. That's when we're looking at that new technology or a shift in our business that could actually set us up for an entirely different direction in the long term. And that's not even taking into account the stuff of yesterday. That's a kind way to put it. Um, but this is that shortcut we took 3 years ago, and the tech debt is rearing its ugly head today and is demanding to be paid. Reality is, all the time we intend to spend on tomorrow and the day after tomorrow often gets consumed by the stuff of today. Are we getting depressed yet? Let me make it even more clear, uh, we still have to remember all this stuff too, on top of the work that we're doing. And at this point, um, we might be feeling a little bit like we're the only ones not enjoying the party, right? All the glossy ads make you think that every business in the world has this figured out but you. The reality is, most businesses are figuring this out themselves. But the clock is ticking. Now the good news is that there are some patterns that we are seeing your peers use that are helping navigate these changes. Um, if you were in Ishit Varjani's session a little bit ago, this will look a little bit familiar. Here are 4 mental model shifts that we see as key for organizations that are successfully managing these changes. Now, as Jonathan mentioned, most of our organizations are set up to deal with a deterministic world, and in that sense, it makes sense for us to have this culture of operational execution. How do I do the job extremely well, right? Avoid deviation from known good processes, being focused on measurement and individual optimization. But leaders that are successfully navigating agentic AI actually see themselves and their organizations more like research labs. This attitude of continuous learning, right, as continuous learners, our focus needs to be on shared experimentation, embracing adaptation, and providing psychological safety so that we can learn from failures. This mental model shift in particular, requires us to look at other areas of leadership when we need to adapt. The first of those, Jonathan already made a nod to, which is, in a deterministic world, it makes sense for us to govern through gates. Right? We can define the process, we can control each action, check for compliance through checklists, right, and audit for deviation. But agentic AI is making us confront reality. Since we live in a probabilistic world, we should probably be spending less time defining and refining the process, and more time providing strategic direction. Defining guardrails and creating feedback loops that allow for rapid experimentation and continuous calibration. When we live in a deterministic world, it makes sense to manage the business like a factory floor because we can set finite limits and measure and calculate against those limits. But successful organizations in this space are operating more like trading floors. How do I provide enough autonomy to the teams? But I need to have real-time risk visibility. And I even need to have adaptive circuit breakers that can respond quickly to emerging risk patterns. And then finally, it makes sense to organize in functional silos when we live in a deterministic world, when we have a known set of problems, and a known set of solutions that we can deploy against those problems, because those functional silos allow us to be incredibly efficient at doing the same thing again and again and again. But when there's rapid change. That rigid org structure, those sequential handoffs, and the isolation of data systems that Jonathan talked about, sometimes make change feel like it's impossible. Organizations that are successfully navigating these changes actually respond much more like an immune system. They swarm and reshape based off of changing customer needs and challenges driven by business objectives and customer outcomes, not hierarchies. Now if you'd like to dive into this topic a little more, there will be a recording of Ishi's presentation, but we also have a link to a blog that uh Isit authored that dives into these mental model shifts more significantly. It's one of just many topics that the executive and resident team produces every year of the challenges and patterns that we are seeing as we talk with our own customers. But what I wanna do now is shift as as we talk to, you know, in, in our team, we talked to over 1500 different organizations annually. We're talking at that sea level change, and we see the the patterns and the questions that we get. And we often hear from our customers like, OK, that's an interesting story, but what's Amazon actually doing? And in this case, this is a very rapidly emerging question, like how is Amazon thinking about org structure in an agentic world? Like many of you, this technology is challenging some of our basic assumptions about how we should organize and get work done. And with over 1.5 million employees, that question is not optional. We have a team of organizational scientists that are helping us understand which patterns are helping us, which are hindering us, and why. Now the answers are shifting. We're still learning, but I'm excited to share with you some of the insights that we've gained from this work inside our own organization. The first insight shouldn't be too surprising. Organizations that align their operating model with their business life cycle phase outperform those that do not. Now some of you are probably starting to break out into hives. Please, not another conversation about centralization and decentralization. Look, we all know. There are some benefits to centralization, and others you gain from decentralizing and granting team autonomy. But what we've found is that this model is too simplistic, and it often leads us swinging from one end of the pendulum to the other. What we actually need is an organizational design model that is adaptive to ever-changing environments. In addition to that, our businesses are too complex to be served by any one size fits all model. So, the emerging thinking. Is that our organizations. Need to be optimized around 3 distinct tensions. The first is speed. As Andy Jasse has said, speed is a choice. How much should you be optimizing for consistency, and when should your primary objective be agility and iterative change? The second tension is resourcing. When should you be thinking about optimizing for scale and efficiency through shared centralized resources and tools, and, and when should your focus be on providing dedicated resources for business specific outcomes? And the third tension is connections. When should you be building deliberately interconnected systems for coordinating complex workflows? And when should you be striving to create more and more autonomous activity? Let's dive into each one of these in a little more detail. First, your customers. Require different speed versus reliability, depending on their context. And so we find that organizations that focus on consistency, they gain speed through systematic execution and standard processes that deliver reliable, repeatable outcomes. In contrast, agile organizations position critical activities close to customers, enabling rapid feedback and iteration. When it comes to resourcing. Your customers actually vary in their need for specialized attention or standardized solutions. And so as we think about this, teams want to drive efficiency by centralizing delivery and building common infrastructure that scale solution across multiple needs. Whereas in other situations, we need those dedicated teams to focus on core capabilities with deep customer context. Delivering specialized solutions for specific needs. And finally, on connections, because guess what, your customers are actually the ones who should be dictating that balance between autonomous innovation and integrated delivery. Interdependent operations, optimized for end to end outcomes through coordinated planning and shared standards. Whereas independent teams maximize autonomy by ring-fencing work into logical units, enabling direct customer signals and modular decision making. Now, where you sit. The optimal balance on each of these actually varies based on business context, customer needs, and organizational maturity. These tensions aren't mutually exclusive. Successful organizations are thoughtfully positioning different parts of their business, along each spectrum based off of their requirements. The key is not to choose one end of the spectrum, but to position different parts of your organization, according to your specific needs, and regularly reassessing. We see this pattern at play across most of Amazon's businesses depending on the maturity of that individual business. Younger businesses often skew towards depth. They're favoring agility, custom functionality, and, uh, but as the businesses mature, they tend to skew towards breadth. Because consistency, economies of scale and cohesive user experience become ever more important. So let's follow that evolution. As we're starting out We're going to skew heavily towards depth over breadth, because early adopters are the ones that are using this new product, and they are seeking innovation and they will accept some amount of imperfections. So we're maximizing speed and flexibility through small dedicated teams with direct customer access. The breadth depth mix starts to shift as the business grows. Early majority customers now join those early adopters, but they bring higher quality expectations while tolerating some iteration. And so now we start to see the emergence of hybrid structures of dedicated and shared teams, because we need those shared teams to support scaling, and we still need those dedicated teams for rapid iteration and adjustments. As the business matures now, mainstream customers start to jump, and they become dominant. And so they're requiring consistent reliable experiences, high quality customer support and structured feature request processes. We shift our operating model to balance established processes with innovation through horizontal platform teams for core infrastructure and federated product teams for customer facing features. As a fully business, uh sorry, when the business fully matures, late majority customers dominate, requiring proven solutions with comprehensive support, predictable experiences, and consistent quality across all interactions. At this point, our emphasis is optimization and efficiency through shared services, automated solutions and support systems, and self-service platforms. Now, this is actually where most organizations stop. They stay at phase 4, right? Refining and squeezing efficiency out of every single process. But this is also where they are the most vulnerable. Because that execution excellence actually becomes the very thing that prevents them from adapting when business climates change or that new start-up shows up on the screen to disrupt their business model. And so at Amazon, we understand, we like the phrase we say at Amazon, it's always day one. The need for that startup-like flexibility is important in phase one initiatives like the NFL on Prime. But it's equally if not more important for well established businesses like home delivery. And so we have to constantly challenge our own recipes for success, because customers' needs are not static. We need to shift our mix yet again to inject fresh innovation. In phase 5, we now have a mix of both loyal customers and customers seeking new experiences, and so we need different value propositions for risk for each of those customers and the balance between familiar and innovative experiences. We want to enable transformation. While maintaining stability through sophisticated dual operating models and hybrid team structures. We find that organizations that are following an adaptive model are far better positioned to react when technologies like Agenic AI emerge. In fact, I'd argue it's that organizational flexibility that has enabled Amazon to weather all the changes in customer needs and demands all the way from our very beginning. Rigid one size fits all approaches just don't work. The second key insight we've gained is that organizations that asymmetrically allocate human AI resources based on the type of work, outperform those that do not. Like organizational models, it turns out there is no one size fits all approach to agentic. So let's look at resource allocation across 4 types of work. The first type of work we call strategic differentiated work, right? This is the work that customers view as uniquely you. It creates competitive advantage, it defines customer experience, and directly enables key goals. The next type of work we look at is strategic enabling work. These are the capabilities that power your differentiation. They support competitive work and reinforce organizational culture to achieve business outcomes. The third category we would call business essential. This is the kind of work that's required for basic operations and near-term success, but it usually isn't tied directly to market value. In fact, most of this work is the keep the lights on work that you just have to do to maintain market parity. And finally we would call another category of work business compliant work. Uh, this is the work that's required right for legal or regulatory compliance. There's usually little to no market return, but it's essential for keeping ourselves afloat. So if we think about these 4 work categories, let's look at how Amazon is currently allocating human and AI resources against these different categories of work. Who's involved in this? Well, first it's you. Right, as strategic leaders. It's our responsibility to provide that vision, that insight, the conviction, and the judgment to define the business outcomes and guide the work. The next group involved in this is AI and Agentic work. It's a combination of AI agents and traditional AI used to solve complex challenges and sift through mountains of probabilities to drive results. The tactical execution team is the humans. All those roles that Jonathan talked about earlier in the day. Those humans are the ones that are creating the agents and the processes needed to achieve the business outcomes. And then let's not forget, there are significant portions of our businesses still today, that can be made far more efficient through simple automation, or by leveraging utility solutions like managed services from AWS and other partners, without reaching for more expensive options like generative AI. So let's look at how we allocate these into those different work categories. Strategic differentiated work is really the only place where executive leadership is critical. We have to set strategic direction, define our own customer facing competitive advantage and make high judgment decisions on product design and innovation. AI energetic systems carry about 25% of the workload. We're leveraging machine learning for things like advanced targeting algorithms, and we're using AI agents for predictive analytics and customer behavior modeling to ensure competitive outcomes. The rest of the work is going to be carried out by that tactical execution team. Right, they're the ones dealing with ambiguity, solving those complex challenges, and executing strategic initiatives. Notice here, automation and outsourcing are next to non-existent. Because there's no known solutions yet to automate, and we would never want to outsource our differentiator. As we move into strategic enabling work. The leadership team can take a back seat. Our role changes to one more of auditing and advising. Now is when we can start to look at the things of tomorrow and the day after tomorrow, because we've set those guard rails that empower our teams to go and build. AI systems take on a greater percentage of the work. They're tackling things like insight generation, anomaly detection, and process optimization. On the human side, technical program managers and solution architects take the lead for technical implementation and for cross-function coordination. Now we start to see the beginnings of automation and the use of utility solutions for things like routine coordination of activities and basic workflow management. When we look at business essential work, agentic systems are used for routine analysis, standard reporting and basic process optimization. Now the humans look more like operation teams, account managers and business intelligence analysts providing operational oversight, exception handling, and process improvement. Agents and people are the ones now that are co-creating these rule-based workflows as problems become better understood and turn those into automation. And then finally, as we look at business compliance, we even skew away from agentic to even more automation as we're now looking for deterministic execution against well understood problems. Here, the human contribution is that context that Jonathan was talking about. It's that dedicated expert knowledge that's needed for those human in the loop decisions, and those situations where rapidly evolving regulatory and compliance frameworks can be digested and understood in the context of the business. Taken as a whole, this asymmetric approach allows us to deploy the right kinds of resources to the right problems. Like most approaches, it's not perfect, but it's proving to be highly adaptable, a way to leverage this new technology. And so our question for you, how are you thinking? About team structure in an energetic world. Hopefully these ideas will give you some new perspectives as you apply them to your own space. For another view on the impact of agents on the work, I'm excited to welcome to the stage, Richard Davis, CTO of Danske Bank. Thank you. Thank you very much. I actually forgot I was coming up here, I was so engrossed in the presentation. So, uh, so excuse me, so I'm Richard Davies, as I said, um, I'm the CEO at Danske Bank and we're based in Copenhagen. And uh. Jonathan mentioned earlier about 95% of organizations not seeing value from Gen E I yet, and we actually think we're part of the latter part of that equation that are seeing the 5% uh of real value from Gen E I. And today I'm gonna just touch upon our story and some of the challenges we see it, both from a tech technology perspective and a human perspective. But before I go into a bit more detail, I'll just give you some background of what where we are on Dansk Bank. So we are a rich uh a bank in the Copenhagen and we have a rich 150 year history. And we've been running infrastructure on-prem for many, many years. And yet to date it's given us a lot of the value that we've seen through our banking systems. But of course as we want to become more agile. Uh, we've introduced, uh, the public cloud, and we've gone from public, from on-prem, sorry, to, to the public cloud. And we've now migrated 850 applications into AWS for the last 18 months. But it's really been around about mindset change rather than just a technical change. But also on top of that, it's given us a great opportunity when it comes to Jenii. It's really given us the phys the infrastructure for us to adapt and deliver really really quick solutions as well as things such as sandboxes. So we say to ourselves that we're catching up from catching up to winning at Danske Bank, and it really is cloud being our foundation when it comes to delivering Gen AI and us becoming an er genetic workforce. We really feel that we're gonna become an AI first bank. People often say, are you really gonna put AI into Danske Bank? But of course we already think it's there. So, yeah, it's a bit cheesy, but uh you know, we had to do it. Anyway, so as we've been delivering Jenny I into our organization, we've got something we now call 10 big wins. We used to call them big bets, big rocks. We're now saying that we feel so passionate that these things are gonna give us value that we're gonna deliver them, and they're called big wins. Now one of them I'm delivering is around our product delivery life cycle. It was based on software delivery life cycle. But as we've kind of gone through, as we've rolled out AI coding assistance like I'm sure many have had, we've seen a huge reduction in our change lead time by about 50%. So this is great. Huge amount of benefit to our developers. But when we started speaking to our developers, we started doing a level of analysis using our live engineering tooling where we could see all the different touch points in our delivery life cycle. And we soon realized that many of our developers, we do have quite a few. We're actually working very, very hard, but only 35% of their time was spent on coding. So a lot of the time they were working really, really hard, but in other areas of the delivery process. So what we found was there was one process for for development, but many, many other processes across the organization. And they were working hard, working with the other processes and to a certain extent. If we move on, when we ask them how they're feeling, well, they felt that progress they were seeing still didn't equal the level of effort that they're putting in on a daily basis. So where are we? So we're on a journey to what we call our new PDLC, which is the product development life cycle. We're actually looking at how we can look at the development teams that are stuck in processes of endless kanban boards, handover meetings, documentation, testing, all sorts of things like that. And we feel there's an amazing opportunity for us to deliver one energetic workflow with zero friction and to a certain extent toil. So some of the agents that we're starting to build, we've actually put one into production already. We're starting to see some immediate benefits from the agents. The first one I think Jonathan mentioned earlier was around business analysis, BAs. We have a large number of BAs, but we also have a lot of developers working on BA. And so now we're looking at how we can automate the specs and validation and reducing the manual effort of our resources. We're also looking at QA. They're testing, how can we get an agent to start accelerating the generation of test cases and are looking for the defective uh detection. Now of course we know that a lot of people don't like actually writing test scripts, but they also don't want to execute so many tests as well, so this is I think something that we think will give us a lot of value. And there's something that's close to my heart as an ex-support person, I think Jonathan mentioned before about the 24/7 is really how do we start thinking about reliability engineering agents. This one really, really excites me. So we already have something called Cloud Buddy and I think we're gonna rename it at some point, but it actually sits in production today and cuts triage time down by about 75% and also improves our root course accuracy. Um, we're also looking at how this can actually help us with incident resolution. It doesn't actually perform an action, but it actually helps us going through log analysis, for example. I'm pretty sure this agent at some point is gonna be part of our organization. In fact, um, as we're looking to give it more and more tasks, we're almost thinking about how we can call it a promotion for the agent. This is the first kind of wave of agents that we're putting in in our PDLC, but we really think that at some point we will have the complete agentic framework when it comes from having an idea all the way through to running the agent in production and potentially even retiring the product. So Talked a little bit about the technology, I've talked a little bit about the history of the bank. One of the biggest things we've seen is the change management, the people element, the human resources. And as I really, really feel that there's a lot of change management to happen, and the reason is is because there's a huge amount of background of different generations, cultures and experiences across the organization. Some are super excited with the genetic opportunities that we have, and some not so much. So we all know the corporate jargon. The first one here. Right, I'll circle back to you. Sounds harmless, but what we really think this says is why should I be using something that can replace me? Well, I think, uh, um, Jonathan mentioned it already. We actually tell them, look, Gen AI won't necessarily replace your role, but uh people using G A I potentially will. Then there's the classic, let's take it offline. Now this one's OK, but really what it means is, look, it sounds OK, but where do I start? Do I really have the time to start learning new tool sets? And this is where we have champions and train the trainers in our organization, continue leaning in to the employees, um, teaching them and giving them uh demos of how others in the organization are getting benefits. And then finally we have the supporters, usually the kind of young grads who are really, really hungry to use some of their genuine tooling and the agents. And really what they're saying is it's really about time uh we implemented some great processes here. So this is something that we're we're seeing across the organization. So this is really around the resources, but what does it mean for me as a CTO? And I think this role is continuing to evolve as well. So we talked about it earlier about being the expert generalist, and I don't think that actually me now is not as deep in technology as I used to be. I see myself as a connector of experts across both technology and the YA employee. This is where the magic happens and really where platform, technology and processes align. I did actually say that I'm a man of many hats and I didn't actually expect my team to put this on, on the, on a slide, so I'll move on very, very quickly. But if there's anything I would say, so there's a couple of things. One is momentum beating perfection. We, when we started off we really really kept on planning, we were planning, we were planning. And by the time we actually went to implement any type of GEA tooling or agentic um opportunities, we really felt that it had already moved on. So we really felt that, um, we've got get moving really, really quick. And what we started to do was some Jenny I hackathons. Now with these Jenny I hackathons, what we did, we gave the end users, the people in the front line with some of the low code, no code tools that we have, and we said, look, we guarantee you a path into production for the winner. Actually, we ended up having 3, the top 3 solutions all getting ready for production. The winner called Checkmate is in production and he's actively used by the team that delivered it in the hackathon every day today, every day. So the commitment that we had said to people about it going into production has really, really driven the hunger for people to get involved and understand more about Jenni I. And then finally, we team up with we'd, we've we've teamed up with a number of great partners and strategic um. Supporters across the organization, our CEO is mandating that the use of Gen AI and we continue to kind of focus on the North Star with becoming becoming an AI first bank. And then finally, this isn't Jonathan and I, this is actually just put together, but we'll actually just say look if we're as we partner up having that North Star and that end vision gives us something for us to kind of focus upon. Without further ado, I'll hand it back to Jonathan. Thank you. Yes. Thank you very much for, for listening to us today. Thank you, Richard, for sharing that story. I love the hackathon idea where we're gonna guarantee it goes into production. All of this is such a fungible state right now, such a fungible space, it's changing every single day. We wanted to give you some deep snippets though on what's happening, we see happening with the rolls and in particularly what's happening with Amazon. Finally, please leave feedback for us. Uh, I'm the track owner for all the senior leaders sessions today. I will read every single comment that you leave for us today. Um, we greatly appreciate the scores and feedbacks you give us, and with that, thank you very much for listening to us today.