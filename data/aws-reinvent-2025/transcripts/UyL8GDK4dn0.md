---
video_id: UyL8GDK4dn0
video_url: https://www.youtube.com/watch?v=UyL8GDK4dn0
is_generated: False
is_translatable: True
---

Thank you. I think you can hear me. Uh, thank you all for attending this session. As anticipated, uh, my name is Guido Biolo. I work for Reply. We are a system integrator. I lead a group of people focusing 100% on generative AI and AI. But I think all of you are here not to listen to me talking about me, but uh to talk about uh an important design choice that many companies are facing uh as they adopt generative AI. Uh, the question is how to select the right approach, uh, when integrating AI powered workflows in real-world systems. Depending on the complexity and the requirements of the task, we might design our system with several different paradigms. We may simply use function call within LLLM. We may deploy a single autonomous agent, or we may orchestrate multiple agents working together. Each approach offers benefits and trade-offs, uh, and as generative adoption expand across industries, making the right, uh, architectural choice becomes increasingly important for performance, safety, and especially for business value. Let's start with the simplest approach, function calling. Modern LLMMO, like the models that are available on Bedrock, can interface with external systems through function calling. It's a feature that is known, uh, because it allows the developer to define APIs and the functions that an LLM can call, can invoke when it needs to access external data or do calculation or things with the code. Instead of generating a free-form text, Like temperature tomorrow should be around 25 degrees. Uh, the model can call a function and, uh, get the result and get back the exact value. This is a game changer for reliability because uh uh structures and deterministic outputs are replacing the unpredictable text generation. Makes AI is safer to integrate into real-world business workflows, and, uh, uh, you can fetch live data, perform calculation, uh, retrieve inventories, check customer balance, verify booking details, uh, all of with the, the, the, with the deterministic external uh function call. Uh, for example, think of a banking assistant. Uh, when a customer asks, what's my current balance, we don't want that, the model guess the answer, but it simply trigger a backend function and can retrieve the exact value from a customer database. Function solving is essentially the bridge, uh, between, uh, probabilistic reasoning, typical of LLM and the deterministic words of software APIs. Let's now bring to a concrete travel scenario. Uh, I imagine I need to plan my trip to Rainvent in Las Vegas, uh, for next week. I will start prompting an LLM asking, next week I will go to Las Vegas for a few days trip. Um what do I have to put in my luggage? And a standard LLM would give a generic list of clothes, generic list of Jackets, sunglasses, things like that, uh, without taking into consideration that when I say next week, uh, he's already providing a lot of information like season, like, uh, things that I really need to do and to bring me, uh, to bring with me during my stay. Now, if I keep the model uh with function calling capabilities, it can announce the generation uh uh of its answer. The model says that, so, so that my request involves the, the place uh and the date and can call that function to get, uh, uh, to, to get uh something specific for that specific moment. And with this real forecast can now say the real things that I need. The result is far more accurate and uh personalized. Here is an example of uh doing function calling with Bedrock. It's pretty simple. Essentially, we put inside the definition of the uh of the prompt, even the tool that uh the LLM can access. Function call is extremely efficient. But only for known and uh simple interactions. Once we scale up to real-world scenario, uh, we have enterprise workflows with dozens of tools, interdependent functions, uh, more dynamic requirements, and things get harder really quick. Uh, the more functions involved, the more back and forth between the LLM and the application we have. So the system still needs to hold the business logic and, uh, Act with this back and forth with the LLM. At this point, we'd start uh using reasoning inside the eye itself, and this brings us to agent. The react pattern that it's reasoning and acting showed us that an LLM can do more than just predict text or call function directly. They can reason. For example, first, I need to check specific things, uh, then depending on the result, I will call another one. And just like humans, uh, essentially think on how to solve a problem. By integrating this tool description into a prompter, the model can dynamically choose which tool to use. Also plan multiple steps ahead and analyze the intermediate result and adjust the action accordingly to the result that obtains. This allows us to build a system where AI is not a passive responder, but it actively drives problem solving, and this leads us directly into an Asiantic architecture. An agent is a step beyond function calling, as we said. It's an autonomous AI process that essentially receive a goal, reason on how to solve it, decomposes into task in this task into multiple steps, and decide when to call function, when to use tools, when to fetch external data. Let's see in practice. Let, let's see the scenario that we had before. Uh, I imagine we want to extend that scenario. In, uh, in this scenario, uh, instead of simple calling a single get weather function, we want a system that is, uh, um, autonomously able to handle multiple aspects. For example, retrieving the weather forecast, checking the hotel availability, uh, verify the flight to come here. And uh even suggest activities depending uh on the length of my stay and the season in which I am. The agent is in its allied with multiple tools, uh, a weather API, a flight search tool, a hotel booking tool, maybe even integrated with my calendar to check, uh, the things that I have scheduled. And the key difference is the key difference here is that we no longer manually orchestrate the different steps. An agent is able to reason step by step, deciding when to invoke each tool and whatever is needed during the evolving of the understanding of the problem. For example, say that we want to plan this 5 trips to Las Vegas next week, uh, the agent can decide to call the different tools, uh, to have information about, uh, the weather, to check the availability of flight and bottles, and even querying, uh, the weather forecast for those days and finally recommending the things that I have to take. Sometimes one agent is not enough. Uh, some business problems are more complex, uh, and need to be, uh, break them into specialized, uh, roles to deliver better results. This is where multi-agent system comes in. Instead of one single agent, uh, juggling between different domains, uh, we can create multiple agents that can collaborate. Each one can be focused on a particular area, uh, having its own expertise, its own dedicated tools, and its own dedicated instructions. Uh, continuing at the travel scenario, but a little bit further. We can have a weather agent focusing purely on forecasting. The flight agent focusing on the flight searches, the hotel agents for the accommodations, the activities agent that suggests all the things that we can do during this period. And sitting on top, we can have a coordinator agent that essentially orchestrate all of them. Its agent can work independently and efficiently, staying in the boundaries of its own domain, improving accuracy and modularity. In this example, if we can improve a single agent without touching the other and without the risk of breaking things that are working, these are some how human organizations are working. Uh, different specialists that collaborate through a manager. Before diving into challenges, uh, let's look at two foundation multi-agent architecture that you can choose from. The first one is the hierarchical pattern, also called supervisor. Uh, in this pattern, we have a central orchestrator that's what we can call supervisor, uh, that breaks down the overall goal into different subtasks, distribute them to the specialized worker agents. Each worker is focusing only on its own domain, uh, without, uh Uh, calling with the other, the supervisor collects and consolidates all the results. This approach provides clear control on who is in charge of what, uh, is it debugging, and straightforward sequencing all of the different actions. The second one is the network, uh, also called Swarm. Here we have multiple agents that can operate as peer in a mesh, uh, with a shared blackboard. There's no single boss. Instead of, mm, we have agents that communicates directly, uh, to share information, to coordinate the different tasks. This pattern offers more resiliency, obviously, because if one agent fails, uh, the others can continue to work. But on the other side, enables uh also parallel problem solving but can be very, uh, very, very complex to manage. Uh, once, uh, wiser than me once said, uh, that, uh, with great power comes great responsibility. We have challenges obviously with multi-agent architecture. Uh, there are several challenges. The first one is the orchestration complexity. Who can talk to whom, when, in what order. Uh, the second one is latency and costs. Uh, multiple agents means, uh, more LLM calls. More LLM calls, more tools, potentially longer response time. Third one, it's debugging. Uh, as a distributed system, if something goes wrong, we need to detailed observability, tracing the full chain of agent decision across the different agents. And last but not least, we have security and safety. Each agent, each agent can access different sensitive data. And uh permission, must be carefully controlled in a way that all the agents stays in its own boundaries. Imagine a real world failure. We can have two agents, one calling each other uh recursively, endlessly, uh, because of a misaligned prompt, uh, or a tool API that uh has been changed without notice, uh, bringing uh uh the agents unable to, uh, to call that specific function call. No one notices until a user complains. That's why strong observability and monitoring, uh, like for example, using strands with open telemetry, it's crucial when deploying multi-agents architecture. When choosing between functional agents and multi-agent architecture, it's not about picking the most advanced adoption because it can be difficult to manage it. It's about selecting the right level of intelligence and autonomy that we need for our use case. The first thing that we have, uh, the, the first key driver in my opinion, to take into consideration, uh, is the task complexity. Uh, it's about how many steps, how many moving parts are in our problem. Um, it's a simple question answer, uh, flow that's, uh, that the user asks, or multi-step tasks, uh, uh, are evolving using the context. If the task is pretty straightforward, mm, function calling is enough, quicker, easier. If it involves uh multiple subtasks, uh, contextual interpretation, chaining decision, maybe an agent, uh, like, for example, the, the example of booking a, a travel, uh, an agent can be a good choice. And, uh, when, instead, a task involves, uh, parallel domains, like for example, legal compliance and financing the same problem to solve, uh, and requires coordination. Multi-agent system, it's usually a better fit. The second one, it's uh predictability versus uh uh adaptability. Uh, yeah, the question that we want to answer is how tight, uh, do we need to control the system behavior? Uh, or we prefer that it adapts in, uh, some open-ended way to solve the problem that we gave us. Function callings offers full predictability. It's a single shot. Uh, the LLM suggests the function, the system is stutic as the latter as needed, and, uh, gave the result for deterministic control. Then we have agents which gives more adaptability. Um, essentially they decide dynamically which tool they need to use based on the user intent and the evolution of the context, the evolution of the, of the problem solution. And then we have multiple, multi-agent system that allows emergent behavior. Uh, essentially, agents may solve subproblems differently based on their, their domain knowledge. This is very powerful, but obviously less predictable. And that's where a good observability, uh, becomes critical. The third one, it's, uh, costal latency. Uh, when, uh, you have You prefer performance or budgets? Where are your constraints? Essentially, do you need a, a very responsible system or you can live with the system uh that uh solve the problem in a synchronous way? Function calls are cheaper and very faster, minimal token use, few model calls. Agents are more expensive. They often uh reason through multiple steps to solve a problem, and multiple, multi-agent system uh multiply cost and latency. Obviously. Then we have a control over the business logic. Essentially, who defines how the system behaves? Are you or the model itself? With function callings, you control everything. With agents, uh, the logic is, uh, partially embedded in the, the prompt and the reasoning steps that, uh, um, that the LLM do. And with multiple agents, uh, uh, you are essentially delegating everything to them to solve the problem in the way that they think it's right. And last but not least, uh, we have the autonomy. Uh, how much initiative should theI take? Function callings are reactive. The LLM says, uh, the user has something, the model responds. Agents are instead proactive. Uh, they can decompose goals, uh, decide the different steps that they have to do, to take, and, uh, ask even follow-up questions if needed to solve the problem. With multi-agents, we have a collaborative and autonomous view. Essentially, they can assign role between them, distribute the task, and solve the problems with minimal to no human input. A recap table to visualize it, uh, essentially, low complexity and low autonomy, obviously, use function calling. Moderate complexity and adaptive reasoning. Here, you can use a single agent. And that complexity with multiple domain collaboration. Multi-agent orchestration. For example, let's think about retrieving a product price. Retrieving a product price is a simple function calling. No, we don't need any more complex than that. For planning a vacation. Uh, using a single agent. It's, uh, a single domain in which the agent has different tools, different API that they can call and can decompose the problem, uh, staying in the boundaries of the domain. Instead, building an enterprise legal advisor obviously involves multiple uh. Multiple Perm sorry, uh, multiple uh tasks between different domains, uh, and that's where a multi-agent system can, uh, can act. Let's map some, some real world use cases. Uh, function calling, we'll say, for example, FAQ bot, currency conversion, all the things that can be solved, uh, very simple, order status, lookups. Then we have uh agents. With single agents, we can say that we can have a, a travel planning assistant, personal research assistant, content summarization. The typical assistant that you are using in your everyday job in some years. With multi-agents, instead, uh, we have uh use cases like complexergeneration, enterprise-wide troubleshooting. Uh, even project management or, uh, legal due diligence can be performed by multiple agents put in the same, uh, uh, in the same solution. The, the thing is, the more ambiguity, the more specialization or collaboration the problem involves, the more energetic approach helps. The more uh uh less specialization, more um we are more helped by uh function calling. Let's wrap up. Uh, first things, always start simple. Don't overcomplicate the problem. Use function calling whenever, uh, deterministic output is sufficient. Or you can use single agents for multiple-step tasks that need adaptive reasoning. And use multi-agents when you need, uh, different domain specialization and complex workflows. Second thing is always plan for observability. Uh, things will break definitely using LLMs. Always plan for observability for cost control, and especially for governance. And the third one, last one, remember that AWS provides uh different, uh, end to end uh tools that we can support the Korean user for supporting uh at every level. We have Amazon Bedrock, lambda, strengths, step functions, uh, even agent core. All these services can be used to build uh agentic AI solution. I hope this gave you a clear model on uh how to apply AI uh inside your project. Here is my contact, feel free to get in touch with me. Uh, remember to leave a feedback of this session through the mobile app. Thank you for your attention. Thank you so much.