---
video_id: fCNpnr1aHLQ
video_url: https://www.youtube.com/watch?v=fCNpnr1aHLQ
is_generated: False
is_translatable: True
summary: This presentation from AWS re:Invent 2025 features Eduardo, Wilson, and DNA from Itaú Unibanco, one of Latin America's largest banks. They share their journey of modernizing a mission-critical system, specifically the migration of their core banking authorization from a mainframe COBOL environment to AWS. The session is aimed at an audience interested in high-availability systems and mainframe modernization, and the speakers promise to share technical details that can be applied to other systems. The presentation is divided into several key sections. It begins with an overview of Itaú Unibanco and the challenges they faced with their legacy systems. As a 100-year-old institution with over 70 million customers, the bank has a long history of consistent results, but they recognized the need to adapt to the digital transformation that has been sweeping through the financial services industry. The speakers highlight the changing behavior of customers, who are now more connected and demand faster access to information. This shift in customer expectations was a primary driver for the modernization project. The core of the presentation focuses on the technical aspects of the migration. The speakers detail the self-paced architecture they designed to ensure high availability, even during the migration process. They explain how they leveraged AWS services to build a resilient and scalable platform for their checking accounts. A key part of this architecture is the use of Amazon DynamoDB (DDB) to support their checking accounts platform. The choice of DDB was driven by the need for a highly available and scalable database that could handle the high transaction volume of a core banking system. The session also covers the key lessons learned during the migration. The speakers are candid about the challenges they faced and the solutions they developed to overcome them. They emphasize the importance of a well-designed architecture, a phased migration approach, and a strong partnership with AWS. The presentation is a valuable case study for any organization planning a similar migration, offering practical advice and real-world insights into the process of modernizing a mission-critical system. The speakers' willingness to share their experiences, both positive and negative, makes this a particularly insightful and valuable session for anyone in the financial services industry or any other sector facing the challenges of digital transformation.
keywords: AWS, mainframe migration, high availability, Itaú Unibanco, DynamoDB, core banking
---

Hello, everyone. Welcome. Let's start with a quick question. Raise your hands if you are in path or planning to migrate to a critical system that needs high availability even during the immigration. Yeah, I think I'm most of you. And uh for my curiosity, who is rewriting a critical system like from mainframe EObo to AWS? Oh awesome. You're brave. I hope we can help you today. My name is Eduardo and I'm uh with my friends Wilson and uh DNA from Itauni Bank. We are going to share the journeys to modernization, focusing on the technical details that you can actually use on your own systems. In the session you talk what is taboo and the challenges they are facing. They are self-based architecture for high availability. How DaGB supporting their checking accounts platform, and at the end, the key lessons we learned along the way. Now I will hand over to Yuso. Let you talk more about ITau. Yo, thank you, I do. Hi everyone, I'm very happy to be here today. It's great to be here to talk about how we are modernize our mission critical system. Before we dive deeper, let me introduce it to. Itoi B, who is one of the largest banks in Latin America, and last year we celebrated 100 years of history. We have been able to deliver strong results consistently over the last few decades. Over 70 million customers have accessed a full suite of financial services from credit cards to cash management, from retail to our wholesale. But even after a century of growth and transformation, one thing has always been true changing never stops. 10 years ago we realized that digital was changing the way everyone was doing business in Brazil. This was very prevalent in the financial service industry. For those of you who are seeing this change in behavior, please raise your hands. Great, we are also witnessing this transformation on how customers consume products and what their needs are nowadays. They are more connected, more online, and they need information as fast as possible. Let's take a look at a few examples that changes in behavior show up in our daily lives in Brazil. The population using WhatsApp to make payments and transfers, paying using QR code at points of sales, managing their investments online in real time, and we have peaks. Peaks is an instant payment service launched by Brazilian central bank in the last quarter in 2020. It was designed to make payments and transfers across banks in under 10 seconds. It has become the most widely service used in Brazil. Around 90% of Brazilians use it every day. It's simple, fast, and fully digital. The platform is open, interoperable, and API-driven, available 24/7, including the weekends and holidays. Last month, 7 billion transactions were processed through peaks as the total. 20% went through its own. In other words, 1 in every 5 peak transactions runs through our checking account platform, in addition to many other transactions from services that I mentioned earlier. Our process approves the Russia's payments based on available funds, overdraft protections, account restrictions, and update the balances according to the result in the real-time. All this change in behavior demand a response from society, technology, and especially from us, the banks, as people adopted simpler, faster ways to move money, we had to rethink how our core system could keep up. That was the turning point. Back in 2018, we decided to embrace its transformation. We made a critical decision to scale up our modernization, and the outcomes we've seen since then have been truly amazing. Last year, right here at REvent, our CIO Ricardo Guerra announced an ambitious commitment to migrate 100% of our platforms to the cloud by 2028. Now you might be wondering what do I really mean by modernization. Well, in our case it's about evolving our checking account platform, a core system bank that serves millions of customers daily. This platform has been running on the mainframe for more than 50 years, and now we are moving it to the cloud. This new platform should be available whenever a customer needs it. That's why we are targeting 4 lines of availability, meaning less than 5 minutes of downtime per month. But the most important, the entire core of this evolution is to make sure our customers' checking account balances remain safe, accurate, and consistent. That's our non-negotiable requirements. To meet those requirements, we had to completely rethink how our systems are designed and connected. That's what led us to the architecture. We'll see next. Here is a high-level view of our current account platform, the one we've been rearchitecting since 2019 as part of our journey. It's an event-driven architecture built on command and response pattern, and we use Kafka as a backbone to connect our microservices, ensuring it's smooth, reliable, and communication in real-time. Now I'm going to show you a basic flow for authorizing a single transaction. First, the account service implements high the potency, validates transactions, and apply key business rules, ensuring that every operation is consistent and reliable. Then the authorized process each transactions and synchronize with our card letters, so data remains up to date in both platforms. And the finally, the dispatcher sends the results back to the requesters and pushes the events to another system banks that need to be informed about these transactions, such as the accountant statement platform. This current platform has been running at scale for years. Processing millions of transactions every day, but our journey doesn't stop here. We continue to evolve, pushing for a great resilience, availability, and performance. Well, The next few slides will take you through on how you are making this happen, how AWS has been helping us, and how Amazon LinoDB has become the key source of this transformation. take over from here. Sure, thank you, Wilson. So I'm glad to be here sharing with you our modernization journey of one of the most critical systems for a bank. Given that failures are an inherent part of any complex system, we often face situation where something goes wrong. Here you can see our CIO Ricardo Gaja and Amazon's CTO Wern Bogos. And as the Werner Bogos says, everything fails, all the time, and probably there's something failing right now somewhere. When we face a failure, it can either impact all our customers or just a portion of them, reducing the impact. So I have a question for you. Would you prefer that all your customers be affected by a failure or just a portion of them? So raise your hand if you would prefer that only a portion of our customers be affected by a failure rather than all of them at once. That's good. So that's why we are planning our new architecture based on Camaa 0 or just C0. C0 is the Taus frameworks implementation for the critical systems. C0 was presented at 2022 event, and you can watch it using this QR code. The cell-based architecture helps us to achieve a higher availability by isolating failures, giving deployment safety, and helping with the scalability. Each cell is designed to be a fully autonomous unit without any stated share between them. It also has pound size and capacity. This approach not only enhances the availability and fault isolation, but also simplifies the scaling by adding more cells rather than increase the size of existing ones. This helps, uh, this avoid unpredictable performance issues and side effect that adding more resources into an existing cell can introduce into our platform. And isolating customers into cells requires a new layer in our architecture, the router layer. The router layer is a thin layer to direct our customer's transactions to its right cell. It allows customers' data lives only one specific cell. That means that customers have enough finches to the cell to process their transactions. In our case, customers' data must not be replicated across the cells in any situations. But if you have a case with more static data, you could replicate the data across your cells and use shuffle charge. The Amazon Route 53 is an example of this approach. But how can we Uh, direct our customers' transactions consistently to the same cell. Here we are going to show 4 algorithms that can address this issue and why choosing the right one is a very important decision for your self-based architecture. The full table mapping is our simplest and most flexible solution. You map each of our customers into a specific cell, but you should take care of how much storage it takes since you should avoid the operations in a router layer to make it as fast as possible. We can also do a prefix range-based mapping, where we map each of the prefix of a range into a specific cell, but this could lead you to a hot cell. The naive model use a model arithmetic to map uh your customers into a specific cell. This is simple to implement since we need only the number of cells, but it's harder to scale because when you add a new cell, you must rebalance your customer data considering this new cell. We can also have consistent hashing where we also use the naive model, but instead of using the number of cells, we use a large number of buckets and then we map each of these buckets into a specific cell. With this strategy, help us, help you to reduce your migration scope because you choose when to migrate each of these buckets to a new cell. You should use an override table to map a few specific customers into a specific cell as needed in your strategy. And in moving customers between sales, it's it's an expensive and data heavy process that should be avoided as much as possible and their and their partition algorithm must be consistent so your customers' transactions need to be processed where their data lives. The full table mapping was the best fit for us since we need more control over customer's placement, and when we add a new cell, we migrate the customers one by one as needed, or we just let the new customers be mapped to the new cell. The router layer also follows the cell-based architecture. Each router instance works completely independent from each other. The router job is simple. It just takes the message and route to the right cell. You should try to keep all the data needed by your purchasing algorithm in memory, so the decisions are made quickly. And every, and each of the router instances can talk with every cell, giving us both speed and resilience. In our case, all the router instances are part of the same Kafka consumer group, so it takes the message from the Kafka command top and sends to the cell over GRPC connection. Itself is designed to be a fully autonomous unit. It owns its data and it processes its own transaction and it can work completely independent from each other, but independence alone is not enough. We still need resilience, the ability to keep serving traffic even when something goes wrong with that cell. That's why the cell has replicas. The cell replica is an active corpse that mirror the state of the primary cell. And together they ensure higher availability and fault tolerance across their platform. Your cell can have as many as needed replicas, and this number has a direct impact on your system's resilience. Also, to improve your system's availability, it's the best price to place each of our replica in a different availability zone. And there's a relics can work in a different setups. With the active active setup, all your server applicants are active at the same time. Uh, general router layer works, uh, act as a load balancer, distributing the requests across your server replicas. This setup fits better when you can rely on eventual consistency. And remember that all data chains must be replicated across your replicas so they will stay consistent over time. Now, in active standby, only one replica is active at a time. And this fits better when you need a strong consistency. This was our choice for the sell, uh, the cell replica setup because our customers' account balance needs to be strongly consistent. And how can we deal with the cell recovery? In the activity active setup, if one replica fails, the router will rebalance the traffic across the remaining replicas. And if another one fails, it will happen again and your remaining rea will have to deal with the wholesale traffic. It's important to keep that in mind when you are defining the right size for your cell replica. Now, the activity standby, if your cell fails, you need to ensure that the data replication across your remaining replicas are up to date. When it's done, the router shifts the traffic from the replica A to the replica B, and then the replica B becomes an active replica. In our case, with 3 cell replicas, we can lose 1 and still be available to our customers, but if you lose 2 or more replicas, we can't ensure the account balance durability, so that cell becomes unavailable. But it's important to remember that the other cells can keep it running and only a portion of our customers will be affected by this failure. And then how does the data replication work? The activa app receives all the traffic from the router layer. And The standard device replicas uh replicates the data asynchronously. So, we use, during, during this process, we use a quorum-based replication model. That means that a subset of replicas replicates the data synchronously while the remaining ones replicate the data asynchronously. We use a journal component to ensure the replication. So, when the active cell replica receives a transaction, it supplies all the business rules, and when the information is right to be stored, it does not write directly to the database table. Instead, it use our journal component which coordinates the persistence across replicas. And waiting for acknowledge from the calling replica and one of the quantum replica. So when it's, and when it's done, the, the journal component sends an OK back to the authorized replication. If something goes wrong, the journal sends an undue request to everyone, so they will stay consistent over time. And this is our cell replica architecture. The cell replica architecture uh have all the applications and components needed to run the workload. So, we have a a router layer. That sends the transactions request over JRPC connection to the authorizer application, and when it applies all the business rules, up to-dates customer's account balance, and needs to uh persist the information, it use our journal component to make sure of the replication and the durability. So when it's done, we send the response to an Amazon SQS. Using SQS helps us to decouple the synchronous authorization flow from the dispatch process. So when the authorizer application sends the response to an SQS, it also sends an OK back to the router layer, and then the router layer commits the Kafka search for that message. At the same time, the dispatcher application receives the responses right to the Dynamo DB always using our journal component to ensure replication and durability, and then it sends the response to the requester as well as to the other platform services like the account statement. And there's a big change here. We no longer depends on the mainframe to process our, our clients or customers transactions. Uh, this makes the system faster, simpler, and much easier to to evolve. OK, so let's do a quick recap about how the self-based architecture help us to meet our availability requirements. If one replica fails, uh, another synchronized one quickly takes over because the data is already replicated. But if two or more replica fails, then that cell becomes unavailable. But, uh, it impacts only a portion of our customers because the other sales keeps running. If you need to scale, it's simple. We just add more cells rather than increasing the size of existing ones. But you might need to migrate some data depending on how your system handles the mig the partitioning. But the self-based architecture is not perfect and it's not for everyone. You, uh, it brings a huge benefit for the critical systems, but also adds complexity. You need to invest in a router layer uh since your customer's data is isolated in a cell. You also uh should avoid migrate customers because it's an expensive and data have process. So if you want to go deeper into the top game, I recommend a great white paper by Hobbs Oliveira that was even mentioned on the last series Reinvent Keynote. And did you remember our non-negotiable requirement, the account balance accuracy? So let's take a deep dive into the AWS services that make this happen. You do. Can you tell us more about the serves? Sure, thank you, Ed. So, now that you know the architecture of the platform, let's talk what database to choose and more importantly, why. So remember IA's main requirement requirement is to keep the account balance safe, accurate, and consistent at any time. On top of that, they need you to to authorize the transactions in under 100 milliseconds, authorize 6000 transactions per second at the peak times, and allow some big accounts to authorize 1000 transactions. The database you pick will allow you to hit this number or not. Together with GFT, uh, AWS Professional Services partner, we tested SQL Servey with Amazon relation Database services using in memory, the B, Amazon Quantum Ledger database, Amazon Aurora, and Amazon Danu GB. And as you have already seen, we chose WGB because it gives high availability, so it gives uh I the requirements that they needed and 49 is requirement, so RGB can process that. It gives predictable performancey regardless of the size of the table, and it also has less operational work. Before we go technical, let's talk about two critical principles. The first one is a depot. So if you receive the same request multiple times, you should process only the first one and return the same result for the following ones. And the other principle is isolation. When you have two processes trying to update the same records at the same time. One change, one process change must not override the other ones. These two principles are really essential for financial data that we must keep them accurate at any time. So we need operations that are atomic, consistent, in the potent, and durable. Who knows that WDB provides ACD operations. Yeah, in, in some venues that to be present, the same thing. Most of the people didn't know that. And I will tell you how WGB helped you achieve this. Let's talk about the table schema that you choose, and it must match what you are trying to do, and the tuss need to have the hypothesis of the transactions and the isolation of their balances recorded chains. And you see here that we can use the primary key as the account ID and the search key as the transaction ID as the transactions. But I think some of you have already spotted a problem here. For that big account that needs 1000 transactions per second, this is creating a hot key. But with a small change we can have the same hypothesis that we need. So if we receive multiple transactions, we will detect that. Uh, the duplicate transactions, right? We have detected that, and with this change, we spread the transactions across the partitions, so we are avoiding the hotkey problem. And now you might be thinking, OK, so let's create a global secondary index so we can list all the transactions of an account. But that's not a good way to go because You will be creating a hot partition on your global secondary index that will throttle, that will create a back pressure on the main table that will also throttle. So the best approach here is to offload your record chains to an S3 bucket using the DAMADB strings and use that tin to query something this way. Also, you might be noting here that at the balances table, we add a version property. This is for the opportunistic locking that I will talk a little bit, and it provides the isolation. Before you, we talk about transactions, I will do a quick quiz here. So, what's the size limit of a partition key? How, how much data you can put in a partition key? So raise your hands if you think it's 10 gigabytes. OK, raise, uh, I, I, I kick a bit far, but OK, I think most of you would raise your hands on unlimited data, and, and that you tell why it's unlimited data. The 10 gigabytes that some of you raise your hands is when you use local secondary indexes because it's based on the item collection. In Dan GB, I collection is a white things that shares the same partition key. And if you use local secondary index, that 10 gigabyte limit kicks in. If you're not using local circular index, it's unlimited because the, the item collection is spawn multiple physical partitions, and for us it was really eye opening when we were testing and we discovered that that we don't have any limited in the same partition key. So now let's go back to talk about transactions and how we get the ACD operation that we need. So When you deal with transactions with relational databases, so you create the transaction and you commit and you roll back, it's straightforward and in down with DB use the transaction right the items they pay equal. And it provides the optimistic locking using conditions. For the transact the transactive records, we use the condition attribute not existing, so it checks if that transaction ID doesn't already exist at the table. And for the update of the balance, we use a comparison if the version that is stored at the table is the same one that we use to authorize the transactions. If it isn't, that says that some other process changes the balance, and we need to go back and try again. Also, you see that there is a client to request a talking property at the beginning of the API call. That's to make the transaction right IT call also with the potency. So if we send the the same call call to WGB for any reason, reason to retry, WGB we will return the same response. And now what happens if a condition fails? Download theB we will return and here her information saying what item that we send in the API call didn't match the condition that we asked for. And then in this case here at Ttaus because of the architecture that they showed us of the archive and standby uh cells. It's a rare condition that happens, but it might happen when we are failing over another replica and so on. So in these rare situations, we accept the slowdown and we do it properly. If the problem was because the version of the balance wasn't the one that we needed at the table, We invalidate any cash that we have in memory, read again the balance from the table, and we reauthorize all the transactions. But if the problem was a transaction that was duplicated, we read the response for that transaction from the table, response, and we send the response right away and we authorize the remaining ones. This adds latency, but it keeps the balance of the really safe, and this is there are no negotiable requirements. And now let's talk about performance. We know that data is safe and um one thing here is that the DnDB wasn't the fastest database that we tried, but it gives us a more valuable item that we want that is consistency. Like when you use relational databases, your statistically changes during the time, which affects your execution plans, and then it slows down your query, your select, and so on. And you might be needing uh DBA tweaking things all the time. With that would it be regardless of the size of the table, the, the speed, the performance is consistent. For the 1000 most demanding scenario that is for those 1000 transactions for some big accounts, we could reach 1200 transactions per second on average and 7 to 90 milliseconds latency. And um this is really good for them and it, it shows that they can achieve the performance that they need and to achieve that 6000 transactions, we only scale the number of sales, so it's pretty straightforward. And how can you get the same performance that we get here? First of all, is to avoid the hot partitions that are, we are already talked at today's schema slide. So Choose the right scheme for what you need and spread the transactions across the partitions. The second one is to use single threaded processing. What happens here at it all when we receive a batch of transactions from the Kafka to process, we group them by account ID in memory and we send out the transactions of the same account ID to the same thread. So what we need here is to not have multiple processes or multiple threads process the transactions of the same account. This way we avoid the race conditions, so the problem from the conditions of the transactional items, and we keep the performance at top. Another thing that you can use is the best feature of the transaction right I think AP call. The transaction writing items can pack up to 100 items in the same call. So for it, it means that we can have one financial transaction and one balance OPH for 50 accounts, or 1990 financial transactions and one balance OPH for a single account. And what happens if you don't deal with the race condition? So this is the number we got with only one thread processing the transactions. If you have 2 concurrent threads processing, the performance goes down 15% and the latest goes up more than double. And you have 4 threads processing the same account. The performance goes down another 15%, and the latest is 5.6 more, and it is, it is unacceptable for the needs. And you might be thinking it was so easy to get these numbers. No, it wasn't. At the AWS professional services accounts we reached these numbers right away, but when we tested the same application at T, we only got 680 transactions per 2nd and 130 milliseconds latency. So we started talking with the AWS enterprise support and guess what we found that the number and the size of the IAM policies were affecting the WMDB performance. So we all had the double policies than we had at the AWS accounts and at the professional services. So we deal with it, we fix the, the roles, the policies of the account, and I thought we could get the same performance that we need. One important thing here that I did, uh, 3 weeks ago another test and now the number of policies is not affecting the, the performance of MDB anymore. So the WDB service team listening to the customer to, to this case that we opened, help us to figure out what was happening, and they improved the service for all of you. So let's have a quick summary why RMDB was the IAU choice for the database. First of all, it's high availability. There's no downtime if to, uh, upgrade the version, and it gives the 49 availability requirement that it all needs. It has the ACD transactions that they need for the balance COP dates. It gives predictable performance for any table size, and it gives less operational overhead. If you are using RMDB in your critical uh system that needs high performance, be aware of the limits of the RMDB. Be careful with the hot partition. This is really important. And find if you, you have two processes trying to change the same record at the same time, you need to avoid the race conditions. Now, uh, here is, there is a QR code with more best practice on using RGB. And now I will hand over to EDA again to talk about ITAU's launch strategy. Thanks Adu. OK, you have your architecture defined as well as your database, and you'll test it a lot, and you'll know that it will work, but you still need a safe method to replace your new system, your current system by the new one. So we're going to show how we rely on the dark launch strategy to switch from your currently checking account platform to the new one. But first, let's see our target architecture. This is our target architecture. Remember all the products, products that Wilson mentioned in the beginning, like here are instant payment peaks, uh, debit cards used on the POS online investments, and everything else that needs to update an account balance. They need to send transaction requests into our Kafka common topic. Then we apply the full table mapping on the router layer. When the authorizer receives the transactions, applies all the business rules, we use our journal component to ensure replication and durability, and then we send the response to an SQS to the couple of the synchronous authorization process from the dispatcher, uh, from the dispatcher response. And then we send the response to the requester as well as to the other platform services using uh Kafka Topics. So, OK. Um, Building this architecture is just half the job. The other half is to make sure that it behaves exactly as expected. So that's where the dark launch comes in. Wear the dark launch in the shadow traffic mode. In this mode, both architectors are consuming the Kafka comment uh requests. So, our current architector is consuming the requests, processing, uh, and making sure that all the business rules are applied and the customer's account balances are predated correctly. And it generates the official response for the products that is requesting that uh uh balance update. So at the same time, the new architecture also process every transaction one by one, and this allows us to validate transaction by transaction if it behaves exactly as we expected. So while both systems uh does not align perfectly. We keep doing this, uh, and fixing bugs, uh, implementing missing, uh, business rules, and when both systems aligns perfectly, we start migrating our customers from the current architecture to the new one. So when we reach 100% of our customers uh being processed on the new architecture, we will be ready to fully retire the current one. Wilson, can you share our next steps? Sure. Well, As you entering the final stage of our transformation, and in my opinion, the most challenging one, we complete the adoption for all products into our new platform, a step that you add around 500 million new transactions every month from bad seasons with some peak days processing more than 120 million transactions. We also operate at cell level, bringing great resilience, availability, and deployment safety as we fully transition to Kamadazar or as you know, CEO, a cell-based architecture. And perhaps the most challenging part, we'll finish the development phase and begin to evaluate our business rules in parallel, leveraging JNAI to accelerate the process. After more than 50 years of accumulated roles, many are outdated or no longer weighing us, so we expect the JNAI to support us in identify, analyze, and modernize them faster than ever before. And who knows, reinvented 2026. We hope to return here next year to share how our journey has progressed and the new findings we've discovered along the way. So as you look ahead to what's next, it's also a good moment to reflect on what have you learned during the way because every step in this transformation, every challenge, every experiment tells us something valuable that others can also apply in their own journeys. If there's one thing we've learned is that transformation doesn't happen in isolation. It takes trust, collaboration, and. Keeping the requirements at the center of your decisions. Build a strong foundation was essential to make speed and scale possible. And never stop testing your ideas, understanding how each AW serves best fits and performance in your specific use case. Remember, complex solutions aren't always the best solutions. Always think about the trade-offs in operation, observability, and cost. Practice first, simulated, measure, and validate the outputs before going to production. That's the best way to move fast and stay safe. And none of this would be possible without great partners. Great connections make all the difference. These have been our key takeaways. Collaboration, experimentation, and shared purpose, that's what drives a real transformation. Well, When companies share the common cultural principles, it leads, uh, endorsing partnership from us, GFT, AWS, and ITAU, the customers always come first. Yeah, we saw, and you know. Customer obsession is Amazon's first leadership principle, and you saw that happening when the WDB team updated the service doing the support case that it opened for them, and all you will benefit from that. Yeah, so speaking about continuous improvement, Amazon is giving more than 1000 free digital courses, lab simulations, and training developed with the service teams. Uh, they are also included some select or reinvent launches that you are seeing these days. Scan this QR code and give it a try. And now to wrap up, I hope we've given you good ideas for your own projects. I know that your time is valuable and we are really honored to have you here in this session. Please. Um, elsewhere the survey for us, it's really important to, for us to check how we are doing. And we will be available outside if you want to talk something more about the architecture, architecture, ask questions, go deep dive in, anything. I hope you have a great reinvent, make connections, learn a lot, and thank you, everyone.