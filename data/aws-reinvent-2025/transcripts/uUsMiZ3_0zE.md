---
video_id: uUsMiZ3_0zE
video_url: https://www.youtube.com/watch?v=uUsMiZ3_0zE
is_generated: False
is_translatable: True
---

Hi, everybody. Uh, thanks for being here. Uh, we know that investing in travel and investing in being here is no small thing. So welcome to Las Vegas, welcome to Reinvent. We know that customers have this expectation. Around where their data is, and ISVs have this insane covenant. That you are holding and handling customer data on behalf of that customer. If you're doing it on AWS there are some very definite ways to not only secure customer data, but to provide the necessary assurances and transparency so that customers can form independent opinions that you're doing the right thing and over time. My name is Peter O'Donnell. I'm a principal solutions architect. I've been with Amazon Web Services for just about 10.5 years. This is my 12th reinvent, and I'm joined today by Jen Reed, another principal essay who covers one of our largest and most strategically critical ISVs. So we're gonna talk a little bit about what this means to protect data, and where cryptography plays a role in that. In the history of what it means to manage keys. We have come a long way from very expensive, hard to manage, cumbersome, single tenant, gigantic HSMs that live in your own building. To a much more flexible cloud-like capability with AWS KMS, our key management service, which does still indeed have very expensive KMS HSMs behind it. We talk about why customers care about bringing their own key and what BYOK means, because as it turns out, we've overloaded that term in our history. We talk about two different ways of approaching what it means to protect and secure customer data with customer keys. And then finally, Jen is gonna show you some really neat software, some code that we've developed to give you an example and a taste for what it takes to implement these things. So I mentioned that we've overloaded the term BYOK. In the beginning, we had a very large and important financial services customer who demanded that we create something that was a big red button, in their words. And this became a feature known as import key material. If you're familiar with KMS there's this idea of a cus customer managed key, a CMK. And you think about it as a key, and it has a key ID and it even has an R, an Amazon resource name. But the CMK is not the actual key. The key is a notional construct, and there is in fact key material within it. The original BYO feature allowed you to import your own key material into that thing, and that was actually not the interesting part. The interesting part is that we allow you to burn that key material instantaneously, while keeping the construct of the CMK. That allows a customer to hit that big red button. Remove the key material from inside of that CMK but later reimport it and undo that big red button. What we're primarily talking about today when we say BYOK is allowing customers to have their own key material and their own key to protect their data, and that is the high order tenet. The high order tenet is that customer data ought to be protected by customer keys. This is the expectation that the engineers have. This is the expectation that the executives have. This is the expectation that regulators and other third party stakeholders may have. It's a very simple, straightforward idea. If it's customer data, it should be protected with customer keys. And indeed we take that tenet very seriously in our own services. When we store and process data on your behalf. Across dozens and dozens and dozens of such services from databases to file systems to the object store and everything else, we allow our customers to protect their data with their keys. And so is ISVs, same covenant, same set of expectations for largely the same reasons. So Slack was one of the first big ISPs that really got this right. And you could imagine, if you use Slack, and we certainly do, there's a lot of confidential stuff in Slack. Whether it's messages, the contact data itself, exchanging files, and of course Slack these days can do lots of other really interesting collaboration things. But this idea of what it means to have your own key is often perceived differently by different customers. We generally take it to mean that it's a customer CMK in a customer account. That is shared cross account to the ISV to make use of, and that's what we're gonna talk about. So when customers think about this problem, right? I think it's important as ISPs that you understand where they are coming from and why they are asking this of you. I need to have my keys, protect my data, and I mentioned this idea of the big red button. That because of this strange role, where you are handling and processing customer data on their behalf, that's core to your business, it's a covenant of trust. But customers still will very often believe that they need a big red button. So that if you have an event, or they spill something into your software, which depending on what you're using, if it's logging, everybody who's in the logging business should know about log spills. The customer will want a mechanism. A mechanism to immediately disable access to that data, and that's the big red button. But there's also dimensions of assurance that are required here. Customers want to observe how you are using the key material over time, and how you are implementing the covenant of what you agreed to on paper, or what you agreed to in a meeting. And that's also part of what it means to let them use their own key. On AWS we log almost all of our APIs into cloud trail. And I say almost all, because there are data plan events in S3 that's actually something you have to go turn on. But KMS logs everything. All encrypt, decrypt, generate data key, describe key, there's a bunch of other APIs are in cloud trail. What's interesting about KMS is that if you use it cross account. That a calling principle in one account, using S3, but references a key in another account, we output two events. Identical events, but into two separate trails. The trail of the calling principle. Which might be your ISV service account. And the trail that belongs to the account that holds the resource, that is to say the key. And customers really like this. So you'll still have your own cloud trail where you can see your use of the customer's key. But because the key belongs to the customer in the other account, they will get corresponding cloud trail records as well, and this is very important. I mentioned, you know, this idea of the big red button, but disabling and revoking access. Customers want to be able to also control the life cycle of that key, maybe give you a new key after a period of time. By thinking of this way and uh building this support into your products from the outset, you can support that. Oh, we're gonna start using a different key. Sure. Go into the settings control panel and change the arn of the key, and of course make sure you properly authorize it. And there's also compliance dimension to this. Whether it's compliance with an external entity, like a regulator or anything else, or even just internal controls compliance. That being able to protect the data is not enough, you also must be able to tell that story and provide assurances over time. In an international market, the idea of data sovereignty becomes even more important. Especially in Europe now and increasingly in jurisdictions all over the world. There is again, this heightened emphasis on the core tenet, that my data should be protected with my keys. And that can help lead to data sovereignty outcomes. And third party stakeholders also love this. At the beginning of my career, I worked for a very large bank through AWS. I worked for AWS, but they were my big baby, my customer, and they made a clear decision early on that all data in the cloud would be encrypted. Today, that's a very normal thing to say. 10 years ago, it's actually pretty revolutionary that they were gonna A, move a bank system or record to the cloud at all, and B, demanded ubiquitous encryption. But today, this is table stakes. And if your product doesn't support these capabilities, There will be customers who will see that as a gating decision, a purchasing gating decision, that if they can't have their data protected by their keys. They might not buy. So, the motivation for you is, as I just said, that this is table stakes. Having been here since 2015, I can tell you when this wonderful customer of mine of ours first said this, ubiquitous encryption, it was a big idea. We didn't really have ubiquitous encryption at the time, 15, in 2015. Today we do. But that also means that your products must as well. And even if you support encryption, you need to be able to tell a rich story, that if it's just an encrypted file system. And there is no separate authorization, once the file system is mounted, that that may not solve your customer's requirements either. Now the good news is, customers tend to trust AWSKMS. I can tell you firsthand, a lot of the first part of my career here was explaining to customers how KMS worked. Explaining to them the HSMs, the design of the HSMs, our regulatory position as it regards PIPs or anything else. And now, customers generally support KMS. They like its characteristics, they like that it comes from us, they like that it's Phipps validated now with the 140-3, which is the new program that succeeded 2, and at level 3. And if you're not a Phipps nerd, it doesn't matter. Just, just know that those are the table stakes, but we have it. But achieving this kind of compliance coverage is really critical for customers. Especially as they tell their own story, their data that they are holding is protected by KMS. Why wouldn't their data that you are holding also meet that same bar? Now what's cool is that Camus is really flexible, and it's lovely. And it integrates with all of our managed services, and you can integrate it with your own software. In the second part of the presentation, Jen will kind of show you what that means, because we have built some really nice SDKs to make this easier for you. An SDK for database services that even allows a little bit of searching over encrypted data in Dynamo. And an SDK for just general encryption. So general client side encryption, whether it's a blob or anything else. We've got some SDKs that integrate with KMS, but they certainly don't lock you into it. One thing that General will show you is that you have alternatives for the key provider. Again, it works out of the box with KMS, but if you wanna hook it up to something else, you certainly can. And so KMS solves a lot of problems for you. The soul of what we do here at AWS is what we call undifferentiated heavy lifting. And so we've already figured out how to scale KMS, how to keep it healthy. It is our highest level of SLA. We deliver KMS at an SLA of 5 9s, and in fact the reality is significantly more available than that. There's already transparent and uh rotation built into KMS where we will uh increment the underlying key material, and just a lot of genuine value that comes from the fact that you're integrating with KMS. So there are a couple of different kinds of CMS. That all has the top layer, the KMS APIs, then there's the second layer, which is where the keys actually live. The best solution. For effectively all customers is regular KMS. Where the key material is both generated within and used for cryptographic operations within KMS multi-tenant HSMs. And again, these things are the real deal. They are bespoke, they're built to our design, and they are Phipps validated. And point in fact, the entire box is Phipps validated. It's not just a little widget inside of a plain vanilla server. The entire widget is a validated Phipps module. But there are some alternatives that will be relevant for your customers. Mentioned earlier that the original definition of BYOK allowed for imported key material. We call this an imported CMK where the CMK, the construct. Exists with the KPI, but the key material is injected by the customer. Some customers came to us and said, well, I can't quite convince everybody that a multi-tenant HSM is a good idea. I think it is, and I'm an expert in this stuff, but sometimes people are like, what do you mean a multi-tenant HSM? And so we offered our alternative. We have a cloud HSM product that is in fact a single tenant HSM and you can graft that thing onto the top layer of K KMS and that's called custom Keystore, and it does exactly what it says. If you've got a stakeholder or a customer stakeholder who absolutely can't accept using a regular KMS, you can hook Cloud HSM up to it and get that outcome. We built another thing that we're sure we don't think anybody should use. But we built it because customers demanded it of us, which is practically the reason we build anything. And that's called XKS, the external key store. This allows for sometimes what you will hear referred to as HYOK. Hold your own key. The cool part about the cloud is that we do all of the impossible part. From the ground, to the concrete, to locking the doors at night, all the way up to the stack. Some customers, whether because the requirement is placed upon them by a third party, or because there's somebody in the security org that needs a warm blanket, which is an OK reason. Believe that that key needs to live in a building that they control. It needs to be in my house. All right. We'll build it, and we built it. This allows you to have an HSN that lives in your own office building, but is hooked up to the front end of KMS and that's called XKS. Probably don't let people do this. It comes with scaling, it comes with availability characteristics that are going to be radically different than good old regular KMS where we do the scaling and the availability for you, but it is out there. But the good news is, as you build to integrated with KMS, your customers still get all this flexibility. That you yourself as the ISV don't really need a reason about this part. But it will be relevant for the conversation. So, let's do a quick primer. I think a lot of people think they know what encryption is, but as it turns out, encrypting data is the easy part. All you gotta do is combine a data key with data. And then you get ciphered data, encrypted data. That is categorically the easy part. That's what you're probably already doing. But the problem is, what do I do with this data key? Where do I put it? How do I keep it safe over time? And the answer is that you combine that data key with another key, and you encrypt the key with a different key. This is known as wrapping, wrapping like a present. So you're gonna wrap that data key with the KMS key, and now you have an encrypted data key. So where do you, where do you store that? Well, as it turns out, the right place to store it is just store it with the encrypted data. You store the data encryption key. I'm gonna start calling that a deck. You store the deck, wrapped with the top key that lives in KMS and you put it in one package, and then you put it somewhere safe, like S3. Question is, well, uh, you told me, Pete, uh. Start, start with a deck, you've got a data encryption key, then you gotta protect that with another key. Great. Uh, is it turtles all the way down? What do I do with the KMS key? And that's where we come in, we do the rest of it. And if you wanna learn about all the full key hierarchy of KMS you can find that online. It's actually a pretty interesting story. We take care of all that other hard part. And of course, we protect your. KMS keys at rest by encrypting them again and then there's a whole thing and it kind of is turtles all the way down, but it ends in, you know, printed out paper that if we ever lost curb power, we could turn the stack of turtles back on the hard way. We've never had that, knock wood, but we do have a plan for that. And so that's what the primer for encryption is. We call this pattern of unique decks that protect data. With decks that are then protected by a high order key, envelope encryption. And this is the way all of it works at at AWS. This is the way you should probably do it as well. And Jen is gonna talk about this idea of a key ring, about starting your own key hierarchy with a key that you get out of KMS. So, That all sounds great. Now we know why customers care. We know what they're looking for. And we kind of understand, OK, envelope encryption. How do you do it? How should a customer let you use their key material to integrate with your software to protect their data that is in your hands? There's a couple of simple ways to do this. If you're just writing objects into S3, just do cross-count key sharing. End of list. But if you're holding a multi-tenant database with individual customer records. It's a lot more complicated than just give me the arn. And if you've, depending on the nature of your ISV, if you've got your own data plan. And it's not just a relational database, but perhaps a much more complex data plan that it's it is itself probably multi-tenant. Now you've got some very interesting complexities. Complexities around availability, complex complexities around persistence, cos the only thing worse than losing data is losing a key, cos losing a key is like losing data. Except even harder. So how do customers share their keys with you? So there's 3 ways to do this. If what you're doing is primarily just interacting with AWS resources, that is to say you're not in the weeds of your own data plane in a multi-tenant data plane, just do it cross account resource sharing. It's one of the oldest tricks in the IM book. You write a resource policy that goes on the key, we call that a key policy. And you delegate effectively, a service principle that belongs to you, the ISV. So, service. Acme Corp.com. Is allowed to call for encrypt, decrypt, generate data key and describe key. That's the simplest part. Some customers think, well, or some ISPs think, well, no, what I really want, what I really wanna do is assume one of their roles. And then use that tax as the key. No, why would you do that? Don't do that. Just do cross account resource sharing. Now, sometimes vendors are like, oh well, I'll call this BYO key, BYOK, and I'll have all the key material. And there's a key for Alice, and there's a key for Bob. But it's not really bring YO key, bring your own key if you do that. Customers don't get the logging visibility that we talked about, they certainly don't get the big red button that we talked about. And so your customer's level of trust in the eventual solution that you're going to market with can be greatly affected by the choices that you make here. We want you to be successful. We really want our customers to be successful. And you guys are our customers, but often your customers are also somehow our customers. And so we want you to do this the right way, which is why we're here having this talk. So as it turns out, crossing out key sharing is really straightforward. Resources on AWS have their own policy document, called a resource policy. And when you're talking about S3, it's often referred to as a bucket policy. If you're talking about KMS it's called a key policy. And as it turns out, this is really straightforward. Statement, allow principle that belongs to Acme Corp. Action. Encrypt, decrypt, generate data key, and describe key. Pretty straightforward stuff. It's key to understand, ha ha pun, it's essential to understand that you're only going to get authorized for the cryptographic operations. That you do not need and nor should you ask for other actions on the key. Those ought to belong to the key owner, your customer. Cos some of those actions can be really powerful. Disable does exactly what it sounds like. You don't need the ability to call for disable on the key, and you should not ask for it. There's a couple of other very powerful actions. Put key policy. You do not need that, and nor should you ask for it. And perhaps most powerful of all, there's an API called Schedule Key deletion. We don't actually let you delete it right away, cause that's a very serious foot gun, but scheduled key deletion. You do not need it, and you should not ask for it. All you need is very simple, write on the key. Encrypt, decrypt, generate data key and describe key. Now, how do you get this going? How do you kind of bootstrap this new customer on boarding? It's probably enough to just publish some Jason. This is what it needs to look like, copy and paste it on your key policy. Your sales engineers can probably do this for your customer during onboarding or ramping or whatever. You could probably give them some cloud formation, which would create a key, and then put the right policy on it. And lots of other ways to think about this. You wanna give them a terraform thing? Sure, whatever. But you should be reasoning about this, because it's essential that your customers not only get it right so they can start receiving the benefit of your software, it would be dumb to delay time to value just because it takes a week to figure out what to put on the key policy. And you want your customers to get it right, for safety and security. Because if they give you a loud KMS star. You now have too much ability. For all the things I just talked about, schedule key deletion, disable, uh put key policy. Don't let them give you KMS on the key policy. Only take the actions you need. Everybody knows the phrase least privilege. Make sure you get least privilege. So, there's a couple of different patterns, ultimately. What I just described is really simple stuff, like if I'm gonna put an object in S3, I wanna protect it by your key, all I have to say is put object key, key ID. But there are some more interesting and complex ways to do this than this idea of a data key broker. Where you're going to start your own key hierarchy. From the customer's KMS key. And then, as you say ingest log files or create, you know, whatever kind of unit of entity in your data plan. You can take that envelope encryption pattern and add one more layer. So it's KMS key to customer key, customer key to data keys. And you can add one more layer too, depending on what makes the most sense for you. This effectively again, is a key hierarchy, and the data key broker pattern here is a simple way to do that. So as customers upload data. There is certainly this idea of crypto wear out, you don't wanna use a single deck, a single data encryption key for a colossal body of data. That's got blast radius problems, and at hyperscale, there's a theoretical cryptoanalytic problem with that. Like if you go and create petabytes of data with a single deck. It it creates an entry point for an adversary to do something like reverse the key, and you don't, it's very easy to avoid that by not encrypting everything with a single data encryption key. And the workflow kind of looks like this, I don't know how visible this is to you, but, you know, these slides will eventually get published on the internet. But this is effectively what the flow looks like for this idea of the broker. So there are some more questions about this. How do I request and deal with the data keys? How do I deal with multi-tenancy, and where does this kind of solve? And again, this is where our encryption SEKs come in. They're open source, they're available for a handful of very popular languages, Java, Python, things like that. And it's awesome. It does right what it says on the tin, it's written by a group of experts, and it's open source so you can understand it and reason about it, and maybe even improve it on your own. For client-side encryption There are a bunch of questions. How do I properly implement it? What modes should I be using? And again, the SDK is almost definitely the right way to answer all these questions. The SDK has a message format. It's pretty flexible. You can even get multi-region resiliency by registering either using multi-region keys, which is a new thing we introduced 2-3 years ago, or you just have to take uh the data and the and the wrapped data key, and it's wrapped under 2 different regions. So if it's in Oregon, you can unwrap the deck in Oregon. There's another version of the same deck that you can unwrap in Virginia. There are, there are two of these. One is the general purpose ESDK. This is suitable for blobs, right? Whatever it is, a lump. For database specific applications, particularly Dynamo, which is probably the right data store for most things, but it certainly works for the relational products as well. The database specific SDK has some additional considerations built into it. And again, these are expert level software packages. They're both open source, they're maintained by a really brilliant group of people. The ESDK is designed to make it easy for portability so that you can deal with these things. There's a, again, a way to register multiple key providers, so that if your customer expects you to be available in both Oregon and Virginia, just as examples, that there's a way to do that. The single message format makes it really easy and a high speed to deal with. I mentioned this idea of like, where do I store the wrapped key and where do I store the encrypted data? And I said the answer is put them together, well, the ESDK does that. It automatically puts them together. And ultimately, you kind of only need to keep track of two things. One, that lump. The data and where the key is, the key provider, which is not the deck because the deck is with the lump, the encrypted lump. The key provider is, you know, which KMS KMS in Virginia, KMS in Oregon, because of course, like most things at AWS that will be region specific. This is what that kinda ends up looking like. This is a little bit of an overview, it's a little bit of a. There's some details left out of this for the simplicity of the diagram, but this is basically what that looks like, that you call through to uh the ESDK. The ESDK calls down to the operating system to get the right crypto. Every operating system is gonna know how to speak AES GCM, which is a. An implementation of AES. A mode. And again, we get the blob that comes out, what's in the lower right there, where you get everything necessary together. Um, I mentioned this idea of a hierarchical key ring, and this is where I'm gonna turn it over to Jen. Uh, there's a deep explanation of this, and practically everything I said is examined very deeply in our documentation. So hopefully this is a pretty good primer. This is a code talk, and I'm gonna turn it over to my friend Jen, who's gonna get into it. Cheers. Break a leg. As you start to OK. Now for coat. Very good. I hope everybody can see that pretty good. Yeah, um. Visual Studio is your friend. So, um, how many people in here understand Java? OK, so this will look familiar to you. um, so this is, um, basically a Java application, um, that was written called Beer Store, which is an example, um, application, but what has been done here is actually constructed it to actually show, um, the hierarchical key. I wanted to start by just looking at, um. At how, uh, that, uh. Those tenant data keys are created and then from that we'll take a step back to understand, um, where that's stored, uh, in Dynamo and where that's declared and then from a step back from that look at the actual KMS so you can understand where the KMS ID, uh, and those components are configured and declared that then get called down here but just so that you can understand the context, really seeing it from this perspective. So, um, if we look down here, um, the most important part, uh, here is, of course, um, you're gonna have canvas credentials, of course, um, in this implementation, um. This is, so when you're onboarding a tenant, each tenant's gonna get, um, their own KMS, um, ID, their own, um, client ID and credentials. So this is so that each one of your tenants, whether it's, um, will be able to understand from, um, a process perspective, uh, which one is used for which key because in, uh, for SAS providers, you want to make sure each, um. Customer that you have, each tenant that you have, are actually being able to manage their own keys independently, um, not all on one cycle. Uh, we scroll down a little bit further here, uh, on that onboarding process, uh, you, each of those is, of course, going to get a branch key, um, and then it's gonna have their credentials. And, uh, within the application that's going to call it. And then when someone is offboarding, um, because we are going to cache those in Dynamo, um, and then they will age out. So the caching and default here is set to 15 minutes, uh, but it becomes deactivated within the application they can no longer use it and then it comes out of the Dynamo DB system itself. So you can see that there after it has expired. And if we scroll down here and of course, you're gonna see, uh, for the rotation of each of the keys. So, of course, if you're going to have customers managing their keys, you want them to manage the rotation of those keys and each customer is going to, of course, have different expectations of what that rotation cycle should be based upon what their internal compliance or, um, security program requires or compliance program requires. Uh, then scrolling down, we can see, um, Uh, how you might want to handle, um, uh, multiple tenants' data at a single time. And so here's a key ring, um, it's a multi-tenant key ring, um, handling multiple customers at the same time, but each of those are cached, um, separately and each of, uh, those, um. Data streams, one can't read the other because each of those data streams, even though it's being handled by the same process, each of those data streams are only really readable by the encryption and the encryption keys stored for it. Makes sense? And then, um, here at the very bottom is if you, if you have a customer and so you can support both mechanisms, uh, because setting up and establishing and maintaining KMS can be a bit of a, um, a process there, um, and so, uh, you can, um, from, for most customers' perspective, when you're setting up, um, key rings and setting up those KMS keys, holding them from a multi-tenant perspective, like the upper example here on 2. 08 makes a lot of sense, but if you have a customer who's like, no, I really want my CAMS to be in a single tenant, and it's only ever in the process with only my, um, data, then here's an example of that just with a single tenant, uh, within, uh, that key ring being handled at one time. So there's two ways of doing that. Now, if we take a step back, remember I said that in the Dynamo DB how, how, uh, that expiration works. So here is actually setting up, uh, that data key broker. For the Dynamo DB table, and so you can see how, uh, each of those for actually setting up, um, that those data objects is established. And the important part down here is, uh, really understanding the coordination of those keys for each tenant within Dynamo. And then when you're actually rotating them, um, setting up your intermediate keys, and then, um, of course, down here is where you're actually setting up. Your key ID, uh, and the branch ID which is per each tenant, and then the encryption context, uh, and the actual credential provider that's being called and can be defined, uh, in the other Java object we'll go into next. And then for that branch key request, how that's being called. And once again just explaining, um. The, the default time, which is here, how long you're going to hold on that delete. And the actual sample application is 15 minutes. It can be 5 minutes, it can be 1 minute, how long you're going to hold it cached. Um, and that caching. Will be if, uh, someone deletes it, um, it will then no longer be in Dynamo after that, uh, but it, it may mean that you're going to make the request to Dynamo more frequently to refresh your cache. So you have to hit that parameter of how long do you want to cache for, because that will be when something it's marked for deletion when it'll actually disappear from Dynamo. But that also just means you have to res you have to be querying Dynamo to actually refresh your cache. So it's really like what, what is the application you're doing and what does that mean from a deletion perspective and letting that that guide that now if you have most of your customers are, are happy with say 15 minutes or 5 minutes, but you have one customer that it needs to be a minute, then in that instance it might make sense to have most of them under the multi-tenant aspect and then have the other one on the single tenant aspect that has that more reduced time frase so that you can handle their refresh but not have to be refreshing every tenant's, um, keys at the same cycle. Does that make sense to everyone? Excellent. Uh, so if we take a step back from that to actually look at the KMS, uh, client, so here you can actually see, um, how it's actually, um, establishing from the SDK, uh, setting up the individual, uh, KMS in keys, scrolling down, um, that then the service client will actually use, um, when the application is running. Any questions? It's pretty straightforward. A lot of our, um, security and observability, uh, customers use us as well as some of our business, um, Business apps, uh, so like Slack or, uh, Zoom and some others also use the same sort of concept and really it's about how do I expose that so the customer's providing access appropriately to the KMS so, um, they're not having to like plug in the arm. Uh, uh. Peter was explaining earlier how uh you can give them cloud formation scripts uh to do that, but, um, on November 19th of this year, uh, pre um reinvent the IAM team, um, announced, uh, partner managed delegated permissions and so which actually makes us a little. A little bit easier and the fact that, uh, within your app your SAS application, you can make a request via IAM. Now, in order to register, you have to provide policy boundary templates that are approved by AWS to the IAM team, but what that is is a scope down policy. So then from your SAS platform you can make a request to. Um, on that, uh, on the customer's behalf to the administrator or the user with the appropriate permissions, um, into IAM for that administrator to approve or deny. And what that does is then from then you can. Actually update the permissions via cloud formation or terraform leveraging that temporary delegation to actually say deploy a role or deploy, um, sharing of KMS, right? But it can only do that to actually do it that one time. But then after that point, say if, uh, I know we, we talked about encrypt, decrypt, and generate key. Most observability and security providers tend to just need decrypt because they're not encrypting the key. They want to decrypt it so that they can read it and then store it on the side, on their side. In the data stored that they're using, but they don't necessarily they wanna wrap it in an envelope on their side then they make the request back to actually read the data using your key, so using that cross account role, but they never want to do actually any physical encrypting or you wouldn't want to do any physical encrypting of additional data because that can be a bit risky, um, or generate the keys. Using their uh key, the customer should always generate those keys. So there are different things you wanna think about from your applications perspective in the design. What do you really need and is it something you just need in order to set up, in which case you can use a partner delegated, uh, permission request for a one time action, um, and then with polic with, uh, permission boundaries, or is it something that you're going to wanna, uh, um, a general rule for, for, uh, encrypt or decrypt or generate keys. But there are ways you can um spread that out so at any one point in time, um you can give that granular access to your customer but what I think is really powerful um is the ability for you to then make those specific requests and policy statements so the customer can make those um choices, um, so you're not having the friction of having them. Go talk to the DevOps person to provide the script to the template to the right account. It'll initiate it in the appropriate account for that appropriate admin to approve or deny. So I think, um, combining these capabilities together gives you the ISV the ability to help customers be able to bring their own keys but do it in a way that makes the most sense, um, and always encouraging our ISV partners to build on AWS so you can use uh KMS where appropriate and then still if the customer does have, uh, an on-prem key store being able to access that by leveraging the KMS construct to to import, um, as well. Any other questions? Yes, with branch keys, um, do you see any pushback from customers who are like super hyped up on er ability where you know you're, you're kind of caching the key, not showing up just logging because, yeah, uh, uh. I think you can have a patient conversation with the customer to explain so the, so the question there is, right, with branch keys because you're not going back to KMS every time, you're not gonna get KMS Cloud trail events for all the cool things. True, I think customers, I'd like to believe, maybe this is me being a naive solutions architect who always believes I could convince something, convince someone of something if I'm right, but the question is ultimately. If you want hyper scale and performance, you can't emit logging every time you touch something. I think It shouldn't probably be at the top of your list, but you could admit your own logging. 100%. You should always permit for being providing the telemetry and those actions because it's also in here. I scrolled past it, but you're also logging the number of times your application's making use of that key. Um, and then of course that would be, you know, emitted in your, uh, logs of your application, but, but I would tell you, you know, the, the question of caching anything is like because this also maybe undermines the big red button, right? If I'm, if I'm caching, if I invented a new top key. And I've got that clear top key. The big red button goes away, a lot of things go away. Uh Your colleagues in your security team in your application security team and the people that are doing with your socc report should all have strong opinions about this, right? uh. Caching is one thing, committing that top key to non-volatile storage and clear, right? There's a lot of things that of course you should not be doing, but yes. Yes, uh, I just want to add one more thing. Kevin Lee, one of the product managers for KMS. Yes, so, so much so I see there are some. Can we make sure that you still have permission to call on the customers. And if you know the cashing basically flu, the time frame that they promise was their customer for 5 minutes. Right. Yeah, that's a really interesting point. I think the point that Kevin's making there is that there are some out of band ways to check to see if you still have the authorization in the first place, and you could use that as a signal to drop that cash, right? Should I repeat that back? OK. Time to ask some questions now I, I couldn't hear. Should we do more questions? Yeah, huh. The, the question is, should we do more questions? Yeah, 100%. Ask your questions. For a and uh we have large providers. You're looking at bring your own. Debate between you know the security team and you know our strategy how to protect our data it's not like. Especially So yeah so. Uh, some of the conclusion that is coming. Bring your own key is just a security because essentially. The. I. The only way we can provide Good if you hold your. Because that time is. Hm. And third party provide. some What you guys Well, I mean, so like you could that that was one of the examples that we showed is you own your own key and um or hold your own key and here it's each of the processes has access to it but the admins don't have access to the processes themselves. So it's kind of it's one of these things that um it might be a digression but I happen to do it a lot uh it's when we're talking about AI and agents people like to think of them as people and and I beg you stop thinking of them that way think of them as processes, right? And if you think about them as processes because that's what they are, um, then it's making sure that. That process ever has access to that component and how do I architect a solution to ensure that process only has access to, uh, that data and those keys and another process never has it, nor can it hand the data over, right? I mean, the notional idea of ownership, right, without pulling apart the ontological concept of ownership, if it's the customer's key in the customer's account, that to me is as strong of an ownership model as if it's in their own building. You know, I work here, but I'm very passionate about it. You own your data. So if you put an object into S3, is it any less yours than if that same file was in a file system in your building? No, it's absolutely still yours. I think XKS, as I kind of kidted that earlier, is a warm blanket. But to me, it is still very much your own key if it is in your account and the ISV has cross-count authorization to make use of it. The main point is this, it doesn't give you extra security if you own the key. as long as the third party. doesn't mean it's secure. I think that's the case. Well, I, I mean, but, but, but that's a, but that's a path that leads to, well, you don't own your own data if you're hiring an ISV to process the data, and that, that can't be true because then none of you would have businesses, right? Like, so the boundaries of ownership. To my taste, uh, if you're accepting the idea that you're gonna hire an ISV to do stuff with your data. You are already through that looking glass. You are already asking them to touch your data, and that's also where you start to say, make sure if they're gonna do any processing on that data, what security and compliance have they gone through, you know, do they have ISO certification? Do they have a confident SOC 2 program? Correct, um, I like to go further than SOC 2, but to each their own table 6. Uh, but, uh, but, uh, because what that does is you have a third party auditor coming in and validating those controls that are put into place, um, that they're handling the data and making sure that the employees never have access or, are never in the processes themselves never write out data that isn't and not any of that activity is logged in which you have that telemetry, yeah, but, but I think I heard you say. For so long as the ISV has the authorization to use the key, you've got a security problem. I can't accept that because again, I hired the ISV to touch my data. Right. And also it's a that's why I was saying it depends on what your application's doing. So if I'm writing something and I only ever write, then I should only have encrypt, right? On behalf of the customer and generate the key, right, and generate the key if all I'm ever doing is reading it from, say, your, uh, a SIM or detection and response, I should only ever be able to read it. I should never be able to actually write it or generate a key for it. And so making sure that you understand what the action is and making sure that you don't give permission beyond that and there's an appropriate permission boundary, uh, in place in addition to those things. Well said. Yes. Oh yeah, 100%. Uh, so how do you deal with, uh, different customers with different requirements? Like, I, I, I, I get that some customers are gonna be, oh, I wanna hold my own key. I, I wanna do it in KMS, and I'm, I'm an avid AWS user, so that's fine. Well, others are gonna be, I don't know what you're talking about, and I don't use AWS. I don't have an account. Uh, how, how do you usually do? I, I think my short answer to that is. Build to KMS And if customers wanna hold their own key, there's a way to do that with KMS, and it's abstracted. Does that impact how you interact with? It has, it doesn't it, it doesn't change any of the API contracts. It XKS, the expert for key store where it lives in an HSM in your office building or data center, uh, it does have implications for performance. Right, uh, if you're operating a peta scale data lake with 1000 nodes banging on it and, right, and you have to go back to the HSM every time. Or you have to go to an on-prem HSM going over a network connection and you have a really small caching time. I mean this is where it starts to become important, the caching discussion just like in for uh a database itself, you know, you sometimes have to cache the most frequently asked things and that's why you set a time to live. Same thing for DNS, um, you set time to live because I need to cache the fully qualified domain names. Now if I have very dynamic, um, IPs. And for low balancers and things like that, my time to live is probably in seconds, right? Um, but if I'm sitting at the top of the name space, my time to live might be 24 hours, right? And so it's really understanding that from, um, a KMS perspective, um, and architecting that in a way that makes sense based upon where the customer. Determines where they want to how long and where it's being stored and you as the provider. That's why I'm saying like it might be for that really particular customer, it's that bottom example and that time to live has to be longer because it's on-prem and I have to take into effect the fact that every time I clear my cash, I'm gonna have to pull it back and then I need to make sure it's distributed, right? And so I have to architect to account for that. But to summarize the answer. The characteristic of the key XKS custom key store, regular KMS does not change API interactions. It can change performance characteristics and availability characteristics of the results. 100% and that's why I'm saying it's like. That's why I'm saying that the multi-tenant one above, most of the time that makes sense, right? If I have one that then is that particular customer is gonna be on-prem from they wanna hold their own key, I am not having that impact the other tenants. Does that make sense? Yeah, I see that on the onboarding side there's gonna be lots of different processes for different requirements, yeah, yeah, you know, onboarding a new client. Yes. 50 questions please. So, I'm used to thinking in terms of data and a key encryption, so now my data is crypted. We talked about rotation of the. And I'm having trouble getting past that that hurdle of now I've got a petabyte of data that's. So we, we are very opinionated about what rotation is and what it is not. A lot of people think of rotation as if I rotate, then I'm gonna destroy the previous key, which necessitates re-encrypting all the data so that it's now protected by the new key. That is not how we do it. Historically, I'm, again, I'm very opinionative about this, let me get through this quickly. Historically, you rotated for two reasons. Number 1, humans had access to it, and now that human left the building. We don't have that problem with KMS. Nobody ever touches those keys, not even us. There is no way for us to access your key material. The other reason you rotate is crypto wearout. I use the same key for all this data, and now I need another one. The envelope encryption pattern addresses both problems. That the blast radius of an individual key is necessarily very, very narrow because it's typically per resource or per file or whatever and there are no, there is no such thing as getting the key out of KMS like there's no API to get key material you can't export. And even if you could, you couldn't make use of it. What we do when we rotate is, I mentioned earlier that the idea of the CMK, that the RN, is itself effectively a vessel. Inside of that is the real key material. If you turn on rotation on a periodic basis, I think by defaulted, uh, year, and did we ever lower the period for that? We did. There you go, 30 days to 7 years. I should, I should, it's very hard this whole week there's gonna be new things and it's hard for us to, um, that at that rotation period we create new key material that will be used for future. Encrypt and generate data key events, we keep the old key material. Because if we didn't, we would have to go re-encrypt a giant body of data, which is expensive and time consuming and really hard to get right because of edge cases. And if we got rid of the key material, it'd be very dangerous. So when we rotate, we just generate new key material that is used for new cryptographic operations, but we keep the old one, right? And it's really important because if ever for like that's the way why the retention for 7 years, um, is, uh, if you ever have to go back in time to go look at data from a period of time where it was previously written, you need to be able to read that. That's right. And so that might be something that's historically stored in in Glacier, but it's still attached to that older key for when it was created. So then when you need to access it, you, as the, the owner of it, when you're, when the application's making the call, can still, it can go a little back on that point in time. Let me let me restate the two big punchlines though to this topic. Number 1, the envelope encryption pattern takes away off the table the reasons to even think about rotation ever. Full stop. Number 2, we have a rotation thing that you can turn on and make somebody an audit happy. Uh-huh. And you don't need to worry about how do I then go back in time and use the key that goes back and does that. It's being taken care of for you. But if you encounter a new data encryption keys and we're gonna wrap and all the data you should that that person is wrong. Uh Mention A. see Councilor. Be. The same one. So that guy was there. Now the commission is coming. so we have That's where I might move on. all the data. Yeah, so what is the solution to that. So what I think I heard was. You've got a kind of set of competing interests, right? You wanna encrypt everything, but there are trade-offs that you want to work around. Let's talk about some of those trade-offs. The classic one is searching, right? The that's the biggest problem. If I wanna have a column and a relational data store of taxpayer ID, Social Security number in this country, uh, but I also wanna look up customers by taxpayer. It's not a great way to do that. There are Vanguard cutting edge homomorphic encryption options that are just finally starting to really become real. Uh, there were some talks this week. We hired a trio of cryptographers, this lovely interesting group of people that have worked together for 20 years, uh, Tul Rabin, Hugo, uh. You know, I'm gonna blank on their names, which is embarrassing. Robert and the crypto. Yeah, but the the searchable encryption thing is out there. You can kind of search across encrypted fields these days. It's not super high performance. Uh, I wouldn't put it in the hot path for a really high TPS application, but there are some ways to do that. Deterministic encryption for particularly narrow key spaces like a Social Security number, like a credit card number can be super dangerous because. Social Security numbers are super predictable. If you know where, when and where someone was born, you've already lost half of the Social Security numbers very predictable. Same with credit card numbers because of CVV2, there's like an internal checksum to the format of a. Uh, credit card number and the first six digits belong to banks. And so the key spaces get really narrow really fast, which means it's trivial to create a rainbow table of all possible values. So you gotta be very careful with deterministic encryption. Mhm. It's getting there. It's getting there. But again, it's, uh, the larger the field is and uh, if, if the cardinality of the field blooms like a free text field, then it all the promises fall apart. If the cardinality of the, of what of the encrypted payload that you're attempting to search across is relatively finite, the solution works much better. But if it's like I want to encrypt all the notes from the call center but still search it, no, that's not gonna happen, but. Could I encrypt addresses and still search across it? Yeah, probably. And the database SDK implements this for Dynamo. That's available today. Searchable encryption in Dynamo is available today. It's, uh, again, it comes with a pile of asterisks that you and your engineering team want should investigate, but it's cool and it works. We have customers using it. Yeah, With the, with the AWS database encryption SDK. Yeah, it's pretty cool, uh. And you should have your account team follow up with us like the team that is working on this kind of vanguard of exploring stuff is very interested in talking to customers and hearing use cases. Right. yeah. You for. Yeah, have your account team tell your account team you're interested in having a conversation about homomorphic encryption. If you search the session catalog for homomorphic, uh, you'll find the sessions. Uh, I'm pretty sure Tal and Raj are talking about it this week. Tal Rabin, who leads that trio, uh. This trio of cryptographers, they all have Wikipedia pages if that helps contextualize who they are and what they're about, um, yeah, we're, we're doing some really cool stuff there. All right, so, um, we've reached the end of the time. The red light is flashing, so, um, thank you all for coming. I hope you found this very, um, informative. Um, please fill out the survey and, um, and let us know how you liked it, and, uh, we look forward to talking to you guys more. Cool.