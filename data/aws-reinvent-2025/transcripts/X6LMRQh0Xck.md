---
video_id: X6LMRQh0Xck
video_url: https://www.youtube.com/watch?v=X6LMRQh0Xck
is_generated: False
is_translatable: True
---

Welcome to day one of reinvent. If you have not already been to a day one events before, this is the day you realize that there's more in Vegas than just its casinos. There's also a day you realize that your biggest friend is are your sneakers while finding rooms in Vegas, and there's also a day you realize that jet lag is real, OK. So just raise raise of hands. How many of you are jet lagged already because you are already, OK, I see a lot of it, that's nothing to be shy about. I'm jet lagged too and I am in central time zone. OK, so I can understand from people that are traveling all across the world. So this session is not about jet lag or your shoes or your Vegas or the need for chapstick, yeah, or the need for chapsticks either, OK. So this session is about building falter and messaging systems using AWS services. A quick show of hands, how many of you are using or planning to use an AWS messaging service in your workloads in any shape or format? I see. OK. Glad you are in the right room. Trust me, this is the talk on AWS messaging services. So, on that same note, let me ask you another question. How many of you have been, you know, had to handle. Outages in your messaging systems, and you have to be called in the middle of the night, middle of your weekend, or middle of your non-working hours. Uh, to handle a complex issue, I see one there. I see a few more rising up, OK, over there, so, yeah, hopefully this session and the learnings from it help you to not be in that situation anymore. So with that, let me introduce myself. I'm Parna Bassak. I'm a senior solutions architect helping out our public sector customers adopt AWS for their needs, and I'm a developer at heart. With me is Tom. Tom, hi, my name's Tom Romano. I'm also a senior solutions architect. I've been working with Parnub for about 5 years now, and we are both members of a serverless technical field community. And I'm also a member of the analytics technical field community in data engineering, we use these patterns a lot as well. Awesome. So, what do you mean to say, Tom, is you can imply this if you're running a data pipeline or a messaging service. You can imply all these patterns there. Yeah, fantastic. So you get 2 for 1, OK, like all the Black Friday sales, buy one, get one free. So there's a BOGO offer. OK, let's go with what we have in plan today. OK, so we're gonna talk about very briefly, OK, uh, about. What the AWS messaging services are, the patterns of it. Again, this is a court talk at 300 level at that, so most of the time. The hopeless Tom is going to life code in front of this big enough audience, OK, without using generative AI, OK, and please say a prayer for him. Uh, and let the demagogues still be with him during the latter part of the session, and then I get to get the easiest part. Talk about a slide deck, right? So we're gonna talk about, uh, some of the resolution considerations you should worry about while designing messaging patterns and systems. We'll talk about patterns, which is the highlight of your talk, and then. Code and of course Q&A again keep those Q&A coming would need some time to deploy so that's the time that we can ask for any feedback questions talking about your architecture something that you have learned would be useful. So with that, uh, let's level set, OK? You might be already using these services. You might already have used these services before. So if you look at AWS messaging services, this deck probably encompasses everything. So we have AWS Native services, and there is a bunch of those. We have event stores, we have event routers. You can look at simple queuing service or Amazon SQS for. 54 queues, standard queues, etc. or if you're willing to go use a topic-based system for pub sub messaging patterns, you can use Amazon's simple notification service. If you're looking at a streaming service, Amazon Kinis with all its variations does give you that streaming interface. And if you're looking for an enterprise service bus for point to point integrations, you can look at Amazon Event Bridge as well. Then comes another set of services that we call the AWS managed open source services. What we have done is taken the open source code and given you as customers, as users, as developers, and access to those through a manage interface so that you don't have to worry about setting that yourself on an EC2 instance. So this comes in two forms. You have Amazon Message. MQ or message queuing services, it has to support for both the rabbit MQ and ActiveMQ. So if you are building those hybrid architectures, bringing in your existing rapid MQ or active MQ over to AWS, you can look at Amazon MQ as an option. And then you have Amazon managed streaming service for Apache Kafka. Again, that's a mouthful of a name, so we call it Amazon MSK. Also gives you that managed platform if you are planning to use Kafka with your architecture. So just a quick raise of hands, uh, how many of you are using. And AWS native Service. I see a few there, a few here as well. How many of you use a managed open source service? OK. Just by count of hands, roughly, it seems there's a more uh inclination to use an AWS Native service which is perfectly OK. Both of these patterns are good to implement depending on what you are doing, but during our talk we're gonna use more of this AWS Native approach, but we will also sprinkle in some ideas about manage open source services too. So everybody probably knows what an architecture or components of a messaging service looks like. You have a producer, you have a consumer. As simple as that. In between you have a messaging service that can be a router, that can be a topic, that can be an event bust, it doesn't matter. If you look at this architecture, when you talk about resiliency of this architecture, because nobody wants to get pinged at 12 a.m. at night. You have multiple points of failure. Your producer can go bad, it might not publish messages, which is a good thing. You don't have to worry about the message coming in. You don't have to worry about any residency. Then they might still be alive, but they might start pushing messages which may not be in the correct format, which is a problem. Either they have not been communicated. That there's a change in your messaging pattern or structure, or your most senior developer has made the most simplest of errors by making a field mandatory in the messaging service. Your messaging services can also go down because of either persistent errors or transient errors. And then lastly, your consumer can also be downed because of some networking problems or somebody forgot to deploy a service, although the CICD pipeline said it is deployed. So during the talk we're going to talk about all these patterns and all these areas of failure and address them through architectural patterns. To talk about it, the first pattern that we're gonna talk about is the 10 letter Q pattern or the DLQ pattern. And what this does is you have a producer, in this case I'm using Amazon SQSQ as an intermediary messaging service. Then you have the consumer too. So if your messages are erroneous, you can configure an Amazon dead letter queue, which is nothing but a simple standard queue to push those messages to this queue. You can implement this very easily in your existing application if you have one. All you have to do is define a dead letter q, and even certain services like AWS Lambda has the option to configure dead letter queues in case lambda you're able to pick up lambda, it's not able to process certain messages because of certain issues, runtime, code issues, bugs, etc. and they can be pushed over to a standard SQSQ configured as a dead letter queue. Now, I always have a problem with calling this as dead letter cues. These messages are not dead, OK, so somebody perhaps took this reference from the old postal service systems where messages were being or letters were being sent and there was no recipients or incorrect address, so they didn't know what to do. In this case they are not dead. I rather would call them error message queue. So that you as a developer, you as an administrator, you as a business owner can intercept those messages either manually or through a systematic way and then republish them back to the SQSQ by collecting them. Typical examples, let's say somebody has made a field a mandatory one. OK, let's call it the ID field is mandatory, which was not previously. So anything that does not have an ID can be sent back to the producer and then you can put in an ID, an arbitrary one to go process it, and then that read drive happens, uh, sorry, readri happens back to the original SQSQ for it to be processed. Again, Tom is going to walk through the dead letter Q pattern through his code. We'll look at what configurations you need, what permissions you need in order to configure dead letter Qs. Has, has anybody implemented dead letter Q in their application before? Wow, well, I shouldn't have talked about this at such a length. OK, anyways, for folks that didn't use it, probably you get some value add as we talk about this during your code implementations. The next pattern is what we call as a retry with a back off pattern, OK. So this is particularly important for transient errors that your message bus or your transient or your consumer might end up having. A typical example, let's say you have temporary networking failure or you have uh overload of messages where you end up having service quotas because of an erratic, um, producer producing too many messages. So in this case what you end up doing is you kind of configure and back off with retry with an exponential backoff pattern in which case you are we are publishing subsequent messages with a time difference between them so that each subsequent message is delayed to the matter and why you do it, the primary reason for doing this is you are giving sufficient time for your message service or your consumer. To keep up to its healthy state before it can go receive messages. So that's the high level idea. Anybody using this uh retry with back off pattern. OK, I see a few folks all across. Thank you for using it. Certain services already have this inbuilt. For example, SNS, when it's trying to publish messages to multiple other endpoints, has re try to back off by default configure within it. Lambda also has this when it's receiving messages from S3 or publishing to other services like SQSQs too, you can of course overwrite them as you want to, but that's a very neat option to have it already configured as a part of it. Now, let's talk about some persistent errors. We talked about transient errors, those appear and go away without you doing much, OK? What about some use cases where you need where you see the producer or the consumer having more transient errors? So for example, if your consumer ends up having pertinent errors which is not recoverable and which are not temporary, then you can employ something called a circuit breaker pattern. What the circuit breakup pattern does is if everything is fine. The circuit is closed. Take an example from an electrical systems, but if there are issues like a persistent error issue with the consumer, we call the circuit being open and what you can do in this scenario is. You can use services like AWS step functions or even lambda functions which Tom would be going to show during these code demonstrations to push them to an SQSQ again as a temporary store and then have an Amazon event scheduler which is going to pull from the messages from that queue and then re-drive them back again. Uh, back to the consumer. So in this case the circuit is open, open, uh, it's, uh, it's not handling in its irregular state, but you have an option to do health checks, understand when the consumer is back up and open, and then redrag those messages back to the original consumer. Anybody implemented circuit breaker pattern. OK, I see one. So if you look at the patterns, DLQ had the most adoption, uh, going by back of with to try being the next best, uh, circuit pickup packet with the third one there. OK. Let's see how far we go down the route and see how far the adoption rate is currently. But you may not have one consumer. One consumer circuit per capita works perfectly OK. What about you trying to push this to multiple consumers? So in this case I have two consumers and you want to have a distributed transaction. And what I mean by a distributed transaction is your messaging service wants to push this to 2 consumers, and both the states of the consumers should be committed in order for the transaction to entirely be successful, right? So you have two local transactions, one going to consumer one, but in this case, let's say the consumer 2 is unavailable because a junior developer is doing a deployment out out outside the green zone, OK? So what happens in this case? You have a system where it's inconsistent, meaning your consumer 1 and consumer 2 are out of state, and that's not an acceptable solution. So what you end up doing is. You kind of do this with step functions that you push or pull in in between the messaging service, and step functions knows how to compensate the transaction. What I mean by it is if step functions understands that your consumer 2 is down, what it can do is it can do a compensatory transaction, reverting the comment made to consumer 1 and then store it again. Either in a database system or in a totally different queue or maybe even a DLQ, OK, or maybe it might do a backup with retry pattern as well. So those are options and solutions that you can go implement and what we call this as a saga pattern. Specifically, a saga orchestration pattern because we are orchestrating between two consumers here. Just for a fun fact, this game. The naming of this pattern came from the fact that a saga means a big long epic story, where each of the characters are episodes within the story, unlike consumers here. Again, in soft in software engineering we seem to always find non uh. Get examples from non-software things like electrical systems, post offices, and now epic stories. Anyway, moving on to the last pattern before we get into the code is the redundancy pattern. In the rare uneventful case that your infrastructure, your messaging service may or may not be available because of a not a fault on your side, you can definitely look at the redundancy pattern. Certain services like Amazon MQ Message Broker allows you to define an active standby pair wherein you define two Amazon MQ brokers in two separate availability zones and then have an EFS file system connected to it. What happens during this scenario is if the primary goes down, the standby can be quickly activated. If you need more higher resiliencies where you cannot afford the time it takes to pull up the standby, you can definitely look at a multi-region, multi availability zone. Active NQ setup, in which case you are looking at a network of brokers that are distributed and deployed across all these regions to enable zero downtime. So with that, I will conclude my presentation, OK? I hope this was. Understandable and this is a good segue to look at code, OK? Tom, why don't you take it over? OK, yeah, let's take a look at some code. So before we dive into the code, what I'm hoping to show you today is that implementing some of these patterns can be done fairly easily without really affecting your main application code. And to demonstrate that, I built a little coffee order processing system and it's very straightforward. I can put in my name. I can put in my coffee order. I can submit my order and if everything works, which it did, yay, um, then a coffee is submitted and then I can go look at my coffee order history. Pretty straight getting coffees or it's just a no, no, this is just a demonstration. We're getting virtual coffee, simulated coffee, and I'll refresh the order history. Ah, the demo gods are just not working with us today. So, I know why. Should we start by praying to the demogods before? OK, what should, what should, what should the prayer be? I know I would do this with regular gods, but I'm no way. There we go. Yeah, yeah. OK, so, uh, we got our coffee order, so we're good to go. Awesome. Look how quickly I fixed my demo. That was So, let's take a look at what the uh architecture looks behind the scenes here. So this is a pretty straightforward consumer. We've got, uh, the producer is my application that I created. It's going through Amazon Gateway, which is my API front door. It logs a message directly to SQS and then immediately returns, so I get very fast response to my front end. It's all decoupled. This is good event-driven architecture 101. Yeah, we could have any broker here. I'm just gonna use SQS because it's convenient. And then our consumer in the background is a lambda function which is a serverless compute function that is processing the coffee orders and as part of that it does two things. The first thing it does is it sends the payment out to an external payment system. And then it will place the coffee order, which for now just places the record in a in a database table. But our external payment system often goes down for maintenance. Anyone have this problem? Yep, OK, so. And it typically goes down for maintenance during a reinvent talk. So, we'll simulate that too. So for example, Just to demonstrate this, I can. Inject a fault. So I'm gonna do a fault injection. And break my payment system. And then when I go to order and I'll order a part of a few coffees, yeah, I want that coffee FYI without being paid. I will get it after the presentation. I'll submit a few orders. OK, you notice that the API responses are going through. But when I go to look at order history. Parnub is not getting his coffee. The payment system is down. Coffees are not happening. So, we need to evolve this architecture to accommodate for this. And not only is part of not getting us coffee, but let's look at what's going on behind the scenes here. I'm gonna go look at my observability and cloud Watch. And you know, I, I submitted my coffee order, boom, great, that's how it should look, OK? But when I look at my message numbers, look, I only ordered 3 coffees and look at all these messages. Every 10 seconds I'm getting another 6 messages. Wow, that's a lot of messages for just 3 coffees. Imagine if this was like Starbucks with thousands of orders. I can see that my SQS depth is staying at 3. Those 3 messages are just getting recycled over and over and over for those 3 coffees. But what's worse is what's happening with lambda. For 3 cups of coffee, look at all these invocations. Invocation, by the way, is the area underneath the curve. I'm getting lots of lambda invocations and. Those invocations are for 30 seconds an invocation. That's my timeout on my lambda functions. So what's happening? I'm spending a lot of compute and getting nowhere. It's just cycling over and over these messages, and I'm not getting my coffee as well, and you're still not getting your coffee. It's, it's still gonna be a while before you get your coffee. We're, we're just gonna improve this first, OK? So, from a cost optimization standpoint, I don't want my system to go out of control in a failure situation. I do not want it to go out of control. I want it to land well. So that's why I want to add. The DLQ. So I'm gonna add a little bit of architecture here. As part I mentioned, I'm gonna add a DLQ. And so that when a single message is retried 3 times, it will be automatically moved to the DLQ. The other thing I want to do is be able to re-drive those messages back into the main order queue when my payment system comes back up. This sounds like a lot of work, but it's really not. And that's because there are features built into SQS that can really help us. With some of this implementation, so that I really don't have to modify my application much. OK, code, yay. Let's not look at that. So, Uh, I've been using Quiro. I don't know if, has anyone been using Qiro? I'm like really into it. I was a VS code person before. Yeah, that's awesome. Nobody has used Quiro, OK, which is great, and you get to see a live coding, how Quiro performs, and you can download Quiro, upload Quiro in your comments too as we go down. Kiro, yeah, Kira is available now. OK, so behind my application, it's infrastructure is code. Can everyone see that OK? It's a little hard. Yeah, it's folks in the last row, see that OK, thumbs up. Cool. OK. Just wanted to make sure, oops. So, This is my queue. This is my current order queue. That's where the coffee orders all go. And to add a DLQ, what we do is we just create another queue. And you could do this with anything, any other messaging service. And uh. Yeah, I actually, um, I just hit pound and Kiiro said, oh, do you want a DLQ with this? And it's like, thanks. So. Yeah, we'll take that. I'm not gonna argue, but let me walk through the code. So, I'm gonna create an order DLQ which is a standard SQSQ, nothing special about it. Except my message retention period. is 1,209,600 seconds. Or 14 days. Why did I do that, Parna? I want to get coffee for the next 14 days for free. Oh well, not quite that, but I need to give myself time to recover. OK, yeah, so I wanna give myself the time it takes to notice that the system's down and recover the system. So I'm gonna let this queue messages sit in this queue for a longer period of time. OK, well, that's great, Tom. You've got a DLQ now you got to go modify your application, right? Nope. It's built into SQS. So I can go back over to my normal SQSQ and I can create a re-drive policy. And when I create a re-drive policy, Wow, I don't have to type at all, do I? Um, When I create my redry policy. You specify two things. First, where you want those dead letter messages to go, What queue? And I want to send them to my order DLQ. And then a max receive count, which is like, how many times do I want to retry before I move them over to the DLQ? And, you know, give them a couple of tries, give them 2 or 3. but then move them over to the DLQ. And uh yeah, Carol really helped me out there. Now the other thing I need to do is granted some permissions and not really wanting to type in front of everyone because I never had a typing class. I'm just gonna uncomment this, but basically what I'm doing now is giving my functions access to. The dead letter Q. And we'll see why I do that later. So just giving some permissions. And then the final thing I'm going to do is send the dead letter cues. Name and URL or ARN and URL over to my lambda functions and environment variables. That way, my lambda functions now know about the DLQ. They don't have to yet, but let's just do that. That's it That's all you have to do to your application. But now we do need a redrive function, so we need to be able to recover this. So I have a lambda function that's already kind of a shell. And this lambda function. is not implemented yet, but if you can see on my screen. This is the main logic of it. It comes in. And I have this class called Test Payment with Canary Success. This is part of the pattern you want to put in your re-drive. The first thing you want to do is see if your dependency is available because one thing you don't want to do is re-drive or send all those messages back to be processed. If your downstream system is broken. So, do a check, do a canary check. Make sure that system is healthy, and if it is, great. Once I'm sure that that's healthy, I can then re-drive the messages. And to do that, I'm gonna use a feature of SQS. SQS has the ability to pick messages up from one queue and deposit them into another at a rate that you specify automatically. You don't have to do it manually. You can just tell SQS go do it. And so we're going to use that functionality. So I am going to type response, just so I have a place for the response of the API call. And no matter what language you're using. There is a AWS SDK. With a SQS client in it. I'm using Python, so I've got BTO 3. And I'm going to use the start. Message Move task. This is the API called the SQS that'll move messages from one queue to the other, and it takes just. Two really parameters that you absolutely need. Which is source queue URL, that's where to move the messages from, and destination queue URL where it's to. Now, Generative AI is often helpful, and sometimes it's not, and it has reversed how I want to do this. So, I want to move things from the dead letter queue to my order queue. And I don't want to move just 10 messages. I really want to move them all. There's a different parameter I want to use here, which is Sorry, we just went out of my head. Number of messages per second. Number of messages per second. There we go. And this specifies how fast you want to move everything over. So I'm gonna do it. Actually, I'll just do it at one message per second and I'll spell it right. There we go. And then Last thing I'm gonna do is I'm just gonna make sure that it actually started that task and so I'm gonna say. Uh, It returns a task handle. And so if the task handle is in the response, I can say that the re-drive task started successfully, otherwise, it didn't. Any questions on that? Pretty straightforward. So basically what you're doing, Tom, is you're trying to re-drive the messages back from the DLQ to over to the actual queue, assuming that the consumer is now back alive. Correct. OK, yep. Yes sir. Can you show us the canary's success? 00, the, uh, the success check. OK, yep, we can do. The question is, uh, can you show us the can we success check how we are doing it in the original code again? This is Python, but again, I think that's the most, uh, easiest language to understand. So if you are a developer from other languages, just follow us along. There are equivalents of these available in Java.NET, and so this is, this is my canary. And what the canary does is it sends a test order, an order that the payment system will ignore when it receives it. But it's basically full of testing it out. It's sending an order for 0 just to make sure it's like a heartbeat check, and I could do a lot with this. I could find out what the delay is. I could. You know, measure latency. I could, yeah, see what the response time is. Um, so basically, I've negotiated with the payment system to ignore this particular test message. And I can send it whenever I want. The best piece I love is the amount is 0.0. That's the only thing that matters. Yes, that's what I'm doing. TTL being managed for you and so you don't end up getting a. Yes, there was. Oops. So the question is, is there a TTL for the loop for canary to ensure that you're not checking the health of the system too many times? so the message doesn't get retried. use them. Ah, OK, yeah, moved between keys, uh, a number of times. So when I did the redrive, do you want to repeat the question? So the question was, how do you stop the messages from constantly bouncing back and forth between the DLQ and the actual Q? And that's really taken care of in the retry logic, in the redrive logic, by ensuring that the system is ready and able To handle those messages before I send them back to the order queue. So I verified that that order queue will work and will process those before I send them over there. And that's key. Uh, sometimes I, I've, I've seen implementations where they don't do that, and yeah, you get a bounce, bouncing back and forth. What if there's a problem with the actual message itself that the logic is going to result in. Uh, what if the problem is with the actual message itself and it continues to get bounced back and forth? That's a very good question. OK, so the way we have implemented one of the best practice there is. There are two use cases that you can do multiple DLQ patterns. One is for messages that need manual intervention, either from developers, assignments, ops, etc. to be able to make a correction on those messages. That's a separate DLQ. And the other DLQ can be a queue where you are just parking the messages in order for them to be processed later when the source system becomes healthy. For example, in this case, the payment system becomes healthy. So that's a divide and conquer approach. You cannot just have one single DLQ to handle everything from manual intervention, schema mismatches, or service unavailability. OK, so I deployed my DLQ and I'm gonna show you this, but then I'm gonna show you another kind of view of this. Um, remember that we had ordered some coffees and they were, they were bouncing around. Well, as soon as I deployed my DLQ, it's starting to get back under control. You can see that the numbers are starting to dip down, but let me show you a maybe a cleaner view of that. So here's the behavior with DLQ. So first of all, I don't have that continual bouncing of messages. Things get under control relatively quickly. But the more important story is what's happening with lambda. Yes, I'm getting a few executions of 30 seconds. But not continuously. I'm not getting lambda storms. I'm not spinning my wheels trying to, they're moving over to the DLQ. And even though Parnob still doesn't have his coffee, right. I don't You still don't have your coffee. And this is where we, again, pray to the demo gods. We're gonna do a re-drive, which gave me an error, so I wasn't able to show that on that. But what we would do is we would re-drive it right over to the messages. Not wanting you to be. Left without, let's do a redrive demo. So Basically what we're going to do now. is with the DLQ. We're gonna take the messages that were in the DLQ. And use the redrive function. To re-drive them back to the event queue. So we'll break the system, order a few coffees. Submit that I'll submit a few. So DLQ test needs 3 cops now? Yeah. And I don't get any. You don't get any. That's not good. OK. Yeah. We see the system behavior gets under control quick. The messages drop off quickly. Our lambda function is in control. So a little bit of processing there, but not too bad. Now I can go fix my payment system. And re-drive the orders. So it starts the redry process. If I go look at order history, we start to see it starts to re-drive those messages. One coffee a second, so there's the 1st order. The 2nd order has arrived. And they're all coming out of the redrive queue. It's that's a demo about how it works. OK, uh, before we move into the next pattern, any questions? Is there anything that we are missing here that we should be implementing? Yes, sir. Uh, SS have Redrive. I'm an operator and I see some stuff in my head letter to you, my re-drive and the guy's broken. I just need something back. Uh, so the question that has that, is there an option in the console, uh, for manual re-drive of messages, uh, Back to the queue which needs manual intervention. So a message comes in probably for coffee. Maybe the coffee type was not mentioned, and that's a mandatory message. It gets pushed over to the DLQ and somebody needs to actually really tell, OK, Pernam needs mocha and not latte, right? OK. And then once you go change that feeling that what's the option to do it? You wanna answer the question. No, OK, OK, cool. So the way to do this, yes, you have this option to do this, OK, so you have, um, uh, there is a, I think it was all samples also have a utility by which you can point it to your dead letter cues in this, in the samples by which I don't think there's a direct way to make a change on the message in the console, OK? You have to create some utility of your own, and I think there are a few samples out there that gives you the option to do this where you can uh configure the. DLQ and as well as the target queue to be able to push those messages, OK, because AOS console does not give any options to make any changes to the messages to the console. It shows you the messages, the structure of it, the count of it, OK, how it looks like, but there's no other options to change them live and then be able to redirect them back again. Any other questions? Yes, sir. Go through the given them back because it's key focus. Like the age or the Get it back. So, um, what is the, the question that he has is, so how are you pulling up the messages from the DLQ to be able to push them back into the standard queue? Is it by age? Is it by count of messages? Is it by message type? Is that, did I get your question right? does it keep the properties, for example, the age is the initial age or is it the age when it was pushed back from the to the to the main. So is it a new message or is it the same and these properties? Yeah, so the message, if you, so the question that he has is, uh, let's say you're pushing in a message to the to the uh to the regular queue and that message gets pushed over to the DLQ. What happens with the age of the message, the sum of the properties there? So essentially the message is kept as is. There are some additional metadata properties that get changed for that message, but these are two different messages in two different queues there. OK. So let's say message A, original message has a time stamp of 10:45. OK. Uh, and then when you push the messages over to the standard queue or DLQ, it probably will have 10:46 at a different time stamp, but the contents of the messages will remain as is unless you are making manual changes to it. OK, so what you define as a message is important. And if order is important, if your order queue is FIFO, then your DLQ needs to be FIFO. Yes, uh, so some of the best practices there, so Amazon SQS also supports, uh, uh, first in, first out queue in which the ordering of which they were published in is maintained. So if you are original queue is an. Amazon's simple queuing service, first in, first out queue, probably our best practice is to use a similar DLQ to maintain the ordering. OK. Let's switch to the next architecture. And what we're gonna do is evolve the DLQ. Oh, there's one more question. Oh, sorry, yeah. And so of triggering Re-drive. So what are the physical practice how how Great question. I'm actually gonna show you a couple of options in the circuit breaker. So when you, uh, let me repeat the question. So what is the best time to re-drive? At what frequency should I re-drive these messages from the DLQ back to the original queue? Uh, what's a good practice there? How soon? How frequently, how infrequently should we do that? And, uh, part of, uh, you know, Tom's response, like any other essays is. Uh, it depends, it depends, and with that, uh, he's going to talk about some other architectures that talks about that in mind. Yeah, I do. I wanna extend the DLQ architecture now into the circuit breaker architecture and also I wanna start looking at self-healing, like how do we make the redrive happen automatically so that I don't have to press the button and I don't get called and then what you have is a self-healing system. That's the dream. Yep, let's, you don't want to get paid. Why don't get to that dream? Yes, so, The first thing I need is I need a circuit breaker. And I've implemented a circuit breaker for us, uh, just in the name of expediency, and it's a controlled database and I've got 4 methods here. I got a method that says, is the circuit open? True or false? Is the circuit closed, True or false, which is the opposite. Um, and then I have a method that will open the circuit breaker, which means something went wrong, and then I have a method that will close the circuit breaker, which means everything is good. Behind the scenes, it's just a Dynamo DB table. It's actually just an item in a Dynamo DB table. Dynamo DB is really good for this. It's a quick key value lookup that you can put cash in front of, so it's really good for this kind of stuff. So I've got a circuit breaker payment. Item in my database and it's the circuit's currently closed. So to add the circuit breaker. I do need to add a little bit more architecture. I don't have any more moving pieces, but I have a bit more logic. In my consumer, what I wanna do is see if the circuit's open first. If it is open, Then I don't want to process. I want to assume I'm just going to fail because someone before me has determined that the payment system is not good. And I just need to like fail fast. If I call the payment service in error. Then I need to open the circuit and send it to the dead letter queue for later processing. So I need to do a little bit more work in my order processing Lida. The only thing that they need to change in my re-drive is if I notice that the service is up, I need to close the circuit breaker and allow messages to flow again. So it's sort of the pairing of the two that open and close the circuit. I open the circuit in my consumer. I close the circuit in my redrive. OK, let's implement this. Let's do the video. OK. We've had some great questions and we're a little short on time, so I'm actually just gonna do the video of it if that's OK. So we're going to look in our order processor. And when you come into our order processor, it just asks for the payment. So what we want to do is see if the circuit breaker. Is currently closed. If it's closed, go ahead and try the payment. Otherwise, it's open. And I'm just gonna go ahead and raise my payment processing error. I'll just raise an error. So you just need to wrap your logic around a circuit breaker. If you get an error, you want to open your circuit breaker. The next thing you want to do is send a message to your dead letter queue manually. Because you weren't able to process it. And you need to catch it and you need to send it yourself. So I'm going to send this message over. And I'm just gonna send my whole order over. So I'm just gonna dump the whole order over into the message body. The other thing that I want to do is rather than raise an error and fail out of the whole lambda, I'm just gonna keep processing. I'm gonna return a stub that says, well, you can get your coffee, but you haven't paid for it yet. So I'm going to feel deprecated. Rather than fail And I've moved my message to the dead letter queue, and I'll process that payment later. And that way Parnav will get his coffee right away. Finally. So that's the only change you need to make to the order processing. Basically, check that the circuit is closed before you actually implement. And if it fails, open the circuit and send it to the dead letter Q. For the re-drive, The change is very simple. When I go to my re-drive function. If the canary succeeds, close the circuit. That simple. It's working. Close the circuit. Allow processing to flow again. And that is literally the only change I need to make to my re-drive. But we want to automatically recover, right? What we can do is we can schedule our redrive function. To automatically run. And it will check the payment processing system. So what I'll do is I'll just schedule it to run automatically. I'm just gonna add an event bridge schedule to that lambda function. And I'll have it run every minute. And I'll call it periodic re-drive. So every minute it's gonna see is the payment service up? Great, re-drive. It's not gonna re-drive anything if there's nothing to re-drive. And that will make my system entirely self-healing. Do you want to do it every minute? Probably not. I'm just doing that for demo purposes here. But that's the only change that you need to make. So coming back to his question, what should be a good redrive policy to re-drive your messages back or check the health of the scheduler depends on your system like an essay would always, always say, right? And that depends on the criticality of it. How soon do you think you need to process, for example, financial transactions probably cannot handle a per minute redrive coffee orders scan. OK, for example, I can survive without um more than a minute without having coffee, so. What's your schedule probably would depend on the criticality of the messages in there, and what do you think is your RT or recovery time objective or recovery point objective there. So what is your defined time in which you have to process messages? Yeah, we can see that behavior here. Just gonna order. I'm gonna break the system again, order a couple of coffees. The first coffee is going to trip the breaker. So I'll submit that order. So right now the circuit's open. The coffee will come through It'll go through the event queue. The circuit will be closed. It'll try the payment service. It'll trip, open the circuit, and send it to the DLQ. So if I go and I look at my coffee and see what happened and look at my order history. I did get the coffee. But I got it with the payment status of circuit open. And so I haven't actually processed the payment. It's sitting in the dead letter queue partially processed. OK, my subsequent coffees, the circuit breakers already open, those are gonna fail fast. I'll see those coffees immediately, but again without the order processing. I see my coffees immediately. But the circuit's open. I'm not processing my payments. Behind the scenes, when I look at what's going on with Cloud Watch, I can see my system stays very much under control. I get that initial push where it's trying and fails, but look at my lambda processing duration. I get that one hit at 30 seconds and subsequent hits are very fast, very efficient from a lambda perspective. Now I can do my re-drive. So when the service is up, it'll close the circuit and automatically re-drive my coffees, therefore reprocessing those payment systems. Remember that I've got the payment status of circuit open. So let's go ahead and fix our payment system. And since I have the automatic redrive happening, I don't have to press the redrive button. It's automatically going to detect that the payment service is now available again. And automatically re-drive those coffees. And process the payments. And so I still see that the coffees haven't been quite processed quite yet, because remember that I'm moving one message a second. So it's going to take a few seconds. But if I refresh again. I'll start to see that the coffees are indeed processed, and now, they're all fully processed. My system is self-recovered and self-healed once the payment system came back up. OK, so Tom, the TLD that I get from this is design your systems to be self-recordable and self-healing. Design your systems to be resilient across multiple different types of errors. Uh, it might be a messaging error, configuration, or other types of errors. What else do you think we should be, uh, looking at as takeaways from this session? Well, if you design for failure, then nothing fails. Right? Because it's just the behavior of your system, your system is able to accommodate it. It's able to continue working and continue servicing your customers, even though there might be a degradation. So again, thank you everyone for attending this session. Uh, again, if you didn't know, we have the session reviews. That you can go to in the mobile app, OK, which is super, super useful for us. Again, as you can tell, this is a brand new talk that we ended up doing this reinvent, it's never been done before, but if you like the, like the session, like the content, and and found that this was useful, please give us your. Honest feedback that is a big, big component for us to learn from your direct feedback and improve this going forward and again we look forward to uh. Meeting more of you or using these AWS services if you didn't know an AWS solutions architect, probably you can reach out to us, uh, and we will give you our numbers, contacts to help you build on AWS messaging services. But if you have to take 3 things back from this session, probably these are the 3 things. Item potent messages is something that you should really, really look at so that irrespective of you can retry, resend, republish these messages any number of times, you should look at redundancy in terms of your infrastructure, not only regional ability zone-based redundancy, but message handling redundancy too, like we talked about regular queues for pushing messages. Another cue for pushing, pushing a different actionable messages, etc. and look at your operational excellence. How are you stimulating those in your dev UAT, uh, pre-prod environments to be able to not incorporate these, uh, in your production environments? Again, these are just 4 of the architectural patterns that we had time to talk about. There are a few more that we have in mind which. We have seen some usages and applications of, so given what we have as a 1 hour presentation, we could only probably show 2 and talk about 5, talk about 4 of these. So hopefully this was a good and good session and enjoy reinvent just picked up all the fun, all the quirkiness of reinvent. Probably I find this super useful even from me being in an AWS solution circuit. Thank you everyone. Thank you very much.