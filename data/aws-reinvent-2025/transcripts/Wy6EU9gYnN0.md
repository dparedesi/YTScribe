---
video_id: Wy6EU9gYnN0
video_url: https://www.youtube.com/watch?v=Wy6EU9gYnN0
is_generated: False
is_translatable: True
summary: "In this session, Sandeep Dhingra from SAP introduces the **SAP Business Data Cloud (BDC)**, a unified data and analytics platform designed to bridge the gap between SAP's transactional systems and modern AI/analytics needs. Dhingra begins by identifying a core challenge: traditional methods of extracting operational data into external data lakes often strip away critical business context, forcing organizations to heavily invest in rebuilding logic. BDC solves this by offering **Data Products**—pre-curated, semantically rich data sets (like complete Purchase Orders or Company Codes) that are managed by SAP and stored in low-cost object storage. This 'lakehouse' approach allows enterprises to treat BDC as the primary source for SAP data, significantly promoting a 'new data economy' where clean data is readily comparable across domains.

The platform integrates core components like **SAP Datasphere** and **SAP Analytics Cloud (SAC)** while offering robust modernization paths for legacy systems. A standout feature is **Zero Copy Sharing**, which enables bidirectional data access with partners like Databricks, Snowflake, and Google BigQuery (with AWS integration forthcoming). This capability allows data teams to view and utilize SAP data products directly within their preferred non-SAP environments without costly and time-consuming physical data replication. Conversely, output from external machine learning models (e.g., fraud scores generated in Snowflake) can be shared back into BDC to enrich SAP-centric reporting. Dhingra emphasizes that this openness allows data scientists to spend less time on data engineering and more on high-value modeling.

Dhingra also outlines BDC's pivotal role in the AI era, featuring the **SAP Joule** copilot and an embedded **Knowledge Graph**. The Knowledge Graph instantiates the complex SAP data model, allowing Large Language Models (LLMs) to understand relationships between business entities (e.g., mapping a vendor's financial attributes in S/4HANA to their procurement profile in Ariba). This grounding ensures that AI agents can answer natural language queries—such as 'Show me open purchase orders'—with precision. Furthermore, BDC supports **Intelligent Applications**, which are packaged analytics solutions tailored for specific personas. For instance, a CFO might view a working capital dashboard, while a Chief HR Officer leverages 'People Intelligence' to track talent retention. These apps are designed to meet 80% of business needs out-of-the-box, with extensibility for the remaining 20%.

Finally, the session addresses the critical topic of legacy modernization. The **BW Bridge** capability allows capabilities for customers to move their existing **Business Warehouse (BW)** environments into BDC, extending their support lifecycle well beyond 2030 (and up to 2040 for BW/4HANA). This move converts legacy BW objects into first-class data products that can be consumed by modern cloud tools, ensuring that historical data remains valuable even as platforms evolve. Dhingra concludes by highlighting the roadmap, which includes growing the library of data products from ~240 to over 400 and launching a new **Data Product Studio** to simplify custom data creation, positioning BDC as the foundational layer for the intelligent, autonomous enterprise."
keywords:
  - SAP Business Data Cloud
  - Data Products
  - SAP Datasphere
  - SAP Analytics Cloud
  - Zero Copy Sharing
  - Knowledge Graph
  - SAP Joule
  - Enterprise AI
  - Data Lakehouse
  - Legacy Modernization
  - Business Warehouse
  - intelligent applications
  - semantic layer
  - data governance
---

Hello everyone, uh, thanks for coming to this session. My name is, uh, Sandeep Dhingra. I'm part of, uh, an architecture advisory team within SAP focused on business data cloud, or I should say all things data and analytics. I've personally been doing data and analytics, uh, for 25+ years and now focus on the business data cloud go to market. I actually spend a lot of time in the field, uh, with, uh, with our customers talking about their architecture, how they can use business data cloud in their landscape. I was supposed to be accompanied by uh a colleague of mine from SAP Mark, but uh he got pulled into something else, so I'm gonna try to cover for him and fill his big shoes and try my best. So talking about business data cloud, if you've heard about business data cloud or even if you haven't, it's a relatively new announcement from SAP. It came out about, uh, 7 months ago in March time frame. That's when we announced Business Data cloud. So I'll kind of try to go into why SAP created Business data cloud and then get into a little bit of what and then how, how is, uh, business data cloud works. But just to, uh, kind of, uh, lay the foundation. I mentioned that uh business data cloud is new, but business data clouds components, the, the foundational components that build the business data cloud such as SAP data sphere, SAP analytics cloud, they've been around for a long time, so it's not new technology. Think of it as a a new packaging, new capabilities added to our current uh offerings and uh uh under the umbrella of Business Data Cloud. So how or uh I should say why business data cloud. So the, the SAP strategy, uh, in terms of uh, um, the suite, the transactional applications and AI is suite first, AI first, and that's something our customers have been adopting. You guys have been, uh, looking at it and adopting that the idea is, yes, you need these transactional applications to run your day to day businesses. That's where you process the business transactions. That's where you create the data. And then in this age of AI and G AI specifically, you want to automate as much of these transactions as you can, whether that's traditional AI or whether that's using generative AI or with agentic AI now or in the future, you want to automate these transactions. So I'm sure you've heard this before good AI needs good quality data. So when you run these transactions, that data is locked in your transactional systems. Typically our customers have been extracting that data into lake houses, into data lakes, into uh object stores, and yes, you can run offline AI on top of it. That's again something I, I call it offline AI. You're taking the data out of these transactional apps. Applications then running machine learning algorithms on top of it, but you also want to enable embedded AI within these transactional applications. You want to build agents on top of it. You want to run agents delivered by SAP on top of these transactional applications. That foundation for AI is provided by business data cloud. So at the very bottom you have the transactional applications which generate the data. Then we expose that data, we make that data available to you using business data cloud, and then you use that data uh from Business data cloud into these AI applications which then run the transactions and kind of creates a virtuous cycle of AI and transactions supported by business data cloud. Now this data that is available to you in business data cloud and we call them data products, and I'll talk a little bit about it, this data of course enables AI but also enables reporting and analytics on top of it also supports your enterprise use cases that you're executing in your lake houses and your data lakes or in. Your cloud stores something like Snowflakes, something like Data bricks, AWS Redshift, or even other cloud provider platforms where you can take this data integrate it with other non-SAP data to enable your enterprise use cases which are again maybe towards reporting and could also be towards enabling AI on top of it. So again, going back to what typically customers have been doing with SAP data, it's about extracting this SAP data with third party solutions with lots of vendors out there who provide different kind of solution to extract that data and take it to object stores, take it to the lake houses. This is typically a complex process. You are extracting the. Data at the most granular level, typically at a table level, uh, an SAP data model is not simple. When you extract this data at a table level, as an example, something like company code itself has 9 different tables under it that you need to rejoin to get a complete view of that company code. So you're rebuilding that SAP data model. You're rebuilding that semantics. You are building these pipelines. You are managing these pipelines. You're monitoring these pipelines by yourself to make sure that the data lands in the object stores on the lake houses, uh, for, for and available to you for processing. It's a complex process. It requires, uh, the knowledge of SAP data models. It requires technical expertise and it requires resources to do that. So, and there's, there's of course a cost associated with it that's the reason, uh, that's one of the reasons I should say we have created business data cloud to make it easier to integrate your SAP and non-SAP data in an enterprise platform. There are other, uh, value, values that come with business data cloud, but this, especially for customers in large enterprise, that's definitely one of the significant values there. The other piece is you have this data and you want to use it for reporting. You might have some very SAP centric use cases where you're getting data from SAP applications, and when I say applications, uh, SAP applications, I don't only mean. Uh, SAP ECC or SAPS for HANA. I'm also bringing in data from other SAP cloud applications such as Conquer, Ariba, SuccessFactors. You need to integrate and harmonize that data to make decisions, to run reporting and analytics on top of that. So we are providing you out of the box content in business data cloud for that reporting, and you'll hear about. As I go forward, or you may have already heard about intelligent applications provided by SAP which are focused today on reporting, but going forward there will be standalone applications that you can execute on top of the data that is provided in business data cloud, uh, spend control tower is an example that's something we're going to be releasing soon. Uh, it's not just reporting and analysis. It's where you can take action on top of that. So again, going back to the three use cases, copying your, uh, extracting data from SAP for your lakes, uh, data lakes and lake houses, uh, enabling AI using SAP provided AI agents, your agents, or even SAP embedded AI, and then, uh, accelerating the data to decision, uh, for, for SAP centric, uh, uh, reporting. So looking at a high level overview of what business data cloud looks like, so at the very bottom you see these SAP applications again, and these SAP applications could be, uh, again they ECC S4 HANA, or software as a service applications that are offered by SAPs such as Concord, Ariba, and SuccessFactors and so on. We have built SAP data products on top of that which are managed by SAP. Data is curated by SAP. The complex joints that I mentioned earlier, that's all taken care of by SAP and you are presented a data product view of that data. A purchase order is a complete purchase order for you. A company code. The example I gave earlier with those 9 different underlying tables, you get a complete view of that company code. Same thing with materials, same thing with the sales order, same thing with general ledger items, and so on. You're getting a complete view of that data product in business data cloud, and we are taking care of the pipelines that land that data in business data cloud for you. And this data lands in a low cost object storage. Those of you who may be familiar with the HANA, uh, from SAP, uh, the, the HANA is in memory on disk, relatively expensive, but here in business data cloud we are in, uh, persisting this data in an object store, uh, and, and that's now available to you for consumption. On top of that, as, as I'd mentioned earlier, we have taken some existing solutions that we have had for a long time. SAP analytics cloud data sphere business warehouse and made those as uh components within business data cloud. You, you want to bring this SAP data and maybe some non-SAP data together and want to mash it up, want to model it together, you would do that in SAP data sphere. You want to run your analytic use cases, reporting, visualization, dashboard, or planning use cases, and that's financial planning that could be workforce planning, any kind of planning. You would do that with an SAP analytics cloud. If you currently have BW and you're using it for, again, for SAP centric reporting, you can continue to use BW. You can bring that into business data cloud also. Then we have added some additional components to that, some additional compute engines to that. One of those is SAP data bricks, so it's a data bricks uh OEM uh version that's now available to you within Business data cloud. It's an optional component if you already have your own data bricks instance in your landscape. Uh, maybe you don't need this data bricks, and since you, you will not spin it up, you will not be paying for it. It's an optional component. But if you have AI machine learning use cases and you want to start using data bricks for that, you can, uh, uh, spin up a data bricks instance under business data cloud itself. This is where, uh, this is an SAP managed instance. This is where SAP is the first level of support, and you can use your BDC commercial contract also to use, uh, and spin up this SAP data bricks. The other thing we have recently announced and we're going to add is uh Snowflake. It's called SAP Snowflake. It's the complete snowflake uh capabilities that you get from Snowflake, uh, but you can get that from SAP now. It's called SAP Snowflake. It's what we call as a solution extension. Basically it's a partner solution where SAP is responsible for uh uh providing that instance or that capability to you, which is Snowflake. SAP is responsible for Level one support, but it's still full blown snowflake capabilities for you that you can abuse along with business data cloud. And then at the top we have these intelligent applications. These intelligent applications initially are SAP delivered intelligent applications, as I mentioned. They are visualization. They are stories. They are dashboards, but we are delivering, we're, uh, working on delivering standalone applications which, uh, use artificial intelligence, which use, uh, reporting capabilities, and most important, they use these data products and the models that we deliver in data sphere, uh, for to, to, to meet your AI and analytic needs. So if you're looking at a solution as an example for let's say your working capital dashboard, you want to understand your accounts payable, you want to understand your accounts receivable, your working capital status, SAP provides an out of the box application for you, the working capital intelligent application that you can use out of the box with, with the Sfhana as an example, uh, either public cloud, private cloud, and use, uh, the, the data products provided with that and, and, uh, pretty much use them out of the box. We also have partners working on these intelligent applications, so there are partners, uh, uh, some large, uh, system integrators, some, uh, uh, other providers which kind of own their data sets, uh, uh, companies like, uh, uh, uh, that, that may own, uh, like Dun and Bradstreet could be an example that are working on these, uh, intelligent. to provide external data sets that are part of the large system integrators they're working on exposing intelligent applications uh for for uh specific needs that that they may serve uh across different industries. So these intelligent applications are going to be SAP delivered, going to be partner uh delivered, but you can develop your own intelligent. Applications on top of these data products too you can take a standard SAP intelligent application or a partner intelligent application you want to customize it because you're going to bring in some additional data maybe from I don't know, Google Analytics uh for for uh uh marketing and so on and you want to enrich that intelligent application you of course have the capability to do that. And these data products are also available to you to build any other applications that you may want to build in say Node JAS or Java or so on, uh, using SAPs BTP capabilities, uh, the Business Technology platform if you're familiar with it, which is kind of a developer platform, so you can use the same data products for that also. So imagine a single copy of the data landing in business data cloud as a data product. You're using that for intelligent applications, uh, for reporting and uh then other AI based applications. You're also sharing these data products with your Snowflake with your uh uh uh data bricks or other lake houses. As they come on board and you're also using the same data products that same copy of the data to enable agentic AI uh for your use cases too, so it's that, uh, kind of the, uh, ideal state where you're not creating multiple copies of that data for you. Uh, talking a little bit about intelligent applications, I gave the example of, uh, the, the working capital, the, um, uh, the accounts payable, accounts receivable, but these intelligent applications that we have developed and we continue to develop will cater to. All different lines of business, all different personas within an organization. So a chief financial officer would be interested, for example, in this working capital dashboard to see the status of accounts payable, accounts receivable, inventory, even, uh, but, uh, uh, a chief operating officer would be more interested in the supply chain side of things or, uh, same thing with, uh, chief procurement officer. A chief human resource officer would be more interested in. Uh, employee retention skills, the talent, and the hiring and so on, uh, so if they're, if, if you're using SuccessFactors, you, you will be interested in the intelligent application package that we have for, uh, uh, for SuccessFactors called people intelligence. So now about how, like how we are doing this. So when we started with business data cloud, we took these five guiding principles to kind of build this uh business data cloud from ground up. One is the persona centricity, which is, as you saw earlier, we are targeting all different types of personas because SAP as a business application. Uh, caters to, uh, to, to these different personas also. So, uh, on the data analytics side, on the AI side also, we are, uh, catering to the same personas here. And then the second thing is the modern lake house architecture. I mentioned earlier that the primary storage for these data products is not HANA, it's the object store. So think of business data cloud as an SAP centric or SAP delivered lake house where you have all these data products sitting in the object store that can now be shared with your enterprise data lakes also, but can also be used for AI and for analytics. And then the data products. I, I know I talked some about it, but these are out of the box data products with business context and semantics and a complete view of the relevant data out of the box delivered to you and, uh, which are, uh, uh, uh, discoverable by you. We provide APIs for consumption of this data and so on. And then of course the intelligent applications that we provide, uh, best in class analytics, uh, uh, AI machine learning, and given that SAP analytics cloud is also now part of Business data cloud. Uh, you're, you're also enabling these planning use cases on top of these data products. You don't necessarily now have to extract that data, take it into SAP analytics cloud physically. It does not need to reside in SAP analytics cloud. Data that resides in business data cloud can be used by SAC for planning purposes as you would bring in your actuals from Sfarhana, and then the plan numbers get generated by SAC planning. And get written back into business data cloud. So SEC becomes a planning engine, but everything else happens in uh in BDC. And then of course the open data ecosystem which I talked about that we have partnerships with uh uh with Snowflake I think uh if I switch uh skip a slide here we have partnerships with uh we uh when we announced SAP Business Data Cloud we went with Data Bricks to start with. Then Google Cloud partnership came along where we can share data with Google BigQuery in a 0 copy format. So Google BigQuery can access the data setting in BDC with with a 0 copy. Think of it as virtualization, where you're not, don't have to replicate that data into the target system. We announced a partnership recently with Snowflake also uh for that zero copy sharing of the data and uh we don't have it on this slide but we recently announced a partnership also with Microsoft Azure around this. I know we are at an AWS conference, so stay tuned for um for that announcement uh that will probably happen soon. I know it's, uh, it's, it's being discussed and so on, so it's, we're not, we're not, uh. Uh, agnostic to, to AWS, we're not leaving them behind. It, it's, it's something that, that's, uh, that will happen. I'm, I'm pretty sure. Um, then let's talk about the again as we talk about data products. So I talked about intelligent applications, but as I mentioned earlier, these intelligent applications address the SAP centric use cases. They take the SAP data products, but you can extend these intelligent applications with non-SAP data also. So when you're thinking of building a new intelligent application to look at your SAP data, to look at your SAP reporting. Take a look at what SAP has delivered out of the box. It May meet 100% of your needs. It may not meet 100% of your needs, but I can guarantee this, it'll probably meet 80% of your needs. You might have some customizations in your SAP system that requires some customizations on the intelligent application side, but you can, uh, that, that should cover 80% of your, of your needs for that. Uh, the self-service data access, the zero copy, that's, that's really, uh, uh, a, a big leap here. It was always a challenge for customers to get that SAP data into the lake houses. You always had the SAP team um in, in your landscape. You had the SAP Center of Excellence, and then you had the enterprise data uh uh data team, enterprise data and analytics team. And enterprise data and analytics team would just say, give me the SAP data. I'll interpret it. I'll mash it up. I'll generate the reports for you. SAP COE would be, why do you want the SAP data? Why can't we meet your needs here? So with this zero copy share uh capability that we have across different partners, kind of bridge. Is that gap, your data is still governed in an SAP landscape in business data cloud, but you can share it with your enterprise data and analytics team, and they have access to SAP data without the need to copy it over, without the need to reinterpret it and remaster the the the SAP data model. And business context, uh, and semantics is an important thing, uh, again, when we talk about business context we are talking about different, uh, not just a complete data product but also there are other associations that come with a data product. There's knowledge graph capability that is coming in business data cloud, and what that really means is, uh, when you, when you talk about a knowledge graph we are. Again, I mentioned that SAP data model is complex. We are taking that complex SAP data model and instantiating that into a knowledge graph, where when you are doing some natural language query, when you're using your large language models to ask questions with your AI tools. These uh large language models do not understand the data that's sitting in your SAP application because sitting, it's sitting in a database. With these knowledge graphs, we are creating a way for you to query your data in a smart way using these large language models. If you're familiar with the uh retrieval augmented generation where you can uh generate better text, this is a way to generate better answers uh from large language models based on your SAP data. Yes. It is a graph database capability that's built into the HANA database. So at the, uh, when we talk about uh business data cloud, and I know I mentioned the object store is the primary storage, but you still get HANA Cloud as part of data sphere, and Hana Cloud has a graph engine within that, so the knowledge graph is built in that. OK. Yes, it is an SAP knowledge base. I, I mean, honestly, who else would be better suited to create an SAP knowledge graph based on the SAP data model than SAP? So yes, that, that, uh, knowledge graph is instantiated in business data cloud by SAP, yeah. And I know I've talked a lot about SAP centric use cases, but business data cloud is open also in terms of if you want to bring in non-SAP data into. Uh, into business data cloud, if you, uh, and I'll, I'll mention two different use cases, you're very SAP centric, uh, for a particular reporting need. Let's say 80% of that data is coming from SAP applications and you're using data products for that, but there's a need for an additional 20% data coming in from non-SAP sources and that there may be a JDBC connection. Uh, an old data connection to these non-SAP sources, you can bring that data into business data cloud also typically I mean typically within data sphere within that, that's one piece of it where you can physically bring that data into, uh, uh, BDC. You can also virtualize it, but let's talk about a different use case where you have shared SAP data products with data bricks or Snowflake or other solutions in future. And now you're running what I had called early an offline AI where you're taking some SAP data, you're using it with some non-SAP data, let's let's say in Snowflake, and you're running an AI algorithm to predict uh uh uh the the uh failure of a plant component. You're using offline AI, that's again my term here to predict the failure of a particular component, but your SAP centric reports for that plant maintenance are running in business data cloud. You can share that data product that you have created out of your machine learning algorithm in Snowflake back with BDC. So when your end users look at a report in Business Data Cloud, now they also get to see what was the output of that algorithm again without moving that data. That machine learning output resides in Snowflake as an example here and you're again zero copy sharing it back into BDC. So this zero copy is bidirectional. So depending upon your use case, you may implement uh uh an AI or an analytic use case in BDC or you might do it in Snowflake or Data breaks or uh AWS in future. And that's the uh the business data cloud connect. I, I already uh talked about it is one of the things I do want to mention is that this is not an open connection where anybody can access your data or if they have the right URL or um the right connection they can just get in. What you're going to share from business data cloud is something that the business data cloud administrator or the data owner decides. Uh, if even if it's your data bricks environment, even if it's your Snowflake environment, you decide to share certain data products which then become available to you in the Data Bricks Unity catalog or the Snowflake Horizon catalog, and then your, uh, uh, users on, on that side can, can start using that. So there's security, there's governance that's built into even though we are, we know that you will be within an enterprise and you would be sharing that data, uh, within that same enterprise also. Uh, we do provide a catalog within business data cloud, so your new developer comes on board, they want to understand, they want to develop a new use case. There is a catalog where you can go and search for what data products are available to you, whether those are standard SAP data products or maybe even a custom data product that you have created on top of that. Remember, we are providing you the primary data products for in all these different use cases for all these different applications. You do have the option to create derived data products on top of that where you might be bringing in additional data, you might be aggregating it, you might be deriving some new fields from that data. So whether those are standard SAP data products or your own data products, they're all listed in a catalog and are discoverable over there. So I mean I'm sure everybody here has heard that when data scientists work on a project they spend anywhere between 70 to 80% of the time on the data modeling, the data engineering piece, getting that data right, um, uh, uh, deriving those additional attributes that they need to, and then they really only spend about 20% of the time on, uh, choosing the right algorithm, generating the output from that AI and machine learning. So imagine. Now with SAP providing you these data products, you don't have to worry about, again, I know I'm gonna repeat myself, but don't have to worry about the pipelining, don't have to worry about the curation of the data, don't have to worry about creating those data products, rejoining those different tables, and so on. So we feel you can save up to 80% of time and cost by leveraging the standard data products out of the box rather than having to move the data yourself. So what we are creating here with these data products, and I know I keep going back to data products, but this is where we are creating a new data economy. We are creating these data products across all these different uh business applications that we have, but in future we would also be creating these data products which grow which. Go cross domain and what do I mean by that? Uh, let's think of a vendor when you are in ECC or Sfhana, you're looking or let's say Sfarhana, you're looking at the vendor attributes from a payment perspective. How do I pay this vendor? What are the bank uh attributes, and so on and so forth. I have the same vendor, let's say in Ariba, where I'm looking at this vendor from a procurement perspective. Uh, I have the procurement specific attributes of that vendor in Ariba. We are going to provide you a common view of that vendor across these different domains and which will cover both the financial and. The, uh, procurement attributes of that. So that's why we are creating this, uh, uh, new data economy where you, uh, we'll have these data products again. Partners will, uh, also go and create new data products. You can of course create custom data products from scratch or, uh, built from, uh, uh, the SAP Foundational or the, uh, native data products and create derived data products on top of that. And these data products as you see on the left side, uh, they come from all these different, uh, SAP applications, but you can create lake, uh, when we say lake house, uh, the example I gave earlier, you're running a machine learning algorithm in Snowflake or data bricks and want to share that with the, with Business Data cloud, that's a data product that you are bringing on board also and then these feed into intelligent applications, your AIML use cases, and, and analytics. So let's talk about what is a data product that is, um, uh, a data product is a well defined is a complete business data set. What we mean by that, the example I gave earlier, a purchase order is a complete view of that purchase order, including the header, line items and the associated uh objects with it. It's it's a well described data product and this is really important. When we create a data product, we are not just giving you the attributes, we are not just giving you the column names and the data with it. We actually have something called an ORD. Uh, uh, description of that data product which goes into the detailed metadata of each individual element that we have within that and also, uh, a metadata around what that data product is. So it's easy to understand, it's easy to discover, and it's easy to search for when you're looking, looking for a data product. If you want to see an example, I didn't put any links here, but you can go if you want to look at the example of what SAP is delivering. You can go to our business accelerator hub, which is API.SAP.com and then click on data products. We have a complete list of all the data products that we have published so far and you'll see about 239 odd data products, I believe, um, that, that you can then also look at the metadata that comes with those data products. And then easily consumable. So whether that's for um intelligent applications within BDC or um where you want to do zero copy sharing with uh with our partners that they're easily consumable and I, as I mentioned earlier, they're of course discoverable using the um business data cloud data catalog. In terms of intelligent applications, how we are packaging these intelligent applications is primarily around the applications that we have on the transactional side. So as an example, cloud ERP intelligence Private is for S for Hana cloud, the private tradition. You may know it as S forhana RS S forhana PCE. This this intelligent package is targeted towards that. What it will have within that, uh, and what it has today, for example, the working capital dashboard, the sales and, uh, the, uh, finance Foundation, and then we will always be enhancing these applications or these intelligent application packages to provide you more and more, uh, intelligent applications and the data products associated with them. So if you want access to these data products as an example, you would still uh get access to the complete uh cloud ERP intelligence private package with the intelligent applications and the data products. That's how they're packaged together. If you have success factors, you would be interested, as I mentioned earlier, in the people intelligence package which covers different areas about Employee central, which is a module within SuccessFactors, learning skills, talent, and, and, and, uh, recruiting. Same thing with spend intelligence. If you have SAP if you're using SAP solutions for spend, you would do that and, uh, supply chain on SCM side. And then the last box, the finance intelligence there is for, uh, uh, S forhana public cloud. If you're on S4hana public cloud, you would be interested in the finance intelligence package, and I know it covers more than just finance, but that, that's how we, we just labeled it. And again, if you have multiple applications, you can get multiple packages of these and uh when we get to that cross-domain data packages, we, when we get to the cross domain uh intelligent app packages will, will deliver that too. On the right side you see a visualization of uh something from um uh from the people intelligence especially around skills that's the out of the box content of the intelligent application that you get along with uh the data products so again if you're only interested in getting the data out to your enterprise data store your enterprise lake house, you're interested in data products, but I would strongly encourage you to look at the intelligent apps, uh, as a complete stack. Uh, again, as an example of the finance intelligence, this is where, uh, different capabilities that you get with finance intelligence, but when you enable this finance intelligence intelligent application package on your instance, you're basically enabling your CFO. Enabling your finance people to kind of work hand in hand with all other areas of the business uh to to get a complete understanding of uh not just the finance but uh things that are built into uh into the finance intelligent package beyond beyond just the finance too. Now, some of you might have a business warehouse, SAPBW in your landscape, and if you're on BW Netweaver, you're probably thinking, what, what do I do with my SAPBW? uh. Some of you have moved on to BW for HANA, and that has a long uh support, but BW Net Weaver is end of uh maintenance in 2027, extended maintenance in 2030, so it's a question top of mind for our customers who are on BW like what do I do with that? So we do have a solution. We do have a, a capability to modernize your BW under the BDC, the business data cloud realm also you can take your existing. BW instance and bring it into BW Private cloud edition under the BDC umbrella so you can take your BW that you may have hosted in your data center you can take your BW that you may have in your uh posted in a cloud provider and bring it into BW Private cloud edition and make it part of BDC. Like what do you get from that? You basically at a very high level get 222 valuable things. One is. BW Net weaver in BDCs automatically supported till 2030. You don't have to worry about extended maintenance. That's, that's an important thing. You get 3 years extension for that. The other important thing is that now when your BW is part of business data cloud, you can generate data products from BW. So same data product concept that we talked about earlier. You can generate data products from your BW and land them in business data cloud. Once they land in business data cloud, they are now first class citizen data products just like SAP delivered data products or any custom data products that you have created, and they can now be shared with Data bricks, Snowflake, uh, uh, uh, or any other uh uh Google BigQuery, uh AWS in future, and so on. You would be able to share those data products and uh. Uh, use them for AI machine learning purposes, uh, cross enterprise, uh, uh, data and analytics, and so on. And in future, come 2030, yes, BW still goes out of maintenance, uh, come 2030, but hopefully by that time you have started leveraging the SAP standard data products for your, uh, new use cases. But what you have built in BW, the data that's sitting in BW is still important from historical perspective if you are. Think of AI machine learning use cases. The more history, the more data that you have, the better your models get trained and so on. So this data is still relevant to you, and you can take this data and uh keep it as an historical archive data and even for reporting purposes, your new data. Current data is coming through standard SAP data products. Your BW data products that even after BW goes away, continues to live in BDC provides you that historical data, and you can join that union, that data to, to get a complete view of historical reporting also. And this data again, the BW data products also land within the object store, so it's same uh relatively lower cost storage, um, so you don't have to keep your BW around, but you, you still have that um uh data with you. Um, one thing I do want to mention is that I said that this adds gives the value that BW automatically gets supported till 2030, but it's, it's also applicable to BW for HANA customers. If you're on BW for HANA, you can still move your BW for HANA instance under BDC. Because the data products are still valuable there, so yes, BW4 HANA is supported till 2040, but uh, you, you can still get the value of the data product generator, the data products generated from BW for HANA, and now you can zero copy, share them with uh uh with your other, uh, enterprise lake houses and so on. Another important part of business data cloud are the AI capabilities, and there's two different ways we are addressing AI within business data cloud. One is we are building AI capabilities within business data cloud, so AI is built into BDC and of course it's being incrementally enhanced. And then second, it acts as the foundation to enable AI for you. So when we talk about AI engineering now we have. Um, I, I mentioned that, uh, business data cloud contains HANA which always had predictive libraries and, uh, uh, other AI type of use cases like we have a vector engine within HANA Cloud. We have the knowledge graph within HANA that sits, uh, under BDC. So there's AI capabilities within that, but with the inclusion of SAP data bricks and SAP Snowflake, you now also have other engines available to you for your AI use cases with. Then business data cloud within the uh the SAP solution set itself, but you can also share these data sets like I mentioned with your enterprise data breaks, enterprise snowflake, and so on to so it's your choice where you want to do your AI engineering. You can do it within BDC you can do it within solutions offered by SAP or you can share your data and go to your enterprise platforms. I know we talked a little bit about knowledge graph that's uh that's an important capability again that where we um use the knowledge graph capabilities we provide the function calls based on the query that a user is writing we provide the function calls to query data within your SAP system you want to have a query like. Uh, uh, how many purchase orders do I have open in my Sfarhana system? Now, a large language model does not understand, uh, the SAP data model to say which field or which table the purchase order is stored in or which field tells me whether the purchase order is open or not. That's where knowledge graph comes in, and we provide you function calls to, to enrich those, those answers. Uh, Juul, if you're familiar with SAP JUL, SAPJUL is a co-pilot that we are delivering within all our cloud applications. With all SAP cloud applications, you have access to Juul. Same JUL is being made available within Business data cloud also. So for your transactional assistance, navigational assistance, and also for analytical assistance, you have Juul now. You may be in your S4hana system, and when you ask, let's say an analytical questions within your S4hana system, if that question can be answered better from business data cloud because business data cloud not just has S4 data but additional data also that that that is better suited for this analytical questions answer. The Juul will automatically go to BDC and bring you back the right answer, the right data set for you. So Juul works across behind the scenes. It's not tied to an application. Juul runs in our business technology platform and goes across these different, uh, uh, solutions. It's how it's visualized is, uh, that where you're seeing it in S for Hana. So, uh, the Juul capability getting your answers is will use BDC will use data products in the background for your analytical questions also. We also have, uh. Uh, uh, natural language capabilities built in within SAP Analytics cloud, which is now part of BDC, uh, where you can ask questions about show me the top performers of, uh, uh, top, uh, performers in my sales organization for the last year. You may be just in SAC as an end user looking at a report, looking at a dashboard, and rather than having that guided. Uh, experience where somebody built a dashboard and a report and so on, you can ask questions in native language, uh, with SSC that will also use the same capabilities. And then of course I talked about agents. Agents will be, uh, the SAP delivered agents will be using SAP data products and, uh, again when you build your own agents using whatever, uh, uh, like we have Jewel Studio that, uh, that allows you to build SAP or AI agents for SAP applications, they would be using data products in the background also. This is an example of the knowledge graph that uh uh capability. This is a generic example but uh like I mentioned earlier, we have um a knowledge graph that is available for SAP data model specifically in business data cloud also when you create an analytical model or the models that ship with our intelligent applications, they are also indexed within uh the, the knowledge graph and business data cloud. So as an end user, if I come in and I say. Which analytical models support the uh uh the the the sales performance scenario you would get an answer saying these are the specific models uh within BDC that can help you answer questions around sales performance for last year or so on and so forth so that that is uh is part of business data cloud also. And the example I gave earlier about automating complex business processes so you can use Juul within BDC to for transactional assistance. How do I create a new analytical model in data sphere as part of business data cloud? It's a valid question. Juul will guide you to do that. Uh, uh, transactional assistance, build me a new SAP analytics cloud story. Uh, around sales performance and, and add these metrics to that you are writing these things in natural language. Juul will help you on, on that side with the transactional and the example I gave earlier about the analytical assistance that it will go to business data cloud, uh, for, for the right questions. So, uh, what you see here on the screen, Juul is a co-pilot if you're familiar with the, um, uh, Microsoft co-pilot or other co-pilots. Juul is very similar to that. You can, um. Uh, you can pull it up in any of our cloud applications of, including SAP Analytics cloud and also in DataSphere in future, and, and you would be able to use these capabilities. So in terms of where we are going with business data cloud, what our focus areas, one of the big focus areas for us is adding more data products and adding more intelligent applications so we can cover more and more scenarios, uh, for our customers use cases. We've, we've been doing this for a long time. We know how you run your transactions. We understand your business processes and so on, so we're building these intelligent applications and the data products because uh we of course understand where that's needed as an example. Uh, we, we launched in, uh, we announced Business Data cloud in March. It became, uh, commercially available in May, and we have about 239 data products across different lines of business, and we have an aggressive target of going up to 400+ data products by the end of this year. So we, we are very actively building these data products and intelligent applications. Um, the unified and scalable data platform. I talked about the native data products that SAP is providing to you, but we also want you to have a very, uh, seamless user experience when you are enriching these data products or when you're creating your own custom data products. So we will be launching a data product studio, which will make it visually, uh, much more, um, uh, uh, much easier to create these data products from, from your perspective to create your own data products and share them or build something with it. Uh, I mentioned we've announced, uh, 4 different partnerships so far. We actually 5 counting Palantir, which was also announced at Sapphire, and, uh, uh, like I said, I mean, AWS would be coming on board soon, so integration with, uh, with our, uh, partners with, uh, you need SAP data along with non-SAP data or even bringing non-SAP data back into, uh, BDC. From a catalog perspective, we had announced a partnership with Colibra where Colibra is, uh, you can manage SAP data in Colibra, uh, through BDC. You bring in non-SAP data directly into Colibra and you get that end to end integration of your enterprise data, your enterprise metadata, and, uh, how the data flows, uh, as an example in Colibra. So that's, that's something we have delivered, but we are, uh, actively, uh, working towards more and more integration there. Um, BW modernization. So we have released the data product generator in BW, but we are also releasing additional capabilities in terms of the data product generator and also you, uh, I don't know, I'm not gonna get into the details, but semantic onboarding. So where you have your BW as part of BDC now, you can semantically, uh, for an example, take the. Queries that you currently have in BW and expose them in data sphere as part of BDC and now you can consume them using SQL endpoints using DataShere and eventually when BW goes away then you're using the data products from from BW also so that's another area where we are working in. Uh, I talked about Jewel in Business data cloud. Uh, it's, it's not been, uh, uh, publicly released yet. It's in controlled release, but that's another area where we are, uh, working on and we'll be releasing that SAP knowledge graph. Uh, it's also, uh, not out yet, and, uh, given the, uh, uh, the expanse of SAP solutions from the transaction site. We have to cover S for Hana. We have to cover our line of business applications. These knowledge graphs will go across all these. So that's another area that that we are working on. And of course AI agents, you, you might have seen, um, if you were at TechE or heard about the announcements at TechE, we, uh, released some AI agents. Then we're going to be aggressively working with more and more AI agents leveraging the, uh, the, the business data cloud capabilities. On the planning and analytics side, uh, like I mentioned earlier, the initial implementations of planning required data to be brought into SAP analytics cloud. We're moving away from that where you can have a central store of all your operational data, actuals and planning and forecast and so on, and the data doesn't need to be copied over into SSC or be written back into BDC for reporting. We'll, we're going to have a common, uh, data layer where, where, where you would be able to do that. And enterprise readiness is always a big thing. Um, I'm at an AWS event when we launched Business Data Cloud. AWS was the first, uh, cloud provider where we launched Business Data Cloud. Since then we have released it out to other cloud providers also, but there are plans to, uh, increase the coverage in terms of the regions, in terms of data centers where we make this, uh, business data cloud available also. Um, and then, of course, as I mentioned earlier, new partnerships that, that, that will be coming also. So that's all I had from a content perspective. I'm happy to take any questions that, that you may have.