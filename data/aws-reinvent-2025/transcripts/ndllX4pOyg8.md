---
video_id: ndllX4pOyg8
video_url: https://www.youtube.com/watch?v=ndllX4pOyg8
is_generated: False
is_translatable: True
---

Thank you all for coming. We appreciate you guys spending your hour with us. My name is Chris Holomec. I'm the general manager of AI and platform for Boomi and my colleague Thomas Benjamin. Uh, he's gonna be presenting in a minute. You don't have to come up, but he is a senior vice president of engineering, and he's gonna come up and talk about the technical. So we're basically gonna do talk about for the first half, really get into why governance of agents and what does that actually mean? We're really actually not talking about agents per se. We're talking about agent tech workflows, um, because that's really where you end up with the impact, um, not so much, uh, not so much agents. We'll talk about that more. But then getting into and then Thomas is gonna actually get into the technical side of things of how do you actually do this not with your with your own agents that might not be so bad, but our customers are living in multi-agent worlds they're moving in they are going to be using stuff whether it's anthropic and open AI and building stuff in lang chain and using stuff from Salesforce and Microsoft and ServiceNow and how do I actually have a common governance layer for that. Um, and do that in a way that I can actually do true workflows that are governed things like finance. Manual journal entry reconciliation, doing goods receipt, invoice reconciliation things that an auditor is gonna come through or if I'm in pharma and I'm looking at staying compliant with overall regulatory, how do I do that in a way? What do we actually need to do to become enterprise class? And that's what we're gonna get into. But first, let's talk about Boomie. So it's funny to see that because that's just from a few months ago and I'm gonna actually show you updated ones talked about 33,000 agents. That number's almost doubled today, um, so we'll talk more. Some of you guys may know Boomi really well, you're customers, you've enjoyed us for years, you're extremely passionate. And um and you're like I know all about you and then actually the other one which is people either say that completely or they're like I've never heard of you, which is fair because if you're not literally in the integration space historically you wouldn't know about us. Boomy's been around for quite a while uh we have, as you can see here. 25,000 customers, you look at the logos and you're like, I know almost all of those, yes, and that means they're actually running their integration processes on Booy if they're up here. 800 plus global partners and over 300,000 users um on our system every day. Um, people also kind of get into it and what we've been known for really of late is in the right hand graphic, which was B Gartner's Magic Quadrant, and you're taking a look at and you're hunting for Boomie and look in the top right hand corner and you see Boomie and for integration platform as a service which is really what we're known for, what people hadn't known for, which just got released, was the left hand graphic, which is now you see is one of the top 4 vendors is booming the API management space as well, um. Where we've been doing a huge amount of innovation. What I always find really interesting about these charts, most people look at them as a snapshot, and actually it's not. Everybody is innovating and working, and the requirements to be in that segment are constantly evolving. So really what this is is a window that is moving upwards with people with innovation. Those and you'll see some names you're like wow, they're not even in the Magic Quadrant anymore. Those are folks that actually didn't, they, their product just stifled, it just stopped. People stopped innovating in it. They might have done some things that didn't hit. They didn't read and talk to their customers, and then you see the ones that actually moved up into that right. That means they weren't just moving up at market speed, they were outperforming the market dramatically, and that's what Boomie has been doing. We could talk about this in data management and others in every segment, Boomie year to year is going up into the right. Now why is it, why are, why are the analysts saying Boomy is this one that's kind of on fire? Why is Boomy listing to us with the biggest companies in the industry as it pertains to AI in shortlists of like 5, you see these huge names and then you're like booming, what, how do they do that? The key to this is actually what's in the platform. So of course we have integration and automation. For those of you guys who aren't in this because you might come from the AI space or another area, integration where we're taking business processes that link between multiple systems and actually directly connecting them so those processes can can work successfully. But integration only gets you common language, common speaking. To make them work together takes automation. All the different steps in there and what becomes really important here is we're beginning to we'll quickly get into AI because that's why you all came. Was to actually start to say some things that I'm hooking up to, let's say an API it might actually be kind of a very old, old, old crud-based API. And so where I might have to actually do a huge number of invocations to achieve any given single business process, creating a customer, generating out, taking a quote to an order, which other might be multi-step integration, Boomy can change all that and make that and expose that as sort of a business level API and then we handle everything in the background. Likewise you might. Have an incredible business API which is actually then developed out and might expose too much capability for security and other reasons. You might actually want to create slices of that of capability and integration and limit that again through automation, then exposing that these become very relevant as you start about exposing APIs within. Agentic Now we get into data management. Data management is getting at two different areas. We're talking about data management in terms of data quality. How can I actually go in and start creating master data records or any object that needs to have extremely high quality, and do that using both traditional rule-based logic, as well as using agents to actually cleanse my data. And actually creating fully cleaned repositories of that information. Now that can be for an integration because we know that an integration breaks when the data doesn't align on two different places. Most companies don't have full master data management systems. IT is still stuck with the problem of quality data. They're the ones dealing with a catch block full of errors every morning when they walk in, and then manually having to fix that. The business is blaming them for having written a poor integration, which when it was really the business who wouldn't invest in clean data. But they're stuck with this, so what our customers are doing is saying, I'm gonna solve that, and I use Boomi to automatically do record cleansing, and then if they wish to synchronize that data back out to the transactional systems. But now that we're actually onto you, so we have those capabilities in there to boo with both agents and rule-based data to create cleansed data and actually store that in a repository if you want for performance reasons. The next thing that people also want to do is actually do data integration. Because we have to move the data around, this is data that is coming through web services, APIs from databases and others that I need to move, whether that is from a workday, from an SAP, from NetSuite, and I need to bring that in. Obviously that was key to being able to do that for master data management or within an integration to make sure it's working, but equally just because I have to get the data, let's. Say I want to get it into Snowflake or Data bricks or I want to get it into like an Azure, uh, you know, into a data lake that I want to work for. We have to get that done and how do I move that down. Boomy will auto generate using AI, the actual extractor endpoint into things like web services automatically just by reading the documentation so you don't have to have us support every different application out there. We do that automatically. Then we do the change data capture on your behalf to move that data through, and then it's also, it has schema evolution, so as that upstream system automatically changes, we notice that, move the data down in the data serialization format, update the downstream schema so that your integrations don't break as you're doing your extract transform load or extract load transform processes based on what you want to achieve. Now the big one with Agentic is API management, and again I said Boomi has now moved into the top of the magic quadrant for that as well, and that is because of our API control plane. You have old systems from TIBPCO, you have more legacy systems from those guys like Mule or Microsoft, and then you have the more modern systems from folks like Kong, and you have those, but now I need a common control plane in which I can manage all those from a security, from a buffering, and from. An overall security standpoint, but equally now I want to expose those as MTP servers. So how can I then expose various API endpoints, and this gets to my point that I made at the beginning about API management. You don't just take a raw API and expose it to an agent when you're trying to create context. It can't speak to a crud API very successfully. I need to actually take automation code that then brings that out, expose out that once I've created that into a business friendly API and expose that at that new API endpoint as, as an MCP server. Boomi does that automatically. Likewise, I may have one that is way too powerful. Yes, delete skim, uh, drop customer, and I don't want to make everybody have that I don't want to give an agent that ability. So I cut down the capability using my code, using, using my automation code to actually bring that down, narrow down its capabilities before exposing it as an MCP server. Then we actually get down into API um management, and this is the ability not only to create, we are not, I wanna say before I get into this, we are not an AI company. We're not trying to be anthropic, we're not trying to be open AI. What we are is a company that helps you activate AI in your business processes. How can I take anthropic, how can I take OpenAI? How can I take my own models that I've built in things like Lane chain or any of the other vendors I mentioned earlier? How can I leverage those in my own business processes where the true value lies? Now I can't do that unless I have the enterprise class features. Which means I have the security, the observability, the governance, and yes, scalability in order to do that, and that's what this whole thing is about how do we actually get all those pieces so that once I have my agentic workflows, I actually have all that in place so that I can move these into production. So Agent studio has first the ability to build agents. Agents are easy, by the way. Building an agent takes you like maybe 5 minutes on the outside. Everyone's talking about agents, ooh, you're like, they're really simple. Now to build one that automatically has built-in guardrails, lets you add guardrails, automatically is checking for things like prompt injection, and yields extremely high quality responses, even under multi-invocation with short-term memory built in. Not so easy. Boomi does that extraordinarily well. Then beyond that, we also then have the ability to then move those into our control plane. And in that control plane, I can actually take and manage not only those agents built by Booming, and again, we're not building our own models, we're leveraging the models from major vendors within your work, in, in your work. I'm then putting that into a place where I can have complete governance. I have all that observability based into it, and I have all the audit trails that I need and not doing it just for the agents built on Boomi, but doing it for an entirely huge host of vendors so I can have a common control plane and bring under control the sprawl that we've been seeing from all these different vendors and how do I begin to manage them and make sure I don't have security issues internally and that I'm also dealing with all the governance issues associated with them. And then the last point is how can I then take those agents trivially. And drop them into my workflow so they're running headless. We're all used to conversational UI's, but in the world in which I live in, it's all business processes. How can I take an agent and just drag and drop it onto a canvas in which it's part of my workflow, a mix of APIN points pulling down. Data out of web services, others I've got classic if then else deterministic logic mixed through in with agents and flowing all that data through from point of pay using data serialized format typically JSON, but whatever you really whatever you love what that which we call agent step allows us to use agents in a true gente workflow fashion. True agentic meaning I have perception. I have an agent that gets called, it has a goal, and it has tools to reach out and speak to all the different systems to build its context in order to do reasoning. So it can perceive its environment, it can pull in everything to create its context. It will then proceed through and reason through everything it needs to to come to a conclusion. We control all those instructions, then has the ability to act by then calling business processes. So yes, it can go human in the loop or human on the loop if we want to involve somebody, but if you want it directly to say, yes, I did a three-way match onside this good receipt in good receipt invoice reconciliation, notify the ERP that this invoice is good and they can go ahead and make payment. And by the way, notify and kick off the process to the warehouse management system to automatically receive the associated goods into general availability. It's exactly what our customers are using Boomie to do. So full, perceive, reason, act. And I can do, we can do that in a conversational UI, but more importantly our customers do this directly within process flows. And then again, Thomas is gonna explain how we do that with complete governance so I can be doing it in that in that workflow I just described, which is in finance where Ernst and Young's gonna show up very shortly in audit and see how you did that to make sure you have all the information. And to do that in a world where I can't not only use a booming agent but I can actually use agents from all those different vendors and I can drag them into Boomy specific processes if I wanna do that as well, uh, that comes out in about a month, um. And that's what our platform is. These are the updated numbers, 62,000 agents currently in production. 13,000, sorry 12,000 of those are agentic workflows. The 50,000 are actually people using built-in agents in the Boomi platform to make Boomie run better for them. IT doing this to write their documentation against their APIs, both technical and business, to help them automa auto gen out their entire agentic workflows, describing a problem and having to do that automatically. These things like Boomy Design Jams, so these are pre-built agents, and then we have the next 12,000 is where people are actually building out gentech workflows themselves, partners, customers, and others, and deploying those into workflows and then managing and monitoring those within Boomi's agent control tower. Our own, our own results are up there, 97% in reduction in response time for our own. We call it boomi on boomy where we use our own platform to support our own customers. 50% faster issue resolution and an 80% drop in documentation time for our own work. So again, I talk about what an agent is, and I kind of want to hammer this home. The ability to perceive, reason and act is truly what agentic means. Within that, you have tools. Now, everyone's like, MTP solves everything. Well, not if it's gonna run you 4 or 500 milliseconds in time on a hop. Yeah, that might be fun for a conversational agent, but that is not OK for a business process. I need to be able to have native tooling to do that. Boomi allows you to prototype an MTP go production if you also want. I can literally just drag and drop and go to native tool. Whether it's an API, a web service, a database call, etc. all listed out in my tools that are reusable, I drag and drop them in, with full delegated authority. Now we do that, that creates. The understanding to build that context window, then the agent itself, as you see on the right hand side, can actually directly call off and execute. It can do task management send messages in Slack. It can go ahead and notify somebody in a Service now ticket, or it can kick off a business process directly as I talked about like in the three-way match. That's what gente processing is, and this is what is required to do this at scale. This is the execution, and then we're gonna be getting into the governance side. Now for a minute, why do we keep hammering on the agentte workflow issue? It's because it's where the business value is. We have these things, and most, if you're dealing, and if you deal internally with your customers, or if you're a partner and you're dealing with in your own clients, I can tell you they are currently confused. We built this slide as an aside, and people now, it's like their favorite one, they keep going, go back, go back, go back, because they don't understand the taxonomy of what's happening with AI. They're thinking about things like co-pilot and confusing it with an agentic workflow. So these things that are these horizontal systems like a chatbot or something that is an or something that's a coding a a system like a Windsurf or a cursor super cool, not the same thing though they confuse those with what is actually happening and what we're talking about on the bottom, which is actually dealing with with line of business, specific business processes and how do I rethink them using agentic. And that's what we're doing with Booming. It's also why we are so passionate about governance, because these work flows, you have to auditors come around and see what you've been doing. They don't really care how you use a chatbot. They don't care about how you book your travel with an AI agent. These are not the core processes that help a business, but it's also actually why you go in and why McKinsey says that these systems have very little business value. 8, and you know, as they look at it, of the companies doing it, McKenzie came out in June with their CEO report on Agentic and saying 8 in 10 companies and Gen AI has had no significant bottom line impact. And what they do, and they talk about, you're gonna read the quote here, there's an imbalance between horizontal chatbots, that's what you saw, not Windsurf and cursor, but the other ones, which have scaled quickly but differ delivered diffuse, hard to measure gains. And more transformative vertical use cases that remain stuck in pilot mode. Now I happen to come from the team that wrote this in McKinsey, and I was there, I left right before they wrote this paper, so I called them up and I said, you guys, how come when you wrote that and you quoted the stat there, was it because it was because you can't get out of pilot mode because you, the P systems were not designed with enterprise class features? And I said, security, governance, and observability. And they said yes, but you also forgot scalability. Because if I build something with like 8 different projects, this open source code, this customer, this API management here and there for one use case. When I go to scale that up, they all scale asymmetrically and all our integration code breaks. And that's only one use case. They can't even get into production. Forget about doing this at scale with hundreds of thousands of agents from different vendors. It does not work to do this without a platform. And that is exactly what also and then everyone's talked about the MIT study. MIT came back and said actually we think McKinsey underestimated it. Here, here they went in, the end value here for the number of projects looked at was 300. And then they did about 100, there was 152 responses or thereabouts for written responses in an academic rigorous way, as well as 52 interviews that were structured, and they came away and said there is only one definitive causal difference between the 95% failure and the 5% successful from an ROI perspective. And they said it was integration. They then came in and said #2 is education, but the only thing that was statistically significant was integration. Agents are easy. Giving them the context through integration and having all the enterprise class features to go, to go live and in production, that is really hard, and that was what we have focused on at Boomi. So here right now you can see as we go, this is talking about. We have 360 applications on average in an enterprise, 10,000 APIs, and we're all used to that sprawl and the problem that has happened. 40% go unmonitored. We have these ghost APIs, all these security threats internally, and then you have over thousands of data sources and databases, and now people are worried about, and we're already hearing about it extensively, which is AI sprawl or agent agent sprawl. Everybody in the company is playing with different vendors. Nobody is thinking about security. They're literally giving chat, you know, chat GPT access to their financial system or their HR system. What could go wrong? Just give them a system password and let it go. No, um, a kid, but it's actually you'd be shocked at how many people think about those things and didn't really think about the security implications or how to have auditing and logging to know how it happened. So Agentech sprawl is real. How do you manage it in a multi-vendor environment? And I'm gonna leave off here and I'm gonna have somebody explain all of this to you, which is my, uh, colleague Benjamin. Thank you. Chris. Now, like Chris has mentioned, every organization is struggling with the sprawl of applications, APIs, data sources, and now it's further compounded with AI agents and the new challenge it introduces, which is non-deterministic behavior. And this is where the Boomi platform for agentic automation comes into play. The platform supports a whole set of use cases which you see on the outer perimeter like lead to cash, hire to retire, etc. Now, the four pillars of the platform are integration and automation. So you can essentially integrate your Salesforce application to your ERP application, whether it's Oracle or SAP. You can integrate Workday to your ERP or integrate the ERP to Service or any kind of permutation and combination. This is the integration process that we've had for over two decades that in a low code, no code manner that all of you could use. You could now expose that integration process as an API. And with the MCP bridge capability that we have released, we can release MCP servers with a single toggle, where the API can become an MCP enabled tool that you can use in your agentic workflow. And this is where the API management. comes in where we have API gateways and a control plane that Chris talked about, which helps you federate across multiple API gateway providers like Apogee, Kong, Gravity, name it. We support 10 different API providers and with the MCP Bridge capability, we can MCP enable every API that you have within your ecosystem. And then to complement that and to set the whole agentic workflow together, we have the agent data management ACAS system, which essentially brings in data because data is the feeder for AI. We bring in data through ETL ELT capability, traditional methods by EDI, modern techniques like ELT change data capture. And we stitch master data from multiple applications that are needed for the gente workflows to execute, whether it's Salesforce, whether it's ServiceNow, whether it's Shopify, Oracle, SAP, we have a seamless mechanism of stitching master data together. And this feeds into our agentic ecosystem which is divided run by our agent management module which is made up of 4 foundational building blocks. One is the agent designer, a low code, no code mechanism by which you can design AI agents all built on foundational AWS bedrock elements. Next is our agent. Orchestrator which helps you orchestrate multiple agents and tools together as part of your agentic workflow and then of course the agent governance, which gives you the ability to observe these agents, look for anomalies, look for latency within the agents, and actually perform actions on the agents and as we unpeel the architecture into a few layers. I'll actually show you how this is actually done, especially with the case of Bedrock agents. And then of course we have a marketplace where all this could be exposed into the Boomis marketplace or also could be exposed to the Bedrock marketplace essentially. So this is kind of a 100,000 perspective of the enterprise architecture diagram for Boomi's agentic automation platform. Now why do we need to govern these agents like Chris mentioned there is a lot of challenges when you integrate multiple applications. It's very easy to integrate two applications, but when you try to integrate your Salesforce application to your ERP system to, uh, incident management system, the complexity just compounds. So this is why governance of agents coming from multiple providers and multiple tools coming from multiple providers is extremely key, and that's what we focused on. The governance is focused on three core tenants. First is universal observability, the ability to observe the right attributes that you have shared with the booming agent control tower so that we can collect these attributes, stitch these attributes, look for anomalies, and even leading indicators to an anomaly so that you can. Do something about it before an anomaly happens and the third pillar is doing something as you know, there are no standards for agents yet, so the actions that the agents perform is quite different with each framework. Some frameworks let you stop, stop, start and stop an agent. Some frameworks let you quarantine an agent. So we aggregate all these different actions across the different framework providers so that you can perform an action when an anomaly happens across multiple providers and in the next few slides and the demos I'll actually show you how this all unpeels itself. The video that you see on play is just a quick thumbs eye view of the actual agent control tower that we're talking about. So let me unpeel the architecture a further layer. The agent studio of Boomi has got 3 core building blocks. First is the agent designer, and again, in the agent control tower, you don't have to design agents with Burmi's agent designer. You can design it from multiple providers like Bedrock, Salesforce, Lang Chain, Crew AAI, name it. But the Booming agent designer lets you use natural language. Language to provide instructions to design the agent. It lets you pick your foundation model. Today we support cloud family of models. We've been prototyping NA models, and very soon we'll open up to other models from other different providers. Next is we allow you to expose tools as APIs as tools through our MCP bridge or you can bring in your own MCP servers that you can hook up to it. And then you can add memory, knowledge bases, and guard rails to your agents. Now once you've designed the agents, you can execute the agent. The executing environment for agents is what we call our agent garden or agent run time, where you have the agent executor for the booming agents, the tool executor for all the tools that we MCP enable within BMI. And then of course the agent orchestrator which orchestrates the activity or interactions between these multiple agents from different providers as well as different tools coming from different providers, not just Booming. In addition to that, we also have a chat interface that lets you essentially examine how your agent is performing in action or multiple agents are performing in action in your actual order to cash flow process or hire to retire process as an example. And now let's come to the booming agent control tower. The control tower is where the real governance of agents actually happens. The control tower picks up observability attributes, and with that you can actually look in real time the performance of the agent. You can look at the token usage. You can look at the error rate of the agents, etc. Now to be able to do all this, there are two key data flows that we look at. From different providers, the first data flow is metadata. What is metadata for an agent? It's attributes like name of the agent, the tools used by the agent, the guardrails used by the agent, and then there are vendor specific attributes. So if you're using AWS bedrock agents that are attributes like aliases, versioning, etc. Similarly, the actions that you can perform on the agent like. You can start an agent, stop an agent. These are the metadata attributes that we actually pick up. The next is the log data. We get the log data from multiple providers. In AWS Bedrock's case, we get it from essentially cloudWatch that the customer gives permission to when they connect the Boomi control tower to their AWS account and we get the log coming into Boomi. We process the log, analyze the log, get inside. Out of the log to do anomaly detection and how we do that we'll kind of unpeel that in the next few slides. We support both push and pull mechanism for moving log and metadata between the provider as well as the booming agent control tower. The control tower also supports agents coming from multiple regions at this point in time. Now, we not only support AC MMCP and A2A within the Booming agent studio, we are also now part of the agency consortium that's started by Cisco and Langchain and actively contributing to the evolution of MCE. EP and A2A protocols. All the systems within BOI are open telemetry compliant, so you can essentially comply and hook into any of your OTel compliant uh observability platforms into BOI that you use for your respective agents. Now because we're in a reinvent conference, I wanna kind of give you a bird's eye view of the entire booming technology stack which includes the code platform and the runtime. The code platform between integration and automation, data management, API management includes building blocks like integration, flow, hub, and APIM, all of which, which runs on AWS stack for more than 2 decades right now, and the agent studio block, which includes the. Agent designer, the agent orchestrator, and the agent control tower are all based on foundational bedrock elements. We use foundational models for bedrock. We selectively pick up services like guard rails, semantic reasoning, etc. We are also tightly well integrated into Amazon Quick Suite as well as Q Business. The entire engineering team at BOI uses AWSQ as an AI coding assistant for a lot of our software development. The beauty of the booming platform is that you can design all your integrations in the cloud and you deploy your integrations into your runtime, which is a hybrid model. So if you're having your own AWS VPC where your systems work, the runtime runs within your VPC and not within your booming cloud public environment, meaning when you moved information between Salesforce and ERP or between your HR system and ERP, it runs within your local perimeter, whether it's your. AWS BPC or any other cloud provider or any other data center of your choice. So that's the flexibility we offer in the hybrid architecture for customers which gives them the possibility to in future support, bring your own LLMs, bring your own knowledge base and such capability as we deploy agents into a runtime. But this is kind of a bird's eye view of the entire Booming stack running on AWS Foundation. There are a number of other services I couldn't show in the chart like. ECS, EKS, Fargate, and a number of other AWS building stock that we use to scale and operate our systems at 4/9 of availability at this point in time. Now, the one thing I want to highlight is that the booming agent control tower is a single governance platform, a control plane to govern and manage agents and tools, not just from Booming, not just from AWS Bedrock, but from 30 other providers including Salesforce, including. chain including Landgraph including Crew AI and a number of other open source frameworks. So anything that you think of it we support it at this point in time. In fact, I have a slide that I'll get into sometime later that gives you the entire gamut of the kind of agents and tools that we support within the agent control tower for governance at this point in time. So let me unpeel the architecture and go into another layer deep in terms of how do we synchronize metadata, metadata meaning. Attributes like name of the agent, the tools used in the agent, the guard rails in an agent, the version, the aliases for AWS specific bedrock agents, etc. Now, on the Left hand side on the on the chart on the right here you have your AWS Bedrock environment where you're running your bedrock NATO agents. Now we essentially uh use the Amazon event bridge based on the connection that is set up with your AWS account and the booming control tower poll the evening mechanism that is there for bedrock. To get all the metadata in a periodic basis when it's changed in a pull or push mechanism we have support for both that information is collected into a the booming agent control tower or ACT as we call it, which is built on AWS Fargate and in the control tower we process the metadata and persisted in Aurora DB with significant replication provided to it. When there is an anomaly observed in a bedrock agent from the observability data that we collected, if we need to stop that agent, you essentially invoke the stock command from the booming agent control tower and through SQS a lambda function passes the command to your bedrock agent running in your AWSVPC to stop the. An agent at that point of time and it gets real-time feedback to the system. So this is kind of how we kind of seamlessly integrated this together so that you don't have to do any of the work we've been working with the AWS product and engineering teams for close to 1 year now to have cloud formation templates underneath the surface to facilitate this integration in a very seamless manner. The next is log ingestion. The 2nd floor I talked about after metadata was log flow. We have a similar manner by which once you hook your AWS account with your booming agent control tower, you are able to expose your cloud watch logs. Once you've given permission to booming to access it. It comes through a fire hose into the booming agent control tower, and the control tower. Persisted in Amazon Time Series DB so that you can go query the data, analyze the data, look for anomalies within the log, etc. and show that in the dashboard. I'll show that in a demo, but this is the other log flow which also happens in a synchronous but near real-time basis between the two agents so that you can get the logs in a continuous manner. The 3rd floor is how do we onboard providers into the booming agent control tower. I told you you have support for about 30+ providers. We classify providers as two categories. One is the. SAS vendors like AWS Bedrock, Salesforce, Microsoft Co-Pilot, we essentially have a native onboarding already integrated with these providers so that the moment you hook the two accounts together, information seamlessly passes in. In AWS Bedrock case, we have a cloud formation template that is well defined, that ensures that information from Bedrock, metadata, log data are all passed, and also the agent catalog is passed to the Burmi control tower so that you can discover it, govern it, watch it. When we go to the specific frameworks like Landgraph or Crew AI or other frameworks, we essentially have an onboarding SDK and an API available by which you can onboard all these different agents from these different providers into the agent control tower. Then next is the sync action. Now, how do you synchronize in metadata between the two multiple providers and BMI control tower? We have two patterns here. The first pattern is the pull via pull via API as well as a synchronous push. We support this for frameworks like. Amazon Bedrock, Salesforce, Microsoft CoPalite, and a number of other vendors. We also have an SDK with Sync Push API capability for the custom providers like Crew, AI and Langchain through which you can synchronize actions between these different systems. The last is reporting. Once we get a lot of the logs, the logs are processed, analyzed, analytics are built in the control tower, and everything is exposed as APIs so that if you want to essentially hook those APIs back to your internal dashboard, you have the ability to call into those APIs from the booming agent control tower. So this gives you a high level handshake mechanism for a few core things. How do you onboard providers? How do you exchange metadata? How do you exchange log data? How do you execute actions from booming control tower onto your respective agent providers? And finally, how do you get the reporting access? So we did a lot of talking. Now let's actually see the agent control tower in action. So we have an anomaly that's created in a customer success agent. The agent is hallucinating and it's logging out users when he logs in from multiple devices. So that's the problem that it has. So let's see what happens. The user goes into Boomi's platform page. You essentially bring up the agent control tower. The moment you invoke the agent control tower, you see the whole portfolio of agents. There are agents from. Bedrock, Booming, Salesforce, ServiceNow, IBM. When you click on the anomaly detector tool, it shows a bunch of anomalies. So we have one particular anomaly where there's an increase in token size. When you look at the anomaly, we see that the token size exceeds the current threshold of 300. The control tower automatically gives recommendations to adjust the model parameters. The user looks at it, reviews it, approves it, and it's set in action. Now let's look at one of the most popular agents, which is like a bedrock agent. Let's click on the agent and see what's happening in that particular agent. We can essentially go into the error panel, and in the panel, you can essentially see invocations, you can see the token usage, you can see a list of errors, and there's a spike in errors, and there's basically an error with the Salesforce agent here. So when you click on that Salesforce agent, You can look at the entire tools, the guardrails for that Salesforce agent, and you may want to disable that agent temporarily to prevent any other disruption to your business process, which you can do. So what you saw in this video was a Pedrock agent calling into a Salesforce agent all governed through the beaming agent control tower by going across multiple providers essentially seamlessly through all the different mechanisms that I just spoke to you about the architecture in the few slides. I have one more. to you that actually shows you how you can build agents with the booming agent designer. It's a low code no code utility where you can go in, you can give instructions, you can provide tasks for the agents as part of the task, you can essentially look at a series of tools that you can add into the task here you want to essentially set the price for the product. You include that into your list. You then essentially look at the guard rails that are available for the agent. It gives you a list of. Guardrails attributes and the respective actions. It also has a demo wizard where you can actually test the agent in a sandbox environment in the designer. You can deploy the agent into the production environment or the appropriate environment. You can then go into the control tower. You can actually click into one of your providers. You can look at all the different agents that are available in the control tower from different providers. The color code indicates different providers, not just booming. You can look at one specific agent. You can look at the attributes of that particular agent, essentially look at all the different tools that the agent has. You can even go and add new tools like the Hubgen agent to it as an example, and then you can look at the monitoring plane. The monitoring plane is where all the log data is collected. To look at your token usage, dashboarded, look at errors and all that. So this is a whole rich set of functionality that is offered and we're continuing to add more and more new features into the booming agent control tower. So again, the key thing here to take away is that The control tower has support for agents coming from multiple providers, tools from multiple providers that you can interact with, govern with, control, and manage, and make sure that your business process executes in a seamless manner. I'm gonna skip this slide, but let's look at what a few customers are talking about it. Like Jade Global, for example, we're able to create 20 agents across different systems like finance, customer support, customer success, etc. and deploy these agents into production, and they were able to save about 65% of their development time. 6I9, which is another company which is able to. Essentially use the booming agent control tower to essentially govern across multiple AI projects that are happening across the enterprise. So these are some examples by which companies are using the booming agent studio and the control tower to get governance across multiple agents and tools coming from multiple providers in the industry at this point in time, all this in production at this point. Now I told you I will share the list of providers we support. These are all the list of agent providers that the agent control tower today supports in production. We have Amazon Bedrock. We have agents from LA, Formita, Salesforce. We have Crew AI. We have Landraph, Langchain, name it. All the top popular providers are there. We're constantly enhancing this list to add more and more providers and capabilities into the agent control tower so that you can get control over the sprawl of agents and manage them much more effectively and efficiently within the organization. Now, in summary, I wanted to leave you with a few core thoughts. Our core goal with agent control tower is to provide scalable AI governance. Chris had earlier talked about integration being one of the barriers of taking agentic workloads to production. We are trying to address and solve the problems because integration has been within the DNA of booming. We've been in the integration space. AI agents and agentic workloads. And next new pattern and paradigm of integration workloads that's coming into the ecosystem and we're embracing it right up front and that's how we have 60,000 agents in production across different systems we give you enhanced visibility. We work with all the different providers to make sure that the integrations with the providers like Bedrock like Salesforce, like uh Microsoft. Co-pilot are seamlessly integrated. We are also working with other open source providers like Crew AI and Langchain to make sure that it's closely well integrated. In fact, with the AWS Bedrock team, I remember we started this collaboration about a year ago where they exposed specific attributes on cloudwatch. They added pause and play actions to their agents so that we can essentially govern it from the agent control. So that's in summary the core capability that we provide. There's more information that's available on the booth. Chris, any points you want to add? I, I did. I want to, when you're looking at the problem, uh, there's two parts of the problem. We just finished a huge study of CIOs of people that are actually actively using our system, and we interviewed them all. What are the top 3 issues they came back with. Number 1 was the difficulty in understanding the ROI and the cost of agents to make sure that that was balanced, like what's gonna be the benefit, risk reduction, increase in revenue, or increase in profit that I'm gonna get from doing this balance for the cost of actually the LLM invocations, which can be tricky. Um, you know, we see anything from 2 cents to $9 to be honest, um, in our own production systems, um, hard dollar cost all the way up to number 2, data quality. How can I actually fix the data quality issue going in to do that? Talks a lot about our data hub product, which is how I could do master data cleansing doesn't have to be master data, but how do I actually take core data concepts that I have and how do I use both rule-based and agentic-based systems to cleanse those and create a store, or else how do I. Actually take my corpuses of documents automatically put those into into a vector database even based on different document type and others which were about to release without having to have a special engineer who understands all the different issues, uh, with overlapping and token size and all the other issues and the third issue beyond that, um, was actually the aspect of these enterprise class features of governance. Now I'm hearing this from all the top analysts. They were all telling me Agent Sprawl is now the #2 issue after ROI. We heard it in our own study that these are coming out, and I just wanna put this in your mind for a second, I'm gonna get to it. It's the same issue. Your companies are making starting to make decisions about AI and and agentic integration for these business processes. Many companies now believe and if you read whether it's, you know, a host of different analysts they're all saying within a few years many of the SAS providers will be not doing well. Your companies will be disinvesting from those and be replacing those with agentic conversational UIs that work with the different users. That means your business process was taken out of the application. The codification of that has now moved down into an agentic layer that includes APIs, web service calls, database calls, vector database calls, and others. That data flowing through, sometimes doing MCP hops, going through deterministic logic, if then else, and doing probabilistic altogether. How are you possibly going to be in a governed state to make sure that you don't have secure somebody hasn't done a prompt injection and jumped in. I don't have hallucinations if you don't have one system that can see all the requests out and all the flows back in through to the agent, so then, and then having something like anomaly detection, looking for variations and needles in the haystack to call attention to those problems. When the auditor comes calling, are you gonna go out to 12 different platforms and start pulling up logs and trying to stitch those together, not only with the calls out, but the reasonings of the different agents from the different vendors altogether to show them how you have complete immutable audit trails across everything. That's what we do today in Boomi. We already do it, we do it in production. It's not Dreamwear, it's not this. I talked about it. We have 12,000 of them in production today. OK? We've been doing this for a while. We have 50,000 in place in our own system over the last two years of people doing it. We use it in Boomy today. That's what we're talking about. This isn't coding it together with a bunch of different systems and praying that it works or not, that you're not here when the auditors come. It's about getting a platform that will enable you guys to then. Innovate at speed and actually get that high ROI from your investments. So that was the comments. No, thank you, Chris. And again, if you want more information, you can join us at a booth. It's booth number 1075. Please come there. We'll have a lot of our experts out there. And again we'll be available for the next few minutes outside for us for any conversations that you may wanna have about how to govern agents because this is something that Chris and I and the whole of Booming has been doing for a while at an extreme scale and at 49 available. Yes, and please don't forget to fill out the survey forms. Thank you for your thank you very much.