---
video_id: NuFey5rCuHo
video_url: https://www.youtube.com/watch?v=NuFey5rCuHo
is_generated: False
is_translatable: True
---

OK, I just got the thumbs up, so we're gonna go ahead and get started. So hello everybody. Thanks so much for being here today. Really appreciate, um, yeah, I mean it's Thursday afternoon after what has been kind of a marathon week, so I appreciate you hanging on till the end. Uh, my name is Cameron Stewart, and we are here to talk about reimagining software development and DevOps with Agentic AI. Um, so without further ado, let's go ahead and get started. So what we have on deck today is we're going to do a bit of a refresher of what DevOps is. It's actually feels like it's been a few years since DevOps was like one of the hot new buzzwords. It feels like everything's agentic and LLMs these days. So just a quick refresher, trip down memory lane, um, and then we're gonna talk about the tools and technology that we're using today, how we're empowering developers to, uh, move faster, to generate code faster, and then we're gonna talk about the other tools that help support and make that all possible, that throughput. So that's what we have in store. Let's go ahead and dive in. I think I first wanna start with what DevOps is not. So often people conflate DevOps with a tech stack, tools, right? DevOps is not tools, it's not YAML files, it's not pipelines. At its core, DevOps is an ethos, it's a philosophy. DevOps arose in response to dysfunction. Because we had disparate teams that had different incentives and KPIs. We had devs that were focusing on velocity and getting features out the door fast. We had ops that was responsible or rely, um, was responsible for reliability and making sure that things were available. We had security that was responsible for, well, keeping things secure. And then we had testing. And quality, um, and QA that was just responsible for quality and maintainability all up. But so these were all different teams that were using different tool sets and everything was fragmented and siloed. And so that dysfunction, that bred dysfunction, and that dysfunction bred longer release times and broken feedback loops and slowed things down. And if we think about kind of the early literature of the DevOps movement, we think about books like The Phoenix Project and Lean Thinking, those were really going back and relying on the principles of manufacturing. And if you think about a factory floor and how smoothly things need to run. A, um, just a, uh, delay in any one specific step along that process causes a delay throughout the entire system. And so what it was focusing on was optimizing the system of a as a whole and not just focusing on a single component. And so it's applying those same principles to software development, to the SDLC software development life cycle. We need to optimize the system as a whole. We need to give teams common tools. Of practices about our culture so that there's not a culture of of blame that it's kind of shared collaboration shared incentives and so that's really what DevOps is is the union of people, process, and technology to continuously deliver value to end users because of course technology did arise right to support these principles and this philosophy like I said to support this culture you know. You know, we did see things like CICD and IAC and GitOps like arise, but those weren't what DevOps was. They came or they arose because DevOps demanded reliability, repeatability, faster iteration cycles. Those are the things that we needed, and so we had to come up with the technology to support these processes. Because you can still have pipelines and be deploying to code and using Kubernetes and that's not DevOps if developers can't deploy frequently, if there's still committee or change by committee, and if there's still kind of broken cycles in there, that's not DevOps. So it's really a combination of the culture, the philosophy, and then of course there are technologies that come together to support and underpin all of that. And so I do wanna address the elephant in the room. It feels like this gets this topic is being brought up more and more these days. The first elephant in the room that I want to acknowledge is that Thomas Domka sadly is no longer the CEO of GitHub, so formally known as, uh, CEO of GitHub. But one thing that Thomas always talked about was we will always need developers. Developers are going nowhere, even in this day and age where agentic AI and co-generation tools are, you know, are in the future, you know, could be generating upwards of 90% of. The code the developers are writing, it could be written by AI, but that 10% is still so important, and developers will stay in the loop. Developers are going nowhere. They're needed now more than ever, and that doesn't just apply to the human developers. That applies to the fundamentals, the little things using small batch PRs, linters, code scanners, code review. None of that goes away. All of that becomes even more important in this day and age where we're generating code at such a fast clip. But in the kind of before times, even before generative AI tools were around, developers were only spending a fraction of their time writing code. There's so many, so other still so many other concerns that they were focusing on in terms of debugging, testing, going to meetings, coordinating, making sure. That the software was flowing through the system easily because again if we go back to those manufacturing principles, that's what DevOps is all about how can we allow maximum throughput? How can we allow software to flow through the system with minimal friction and obstacles along the way? That's ultimately what we're trying to achieve at the end of the day. And so going back to, you know, developers were only spending a small part of their time actually coding, but there were all these other concerns that they were also having to focus on. And that even gets magnified in this day and age when they're being when they're able to offload kind of the writing of the code to these other tools because when we're generating so much code at again such a fast clip there's so many other pillars of the SDLC that are still just as important and if we don't have the processes in place to support all these other aspects of the SDLC. All of kind of this, um, you know, innovation that we can realize with AI is just gonna become complexity very, very quickly and so if we think about kind of the pipeline or the hose, if we're starting at the front end and just allowing developers to just generate codes so fast and it's rocket fuel and they're innovating and they're pumping out features like never before, but the rest of your process isn't able to support that, that's gonna become a bottleneck and again that's what the whole manufacturing principles. And DevOps, um, you know, arose from is to remove those bottlenecks because it'll stress the entire system. So we can't just focus on the beginning of the pipeline or really the kind of the middle of the pipeline. Let's just generate a bunch of code really fast. Now we have to think about the rest of the process. And so now I think we're really moving from, you know, we're in the age of, yes, you can generate code very, very quickly, and there's a lot of it being generated at amazing speeds. But now the process that we need to focus on is verification and validation. Now we need to make sure that that code is secure, that it, um, adheres and complies with governance standards, that it has all of the guardrails in place so that we can have an automatic flow through the system. Because if we think about it, when we kind of arrived in the AI era, that was like just being excited that we had a car. Now we have an F1 engine, but we need to make sure that we have everything else in place to support being able to go at this pace and at this speed. We need to make sure that we have brakes, steering. I mean, seat belts. Come on, we have to make sure that we're gonna stay safe. And so that's all, those are all the other concerns that now we have to kind of focus on now that we're able to go this fast. So let's talk about if we think about kind of that front end of the pipeline like let's talk about the tools that are working that are actually helping developers to generate this code. So if we think about kind of the evolution of generative AI and the tools that we're working with, you can think of it and across a couple of different areas. We're gonna look at the scope of changes, the frequency of the interaction, the inner versus the outer loop, and the developer canvas. And so, you know, GitHub released, uh, co-pilot in 2022, which is a year before Chachi BT came out, which is kind of crazy to think. Um, and it was so novel, right, to have coke inflationss at your fingertips. Now you could just have your thought kind of finished for you, or you could have conversational chat where you didn't have to go to Stack Overflow or Google to answer your question. You just had it right there in your IDE. That was amazing, really changed the game. And so what we were seeing was like co-pilot was really good again that co-completion those next few lines and when we first uh released co-pilot we called it your AI pair programmer. And if anyone is familiar with kind of how pair programming works, it's that it's two developers, one keyboard, one monitor. Both working on the problem together, super helpful to have that extra set of eyes there to be like, oh, that's a typo. Oh, here's, here's the syntax for how you'd wanna finish that function. Co-pilot was that, you know, it didn't have to be a human sitting next to you. Now you could catch your typos and finish your thought and tell you how to finish that function definition or what the next function needed to be. And so that was really helpful to have that again just kind of at your, your uh fingertips and that experience needed to be really snappy really fast. We wanted to have it in real time. It really was kind of finishing your thought as you were actually typing and this was again focused on the inner loop and this largely the surface that you were interacting with was your editor, whether that was VS code or others, but you were working in your IDE. Then we kind of evolved to having conversational chat, being able to make edits across multiple files. Again, this experience still largely lived within the IDE, um, and still focusing on the inner loop, and this maybe though kind of expanded the amount of time that it took because some of the reasoning was deeper. You were asking bigger questions. It took a little bit more cognitive load and so this might now, um, you know, range on the, uh, order of magnitude of seconds to get a response to you and your IDE. Then we, you know, really kind of change the game and we get to where we're actually handing off entire tasks to 8. It's not just focusing on a specific like, here's this box of code. I wanna be able to do this again. Can you do that for me? Now we're saying, hey, I have this new component I wanna make or I have this new feature I wanna implement. Can you write that feature for me and create a new branch, push it to it, and create a PR and get up for me? And the agent can do that and it's incredible what you can hand off to agent to an agent and but of course, you know, again this is a little bit more computation that requires and so now we're working on the order of magnitude of minutes still focusing on the inner loop and this was still living. Within the IDE and of course obviously I work at GitHub so I'm gonna talk about co-pilot a lot, but you can kind of insert your favorite tool here. We're not the only player in the game anymore and there's lots of tools out there that can do this code completions, conversational chat agents that can work a little bit more autonomously. And so now kind of the next evolution and what I get really excited to talk about is when we talk about things like coding agents and so within the GitHub ecosystem what this looks like is what we call co-pilot coding agents and what this uh does is that you can take an entire issue and you can hand it to the co-pilot coding agent and it'll parse the body of that issue, understand what it is you're trying, like the work that you're describing, what it is you're trying to accomplish, and it will. Go to work and you can assign whole tasks to co-pilot whether that's increasing test coverage, writing unit tests. I wanna implement dark mode on my UI, um, you know, you can do all kinds of things that you can hand off to the co-pilot coding agents and initially we started with GitHub issues because, you know, we're gonna start within the ecosystem that we know and love, but we've continued to evolve where you can actually interact with and assign things to. Pilot coding agent. So now you can do it from, um, Azure DevOps boards. You can do it from Linear. Coming soon. You're gonna be able to do it from Jira. You can even do it from Slack. It's pretty impactful to be able to hand an entire task off to co-pilot coding agent because what this does, this is completely asynchronous. You can hand, you can assign co-pilot coding agent 5 issues, and then you can go to a meeting, go to lunch, go pick up your kids, go to bed, whatever it is, go do whatever else you need to do. And then you can come back to 5 draft PRs. It's pretty incredible. And maybe co-pilot doesn't get it 100% of the 100% right 100% of the time, but when it does do it in one shot, you feel pretty powerful. You're like, huh, I didn't even have to fix that bug. I didn't even have to look at that bug. Co-pilot knew what the description of the bug was, was able to parse the issue, generated the fix, ran tests to make sure everything was secure, and now we're good to go. So these are the types of tools that you can use that can help to automate this flow of software through the system. This is just one example again we're kind of focusing on the beginning of the pipeline. This is helping developers generate code rapidly and you know, developers are getting a little bit more hands off in the scenario which we'll talk about more um in just a bit. And so this really is kind of the shift that we're seeing when we, we started with, you know, code completions and then conversational chat, but now we're really moving from assistants to agents. I mentioned that when we first released co-pilot, we called it the, uh, AI pair programmer. Now what we're kind of referring it to with the rise of things like co-pilot coding agent, it's your peer programmer. You can actually hand entire issues to it like it was a junior dev on your team, and so it's less a tool and more, you know, something that's that can act more autonomously. So we're helping to, you know, evolve from passive agents to more autonomous or passive helpers, excuse me, to autonomous agents. So let's uh take a look at what that looks like. I wanna show you, um, co-pilot coding agents. Give me just a second here. We're gonna switch on over. OK, there we are. Um, welcome to GitHub. I have this, uh, repository, which is kind of like a logistics app and. And um, I have a number of issues here of things that I can work on. So we can take a look at a couple of these, um, you know, explore using a green color palette, page navigation and keyboard shortcuts, um, performance optimizations, add autocomplete suggestions for the search bar. Um, let me, we will start with this good first issue. The navigating to the help center page doesn't redirect. So again, this is a GitHub issue, but it doesn't have to be. This can be a linear ticket. This could be a JR ticket. This can be, you know, you can describe this from Slack, um, but we have the details and the issue here. The user should be redirected to the help center page when they select it from the bottom. Bottom menu and then we have a nice screenshot here and that's all that's in the issue so it's not um all that verbose but it is nice. I mean it's pretty straightforward in terms of what we're trying to fix the screenshot's super helpful and so what I can do is I'm just gonna go ahead and assign this to co-pilot and because so I can optionally add another prompt where this is. Targeting, you know, which repository do you want to target? This is the one we're already working in, so I'm gonna stay there. We'll talk more about this later, but you don't, you also have the ability to assign it to other custom agents. We'll talk more about custom agents in a little bit, so I'm not gonna touch that for now. I'm not really gonna add anything. I think that the issue is good enough as is, and so I'm just gonna go ahead and assign it. And so that's gonna kick off this whole process. Now co-pilot is an assignee. We'll see, we'll watch it for just a second, because you can see here that I assigned co-pilot this. And what it's going to do is it's going to start a draft PR. And in this PR. It's going to say, hey, thanks for assigning this issue to me. I'm gonna start working on it. I'll keep this PR's description up to date. It'll actually post back as it makes, uh, changes and kind of goes through it, does its thing, um, and it'll kind of, yeah, keep you updated there. Now I wanted to kick this off because this will take. Maybe 10 minutes or so we'll see depending conference Wi Fi, you know, uh, so we're gonna, we'll come back to that so we're gonna let that kind of cook for a bit and in the meantime let's go to VS code and talk about um some of the other ways and some of the other tools that developers, uh, have at their. Proposal in order to help them, you know, generate code and so again I'm a BS code. I'm gonna be working with a co-pilot and so one thing that I have is, um, again this is a logistics page and you can also do like a shopping cart thing or you can add items you can. Add items to a shopping cart, but we don't actually have a shopping shopping cart page at this time to display the items, so I wanna help have co-pilot help me with that. So I'm going to say can. You help me create a shopping cart page. And use the, I have a screenshot or an image of what I want it to look like as a reference. And so what I'm doing here, so a couple of things, because again this is I just kind of kicked this off, this is gonna cook for a minute. One thing to call out, I'm working in agent mode and so with, by the way, can everyone see this OK? Do you need me to bump up the font or anything? We're good? OK. Um, with VS code you have a couple of different modes that come out of the box. Initially we started just with ask and then we added edit and then agent, and then we recently made plan available because you also have the ability to create custom chat modes and the custom chat mode that literally everyone was creating and putting in their, uh, repositories was a plan mode and so we're like. Well this just makes a lot of sense and everyone wants to use this, so we're just gonna put this out of the box MVS code so you can kind of target which mode you're interacting with. I find the agent mode is probably the one that I'm working with the most unless I'm specifically working on a plan where I'm not trying to generate any code. I'm just kind of in that ideation brainstorming phase, and then I'll work on plan mode. Uh, but you can see that I also have another list, and these all correspond to other, uh, custom agents that I have defined within my repository. Now how you do custom, um, customizations with co-pilot, um, at the repo level is using the construct of this dot GitHub, um, directory. And so within that directory, you can see that I have actions, agents, chat modes. Instructions, models, prompts, we have a whole bunch of things in here. And so I have these custom agents which are defined. We can see API specialists, TDD green, TDD red. We have a couple of custom agents here. You'll notice that that then corresponds with the custom agents that I see here. So again, you can kind of target these custom agents if you have a specific task that you're working on. We'll go deeper into custom agents a little bit later, but I just wanted to call that out since you can. See them there and we're wondering what if you were wondering what those were. So if we go back to co-pilot, we can see that a number of things have happened. So first it's, um, you know, saying let me examine the existing front end structure to understand the current issue. You can see, um, you know, what it's using for reference. It's using a custom instructions file, um, you can see, you know, the files that it's reading to understand the repository structure and how the codebase is functioning. Um, it's gonna check if there's a cart context already and look at the color theme. Now let me create a comprehensive shopping cart implementation. It's telling me what I'm, what it's going to create. It's going to create a cart context to manage the cart cart state, cart page component. Um, it's going to update the, um, file to include the cart route, and it's going to update the products component to use the cart context. So it has a number of things. Again, it's gonna kind of. Continue to work, but you can see here that I'm handing co-pilot an entire task. Implement this functionality for me, and it's gonna make changes across multiple files. Right now we can see up here it's already, um, created and is working on those two files. So that's super helpful that it's kind of again working on that now while co-pilot agent mode is working, you know, of course there's other things that I can be doing, but it really has kind of monopolized my IDE session for this particular task. I'm waiting for it to complete. It's output and that's really what I, we're gonna pop back over and we're gonna check on how our, uh, coding agent is doing, um, because what I love about handing off to the co-pilot coding agent is that it really does feel like so much more of a handoff. I'm not quite as involved sitting next to it waiting for it to do its work. I'm just completely saying, hey, you go take care of this and I'll be back to check on you when you're done, honestly, um, but we can see that it has indeed kind of updated the body of the PR now it's created a plan and it's working. Uh, it created a list of steps that it's going to work through, and it's already done two of those. So same thing, I'm gonna pop in to kind of check on the co-pilot coding agent, what we call a session. So we have this button here that I can view session, and what this is gonna do. So this is going to take me into co-pilot's session and so we can kind of see from the beginning. First thing it does, it's gonna check out the code. It's gonna set up node and it's gonna start both the GitHub and the Playwright MCP servers. Now those ones are loaded by default, but you can also have your own MCP server definition if you want the coding agent to use a specific tool or to use a specific, specific MCP server, you can configure that. So these are just the two that are on by default out of the box, but you can definitely. A more customizes as you, um, as your, you know, need kind of, uh, requires. So same thing like co-pilot takes kind of a very, uh, similar path with both of these is I'll start by exploring the repository structure, understand the code base, locate the relevant files for this navigation issue, um, you know, goes through those various files. Now let me explore the front end. Let me examine the footer component and the app routing structure. You can see the files it looks at for that. Now let me check to see if there's a help center component or if there's a page for that already created. Now, let me check. It's going to look at our package JSON and it's going to understand the build and test setup. It's going to look at the dependencies. Um, all right, now I understand the issue. The help center link and the footer component is just using an HRF that doesn't navigate anywhere. So, again, kind of our plan, what we need to do. Um, so co-pilot's making good progress here. Um, we're going to update the footer to use RA's router link. Uh, we're gonna run the project. The build succeeded. OK, so co-pilot is still working here, but these are examples of kind of two different ways that you're using, that you're interacting or you're having an agenttic experience. One is in the IDE, and that's leveraging agent mode. And again, this is just co-pilot specific, but there's other tools out there that give you the very similar, you know, agent experiences or agenttic experiences. Uh, the other is by leveraging another tool, co-pilot coding agent, that you can lob something off entirely to delegate that. Responsibility to and it'll just work in the background. The output spoiler alert is gonna be that we're gonna get a PR with all of this work completed for us to review. And so like I said, we'll see, you know, we'll see what it looks like and how good of a job it did and maybe co-pilot doesn't get it in one shot every time, but it at least gets you pretty far, maybe 80% of the way there, and that gets you a great place to at least now it's a good jumping off place and you didn't have to start from there. So we're really empowering developers to move very, very quickly here. All right, let's pop over, um, to back to the PowerPoint while these things kind of finish. And kind of continue to talk about co-pilot coding agent because now I do wanna talk about it in kind of more of a real use case because that's adorable little demo scenario that I have cooked up here but let's talk about something a little more production grade. So internally, uh, we at GitHub use GitHub to build GitHub. It's turtles all the way down. Um, everyone at GitHub uses GitHub sales folks, marketing folks, everything lives in an issue. We track call logs and out of office requests and GitHub issues that we use the platform, um, for more things than it was designed, honestly, uh, but this doesn't stop at just the platform itself. It also, you know, extends to the AI tools that we're also building and so. Our internal teams, uh, use co-pilot coding agent extensively. In fact, we use coding agent to help us build coding agent. And during that time, during March, you can kind of see here, it was one of the most productive members of the team. And so it was able to create new features, but it was also able to address tech debt, which is really, really incredible because like as GitHub we get an inane amount of features. Request. I know that you all can relate to this as well, but there is just an ever growing backlog, and it feels like you're never really burning it down, especially with the really annoying nitpicky stuff like, you know, that does represent just tech debt in general. It's the boring stuff, it's mundane. Developers don't wanna work on it. They wanna work on the shiny new stuff. There's always pressure to get the new feature that's actually gonna deliver business value out the door first. There's constantly this war between like tech debt, new features. Protect a new feature and new features win every time and so you know this can kind of be a bit of a battle in terms of how do we address this and I'll kind of end with this at the end of the talk about um how we're handling this at GitHub, but I just think it's really incredible that we're using copilot to do some of those boring things that developers don't wanna do and it's allowing us to burn down our backlog and to be more productive because we're able to offload this to co-pilot. And so in for the um core GitHub repository whoopsies um. You can go in and see that co-pilot coding agent is the #1 contributor to our core repository that builds GitHub.com. Which is pretty incredible because it's only been around for a couple of months and right behind it in position number 3 is a co-pilot code review agent and so this is having a massive impact to us at GitHub. We're using these tools to really burn down our backlog and to really make commits, and I know this slide looks really pretty and looks like it's a marketing slide. So I just wanna prove to you that this is true, and we're just gonna pop over to, uh, what we affectionately call GitHub GitHub. This is the core GitHub repository. You're looking at it, and if I go to the insights tab. And we wait for our contributions. You can see top committers is what we're calling co-pilot Sue agent, which was the internal code name for co-pilot code agent when it first came out. And if I, you know, adjust this from one week to one month, like this is live actual data, you'll see that the, you know, it does adjust. Here we have co-pilot code review. So this is what co-pilot looks like actually in the wild. Like we are using this internally at GitHub. Alright, so now I wanna switch gears a little bit, um, and talk about some of the other pieces of the AI infrastructure that kind of support the other parts of the process. It's not just about developers writing code. So first, um, in terms of being able to realize the maximum value and to get the most out of these AI tools, especially these agenttic tools, as we all know, context is absolutely everything. We first learned this with how we would rewrite our prompts. There was a lot of nuance that could go into what you were asking the tool to do. And if you could give examples, if you could give a specific format type or an. Output that you wanted to see, you would get better results. Now this has really widened the scope of this has really widened from, you know, rag and using other tools to pull an MCP or using MCP to pull in other tools to pull in context from other systems. I mean, really the name of the game is how to give the most appropriate and relevant context to the LLM for the particular task at hand that you're trying to handle and one of the kind of best practices. That we have landed on and that is widely adopted throughout the industry is custom instructions and so this is your opportunity to tell co-pilot and other tools how you want a particular task done and what I think is really um interesting and where some of this nuance is really starting to come into play is you know you can use kind of like a top level like we see here again using the dock GitHub directory. Um, just a top level co-pilot instructions file you can definitely do that. But what becomes even more interesting is then if you start using instruction files that only apply to certain languages or frameworks, so if there is, you know, whatever for all of your CSS files you want one set of custom instructions to apply to those files, but you want a different set of custom instruction files to apply to your playwright tests, for instance, you can use this construct, that middle construct. To only apply it to certain file types and so this is really important because this not only is um you know, taken into consideration when you're working with co-pilot in your IDE or when you're working with agent mode but then when you start to do other agentic experiences like co-pilot coding agent or co-pilot code review which we'll talk about, uh, shortly, it will look at these files and pick up. On this, um, and use this for context so that you can be very specific about how you do things within your organization. What are your coding standards? What are certain compliance guidelines? How does code need to be formatted? What does it need to look like, especially when you're doing code review, custom instruction files are gonna be your best friend, and I would highly, highly recommend that everybody use this with every repository. Um, and then just in general if you're just working with top level agents, you know, you can have different markdown files that guide that particular agent again on how you want it to behave. So there's lots of kind of customization here. I do want to show you what this, uh, looks like, so we'll pop back over to VS code. Um, I want to show you some instructions files. Um, and so we have different instructions files for, um, you know, API instructions, um, and this is for, you know, guidance for editing and reviewing API code changes. You can tell it what it applies to. So again, just within these directories and these file types, um, you can give it kind of the review guidance, talk about your general API principles, make sure that it has a, uh, specific checklist that it is adhering to. So that any time there are changes to any of these files that are listed here, again, if you're doing something like code review, this will specifically these guidelines will be applied specifically to these file types. The other cool thing that you can put in the Matter hatter uh description here is you can put, you know, if you want to exclude something, so there might be custom instruction files that you just want co-pilot code review to look at or that you just want the coding agent to look at. So there's a lot of opportunity for kind of customization and granularity that you can get with this simple construct of using your custom instruction files. And so that's just one, example. Um, the other thing that I wanted to kind of chat about is using, um, custom agents. And so if we have, let's see, I think. That. Do do do. OK, so let's take a look at this, uh, custom agent that I've created, which is an accessibility agent, and we're gonna see what this kind of looks like in action. But again, it kind of follows the same top level structure. It has a description, so this is an expert assistant for web accessibility, um, and you can configure certain tools, different, uh, MCP servers that it might want to have access to and the different tools that it wants to call. And then again you can kind of give it the like. Uh, structure of what it is and kind of what your expertise is and you can help ground it in the context and in the approach and this is again is all just described as a simple markdown file so a ton of kind of capability and benefit in a very simple construct and what that will look like is since I have that accessibility agent we'll pop back over to my. Repo for a second. Um, let's go back to the pull request. We'll come and check on co-pilot's progress again in just a minute, but we'll go back here. And actually, I don't even need to navigate to the code tab. But within the GitHub UI and I'll make this a little bit bigger. You have the ability, you have this agents panel and a couple, uh, important things here. One, you can see all of the recent sessions that I have for across various agents that are happening. So we see kind of our, uh, redirect issue on the help center page that's the one that's currently in progress, um, but I have a couple of other ones. What's nice, I could pop back into any of those sessions to again see what happened, what co-pilot's thinking was. This is important from kind of a just auditability and governance perspective. Also as an org owner, you can see all of the. sessions that are occurring within your organization and pop into them. So again that's helpful from just a kind of um security perspective, but what I can do is I can select from my list of agents, my custom agent here. So I'm using the accessibility agent. I still wanna target this repository. I could go to other repositories and I'm gonna give it a um prompt that says something like ensure this repo is adhering to accessibility. Guidelines and requirements, and I'll go ahead and fire that off. And what that is going to do is that's going to use that custom agent, but custom agents fundamentally work in conjunction with co-pilot coding agents. So this is going to spin up another session, another task that co-pilot is going to work on, but it's within a very well, uh, well-defined and scoped. Parameter this is a specific task and so what's nice here is any time you have tasks that you're finding yourself you're doing over and over again, create a custom agent for that. You can see some of the other examples that I had here for um custom agents. Let's just start a new session. And you can see, you know, I have a compliance bot. I have a documentation specialist. Like there's a lot of different custom, um, custom agents that you can create. And speaking of, if you're like, hm, what are some other good ideas for agents that you might wanna create, uh, I don't know if you all are aware of this awesome repo called Awesome co-pilots, but this is a great. Resource that you could go and look at to get ideas for um what are some other good examples for these customizations that you can take with co-pilot so you can see we have, you know, examples for custom prompts here for custom instructions files for custom agents and so you can go in here and I bet there is an accessibility look there's an accessibility agent right there. Um, so this is really good to kind of see what are these, uh, custom agents if you're looking to get some inspiration for, um, you know, other agents that you might wanna pull into your workflow, an APR architect agent, um, you know, an Azure specialist, like there's a lot in here. So definitely recommend that you go and check out the awesome co-pilot Repo. Um, it's, you know, open and public and just a collection of good examples and patterns that you can use for, um, inspiration. Um, so now I'm gonna pop back over to, um, our custom instructor or our PowerPoint for just a minute. So we just talked about custom agents, and so these are specialized agents again defined and marked down files, but if you have specific things that you find yourself over and over like SEO optimization is another great example of where you would want to use a custom agent because then you can really just point that agent at a task at your repository and say. Hey, go make sure that we're adhering to these, these guidelines. Again, that's the type of stuff that developers hate working on. So if you can avoid developers working on that and offload it to an agent, do so. That is the kind of toil that we are eliminating. If we go back to those DevOps principles, it was all about, um, reducing the waste and that toil that developers hated working on. And so this is another example of what that looks like in this AI era. Um, and so we saw this kind of briefly, but I would say in this, um, world where we are starting to see lots of agents that have multiple sessions that are working on different things, all of a sudden, while that's very exciting that we can leverage these tools to do all those things. That also creates a little bit of sprawl and if you're kind of in like the administrative or org owner role that can make you a little nervous of how do we have visibility into everything that's running, who kicked off what session, who, what agent is running, you know, what task and so whatever tool you're using. Have it be a tool that gives you visibility into all of the different agent sessions because having visibility into this, being able to have some kind of auditability is really important and just from the developer perspective to be able to manage all of your sessions is super helpful. One thing, um, kind of new improvement that we've brought to co-pilot and coding agent is, as we've seen, you know, a co-pilot kind of has its session, you can actually now pop into that session. And do live steering. Previously you had to wait for its work to complete if you change your mind and you know something needed to be the button needed to be pink and not blue, um, now you can actually do live steering in the session for co-pilot and you can, you know, make that quick decision and it'll take that in for feedback and adjust accordingly. So, um, the ability to kind of manage your sessions and then pop into your sessions and kind of steer is an important capability. Lastly, some of the tools that you know, you, we kind of recommend you use, um, MCP, this is, um, you know, it's called kind of the USBC for AI. It's kind of the universal connector that allows you to bring in context from external systems to provide to the LLM, honestly, now I would say this is still a little bit of uncharted territory. Uh, we at GitHub, we first started thinking about how. To integrate again, pulling in data from external systems to provide to co-pilot to make it more effective, to bring your context from your organization into the chat to make the responses that you're getting more tailored to your organization. And we first went on this journey and started with something that we called extensions, and that was about 4 months before that Anthropic announced MCP and everyone quickly was like, OK, MCP is the way. And so you know we also kind of adopted that and have, you know, support for MCP servers and have an MCP server registry and all of that goodness within the co-pilot ecosystem and then I don't know if anyone caught, um, about 3 weeks ago anthropically something called skills and so that might be a new construct. So I would say, you know, MCP is still a little bit of, um, not unproven technology, but they're still. A lot of question marks with it. I think there's still a lot of unanswered questions for how we're going to do this in kind of a standardized way. So we'll see kind of where all this shakes out. For now it's MCP. It might look a little different in six months, but for now, you know, this is a really good kind of path, and there is a lot of adoption around using MCP as the way to pull additional data into your systems. Um, but it is important to have some governance, um, in place because, you know, you, these are, you're giving tools access to your secure development environments. There's a lot of information that they can access and so, um, you wanna make sure that you're doing that in a thoughtful and mindful way. You wanna make sure that they're, um, able to meet compliance standards and that you're kind of balanced. Balancing, you know, the productivity that you wanna get with also being, um, sensitive to the information that's also being shared with these tools and so some of the kind of best practices that you can, um, deploy is you can use a registry based allow list. You should always use OO if you can, um, you wanna be able to define and control which MCP servers developers are using. You don't just want it to be like. Wild Wild West, whatever tool developer kind of sees fit for that purpose, you wanna have a little bit more control over that, um, you wanna block kind of any unapproved usage that you haven't specifically said like yes it's OK to use this particular tool, um, and then of course always like communicate that well to developers provide clear, um, policy messaging. Um, and one other just kind of piece as from the like the control aspects within kind of this AI, uh, world is the ability to audit this, um, activity and so specifically with Co-Pilot we've recently made some improvements to our audit log for all of these things that are kicking off and the ways that you're using Co-Pilott so now you're able to understand who is. The kind of user that initiated a request, what is the co-pilot like interaction if it's coding agent versus code review that is hat that, you know, performs the action and all of this is auditable via the audit log. So I'm giving you a little bit more control because you can't go fast without the proper guardrails in place. And so this is just one example of one of those guardrails. OK, so if we think about what is the kind of new, the whole DevOps pipeline look like in this AI world today. In yesteryear, this is kind of what your old life cycle would look like. You would have an idea that is born. You'd have a number of developers that are working on it, and, the idea would be logged, a ticket would be created to track that work, uh, you would assign that ticket to, you know, a developer, a team member. There would need to be clarification that would happen. Sometimes context could get could get lost. The developer goes on vacation. You're having to kick it over to another developer, you know, a PR is initially opened, reviewed, more feedback is given another more work continues you iterate, you iterate. Finally, maybe you, you know, um, do some security checks, um, kind of get those, uh, taken care of, and then, you know, you can approve it and merge it sometimes, hopefully not, but sometimes then vulnerabilities can even be found. In production after, uh, things have been merged and then you're gonna kind of kick kick that back and address it from the beginning, but this is what the kind of the old life cycle looked like and this could range anywhere from weeks to months and so if you were, you know, really, um, a fast moving organization that had really good deployment pipelines in place, this could maybe be on the order, uh, magnitude of weeks, um, but more likely probably in the month time frame. Well today it looks a little different and in terms of who's involved it's gonna look a little bit different. So the new life cycle is that yes, ideas will still be born and that is where human creativity will never cease to be necessary and then you're going to, you know, have some brainstorming that needs to happen. There's gonna need to be a human that approves. Yes, this is the plan, this is the next right thing that. We need to work on. You're gonna do some specking. What should this thing look like? You're gonna need human approval for that as well. You can see that we have a couple of humans, but then we have a whole lot of robots. That is to signify that could be get co-pilot. That could be cursor. That could be cloud code. That could be your tool du jour of your tool of choice du jour tool du jour anyway, your tool of choice. And so you know I mentioned earlier the developers are not going away. Developers are absolutely still in the loop, but I will acknowledge that the role of the developer, really everyone's responsibilities, is really starting to evolve and change a bit. And so I was, you know, talking with some colleagues and we were talking about, you know, this idea of specking and how important that has become in today. Day and age when you're handing over an issue to something like co-pilot coding agent, your mileage will vary substantially based on how well documented that issue is, how specific you are in terms of what expected output you expect to see, um, you know, the test coverage that needs to be required, you know, any amount of detail that you can put in that issue. Is the more detail the better and so specing is gonna becoming more and more important so developers are gonna start becoming better at writing specs. PMs are going to become a little bit more technical and more proficient and maybe a little less reliant on developers. Now a PM could have maybe 3 different ideas for what a front end could look like. And they have these designs captured in Figma. Well, they could work and use the Figma MCP server and and GitHub copilot, and they could create 3 different front-end prototypes. They don't have to go to the developer and say, Hey, can you wire up 3 different of these apps so that we can decide which one looks best? Now they're gonna be able to do that on their own. And so everyone's role is going to evolve a little bit, and I mentioned that. I don't think we're that far off from developers, um, seeing that 90% of the code being written is likely being written by agents and so they're gonna be more responsible for understanding what is this software need to look like, what does this architecture need to look like, what are the specs and the success, the acceptance criteria that is, that's gonna be part of this project, and I was listening to a talk. Um, by Brendan Burns, who's one of the co-founders, um, or one of the original, um, contributors to the Kubernetes project, and he was talking about layers of abstraction, and he said, you know, if you write code in C, you're two layers of abstraction from away from the computer that's actually running that code because C compiles down to the intermediate language and then that compiles down to assembly. And so from the developer perspective, like, you're not actually seeing like the code that's getting executed, that's getting run because we have abstraction layers in between us, right? And so similarly we're now just creating another level of abstraction that developers are going to kind of benefit from because they're gonna be more responsible for architecting the entire system, how the agents are gonna coordinate with each other, but the actual execution, the atomic unit of execution is gonna happen with the agent. Like that's just the reality of the world that we're living in. And so we will see that, you know, more and more we're gonna rely on the robots to, um, take care of this process for us. But that's OK because again, humans aren't going anywhere, it's just the nature of the responsibilities is changing slightly. And so what we see here though is, you know, after we've kind of brainstormed inspect, like what is it that we need to build, we're gonna do some coding, we're gonna do lots of coding, we're gonna iterate. You know, oh, we might have found a bug, and as part of that process of that code being generated. You want to have as much automation as possible in place so that it doesn't slow down again, kind of become the bottleneck in the overall process. Remember, we're trying to optimize the ease of and uh software being able to flow through the system with ease. And so what we're looking at is things in there you can see that it says auto fix, and that's a co-pilot capability that is able to identify if there's a security vulnerability that's been detected, understands what that security vulnerability is, and then can actually suggest a fix to remediate that process. So I'll show you what this looks like within the PR workflow and how you can use that. But again, if we can rely on. Agents to help remove these blockers and not get hung up when we do run into anything that's gonna be key because while we do have to ensure that the software that is getting delivered is secure if we can automate how that is detected and then remediated all the better, right? Put the guard rails in place but let them be, um, you know, handled by these agents to help you move fast. Um, then, you know, kind of continuing down the process we're gonna be able to do code review that also can be handled in agentic fashion these days all the way to kind of we're ready to deploy again that's gonna need human approval, of course, just to make sure that everything that's generated looks good, designs as, um, intended, that is behaving as designed and that everything is secure and adhering to all standards and compliance requirements. So I mentioned as part of that, um, a couple of things. First thing, co-pilot code review. This allows you to do kind of an engentic code review, and this is something that you can set up as a rule set on your repository so that every PR that gets created leverages co-pilot code review. You can even configure it so that it can run, um, security tools or linters, and you can have a number of things. In fact, you can even, oh no, um, we'll see configuring a linter, um, but so that you. Can have a code review do a first pass because oftentimes we see that that's where one of the longest wait times occurs is waiting for a human code review to occur and so if you can at least take a first pass from an agent that's an incredible benefit to developers to again not slow down the process to keep things moving. You can catch things earlier developers can fix it that's less manual or that's less um requirement on the human developer that will ultimately come in um and you can help. To reduce the overall load of what they're reviewing when they do step into the process. So you can do a co-pilot code review. Again, you can do that in an automated way. You can also do co-pilot autofix. This is what I described, um, where you're if a security vulnerability is detected, now you're able to kind of have the developer spend less time fixing those vulnerabilities if you can offload it to an agent. So this is something that, um, co-pilot code agent or co-pilot coding agent can now do. It has, uh, security capabilities so that it can do auto fixes and can leverage our static analysis tool codeQL under the hood, um, and you're able to again kind of have an agent to help you with this process. So, um, and when you're leveraging, um, autofix when you're doing this kind of at scale, you're really able to see, you know, faster fixes that occur within the pull request. So catching these things, of course, before they make it to production, you wanna catch it in the developer workflow in the GitHub world we really consider that the PR, um, these are the, this is the time and place to catch these vulnerabilities and to remediate them before it moves any further. Um, you're able to see kind of 7X faster fixes for things like cross-site scripting, 12x faster fixes for things like SQL injection. Um, these are very common patterns that LM LLMs have gotten very good at detecting and knowing what is the canonical fix in order to remediate that vulnerability. So again, that's low hanging fruit that we can just offload to a deve to an agent so that your developers don't really have to worry about it. Of course they'll be able to review the fix and to make sure that, um, you know, it looks good. Of course you're still gonna have all of your testing framework. Work there to make sure that everything is still green and passing um and so nothing you know everything is still being reviewed and following best secure practices um you're leveraging an agent and not having to take developer time to actually implement these fixes so pretty meaningful so let's take a quick uh look at what that um looks like so. If I go back to my repository, you can actually see here, um, I'm gonna go back to another pull request that I have, not the one that co-pilot just opened, the one that I had. Um, opened earlier today and we can look at what this looks like again. We kind of see the PR as the place that a lot of these processes should occur because this is where developers are already kind of used to getting feedback. They're still kind of actively working, but this is where, um, you know, code scanning it's run and any vulnerabilities that are detected are, um, alerted and notified and annotated within the PR. So we can see that we have a number of different actions that are being run. We're doing a dependency review to make sure none of our, um, packages have vulnerabilities in them. Um, we're also doing a CI results, um, summary. And then you can see here that we have this bot, GitHub Advanced Security bot, and it's calling out, you know, a specific, uh, file, and we'll see here that we actually have an alert from CodeQL again, that's the technology we're using under the hood to do static analysis scanning. And that we have a vulnerability for uh missing rate limiting and that co-pilot has a suggested auto fix so it gives you a high level description of, you know, what the problem is and what the fix needs to be and then giving you a summary of the changes that that are required and then it actually gives you that suggested fix right in kind of this diff view, um, similarly, you'd be making changes to two files. And so you can, you know, commit right from here. You can also, you know, open this in your IDE. It'll take you right to kind of this fix and the proposed, the, um, proposed fix from co-pilot. You know, there's a number of different things that you, a number of actions that you can take. Similarly, so we have a lot of, uh, issues in this PR. No surprise, I wrote it, um, and so we can see that we have a number of vulnerabilities, but we have autofi there to help us out with those vulnerabilities. And so that's on, um. Ultimately what that looks like. So that's super helpful that I'm alerted of that. If I wasn't within the PR, if the code scanning ran kind of out of bounds and it wasn't new code that was being checked in that had code scanning running on it, um, oops, um, and I pop over to my security tab, and I had just security results, um, just in general. So here we can look at, we have a code injection, critical vulnerability. This is interesting because this is actually looking at our actual. Workflows and we have potential code injection in uh the parameters that we're passing into our workflow because it could be controlled by an external user and so what this is now saying is that you know using user controlled input and actions could lead to code injection. It gives us more information here which is super handy but what I'm able to do is I'm also able to generate a fix for this vulnerability. So again, kind of in terms of. Reducing cognitive load from the developer, the ability to do this is super impactful. But more importantly, what I was, um, more trying to show was that you have the ability to kind of catch these things in the PR in an automated fashion. Now you also have the ability to assign if there are vulnerabilities are detected, you can assign those directly to co-pilot coding agent to take care of. So there's, that's another way that you can kind of offload to the agents. The other thing that I wanted to show you, I mentioned we talked about code review, and so I just wanted to pop into my repo settings, go down to um co-pilot and to do code review and to show you kind of what that looks like. So we have a rule set that has been set up that leverages code reviews. So I'm gonna pop into this rule set, and this is really how you protect whether you want it. You can create a rule, uh, rule set for a branch, a tag, a release. There's a number of different ways and, um, interactions that you can apply a rule set to, um, and you can, you know, um, specify which repositories you're trying to target, which branches you're trying to target, and then you can see some of the rules that we have in place for to. Protect this branch, um, we require that pull requests occur before merging. Um, we require workflows to pass before merging. We require code scanning results. Uh, we require code quality results. Now we have the ability to do, uh, code quality with, um, uh, an agent, a co-pilot agent, but you can also request the co-pilot do a code review. And so it could be on like this will just be on every PR that is created. You could also then optionally, um. Select or elect to have it on any new pushes or also on draft pull requests, so a little bit of choice there, um, and then you can also manage which static analysis tools co-pilot will use in its code review. And so code QL is selected by, um, default, but then you can also select to include linters here. So there's a lot that we're starting to offload as part of the code review process. To again catch these issues before um as early as possible to give that feedback to the developer as soon as possible so again we're not trying to slow things down later on in the process we're trying to catch them much um further um along. And so yeah, I think that's all that I wanted to show you with code review just that this is definitely something of best practice that we recommend that you can, you know, have this occur on every PR that is created on GitHub and so this is, you know, something that I would definitely recommend that you all look into. Alright, so we're wrapping up here. We have about 5 minutes left. Um, you know, I was talking earlier that we're, we're thinking about the front end of the funnel, and that's where we have no problem today. We have so many tools that are available to us or helping developers generate code, um, and before this time, you know, speeds that we've never seen before, um, but now we need to focus on the other half of the pipeline which, uh, is all about verification and validation, making sure that this code is secure and that we're comfortable bringing it into our production environment. And so just from kind of a. TLDR for some of the things that we talked about, you obviously wanna have your validation or your security validation tools. Security has become more is more important than ever in this era of generative AI. You also should leverage co-pilot code review because there's so much that you can tailor within that process. You can pass it custom instructions files. You can require that it runs on every PR. You can have it run security tools like static analysis or linters, and you can have those things occur automatically at the PR level as part of the code. View before a human ever even gets involved and then you can also use our new uh quality code quality agent which will give you a score for things like readability, maintainability, any quality issues that are surfaced. It'll surface those for you. You can have a developer look at those. You can apply. You can ask co-pilot coding agent to generate, um, a fix for those quality issues that are surfaced. So there's a lot that can, you know, help you tools that are already available that you can realize today to help you stay secure in this, in this space. All right, so in sum, here's some of my recommendations and calls to action for you all to do today, um, invest in the primitives. I've talked a lot about this, but use those custom instruction files because they are so you can be so specific and so granular and so tailored into what you're trying to do at different processes, whether that's code generation or code review leverage those custom instruction files. Every repository should have one. I'm really gonna lean into that. Every repository should have one. second, whether it's MC it's MCP today, if this changes in the future, we'll see, but leverage the tools that allow you to pull context in from other systems to be more effective in using your LLMs. Secondly, leverage the agents. The agents are what help you automate away the toil. It's again, coming back to those DevOps principles. Remove toil, remove those bottlenecks. The agents are the tools that can help you do that. Then leverage the processes. So do the code review, have automated verification and validation. That's the part of the funnel that we're really trying to focus on right now. So have those processes that can help you validate and verify that the code is good to go. And then lastly, don't forget about the fundamentals again. AI does not change any of the core of DevOps. So having code scans, using linters, doing code reviews, having code owners, all of that, small PRs, frequent, um, check-ins, none of that goes away. Those things like we're doubling down on the importance of those things in this AI era. So definitely don't lose track of the fundamentals. And if you're not doing these things well today, AI is gonna bite you. So focus on doing those things really well first. And so again, just a kind of friendly reminder because it's one of the my favorite things to talk about, we are leveraging co-pilot coding agent internally and it's really driving huge impacts in terms of our backlog and addressing our tech debt. But really don't take it from me because I'm in sales, so, uh, but you should take it from Brittany, and this was a talk I know it's maybe not standard to, you know, pitch someone else's talk when you're giving a talk, but Britney stood up at GitHub Universe, which is about 5 weeks ago, and she said, I'm not in marketing and I'm not in sales. I'm an engineer at GitHub. I don't even work on co-pilot. I work in billing, and she said, I'm just here to talk. To you about how excited I am, how we're using co-pilot coding agent to tackle tech debt on our team, and she gives really good examples of the tech debt that they're addressing, the ways to be most effective with co-pilot coding agent, and it's just an overall delightful talk. So there's a QR code there. I highly recommend that you go check out Brittany's talk because she's kind of the real world, um, experience that can speak to using these things in a production system. Um, and that's all that I have for you. So thank you very much for your time. Appreciate y'all all being here. Hope you have a fabulous rest of your conference. Tomorrow's Friday. Yay. Uh, thanks guys.