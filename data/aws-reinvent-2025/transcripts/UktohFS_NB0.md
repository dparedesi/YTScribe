---
video_id: UktohFS_NB0
video_url: https://www.youtube.com/watch?v=UktohFS_NB0
is_generated: False
is_translatable: True
---

Good afternoon everyone. And thanks for joining us for this session, which is about what are the things that we see at C-Skiller with AI and what we've been doing with ZeroTrust. I also am fortunate to have Matt Matthew with me, who is one of our champions, who has drove uh some of our technology at Amazon Robotics. He'll talk about how they went about it. So, uh, there's a lot of things that I want to touch upon, cover. We'll be around, happy to answer any questions afterwards. Uh, I thought instead of trying to hit on one topic, I want to focus on what's the bigger picture that we are looking at, key trends, things. So, I'll try to hit on many of them, but, uh, if time permits, we'll take some live questions in the end as well. So, uh, we are seeing a big shift in the intelligence systems, a lot of focus on automation. You know, everyone talks about APIs and automation and uh with agents and AI coming into the picture that uh is becoming, the race is becoming actually even worse. Now, there were some things that are lacking in the adoption of agentic frameworks. Now, some of the things that we are seeing around identity and authorization for agents, we are seeing uh how the infrastructure is readily available, some of those barriers are going away. But if I take a step back, uh, You know, I've been at ZScaler for close to 14 years now. When we started the company at that time, there was a big focus on uh from C CIOs we used to hear, we're never going to take our security to the cloud. Security is meant to be built into the data centers. There are some mega waves that come that provide tailwinds to adoption of newer technologies. It was internet, cloud, uh, zero trust, you know, it creates new opportunities. It changes the paradigms on how we have seen the world evolve over a period of time. And it also needs a little bit of mindset change on practitioners like yourself. But when we think about these uh waves, there are some giga waves that happen, which subsume these mega waves. It was industrial revolution, and we believe the big gigawave we are seeing right now is the AI revolution. It started 3 years ago when chat GPT came out, but that was uh tip of the iceberg. There's a lot more happening in this space. Uh, companies like us are also Uh, you know, uh, we are. Evolving. We are not just embedding, we started with the focus of embedding AI in everything that we do as a company. All of our products are becoming more intelligent with AI, but also how do we extend the platform to secure AI for our customers. So, as we think about this whole concept. Trust, right? We all build implicit trust in networks to begin with. I started my career building networks, and I know one of the things that we always did was we started by building trusted networks and untrusted networks. That's how firewalls came into the picture. But over a period of time, you know, what we also realized is, in this world, lateral movement, uh, you know, ransomware attacks. These happen because the way we have built networks. The attackers have evolved to exploit that. So, the traditional security models do not work anymore, like having connecting two sites with VPNs and putting firewalls that give you a false sense of security doesn't work anymore. Moreover, the new form factors that are evolving, whether it's AI agents or IOT OT, traditionally we see still people using an OTIT separation firewall. It doesn't really do anything from a security perspective, just creates a demarcation point. And then you think about ah distributed systems that are always communicating, how do you secure that traffic. So, the goal is to make sure you can adopt these technologies to be more productive, but with a secure framework. We at these scaler started with one single vision. 15 years ago. I remember when we sat down in a room, we said basically, We will be a policy engine or a switchboard between traffic going from any source of traffic to any destination. Source at the beginning was a user, traffic was going to the internet, so we basically said, what is the best way to secure that traffic. We built this highly scalable distributed proxy in the cloud. Then VPNs became a problem. We built the zero trust architecture, zero trust network access back in 2016, and now everyone talks about it. So, the intent is We all have until then tried to secure this communication using network as a control channel. Network is a way to connect things. Network should not be the one that on which the security should be built. IP addressing is a way to label how traffic flows, not how you secure things. So that is the genesis of how we have evolved. Now, we, everyone talks about digital transformation. We play a role in that. The digital transformation starts with, uh, you know, customers transforming their application, lift and shift to the application to the cloud, uh, or building cloud native apps. Uh, we partner with, uh, uh, AWS and all of the hyperscalers to make sure we provide fast connectivity to these applications running in public cloud. But where we play a role is on the network and the security transformation. Started with the security transformation, network was plumbing, everyone was using a router or a. SDWAN, but now everyone is questioning towards moving towards a zero trust-based branch model, where the network is just a way to connect. Uh, it is easier to connect. You can, uh, drop in a connection, but it also has the concept of zero trust built into it, and I'll talk about that in a minute as well. But these are the two aspects on which we play a role and are able to extend our platform. Now, when we think about zero trust, We think about Zeros, everyone talks about ZTNA. So ZTNA to us is not really what a use case, right? Zero Trust network access is users accessing applications, remote access without VPN. That problem we have solved for many years. In fact, uh, one of the things that we did, uh, especially after the pandemic, you know, everyone went to a ZTNA model as employees started coming back to work. We built this inside out ZeroTrust model with our customers basically saying, since users are sitting in a corporate network, I don't want to connect them to Application just because they are on the network. So, inside of ZeroTrust evolved, then the concept of ZeroTrust everywhere evolved, where we basically said, ZeroTrust is not just about users, it's also about your third-party contractor, B2B users, or uh B2B sites, we have like large distribution companies who talk to their supply chain with site to site VPN. Those companies don't have a good security posture, you can get a compromise through that. So how do you make sure the eroTrust gets extended for those use cases? Then ZeroTrust also gets extended for workloads in the cloud. One of the things we have been focusing very heavily in our partnership with AWS is building a cloud native gateway service, being able to secure all the workloads egressing to the cloud without deploying any firewalls. So, we have a very detailed, deep dive on this tomorrow. If you are interested, you can come back for that session, and then ero Trust for physical sites. And the new frontier that is emerging is AI infrastructure, not just the chat GPTs or Geminis, the world that you're using on your laptop, but uh you think about agents that you're gonna build with agent core or foundational model on Bedrock, right? And they go across, around the boundary of a single hyperscaler to, let's say, uh, build with, uh, I was talking to someone at agent code, they are also integrating with the, the models people can use in uh OpenAI for example. So, these boundaries will transient and our goal is to secure those communication as well. But we are the switchboard policy engine that sits in between. So when we think about the transformation that we typically see, In this architecture. A lot of our customers uh come to us from very traditional network and firewall-based architecture where they backhaul traffic, they are connecting things, uh, bringing traffic to certain, uh, traffic checkpoints in their data centers or in public cloud, and then they are establishing connectivity, right? In this model, there is network complexity and cost involved. There is, uh, redundancy of security controls, and then there is also complexity of managing that security stack. Our goal is to shift customers towards a simplified model where we are the policy engine, you bring traffic to us, we give you form factors like a client on the user desktop, we have a physical appliance that you can deploy at your site. Or you could have uh a virtual form factory in public cloud where there's a lot of virtualization to bring traffic to us, bring with the right user context, workload context, or with uh uh IOT device context and build policies on it. And do it in a way that you are not doing 10 different policies that don't understand each other with a single context, single policy that is tied into your business uh requirements. Now, uh, when we think about zero trust for users, there are a couple of things we do, right? Users could be coming from any device, any location, or a guest Wi Fi, could be a non-employee, third-party contractor, when they are going to Things that are running on the internet, even SAS applications like Office 365, uh, Google Apps, you don't run the namespace of that, you don't manage them. They are SAS service, right? So, you want to make sure that you are securing all those traffic flows. And there are applications that are managed by you, whether they run in your data center or they are running in AWS, you own the name space, you own the DNS for them, right? So, your goal is to make sure those applications are not exposed on the internet. That is one of the foundational principles where we say, Your IPs, your namespace goes dark on the internet. That is exactly what a private access services do. But security should not come at the expense of the user experience. So, we, that's why we have 165 POs across the globe. We can also extend our footprint into a private or hybrid deployment. But, uh, things can go wrong, not because of where your security is happening, it can go wrong because of end user device issues, network, ISP issues. Our application performance. So we measure that digital experience and tell you where the problems are and can offer you root cause remediation for it. But there, as you adopt new technology, you have to retire your older technology. Everyone is looking for cost savings. So, what we think of ZScaler like a DMZ in the cloud, we are subsuming the functionality of a lot of inbound, outbound DMZs that you have built, a lot of traditional networking you have built, and uh replace that with a zero trust architecture. And as you think about uh How this Stack is evolving. One of the things that I keep hearing from customers is, I need to segment my network, I need to segment my users, I need to segment my applications. We have built segmentation as a foundational policy construct in all of our products. So, you don't need a separate VLAN or an IP network segmentation tool, IP segmentation, microsegmentation. They all become complex, they all have different tool sets, they don't talk to each other. I have worked with very large banks with 300,000 users and like 2000 user security uh engineering teams that have struggled to deploy microsegmentation products at scale. Our goal is to make sure we basically learn the behavior. This is one area where we basically introduced the concept of intelligent segmentation or AI in policies a few years ago. We basically understand who's going where, especially in your name space, you could have a Windows Server running on under a rack for 10 years. You don't know who is accessing that, right? You don't want to unplug it, you don't want to block it because you don't know what will break. And what we do is we basically understand who goes where and come up with a baseline policy that we recommend and you can implement it. You immediately go from 0% segmentation to 40, 50% segmentation. Now we are going deeper into it. What we introduced recently is we actually go inside a department and say, these specific users go to this application on port 443. There are 5 app users in IT who go to this application on a high port. They probably are maintaining this application, you create a segmentation policy for them on that high port specifically, giving you more granular identity, uh, specific segmentation, and then You can push that user group through Scheme to your directory to basically have fine-grained segmentation. We have customers who are moving towards close to 80, 90% segmentation with this architecture. So, segmentation becomes a practical deployment architecture and not just a theoretical concept with this. So, this is what we have been doing really well. I want to talk about what we are going to do in the cloud and the AI space, but before that, I would like to invite Matthew to join me here to talk about the security transformation at Amazon Robotics. Matthew. That's for you. Thank you. Thank you Davil. Uh, good afternoon all. My name is Matthew Foreman. I'm a senior technical program manager at Amazon Robotics. I have the distinct pleasure of serving alongside 150 of some of the most, uh, skilled IT professionals in the industry. Today happens to be my 3,852nd day one at Amazon. For those of you working on doing that math, carrying the one with your fingers and toes, it's about 10.5 years. That puts me in the top 2.5% globally by tenure at Amazon. Today, however, is my first day one, presenting at AWS Reinvent. So, I'm not a betting man, which makes me a pretty lame guy to go out to Vegas after the conference, but I promise you that we're all gonna learn something today, myself included. At Amazon, one of our core philosophies is that every day is day one. So what does that mean? Um, our day one culture is not only a culture, but it's also an operating model. When we put the customers at the center of everything we do, we solve their problems. When you combine that customer's obsession with long-term thinking and innovation, you start to understand how Amazon approaches problems. So who are our customers at Amazon Robotics? We have about 5000 Amazon associates, uh, that our group covers across 9 distinct research and development sites. And that population has collectively deployed over a million robotic systems across 300 facilities worldwide. As a business unit, Amazon Robotics has a goal to create a safe, efficient, and sustainable workplace. In the context of today's conversation, safe includes information security. Robotics IT is chartered with providing differentiated services to our customers. Hardware engineers, electrical engineers, software engineers, industrial engineers, EHS engineers, compliance, uh, designers, lab technicians, uh, manufacturing technicians, supply chain professionals, strategy leaders, learning and development, security, facilities. I'm probably getting very close to naming my favorite child, which is a proud father of one, I haven't yet mastered that skill yet. What we're not responsible for at Amazon Robotics IT enterprise-wide services, things like exchange, Microsoft 365, unified communication, printing, standard non-specialized productivity networks, and builder tools. So Amazon as a company began their zero trust journey many years ago. And I'm very happy to share that at the end of 2023, almost two years ago exactly, We completed uh phase one of what we call our unfabric program internally. We externalized 454 sites, uh, uh, facilities, excuse me, and 158,000 applications. Now when I say we, that's really enterprise engineering, not robotics IT. Like most programs, however, it's subject to the 80/20 rule. You can have a world-class solution that solves 80% of your problem, but there's always a tail. There's always something that doesn't fit into your deployment model. Um, in our context, that's legacy applications. What do we call a legacy application? A legacy application is one that requires private network access between users and applications. That application might be a service, it might be a server, it might be a file store, it might be a SQL server. Whatever it is, it expects to live on the same private network. Many of these applications that we support in our business unit, um, are cots, commercial off the shelf applications. We don't have the ability to modernize those applications. We can ask nicely, but ultimately we're beholden to our vendors. Some of these applications also use natively insecure protocols. Telnet, anyone? So what do we do? Well, we look at the portfolio. Um, I have a, a subsection of the applications that we use up on the screen behind me. I'm gonna pause for just a moment and allow everyone to sort of skim through that. I know it's a little bit of an eye chart. So these tools generally fall into, let's say 3 categories, um. You will use these tools in your environment, which is what we do at Amazon Robotics. You will use tools similar to these to support, um, staff or your teams. That laundry list of engineering disciplines, hardware, electrical, software, industrial, EHS compliance, design, manufacturing, supply chain. Almost all of them use a tool that is either on this screen or in these product families. And if, if you're thinking to yourself, well, Matthew, I don't support any of these people. I'm, I really would rather you just keep moving. Every IT professional's favorite peripheral printers. I guarantee you, I don't guarantee. In all likelihood, in your environment, somewhere there is a printer. So Amazon Robotics took on 4 tenants in our zero trust journey. We're going to eliminate the corporate network. Remove all dependencies on Active Directory, no VPN. Everything's gonna get moved to the native AWS cloud. Whether that's on-prem bare metal servers, on-prem virtualized servers, or existing EC2 resources that are in the cloud, but peered back to the corporate network. We're gonna increase our security posture, least privileged access, we're gonna automate user provisioning and baselining. And we're going to secure those applications that use natively insecure protocols. And finally, we're going to segment at every level. So not only are we segmenting our applications like Davo which is speaking about, but we're also segmenting our infrastructure. What does that mean? Every single application is its own AWS account. There's no east-west travel, and we've implemented lease privilege from an administration standpoint. Someone who has access to the console for one application doesn't have access to the console for another application. We reduce the blast radius. So what is this shifting architecture called within uh internally? Cell, secure application link. Anyone that works with me will tell you I'm a pretty plain English guy. I like very simple naming conventions. It started off as securely linked users to applications. But Slua doesn't quite roll off the tongue as nicely as Sal does. So in the Sal world, we leverage, the Zero trust exchange as a switchboard. Users connect to applications, not networks. And we do policy enforcement in the zero trust exchange for every single transaction. ZPA ZScaler Private Access enables us to provide. Segmented, encrypted, time-bound, least privileged, posture verified, MFA compliant connections from users to their applications. Now if you're playing Infosec, bingo, hopefully you just won. So when we get into some of the specifics, Amazon Robotics is a ZPA first customer. It's something I'm proud to share because it's not your typical ZScaler deployment model. A lot of customers start with CIA or we'll do a ZIA ZPA combined, but as I mentioned, Amazon Robotics provides differentiated services. ZIA wasn't in our portfolio. It's not, it's not a service that we needed to offer our customers. And the ZScaler team was able to give us an avenue to license what we needed to to service our customers. We integrate natively to our IDP. We packaged our ZScaler client connector client to make it a one-click install with preconfigured environmental variables. These are all things that ZScaler offers out of the box. When you start to look at the stencil diagrams, we deploy app connectors in the AWS cloud. They come very nicely packaged in AMIs available on the AWS marketplace, which means that ZScaler takes on the burden of M of the updates and the maintenance. They're deployed, um, in a highly available fashion in auto scaling groups across multiple availability zones and application, uh, dependent multi-region. Users can no longer directly access their applications. Applications require zero inbound connectivity. All connections are inside out from the VPC. ZPA enabled us at Amazon Robotics to deliver a scalable solution, which we call Sal, across to all of Amazon. Our day one culture encouraged us to build highly effective solutions for our engineers and build long-term value for Amazon. So today I'm proud to share that we offer Sal as a service. And depending on how much time I can negotiate from the sysDEs at our weekly stand up, it's either a white glove deployment, where we'll take on your application and run it for you at Amazon Robotics. We have a managed self-service model where you can run your own app connectors and we'll manage the exchange. And then using ZScaler's micro tenant capability, we offer a fully delegated administrative option where partner teams that are high on the maternity curve can manage their own solution within the architecture. So, but wait, there's more. I have a cool little device here. This is the zero trust branch. It's called a ZT 400. Davill's going to talk a little bit about Zero Trust Branch further in his presentation. But we were able to take all of the same primitives that I just shared with you about least privileged application access and apply it to our physical world, using the zero Trust branch. We have on-premise uh prototype labs and manufacturing facilities that leverage 3D printers, CNC machines, um, additive subtractive, you name it, we got it, lots of cool stuff. But almost all these devices nowadays want to be connected to the internet, and each provider has their own SAS solution, and you need to worry about data management and who has access to your prototype files. So by deploying Zero Trust Branch, we can operate all of these devices in a local network-only zone. But still gain all the benefits of having them online available through the switchboard that is the zero trust exchange. This is another example of how ZScaler helps us obsess over our customers and remove friction from their workflows. I'm really proud to say that generally when you add security, you add friction. And I believe we've done the opposite. We've increased security and we've decreased friction. So I've made a couple of claims today about how great what we've done is and what our customers think about us. So I wanted to actually share some voice to the customer, straight from our customers. We solicit feedback from our customers consistently and more specifically quarterly. One of my favorite bits of feedback up on the top left here. Is that it works right away, 90% of the time. Well, I'm not Pete DeSantis, I, I don't run utility computing. 90% probably is OK. But I reached out to this user and I said, hey, why, where's the 1%? What can we do better? I said, well, Matthew, if I don't sign into Slack first or access one of our other corporate resources, I need to do my MFA token every morning. Said, well, that's not really a Sal problem. We have some security postures that require you to authenticate every 18 hours, and if Sal's the first time that you authenticate, I'm sorry, you need to do your, your MFA. But the feedback is positive. Users perceive Sal, which is ZScalar Private access, is more performant than VPN, and what they don't realize is it's because we provide access to applications, not networks. When we get to the actual numbers behind all of this. Since March, we've migrated 49 internal applications to the native AWS cloud using ZScaler Private access. ZScaler is available to 5000 Amazon associates across the Amazon Robotics business unit and has over 700 daily users. We've implemented least privileged access to 100% of those 49 applications. And finally we're able to move all of our COTS applications to the cloud. We did all that while deferring 75,000 VPN sessions. So with that, I'll hand it back to Davel. I know he has some interesting things to say about some of the AI works ECLer's been doing. Thank you, Matthew. This was great insights. And I equally hate all the acronyms that analysts throw at us, not a big fan of them. But let's talk about eroTrust for cloud workloads. We talked about ZeroTrust for users. Cloud workloads, right, this is a very interesting area. We started dabbling in this area about 56 years ago. Uh, our goal, which we have been able to achieve now is securing all workloads in all clouds. Whether AWS or Azure or GCP, you know, there is, there are similar constructs, but they are not exactly the same. So, you have regions, availability zones, you have different forms of connectivity from VPC pairing to direct connect that you need to look at. Then you have more persistent workloads with EC2s, and then you have, you know, your lambda functions, which are non-infrastructure workloads. You need to secure all of that, right? So, broad positioning, as I said, like 3 things we do here. I have thousands of customers doing what's in the first bucket, which is securing workload to internet access. This is where typically you would deploy a north-south firewall or a virtual firewall, but as I said, firewalls are looking at sessions. They are not decrypting traffic, they're not actually doing any real security other than maintaining sessions. And as you deploy more virtual firewalls, it gets more and more complex. So, I have very large customers like United Airlines who are doing petabyte scale egress without deploying any firewalls today. Second use case is workload to workload segmentation. This gets interesting because at a broader level, workloads are like users. They either are going to the internet, they are talking to each other, but unlike users, they don't have persistent identity, so identity becomes challenging. So, we have been doing a lot of work that I'll talk about in the use cases. But the use case, I, I typically see a lot of customers jump into microsegmentation, trying to segment at a workflow or network flow level, that becomes too complicated. What some of our customers who have gone on this journey with us, what they did is they basically zoomed out and said, we need to define macro segmentation boundaries, which is to say, I have a VPC that should, is a pre-broad staging VPC that should not be exposed anywhere but to my production VPC. It goes dark on the internet for everything. Or I have a specific subnet in my data center that is speaking to a workload in the cloud, that subnet should not be advertised anywhere else. So, those kind of macro segmentation use cases. And then you layer in microsegmentation, ESpace segmentation on top of it. So, our goal is to be able to do that with a consistent policy framework, as I mentioned earlier. Let's look at how this looks like from a multi-cloud security perspective. First use case is You know, customers are shifting, lifting and shifting applications to the cloud, or they are migrating applications to the cloud. Uh, the use case here is a hybrid cloud, where you have a physical side data center from that where you are connecting to your uh applications. We are able to basically give you a very specific policy to say, a specific IP subnet in your data center goes to this VPC, build the policy, and build the access. Then comes the second use case, which is multi-cloud. Some customers have multi-cloud first versus there are different variants variations of it we see. Uh, and, uh, the, the thing here is now, we have been integrated with AWS tags and MacC tags for a long time. Basically, we, we connect via API to your tenant, we consume those tags, and they become criteria in the policy. You can say anything which is tagged SAP cannot talk to certain applications, for example. So, those tags in a way become identity for your workloads. We also read your VPC names, they become, they become locations in our console. You can build policies around it. There is also a lot of in large scale customers, we have seen complexity around cross-region, multi-region deployments. Uh, multi-cloud is a reality. We see customers, their primary cloud is AWS, but they're quite a small company where they are running like a big query in Google. Now they need to connect application to it. So, those scenarios come up every single day in our world. And uh Then intra-region. This becomes really interesting. Many of you who are from a regulated industry like uh healthcare or finance, you need to have policies, let's say PCI specific policies at the workload level, within the workload that is running inside your uh VPC. So or at even uh we have seen network flow based, what is inbound versus outbound. So we can support those use cases as well. So, From a broader perspective, we can give you a segmentation framework, full decryption. We don't even do, you don't need to worry about just doing domain-based filtering, which is what most customers do with firewalls. We can give you full SSL decryption, data security, DLP on your workloads, full sandboxing, advanced threat protection for your workloads, uh, egressing through us. And if traffic is going to stay within the boundary of AWS, We will not take your traffic outside AWS. We actually extend our footprint in AWS where policy enforcement happens inside AWS as well. When you think about now specific rule sets that you need to build at a workload level, so we introduced the microsegmentation service, but it is layered on top of the these private access service or the ZTNS service that Matthew was talking about, because you guys are already doing app segmentation with us. Microsegmentation layers on top of it as a specialized use case. You don't need to rebuild that from scratch. So you get full visibility of network flows, what is going in and out of your workflows. We can, we can support containers and EVPF for example, we can support network flows and build policies on it. We can give you process level visibility, and then layer in the intelligence segmentation that I talked about, not just for user to app, we are extending it for app to app or workloads, workload to workload as well. On top of it, one of the friction points, the point of insertion for Z scalar is. We have a service called Cloud Connector, which is a VM, uh, built as with full, uh, you know, terraform, cloud formation support, auto-scaling support, uh, could be deployed, uh, with full automation, but you have to manage a VM for that, right, uh, to egress traffic to us. A lot of customers deploy them in landing zones, they deploy them in their security VPCs, uh, with, uh, uh, gateway load balancers. So there's a lot of reference architectures we support for that, and it can scale for terabyte scale traffic. But some customers came to us saying, while we need that for some of our work to remove the friction for our developers to make this as part of their shift practices. What if we don't need to deploy any VM? So this is where we introduce the cloud gateway. It's, it's generally available in AWS. We just launched it in GCP as well. So, here, you don't need to deploy the cloud connectors or any virtual infrastructure using your managed endpoints in AWS. You can point traffic to us. Think of ZScaler running a VPC like how we run a ZSkiller cloud, uh, in our data centers and in uh AWS we actually have a full VPC in which we will set up these cloud connectors with an auto-scale function for you. You don't need to deploy anything. And The one big thing it does is it basically removes your friction from deployment. I have customers who actually are telling their developers, you can set up your VPCs without any firewalls and no upfront audit, just follow this reference architecture and they get audited later. But this deployment takes 10 to 15 minutes. I have customers like Siemens who have deployed, who who developers can deploy their workloads without going through weeks of approval cycles with this reference architecture now. So When you, we talked about cloud, and Matthew touched upon the branch, appliance. He showed you the smallest box that we introduced 2 or 3 years ago, ZT 400, that supports up to 200, 300 megs built for smaller sites. We have been supporting multiple hardware sizes. There are one UAck appliances that support 1 gig Egress. In fact, we just, in September introduced our Campus appliance, which is 5GB Egress and 40 gig within the branch for East-West. Uh, The concept of zero trust branch is not to build an ST van. You know, about 6 years ago, 7 years ago, when every security company was building or buying an ST van, a lot of customers came to us saying, why are these killers not doing it? I fundamentally think that the concept of SD-WAN was required at that time because it gave you a smarter router with more automation. We opened our connectivity APIs to connect with every single SDVAN vendor. We support automation with about 2 dozen SDVAN vendors today. I think now only 6 or 7 of them are left, but we basically have automation with them. But SDWAN has a big fundamental flaw that it basically creates very permissive network connectivity, and it creates side to side connectivity, it creates more mesh networks, which actually increases the attack vector. So one of the things that we wanted to do was we took time to build the right architecture of what we're calling a zero trust branch. Many of you probably follow Gartner, so Gartner has started talking about zero trust branch architecture as a few months ago, we've been talking to them about this concept for a while. But this cafe-like branch or Starbucks-like branch model is simply that you have a hardware appliance that you can plug and play, bring to ISP circuits, and it subsumes the functionality of your SD-WAN, north-south, and east-west firewall, your NAC layer 3 switch. What do you need in your branch in this case? You need a gateway appliance that we provide. You need Wi Fi access point, you need L2 switches to connect more things to the port. You don't need anything else. Now, You need routing. We support full routing protocols on this, but you don't need to do overpermissive routing or firewall rules. For example, in this case, The inbound, uh, like Matthew talked about printing, printing is something that I've seen in a lot of manufacturers. There's a remote printing use case, SAP printing, for example. Typically you will poke holes in your firewalls to allow inbound access. The same firewall ports rules are exploited during ransomware attacks and your network gets locked. We basically build the ZPA logic, the app connector or the gateway that we have with ZPA, containerized on this hardware appliance. Which means the inbound access is driven with an identity-based policy, not with a routing protocol. We support OSPF, BGP, everything, but most of the complexity that we created ourselves over the years, and again, I have done a lot of networking, A lot of that is not required. We can simplify that, and that's something that a lot of customers, when you bring security and networking teams to sit together, they appreciate the value. It also simplifies your M&A. A lot of customers of us grow with acquisitions, you want to connect to networks. That is a wrong thing to do because you are going to bring the security posture of a company with a poor security posture to your network and that can cause issues. So, one of the big value propositions is not connecting network, not worrying about overlapping IPs. And connecting application to application or user to user. And if you are in manufacturing, one of the big use cases, we acquired a company called Air Gap Networks last year. Which was very focused on OT security. So, uh, we subsumed that that in the Zero Trust branch. So, it basically becomes a DHCP gateway, gives a slash 32 IP to every device on the network and ear gaps every device. So it creates micro fences every network. So it is microsegmentation without any agent. So your cameras, your shop floor devices, your IOTs are also fully uh uh secured. Like in ZScalar corporate network, we are not huge, but our corporate network in San Jose. has close to 1000 employees. We have multiple engineering labs. We don't have a corporate network anymore. I connect to a guest network when I go to our office. When I connect to the engineering labs on the on a different floor, I'm going through the policy engine and these appliances are protecting us. We don't have SD-WAN or firewalls anymore either. So we have good reference architecture we can share with you, but the intent is this progression going from users to branch to cloud, you uh are able to secure it everywhere. And also the goal is that a lot of our, our platform generates a lot of telemetry. So, one thing we have been doing from day one is all our telemetry could be fully integrated with any SIMs you are using, any security operation data lakes you're using. Uh, we support uh SSF framework. We actually integrate with AWS uh data lakes as well. So, uh, our customers are able to get very verbose logs, which are kind of gold mine for security operations team, and they can actually build a lot of uh rich data pipelines from it. And also, Our products are very, a lot of, you think about ZSkiller as a cloud security company, but we have deployments that are 100% on-premise. We have deployment in, um, like, uh, like classified networks, which are air gapped and not even connected to networks. So, we can support pure SAS-based, cloud-based model, hybrid model, on-premise model, there's a lot of flexibility on that. But core intent is to get better security and simplify and also reduce your costs. The last thing that I want to cover in my session is about AI. This is Top of mind for everyone I'm talking to. And uh even uh my partnership, partners, when I look at it with AWS in the last few weeks, I've been spending a lot of things that are building the AI infrastructure. We are getting deeply embedded and having those conversations with them. But as I said, like, It, everything started three years ago. I remember we were at the RSA conference in April, uh, chat GPT came out, uh, with GPT 3.2.5 model, and everything changed after that. Now, there are thousands of, uh, Gen AI applications in enterprise. One thing that everyone is trying to figure out is what Gen AI people are using. So, this is where the last Uh, 2 years, we have classified about 2000 different applications. We have prompt extraction and classification for dozens of applications, uh, and, uh, you can do your traditional DLP on them, you can get full visibility into what is going on in these prompts. But where a lot of interesting work is happening, as I mentioned, is around uh agents. So, AI started with predictive AI. We are in the generative AI cycle. Everyone is talking gente, but gente is more marketing so far. It's, I, I haven't seen a customer who has deployed a lot of agents at scale. Some of the financial services customers I talked to, they are experimenting with embedded agents in their chatbots to basically converse with consumers, but they are not settling insurance claims through that agent. I think that world is going to go there in the next 12 to 18 months, but are we ready to secure that? On top of it, agents themselves have multiple types. In my view, in the next few Quarters at least, most of the agentic air traffic will come from agents embedded inside SAS application. Yours Salesforce will have a Dreamforce agent that will be gente, and when I say agentic, it's not just web traffic, it could be WebSocket, protobuff uh protocols, it could be A2A protocols, and I recently, I follow a lot of ITA forums. I saw 82A protocols which were with Linux Foundation have actually gone to ITF forums now, which means they will get standardized and will get used more and more. There is a lot of focus on gentic identity, a lot of startups. Microsoft introduced the Entra ID. I've been working with the AWS IM team, which is also building more IM capabilities in this area, so we integrate and consume identity from everywhere. But the interactive agents is something we are seeing more chatbots for employees, for, uh, you know, consumers. Autonomous agents is very, very early stage, and there are digital colleagues, digital twins, which are going to have the same permission model, RBAC model that you have as user, but they are your digital twin. When we think about securing AI, we have two parts to it. One, something we have been doing for 2+ years, again, thousands of customers, securing public G AI applications and uh being able to secure that traffic, extract prompts, and then being able to run AI guardrails on that traffic as well. AI guardrails are more sophisticated, small and large language model-based detectors that find things that typically your DLP engines cannot. And uh specific tools also build like a lot of customers are using Microsoft co-pilot, so we can actually have co-pilot readiness to tell you what data it is touching in your environment. But what we are doing on the right side is very exciting area. which is to secure AI infrastructure and AI applications that you're building. So, here we are We introduce what we call an AI guard, which is runtime guardrails for AI systems, which basically sit, is an LLM proxy that sits between your LLMs and your applications that are conversing with LLMs or users who are conversing with LLMs. These are, again, small language-based detectors. We have built this on AWS so you can basically say if you use Bedrock or Agent Core, you can actually invoke them on day one, and your application to Uh, LLM request and the response for your LLM all is inspected here. We have out of the box support for Bedrock, Anthropic, OpenAI, and you can also do it with any other, uh, system as well. But when I look at the broad AI security equation, right, there are 4 big pieces we are looking at it. We have, uh, we introduced AI Guard in June, uh, about, uh, dozens of customers are in deployed it in early access. We are doing GA of that in January 2026. Um, but it is something that a lot of customers have interest. But we also realize AI is such a new area that the traditional red teaming tools don't work in this world. There was a huge gap in this market. So, this is where we acquired a company two weeks ago, we announced we acquired SPLX, which is AI soft bill of material, AI asset management, and AI red teaming company, and uh there's a lot of governance framework we are able to build. So, we already provide this level of visibility for a couple of years where you have the full visibility of shadow AI. You have visibility of what AI usage by the department, and you can build policies, can do prompt extraction. Now, with the acquisition of uh SPLX we can actually give you full visibility into your AI infrastructure and apps. So, we can see what models are being deployed in your environment, what MCP servers are used. We can give you full visibility of your agents and your models talking to your Git repositories and what is going on in that uh uh workflow and full visibility of what guard rails are deployed. In fact, one of the things that we just rolled out, we have uh Ability to read uh guardrails on Bedrock and we can see if you have enabled them. And uh uh find vulnerabilities uh through red teaming and fix them as well. Also, getting the full visibility of the infrastructure and tying that into data, like, with our data protection, we actually classify your data, we actually see where that data is sitting, and then tying that AI footprint to your data as well. So, looking at infrastructure, looking at uh data and tying it together as well, which is very unique. What SPLX brought specifically to the table is being able to scan your entire AI infrastructure, your AI projects. Uh, you can run scanners either through a SAS service we run from AWS. You can deploy it as a multi-tenant, single tenant service. You can also deploy it in your data center in a private deployment if you need that. But there are a lot of adversarial attacks that have been pre-populated. You can simulate them. Typically, when you are building AI projects, you run these scans, you fix things, and you run a scan again before you push it to production. But AI world is very dynamic. If a new GPT model comes, uh, you basically want to redo these scans. So, that's something we support out of the box. We have support for, for example, Gemini.0 when it came within 2 days, right? So you want to be ahead of that. I talked about guardrails earlier. Uh, there are multiple guardrails we support. Every bullet item here is basically a small or a large language model that is understanding your agentic traffic or your LLM traffic and, uh, learning the output. If you're a car manufacturing company, it basically says that uh the consumer who is talking to your LLM is not talking about another car competitor and trying to get a quote from you. If you are an insurance company, it will do that. So there's a lot of that. Readiness built into it, but also learning is involved here. And uh governance is important. One thing that we have been doing is there are new AI frameworks coming. EU AI. A lot of European customers have been asking for it, so we have reporting on it, uh, NIST AI risk management framework and uh OAS AI top 10. We have a lot of analytics that that maps the vulnerabilities and risks that we find to these as well. So as I mentioned, Our goal is that what we've been doing for many, many years in zero trust world, marrying that into the AI, we are one of the richest source of uh security logs. We have introduced certain capabilities around asset management and, uh, you know, uh, gentics security operations that I won't spend too much time, but that's an area that we are evolving ourselves into. We have one of the very exciting product deployed with about 5,000+ customers, which we call a ZDX or Zar Digital Experience. Which is built from day one with AI to fix issues that end users are facing. We can uh find root cause of bad user experience, remove the time spent on solving user tickets through a deeper integration with tools like ServiceNow or workflow tools, and being able to automate remediation. So, network operations, IT operations, Service Desk uses it very, very heavily. But at the bottom is what you see is AI data fabric, uh, so, We have a, we acquired a company called Avalor two years ago, which basically is a general purpose security data fabric that connects to 150 different kinds of security products, networking products, and subsumes their logs and can correlate, contextualize those logs to say, out of 50 or 10 different sources. I'm seeing indication of Lo 4J coming from 10 different products, and this is what I can tell you is the problem here. And then you can map it to assets and try to fix those problems. One last very important topic before I wrap up my presentation is uh, People ask us, and this is a question everyone asks all of their vendors these days, is this killer using my data to train the AI models? The answer is no. There is a a QR code, we actually have a very detailed document and a blog on this that you can read. We do not use customer data for it. We have a lot of training data. If we're gonna use your data to train in context of your training, we basically strip out all PII from it. So, your data is safe. We are not a uh Point application like Salesforce or Office 365, we don't use user data on it, but we do have metadata. Like when we store a transaction log, we know which user it is for, what location they are coming from, but we can strip out all that information and we use that intelligence then to power your tenants, your information on that. So As I wrap up my presentation, 3 big things, we've been talking about it, secure, simplify, transform. You can't do that one at a time. You need to have a good digital transformation strategy, and our goal is that we come in with the intent of securing your data, securing your applications, your workloads, simplifying your architecture. We come, we see very convoluted network architectures, whether it's in branch or cloud, how do we simplify, have more consistent policies, And give you more agility to move faster as a business with, by taking out a lot of complexity from your networks. With that, we'll wrap up the presentation.