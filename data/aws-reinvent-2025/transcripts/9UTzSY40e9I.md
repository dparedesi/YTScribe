---
video_id: 9UTzSY40e9I
video_url: https://www.youtube.com/watch?v=9UTzSY40e9I
is_generated: False
is_translatable: True
---

Hello everyone. Uh, thanks for coming. Um, hope you guys are off to a great start this week and make a lot of money later tonight. Um, so my name is Moon Kim. I'm a lead machine learning engineer at AWS Gen AI Innovation Center, and today we're gonna be talking about building Prudentials micro agent platform with MCP and Away. Um, we're happy to be here. Um, I've been working with Rohid and Sub. I've been very fortunate to build, co-build with, uh, co-build this platform with them, and we're happy to share, uh, the details. Alright, so I'll kick us off with common challenges that our customers in financial services and insurance industry are going through and the approaches they are taking to address them. Um, then I'll hand it over to Rohit and Subir and they will talk about Prudential and what it means to manage their AI initiatives across all lines of businesses. Um, they will also talk about a specific use case called Life Insurance Advisor AI Assistant, and, and they will also, also talk about how they built the platform around it, uh, which it can support many more, uh, use cases. Then we will discuss impact and future directions and close it off with some takeaways. So let's dive in. Um, enterprises, especially within FSI industry, um, have a huge ambition, and it's only growing, um, and these are so many, and there are so many opportunities with GNAI, right? Intelligent document processing, um, analyzing data, using agents, um, and simplifying the workflows for your, uh, customers. And these are only the beginning, right? Some enterprises are speculating to have thousands of agents to be part of their business. And thanks to the market we want to deliver uh G AI solutions with urgency, right? Uh, they want to be at the top of the game, um, and naturally. Right, they want to be part of the part of the game and naturally developers and teams want uh flexibility and autonomy, uh, so they can bring POCs to production, um, quickly. And all this have to align with one enterprise mission, right? Uh, meaning they have business goals, um, constraints, and you have the branding to protect, right? Uh, you want to make sure that all of your GI solutions are within, uh, governance. So what a lot of our customers end up doing is they build multiple solutions, multiple, um, um, agent tech solutions, uh, within one repo, which might be the same repo that you might have developed 2 to 3 years ago for, for the rag application, right? But this starts to break down when there are too many agents and there are such things as too many of something, right? Um, agent implementations are entangled and um some components are shared so the boundaries of ownership, uh, gets blurred. And I've seen deployments take days instead of minutes because making one line of change might trigger uh security alerts from multiple teams. It also makes it difficult to properly manage um sensitive data like PII PHI PHI because each of them might require special logic to treat the data properly. And on top of these ensuring that your use cases and platform scale with time is critical uh for long term success, meaning your solutions need to adapt to the latest GI trends, right? There are always new technologies coming out every week and you want to see if it fits your solution and if it does, you wanna be able to apply them. And we would need to maintain the optimal performance by updating the uh your models, uh, their prompts, and sometimes the implementation itself, um, so you can adopt maybe reasoning capabilities and and whatnot. So naturally the architecture shift becomes inevitable, right? We want to make, we want to take some components out and, and separate the concerns for business logic, uh, runtime execution, governance, and scaling. That's why modularity is a key. It allows you to separate concerns and easily swap components when necessary and identifying key components like run time, memory, code interpreter, uh, and browser tool will go a long way. And this will allow you to adapt and move quickly in um in the industry. The growth also needs to come with um governance uh so that you can sta stabilize um using a centralized um platform. Enterprise need to manage the access control uh of their users and agents uh for their resources, right? We also need to govern and observe uh the solutions end to end to make sure that, you know, your developers and AI agents are following their standards and policies. This is where folks like myself, uh, from AWS GAI Innovation Center came in to help our customers, uh, especially Prudential, build their platform that is scalable and future ready. Uh, we start by identifying the problem and sharing some best practices, building a solution and bringing it to production within their environment. So, uh, with that said, I'm gonna hand it over to Rohid who's gonna talk about, uh, Prudential and how they scale, uh, AI agent tech platform. Thanks, Mo. So, uh, hi, everyone. I'm Roy Kapa. I'm VP of Data Science and Prudential. And for those of you who don't know what Prudential is, Prudential Financial is an American financial services company, uh, that offers like insurance, retirement, and investment management. Uh, we do cater to like individual and institutional businesses across the globe, uh, and operate in 40+ countries. So, naturally for the enterprise like Prudential of that scale and this large, you expect like customers have different sort of expectations on different sorts of things like uh personalization, speed, trust, uh, superior customer services, and a lot more. Like that's the high bar that our. have a typical expectation set on a large financial services like Prudential. And with that said, like, let's take a deeper look into the businesses that we have and how AI is helping in addressing some of these challenges. I'll try to relate back to what Moon said earlier, like what typical FSII enterprise are facing, and within prudential lens, I will try to share a view on what does that mean from AI use cases and scaling those AI use cases. So, overall, the slide is a matrix that represent different uh like challenges and the opportunities that AI can provide. And I'll probably try to explain like, uh, in, in, in detail. So, for Prudential, uh, you have like 3 different business units, retirement group insurance and life insurance. I'm not talking investment management here for this particular session, but these are like 3 primary components within the US business and Each of these business, if you look into the business functions, they are probably similar in nature. Uh, all these business units have like distribution and sales, underwriting and risk, customers and claims service, and then you have like product development and marketing, and Although every business unit has like their own new innovative products, or they have like different, their own customer journeys, every one of them have a similar kind of challenge for distribution and sales, like you have fragmented advisor workflows, limited personalization, for underwriting and risk, you have like manual, slow underwriting, rigid risk models. Customer service and claims like you have high servicing costs or the claim process usually takes longer. Product development like you have slow innovation cycles and marketing, you have like generic campaigns and low conversion rates. These are not only just potential challenges. Maybe you can relate it to typical financial services challenges in general across these kind of different functions that they also have. And from an AI outcome standpoint or a goal standpoint, where businesses are looking forward towards this, how can actually AI create like hyper-personalized advice at scale as a sales enablement. And if you look at impact perspective, these AI solutions, if you try to build for each of these business functions, they directly impact the people who are working in these organizations. So for example, like for distribution sales, as I said, like if you want to build hyper uh hyper-personalized advice, uh, sales enable, better sales enable process or like uh next best action kind of models, they directly impact your advisors and brokers. Same thing, like for real-time risk assessment, if you want to build, it directly impacts your underwriting and your underwriters and risk analysts. From a customer service and claims perspective, if AI can Actually help in creating like self uh serviceable uh processes, or it can also create like automated claims triage. Things like these directly impact your call service agents and claims specialists. And if you, if you think of like product development, like if you, if you try to create like a-driven market insights or personalized riders or solutions that, you know, build inside your products, these directly impact your product uh development. Product management folks, or these actually impact actuaries, and same with like marketing as well. So what you're seeing here is every business function has a set of challenges that can be solved using an AI and that AI goal or outcome has a direct impact on the people who are working within each of these functions. That's the business strategy. That's where we are seeing a lot of indust industry is heading towards. And today's discussion, I would like to share one such use case around the very top on distribution and sales, and how we are actually using AI financial advisor for life insurance business as an example, and how we are actually trying to help our advisors in delivering a personalized, say a better sales enablement and a better process compared to where they are today. And although overall like Agentic AI can actually deliver all of these things, we are hoping that it can deliver all of these things from a value standpoint. The biggest question is, can we scale with time? Can we actually scale with these many use cases? Are these realistic? So those are like bigger questions, but I'll just deep dive into the use case, straightforward. So, when I say like life insurance advisory assistant, uh, one thing I would like to note here is from an advisor lens perspective, if, if you just break down like what advisor does on a, on a daily, day to day job, uh, from a life insurance carrier perspective, an advisor typically engages in like client engagement for prospective clients. Uh, they need to do like need assessment, uh, a solution design. They need to identify like which kind of Product is more suitable to show illustrations to the clients and try to sell, OK, saying this kind of product might be good for a 30-year-old or a 50-year-old. They might probably look into a separate IUL kind of product. So different product presentations, illustrations, how much benefit they acquire, those prospectors need to be shared with the client. Then if the client agrees, the advisor typically pushes them to like application and underwriting support where they have to fill an application, apply for life insurance, get the policy delivered, and once the policy is delivered, they have to do like service and follow-ups for the next 1015, or 20 years of the policy. If you look into this whole end to end loop into what an advisor does on a daily basis, there are like 5 or 6 different steps. Each step, advisor has to log in into one particular system or has to deal with one particular IT system in the back end. So overall, what is happening is from an advisor lens perspective, if they have to do this for one carrier, and if you have like 5 or 6 carriers that an advisor is working with, they have to interact with like 50 or 60 different IT systems. This is not a real value of an advisor, and it is probably breaking. The value chain of what a financial advisor is supposed to do. Ideally they should be providing good advice or probably helping clients in delivering something. What they ended up doing is tangling with multiple backend operations which may not help them in a better way. This involves looking into all different tools and systems and also advisors are required to. They, they are required to actually maintain long-term interaction with the clients for 10 years, 15 years on the life of the policy. And what is happening in the process is, for the first client that they started 10 years ago, they probably forget the context, like what they actually talked 10 years ago, why did they give that particular advice, and what is happening on a periodic review basis. So like these are the problems, and that's typically what an adviser is facing. And I will share with you in terms of like how we are trying to solve this from an AI assistant standpoint. So this is a view in terms of like sharing like how we build the advisory assistant, the financial advisory assistant, and how it is transforming the distribution and sales process. So on the left side, on the screen, what you're seeing here is an original experience today. Uh, when I say today, like it used to be the experience in the past. where an advisor has to actually log in for different, different things into different, different systems. So on the very left, what you're seeing is a manual process on Quickodes. So QuickCode is more like an informal process, where, let's say people reach out to advisors, or advisers actually reach out to carriers saying, I have a prospective client, they have a medical condition like diabetes, they have hypertension, or they have like cancer. Uh, can you offer me like what is the best quote? And they typically give you medical advice, like medical information in the request. And what happens in the back end is an underwriter from a carer perspective actually takes like 1 or 2 days and get back to the advisor in 1 or 2 days with the answer. This is because the volume of these courts is high, and underwriters are like stacked with a lot of requests coming up from advisors asking for multiple requests. So this is a big challenge. You have like 1 to 1 to 2 days delay happening in the process. The same thing, like if you look into forms or getting like product-related information, for example, if a if a, if an advisor is looking for a customer to fill up an application, And they expect the client to fill like a 1030 exchange for a tax purpose benefit, or they want to get like some kind of rider benefit or some kind of disclosure sign. They need to find this form. They need to either call some carrier system in the back end like customer care service, be on call for 10 minutes to get like what is the right form, or do the search in the manual system on their own and try to figure out if this will work or not. Same thing is with product-related information. Usually, insurance products are complicated in nature. If they want to know like if a particular uh product feature can be applied to a particular client or not, they need to have a lot of knowledge, or they have to probably uh request a product specialist. It takes like 10 to 15 minutes even here to figure out the answer. If I keep going on on the pink side of the space here, there is a lot of inefficiency that we can see in terms of what advisor is facing today. And what we have done is we have tried to replicate those processes with an AI-driven systems on the right-hand space. Now, with an, like a multi-agenttic AI system, we are actually delivering all of this information instantly to our financial advisors on the go. And what does that mean is, what we have built here is an advisor agent, which is giving them a chat experience, which is more like natural language-driven and rich conversation or context-driven, where advisor can actually ask as a one-stop go and request for different kinds of interactions they have to usually deal with. So there's a foundational product that we have built, and what is happening in the background is we have an orchestration agent, which is a single point of entry for advisors. It takes different sorts of inputs from the advisors. It understands intent, and it is non-deterministic in nature, so it routes to multiple subagents in terms of what the context is based on the context that advisor is asking, and gets back to the answers for the advisor's requests. And in the back end what you're seeing is the subagents in the whites. The first one is like quick qu agent, the second is forms. The third one is like product agent, the fourth one is like illustration agent. And the top bottom is like book of Business agents. These are like set of agents that we have built. And each agent is a specialized entity that is trained in the process to actually deliver the accurate, with more accurate responses back to the advisor. I would probably highlight a bit on the quick court process a bit. Because it is a way we are trying to use AI to replicate an underwriter and give those decisions instantly to our financial advisors through this process. So what happens is, if an advisor is getting a request saying, I have a client who has like diabetes and who have like cancer, can you give me a medical quote? They can actually use this chatbot, and the chatbot is intelligent enough to actually ask follow-up questions based on our underwriting documents. So it is trained on more than several 100 documents, where every document has a detailed description on how a condition should be risk rated from a risk perspective. And if you can correlate this to any risk assessment process across your financial or underwriting process across different insurance companies. Every underwriter has like these kind of manuals, and what we have done is train those manuals in a way that could actually answer these things automatically. So we have built uh training or validation pipelines that will automatically figure out uh prompt optimization, validation, and also like uh for asking the follow-up questions on what level of information is needed to make a decision. So in this example, if the advice He gets a request saying if imagine like he's sitting in front of a client and he's saying like, hey, my client has diabetes. The bot immediately will ask questions, follow up, saying, OK, can you give me information on what is their A1C value, what is the high blood sugar, like what are the sugar ratings and what kind of medication they're taking. So it gives them an assessment in terms of understanding what kind of risk from a diabetes perspective that client has. The same thing, like if the client says like they have cancer, the bot will actually ask follow-up questions, like, what is the remission date, uh, were there any treatments performed? Was there a chemo performed on the client, what stage of the cancer they're in. So the bot is intelligent enough in terms of asking these follow-up questions back and forth. And then, based on these follow-up questions, it tries to get the information back from the advisor in order to make the necessary decision. The same thing is with like forms. Forms is also built on hundreds of different forms across different areas, and advisor can get the form on the go, and the forms agent can also actually ask follow-up questions stating what kind of transaction are you looking for, what state, particular form you need. And similar thing is with product as well. It's like a smart search feature where from a context standpoint, like they can ask deeper questions, like what kind of product can I use for my client? What are the features, can I apply this kind of feature to my client or not? And the agent actually gets back to them with responses. Overall, what we have built here is we have an orchestration agent and You have like sub-agents, and the context is shared between both of them. And also at agent level, what is happening is we have guard rails established from a functional standpoint, we have guard rails established at each agent, and also at orchestration agent. That actually handles uh like your invalid queries or sub-queries or also handles some kind of like follow-ups back and forth with this. And with respect to illustration and book of business, it's also more like, think of these like your APIs being served through these agents, where your book of business uh typically means like an advisor's book, which includes like hundreds of thousands of policies that have, they have placed in the past. So they can, it, it can actually give them information on next best advice, like next best action, what would be A particular policy would look like, what are the actions they need to take on a particular policy on their book. It, it, it gets really hard for advisors to actually manage this whole thing, so we are using agents to help them in this process. So overall, what we are seeing is a multi-agent system that is helping advisors. We are live today with more than 100,000 advisors actually using this, and, and it's more like a foundation structure that we have built where we can actually add more and more agents on top of this. So this is one particular example of how we are using AI and how we are actually transforming our sales and distribution within life insurance. And what we are expecting is the more, in the previous slide, like you have seen a bigger picture of where we want to drive AI across different business functions. Uh, that's our goal, and my colleagues will be here will actually gonna explain like how we are trying to get towards that goal and what is needed from a platform or what is needed from a solution perspective to actually get there. Thank you, Rohit. Um, good evening, everyone. I'm Subidas. I'm director of Machine Learning Engineer. As you have heard, um, Rohit, that the use case that is already developed here and the model is ready, and once the model is ready and the business accepted the model, right, the biggest challenge that we faced. is to, um, how do I deploy the model in production and at the same point of time, scale with time, OK. Um, And the deployed model should be able to scale up to 100,000 users. It should be able to support intent driven orchestration. The agents that are there, the components within the agent should be able to be reusable and at the same time, what the entire solution that gets deployed should be secure as well as compliant. So these were certain challenges that came from this particular model that is approved. OK. Now, in addition to. In addition to this model, right, deployment model, right, we also faced some challenges, right? How do I scale for other solutions, um, um, in order to make sure that this is reusable across um the entire enterprise. So this is our um um microservices architecture, but before I dig deep into it, right, let me explain something about scaling in time. Scaling in time, what I mean by that statement is that, in the AI G AI space, the uh um uh information in the space is changing at a very rapid speed. In order for the system to address correctness, completeness, and accuracy of a particular system. And at the same point in time, we would like to take advantage of those enhancements, those frameworks, be it from a prompt management standpoint, be it from a context engineering standpoint, be it from SDKs, be it from a pipeline, anything that is coming up, we would like to take advantage of it. So that is basically a problem of scaling with time. And along with that, we also saw something, uh, which came from other, other teams is like, how do I democratize the entire solution development so that the development and deployment of these various agentic solutions can be, uh, uh, uh, given to other teams based with a minimal touch point with the platform. And along with that, definitely we would like to standardize the frameworks, the pipelines, the tooling, and, and the tech stack that is used there. So, with these challenges, right, we reached out to AWS uh Innovation Center and we came up with um uh a microservices-based architecture which you see on, on the slide. In the slide right here you can see user interacts with the UI app where an SSO authentication happens and the SOSO authentication happens based on the user's home access level control. And once the user is authenticated, a secure token is generated and that particular token is passed to the agent declarer. Agent layer revalidates the token. Once the token is validated, it generates a context-specific window ID and maps it back to the secure token. These, these two pairing is again passed to the orchestration agent, and orchestration agent builds that entire thing and uses that particular pair pair context ID in order to maintain session and context engineering for the entire discussion. Uh, gentic discussion purpose. And the same context ID as well as the Window, um, uh, secure ID is passed to the farm's agents and a particular agent, be it farms, be it products, right, they use LLM gateway, which is another secure way of accessing LLM in order to get response. And, and if an agent wants to use knowledge management, it uses the knowledge management system to get the, get the relevant documents and generate its response and response back to the user. So, while all this thing is going on, right, um, and, and this entire system is deployed, uh, to scale up to 100,000 users. One of the pieces that we have seen here, right, is that the context engineering around this 100,000 user base, which is paired with a secure token and the context window ID becomes very challenging, um, uh, because what happens is, right, Model in a typical sense, right, sometimes they drop performance for unknown reasons and debugging this context engineering frame in order to span, separate it out, and find out exactly why it happened. It is challenging in this environment. So, we'll talk about more in the um uh uh um uh next slides, uh, but another component that I want to add is that, while all these things going on, we are actively developing and adding more agents and adding support for MCP based tool access as well as um API access for the agent delayer. We are also adding support for agent declare to have monitoring and observability. We are also adding support for agent declare to have the evaluation framework attached to it. So Now that um this is our um internal orchestration of our architecture of an agent, right? How it a particular agent once, the previous one was the deployment architecture of the entire LM system. This, this basically boils down to a specific agent, how it is architected and internally how it is um uh sharing the data across different uh segments of an agent. You can see that in a particular region on the right-hand side, uh, sorry, on the left-hand side, it accesses the data plane and then, and it uses MCP as well as it uses the React framework, um, and, and, and it uses the memory management for short-term memory as well as long-term memory, um, access and Um, and A2A protocol in order to move from one agent to another agent, as well as this particular agenttic system if it needs to transition to and on access to some other different agenttic systems like planned provision, which is a retirement multi-agent system, and IDP, which is another multi-agent system, it uses A2A protocol. Along with this, you will see that the context engineering framework is under active development. This is based on the ACE framework which came out recently, and we are actively developing on this one to see exactly if we can enhance the context engineering that is needed in order for us to scale at this level. So, in order for us to maintain such complexity, as well as scale with time, as well as implementation of MCPA2A, the only solution that came into our place, right, we have to take a platform-based approach. And that's what we'll, we built our agenttic platform where you can see that traditional model space is being catered by the Sagemaker inference, which is, which is also sometime agent uses it in uh via an MCP. And, and on this side, on the GEI side, you will see gen gente AI which has a vector store available to it in for knowledge management system. It also has a Bedrock-based agent and an LLM gateway and actively developing a management and evaluation framework for the platform for its enterprise need uses the enterprise services, be it for agent ops, um, for GitHub actions. Basically the entire Devsecops is being available through the enterprise services. For its data needs, it is, it relies on enterprise data and for its infrastructure and tech stack, it uses the entire AWS system. The platform is predominantly used by data scientists as well and machine learning engineers for developing and deploying models, whereas from a consumer standpoint, it is consumed by business and and and business users and apps. Um, so now that we have built platform, we have taken a platform base. I would like to also share a few, um, benefits that we have seen taken by this approach. One of the, um, uh, benefits that we have seen directly is that since we have a platform-based approach, right, we, we are able to ensure that responsible AI is engaged at that level. That means anything and everything that is running on the top of it can be, can be going through this responsible AI framework. Same point of time, right? The time. To value which plays an important role in the benefit realization can also be done because what happens is, right, if you develop a uh agent multi-agent system, right, and deployed bespoke, um, you will not be able to um uh uh able to share the common layers, right? That means every time you have to rebuild and you spend more time in rebuilding the common layers, but platform-based services allows us to do that particular and, and share the common layer piece. And from a monitoring and agent monitoring and evolution standpoint also, we are evaluating and deploying something which basically helps us to measure the entire agent span as well as agent traceability, as well as observability into it. Uh, with this, right, I would like to pass it to Rohit again, uh, in order to share some business, um, outcomes and lessons that we have learned. Thanks. Uh Now that Suvi has explained like why we are actually building a platform, uh, you've already seen like where our business ambitions are, and you've already seen like how one use case has evolved into like different use cases and why a platform-based structure would actually help us in getting there, and what are the general benefits of an agency care platform from a common uh solution standpoint. I would like to highlight some of the business outcomes that we have seen from this approach, and later, I would probably dive a bit deeper into like where we are heading from a future standpoint as well. So overall from a business standpoint, we have observed benefit realization is happening. It is happening because we are able to reduce some of the key things that we are facing across like turnaround time or time to actually get the business value generated from an AI use case itself. We are able to actually reduce. The turnaround time from like 6 to 8 weeks earlier to like 3 to 4 weeks now. Uh, what is happening is, once we have built a foundational, let's say, advisory assistant system, uh, we are able to add multiple agents on top of this and able to deploy into production in like 4 to 5 weeks' time from deployment, from development and deployment standpoint, both together. Uh, some requests that are coming from advisors, if they say like, hey, I want to add this, I need to have this kind of product also embedded inside my product-related agents. So, the requests that users are asking, we are able to deliver quickly and deploy them quickly as a stand-alone solutions. That part is helping us from turnaround time perspective, and ability to actually integrate with existing IT applications or workflows as well. Similarly, on standardized solutions, there is also another benefit that we have observed where We are able to actually scale from one use case to multiple use cases now. And also what we are seeing is if we have built one particular use case in one particular business area, we are now seeing value of how we can reuse this particular development across in the same way in other business units. And the other part that we are seeing from this approach is you are reducing tech debt. A lot of components within multi-agent systems are actually changing outside in the market. You see a new context framework arising. a new A2A framework arising, you see new SDKs arriving. So all of these things are changing very drastically, and it's not easier for us to actually keep up on those paces. So having a standardized solution set from a platform standpoint is helping us to upgrade for longer runs. And some things, like for example, if there's a new model released or if there's a new change in observability related systems, we are able to actually keep up with those kind of changes as well. And the other thing is we are observing like business feedback. Uh, we are able to actually Add the business feedback very well in the earlier in the game. Earlier, what used to happen is your data scientists or engineers who are building the systems, they used to focus on not only just building agents, but the surrounding components around it, like how they can handle multi like context, how they can handle. How the system from development environment to stage or UAT environment, they, they will be seeing, like, they usually see like a lot of issues in terms of how they move from dev to stage or UAT and things usually start breaking apart when you actually add scale into the context picture. A lot of LLM performance usually used to drop. Now with a lot of these standardized solutions, we are able to actually dig deeper, even getting insight into like tracing or debugging a particular issue, understanding the chain of prompts from an observability standpoint, monitoring your solution once it goes into production. Look into that solution and actually trading on that, these things are becoming easier. We are able to actually incorporate business feedback quickly, which is actually helping us in gaining business trust on AI systems, and that in practicality has actually helped us in focusing more on develop developing a solution from a performance standpoint rather than looking into all other engineering related aspects. That is probably Bigger win for us because now our data scientists can actually focus on improving performances where performance like in financial services, especially the area that we work in, I think performance is a key part, and a lack of performance usually adds a distrust from an underwriters or the user's standpoint, like who are advisers underwriters or risk agents, etc. And overall, like, I would like to share like what are the lessons we learned. Uh, one thing that we have absolutely learned is your agents are not suitable for all business problems. Uh, some problems, like for Quickode that I mentioned, it's not an agenttic solution by itself. It is more like a stand-alone LLM application, where for a particular task, you are trying to replicate an underwriter using a complex LLM application system by design. Same thing, like if you think of building an IDP solution, I think a simple IDP solution may not work, probably for some of the use cases that you have. If there's a complex handwriting or there's some complex kind of information that is being handed over to your agents, you probably need a separate process for that. A generic agent system may not work. And the other thing that we observed is the solutions that we are building need to be built from an end to end value chain perspective. Same example, like if I take a NIO, uh, not in good order kind of use case, which a lot of businesses are trying to solve, and if I try to build an agent to solve an IDP related issue, it may not work by itself. Maybe the IDP solution we are able to solve. But from an end to end value standpoint, you probably need other components on top of your IDP itself. For example, uh, if you have a workflow where you are trying to figure out whether this is good or not good or a case. You need IDP plus you need a business rule processing system on top of it, or you need like some kind of workflow management on top of your IDP processes to understand or fully implement or execute the end to end NIGO process, and then see the business value benefit. So, business alignment and end to end value creation is actually crucial in actually gaining the value benefit realization from these use cases. The other part that we have learned is there's an unpredictable drop in Asian performance, and it happens a lot when you try to scale in production. Traditionally, one or two reasons that we have observed is one, there's model upgrades that are happening which probably are not are probably affecting the way the Agents actually perform. And the other thing that we observed is your training and validation data set may not have seen all the cases that typically you're seeing in your outside world. And there are some issues around with like how much memory and context engineering can actually come into play, and that is also an issue. And That probably is one of the bigger aspects that we are trying to solve in terms of how, if you're looking into like scaling into multiple advisors, multiple underwriters, and especially from an A2A standpoint, if you're trying to reuse some of the agents that someone, some other system has built, the context engineering becomes a key challenge here. How do we actually maintain that? How do we actually log it? How do we do the debugging or tracing? I think this becomes a key important aspects when we are trying to solve this kind of use cases. And here I would like to talk about the future direction, like where we are heading. Uh, one thing that we have felt or realized is integration with other line of business agents is probably a key win to success, cause some of the use cases that other businesses solving, we can reuse some of those agents in other business systems as well. And having that reusability component actually addresses a lot of the issues. The other piece that we have observed is, uh, having a standardized approach on memory and observability, and also like context engineering might help in scaling in the longer run. For every application system that, uh, for every multi-agent system, it's hard to actually recreate its own database, its own cache memory, its own like uh engineer, like short-term, long-term. Memory or like static memories and building context engineering around that. It, it may not scale in the longer run. Maybe one pattern for one particular agent system might work, but if I switch from advisory assistant to maybe some real-time system or from there to IDP or from other use case, use case by use case, it becomes very harder to scale, and things like agent core, which actually provides some of these features inbuilt, which most of the Industry is heading towards, and if if they're actually doing all of the groundwork, maybe it's better to just adopt this as part of your platform and try to incorporate those features into your platform and reuse them in your systems is probably a better approach for the longer run. If you have some edge cases or use cases which are very complicated, then probably you can probably try to re-engineer that, but for all the generic purpose use cases, it's probably better to stick with something industry is heading towards. And with that said, this is a a a a mega view into where we are heading in terms of the scaling AI agents with time and trend, and You are seeing like a bigger picture, like we have a bigger ambition from our multiple agent systems. Now, if you have to build like multiple agents, what we have, or what we are thinking is, you need to have a different agent development layer on the very top, and then you need to have a core platform layer, and then you have, you need to have like an enterprise and uh enterprise uh services layer on the very bottom. What do you, what do I mean by agent layer and what do I mean what platform core layer is? You need to standardize some of the things, which are probably foundational in nature for building any kinds of agents. So on the top layer, what you are seeing in the agent development layer is This layer is supportive in building or probably democratizing the way agents are being built by using any kind of SDK or by using any kind of framework in different business environments, not only data scientists, but this kind of framework should actually support data scientists, software engineers, AI enthusiasts. To build their own agents, be it agentic or be it non-genic layer like non-aggenic solutions, our fundamental thought process, people should be able to build their own multi-agent systems, and this particular layer on the very top from a platform standpoint should actually support in building up these layers on the go. Capabilities like deep research agent, uh, capabilities like IDP or call, like call summarizations or customer service summarizations, uh, image recognition. Like there are a lot of things which goes inside like capabilities that could be built as top of your agent layer on the very top. And the core idea is you provide core services like interpreter, uh, execution, browser, etc. like these kind of tools. And make these agents self-discoverable across and make them reusable across on the agent layer or the agent development layer itself. So people on the very top are just focused on development. They're not focused on the, the rest of the components from a platform standpoint. The core platform in the middle should become more like a foundation layer on these Asian development systems that we are trying to build on the very top. The core platform should handle things which are related to a centralized bedrock environment, your context engineering environment, your development environment with StageMaker Unified Studio and Enterprise data stack. That becomes your foundation. And some of the core pieces that we want to add here is your MCP gateway, your A2A gateway, your GAI gateway. Along with that, we are thinking of adding a registry for your agent discoverability or agent management and agent report card, and registry for your MCP and MCP uh MCP management as well. So fundamentally, any agent that is being built on the very top will use the core functionalities from your platform layer. And they will actually adopt the agent configuration patterns, agent agent-like registry patterns, discovering those agents, identifying the performance of those agents, and deploying those agents. So your core platform will become more like your foundation layer on how some of the core services can be provided in a modular way. These modular solutions will actually help people on the top layer in deploying things at a scale. We can reuse the agent monitoring or agent development deployment, like any of those frameworks on the top, from the bottom, and deploy those things on the very top. So these are like two different layers that we are envisioning of building, and the infralayer sits in the middle, and your enterprises infrastructure services, which are like your splung service now, etc. stays in the very bottom as the crude base layer of the entire thing. So that's how we are envisioning how a hybrid modularized platform will shape up and help us in attending our ambitions of creating like different multi-agent systems for different business functions in the longer run. Uh, with that said, uh, I'll give back to Moon to conclude and give the takeaways. All right, uh, almost there. Thank you, Robert. So, uh, before you guys go, um, I just have 3 takeaways. It was pretty hard to boil down to 3, but, um, first, scaling with time is not trivial, right? Everybody, anyone can scale nowadays with Kubernetes with any, uh, scaling platform, right? But, uh, scaling with time, uh, requires you to think more deeply about, um, how you're gonna prepare yourself for the future, right? Um. So, um, understanding what the latest, uh, GI trends are and also how you're going to optimally maintain the performance, uh, requires you to make your solution modular. So here modularity is key, right? For your long term success and this will enable the first point ensuring the fungal liability, I think that's a popular term in finance and technology, but uh it allows you to um have a building blocks and um replace some some of the things that if uh you need to um exchange it for something better. Um, and also separating concerns, right, uh, to ensure that, uh, each unit can operate independently and scale, um, also independently. And lastly, we want to have a centralized platform to stabilize growth, right? Just like Rohit said, you want to have multiple layers. One is a core layer and then on top of it you wanna have a distributed layer, right? Uh, this will allow you to provide, this will allow you with governance, right? And this will prevent silos between teams, between GI solutions. And uh it will allow, it will also make it easy for your GI solutions to uh plug and play within your um within your platform. So with that said, um, um, that's, yeah, that's the end of our slides. Uh, we're open for questions. Thank you. OK.