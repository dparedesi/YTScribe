---
video_id: sogq2AHaqJc
video_url: https://www.youtube.com/watch?v=sogq2AHaqJc
is_generated: False
is_translatable: True
summary: "Mike Revitz, from the AWS product team, presents a deep dive into the new features of DMS Schema Conversion, particularly focusing on the use of generative AI for database modernization. He is joined by Vlad, a tech lead for databases at AWS. The session is interactive, with a strong emphasis on live coding and answering audience questions. The main announcement is the launch of Sybase to PostgreSQL conversion using generative AI within Schema Conversion. This is a significant development, especially for the finance sector where Sybase is prevalent. Mike explains that the conversion process uses a combination of deterministic and probabilistic rules. The deterministic engine, which has been in development for over 15 years, handles the straightforward conversions. If that fails, the probabilistic engine, powered by AWS Bedrock, takes over. This engine analyzes the context of the SQL code and generates a PostgreSQL equivalent that achieves the same outcome. Mike demonstrates this by converting a Sybase database to PostgreSQL. He starts by showing the database schema and data, and then attempts to convert a view and a stored procedure that fail with the deterministic engine. He then uses the ""Convert using generative AI"" feature, which successfully converts the code. He emphasizes that while the AI-generated code is likely correct, it should always be tested thoroughly. He also shows how to export the converted SQL code to an S3 bucket, a practice he strongly recommends for version control and repeatability. The second major announcement discussed is AWS Transform, a full-stack conversion service that uses agentic AI to modernize .NET applications and their SQL Server databases to PostgreSQL. This service automates the entire process, from analyzing the application and database to converting the schema and data, and finally, modifying the .NET application code to work with the new PostgreSQL database. Mike walks through the process of setting up and running a Transform job. He highlights the importance of fulfilling the prerequisites, such as setting up database credentials in AWS Secrets Manager and providing access to the GitHub repository. The Transform engine then analyzes the application and database, identifies dependencies, and groups them into migration waves based on complexity and interoperability. Although he can't show the entire end-to-end process due to time constraints, he shows the results of a job he ran the previous night. He demonstrates how Transform modifies the .NET application code, including changing connection strings, adding the PostgreSQL framework, and even creating new functions that are required for the application to run on PostgreSQL. He reiterates that this AI-generated code should be tested, but it significantly reduces the manual effort required for modernization. In conclusion, the session showcases how AWS is leveraging generative and agentic AI to simplify and accelerate database and application modernization. The new features in DMS Schema Conversion and AWS Transform provide powerful tools for migrating from legacy systems like Sybase and SQL Server to modern, cloud-native databases like PostgreSQL."
keywords: database migration, DMS, schema conversion, generative AI, Sybase, PostgreSQL, AWS Transform
---

OK, welcome, everybody. Hopefully you're all here to look at um database schema conversion or DMS schema conversion. I'm also going to be covering the new transform announcement that uh G2 made on Monday, if any of you saw that. So, it's all about new announcements, um, so those of you that saw my session last year. The flow's the same, the content's completely different. It's all the stuff we've done this year. So I'm Mike Revitz. I'm a database migration specialist. Uh, actually I work in the product team now, but I'm not a database migration specialist anymore. I've moved teams. I'm now in the product team, uh, controlling the, uh, uh, how the skimmer conversion's integrated with AI. I'm joined by Vlad. Hi, I'm Vlad. I'm the tech leader for databases here. I'm here really to help him out, so I'm gonna be running around with the mics. If you have any questions, raise your hands and I'll come to you. Well, yeah, and please, uh, ask questions. It's, uh, it is level 400. I, I'm assuming that you're all reasonably comfortable with database terminology and ask questions. Uh, code talks are unusual, they're interactive. Uh, we encourage you to ask questions. As I'm going through the demos today, and I will be live coding, by the way, I've only got about 4 slides, the rest of it I'm gonna be coding the entire time. There's 3 or 4 things I've got to show you, the rest of it, if we don't, we don't. Um, questions are more important. If there's things you want to know, please ask. Um, Vlad's gonna be running around with the mic and uh be able to take the questions. I'll be looking at my monitor, so I, and I'm looking at all these bright lights. I can hardly see anybody anyway. So, I've pretty much gone through what we're going to cover. I believe these slides are available for handouts. You can go back through these, but as I said, it's the Sybase is a big one. Anybody using Sybase databases in the audience? There's a few of you. Good, good, yeah. Uh, so I don't need to tell you that it's quite a hot topic at the moment. Um, so we are about a week ago, Friday, just before. Event we launched Sybase with generative AI in schema conversion. So that's our big announcement this year, and I'm going to be showing you that, how that works. And the other announcements, as I said, was G2 with Transform, and that's using the entire stack using Agentic AI converting .NET and SQL Server to Postgress. So I'm going to be showing you that as well. Um There we go, so. I typically start with this slide, and the reason I start with that, this is the database we're gonna be going through, by the way, the Sybase database. Uh, but the reason I show this is more informational. Whenever you use schema conversion to do an analysis of your database, you get a report and it typically looks like this. The, the one that says 100%, that's your data objects, those are your tables. It's, if it's not 100%, it's 99%. It's, it's very rare that it's anything other than that. Your code objects, those are your challenging ones, this is where your business logic resides, and when you see something like this, 6 66%, does it say? Yeah, when you see something like this, your immediate reaction is, well, that's gonna be too difficult, so I need to not do it. There's a couple of things you need to understand with that. One, and, and we're, we're looking to move away from this, by the way, percentage doesn't actually tell you anything. 66% of a uh database that's got 100, 1000 lines of code, that's what, 300 lines of code that have got to be converted, that's no big deal. But 95% of a database with a million lines of code, that's a big deal. So the percentage doesn't give you the whole story, so you need to dive deeper. And the other thing about schema conversion is if it doesn't know what to do, it typically throws a 9997 or a 9996, a 999 something, and that basically says I couldn't work it out, and therefore it assumes it must be really difficult. So you get a report that says, I found 100 things and they're all really hard. One of the most common causes of that is dynamic sequel. It doesn't know how to interpret dynamic sequel because all it sees is a string. It doesn't know what's in it. When you actually analyze the code, more often than not, it's a straight conversion, it's actually really straightforward. It's not difficult, even though the report gives you this scary number. So all I say is, that's not a reason not to do, dive in, find out what's going on, find out what's really sitting behind it. I think this, oh no, I've got 22 slides to go, a couple of marketing slides, apologies. Schema conversion. So this is the product that we use, connects to a a source, connects to a target. For generative AI, the source databases as of today, are Sybase, SQL Server, and Oracle. Uh, your target is Postgress, so those are your generative AI options at the moment. The source and target can be anywhere where you can get an IP address, a connection to using JDBC. So EC2 on-premise doesn't really matter as long as schema conversion can see it. Within the engine, we've got deterministic rules. They've been there for 15+ years. They're pretty established now. Even Sybase was in there, so schem, did anyone use Schemer Conversion Tool? Uh, which, yeah, a few of you, that's good. So Schema Conversion Tool is a product we created 15 odd years ago to convert databases, and then 4 years ago we turned it into the service schema conversion, which we did so we could add things to it like generative AI. Sybase has been in that code stack for almost since it launched, I think about 1413 years ago, we've had Sybase deterministic rules in the engine. So adding Sybase into schema conversion, actually we took a very well established code stack and put it into our service, so we didn't have to create new stuff here. So it's a pretty, a pretty solid conversion rule set that's in there, the deterministic rules. The new bit that we've added, as I said, is the probabilistic engine, uh, using Bedrock. So we, so the way it works is if the deterministic conversion doesn't work, we then give it to Bedrock to see if we can use probabilistic rules to do the conversion. Uh, and, and that's how it works, that's, it's as simple as that. I went into that in a lot more detail last year. Uh, I want to get into the coding this year. The other one that I'm going to go through is the transform announcement, the one that G2 made on Monday, and this is, this is a full stack conversion. Now, I'd love to show you the entire thing end to end, but unfortunately, it takes an hour and a half. Uh, so I can't, uh, I can't do that, so apologies for that. But actually if I step back, I'm actually not really apologizing for that if I think about it, cause I'm doing a full stack conversion at .NET and a SQL Server database from SQL, uh, yeah, SQL Server database from Microsoft to Postgress, and I can do that entire process in an hour and a half. That's actually quite impressive. My problem is I've only got 60 minutes, so I can't show you the whole thing. Now, I did run it last night. I've run it end to end last night. So what I'm going to do, and I, I'm gonna have to bounce around a little bit cos it's an ergentic AI solution. And so you kick a job off and we can sit there and watch nothing happen for 5 or 6 minutes, or I can show you something else. So I'm going to be bouncing around a little bit just to show you what's going on, so we're not watching the paint dry. Um, and and so what I'm going to be showing you is we'll, we'll go through the Agentic model, show you how it all works, and then when it's running, I will show you some of the things that it created last night, so I can show you what it's actually doing, um. There's one job we're going to get to which runs for 20 minutes. When we get to that point, I'm gonna switch in and show you the cyber stuff. Um, and then if I time it right, when we come back, we'll be at the next step in the Agentic model. So that's what we're going to be doing. And I think that's it for my slides. Oh no that's me. Um, all you need to know about me. I've been doing this a long time. As people that work with me like to point out, I started migrating databases before they were born, so that either makes me really experienced or really old. I prefer the former. I'll, I'll let you decide. Um, but yeah, that's me. Right, from that, we're gonna do some coding. Uh Yep, and we're on the right slide. Um, I prefer to stand than sit down, but I think I'm gonna have to sit at some points to type, but I'll be up and down, but I can't, I can't see you if I'm sitting down. So. So we're gonna start with the Agentic uh model, um, the transform model. So what we're gonna do, this, this, uh, this application is freely available on the Amazon website. I've got some links at the end of the slide deck because I'm pretty certain they're downloadable, but if they're not, if you search for Bob. Use Books. It's a little .NET application. We use it for testing and training. Um, all I've done is I've taken, so when you download it and you install it, it installs everything into one host. All I've done is move the SQL Server element out into an external SQL Server enterprise database just so I can demonstrate it. So this is the application. I'll just very quickly show you what it does. Uh, if I log on, it should show you some stuff about me. There we go, I'm logged on. Um, so it's a running application. It's got pages. I created an order which I canceled. Uh, I can shop for some books. It's not a huge database, I'll be honest, but it's got all the processes in it, and it gives me something that I can demo. I'm not gonna bother ordering anything, it won't turn up anyway, it's only running on my laptop. Uh right, so let's go in and we'll start in transform. Now, I've done this a few times and I've got so much to show you. If I don't go to my cheat sheet, we're gonna get lost. So we're gonna start in the transform. So this is the transform engine. So I've created a work space, I've pre-created the workspace and I've done that so I can create all the engines in it. And within there I've got this one job that I ran yesterday, uh, which took this end to end, that's successfully completed. So the first thing I do is gonna create a new job. And so what it's now doing is it's having a look to see what things are available to us, uh, what things it can offer me that I, that I can create. Uh, and so here's the list. Um, so there's a number in there, mainframe, etc. but the one we're interested in is Windows modernization. So if I click on Windows modernization, it now gives me two choices. You've got .NET modernization, and what that does is it will modernize the .NET application into uh modern architectures. And you've got SQL Server modernization, which actually does a .NET modernization as well. But the dis the distinction is the SQL Server modernization is converting the SQL Server database into Postgress. In fact, I'll click that so it's doing something while I'm talking. Uh, it'll convert the SQL Server database into a Postgress database, and then it will modify the .NET application and make all of the SQL Server code changes necessary to make it run against a Postgress database. Um, and that's the bit I'm going to show you at the end. So, um Unfortunately, I have to wait for the Agentic AI to catch up with where I'm up to. So at the moment it's looking at all the things that it's got to create, all of the privileges it needs, all of the access it needs in order to complete a a SQL Server modernization program. So one of the things it's got to do, this is running in, in a separate service, this is a separate service available to me. It's not part of my AWS application. So it doesn't have privileges to connect to any of the things in my account. So one of the first things it's gonna come up and say is, in fact, the first thing it's gonna come up and say, uh, thinking about it, is it's going to come up and it's going to give me a list of prerequisites, things that you have to do, so. One of the things we discovered, so this has obviously been through Ibita, we've had it out with pilots with lots of people, and one of the things, oh, it's come up already, uh, one of the things that it's going to do is it's going to say, you need to have done all these things before we start, or I'm going to fail. Now, we're all engineers. Once upon a time I was an engineer as well, and As an engineer, reading the manual is an admission of failure, so you know, we none of us read the manuals. Um, I'm telling you, read the manual because if you don't, it's going to fail. So we've got a whole list of things up here that you're supposed to do. Actually I'll say I never read the manual. Um, anyone use KNR that mean anything to anybody, or are you all too young, uh, all too young. KNR is the C Bible, it's about that thick. It was written by the guys who wrote uh C initially. Uh, I used to live with that on my desk, but anyway. So let's see what it's gone and done. Um, so it's come up and it's said, well, I'll explain this so you can see it. It said, you need to do these things before I can start. I'm, I'm not gonna succeed if you haven't done these things. And this is all database stuff really. So it's saying you've got to have a user in your database with permissions to read it. I've got to analyze your database, I've gotta be able to connect to it. The other thing it's saying when we come down here is the credentials, so your database credentials have to be put into an AWS secret so it knows how to log onto the database. But you've also got to put some tags on that secret so Transform knows how to find it. Otherwise, I mean, most accounts have got loads of secrets in it, which one do you go to? So you've gotta have a secret in there. And this is what your secret's gotta look like. I'm not gonna show you my secret cos it's got my log-on credentials in it, uh, but this is the contents of your secret, username, password, what type of engine it is. The engine's actually required to tell schema conversion what it's doing, not for transform. Uh host name, IP address. Oh, here's an interesting one. during our early testing, uh, we don't know why. Um, but if you put a domain name in there, it may fail, not all the time, but it may fail. Um, we're investigating that at the moment, so if you put an IP address in there, it works every time. It's something going on in schema conversion we haven't got to the bottom of yet. So if you're testing this for now, use an IP address. Um, domain name will be fixed because IP addresses are bad. Um, I hopefully I don't have to tell any of you that. Um, so, So that's the database side of it, and then the other thing you've got to do is you've got to tell Transform how to connect to your GitHub repository, and so you've got to have created the necessary stuff inside your account to connect to your GitHub repository where your .NET code lives, um. And I've really got to stop talking while I'm doing this, I should click go so that it's actually doing something whilst I'm talking. Anyway, so. We're now clicking off and now, so what it's done is I've confirmed that I've done all those prerequisites, um, and it's now going off and finding out if it can actually see everything, so it's told me what it needs, and now it's going to say, Can I get to the stuff you've told me you've already done, so it's gonna try and get to the secret, it's gonna try and get to various other things, and what it's gonna come up and say at some point, now it's still running at the moment, catches me out every time. You've got a yellow box that there saying I'm waiting for customer input, and to the right, I don't know if you can see it in the room, to the right of it, it says it's running. It's actually working, it's not waiting for customer input. It's just telling me it is just to confuse me. Um, so what it's doing is it's trying to find out if it can connect to the things it needs, and it'll come back in a minute. And what it's going to do is it's going to, in fact, has it come back? Yes, it has. It's gonna come back and it's going to say I need some privileges. So, the first thing it says is, I need a connector that knows how to connect to your database. Um, now, I can't say create a new one, cos I've already got one, it knows there's already one there, so all I can do is choose the one I've already created, um. If I, I've had to do that because to connect to it, I've got to put all my connection details in there and again I'm not allowed to do that. That's a bad thing to do, to put up on a screen all my connection details to my Amazon account, security would not be happy. Uh, so the next thing it's gonna do is it's gonna say, OK, so I know how to get to your database. How do I get to your application code? So the same thing, I've got to say I've already created a connector, uh, and this connector gives you the privilege to talk to my account. So when I say choose the connector. You see this, uh, does my mouse show up on there? Um, we've got this approved, so what this means, so what is actually happening in the background, and I'll kick that off as well so we're not waiting, uh, so what's happening in the background is I create a request against my Amazon account, and that request is saying my transform session wants the privilege. To connect to to resources inside your account. And so what happens inside my account is I get a notification request to say this thing is trying to access your account. Do you allow that or not? When you say yes, what you've now done is you've given transform permission to run those things in your account and It creates some uh IM roles and things like that that allow that to set it all up. So that's, that's what I wasn't able to show you, but that's what's going on when I was doing all those authorisations. And so now what it's done is it knows how to connect to the database, it knows how to connect to my GitHub repository, so it's going to give that a go. And I'm just gonna see if this is one of those eight-minute jobs or not, cause I've got a feeling it is. Uh, oops, that's down on this one. Uh, so, yep, we've done that, right, so let's go back into here. So what I'm going to show you. One thing I always do, and this is more an educational thing than anything else, I am and have been for a very long time, a huge advocate of infrastructure through code. If you're not currently doing this, I really, really strongly encourage you to learn how to do this. Everything you're looking at that you're running today, that I'm running today, is built through cloud formation templates, every single thing. So when I finish doing a demo like this, I just delete my stack, it deletes everything, I build a stack, and it's back to exactly where this started. Um, I cannot encourage you enough that you really should be doing that if you're not already. Hopefully you all are. Um, so the first thing I'm gonna show you is the, uh, architecture we're running here today. So, as I said, um, Bob's used books. Is that big enough for you? Do you need me to make it bigger, by the way? All good? Perfect. Uh, so we've got 3 EC2 hosts, I've got my bastion host. Um, I use my bastion host, uh, because that lets me RDP into my hidden, into my, uh, SQL Server host. So one of the questions I get asked a lot is, how do I connect to my RDS databases? They're hidden on a private network. You know, I've got no access to it from the external environment, as it should be, by the way, you shouldn't have access to your databases. But what we do is we create what's known as a bastion host and then using SSH tunneling, I can use all of my desktop tools, so uh DBeaver or or whatever your tool of choice is to connect to your RDS databases. You can also use it to RDP into your SQL Server um hosts, which is what I'm doing here. So my bastion host has only got SSH access. But through that, I can open up an RDP session to my SQL Server host to debug it. So that's what I create that for. And then we've got one that's called my, uh, Bob's Books application host, you can probably guess what's running on there. And I've got the um SQL Server host. So that's what's running. It's a pretty small environment and that's what we're connecting to. Um, the other thing that I wanted to show you in there is, uh, the secret, there we go. Uh, where's the secret? So, One of the prerequisites was you've got to create a secret that tells Transform how to log onto your database. So here's my secret, uh, Bob's book, SQL Server, and the IP address. Um, I, I actually build this up dynamically in my templates, so it actually is the name of the database at the end of it. And so this is what it is. I'm not gonna show you the contents, but I'm gonna show you the tags. So remember I said we've got to have tags on the secret so that the Transform knows how to connect to it. So there's the two tags, project and the, the name. It is case sensitive, so make sure you're entering it like that, and the owner as database connection. So that allows Transform to connect to the secret, and the secret tells it how to connect to the database. It doesn't know anything else about the database. Uh, the other thing that you've got to create is this one. So this is in the developer tools, and this is the bridge between my Amazon account and my GitHub repository. So when Transform wants to modify my .NET code, it's going to use this link to get to my GitHub repository to make all the changes in there. And then what it will do at the end, it will ask me to create a new branch, is actually what it's going to do. So that's everything that it's doing at the moment. It's, it's connecting to my secret and to this uh connector to ensure that it can connect to the things it's got to convert. uh, and then let's see where it transforms up to. This is where I don't, yeah, it's still running, right. So the other thing that I'm going to show you then, uh, whilst we wait for that to finish doing something, is I'm going to go in and show you some of the stuff it created last night. So, um, one of the things, the first thing it's going to create is it's going to go into the console, into the, uh, database migration service. Actually I'll go back to the start so we know where we are. So database migration service is where all of the database conversion tools live. Skimmer conversion, which converts the uh the structure of your database, and database migration service moves the data between databases. So the first thing that the transformer is going to do. Once it's finished ensuring it's got connectivity, and I'm going to keep an eye on that because I want to kick that off so it starts doing the work, it's going to create a profile, and what the profile does is it tells schema conversion what networks it can run on, what privileges it needs, and everything it needs necessary to connect to a database. It's then going to create 2 data providers. It's going to create a data provider which connects to your source, and as I said, this is that bug that I've told you about, um, use the IP address for now. Uh, for some reason that only affects the source, not the destination. So for my Postgress database, I'm able to use the DNS name. Uh, and in fact, it would appear that this has already created it because something that it's just changed. So it's actually looks like it's found the one I created last night actually, because I can see that it's changed the virtual mode to on. So let's have a quick look in there and see what's going on. Um. No, that one's not a virtual mode, that's bizarre. Uh, so anyway, let's go back to where I was. So what it's gonna do is it's gonna create two data providers, one of them to connect to the SQL Server database, and the first one, when it does its analysis, it's gonna use another new feature which we launched about two months ago now, where you can use a virtual target, so you don't actually have to have a Postress database in order to do your analysis. So it's going to create one of those and then it's going to create a project which connects to the two and it's going to do the analysis on the database to work out how hard it is to convert and you get a report like the one I showed you at the beginning. Uh, let's see where we're up to. Uh, we're still running, OK. So, oops, not that button. Uh, so once it's done that, uh, in fact, let's show I can show you what's going on inside there then, cos we've got time if I'll get back into the right window. Uh, so this is what a migration project looks like, um, so we can see all the connectivity details. Uh, when you go into schemema conversion, we can now see. The source database on the left, this is my SQL Server database, and Here we go, Bob's books, oops, and uh the only schema within there is DBO. Eventually In its own time, there we go, um, and it's going to be doing some analysis on that, working out how difficult that is to convert. Um, it hasn't run its report yet because if it had, I'd be able to see it in the bottom, and it's going to say, well, guess what, 100%, because this one's really easy to convert. So it's doing all that in the background. Now, I don't know how many of you have actually tried to use schema conversion. Uh, I think a few of you put your hands up earlier. It's, let's say it's got some nuances. It's not the easiest thing in the world to set up. Um, Transform's doing it all for you. It's nothing you have to worry about. Normally you'd kick, you know, a couple of Transform jobs off and it would be running, uh, and I really wish it would finish running so I could go on to the next part of the demo, but anyway, I've got no control over the speed the agentic AI is running at, so. So that's the uh schema conversion part that it's running. Now, the other thing that Transform is going to do if I go back into DMS is it doesn't just convert the schema, it also converts the data as well. And the way that it does that is again, it creates two endpoints. Uh, these are definitely the endpoints I created yesterday because I recognize the names. Um, so again, you've got a destination, which is your Postgress database. Now in We don't have the same restriction on names. You don't have to use IP addresses, but Transforms picked up all its information from the secret. So because it picked up the IP address and the secret, that's what it's used. And again, we've got the same target. And then the other thing it does is it creates a task. And so the task moves the data between SQL Server and Postgress, and as we can see here, it has, if I go into the right tab, it has moved. Half a dozen tables. It's not the world's most complex application, but that's not the point of the demo. The demo is not to show you I'm moving something complicated, it's to show you what it can actually do. So it's something that I want to succeed, let's be honest. Uh, but there is some data in there and it moves all across, and when you launch this in Postgress, all your data will be there. And unfortunately I don't have time to deploy all that, so you're going to have to take my word for that one, I'm afraid. But that's the other thing that Transform is creating in the background and again you don't have to do it. You can create as many of these jobs off at the same time as you can, so we can use this to migrate 100 SQL Server databases, for instance, instead of having to do them one at a time. Right, ohh, finally, it's asking me for something to do, cool. Right, so it's gone through and it's found everything, so let's bring this one up so we can see it. So it's found my, my database. Uh, it knows it's running on EC2 and it says this is the database uh that I found, do you want me to do anything with it? Uh, and it's also found the repository, uh, and it's found that there's a branch in the repository. There's the main branch, which is the one I wanted to convert, by the way, that's the SQL Server branch, um, and then I've got this reinvent 2025. This is the one I created yesterday. We're gonna look at that later on, by the way. So this is the converted Postgress version of my application, um. But I'm gonna convert it into mine because it's not gonna do anything if I choose the Postgress version. So once I click start assessment, it's now going to connect to the repository, do analysis to find out how difficult that's gonna be to convert to Postgress. It's going to do the same with the database, run an assessment report and find out how difficult that is. Um, now, When it's doing the connection, it is quite possible that when it went to the SQL Server instance, it may well have found several databases, and in fact, the first time that I ran this through as a demo test, it found every single database in my SQL Server estate. And then what happens if you had a a GitHub repository with multiple applications in it, you get a report for everything, and then you get to choose which ones you want it to convert. Um, for simplicity's sake, I've stripped it down to one, because again, I want the thing to work. So it's found the one database, the one application, and it's now going and running a report to see how difficult that will be to convert into Postress for me. So. So that's what it's doing, but it can do multiple applications, as I said, it will find every single database in your instance when it comes up. And what it's going to do now is based on complexity, it's going to put those into migration waves. It also looks at interoperability, so it looks at is the dependency. Between your application code and your database, do they talk to one another? Do I have to put them into the same wave, or can I create waves based on complexity? So all that's going on in the background, and I hope we get to that point when we, uh, when it's finished running. Well, this is gonna run for about 20 minutes now. So what I'm going to do now is I'm gonna take you into the Sybase, uh, part of it. Um, so we'll just double-check that that is indeed the one that's, uh, going through. We've done all that, uh, we've done all that. Yes, so we go and we're now into the assessment, so we've done all that. Let's go into, right, so. Oh, I suspect you're all well, uh, versed in AWS at this stage, but I will point this out because it is one of the gotchas that if, if you've not been into the console before, this again is the cause of, of quite a few support calls. Um, I'm running out of North Virginia, US East One for all of my transform stuff. My Sybase code is all running out of Oregon. So one of the Ah I've been worried for a minute. Um, all of my, uh, so my Oregon account has got a completely different set of project codes, and so you, we sometimes get it that when people go into the console and they go into their EC2 list or the database list, there's nothing there, and then there's a big panic. Where's all my, where's all my stuff gone? Um, make sure you're in the right region. Um, so anyway, so I've gone into this region. I've got 3 projects in here. I'm only gonna show you the Cybase one because I haven't got time to show the others, but these are the 3 database pairs I talked about earlier. It's, do I need to make that bigger? It looks a bit small on mine. Is that big enough for everyone? It's all OK, good. Um, so these are the three database pairs that we currently support for Gen AI. So we're going to Sybase. Again, you have a secret which has got all the logon credentials. This is how schemer conversion knows to connect to your database. You have to create a role, and the role gives schemer conversion the permissions to read the secret, uh, same for the target. And then the other thing which is in here, so I'd say the schemer conversion bit. The other thing that's really important is you have to create an S3 bucket. Uh, I do know that this causes customers or organizations some challenges because of demarcation of roles. Uh, but these are all prerequisites for schema conversion. Transform doesn't have the problem, by the way. Transform does all this in the background, all of the stuff you've got to pre-create, other than the secret I mentioned at the beginning. But when you're doing schema conversion yourself, so when you're doing it for Sybase, you've got to create all of this. Uh, so if we go into the console. Uh, on the left-hand side, uh, this is the, uh, the slide we started with. Uh, we've got, uh, my demo database. My reports 100% on my data objects, 66% on my code objects. So the first thing I'm going to do, I, I've also, um, so again, this was all built with a cloud formation template. I, I rebuilt it all last night to make sure it was all good to go today. Um, I have, as part of my build process, I've used the API calls into schema conversion to convert all of the tables. They're 100% anyway, and I've also moved all of the data because that clock is ticking alarmingly fast. So I, I wanna get as far as I can to show you the important bits, so DMS works, I don't need to show you that. So, first thing I'm going to do is I'm going to go into uh where's that window? I'm going to go in, I'm gonna log on to my um Cybase database first, and we're just gonna make sure all of the data's there, so that's, oops, it's in this one, Rather than you watch me make a load of typos, I'm gonna cut and paste it, so I've just connected to my Cybase database. Now what's interesting about my Cybase database is this isn't even in my account, it's not even in this region. I have connected to a Cybase database that's in somebody else's account in another region completely hidden. This is using, as I said earlier on, this is, I'm using an SSH tunnel, which I've got in. Another window open up to allow me to connect to this database so you can still use all of your desktop tools to connect to these hidden databases. So again, it's not a huge database, but it's got a number of tables in it, some data in there, and if we have a look at the Postress database, I'm hoping so this is the Aurora Postgress database, uh, it's got the same data in it, um, which I'm really glad about cause DMS copied it across and I'd be really annoyed if it was different. Um, so we've got two databases with the same tables and the same data. Now the challenge you get is converting your business logic. It's the business logic that causes the problem. So the first thing I'm gonna do, I'm gonna look at a view, and I'm gonna, uh, from in here it tells me which view I'm looking at, uh, the portfolio summary, right, um. So all of the code in this database is financial code, but Sybase, for those of you who aren't familiar with Cybase databases, it's really, really prevalent in the finance sector, especially in Europe. There's an awful lot of Sybase there. It's typically very old. It typically Began life in either IBM or Sun as it was at the time, so it's all Unix-based typically or it isn't anymore because they've ported it, but it's all typically old code. Customs I've spoken to, there's nobody left in the company who's written it. This is code that's been there 2030 years, so it's a mystery. Um, in fact, I was chatting to a customer earlier on today who've got a number of Cybase databases that they've got to, uh, that they've got to do something with, and the challenge they've got is, as I've just said, they don't know anything about their code. Now, I was with a customer down in Spain earlier on this year, who exactly the same position, ton of uh Cybase, uh, financial code. This was a, uh, I think this was a trading house I was with. Um, and nobody in the company knew anything about it, so I can't remember how our conversation got around to it, but in the meeting I was at with the CTO and his chief architects, etc. I used what at the time we called Q Developer. We've just rebranded it as Quiro. You must have seen all the stuff about Quiro now. It is really cool, and I pointed Quiro at the directory where their source code was and said, What can you tell me about it? And what it told the CTO, it told them which company they bought it from, when they bought it, all the changes they'd made to it, all of the security patches they'd put in it. It gave them all this information about what the application did, what it was for, where it came from. Not one person in the room had a clue about any of that. The next thing I said is, so. What other things does it talk to? What, what objects in the database does it use? So it again scanned the directory and then then it gave me a report and said these are all the database objects it talks to functions, procedures, tables, and this is, this is how all the functions interact with one another. So it gave me all the interoperability points, and it did all that in about 3 minutes. So those of you that are worried about or wondering how am I going to modernize my cybase databases, the tools exist. Just use them, you'll be amazed at what it's doing. Um, the, what we've done with schema conversion is turn it into a service for you, specifically for the database part of it. Anyway, I, I digress, uh, I've forgotten the name of the view I was looking for now. Uh, I am looking for the view called Portfolio summary. So portfolio summary, there it is. So portfolio summary, um, it, uh, failed to convert. I've got a 3014, I've got a, a critical error. So schema conversion using deterministic rules has said, I don't know how to convert this piece of code. So, Think, hours, days of coding effort. So what you can do now is we've got two options. We can go through the convert button here or I can use convert using generative AI. They both go to exactly the same place. I'm not entirely sure why we put an extra button on there. Comfort I guess. Uh, but what it does is it opens this pop-up window. Uh, the convert will do the same by the way. And we've got this toggle switch. And the toggle switch says, and I'll kick that off running, uh, what the toggle switch does is it says, OK. Once you finish your deterministic conversion, actually I use these terms all the time. This was pointed out to me when I did my walkthrough. Do people know what I mean when I say probabilistic and deterministic? Yes, no. Yes, all familiar with James, good. I, I was. I use them because I know what they mean, and it's one of these things where you say things, but anyway, um, yeah, so it goes through and it does the deterministic rules, and if it can't convert it, and it hasn't done in this case, what it does is it packages up the context of the sequel and it sends it to our Bedrock engine where the LLM has a look at it and it and it understands the context of being, what's being done, understands what we're trying to do, and it will come up with an post-gress alternative which will achieve the same outcome. Um, Now when it does the conversion, it doesn't actually mark it as being fixed. So when you do a deterministic conversion, what that means is I can determine what the correct outcome is. So in the case of, say, an apologies, my background is Oracle, so I have to revert to Oracle syntax. But in the case of Oracle, if I'm doing, says if this value is null, use this one, standard function. In Pogress, the command for that is called coalesce. So coalesce, if this one's null, use that one. I know that if I replace MVL with coalesce, it's guaranteed to work. I can mark that as fixed. That's an example of a deterministic rule. A probabilistic rule, uh, and you can just see now that it is completed, it said I have successfully completed this conversion, 100% success rate, uh, but it hasn't marked it as being successfully converted. It should, let me see if I can show you this, if I scroll up. Uh, action items, there we go. Um, I, I don't know if you can read that, but it says this conversion uses machine learning, uh, that generate predictions based on patterns. Basically, I can't say this is fixed. I think it's fixed. This is why it's a probabilistic, it's probably right, but we don't know. You really do need to test this. Uh, I've got a session coming up, my next session. I'm actually gonna go into this in a bit more detail, but I haven't got time here. Uh, but yeah, but you really need to look at it, test it, it probably right. Anyway, uh, so we've deployed that. So one of the things you can now do, um, and I say this every time I do it, I'm not a fan of this feature, but apparently management love it. I can go into this now and I can say apply that to my Postgress database. Actually, before I do that though, what I'm going to do is I'm going to run it, so I'm gonna execute the view in my, uh, Cybase database. Uh, so let's do that. So when we run it in my Cybase database, so this is um a view of my portfolio, so a list of all the stuff we've got basically. Um, now, because I didn't convert this earlier on, I sincerely hope, if I run this in Postgress, I should get an error because it's not there. Indeed it's not. So it's saying, you know, view's not there, it didn't compile, I couldn't, I couldn't deploy it. So if I go back now to my uh console, one of the options that's available to me is I can, Apply this change directly to the database now. I've been head of architecture, I've been head of development, and I would discourage very, very strongly anybody from my team ever doing that. Like, where, where's the control? How do you know you can repeat what you've just done? Um, for my next conversion, I'll show you what you should do, but it's there. Now, I suppose the argument's there that if I'm in a development environment, I want to just rapidly deploy it if I can, and so the ability to deploy it multiple times, um, possibly works, I don't know. Not a fan. Anyway. Uh, let's go and have a look and see what that's done. So if I now go back and rerun that query against my Postress database, uh, we can see that it has now successfully worked. So the code that generative AI has converted has worked, and I hopefully, uh, if we have a look, uh, they're coming out in the same order. So William Garcia's got 100 whatever players, uh, worth 9800, and if we go down here, he's got 100 of them worth 9800. I'm not gonna go through every line. But it's converted all the code, it's executing correctly. So there's a conversion piece that you don't have to work, uh, worry about yourselves. Now, the next one I want to show you is, cos that's a view. Views, views are more straightforward, and nothing's easy when it comes to conversions, by the way, but views are more straightforward. So let's have a look at a package and the package I'm or procedure actually, I'm gonna look at is generate trade report. So let's see if we can find that one. so in our procedures. SP generate, generate trade report. Oops, let's go, put that down. So here's generate, oh there's the 9996 error that I was telling you about earlier on. So generate rate report has again failed to convert. Uh yep, you can see, 0% conversion. So I'll kick that off and start it converting before I start talking about it. Um, we'll be here forever. And we Roth. So yeah, so. So this one is, uh, again, it's, it's actually based on financial code. One of the ongoing challenges that we as a cust company have is getting our hands on representative customer code. Everybody says, can you give me a customer reference? And everybody says, I don't want to be a customer reference. Everybody says, Why don't you use this against customer code, but no one wants to give me customer code. So it's an ongoing challenge that we have. But sometimes we work with customers, early adopters and the like, where we work with them. We do occasionally get our hands on code. So the code in here is, it's not customer code, I hasten to add, but it is based on it. It's using the types of things that struggling. So when we've done conversions for customers in the past where we've had to manually convert the code, these are the, this is the code that we've trained our model on, uh, to get it to do the conversions because that's how, that's how AI works. You have to train the model, you have to show it the correct way to do it, uh, and then you repeatedly do it. So these are all based on that. Now, the other thing you'll notice, um, that's it's finished already, that surprised me, uh, the other thing that you notice is The deterministic conversions are pretty quick. If I do a deterministic conversion on that function, it's gonna be uh almost instant. But when you do it through the AI model, it slows things down dramatically. So this is one of the things that you need to take into account, it's like don't just blindly convert your database using everything with AI because unless you can kick it off overnight, that works, uh, but it is gonna take you a lot longer. Anyway, we have now converted our procedure. So what I'm gonna show you now is the way that I would encourage all developers to do with this, and so we can go back into actions now, and I can say save a SQL. So what this is going to do is it's going to create the SQL code and it's going to write it up to the S3 bucket that sits underneath um. Sits under this scheme of conversion now. Hi, there we go. So one of the. Annoying, it annoy, it annoys me anyway. Everything that you're doing is at the back, not the top, for whatever reason, so I've just clicked that, I want that to create the code for me, but it's not the one that's on top, um, it's not that one either. Or that one, it's this one at the bottom. Uh, so what it's done is it's now said I've successfully converted the, the converted code into a SQL script and it's located in this S3 bucket location. I promise you, you want to click this button. Um, it is sitting in an S3 bucket. I, I don't know if any of you have ever had a look at the S3 bucket that sits underneath schema conversion, but it is a, it's a maze of files, you know, the chances of finding the file you're looking for in there are remote. Uh, so we've given you this link and it says this is the file, this is where the file is, and it's in a, a, a buried directory, and from here I can download it. Uh, so that's downloaded, yep, that's completed. So if I open up that one, cos that's the directory I'm running everything out of, and I open up that one, which is my downloads, I should. Be able to, uh, my finger doesn't go that far, there we go. Drop it into there, so if we now go back to here. Uh yep, there's the zip file. Oops, and zip. uh per square sequel, oops, sequel.zip. Right, so, I've now got the SQL file that's schema conversion converted and it's now sitting on my laptop, so I'll test it, and when it works, I'll put it into my GitHub repository. That's what I would normally do, and then for production you come out of there. So if I go back now and I go into my Postgress command, and I run uh Postgress SQL.SQL, there we go. Um, so I now deploy that into my Postgress database. And again, off of my laptop, I know I've said it a few times, but I'm running Postgress on my, on my MacBook and I'm connecting to an Aurora Postgress database, which is on a non-routable network hidden well inside my, uh, my environment, uh, and it works fine. Um, I'm old school. I said at the beginning, I'm old. I work on the green screen. I'm, I'm not a gooey person. Uh, I get ribbed about that all the time. I, I, I work on the console, sorry. But if you're if you're more comfortable in DBaver, you can do exactly the same in DBaver or any other gey of your choice, so. So, so, yes, we got a question. Yes, can you open the file, that Aji file, please? Can I what? Sorry, can you open the file? Oh yes, certainly. Uh, on. Uh, I'll make it bigger so you've got a chance of being able to read it. OK, so. So what it's done is it's uh drops the routine if it's there, um, creates a schema if it doesn't exist. I don't know why it does it in that order, cause surely you, no no, it's gotta drop the routine before you can drop the no, it creates a schema anyway, um, creates a scheme if it doesn't. They all exist in my environment, so those were the two that didn't happen. And then here is the uh converted code. So there's the uh informational message. Now one of the things that's really uh important in the informational message here, so this is the one that says make sure you test your program because it's probabilistic probably converted. And then it puts this marker in here and says this is the beginning of the code that I converted for you. Uh, so here's the, uh, here's what it converted, um. I've gotta be honest, I don't know exactly what this code used to look like, so I can't tell you where the change is, uh, but what it has done is it says this is the end of all the changes I made. So what everything I change is between those two markers. That is what it's done. Um, and so, and then it's just a create a replace procedure. Was there anything specifically you were looking for? what it looks like and it have. Yeah, I want to see like it's adding the comment what is done, so we can use this one and see, OK, what happened there at least. That's a good thing. And also having a protection if it's an exist, not exist, so that I want to see in the script file also. Yeah, yeah, and the other thing you can do actually is I, I brought it out as a single file. What you can do, and let me show you one of the other. Gotcha's features, I'll call it a feature. Um, one of the other features in scheme of conversion, uh, oops, that's not the one I want, I want. a conversion. Where schem, oh, there it is, uh, so one of the other things you can do is, so. Let's assume I had done. Uh, if I had, well, I've done that, so even though every one of those procedures is ticked, the assumption is because I've said deployer's code, you're going to assume that everything that's ticked is going to be exported. So one of the features. Yeah, I'll call it a feature of schema conversion is it only runs from the location of your cursor and below. So the only code it exported was the code of the procedure because that's where my cursor was. Now if I had gone up to this level and I had say clicked that one, that one and that one, and I said from procedures, I want you to generate the code, what it would then do is create one file with 3 procedures in it. Because it does everything that's marked below where the cursor is, and likewise, I can get one file with every single procedure in it uh by doing that. Now, what we would typically do, what I'd recommend people do when they're coding is at the data object level, tables and indexes, because those are almost always 100%, I would take them all out as a single file. But when you get down into the code objects, you know, the procedures and the functions, I would typically take those out as one object per file, because that's how you work on them. When you put those into code control, you typically manage them at an object level, whereas your tables, you tend to manage at a database level. Um, but you've got that flexibility within here to take them out at the level you need to manage them. Yeah, OK. Thank you so much. Right, let's go back to my code and make sure it's worked. So I'll just make that smaller now so I can see it. Uh, so yeah, so, so what we've done is we've converted that procedure, um, I'm just gonna quickly have a look and see what that procedure did. Uh Oops, I should have done that. So this is the This is the trade report, so it's come out and it's, it's a report of all the trades that have occurred. I've gotta be honest, the data doesn't mean a huge lot to me. I've never been a trader, um, but you can see what's in there. And so if we go to the, uh, Postgress equivalent, uh, using the stress function we've just converted, uh, we should, fingers crossed, get exactly the same results. Uh, let's pick one at random. So we go 4 down. Emily Davis, uh, oh, she's using play as well. The play's popular. Uh, she's bought 80 of them at 135. If we go to this one. Uh, here we go, Emily Davis bought 80 of them at 1:35. So we've got the same data in both. So again, we have successfully converted the code without you having to manually do it yourself. So that's that part of it. Now, I'm watching that time clicking away, uh, so I'm gonna go back to transform cos there's one thing I really do want to show you and one I would like to show you. I'm going to start with the end point, what happens at the end, because I think that's the most important. So what's happened is, Schema conversion, oh sorry, Transform has executed schema conversion to convert the database. It's executed DMS to convert the data. Well this one hasn't yet, but the one I ran last night has. I've already shown you the output of that, so. Other than showing you how to kick it all off, I think it's more important, what I want to show you is what it did in the GitHub repository, because when I ran it last night, um, we, we've already kicked off the step that says I want you to do it, but it hasn't got there yet. So we're going to go into my GitHub repository, and I'm gonna show you what it actually did last night. Um, so. That's my GitHub repository, so we'll connect to that. Uh, where shall I do that? I'll do that here cos we've finished with Bob's books. So if I go into Git, there we go. So this is my GitHub repository where the application code for Bob's books sits. So if I go in and say, create a pull request, and I want to, uh, Uh, I'm gonna have to look up how to do it. I can never remember how to do this. Uh, click pull request, new pull, there we go. New pull, and then compare. So I'm gonna compare main, which is my SQL Server code, with the code that I converted last night. I'm gonna make this, you definitely can't see that one, oops. How's that? Is that big enough? Yep. So what this is now showing you is Maine, which is the Actually I don't know which one's green and which one's red, but anyway, um, you can see all the changes that have been made by Transform. So if I do a search for Progress. Um, you can see, um, so red is the new stuff. Uh, so you can see what we've put in here. So, for example, we have added the Postgress frame framework that's been put in there by, um, uh, by Transform. So somewhere there's going to be a corresponding removal of the SQL Server one, I suspect. Uh, if we go down, uh, where's my, where's next? So the problem you get when you make your window bigger is you lose all your buttons, you can't find them anymore. Somewhere in here is the next button. uh, oh there it is, gone to the bottom. Right, so uh so there's the, So there's the pore frame again. Uh, another one for postgrads. What I'm looking for is the connection details, which I think is about 3 or 4 clicks down. Here we go. Um, so this is the connectivity information. So we've now changed it to say that we're using the sec secrets, um, and we are connecting to our Postgress database rather than MySQL Server database. So where's the, uh, connectivity commands for Postgress? Uh, that's going to be, uh, up here, I suspect somewhere. Um. Now, here's the SQL Server one. So here's the SQL Server Connect string, which has been removed and it's been replaced by the Postress uh Connect string. So it's done all that for me in all of the necessary library chains that are required to support that. Now when I've looked at this previously, when I get to the end, uh, if I go right to the bottom. I don't know why there's 3 in here this time. These are brand new functions that didn't exist in the program before. Are they new files or are they new, new functions within a file, but Transform has worked out that in order to run in Postgress, I've got to have these brand new functions. You can see there's no corresponding red that I've removed, this is all green, this is all brand new, and it's done all this for me. Uh, it's stuff I don't have to do. I fall back to what I said earlier. It's been done by generative AI. I'm actually contradicting what Swami said earlier on now about the fact we should trust AI. I don't, I'm sorry, I, I'm not gonna trust that. I'm not gonna trust that with financial information, I'm really not, despite what Swami might have said in his keynote this morning, um, test it, please. But it's taken an awful lot of uh code off the table for you. Um, it's stuff that you don't have to do. It's all the complexities of integrating schema conversion with database migration service with all the application code modifications. I've just clicked a few things and made that work. Um, we've got 5 minutes to go. Uh, if anybody's got any burning questions to ask, I think we're done.