---
video_id: zOGMWM5HQ_0
video_url: https://www.youtube.com/watch?v=zOGMWM5HQ_0
is_generated: False
is_translatable: True
---

Mike Cher, Mike Check, cool, hi. Hi everyone. Um, so yeah, I'm Michael, I'm VP of strategic alliances here at Poly AI, um, and yeah, thanks for spending a bit of your morning with us, um. The title of the talk, how enterprises are deploying polyized voice agents to reduce handling time by over 75%. I'm gonna suggest flipping that a little bit, I mean handling time, everyone talks about that, um, the objective really is to save labor hours, right? And so what I'm gonna talk about today is how, how poly AI, um, what our enterprises are, are sort of looking at to do, uh, to have an AI agent that can truly take on the work of about 1000 FTE, like what does that actually, um, look like, right? So, I'll talk a bit about us. I'll go through one of our Fortune 500 customer examples, specific uh gas and electric, and how we're deploying an AI agent with them, um, and I'll talk about a few of the capabilities we see as important, um, to have these AI agents operating at truly enterprise scale. So a little bit about Poly, um, we were started in 2017, um working with uh large language models and transform based architectures specifically for uh enterprise customer service as the use case, right? Um, our three co-founders, Sean, Eddie, and Nicola were researchers at the University of Cambridge, studying dialogue systems, speech recognition systems, um, and they really wanted to find a way to apply that, um, invention of the transformer model, but in a way that could touch the daily lives of everyday people, and they found that in customer service and contact center. Fast forward to today, we have about 2000 individual AI agents now running in production for over 100 enterprise logos. Um, we've raised over 120 million venture capital, um, for investors such as Nvidia. Uh, we've recognized in, uh, this year's Magic Quadrant in conversational A platforms, um, and we're now about 280 people, 290 people spread out across London, uh, San Francisco, uh, and, uh, New York, right? Um. To talk quickly about us and AWS, so we're built on AWS, we're available on the marketplace, uh, we're one of the, uh, G Gen AI competency partners as well as other competencies, uh, and we have multiple live deployments already with Amazon Connect across US, UK, Europe, uh, we also do work with other contact center platforms, we work with our friends at Zendesk as well, um, so yeah, just a little bit about us and, and Polly. Um One of the things that we hear time and time again from industry analysts, from our investors, is, uh we really stand out in terms of the enterprise scale deployments that we have running in production, so I'll talk to about one today, uh, which is our deployment with the PG&E, right? Um, for a utility company like PG&E there's no interaction that's more important than an outage or a billing conversation, right? Um, before Poly AI came around, um, what that looked like for the customer is maybe over an hour of wait time, uh, during very unpredictable periods, during very sensitive periods. Um, these are periods where actually the, the, the, the utility needs to get things right. There's a lot of regulation around communication to the customer. Um, and they were struggling with a legacy nuance IVR that was very difficult for them to make changes, to adapt, right? Um, so what I'm gonna do is actually play a very short clip of um our customer and the solution, and I'll talk a bit about then the impact. Really? Hi, thanks for calling PG&E. I'm Peggy, PG&E's virtual assistant. How can I help? Hi, Peggy, I think my bill's due, and can you tell me how much I owe? I can give you balance information over the phone, or I can tell you how to check your account balance online. Which would you prefer? Well, definitely over the phone. Great. Your current balance, including your upcoming payment plan installment, is $29. Very short clip, I'll give you the link to the full video, right, in just a little bit, um, but I wanna talk quickly about then the impact, right? Um, that was our customer there, um, Kristen Punter, um, calling the solution at Live and in Production. What we helped, um, the customer do there, migrate 7000 intents that were built into their legacy IVR. Over to a Gen AI um solution, resulting in about 67% call resolution, about a 25% reduction in overall customer efforts. Um, now, during a period of outage, being able to scale that AI agent about 50x within 5 minutes to deliver uninterrupted service netted about a 22% increase in CSAT. Um, and just to show you like what does a deployment actually look like, right, like, you know, I'm not gonna sit here and say we did that all on day one, right? This is a journey, especially at the enterprise scale, especially at regulated industries. We started with outage notifications, once the customer was comfortable with the level of performance, you grow that, add use cases, um, until now you're on track to about 16 million calls per year. Um, every time you add a use case, there's always unexpected challenges with voice AI, right? There's different tuning that you need to do around speech recognition. There's different, um, intense sort of reco uh knowledge base, or rag issues that might pop up that you need to address. Uh, so it is a journey, right, but it's one that we've gone on successfully for multiple Fortune 500 companies. Um, so yeah, this is a little link uh to where you'll be able to find then the full video uh talking, um, from our customer about our impact. Um, so now then to touch on what does it actually take for an AI agent to do the work and be capable of doing the work of over 1000 staff. We view this challenge in about three main lenses. Um, firstly, it's the application, the AI agent itself, that's about the customer experience, the brand experience. Um, second, it's the platform itself, so what is it for the developer, what about the contact center manager, what is their experience, uh, when you're operating at a scale of over 1000 staff. Um, and then finally the operating mode, what's the vendor experience, right, and what's the then the experience around um the continuous improvement of the solution, so I'll talk a little bit about each of these pillars. Um, in the first pillar with the AI agents, um, when we looked at the performance of our solutions in aggregate, we found that about 70% of the time, poor experiences delivered by a Gen AI solution, uh, was actually down to, um, errors in the speech to text, errors in the transcription, not necessarily that the AI. Wasn't smart enough to figure out the answer, it was given an incorrect signal from the speech recognition engine, right, so for us, what does enterprise grade look like for spoken language understanding? Through our partnership with Nvidia, we're building, and we have built an ensemble of speech to text models, so think of a, A model for US speakers, a model for UK speakers, a model for zip codes in the US that's different to the model for postcodes in the UK that's different to the model for first names in Croatia, right? So being able to really optimize speech to text is really, really important. Um, being able to switch models, boost certain words, create guardrails, um, anywhere in a conversation is also very important, so, you know, it is, um, it is limiting if you're only able to adapt your speech recognition at very specific points in the solution. Um, voice activity detection that automatically through machine learning adapts to the caller, right, there's nothing more frustrating than like that whole interruption game that happens when you're sort of offbeat a little bit with an AI agent. Uh, so having our own sort of voice act uh activity detection, uh, capabilities there has been very important to scale to enterprise, uh, and then finally with AWS, uh, an architecture that can scale instantly, right, so auto scaling, and like I mentioned, Um, in the utilities, in the outage, um, uh, use case, being able to 50x the call volume within a matter of minutes. Um, secondly, in the AI agent, how do you get customer engagement? There's not, it doesn't matter how intelligent the AI agent is if customers are not willing to engage, right? Um. Certain information is great through a spoken conversation, um, but other forms of data are also important. We don't always give information by speaking. We might give information by sharing videos, by sending forms, spelling, um, sharing locations and photos. Uh, and so for us enterprise grade customer engagement is the ability to move into multiple modalities while maintaining voice as the primary, right, so being able to send, Forms in the middle of a conversation without ending the phone call, so the phone call is still live, you're sending a form, you're waiting for the customer to complete that form before you continue the conversation, um, you're you're giving the customer an ability to share photos, share videos, uh, share location pins, right, so that's all very important when it comes to uh voice AI uh running at scale. Uh, thirdly, around the AI agents, um, the LLM layer, right, what does enterprise grade LLM orchestration look like? So we have our own, um, LLMs, it's called the our Raven models trained on top of AWS, and we're currently sort of in the process of surfacing those models through StageMaker through Bedrock. But having LLMs that are trained on your specific use case, so, um, have, uh, been fine-tuned to the style of a contact sensor conversation, of a customer service conversation. Uh, is really important for more, um, natural lifelike engaging responses. Um, being able to trigger function calls, integrations, anywhere in a conversation, either synchronously or asynchronously, that is a very important capability when it comes down to, uh, solutions that can handle, um, uh, operations at scale. Um, having dedicated instances for inference, right, so not sharing instances, having one dedicated to the LLM to the speech recognition layer, uh, and finally having a level of architectural flexibility. Enterprises rightly are very concerned about where data is being processed, where data is being hosted, uh, and so having a level of architectural flexibility is something that we also offer, um, our customers. Next, to go into the platform, um, before you can run an AI agent at the scale of 1000 people, uh, you need a level of observability, right, and so just to show an example of what we offer to our customers, so core metadata is fairly standard. We also offer custom metrics, these are business metrics, right, uh, context states, so being able to track what is happening in the conversation and the history. A conversation, being able to track exactly the inputs and outputs given to LLMs at every step of a conversation through every function call, and finally transcriptions and recordings. We also allow the developer to dig into the full LLM request if they need to, for debugging, for troubleshooting, and we also provide visualizations of latency, so um you know, there's, Uh, when an AI agent is taking a bit longer to respond, uh, you'll be able to, and it's, it's important to understand whether that latency is coming from the speech recognition, from the LLM, from the way that you've written your function calls, from the text to speech provider, um, that's all very important for troubleshooting and debugging. Next is the collaboration, right, experience, uh, so, uh, when you're operating with an enterprise, there's never just one person that is looking after the solution. You're gonna have IT folk, contact center folk, customer experience folk, there'll be multiple, um, team members that are working on a solution and evaluating a solution concurrently. Um, so think of this as like a maturity scale, right? The very first thing, the most basic thing that you need to be able to do. Uh, is accommodate different users, different levels of permissioning, different environments, so nothing gets pushed straight into production, and so it's important to be able to offer that, uh, on the AI agent platform that you're working with. Now when you have different users, you have different environments, what you're then gonna need is an audit trail, right, what changes are being made, what version of the agent is live in which environment, who made that change, why did they make that change, be them to append notes. That was sort of stage two for us, right, as we were going on this journey. Stage 3, which we're very excited to be launching, is then not just having an audit trail of a single version of the solution. But now having simultaneous drafts, right, and a merging process, so that um everyone can be working on the AI agent concurrently, and there is a way to merge different drafts together without conflicting and without destroying functionality and without losing capability, right, that's been a very, very important change that we're introducing into the platform, um. And the ultimate goal that we see, right, the end result here, um, is then once you have simultaneous drafts, you have the ability to manage conflict and merging, you have order trails, you have different environments, those are the unlocked steps to having a native developer co-pilot, right, so um you don't need to be a developer. You don't necessarily need to be writing Python to build a state of the art voice AI agent, you should be able to prompt a co-pilot, a cursor-esque, cloud code-esque experience, um, but before you can do that, you need all these other pieces in place, and that's what sort of we're offering, uh, to our enterprise customers. Next, beyond observability is analysis, analytics, insights from the agent, um, and so, uh, these are just screenshots of some of the capabilities that we offer. Um, there is an ability to through natural language, create the analytics that you want the AI agent to be. Tracking, right, so this is an ability to implement custom metrics that are important for different types of business operations. Um, and then down the bottom here is, um, yes, we provide dashboards, actually we use Amazon Quicksight as our dashboarding solution. But we are also now enabling for the business user, a natural language way to talk with their conversational data, to talk with their contact center, essentially, and we're unlocking that through a um smart analyst type of capability. Uh here we're leveraging um Bedrock and the anthropic. Models for this type of use case, right, so I think the new paradigm will be a more um conversational, shall I say, natural language way for you to interact with the millions of phone calls that are now being transcribed and flowing through your contact center um platform, right. Um, and, and finally I'll just touch on quickly, there's a lot of talk around forward deployed engineering as the model, right, so we've touched on agents, we've touched on platform. Now this is about the operating model, what does it look like when you're having an AI agent take over the work of a 1000 people, right, you need a different type of AI operational layer. It's not just about 4 deployed engineers, although they are very important. Uh, we also offer to our clients, um, our expertise in, The architecture component with solution consultants, we have our own product solution managers that's helping the enterprise think about the improvement cycle of the AI agents um that have expertise around whether, you know, this should be a fix in the speech recognition, in the LLM in the text to speech, and we also have our own dialogue designers, right, um, that are working with enterprises to implement their brand experience into um an AI agent, right, um. So that's um all the content I had prepared for you today, so again, having an AI agent to truly take on the work of 1000 FTE or more of staff, um you need to think about a lot of new capabilities from the AI agents, from the platform, and from the operating model that you have with your vendor and with your technology, um, providers, right, so, Um, we've got a few minutes left. I mean, if you do have a question, happy to answer it on stage now, or I'll be around after this conversation. Do we have any questions from the audience for Poly AI that could answer? Just raise your hands. This is your time to get one on one questions answered. Don't be shy.