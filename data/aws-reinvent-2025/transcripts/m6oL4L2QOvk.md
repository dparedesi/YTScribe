---
video_id: m6oL4L2QOvk
video_url: https://www.youtube.com/watch?v=m6oL4L2QOvk
is_generated: False
is_translatable: True
summary: This session explores the latest innovations in Amazon Elastic Block Store (EBS) delivered over the past 12 to 18 months, presented by product managers Aaron Chen and Suraj Panan, who examine EBS advancements through the lens of a rapidly growing fintech company operating across three critical workload categories: real-time transactional processing systems, analytical warehouse environments, and developer testing environments. EBS, a network-attached persistent storage service for EC2 instances, provides disaggregated storage with various volume types including IO2 for mission-critical workloads and GP3 for general-purpose applications, backed by a vast distributed system maintained by AWS engineers that enables different performance levels, durability guarantees, and sophisticated features beyond simple provisioned disk capabilities. For transactional processing systems handling millions of customer interactions, AWS enhanced IO2 Block Express volumes to deliver consistent sub-500 microsecond latency (tightened from sub-millisecond), expanded global availability to all commercial and GovCloud regions ensuring worldwide infrastructure parity, and introduced comprehensive observability tools including average latency metrics in CloudWatch, IOPs and throughput tracking, volume-level and instance-level exceed checks that instantly identify performance bottlenecks, and integration with AWS Fault Injection Simulator for chaos testing with four latency injection templates enabling customers to proactively test resilience through sustained, increasing, intermittent, or decreasing latency patterns. To prevent accidental or malicious data loss, AWS extended Recycle Bin protection to EBS volumes, allowing administrators to set retention periods where deleted volumes remain recoverable with all original tags, encryption status, and permissions intact before permanent deletion. For analytical warehouse systems processing diverse data streams from OLTP systems, sales, finance, marketing, and IoT sources, AWS significantly enhanced GP3 volumes by increasing IOPs five-fold from 16K to 80K, doubling throughput from 1GB to 2GB per second, and quadrupling maximum volume size from 16TB to 64TB, eliminating the need for cumbersome RAID configurations in containerized Spark environments running ETL jobs and complex queries with intermediate data processing, while also launching the R8GB instance type providing 150 Gbps bandwidth and 720K IOPs to ensure the network pipe between compute and storage fleets never becomes a bottleneck for latency-sensitive tightly-coupled systems. To accelerate developer workflows, AWS introduced EBS Volume Clones enabling instant creation of performant target volumes directly from source volumes without snapshot intermediation, supporting cross-volume-type cloning from IO2 Block Express to GP3 for cost-effective test environments while guaranteeing zero performance impact on production volumes, facilitating more frequent test environment refreshes that improve code quality, and enabling simplified blue-green deployments where development teams can quickly create parallel environments for seamless code deployment with rapid rollback capabilities. Additionally, AWS enhanced the golden image workflow for globally distributed development teams through time-based AMI copy guaranteeing 15-minute replication across all regions regardless of regional load, provisioned initialization rates up to 300 MB/s for predictable volume readiness from snapshots, and initialization status visibility ensuring developers receive fully-performed volumes ready for production traffic, collectively addressing strict recovery time objectives for disaster recovery scenarios and enabling hundreds of simultaneous instance launches with consistent performance characteristics across availability zones and regions.
keywords: Amazon EBS, block storage, IO2 Block Express, volume clones, disaster recovery
---

All right. Hi everyone. Welcome. Welcome to Vegas. Welcome to the session 5:30 in Mandalay Bay. You guys must love us. Alright, today we're gonna take you through this journey of, uh, what's new with uh Amazon EBS. We're gonna cover the innovations we have done in the past 12 to 18 months, and, uh, uh, we're gonna have a little bit fun. So my name is Aaron Chen. I'm a product manager at Amazon EBS. Along with me is, uh, my friend Suraj Panan. He's also a product manager at the EBS. We'll invite him down the stage and uh I'll walk you through the first half of the journey and then we'll swap. Cool So, before we get started, let's talk about EBS a little bit. EBS stands for Elastic Blog store. At its most basic, it's a network attached persistent storage to your AC2 instance. The storage is connected to your virtual machines over the network, so it's disaggregated from your EC2 instance in terms of the data life cycle. You are able to stop and restart your instance, you are able to reboot your instance, your volume and your data is still going to be there, right? That's why we're able to offer the different volume types because it's attached over the network. You have your IO2 formation critical workloads. You have your GP3 for general purpose workloads. EBS also provides the capability of backing up your data by snapshotting. Snapshot is backed by Amazon S3 to provide high durability, so in case of an issue, you are able to start from your snapshot and go back to your production environment. And the last part, between volumes or between volumes and snapshots, you want to move data. This can help you with the different workloads such as instant boot. Test and data environment creation or disaster recovery. That's what we call data service. So EBS consist of those three pillars. One thing that's very important to know is that EBS is not just a provisioned disk. It's just not only offering the block storage volume, but behind the scenes, it's actually a vast distributed system and it's maintained and operated by our ABS engineers. So it's with that kind of system, we are able to offer you different level of performance, durability, and different features. So, in terms of workload, EBS is a storage that serves a variety of workload, all the way varies from the most mission critical workload that's powering your ERP and the CRM. To, uh, all the boot volumes that booting your EC2 instance or to the indexing layer and the caching that for your analytical reporting environments. If you have ever spinned off an EC2 instance or ever run anything on Amazon Web Service, chances are you have used EBS. So, like all the Amazon services, all the innovation we do are deeply rooted in the customer needs and use cases. EBS is no exception. So today we are looking at the EBS innovation through the lens of a customer. Let's use this uh rapidly growing fintech company as an example. They have their core business as an operating database for their real-time transactional processing. They also have an analytical warehouse so they can use that to understand what's happening with their business with daily and weekly reports, generating insights, trying to analyze their business, etc. Lastly, to provide the new features and the new experience to their customers, they need to build and test, and that's why they have a developer environment, so they are able to continually bring more innovations to their customers in a more controlled environment. So we're going to talk about our innovations in these 3 aspects. Let's start with the transactional processing systems. So these are your most mission critical applications handling their incoming customer traffic. For our fintech customer here, their customer experience is directly correlated to the performance that's underlying the system, which is why their business is critical. These applications are typically backed by relational databases, and those relational databases run on EC2 as your compute layer while the EBS as the persistent storage layer. These relational databases usually require a consistent sub-millisecond latency. This is because that the application will trigger multiple combined IOs and when they come together, the storage requirement is taking multiple transactions or millions of transactions. In addition, Because they wanted to rapidly grow and expand globally, they will need the infrastructure level parity worldwide. That they can simplify their infrastructure. They are able to run their applications without any modifications with the same architecture everywhere. It takes a lot of operation burden off them. Lastly, because of this system is very mission critical, the customer needs to constantly ensure that their system is of high resiliency. As a result, they need observability to understand the performance of their systems if it's meeting their expectation, and they need to continue to test if the system's resiliency is good enough and if the failover mechanism will operate as expected to maintain the high availability. So let's unpack all three, each of them. Let's start with the performance metric which is the millions of uh transactions or consistent sum millisecond latency. So to deliver the desired experience where customers don't experience a lag when they run something, these applications require to have a storage layer that is a very low latency. Imagine you are clicking a button, you are submitting a form, you're making a purchase. These things usually will trigger a ton of correlated aisles that's either read or write. And all of us would hate the spinning circles and waiting for something to process. So to ensure the customer getting the instant response on these things, each of the storage IO needs to have a very low latency, ideally sub-millisecond. And to ensure that experience is actually very consistent. Your storage layer needs to deliver some millisecond latency or very low latency in a very consistent manner. If you don't, they might lead to lag or even the application unavailability. And then it could lead to loss of sales or loss of revenue, so there's also real monetary impact. So that's why at EBS we recommend you to run the very critical workload on L2 volume. L2 volume provides the best, lowest P99.9 IO latency among the major cloud providers. And we further tightened our latency guidance from the sub-millisecond average latency to sub 500 microseconds. Beyond that, we also added the clarity to how our IO2 outlier latency differentiate from our general purpose volumes. So now customers are able to understand the difference and making the right price performance trade-off. So we cover the performance. The next pillar is the global infrastructure parity. So as our fintech company grow more into different places, you also wanted to develop in those new regions that are different in the worldwide. So you want the same infrastructure available across the regions. It will reduce the operation burdens and will bring the data closer to you, to their customers, in this case, so they can achieve lower latency and offer the same experience everywhere. As a result, we expanded IO2 block express volume to all commercial and the gov cloud regions meeting the customer needs. So our FinTech company here is able to serve their customer in the same way everywhere. Now we talk about the performance, we talk about global parity. The next pillar is high resiliency. For application to be high resiliency, it starts with one thing and that's measurement. A lot of time that we hear customers asking us these questions like, I have an EC2 EBS environment, how do I monitor the performance? Do I have enough headroom? We just got an issue. Is it an application issue or an infrastructure issue and AWS can help. So with, with this, you actually want to provide observability and observability have helped customers to observe to understand their performance and to understand where things can go wrong. So over the past couple of years, EBS has been on a journey to improve the visibility into the volume performance. In 2024, we launched a metric that is average latency in cloud watch. This provides customers to be able to understand where the performance bottleneck. This year we launched IOPs and the throughput metrics in CloudWatch. So that Dell customer can monitor and track performance trend and optimize. These are the regular metrics. We also launched another set of metrics called exceed checks. So last year we launched the volume level exceed checks, and this year we launched the instance level exceed checks. These exchange checks are the zeros or ones metric that if your driven IOs or throughput reach beyond your system's entitlement, it will turn into one and you know that's where your bottleneck is, right. With those signals, it tells you right away that the performance degradation is because of the entitlement of your system or something else, right. So with that, Uh, if your, if your, uh, bottleneck is on the volume side, you are able to use the elastic volume to tune up the performance and to release that, or you can modify the instant size. So now, customers say, I can measure the impact. What's next? I can see the average latency, but how do I know that at what time my system will get disrupted and if my standard operating process procedure will work. So introducing chaos testing, right. It's not an unfamiliar concept because it is necessary today to build a resilient and reliable system by proactively providing tests and finding those vulnerabilities and then you can fix them. So, chaos testing is something that you've done in a controlled environment because you don't really want to do it on your production. So when you do that, you are intentionally simulating simulate a failure in this environment so you can uncover the hidden weakness or dependencies. And once you realize that, you can fine tune the process to improve the recovery times and to test your standing operating procedures to ensure the system fell over to the other side correctly. And that is very critical for the modern complex and distributed systems. So AWS fault injection Systems or FIS force injection Service or FSS is the service just for that. It is a managed service that enable you to run these for injection experiment on your workloads. If you think about the EBS fault, it manifests itself as a slow IO or stuck IO usually. And in 2023 we've launched an EBS action in FAS called stock IL. So you were able to test if a volume was stuck and monitor if the timeouts and alarm functions are working as expected. Well this year we are introducing more tests in your latency. So you are now allowed to inject latency to your system. And so think of it as you are simulating a gray failure, right? So we offer 4 different types of templates so you can run the test, such as the sustained latency, uh, increasing latency, or intermittent latency as like a spike, and then you decreasing latency. Of course, you can also specify and build your own custom template by figuring by inputting the read and write mix and introducing latency to read or write. So with the performance tested and observed with the impact on mitigated the understanding operating procedure, the other part of the protection to achieve resiliency is to prevent data loss. Customers sometimes delete volumes. By accident or even malicious intent. And that is very important because those kind of disruptions can result in financial loss or sometimes even damage to your reputation. So, having such a a data protection strategy is critical and ensuring the data can be restored in a timely manner after incidents is very important. We've launched recycle bin for EBS snapshots a couple of years back, and now this year we have extended that support to EBS volumes. To use recycle bin, you are able to set a retention period, so when you delete a volume, your volume goes right to the bin. Within the retention time, you are able to perform a recovery action so the volume goes back to production. Those recovered volume is immediately available and you are able to be able to attach it to your EC2 instance and resume your workload. The volume will retain all the tags, all the encryption status or permissions that you specified for it before. For the volumes are not recovered and the retention period relapsed, then they are deleted permanently when the retention period expires. So you can create these retention rules by a single volume or by group volume, just use tags and to figure out. OK, now coming back to our fintech customer. I can't hear you clearly. I'm sorry. I like the snapshot protection. Yeah, it's the same thing as the we launch for Snapshot. So coming back to our fintech customer here, we covered. The first pillar, which is the real-time transaction system. Now let's welcome Suraj back to the stage. He'll talk to you about the other two. Right. Thanks, Alan. So Aaron spoke about the real-time transactional systems which are extremely important to run your, um, and run your business, right? But if you think about the analytical warehouse system, that's where you get to figure out, hey, what's happening with the business, where is the business going, and what do you do about it. So it's extremely important in a way I think about it as you have so many different stakeholders in the business, it aligns everyone on a single source of truth, right? So that's why your analytical warehouses are so important. And if you think about some of the questions you would ask from uh analytical systems, if, if you think about financial data, it would be, how are my margins trending? How's my revenue trending if you're thinking about, uh, sales, sales, uh, question, you would be thinking about how my products selling in each of the different regions. If you're thinking about marketing, hey, you're running different kind of campaigns, right? And you wanna know how is the conversion for some of these campaigns and if something is going great, how do you double down? If you are doing product development, you're trying to figure out how are my customers using my product currently, how, what are, what is the sentiment, what are the complaints you're hearing so you can drive that to drive, uh, better product decisions. And on the inventory side you're trying to figure out, hey, do I have the inventory to support my customers? So there are different kind of questions you wanna ask from the analytical wareo system, as you would imagine, it has a bunch of data which streams in into these systems, and then you have to run analytics and querying on it to get the insights, so. Um, so it's a very, it's a very resource incentives, uh, intensive system, and we'll get into what kind of product storage requirement it drives and what we have done in 2025 to make the analytical Va system much better to run on EBS. So as I said, you have all kinds of data streaming into the analytical warehouse systems and typically the storage is S3, right? So you have your OLTP system streaming data, uh, through your change tracking into the systems. You have your sales data, finance data, marketing data, IOT data, like think about all the kinds of data which is streaming into S3. And uh for that data you would think it's going to be in all different kinds of formats, right? So if you have to run a query you have to normalize it to some extent so you can run queries on it. So that's where one place where EBS comes into play when you have to do the ETL jobs on these huge data sets which is sadly necessary because you need a faster processing layer. The other place where EBS comes into play is when you're running queries. It could be your nightly queries. It could be a up queries. It could be your nightly reporting jobs. Customers need a fast storage layer there to kind of. Speed up those queries, right? So the first requirement is data has to be extracted quickly from S3 into the ABS layer so you can run the ETL jobs or you can run your queries. The second requirement is if you think about these queries, if you're thinking about aggregates and joints, there's a lot of data, intermediate data which gets generated which you necessarily don't want to persist in necessary, right? It's a throwaway data which you don't want to keep, uh, long term, but you want it absolutely during the time when the query is running. So if you, because if you lose that data or if the volume fails, then, uh, you'll have to rerun the whole query again, right? So it's important that EBS has enough capacity to manage, manage that query layer. And lastly, if you, if you guys are aware of how these data processing layers work, typically there is a Spark, Spark framework, so they take a query job and they split it into smaller jobs. That's one way to think about it. And then you make sure that these jobs, they split it into smaller sections so they can run in parallel and also it's better failure management. So if a small job fails, you have another job which comes up, uh, spins up in its place. Another Es volume attaches and it goes right. And customers typically use containerized environments for, uh, for that kind of processing. So now if you take a step back, uh, we need high throughput, we need large capacity. Now you can definitely get that by combining raiding different kind of EBS volumes. That's one way to do it. What the hard part is in containers environments, raid is not natively supported. I mean, raid in general is cumbersome, but in containers, if you're dealing with a lot of systems, it's going to be extremely hard to, uh, support, uh, support raiding of volumes. So that drives the requirement that hey I from a single data volume I need very high throughput and very large capacity, right? so that that's what motivated us to deliver GP 3 volumes with larger performance and higher, uh, larger size. The it reduces the need for you to raid volumes in a continuous environment. So we increased IOPs by 5X. We went from 16K to 80K, uh, throughput, doubled it from 1 GB to 2 GB throughput. And we also increase the size from 416 terabyte to 64 terabytes, so 4X improvement in size. So Aaron also spoke about the OLTP system. So this also helps in your OLTP environment. So typically what customers do is they have a production environment which might be running on IO2 BX volumes for latency consistency, but then your tester environments don't need that kind of performance. So they will be running on GP 3. Um, but they need the same size, right? So if you have a 64 terabyte IO2BX volume before this launch, you would be striping 4 GP3 volumes to, to get that same test of environment, and it's very cumbersome if you're snapshotting that environment. So now with this launch you can have a 64 terabyte IO2 volume and a 64 terabyte GP3 volume. So simplifies your test of workflows, so improves developer agility. So that was one of the features we launched for the analytical workflows. Also helps OLTP. Now, as you know, EBS is network attached storage, just having a very large volume with a lot of performance investing just that is not going to, uh, solve the problem. You also need to make sure that the network pipe which comes from the compute to the EBS fleet is big enough, uh, that customers can drive that throughput, right, drive that performance to the, to the volume, and this has been a journey for us because, uh, bigger the pipe, the lower the TCO total cost of ownership of an EBS solution. Customers who have very large scale of workloads also helps them land like even larger and larger workloads on top of us. So we started with 100 IOs, uh, sharing with, uh, EC2 Networking back in the day, uh, with Nitro enabled all the nitro instances have a dedicated EBS pipe with much larger performance. In 2019, 2020, we realized that customers need a separate SKU with very high networking, uh, performance. So we launched R5B, also R5N. So R5B had 3X higher performance than the generic instances at that point in time. Then we launched R6N to follow that up, and this year we launched R8 GB. It has 150 GBPs of bandwidth, so that's 18.75 gigabytes of throughput from a single instance to the EBS fleet and 720K IOs, right? So with that, you, if you have an OLTP system, they, as Adam mentioned, they are very latency sensitive. They're very tightly coupled systems to deliver that latency sensitivity, right? So that delivers. That requires scale up kind of computer, right, if you think about it. It's a lot of a lot of CPU, a lot of memory, and as it is, a lot of storage performance needed from, uh, from a single instance. So that helps with that for sure. You can land like even larger and larger workloads on, on AWS and on EBS. Uh, the second thing, as I said, uh, if you, if you in the previous slide, these query jobs get broken down into smaller jobs. So when you're running these analytical jobs, you're using smaller instances, and generally when you are using instances, you don't want your CPU or memory to be stranded, right? That's the most expensive part of an instance. So by making the pipe bigger we ensure that that doesn't become the bottleneck, right? So you have better TCO of running, uh, running an EBS solution. So that was for the analytical workflows helps OLTP as well. Um, we use that as an example because it's easier to explain, uh, in the analytical framework. Now the next thing and the last one we want to discuss is the developer environment, right? So if you think about a developer environment, the customer has a production environment which is taking live traffic. They want test of environments for. Development purposes, but the requirements are the production environment should not be impacted when you're creating a test environment. You also want to make sure that the data you're transferring to the test environment is, is not sensitive, right? You don't want that data to be widely shared. So that's, that those are two requirements on the production system when you're trying to create a copy of your volume. And then the other workflow and the other requirement on the test environment is they want the data to mimic production environment so that there's this push and pull from both sides because you want similar rich data. So you can work on that, uh, you can simulate real world examples, right? So if you are a, if you are a, if you are a person managing infrastructure for developers, there are a couple of things you want to think about. You want to ensure that the test environment is as close to the broad environment as possible. And if you have a distributed development team, you want everybody to work off the same code base, right? So those are the two things. So think about our fintech customer. They have a real, real-time transaction system, live traffic, that's an issue. They want the ability to create a copy of that environment as quickly as possible. Debug the issue, root cause issue, fix the issue, and deploy the fix, right? So we'll see how we made that the developer experience simpler this year, but with the features we have launched. So they're digging deeper into both of those workflows. So the first workflow is a copy workflow. So you have a production environment which with EC2 instances with a bunch of EBS volumes attached, you create your test ever environment again instances with a lot of volumes attached, right? So in the broad environment you don't want any kind of impact when you're creating these copy workflows. You don't want to copy sensitive data as well. So that's a requirement on the broad side. On the test de side you want to create. More frequent copies of the data, so it's as fresh to the production environment as it can be, right? So you want to be very close to that. Uh, the other requirement is on the production side you might have volumes, you might use IO2BX volumes, right? And on the test step side you might not need IO2BX because it's not very latency sensitive. It doesn't make sense to have IO2BX there. So you might want the ability to mix and match volume types. Your source could be IO2. Your, uh, destination could be GP 3. So you, so those are the requirements which that workflow drives. And then if you think about the second workflow which is, hey, I have, I want all my developers like this FinTech company which you're talking about is growing globally, right? So they have developers all around the globe. They wanna make sure everybody's working off the same code base. So in that case what customers do is they create an army which is Amazon machine image, a golden army. Uh, which basically underneath the covers is creating snapshots, right? Army creates snapshots and then they copy that snap, copy the army across different regions, and copying the army triggers copy snapshots underneath the covers. And then you're when you create a dev environment you are launching an instance from an army, right? So again that's a volume getting created from a snapshot. So you can see there are multiple moving parts here. Customers trigger this workflows sometimes daily, sometimes weekly based on the development cycle. So for both of these workflows they require predictability and speed because if it's not predictable and fast it's very cumbersome to manage, right? So that's what we heard consistently from our customers. So let's look at each what we did in each one of them. So we launched eBay's volume clones, uh, this, this year. So previously customers, when they had to create a volume clone, they would use snapshot as the intermediate layer, right? You would create inauthentic environment. They would have IO2BX volumes. They would create a snapshot of those IOU2BX volumes, which means pushing data from the EBS volume, the EBS fleet to EBS snapshots, which is on S3. Then you're creating a volume from that snapshot, which means again pulling down data from the snapshot down to the EBS volume, right? So takes time to do that, um, it's cumbersome to do that and, and, um. And then after the data is fully, like after the volume is fully initialized, you would attach those volumes to your test of environment and, and, and your instances to, to trigger the test of workflows with volume clones. What we have done is we have taken the snapshot out of the picture. So now you copy data directly from the EBS source volume to the target volume. Uh, we, it's a single API call, right, and you can create a performant volume with a single API call instantly. Uh, you can start with an I2 BX volume on the left hand side, create a GP 3 volume on the right hand side for your test of environment, uh, and we make sure that the broad environment, the broad data, broad, broad volume does not get any kind of performance impact, right? So those are the requirements from the previous slide. So you've done that. So as I said, the previous workflow used to be, say you're a developer managing the previous workflow. You have to know when the snapshot was completed. You have to know when the volume is fully initialized. That's very cumbersome with, with this, we have improved developer efficiency, and if you recall, the other requirement was to create copies more frequently, right? Now that copies doesn't take a lot of time to create, you can create more copies frequently to keep your test environment as close as possible to the production environment, which improves the quality of your code, right? So that's what we did. Um, other than this workflow, we also see customers use cloning, and this was an emergent use case I think we kind of knew it could be used for blue-green deployments. So blue-green deployments are where customers would have two live environments. There's a blue environment which is the existing code base, and they have a green environment which is the new code base, and over a period of time they start moving traffic over and if everything goes fine they switch over and the green environment becomes the new environment. Um, and if something goes wrong, they can quickly flip back to the blue blue environment. So it reduces the risk when you're deploying software also makes it much more seamless. So previously customers used to use snapshots for that. So you can imagine if you're using snapshot, as I said, it takes more time. So as a developer you're managing the blue and the green. The deployments with green environments for a much longer time, right, because you have both of those things going at the same time. Now with copy you can just have the new environment created. You still have to manage the flip over and all that that's still, still on you, but still is much easier and much simpler to do than before, right? So it minimizes, you can switch, uh, minimizes the developer environment and improves developer agility, which was one of the main motivations for doing this. So that's, that's volumes to clones. The other workflow was the golden image which you had and you want it to copy it across regions to developers all across the world, right? And as I said, there are multiple steps in that workflow. One of the flow, one of the things you have to do is you create an army, then you copy the army across different regions, and then you create, create, um, volumes from it. You don't want, like if a developer is coming online in the morning, you don't want the developer to deal with a system which is not fully performed, right? That's a waste of their. Time and waste of resources. So that's one constant feedback we heard. So copy army workflow by by design is the best effort workflow. So if you're copying an army across different regions, based on how busy the regions are, your speeds will vary, right? So, so a developer in dub region would get something faster was a developer in, uh, Fra region, for example, uh, US EU West and, uh. US too, I use the internal names, um, so we launched time-based, uh, army copy last year in February so you can give us a time as low as 15 minutes and we'll make sure that across all regions these armies get copied in 15 minutes, right? So that makes it much easier. It's predictable that you know, the armies are gonna be there. The other part of the workflow is creating, uh, launching an instance from, from an army, and that triggers pulling data from the snapshot to the EBS volume, right? So that workflow is also not predictable. It's best effort based on EBS snapshot, how heavy the load is on the snapshot, uh, on the SC fleet and on the EBS volume fleet. So here again we launched provision rate for, uh, volume initialization. You can go up to 300 megs. We ensure that the data gets pulled down from S3. At that speed, right? So you know predictably when the volume will be fully ready and you can, you can, you can, um. Give that to your developer and he can be sure that the volume is fully performed along with that we also launched the ability to know that hey, all the data from the snapshot is fully pulled, pulled on from, uh, into the EBS volume so we know that the volume is ready to take, uh, production traffic. Uh, that's available for all volume types, not just in the context of this feature. So volume initialization is one of our basic workflows. If you think about army launches, right, it triggers the volume initialization workflow, and we have seen customers who have a single army launching hundreds of instances use this feature because it gives them predictability that all those, all those, uh, instances are ready to take on the workload, uh, production traffic. We see customers who are copying environments across AZs because the copy volume is is an in AZ copy of the volume. If you're copying volume of production environments across AZs, this is again useful to make it predictable and fast. And lastly, if you are recovering from a disaster, you are recovering from a snapshot to a volume. You have strict RTOs, recovery time objectives. This ensures that you're able to meet that, uh, recovery point objective. So it's a, it's a core primitive for us and. We're going to invest in that to make it faster, so that's, that's, that's, it speeds up a lot of workflows. Just summarizing all the things we spoke about here, so Adam spoke about the real-time transaction system, uh, extremely latency sensitive, so we reduced the IO2 BX volume latency definition from sub millisecond to sub 500 microseconds so you can handle even, even, uh, even stricter latency guidance we to make sure that all your customers. Can benefit from this, uh, this latency we have IO2 worldwide available so you can, you can develop the same, same stack across the whole, whole world. We launch metrics, performance exceeded checks, so volume exceeded checks we launched last year and instance exceeded check we launched this year. So in a stack it's very easy to figure out if the bottleneck is the instance or is the volume. We launched average latency metrics last year, average I throughput this year, so you can trend your performance over a period of time, put in alarms, and figure out when something is going wrong. On the resiliency side, we talked about latency injection with FIS, fault injection simulator. We had launched, uh, pausing NO in 2023 that basically simulates, hey, if you have timeouts in your stack, how does, how does it propagate, uh, from the storage data upwards, uh, if you have certain alarms, how does that propagate in this year we launched the ability to inject latency into your data path, right? And you can, we have 4 templates, but you can also create your own template with readre mixes and how much microseconds of latency you want on the read part on the right part. And lastly, if customers accidentally delete data, delete a volume, delete a snapshot. We had recycle bin protection for snapshots. We extended that, that to volumes as well. On the analytical warehouse system, need a lot of speed to pull data from S3 into the EBS fleet. So we have larger and faster single volume GP 3 volumes, REGB with Â£150 as a bandwidth and 720K IOPs, as I mentioned, also helps, helps your OLTP systems. The larger and faster GP 3 makes test of environments much more simpler. Uh, to use and the REGB enables you to land even larger and larger workloads on top of top of EBS. And for dev environments, for developer environment to improve developer agility, we launch volume clones. We can create instantly create a performance volume from, from, uh, from another EBS volume in the same AZ provision rate for initialization and, uh, time-based army copy makes having a golden image and copying it across the globe much more easier. Initialization status helps you understand when your volume is fully ready, and you can put that in production to take on latency sensitive applications. So that's, that's the bunch of features we launched this year. Um, these are the other EBS sessions if you're interested in. The last one is about networking and EBS workloads if you like that, and he will be there for that session, so you can go, go for that one, And then Adam and I will be hanging out here. So if you have any questions, let us know. Please take the survey. We read all the surveys. If you have, if you can put notes in there, that's great because we look at that and figure out how to make the session better, uh, next year. But thanks for coming. I know it's a very late session, so we appreciate you all being here. Thank you.