---
video_id: XjM0VtDDbt4
video_url: https://www.youtube.com/watch?v=XjM0VtDDbt4
is_generated: False
is_translatable: True
---

Good afternoon I'm Ian Coley, the director of advanced computing and simulation at AWS. Thank you for coming today. Before we start, I just wanna make sure that this whole silent disco thing is really working. So I've never done one of these before. I don't know how many you have, so I wanna take a little poll to see how we can get a little interactive. How many of you, is this your first reinvent? Please raise your hand. Wow, congratulations. On the other end of the spectrum, how many of you have been to more than 10 reinvents? Anyone? Wow. Well, I'm kind of in between. This is actually my 9th reinvent, my 8th presenting. I started in November of 2017. Uh, unfortunately I was staying at the Vdara and no one gave me the hint about wearing comfortable shoes, so I subsequently walked a half marathon on my first day, uh, coming to different presentations here and there. Since then I've, I've learned my lesson, but it was an interesting time to be talking about HPC on AWS. You see, two weeks previous to that had been supercomputing 2017 in Denver. And I was freshly minted AWS employee and I ran into a number of my former colleagues at WhamCloud, at Intel, at Ink Tank, at Red Hat, and they asked me, Ian, what, what does Amazon Web Services have to do with high performance computing. And let's just say we had a lot of skeptics around, and part of the reason I'm so excited to have the two colleagues that I have with me today to talk to you are because two of the biggest skeptics and honestly two of the biggest companies that held us accountable for developing the HPC infrastructures and orchestration tools that we have today are Shell and Toyota. In fact, I recall very vividly walking into a customer meeting with Shell at supercomputing 2017. And a very kind gentleman in a very strong Texas drawl said. Ian, you seem like a nice guy. But you don't have the performance. I don't know about your security and to be honest, I don't know that you'll ever hit the price that I need to perform my high performance computing workloads on AWS. Wow, welcome to welcome to the company. That was quite a shock, um, but it was really refreshing to hear someone that could be that open and honest with me. A couple of months later, one of my first international trips was to go meet with Toyota again. sat down. They explained that they had decades of experience of tweaking their high performance computing clusters to where they could perform at such levels of efficiency that they weren't sure that we could ever demonstrate the business value of moving some of those workloads onto AWS. And here we are It took us a while to get there, but not only do we have both Toyota and Shell migrating a portion of their workloads onto AWS, but they're gonna talk to you today about how they have them in production and what that has meant to them. So what are we gonna talk about today? We're gonna talk about PCS parallel computing service. What is it? Why did we develop it? In a big part because of what I just said, very demanding customers like Toyota and Shell and others asking us for a fully managed HPC as a service. We're gonna go a little bit into the design cost pricing where you can find it, what regions it's in. And then you'll hear from them directly. You'll hear from Shell and from Toyota about how they're implementing it. And then I'll come back up and do a little recap and I'll give you a little teaser with a pretty cool little demo on one of our other services, AWS batch. What is driving this need for HPC as a service? What is causing us to really evaluate how do we make HPC workloads simpler for customers to execute and part of it is just the explosion of HPC. I mean, honestly, with the growth of AI workloads, the the integration of AI and simulation, we see customers across disciplines looking at how to more efficiently and effectively. Implement architectures that before were considered some of the most extremely demanding. Of any and all of scientific computing. And that's why we've developed parallel computing service to address these solutions. Instead of the complexity of creating your own infrastructure, we're allowing simple infrastructure is code, repeatable setups that can be driven by APIs. We're allowing customers to focus on what they do best. Which is scientific workloads, research and development, engineering and simulation. And allow the expertise in the actual infrastructure to be handled by our managed service and take away some of that undifferentiated heavy lifting, still still allowing those on-site HPC administrators to perform their very important tasks of upleveling what their customers can perform, by giving them more tools to where they can rely on us to do some of the more mundane patching updates. Often things that would have to take a whole cluster down previously that can now be done. Via API driven development. And seamlessly to the underlying cluster. So again, what is AWS Parallel Computing Service or PCS? It is our initial version is a managed SLRM offering. How many people have heard of Slurm? Please raise your hand. OK, a bunch of people. Slurm is the most popular open source schedule option. While there are a number of popular schedules across industries from LSF to PBS Pro to Symphony, Slurm has taken on a really important role, especially in large language model training and in AI, because of the role it's been in academia and it's open source background. And so because of that we thought let's start with a scheduler that's fully open source and that we can provide a breadth of experiences to our customers. Now we're still reviewing other schedulers, so if I didn't mention your favorite scheduler or if you say, Hey, Ian, Slurm is great to have us managed, but I've got a bunch of stuff written that's tailored to a specific scheduler, I would really like a managed version of that. Come talk to me afterwards. Send me an email. You have my contact info at the end of this. We're still looking to expand this. We just started with Slurm because of the popularity within open source. Where does PCS fall within our our HPC portfolio again HPC is a pretty broad term and so I wanted to give you a little picture of everything that we talk about it it's just like you would think about high performance computing, uh, on premises. We need networking, we need compute, we need performance storage, and we need some way to tie it all together into a coherent cluster. And so that's why you see here. We have remote visualization from our our res. We have remote visualization from Amazon DCV. We have a various ways that you can instantiate different clusters depending upon what you're looking for. I mentioned a little bit about AWS batch. I'll go into that later. I also talk about how we've evolved from parallel cluster to PCS and why some customers choose to to use one over the other. And then we've got this whole family of EC2 instances from our HPC optimized instances. All the way down to our most latest and greatest R8I on the Intel Xion 6 generation Granite Rapids chips that we recently released all the way to the latest and greatest Nvidia GPUs from the GB 200 to the B300 available in our P6 family. But whatever that particular EC2 instance you wanna orchestrate, we can do that with PCS. Again, it's not just the compute though, it's the storage and so you have a whole family of storage products that you can integrate into your cluster depending upon your needs. Some people really like FSX for luster again because of the open source background similar to Slurm. Some people. A whole bunch of their infrastructure set up with FSX for NetApp ONTA and so they want to maintain that. We support all of that. You can connect your storage that you choose for your workloads to the particular compute you like all using PCS. So how did we get here? Again, I, I talked about how I, I joined Amazon at the end of 2017 when I showed up, there was this long partnership with Intel and AWS to where they had a vision and saw back in 2015 we need to make it easier for customers to instantiate these large HPC clusters and so we jointly created this open source tool kit called CFN or Cloud Foundation cluster. But when I showed up, I talked with a bunch of customers and they said, is this even associated with Amazon? We see like a GitHub repo and you know this doesn't really look like something I'm ready to stand behind and put my production workloads on unless it has like an AWS something next to it. So we very quickly said, OK, we need to stand this up as more than just an open source tool kit. We need to have this be a fully fledged Amazon supported solution with a with a support team behind it. And so we rebranded that open source repo as AWS parallel cluster and stood up a whole team of engineers that to this day continue to upgrade and improve AWS parallel cluster. But along the way we learned from a lot of customers, hey, I appreciate the modularity. I appreciate the ability to kind of hack AWS parallel cluster because it is completely downloadable, as I said, open source tool kit, but you know, I really would like a managed service. There's so many things that are hard to do with just an open source tool kit, number one being. You know it's kind of annoying that I have to blow away my entire cluster and recreate it from scratch just to pick up the latest and greatest parallel cluster version. Um, is there some way you could do it like all the other AWS services to where it seamlessly is upgraded behind the scenes and I don't have to think about that? As well as I would love to be able to do infrastructure as code. I wanna do more API driven development. Can you make it a true AWS service? And that's why last year we released AWS PCS. Water. O What does it allow you to do? Again, it's managed SLERM, so what does SLRM allow you to do? It allows you to scale and schedule resources for compute jobs. You can define how you allocate those. You can give priorities. You can set up various cues and we'll go into some of the details and the, the actual uh orchestration of those jobs, and you can set various priorities. One of the key values of moving your scheduling to a service like AWS PCS is the ability to dynamically provision resources. If you can imagine. Typically within the history of high performance computing we're looking at a fixed box. We've got an on-prem resource that is let's just say 100 nodes, 1000 nodes, pick your favorite number, and we are trying to efficiently allocate jobs to exercise and execute on those resources. But here's the thing with the cloud, we blow the top off that box and we say, when does it make sense to have those resources? Do we have jobs in the queue? OK, if we have jobs in the queue, then let's scale up. If we don't have jobs in the queue, then let's scale down. That's one way that customers take advantage of this dynamic scaling. There are other times where, especially in the new world of very scarce GPU resources where you say, I've got these GPUs and I'm not letting go of them, OK, and I'm gonna use them just like I would an on-premise resources and I'm gonna keep it up 24/7 and I'm gonna feed it just like I would, and I want you to just maximize scheduling against those 50 GPUs as much as you can. But depending upon that static allocation or dynamic allocation, it's all up to you. You have control over how you allocate those resources to the compute jobs that you need to execute. So. One of the nice things too about having a managed service is now we're integrated with the broader AWS system and so you get cloud cloud cloud watch logs and so you can look then oh what happened with my jobs what happened with this scaling, what happened with this execution and so you get that insight that before with parallel cluster you didn't have those insights. One of the one of the high value updates that I see of moving from parallel cluster or moving to PCS is customers have told me again there's so many times where I just wanna upgrade something. It could be I wanna upgrade an OS on the nodes. I wanna upgrade just a, a particular patch. I wanna upgrade Slurm versions. And all of this has to be done by the admin. Can we figure out a way that kind of AWS can take some of that undifferentiated heavy lifting off of my admins and give me the resources to where I can just say update the cluster and hit this API and that will happen. And we talked about the flexible architecture you can use CPUs, GPUs, pick your favorite storage regardless of what is particular to your infrastructure and your needs. We're not prescribing what you have to use it for, and that's part of that benefit of moving to cloud resources. It's not a one-time snapshot to where you have to pick, OK, what is my 80% solution that maybe right now is going to be a certain flavor of GPU and a certain flavor of CPU, but at the rate that they're cranking the wheel on new GPU versions, by the time I actually get it into production, I may be two or more. Iterations behind on the innovations that have happened there with the flexible scheduling that you have on AWS. I spin up some of the older instances. I spin up some of the newer instances. It's totally in your control what resources you allocate to your jobs. When we looked at this creating PCS, we wanna make sure that we're meeting the needs of multiple stakeholders. Obviously within HPC we have not just scientists and engineers, but we have a whole family. We have HPC system administrators again, the people that are actually allocating the resources for the scientists to do experiments on. What are their needs? There has to be some sort of really robust logging. There has to be a way that they can have telemetry into what is, how efficiently is my job being scheduled? What resources is it taking advantage of? Do I have resources sitting there that are not, they're not being utilized. And how do I measure that efficiency? For the scientists and engineers, again, they're the core end user, how do we make it as seamless to them. To where they don't even notice if they're running on. AWS with PCS, maybe AWS with parallel cluster or on premises, how do we make that slurm migration such that for them it's the same experience because at the end of the day the last thing we want to do is slow down the innovation by our by our researchers. We want the opposite. We want to help them speed up and you're going to see some of the examples from customers about how migrating to PCS has helped them really improve that innovation cycle. We have a number of partners and ISPs that have built on top of uh parallel cluster before and now on PCS that wanted us to really do that integration of an AWS service so they could build a partner offering for their customers. So let's take a quick deep dive into what does PCS look like. You see, it's a number of, it's a standard cluster. So A cluster unsurprisingly has a number of node groups. We have one for logins. And we have one for compute types and then we have a number of queues that kind of schedule back and forth and we'll go into different options that you can have around queuing and then again pick your fla your favorite flavor of storage, your favorite directory service we'll integrate with it it's not prescriptive. So here's an example where you see a user logs into node group A, OK, they have a queue that is attached to two different compute types. So they've got one node group that's specified for ARM CPUs, one node group that's specified for X8 X86 CPUs, and that queue can schedule between them. Similarly, you could have one that's GPUs and one that's CPUs. Now on the other hand, we see on the 2nd example below where you have the opposite thing. Instead of having one cue that goes to two node groups, you've got two separate cues that go to a single node group. And again that gets to the area where I'm talking about. Let's say you have that ODCR, that on-demand capacity request, where you want to maximize that and so you don't really care if it's jobs from QA or QB. You want to make sure that those hardware resources that you've committed to use are being employed as effectively and efficiently as possible. Here's even pulling back the covers a little bit more into some of the detail of the architecture. And so you can see You can SS SSH into the login node. A user can then execute their cues from two different permission groups and. What I really want you to focus on is the two big boxes, or actually one big box on top, little rectangle on the bottom, and that is the shared responsibility model, and that's where everything that's in that bottom rectangle, we handle all of that, we handle all those updates. You don't have to worry about any of that if there are minor security patches, if we have new versions of software that we roll out new features and functionality. That just updates you get that for free. You don't have to do anything we just upgrade the service, everything in the top box that's all in your VPC. Your compute nodes you control that. So if you're gonna do something like let's say a massive update to all of your underlying uh AI, that's something that your admin would continue to have. But if it's something that we're gonna provide a newer version of SLERM to you to execute, you can then use our update cluster API to upgrade your SLERM version. And again we wanted to make this as seamless as possible just like every AWS service so console API SDK, it all works. How can you purchase this? Again, we're, we're just talking about scaling EC2 nodes. So the same way that you purchase EC-2 nodes, so ODCRs, spot on demand, you can utilize those. Again, here's that shared responsibility model. Here's what we update for the controller. Here's what you update. In some cases with it's a minor version. It's a nondisruptive update. We just do it. If it's a major version, we want you to have that control to where you can decide whether or not to update it. Same with PCS features we update it. And it's fully supported. Where is PCS? Well, right now these are the locations where it's at. You can see there's some in Europe, there's some in Pacific, there's some in North America, but the most exciting thing that I wanted to talk about is that by the end of next year we don't need this slide because it'll be everywhere and so we are making it globally expanding so our AWS PCS by the end of 2026 will be in every Amazon region. Observability cloud watch logs. I talked a little bit about that, just standard observability things from AWS you'll be able to get all of that with PCS. Especially around taggable resources, this is how customers often track track their cost. By tagging specific jobs to work groups. That's how then that allows them through the cloud Watch logs to say, OK, this work subgroup perform these jobs which cost this X and you can do your own internal build backs if that's what you're doing for cost accounting. Pricing, there are two fees, OK. One is, let me just go into this, how your cluster controller is set up. Now this is something we want to improve in the future, but right now you kind of have to say, uh, t-shirt sizing. I think I'm gonna need to do a small or maybe I need to do a large, and then if you, you can upgrade, but you need to like tear everything down and go back in order to upgrade in the future we want to make this dynamic scaling, so maybe. At one point you need a small and sometimes you need a large and you can just migrate back and forth without it being as invasive as it is today, but right now you need to commit to what is the size of your controller because that limits how many jobs you can execute. Then we have uh for the accounting feature where we do Slim accounting obviously that's gonna save an accounting database which takes up S3 storage so we're gonna bill you back for that storage, but it's, it's not a big plus up or anything we're just trying to account for the storage that that accounting database could take up. And then you're, you're going to pay for your general EC2 instances. Those are in your account. Last, I wanna, I wanna talk about a real world example before I turn it over to, uh, Satoshi Son for a brief overview of how they're using PCS at Toyota and then a deeper insight from Michael about what they're doing at Shell, but Tune Therapeutics, if you haven't heard of them. It's really interesting, um, there's, they're a company in the biomedical space studying epigenetics. Basically what they're looking at is not just gene editing or anything, but how do you turn gene expression off and on via medicine, and they just went into trials earlier this year on a treatment for hepatitis B. And so by not doing gene splicing where you can, oh, oops, we we got the wrong thing there, or who knows what is going on on the side there, by limiting it to how genes or groups of genes are expressed. There's a very favorable outcome that they see by being able to limit their impact to epigenetics as opposed to genetic sequencing and editing and so what they've seen from us is. By moving database PCS, they were able to cut their innovation cycle down from 12 weeks to 2 to 3 weeks. Now I want you to think about that in sheer terms. Imagine if you're scientists, engineers, researchers were able to turn the crank on great ideas that they tried 4 times a year. That's what they were doing before-ish. Now, 25-ish times a year. What, what kind of a change would that allow you to have in your organization if you could turn the crank on innovation that much more rapidly by speeding it up. So with that, uh, I'm gonna give up the stage to Satoshi Son where he'll talk to you about what they're doing at Toyota. Thank you. Hello, everyone. My name is Satoshi Kimule, and I'm the leader of HPC atwita Central R&D Labs. Today, I'd like to share how our organization modernized HDC environment. First, Let me briefly introduce our company. Toyota Central R&D Labs is a research institute. Within the Toyota Group. It was established back in 1916 to create useful and high-quality research results. We worked together with a variety of companies and research organizations, both in Japan and overseas. Including Toyota Group companies and our technical partners. We conduct research across a wide range of fields including information technology, environment and energy, and material science. Our major achievements include the development of QR code. The practical article of vision. Visible light responsive photocatalyst and the demonstration of artificial photosynthesis. These studies contribute to solving social challenge and building a sustainable society and continue to evolve through collaboration with Toyota Group companies and research institutions worldwide. We integrate the computing needs of various research team. And provide an efficient and scalable shared computing environment. This environment is operated by a team of about 10 members. And is designed to flexibly support a wide range of applications and resources. Including CAE simulations, AI and machine learning workloads, and And large scale research data stretch. We support researchers in efficiently accessing the computing resources they need when they need them. Since this is a shared computing environment, we usually design and provide standard computing. Resources But depending on the research project, some need large scale resources or long running competitions, ones that can take several months to complete. In international efficiency environments when we try to meet all those demands, a lot of jobs ended up waiting in the queue. And adding new computing resources could take months from ordering to actually learning. First, to address our challenge, we started to started by providing dedicated to instances. However, costs were incurred even when the instances were idle. Next, we adapted AWS parallel cluster. But setting up individual environments for each researcher was time consuming. And running separate controller no increased cost. So we dedicate not to expand its use. Later, AWS parallel computing service was released. It provided the dedicated nature of its seas and the flexibility of parallel cluster only in just a few clicks. So we quickly dedicated to adapt to it. PCS is provide as managed service that including the scheduler. Since the PC environment can be intuitively configured and built through algae. We can now easily create environments on our own. Without relying on external vendors as we did before. For providing computing environments, we listen to each researcher's needs and simply link the appropriate instance type. And the required number of instances to their own dedicated queue. This allows them to start large scale or long running competitions immediately. In addition, Because the instances automatically stop when the competition is finished, it has also contributed to reducing overall costs. Finally, Here's the outcome we achieved by adopting AWSPCS. Environment set up. Which usually take 6 weeks on premise and several days with a parallel cluster. Can now be completed in just 30 minutes with PCS. Allowing researchers to spend more time focusing on their work. Soon after the release, actual use began. With requests for R7I 48X instances for large scale material simulations and P4DE 24X large instances for AI and machine learning workloads. Being able to quickly accommodate these advanced computing demands, demonstrate the flexibility and effici effectiveness of PCs in practice, in addition. Integration with jobs execution now allows research. To be used only when needs. Improving overall utilization and leading to cost. Optimization. We are also free from daily operations, giving us more time. To focus on creating new value. Let's transform together from a system that process into ones that respond to needs. Thank you very much. All right, good, good afternoon, everyone. I, I'm Michael Gujral with, with Shell. I lead our global HBC engineering operations. As you can tell, I do not have a Texas drawl, so it was not me in 2017, but we will talk about 2017. Ian and I have had many similar meetings, but, uh, happy to be on stage here, uh, to talk about our HPC journey with AWS and specifically some of the things that we've seen, uh, in, in PCS, um. First, let me talk a bit about Shell. I don't work at a gas station and it took me a long time to convince my kids of that. Thankfully they now know where my office is, so they believe that, I don't go to a gas station every day. Uh, but as a company, uh, 2022 numbers, but we're the size of the city we're. We're in 70 countries, uh, 46,000 people visit our retail site. Those top two are things that most people associate with us. Most people know with us. Uh, it's really not what I'm going to talk much about today at all. Um, what I'm gonna talk about is our upstream side of the business because that's really who uses HPC. Um, so 2800 barrels of oil equivalent per day is our production, and then 66 million tons of liquefied natural gas, um, are, are two key energy sources. What does that mean and what do those ultimately produce? A lot of energy solutions, so hopefully everyone drove a Toyota here and filled it up with Shell, and then that you'll be compliant with the the the presentation here, uh, but a large range of of uh energy solutions as we see ourselves as an integrated energy company providing energy for the energy needs of of tomorrow. But what we're gonna talk about here today is getting into that and again a lot of different customer segments um that that that our products help help and fuel but again to fill up all those pipes we need a tremendous amount of compute to not actually produce it but to find it so what we're gonna talk about today is upstream so in our upstream business. We need 85 to 95% of our compute is used for seismic imaging. What's seismic imaging? You send sound waves into the earth and you listen back to it, um. Very, very complex physics and, and so two questions to think about when, when we look at this slide. One, why do we need HPC? Why do we need more HPC? And then why cloud? Why do we believe Ian in 20 well, we didn't believe him in 2017, but why, why, why do we, why do we believe in the cloud and why, you know, what's, what's going on? And my slide is not working. Let's see. We'll see if the the we'll see if the animation uh fixes itself, but uh. Why more HPC? So as we go into more and more complex areas and as we try to find um oil and gas either deeper or or in in more challenging spaces, we need more physics and very simply put, the algorithms that we're solving are physics that were probably based in the 1970s. It's, it's wave equation based. The challenge has always been the affordability of compute. And so essentially we give our geophysicists a new machine they fill up, fill it up algorithmically. The same thing happens with storage, but this is not a talk about storage, um. And then why cloud and and and Satoshi Son talked about this as well and Ian talked about this as well. The cloud enables us to be more reactive. What do we historically do? We guess we think we need this much compute because we think we're gonna have this much, this many projects in this many years and you buy a big system. And you fill the system, but you never really know what could we have done. What you generally do is you prioritize your workloads, um, but blowing the cap off, as, as, as, as Ian said in Cloud was a huge driver. What does that do for us as a business? Enables more rapid decisions. If we can make those decisions much closer to when we need it, if we can turn. Capacity on when we need it in a value you know enabling value of information that for us is a critical path to our bottom line. Get these images out faster is enabling our business, uh, to, to move faster and then delivery timelines what you don't see but is probably of no surprise is getting gear on premise has become incredibly challenging. Uh, prior to COVID things were generally. Smooth-ish, simple-ish, um, now in a, in a post-COVID world with the AI boom with, uh, with modern day GPUs using, uh, a, a tremendous amount of power, this has become a complex challenge that is. Is one that we do. We still do it today. We still do have some on premise, but it's one that I'm also very happy that AWS does a ton of it for us, uh, because the scale and the repeatability and, and, and just the efficiency that they do it at is not so it makes it that my engineers don't need to worry about that. So that's why we need HPC. This is why cloud. And let's, let's, let's go down memory lane. So it wasn't me in 2017 at SC, but, but again, from 2017 to 2022. We struggled We, we, we saw this thing called cloud. We thought, oh, we should try and do HPC in the cloud and, and we tried a lot of different things, largely POC scale. And, and I think a lot of what we did was we tried to do the exact same thing. We said, hey, I have 10 nodes here. Let's provision 10 nodes. Oh, your 10 nodes don't look like mine. I don't like your nodes. Oh well, you know, let's, let's try spot because spot's cheaper. Well, we can't handle interruptions and so we just kept failing, um, and, and really didn't see a lot of traction. And then, and, and the person that came up with it sitting here in the audience say we, we, we said, what if we could go 10x as fast. What if, because when you go 10x as fast, you change how you do things in life. When you take something that takes you 6, you know, 6 hours to do or 60 minutes to do and you can do it in 6 minutes, you're gonna do it more times and so the 10x challenge that we said was, all right, Amazon. We want you because we have an embarrassingly parallel workload, just make it go 10x faster wall clock time that's all it's a simple ask you're infinite, let's do it and um. And what we also said was do it technically first. Commercials are important, but we're gonna put that on a parallel track that and, and, and then if it's really expensive, we may never do it. We may do it once and if it's affordable, we'll do it all the time. But, but we separated the two tracks and said how do we go faster? How do we actually impact our bottom line. It was still hard because going 10 x scale, scale breaks everything, and so that was hard. In 2022, the stars aligned for us. One of our key algorithms, full wave form inversion, had just become accelerated onto a GPU that led to a much more heterogeneous design, or sorry, homogeneous design that our nodes because of Nvidia's reference architecture looks a lot like a P series node, um, in, in AWS. We realized that. We didn't have to take the whole workflow. We always thought we need to take every single bit of our HPC workflow end to end. What we realized is, no, actually we don't. Data has gravity, but HPC has attraction. And so what we decided was, and we basically unwound our workflow and said this bit runs on accelerators and what do you know, the input size is actually pretty small. We can send that up and use a tremendous amount of GPUs and bring it back down. So all of those things align that in December of 2022 we go live in production and with that at the time P4DEs A 100s and and and that was really the start of our journey in, you know, the journey was long but that's been the start of our production journey and it's a wild time because in December 2022 for those who remember Chat GPT had just come out. And so we're like, oh yeah, these A100s are great, and then we, it was, it became very challenging to get them, and that's, that's the, the next part of the story. But again, and, and coming to the tagline here and, and the advantage of working with Amazon for a long time is you start to speak their language as well and that we always thought this was going to be a staircase and we're like, well, OK, Ian, you have to, you know, get to step one, get to step two, we're now we're at a point where. We're actually at a flywheel and, and, and, and, and that we do iterate much more. So what happened in 2025, 1 of the biggest things for us is capacity blocks. So having EC2 capacity blocks and having the ability to have predict predictable bursts because trying to get a P4DE was, uh, a challenge and we'll, we'll, we'll leave it at at at at that. But with capacity blocks with the visibility we have of when we need capacity, this has been a huge enabler for us. So the, the stat to give you. Since 2022 because of our ability to burst, we've accelerated 2.5 years of wall clock time of projects by by enabling burst. That's critical path items to our bottom line that we've been able to accelerate by, as Ian said, blowing the lid off and thinking differently about what capacity do we need. So now, now we're in the flywheel, so. The bad news is we're still not at 10x. The good news is we've sustainably hit 3 to 5x and and and and and that 2.5 years is of course a proof point of that that we are definitely headed towards there and so what are we doing now? Now we're in the flywheel and the pace that we're able to iterate, the pace that we're able to do things, and this is where PCS has become a piece of that is. The, the, the journey now, if I look at what we've done even just this year in 2025 versus what we did in 202 to 202025, the pace of innovation that we're able to drive is just so much faster, um, both that's. Of course what our HPC users do, but even what us as an HPC department does, how we think about it, how we provision our systems, so. Let's, let's, let's dive into a bit more detail about how we started and, and, and, and where we go, and I think very similar to Toyota we started with parallel cluster. One of the things we learned in all those early POCs that failed was, well, we realized we don't have a containerized workload. So while Batch is a great tool, it wasn't the right tool for us, but we did try to use it for, for a good, you know, a good number of times. We tried other solutions as well, but what we realized is parallel cluster and slurm was familiar because it's what we use on premise, so it was this comfortable feeling. Now the cloud wasn't this scary thing of, oh, we know how to use Slurm. We know, you know, so it, it was a very, very familiar thing. Um, we were able to use it in multiple regions and, and, and, and multiple clusters, and that was really what enabled us in, in 2022, really great tool, um. But of course you've you've heard Ian mentioned this already. There were challenges with with parallel cluster in that we knew we could do better. We knew that there was more that we could do there was more that we could do in this cloud journey. And so where were the, where were some of the pain points or what was, what were some of the infliction points we wanted to combine multiple architectures in a queue. You don't really think about wanting to needing to do that on premise, but now you can. What if I want graviton and AXE 6 sitting beside each other? Well, that's a novel concept. Why, but, uh, you know, it was reasonably hard to do or it needed a lot of clever engineering work to do in parallel cluster. Native terraform support, we use terraform in parallel cluster through cloud formation. It was a lot, lot. We had great engineers that uh that that made that work. We'll we'll leave it at that, but maybe not where we wanted to invest all the time that we we we need to. Multiple OS support, especially as our AI workloads uh are continuing to emerge. We're seeing more need for, for, for Ubuntu. We're using Rocky. We're using Rail. So again, being able to have multiple OSs is just another thing that gives us flexibility as an HPC provider inside the company. Seamless integration of Spot. I'll come back to that story a bit later on how, how cool that's been, um, a good unpopular thing to say in an HPC talk, but some of my HPC engineers in private have admitted that they like the GUI. Um, they will never tell their peers that, um, but, uh, the, the GUI has been a very handy tool to, to visualize what it looked like, and, and again, instant cluster. Um, upgrades, this is true because we came to a world with parallel cluster where it's very familiar. You take the cluster down, you bring it back up, but any update and the reality in the cloud is you're doing way more updates if you want to or if you, if you desire to because on premise you bring in a cluster, you have new nodes for any number of years. Well now they're releasing nodes all the time. Maybe I want a different shape, maybe I want a different size, so the number of updates can be so much more so. That that was really our inflection point when they announced PCS. It was this looks great, but, um, and that was one of those hard customer meetings where we're we're we're there with you. We just need these features and, and my kudos and recognition to the to the PCS team. Uh, we, we set up, we set a path. We looked at the road map, we said, OK, there's our jumping point. Um, we, we needed key things like Rocky 8. We needed capacity block support. We were not willing to do PCS as a toy, as a POC. It was, we're gonna go, but we're going with our biggest production workloads. That's how we're going. We're not gonna, we're not gonna go just for fun. We're, we're gonna go, we're, we're gonna go for it all, um, and so once those were met, we already talked about the, the, the motivations. And then the fun really started to happen. So what happens? We, we had this timeline, we knew when the features were coming, we had everything lined up. We have a great AWS Pro Surf team that's been working with us since 2021 as well. In the 11th hour we're getting ready in the final sprint. We, I get a call on a Friday morning and one of our, one of our proserve, uh, engineers has decided to leave AWS in 2 weeks. Um, that was a challenging call and, uh, it, it, it led to a bit of a fire alarm scenario. We said, OK, who are, who are the engineers we need from AWS? Who are the engineers we need from Shell? We got them all in a room in the Netherlands. Thankfully we were able to get everyone's visa in time. One of the visas came in Sunday night as the flight was Monday morning, so there was some, some hairy moments in there, but we got all the people together and it was just phenomenal. The, the excitement that was in that room of them being able to solve problems, to be able to deliver it. It was really, really amazing to see, um, that that that come together and again it was. It was, you know, some of the considerations of we do things on a head node because it's there in slurm on premise. It's just, it's, it's, it's there, it's convenient. Well, now it's Amazon's head node. We're not allowed to touch it, so now we have an admin node. So there's, there were some considerations, node groups. It's a great idea, but when you haven't thought about it, it does take something of how best do we use a node group? How do we, how many, how many nodes do we want? How many do you want to put in, what's maintainable, um, dealing with, you know, quotas and, and swaAF quotas and convincing the PCS team that no, yes, you need to increase the quota, uh, and then exposing Slurm features because again, having used Slurm, we knew what we would want to see and again it's just been a, a, a really great. Uh, partnership in that. So there, here's what it looks like. This is, I, I, I think I'm not gonna go into detail. Owen, uh, Ian showed you a bit of this already. I will call out because someone's gonna look at their screenshot later and say, is there a hamster in there? Yes, there is a hamster in there. Hamster is one of our, uh, API tools. Our optimization team. Has has a thing with rodents. They're called the rats. That is hamster. There is a tool called mice and others, but yes, that is a hamster, but essentially on the left you have your user and and and and the user has no idea whether it's parallel cluster or PCS. They are aware whether it's on premise or or the cloud, but that's only because of data, and they need to make sure their data is there. But other than that, it's the same user experience we run across multiple AZs. We run across multiple regions, um. And, and, and really in, in a very seamless way and you see Spot in there and I'll I'll I'll come back to that one so. We were at Supercomput 25 a couple weeks ago and one of our lead developers was there and said, I want, can I get, he says to our engineer, uh, that is leading our PCS effort, said, hey, can I get a spot instance in, uh, in, in Oregon? Opens up his console. Two lines of terraform hits commit within a few minutes there it is in Oregon live under PCS. How has that historically work? You know, update the cluster, take the cluster down, drain the cluster, do it again. That seamless upgrade that that that Ian talked about is very, very real. And, and then with terraform as well again, two lines of code. That's seconds. So Satoshi So said, said 30 minutes again. I think big cluster change is probably a minute, you know, maybe better than 30 minutes, but this one was, you know, a minute, and, and it was just such a cool thing to see how happy our researcher was that it just came through. And the other thing that we always had to do. We have the advantage of an embarrassingly parallel workload. So when we did these cluster changes, we could still make it seamless to the user. You would slowly drain one cluster, you'd slowly rehydrate it. It's really clever engineering that that our HPC engineers are able to do. But now they don't even need to do that. Now they can use their creativity elsewhere. So again, Once we got through the scare of losing the resource and getting all the right things, I can tell you our migration to parallel cluster to to to parallel cluster service was really anticlimactic because the way we found out about it was one of our overseas engineers decided to just do it, um, and, and then the team in, in, in the US came in and said why is this one monitoring thing broken? Nothing with the cluster was broken, but it's just why I was like, oh, I, I decided to switch to PCS. It's like, thanks for telling us. So, um, but you know, really, and it's exactly what you want it, you know, no news was good news, and, uh, it's, it's, it's, it's, it's been, been a really great thing. So that's, that's why PCS, it's, it's, you know, it's, it's how it's helping us focus on what we need to do, what's next, and, and, and again, at least for our HPC side, one of the things now is, OK, now they control our slurm. They know where the capacity is. They know how do we play multi-region? How do we get more creative now about finding and unlocking, um, more capacity, especially because for us we're using primarily P series Nvidia instances which are on the, on the harder end of the spectrum of, of, of nodes to get, um, a shameless plug if you wanna know more about Shell's HPC journey, uh, IND 3314 tomorrow at MGM. I'll talk a bit more about our, our overall journey. And then with that just maybe one last comment and and and it's a big thank you, uh, Ian, to, to you, to the whole PCS team, to my team that made this possible. A tremendous amount of work, uh, has gone into the journey since 2017, but even more recently in getting to PCS and really excited to be here and, uh, to share where we've been. So Ian, thank you and with that back to you. Huge thank you to Michael and Satoshi Son for sharing a little bit into their journey on AWS from on-prem onto AWS parallel cluster onto AWS PCS. If you yourself wanna find out more details about PCS, please take a screenshot of this, look at the QR codes. We've got some getting started documents as well as further details on it. But I also, I couldn't leave this presentation without at least giving you a little teaser on AWS batch and some other things we've been cooking up. And one of the things, uh, AWS batch falls in our orchestration here, you heard Michael talk about he doesn't have containerized workloads, so he wasn't interested in it. Well, if you do have containerized workloads and you're, you're running on ECS or Fargate or EKS. Batch is a great scheduler that we've created on AWS and one of the interesting areas that we see differentiating here is where customers say, you know what, if I wanna run my containerized workload, you know, maybe I'll consider AWS Batch, but it is an AWS proprietary scheduler, so it doesn't have a lot of the open source. Ecosystem around it that a slurm does, but if you're willing to go all in on AWS APIs, AWS batch is a great solution for you to consider for your containerized workloads. One of the very interesting updates that we did this past year was we integrated it with Sage Maker training jobs. And where this is really cool is Batch allowed Toyota Research to do large behavioral models. For those of you that most people are familiar nowadays with LLMs, but LBMs are not as well known, and where that that comes into play is where they're actually training robots how to interact with everyday world. So instead of having to go a step by step training, they're creating a model, they're updating the data set and then allowing the robot to iterate, and I'm going to show you a video next that will just, it's about a 1 minute video, and I'll invite you to look at the differences between the video on the left, which is just standard trying to train it point by point, to the one on the right which is trained with an LBM. And I'll especially invite you to look at how the robot struggles with the banana, but this is this exercise is a robot being set just set the table. So imagine if you will, we're living in an era where for whatever reason there this is either someone that's physically incapacitated or needs some sort of support and so they're looking for a robot to help them set the table and you can see here this is this has been accelerated to try to get it through in time. Uh, for this demonstration, but you can see how the robot on the left, let's just say it's kind of on the struggle bus with a lot of these features that that a human could very easily pick up the, the cereal, pick up the bowl, pick up the banana again, really struggling to pick up the banana. Then on the right it's just sitting there done it's kind of been waiting there OK the the breakfast is set, where do we go? Poor guy on the left. Just pouring cereal all over the table. So this is an idea, this integration with with batch with StageMaker training jobs allowed the creation of this efficient large behavioral model where Toyota's innovation was able to really accelerate. And it's still struggling with the spoon. I'm gonna let it go, poor thing. So what does it allow you to do now again this didn't require any code change between the left and the right. That's kind of weird, no code change. This is just using the trained model with a different data set and allowing these robots to really generate new insights with updated visualization data sets. If you wanna learn more about AOS patch again I know this this is just a brief gloss. I just wanted to show you that what I thought was a pretty cool demo take a picture of that QR code, take it for a spin. Um Now Uh, this is kind of like the Steve Steve Jobs, but wait, there's more. We announced that supercomputing a couple weeks ago and early next year you will have access to the latest and greatest AMD Turin in our HPC 8A instance. So those will be out early next year. Also, significantly, invite you if you wanna see the details, take a snapshot of this QR code. I spent a long time in the US military as a naval intelligence officer, and so this means a lot to me personally, um, but we saw that our customers in the classified spaces and government spaces specifically did not have ready access to the latest and greatest. Supercomputing and AI resources and so we have committed up to a $50 billion investment ensuring that our customers in GovCloud East, GovCloud West, secret and top secret regions have access to the most innovative hardware resources they can get to execute their mission specific workloads. And then I, I couldn't leave this without at least um. Giving credit to my team's recognition at the Supercomputing Awards for the 8th year in a row, recognized as the best HPC in the cloud platform, and then the thing that we talked the most about today, AWS PCS also being recognized as one of the top 5 new technologies to watch in all of HPC. I would invite you also if you're here for the rest of the week hopefully there are a ton more HPC sessions we've got breakout sessions we've got, uh, working sessions we've got a few more of these keynotes. Please take a look at that QR code, go to those sessions, ask more questions, and then I'll leave you with this. There's our contact info if you wanna get a hold of any of us, we'll be standing up here on the side. And then invite you please please complete your survey. It's super important to us. That's how we get better. We wanna hear directly from you. Was this valuable? Did Ian talk too long? Was Satoshi really insightful? You know, those types of feedbacks we really always look for that for you directly to tell us how we're doing and how we can make this interactive with you. Did you enjoy the silent session? Was it weird? You know, anything you wanna put in there. This is my first silent session. I thought it worked pretty well, but I'd love to hear from you all and so thank you so much for your time and hope to see you more.