---
video_id: QYAYR0LmO8U
video_url: https://www.youtube.com/watch?v=QYAYR0LmO8U
is_generated: False
is_translatable: True
---

Good afternoon everybody. Does everybody have their headphones on and can you hear me? OK. No. OK. All right. Um, good afternoon. Uh, welcome to the session on making autonomous networks in the telecommunications industry a reality using agentic AI. My name is Ishwar Perulkar. I'm the chief technologist for the telecommunications vertical at AWS. Telecommunications companies spend a lot of effort and money in operating networks. Hence, they're called operators as well. And today I'm going to talk about how Agentic AI is helping them reduce the cost and the time to manage and operate these networks, the work we've done with one of our strategic customers and partners, British Telecom. So the session is structured as follows. I'll give a brief introduction on some of the challenges that the telecom industry is facing, some of the big challenges, to give some context of why making networks autonomous is important and critical for the industry. I'll talk a little bit about what autonomous networks mean. And how AWS's agentic AI strategy fits in to help take them on that journey towards making networks fully autonomous. Then I'll have Raza Renama, who's the managing director of Mobile Networks of British Telecom, talk about British Telecom and their vision in this space and also the challenges that they set out to solve using AWS services and AWS technology. So after he talks about the challenges and gives you the lay of the land in terms of what the problem statement was and what we were trying to solve, we'll have Ajay Rabindranathan, who's a principal essay in the telecom vertical in AWS, talk about some of the approaches we took, some of the use cases actually, some of the use cases that we focused on, the approach we took, and the solution architecture that we applied to make these networks autonomous. Then we'll wrap it up with some of the benefits we expect out of this work and next steps. There's a path we have to scaling and expanding it, and we'll talk a little bit about what the next steps are in this journey. So let me give you a quick overview on uh why making networks autonomous is relevant and how AWS's strategy in Agentic AI fits in here. So if you look at at a 100,000 ft level, there are three big challenges that the The telecom industry is facing. And these are also opportunities, so you can look at them as challenges or opportunities. The first one, as I mentioned earlier, is the cost of managing telco networks. It's pretty significant and can go up to 1/5 of the revenue in some of the larger operators. And a large part of the reason is a lot of the operations are manual. You employ a large workforce to manage operations. It takes time to diagnose failures and understand what's happening in the network. So that's one of the bigger challenges that the operators are trying to solve. The second one is about 5G, which is the current state of the art in mobile networks. Now 5G was a big departure from 4G in the sense that it was meant to be a dynamic programmable network. It gave visibility into the network and allowed for control of some of the configurations in the network. But the industry has not yet completely fulfilled this promise, and gente AI, uh, the transformation that we're going through in terms of this big tech, you know, technology inflection point is something that can help them achieve that promise of 5G. Lastly, telcos have a lot of data. The data comes from network elements. It comes from devices that users use. It comes from user behavior, and all of that data has a lot of potential to not only help reduce costs but monetize and build personalized products, and it's quite underutilized today. So one of the opportunities here is how can this data be transformed to data products that can then be used by ML technology and applications on top to derive value. So one of the significant tenets that main tenets we started this work with was to look at it from a data first perspective, really look at what data is available, how it can be curated, and how that can be leveraged to build ML applications. Let me give you a brief uh overview of what a telco network's life cycle looks like, and this is uh pretty, uh, I mean, folks from the industry are familiar with this, but for the others, uh, I thought it would be helpful to just understand where, what we are focused on. So there's different phases in a network life cycle. The first one is planning and engineering. So this is where you figure out, uh, you know, the targets, which markets you want to get into, what kind of bandwidth you want to provide, where should the cell towers be. So there's a whole bunch of effort that goes into planning and engineering this. You decide on which network equipment to procure, to build the network, and so on. The second phase is deployment and configuration. This is actual installation of all of the elements, connecting them, testing them, validating them, and configuring the various routers and base stations and elements in the network. Once the network is live, a big part of it is services fulfillment and activation. So based on customer demand, consumer demand, enterprise customer demand, the services are activated and launched on top of this network. And then there's operations, which is making sure that the network is performing to standards, meeting the KPIs, making sure that you're optimizing the network and getting the most out of it by traffic steering, by things like traffic steering, things like optimizing RAN scheduling, and so forth. So there's a whole area of optimizing network performance. And then there's detection, diagnosis, and fixing of failures when something goes wrong. How do you figure out what's wrong? How do we fix it? Now, this work is mainly focused on the last two pieces here, which is uh operations and the services fulfillment part of it. And over time, we expand, expect agentic A to expand to these other phases of planning and configuration as well. The industry defined levels of maturity in this journey towards autonomous networks. TM Forum is an industry standards body that came up with this, came up with this maturity level. Framework to be able to evaluate where we are, where an operator is in its journey towards autonomous networks, and this came out in 2019 before the AI kind of transformation and the technology wave that we are seeing emerged. So L0 level 0 is is all manual going to L1, which is preconfigured, uh, you know, execution of a few tasks, then goes to L2 and L3, which has closed loop operations, uh, you know, going from very static, very prescriptive, descriptive to intent-based. There was some work done on languages to express intent which could get translated to network configurations and so forth. And L4 and L5 are where we really get into a closed loop with end to end services. So we are roughly around what the work we are doing here is roughly around that L4 level. Note that this came, this was an abstraction created in 2019 before AI came, you know, came to the forefront, so it was aspirational. It's a little abstract, and what we are doing with this work is really giving it a little more tangible sense and feedback as to what we mean by these different levels and the levels of autonomy that can be achieved. We are using obviously AWS's Asiantic AI strategy and different pieces and different parts of the approach that we have taken, so I'm just going to quickly go over the AI stack and how it's relevant to this space. So at the bottommost layer in the stack we have infrastructure. So this is access to silicon. We obviously have access to Nvidia GPUs, but also we have custom silicon, AWS Stadium and Inferentia, which has some benefits in terms of price performance. And then there's Sagemaker AI, which is a tool set to train and fine tune models on this infrastructure. The middle layer is AI and agent development software and services. In this at the top we have SDKs for agents, so we have our own strands agents, but also we support open source frameworks and we're using strands to create these agents for autonomous networks. Underneath that is Amazon Bedrock, which is our managed service where through simple API calls you can build complex agentic systems. So we have access to different models, a lot of tier one third party models, but our own family of Amazon Nova models. You can select and choose, and there's capabilities of optimization and guardrails and customization along with that. Uh, but the key piece here is Agent Core, which we announced a few months ago, and you will see a lot more announcements at this reinvents coming in terms of more capabilities and features there. And think of Agent Core as a suite of primitives to help build complex gentic systems that are scalable, that are enterprise grade with security and reliability that's required of a large complex gentic application. So this is a part that we are leveraging heavily in building autonomous networks. At the top are applications, so these are out of the box agents or family of agents. And this is something that right now does not really translate to what's required in autonomous networks even though we are using Amazon QCLI in some cases to really look at how we can translate natural languages to telecom infrastructure. And also I see potential for using agents and agent tools from the AWS marketplace to fulfill components of this overall big picture of what's possible in making networks autonomous. There's a roadmap you have in terms of more use cases, and I see that marketplace playing a role as we go and build more of these use cases and more complex agentic systems. So as you can see, uh, obviously we're using the infrastructure part, the, the autonomous networks. The inference runs on AWS and we're using a large part of the Asian Corps and and SDKs for agents to build out some of the components here. With that, I'll hand it over to uh Reza to talk about BT's vision uh and also why they chose AWS. Reza. Thank you. Sorry, thank you. I hope I'm audible. Um, so I'm Reza Ranama. I work in uh British Telecom, and I'm gonna tell you, take you through the journey that we have, we are going through as part of really utilizing this technology to have the vision that we have to bring into life for our network. So a bit about British Telecom. So we're um. We've been around since 1846, so we've been around for a while, and throughout these decades and centuries we have proud ourselves to be the innovators in this domain. We've done loads of stuff from the first telegraph to right now having the best mobile and fiber network in the UK. Our network really consists of two major layers that we have in the UK. And that is our fixed network that contains our copper network, our fiber network, enormous MPLS network, the internet network that runs pretty much the UK, and on top of that we have our mobile network that sits on top of that. I run the mobile network, so my passion sits in mobile, and I'll talk mainly through what we're doing around modernizing our mobile network and How we're going to use this new tech to take us into where we want to go in terms of autonomous network with our with our mobile network and just give you some examples in terms of the scale of the network, the mobile network that we have, we have about 30 million provisioned subscribers and every day about 22.5 million mobile users use our mobile network and And millions of other business users plus we also run what we call a critical national infrastructure, so emergency services and all of that runs on top of our mobile network. We have an ambition. There are 3 pillars in our ambition. We really want to be there, we say we want to be the trusted connector for our consumer base and for our business base and These three pillars are build, connect, and accelerate. We're building like Fury our fiber network across the UK. Millions and millions of subscribers will have fiber to the premises. On top of that. We also have an ambition by the end of 2029, early 2030, to have 99% of UK population covered by 5G standalone. And just briefly, what I mean by 5G standalone for some of you who are not familiar with the term is that 5G end to end, 5G radio, multi-spectrum of that. And the core networks plus the the whole thing we're trying to do that within the next few years. On top of that, we want to also switch down our legacy cellular networks. So we already switched off the 3G network and we will be switching off hopefully by then our 2G network. So we will be mainly 5G stand alone with some LTE left. Then we want customers wanting to connect to these awesome networks that we built. So when we bring fiber to your premises, we don't only leave it there to the doorstep, we bring Wi Fi 7 into your home as well. So we are the first operator in the UK to launch Wi Fi 7. And when you think about it, by having that potential of Wi Fi 7 and 5G, we create the best converged network, the first heterogeneous network for our consumers and our business customers. So wherever you are, the best bearer serves your needs. And then on top of that we will build new applications with some of that will go through and then we want to accelerate doing these things. We want to take cost out. We want to Develop these services much faster, and this is where an example of that is here creating with AWS is what I call AI operation work. So imagine a network. When we think about this network of the future, is that it's AI powered, it's intent driven, and it's autonomous. When I say it's AI powered, it's actually a network that is not only utilizes AI to get to operate itself, but it's the best network for the future AI applications. And these new applications are coming thick and fast, so the network of today is not necessarily what we need for the network of the future, where wearables, millions and millions of devices that you carry, they continuously want to talk to the cloud in order to have various AI applications, intent-driven, because when you need to use a service, the network needs to be able to provide it for you. And network needs to provide that service for you based on the application that you have. So if you're a gamer, then we want to put you into a slice for gaming so you have an awesome gaming experience. If you want extra security and you just launched an application, the network knows that you need extra security and provides that for you. And autonomous means that. For us, the vision is that that self-healing network, and that self-healing network was started in 4G, but the reality is that it really has not delivered yet. But with 5G standalone it is very different because the entirety of the network is API driven. The days of Diameter and SS 7 and all of them are gone. Everything is IP based. Everything is API driven. So therefore we can utilize the technologies such as and SSF to launch slices or applications that gives you the intent and the network looks after that service. So but that's easier said than done. So we have a huge number of challenges as an operator that have been around and have had all of these various generations of the network. This just gives you a very basic view of what we deal with in running and operating this network. So we have on the top you see 20,000 macro sites. So these are the big antennas and the poles that you see in the streets. Each one of them have multi-carriers on them, and we have 20,000 of these. And we're growing. We have a huge amount of small cells that we pepperpart the country and we bring that in, especially for our top 25 cities in the UK, in order to really provide excellent coverage and even during the busy hour to provide you that minimum bandwidth that you need for the applications that you use today. We have a distributed core network, so our core network 100% is containerized now. It runs all on Kubernetes and is distributed across the UK from north to south. And the reason we've done that is because we really want to optimize the network for the use case. that we have. So when you are when you are attached to this tower, from that tower, your bits goes into the closest gateway. From that gateway it goes closest UPF. From there, then we put it to the internet in the closest possible way. So that distributed network is very important. But that means that lots of stuff has changed when you run the majority of your network on a container containerized network, including our network. And the radio network, the radio itself, we monitor 4000 KPIs for each tower. That is so chatty when a node goes up and down in the containerized domain for the core, it's chatty, so the amount of data that is generated within this network is enormous, huge, and then on top of that per day we have, you know, some of these stats, you know, we have, for example, 12 12,000 events a day. We do hundreds of changes in a day and. And our operation is not really where it needs to be in order to deal with the ambition that we have for the awesome network that we are building for the UK. So when we talk about change, a small change can impact something somewhere else. So you can make a basic SRV record change, a change, and something somewhere else in the network breaks. And those are the challenges that we face today in this containerized 100% software run environment. We have to up the game and ensure that. That we're modernizing our network, but We've started and we jumped on AI bandwagon a while ago, but we made a number of mistakes, and, and some of those stuff that we're sort of thinking, working on right now are the stuff that I put here. People, if you think about how the mobile networks were run, I've been in mobile networks for 30 odd years, and since the days of 2G, 3G, 4G, and 5G, the functions that are done within the within the mobile networks engineering has not changed a lot. So in the 2G and 3G, for example, you have the HLR engineer, in 4G you had the HSS engineer. And now in 5G you have the HLR HSS, and SDM engineer. The same function exists. Then you have again the same thing around your gateways from the days of 2G to 4G and 5G and so on and so forth. So really things haven't modernized as much as the technology is modernizing within the people side of it. We are still a network engineering team, but we've got to transition ourselves from a network engineering team to a software engineering team that runs a mobile network, and that transition is what we're going through, let alone. Becoming experts in AI. Data. So I showed you how many nodes we have in the network. So we have petabytes and petabytes of data sending all sorts of information from the basic SNMP MIBs andoids to sys logs, all sorts of stuff continuously being pumped out. And as throughout the years we keep building these networks, these networks have their own data ingests, and some of them are completely separate to each other, and one group uses that, another group uses a different one. And I don't think we are alone in this. Most operators, I think, still operate in that way, so the siloness of data. And not knowing what to do with data and data that is not clean is a problem. And then obviously the processes, as we keep building stuff, we set up certain processes, and these processes hardly change and so on and so forth. And tools, tools is one of the big my big bugbearers. And the reason for that is every node that you build comes with this element manager and that element manager then is monitored by another network management services. So in our network we are a museum of tools. We have one of every tool under the sun if you think about it. So all of these are the challenges that we face. So we came with this concept that we really want to run our network with data. So we called it DDOPs, data-driven operations. We're not marketeers, so we come up with strange names. So DDOs basically has the first action that we decided to do is to fix data, clean our data, ingest the data into one place, fix data engineering, and then try to clean this data. And the cleaning of this data is very, very difficult because you've got to bring the RAN guy that understands what the data that comes out of radio, makes sense out of it, helps you to clean it. Same with the core network, same with the devices team, and then you've got to bring that together holistically to create one view of what's happening in this ginormous network. And once we clean that data, we bring it into a visualization, data, data analytics that humans then can make faster decisions. And therefore there are some 5 pillars that we put here for ourselves. What is the cause of what happened when something goes wrong? What happened at the moment we could spend hours looking at various tools to figure out what broke. So we want DDOs to really quickly pinpoint that within this function this went wrong. What is the impact of that function not working? Who is impacted by that function? Which customer? What do we do with all this data that we get? What can we learn from it, from the behavior of these nodes and how they operate? Are they operating correctly? And how do we automate everything? How do we automate what we just saw? How do we automate what just broke and really bring the continuous improvement mindset into engineering to say if something breaks once, we really don't expect it to break again. Use the data to figure out why it broke and try to. Try to ensure that it doesn't break again, so this started and we then started to look for partners and Why we chose AWS because like many other well we decided to do this on our own and we made some good progress, but to do this by yourself as a telco where we found that it could be slow and you can make a lot of mistakes. Three things we went through in this journey. AWS one was the culture, the culture that AWS bring into this. So I remember in one of the early sessions that I had with them, you know, they do the usual, put the empty seat there and say nobody can sit there, it's the customer's seat, and me as a, you know, engine room person, like, what, what, what are they talking about? You know what is this now, but it is important because then we looked back that the aim is not for me as an engineer to have a tool that makes my life easier. The aim is actually for the customer not to have an interrupted service, because you think about it, mobile networks are becoming the lifeline of almost your everyday work. Huge amount of us really rely on them heavily. In the UK, 83% of all emergency calls come through the mobile network, so So thinking, putting the customs affairs and ensuring that we're going to use DOs so that our up time and our service is at a certain standard, that that customers affairs mentality helped us a great deal to build a fair division. And the other thing is if we wanted to build everything on our own, it would take us a lot of time, and AWS have developed a lot of technologies that we can use such as bedrock agent core and nitro. Some basic example that you know we get the data, we work with AWS, but when we put it in this environment to accelerate that work and then the other thing, the third one which is very important for us, is we started to understand each other's language very quickly because of the expertise that they brought in to work with us on Dubs. So that understanding of telcos, so when I talk about RAN and RA KPIs, they were matching that and that was really, really helpful for us. So Um What are, what are the success criteria for us? So data is going to be the foundation of everything we're going to do. So to actually slow down and not to jump on a basic use case to create some basic either gen AI or a gente AI to do one part of the bigger journey that was important for us not to do that. We wanted to look at the much bigger picture and bring that into life, and data is at the heart of that. So we're really working with AWS to create the best data engineering. Roadmap and deliver the future of AI on top of that, secure by design. Well, we all hear what's happening every day around the cyberspace and the attacks that happen specifically in the United Kingdom across some of some of the big names. So we started to design everything with cybersecurity in mind as well, especially as we go through this. A lot of the stuff that we build in this DPs. Around network optimization and resilience, we can bring that into cyberspace as well, you know, the basics, Snort and Syracuda development of stuff that we use to push into seam and our SAC, a huge amount of that we can automate in this domain, and nothing is sacred. We can go after everything to automate. But building that massive picture of what does it take for the user to have the best service and understand everything that happens in the middle and automate as much of that possible, that is our aim. And we've got to build stuff that is scalable. We can't just build one tool and then have another tool and then create a process between them. This is going to be one ginormous ecosystem that provides us with these sets of technologies. Now I'm going to pass over to my colleague AJ here who will talk to you about the details of this solution. Bye. Thank you, Reza. Uh, and, uh, and, uh, we really thank you for, uh, your vision, your team's vision, as well as, uh, your intent, and, uh, and also the resilience you have shown in, in putting together this program to execute with us. Um, so my name is Ajay Ravindranathan. I'm a principal solutions architect in, uh, the telecom Industry Business unit. I'm going to spend a few minutes talking about the solutions architecture and some details about the use cases we are building as well, and some we have already delivered. So first, when we started with uh BTV, uh what we did is we worked together to define what is a North Star for us in in autonomous networks and implementing Level 4. And we realize that AI is going to be pervasive across all the layers you see here. There are 3 fundamental layers, the network layer, so we are going to see AI native networks and network data sources that are going to provide data which has been already curated by machine learning models and AI agents in the fullness of time, of course, that sit close to the network. And then the next layer above is AI powered data product life cycles, and over here what we're doing is we are ingesting that data, curating it using data management primitives and creating products out of them, data products that then serve the AI applications that sit above in the layer which is data-driven AI for network applications. So in this layer, as you see, you've got generative AI primitives and really hyper optimized machine learning models and analytics algorithms as well. That solve for specific use cases and which are essentially using the right tool for the right job and then supplying that insight into an agentic AI layer that brings it together and serves the outcome to the human aura system. So essentially this architecture is all about turning data into insights and turning intent into action. So let me deep dive into the layers now. So as you saw, there is a set of data sources right at the bottom. There are performance counters, alarms, topology, config, incidents, changes, knowledge sources. All of these acts as the raw data that is required, and you need to ingest this data from the network. So if you drive an analogy, this is like the flour and the raw ingredients you've got in your kitchen. To make that beautiful bread which is the inside that comes out of it. So then you've got the second layer which is your AI powered data product life cycle management. So here we have data management primitives which go from agentic data engineering and feature engineering. So if you think about an ML life cycle, there is a lot of effort that goes into curating the data, into building data engineering pipelines, into building features out of those so that ML models can use them. And here we want to accelerate that using agentic techniques. The second part of this, which is also unique is the agentic semantic layer. So again, when you define these data engineering pipelines and features, you want to define them once in one place and let all of your products use them. In in a way that they can at run time understand the KPI definitions, alarm definitions, correlation definitions, etc. and then use that in runtime. So that is the agentic semantic data layer. And then when you couple this with an open data format like Iceberg on S3 and couple it with agentic graph databases as well, the intelligence layer, so as we all know, networks are best represented as connected elements, and then you've got graph databases which do that really well, and you can traverse the network and find connections between networks very easily. And then run heavy analytics on top of that. And then finally, a vector store is a key ingredient again, a primitive that allows you to make all of the data, that unstructured data that sits in your enterprise, that's really a wealth of knowledge within your operations as well as your documentation, come to life so that Gen AI and Agentic AI applications can use that. So what you see above is those data products, you know, in the RAN and core you've got KPIs and alarms, you've got customer experience metrics coming in from the core as well, and then you've got a cross domain network and service topology, and then finally your vectorized operation docs. One key element is a network digital twin that you also see there, which is essentially a higher order data product that we generate out of network and service models and topology. And performance and alarms alongside giving you a view of your network, which is really a historical view as well as a current view that can be used by AI applications. So when we then use this on the top, you've got data-driven AI applications for networks where you've got hyper optimized models like let's say anomaly detection models as well as impact prediction models for change impact analysis. Reza talked about change and how it is difficult to analyze the impact of change, so these models would sit in that layer. As well as causal graphs that record what has been done by agents and the root cause that has been analyzed by them, how do you make use of that in the future? So then at the top you see the agents that we have started with, uh, these are some of the agents like root cause analysis agents, service impact analysis, troubleshooting and diagnostics, and optimization. So essentially what we're doing here is again looking at that analogy, taking all the raw data, that flower, curating it, curing it, and then creating insight out of it, and then also creating an agentic loop for intent driven orchestration back into. The network where you could ask for things like what's the problem in this particular part of the network, how do I optimize this network for better capacity, how do I optimize it for let's say better coverage or removing interference, and those kind of intents can be expressed at a very higher order of magnitude by an operations executive and then can be translated into what is needed to change the network. So these are the top 3 use cases that we that we have started with, core and ran anomaly detection, uh, core and ran root cause analysis, and service impact analysis. Let's look at the architecture. So here we've got data coming in from the on-premises data centers, you've got an ingestion layer that is uh that is treating streaming and batch transfer data. So you've got Amazon MSK for your streaming data services, and then Amazon EMR which is for batch processing. All of this is, um, you know, underpinned by a data catalog which holds your metadata and it holds your business data catalog, and you can then create the right level of governance to drive quality in your data ingestion and curation pipelines, and then you have Lambda and EventBridge to create event-driven architectures out of it, and Amazon S3, of course, is our object storage that allows you to store data in that open data format iceberg that I talked about earlier. And then on top of this layer, it is important to use the right tool for the right job. So time series data stored in Iceberg and Redshift and Click House for your cold, hot, super hot uh data. And then topology data being stored in Amazon Neptune and Neptune Analytics. So this is a key part of the architecture that underpins the connectivity between all of your elements and allows you to run analytics algorithms on top of the graph analytics algorithms like breadth-first search, depth-first search, community detection, centrality. And then finally, you've got all of your alarms and events in Amazon Aurora and GIS representation of your network as well. So what do we do with this data once it's stored in the right format, you can then start using Amazon Sage Maker to run machine learning models, so you can see. Multivariate anomaly detection and coverage analysis as models being run there and then the semantic data layer that I talked about that is built using Amazon Bedrock and the semantic data store being Dynamo DB that sort of facilitates this whole consumption layer so that you are not repeating definitions of KPIs and other things. They are all done in a declarative way so that they can be ingested on demand. But what really takes this to the next level and how we are talking about acceleration is using agentic AI applications on top of this. So at the top you can see RCA agents, service impact analysis agents, troubleshooting agents, and RAN optimization agents that are built on Amazon Bedrock agent core. So Agent Core allows you to really take these agents to production using the right primitives around session isolation, identity, integrating with the external world with MCP, integrating within agents using A2A, and then going and providing security with identity as well for these agents. So let's look at one of these use cases now, the multivariate anomaly detection use case. What were the challenges that we found? So BT already has anomaly detection algorithms with machine learning running on their network at the moment. They use univariate anomaly detection models. They have dynamic thresholds that have been defined on them. And but the challenge is that univariate anomaly detection models produce a lot of noise. There are large volumes of anomalies coming in, and most of these can be false positives as well. So what we're doing is we are transforming this to a multivariate anomaly detection method where we are using temporal pattern clustering techniques to group cells of similar behavior. We are then optimizing the number of models to be trained as well based on the topology of the network, you know, having that awareness of which parts of the network behave similarly, like dense urban areas versus macro cells in rural areas versus small cells, etc. And then we train multivariate anomaly detection models on top of this, so we have trained models such as LSDM, autoencoders, as well as transformer models to provide the right level of accuracy in detecting these anomalies in different scenarios, so learning interdependencies between KPIs and then forming that causal graph. So how does this look like in terms of an architecture? The data preparation is with lambda and the streaming services are MSK and EMR for batch. They do the data prep. The cell clustering and KPI clustering is all done within Amazon Sage Maker and using analytics as well as machine learning algorithms, clustering algorithms, and temporal analysis algorithms. And then models are trained within Sagemaker. They are stored. The results are stored on S3 and Iceberg. Inference is done using Sagemaker endpoints, and again, all of this is managed and surveless services. There's no infrastructure to stand up. You use these services on demand and you pay for them on demand as well. Evaluation done within Sagemaker again providing you know what are the important features that are leading to these anomalies, what are the false positives and false false negatives, the objective metrics from these machine learning algorithms. Super important is getting feedback from operational SMEs as well, and then feeding that feedback into a supervised retraining or fine tuning of this model for subsequent inference. So let's talk about the next use case. All of these anomalies then feed into this agentic root cause analysis and service impact analysis use case. Well, you know, um, I guess many of you are from the telco industry and for those who are not, this is a very quick introduction that you've got all of this coming in from the network, and the, the, uh, you know, anomalies, incidents, changes, knowledge bases, network topology, raw alarms, and the job is to really turn that sea of red into actionable insight. What is the root cause and what is causing it? So there are a number of challenges here. There is heavy cost in rule-based automation. Supervised ML models do not give enough performance today because of lack of availability of good training data. And then network topology is what underpins this, and it's often incomplete and inaccurate. So how did we solve for this? We, we invented this, uh, this technology or this representation of agents, uh, and we called it domain specific community agents. So what's a domain in this case, it is, uh, let's say 5G core or 5G RAN or transport, uh, these are network domains, IPM, PLS, DWDM, etc. And then you have communities. Communities are affinity groups of nodes that are connected closely to one another. Networks are designed in a way to keep them resilient as well. So when they are designed, they are designed with a blast radius in mind, and these blast radiuses often mean where you will see propagation of alarms and anomalies. And that's what a community is, we use network SME knowledge from BT to define what these communities are, and then we are evolving it with community detection algorithms within uh within the graph as well. So now, think about it, these agents that are operating within these communities, collaborate with one another and then share knowledge with other agents which are across communities, inter-domain, inter-community agents. And what their job is to correlate across these communities and find the root cause, like if there is, let's say, a transport failure occurring in a particular area that is causing cells to go down in many areas, that would be an example of how you would do interdomain, intercommunity correlation. And then service impact analysis is where we take the output of the root cause and then we correlate it with customer experience metrics and identify the number of customers that are impacted, what kind of services are impacted for those customers, so that you can then communicate to those customers and proactively solve for them as well. So finally, I'd like to take you through a little bit of the high-level architecture here. So you've got Amazon Bedrock Agent Core right at the heart of this architecture with runtime, identity, gateway, observability, memory. These primitives providing particular capabilities, you will hear a lot about these primitives in the coming sessions that you will attend through this week, and, and really the sequence of of the of the flow of data here is that alarms and anomalies come in via MSK from the left. And then the agents that are deployed on runtime use Amazon Neptune, the network topology within Neptune, to identify the clusters of alarms or connected groups of alarms using graph analytics algorithms, and then they use the knowledge bases within within your operations knowledge base as well as RCA knowledge base that grows over time. And then does the root cause analysis using the reasoning capabilities of large language models and small language models. Right now we are using base models, but then we are also embarking on fine tuning these models to create a smaller footprint of your token usage as well as better latency. And then the alarms are stored on, on Amazon RDS and the service impact metrics are stored on Amazon S3. And then we have integrations into trouble ticketing systems to create, uh, update and delete tickets as well. So this is where we are at the moment with this use case. The next step obviously is to take this forward with more closed loop automation where possible, and to talk about these next steps, I will invite Reza back on the stage to talk about some of the benefits and also where we are going next. Thank you very much. So this cannot just be a technology modernization. It is very much so is how we change the way we operate and how we run our business. So first and foremost, we are looking at taking x amount of cost out of our business by removing the efforts that we have today into running the network. So these agentic workloads, the ways of utilizing AI, we're removing the cost not only from the people's side but from every element, consolidation of tools, all of that. So the cost saving is very important, change efficiency. We must improve our SLA. We must improve the up time of the network, and we must improve the service that we provide our customer base, regardless of what that service is. The data platform, the data has to be consistent. It has to be available in a timely manner. We can't operate in an environment anymore for an autonomous network when data is hours and hours late, so it's very, very important, and the customer impact identification here is that really the impact to customers when something goes wrong is very clear, and a remedy is available very quickly. Um So cost reduction, as I said, is the most important one. So what's next for us? So we want to, upon the success of what we go through right now in various elements of mobile network from the core to RAN, all of that, we want to make sure that we be able to expand this to every part of the network. Every function through this chain should be should be part of this journey. Um Coverage analysis and optimization is one example of poll that I want to open up with. So the mobile networks work in octagons, so the amount of data that you receive within this octagon that you're sitting in is very important. We want the network to optimize itself for that area that you're in. Adjust its performance in order to again give you that that content aware networking. People and process transformation is very important, you know, we recognize that we need a new set of skill sets in the team, as I said, software engineering team, AI engineering teams that run the mobile network. The reduction of the impact to change, you know, per week we do in our mobile network 11,000 changes, and majority of the time we're successful, but we want to reduce the risk of that change. We want to use and adopt the domains such as utilization of to focusing for this specific function. And dynamic network slicing use cases is very, very important in the future of the mobile networks. So as all the users and millions of devices from wearables to your cellular phones to the IT move into this 5G domain, prioritization of the service based on when you need the service or if you pay for that prioritization is super, super important, and we want that to happen automatically. So if you're a gamer, you've paid for a gaming subscription, the moment you start your gaming app, that's when it drops you into the, into the, the slicing er er that is good for gaming and holds you there. And that is the vision that we have. So everything has to become measurable. We have to reduce costs, improve efficiency, and delight our customers. I'll pass back to Ishwar to close it for us. Thank you. So you saw the benefits, you saw the next steps, you know, I mean, obviously British Telecom is leading the charge with us on this one, but we are looking to see how we can serve more use cases with more operators around the world. I wanted to touch on a few other sessions which are kind of related to this topic. The first one is Agentic AI for autonomous networks, agent core design patterns, and these, you know, we didn't get a chance to go into detail in the use cases. We gave you a flavor and gave you the overall picture of what we are doing in this space, but in the first session there run by Ajay, you will go deeper into how Agent Core, we're using Agent Core to really build this agent. that's tomorrow, so I would encourage that if you want to learn more about how we are actually building these use cases. The second one is about, uh, domain specific fine tuning. We are realizing that there is an opportunity here to fine tune some of these models for them to be cost efficient, for them to be more accurate with domain specific data. So there's some experimentation and POCs we are doing in that space. That's the second one. The third one is using the Q Developer CLI. That was the top layer in the Agentic stack that I described, and we're using that QCLI there, which is a command line interface and MCP to use natural language to translate that to telecom infrastructure deployment, so not directly autonomous networks but related to how you can manage telecom infrastructure. And the last one is a workshop, a hands-on workshop for an AI agent's framework for RAN network optimization, RAN network operations and optimizations. So that's a hands-on workshop. That's, that's a space that has a very rich potential in terms of applying AI for optimizing various parameters from power to scheduling. To things like carrier aggregation and so forth, and in this workshop you'll get a feel for how you can use Agent Core and some of the other tools that we have to build out some of these optimization use cases in the radio access networks. Thank you for attending. I hope this was useful to understand how agentic AI is being used in solving one of the big challenges in the telco industry. This is something that's unique to the telco industry. A lot of the other use cases are horizontal. We see them across industries, but this area is very specific to the telco industry and jointly with British Telecom, we are on a path to really fulfilling that vision of fully autonomous networks. Thank you again for attending. Please remember to fill out the survey. It's in your mobile app. Don't forget to, uh, you know, kind of take the survey and give us your input and feedback. Thank you. Thank you. Thank you.