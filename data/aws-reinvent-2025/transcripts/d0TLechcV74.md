---
video_id: d0TLechcV74
video_url: https://www.youtube.com/watch?v=d0TLechcV74
is_generated: False
is_translatable: True
---

All right, to get started, who hates raising their hands in sessions? Alright, cool. Now that we got that out of the way, how many of you have moved at least 5 times in your life? Alright, how many have moved 10 times in your life? Oh, all right, so get a load of this. You're gonna, this is the one thing you're gonna like, next week you're gonna be like, man, the one thing I remember from Reinvent, it's this right here. Ready? All right, the average person between age 18 and 45 in the United States has moved 11 times. I kid you not, you're gonna wake up a week from now and you're gonna be like this bald bearded guy told me that people moved 11 times in their life. Why do people stop moving so much after age 45? Yeah, it's painful. Your lifestyle changes. You don't, you don't have time for this. Moving can be a, a real pain. One more. One more move for sure. Uh, so when we started our planning for this session, uh, Arie and I were like, you know, we really like these sessions to be fun, we'd like to figure out some way to actually make this engaging. So what do we do? We reach out to our product marketing person. I wanted to share with you some behind the scenes of how this actually works. So, uh, Arti emails Bianca, our amazing teammate who works in product marketing, uh, and she's like, hey, can we get a moving truck, uh, up next to the stage? We, we brought the, the trucks in the past on stage. Could we do that? Uh, Bianca's response was like, for real? And we're like, yeah, you know, don't worry, we won't drive it, we'll just sit there, maybe we can get some moving boxes. And, uh, you know, she was not, she was not reassured on this. All right, so, well, we, we couldn't get moving trucks. Um, we couldn't get boxes. What do we do? Next best thing. We used AI Uh, about 10 prompts later, I was able to successfully generate, uh, an image that I thought was great. Uh, a huge thank you to my wife for telling me what a boho aesthetic is. I would not have known that. Uh, and my children for saying that this high-key slays. Um, so I think we have a pretty good, a pretty good image here. So the question you're all asking is, why in the world am I looking at an AI generated image of a couch? The thing I want to point out here is when you're moving. The way that we move this couch versus the way that we move the books in the background versus the way we move the lamps or the plants, they're all different. It's not one size fits all for how we we move all of it. The new house you're moving into may not have amazing AI generated bookshelves in the background to put those AI generated books on. Uh, they may have, uh, a different layout. The house may have different number of rooms, but it's all different when you're moving from point A to point B, having to try to figure that out. Typically it's pretty easy to actually move the couch. I, I say that, you know, not having moved the couch recently, but it is pretty easy to move that, you know, it's, it's a, a big fixed item. You can just lift it and you can shift it into the new location, whereas the books, a lot of the knickknacks, the smaller items, figuring out where all of those go in the new house, that part can take a little bit of time. So as we talk about moving, it's the same thing that really happens when we're talking about moving our applications and moving our workloads from an on-prem environment uh into the cloud and one thing that we really think about is that there is not a single path, there is no single way to move everything from on-prem into the cloud that makes sense for everybody. All of you may be at a completely different place in your cloud journey. You may have completely different types of workloads that need to. Move in completely different ways. Yes, picking up a VM, moving it from point A to point B, that part can work pretty well. It's pretty straightforward, but you may have other applications that are better suited to run on spot instances within EC2 or even different size or different, uh, capabilities within those EC2 instances. You may have, uh, uh, cases where you can move into a serverless architecture. You could leverage lambda. You could leverage EKS. You could use RDS and move it into managed services. The thing here is that we we we talk about customers not being a one size fits all. Like there is no, we say this customer is going to lift and shift. That's really not the case. This customer may use lift and shift for certain applications or they may be using different methods as they go along. When we talk about these methods, if any of you have ever seen, uh, the AWBS articles about the seven R's, there's, you know, the different methods for actually relocating. A lot of the methods I showed here fit into the seven R's. You can re-platform, you can refactor, you can re-host, you can relocate. There's a lot of different ways that you can go about moving these applications from point A to point B. And even the point B may be different in many cases. Point B may still be on premises. You may be able to use those workloads or run those workloads within something like an ADBS outpost, which can still run in your on-premises environment. So let's talk about one way to do that, and that's lifting and shifting from an on-premises VMware environment into a cloud-based VMware environment. So earlier this year we launched the Amazon Elastic VMware service. The Elastic VMware service is the ability to take and run, uh, VMware-based workloads, the VCF stack, directly in your, uh, Amazon, your AWS VPC. So just like how you would run an EC2 instance within your VPC and connected to the environment, you can now run the VMware stack directly on ADBS metal infrastructure sitting within that, that, uh, environment. So this is the same VMware stack that you would run in your on-premises environment. It's not something special. It's not some. Uh, modified version, we literally take the commercial off the shelf, uh, capabilities, the commercial off the shelf software, and we run that within, uh, AWBS VPCs, uh, within the environment so that you're able to move from point A to point B without having to change the people skills that you have, the processes that then run books that they operate, uh, and the technology that they use, whether that be third party solutions, uh, or, or scripts. So from a basic feature perspective, um, I mentioned that this is running the standard BCF stack. So we take, uh, cloud Builder, which is a part of the BCF stack, we gather a bunch of information from you up front. We say, hey, tell me about the underlay networks that you wanna run. Tell me about the number of hosts that you want in the environment. We collect a bunch of information from you up front through the AWBS console. We take that information and we actually bootstrap the metal instances and we push the configuration into Cloud Builder and then let Cloud Builder deploy the VM. our stack. So, uh, in VCF it's basically just like how you would take those old school like CDs that used to have like the, the preconfigured, um, configuration for VMware and you pop it in and the server kind of brings itself up. It's very similar to that, uh, in the cloud world where you give us a bunch of information ahead of time. We'll take that, we'll bootstrap the environment, we'll pass the information to the cloud builder. Uh, it'll run and configure the environment. We hand you back the credentials and we say, here's the credentials now you can log in and you're running VMware on EC2 instances within your BPC. Um, you can interface with this through, uh, both the ADBS console and the API. So if you were to go into your AWBS console and look for the, the EBS, you would actually find that service and you could go in and deploy an environment, uh, and get started today. I did mention we're running on a uh EC2 instances. These are I4I metal instances. So this is bare metal. This is not nested virtualization or any kind of, you know, vert on vert or special hardware sitting off in the corner of our data centers. This is standard EC2 metal infrastructure with the I4I metal instances. Today we do run VCF 5.2.1, and you do have access to SCDC Manager, vCenter, all the normal VMware tools that you would run on-prem. Uh, you can access those, uh, in EBS. So, uh, a really simple way of thinking about this is it's almost like using AWBS metal infrastructure like a co-location environment, but you're able to dynamically scale up and down those servers with the click of a button as opposed to ordering more hardware. You do have full administrative rights, so we do not, uh, run this as a managed service. This is completely controlled by you, the customer, just like if you were doing it in an on-premises environment. You have full admin access. You can get, uh, and do really about just about anything, uh, in this environment that you could do in an on-premises environment. Um, from a consumption perspective, you do have the ability to deploy instances using instant savings plans. So if you wanted to commit at a 1 year interval or consume on demand or even 3 year intervals, you do have flexibility, uh, and, and choice as far as how you, uh, how you consume those instances. And we do operate in a bring your own subscription model. So going forward kind of in all cloud providers, um, running VMware, that it is a um a bring your own subscription model. So you can take the existing VCF subscriptions that you have on premises, you can bring those with you and you can apply those and use those into the EVS environment. And then choice, um, you do have the ability to run these yourself, uh, or you can engage a partner. We worked with a lot of partners who have built managed services, uh, where they can come in and operate this for you, uh, in ADBS just like you would do in an on-premises environment. From a scale perspective, we launched EVS back in August and we had 6 regions available. We're now up to 12 regions, uh, and we're continuing to launch more regions, uh, later this year as well as going into next year. So you'll continue to see us work and getting EVS launched into all ADBS regions over the next few months. I mentioned briefly kind of the the customer manage versus partner manage. This is a big deal for a lot of customers who are maybe moving to the cloud, uh, and they have had uh on premises managed service provider partners that they were using who are no longer a part of Broadcom's managed service provider program. Uh, in that case, uh, you are able to move into EBS and leverage third party partners who are, who are still in that program. They built up, uh, they have a lot of expertise with running in EC2 environments running inside of AWS, and they have a lot of expertise running, uh, in, um. Uh, in VMware environments and so there's just a lot of partners that you can leverage to do that or you have the choice to do it yourself. The big thing here is there's a lot of offerings out there that force you into a managed model. They force to say, hey, you, you don't have full administrative access. You're operating in a delegated, uh, delegated model. Uh, in our case we have, uh, built this as a customer managed solution first, so by default you have access to everything, and then you can bring in a partner if you would like them to run, uh, and operate the environment on your behalf. Um, quickly just mentioning some of those partners, it's not just the manage service provider partners like that we have here, uh, shown at the top, but also, uh, on the ISP side. A lot of the tools that you use in your on-premises data centers will operate just the same way in EBS. Uh, think of things like, uh, NetApp or Pure Storage or Beam. Um, a common thing we used to hear from customers is, hey, when I moved to the cloud, it's not just about moving the workloads. I have to now suddenly reevaluate all these solutions that I'm using my backup provider, my DR provider, I have my security tools, like all these things that I've built and integrated into my environment. I now have to reevaluate how I'm going to do those in the cloud. When you lift and shift with EVS, pick up those workloads, move them from VMware to VMware, you can keep the people, the processes, and the technology exactly the same as what you had on premises because you're still using a VMware environment. So kind of going back to that moving uh metaphor that we talked about in the beginning, imagine like you have a house and your house is kind of out in the country a little bit and you have a whole bunch of land, so you have a whole bunch of space available to where if you wanted to build things you could, you could build a bakery, you could build a store, you could build whatever you wanted, you have tons of space, but ultimately you have to build it yourself. Now think about moving into a destination where you're a part of a vibrant village, a community that has all of these things already in there. You already have a baker, you already have a grocer, there's a hardware shop all of these things exist in this village, and now it's walkable. You can just walk over and interface with. These things without having to go and build it yourself, that's really the way you think about scaling and operating, uh, in a VMware environment in AWS. You're taking the same house, the same floor plan, everything that you had before, and you're able to move that into a community that now has all of these other capabilities. So you can take this workload that you were running, uh, in VMware and now it's sitting in your VPC. You have RDS that you're running in your VPC. You have S3. You have EFS. You have all these other cloud capabilities that are now sitting co-resident in the same environment with your VMware-based workloads, and we see a lot of customers do this. They'll take, uh, a database, for example, that's running on a VM inside of VMware, and they may move that over to RDS, but the application itself is still running in VMware on a VM. Uh, if the application is really, really hard to transform or modernize or change, uh, we are totally fine with being able to have you run that workload in VMware. In fact, if you have workloads that you plan on keeping in VMware, uh, we want to be the best place in the world for you to run those VMware-based workloads. If when you move that into the cloud, you want to expand and extend that application to be able to interface with other AWS workloads, we want you to have that capability as well. All right, I'm gonna hand it over to Aarti, and she's gonna talk a little bit about the, the building blocks of EBS. Thank you, Andy. While our product marketing person was not able to get us the couch or the truck, we got a good Monday session that I requested for. The primary reason is what I'll be doing in the next few minutes is talking about the 3 key building blocks that make up the service. This is an introductory level session, and then we have some great deeper dives throughout the week that you can go in and plug into as you wanna learn more about the storage or networking, etc. And he touched upon this. I wanna spend a couple of minutes here. When EVS deploys the VCF stack, we get in inputs from you. And if you've deployed a cloud builder on VCF stack on premises, you would see that the cloud builder requires certain inputs, and that's all the service is doing. We collect all these inputs from you and take care of the deployment. It is a fully self-managed service minus the initial deployment. We wanted to kind of. Remove that deployment from you and take care of it on behalf of you. So when the stack is deployed, you get all these components deployed from STDC manager to the ESXI hypervisor to storage to networking, but we also take care and as you'll see when we talk about the building blocks, the underlying connectivity and storage options for you depending on your use case and your application needs when we deploy the stack. We deploy it in a single consolidated domain, but of course there's flexibility for you as you deploy more hosts and you can bring up additional clusters. You can do multiple workload domains. We deploy. I kept saying we deploy EVS service deploys the environment for you in your AWS account in a VPC that you choose. So obviously from a security standpoint, the AWS shared responsibility model is still applicable. Where it varies is we as an AWS are. Responsible for the underlying AWS components that you see here, so this means from a region availability standpoint or an availability zone standpoint we take care of that. We also take care of capacity for you. So you place in a capacity request reservation saying, hey, I need 10 hosts by a specific date, and we enable that capacity into your account. But anything out upward of the hypervisor, the ESXI stack upwards is your responsibility. This means you're responsible for patching your environment, you're responsible for updates, etc. So there's 3 key building blocks that I kept mentioning. The first one obviously is compute. We started with i4I.metal as our first instance type. This is a bare metal instance where we deploy the environment on. We have a good history with I4I. Metal. Uh, for some of you who are familiar with the VMware cloud on AWS, the managed service, we utilized I4I. Metal. We've received good feedback from customers across various use cases of their applications. These instances also go through a full certification with Broadcom. So today if you go into the Broadcom compatibility guide, you will see Amazoni4I.metal listed as a certified instance to run VCF 5.2.1. So we do go through the entire service certification, storage and network certification with Broadcom. Our goal we we launched with one instance type, and our goal is eventually to get every metal instance that's available on the AWS portfolio available for you so you can choose based on, hey, I do have a high memory workload, so I need more memory versus compute. So that's our goal and it's on our road map. And he talked about scaling. So if you think about how do you scale this environment that we deploy, think of the EVS stack that we deploy, the environment as a top level construct. Within the environment, we take care of that first cluster that you see here. It's a 4 host minimum. 4 hosts minimum, this comes from the VCF requirement that we have, and every environment can have up to 16 hosts. We've tested up to 16 hosts and are satisfied with the performance, and we are slowly expanding this number of hosts soon as well. You could have up to 16 hosts, and you could have this as multiple clusters as well within that environment. If you have a requirement to scale beyond 16 hosts today, you could obviously create multiple environments, and these environments can communicate to each other using a transit gateway. The next building block is storage. So the I4I.metal instances come with 30 tebibytes of local NVME storage, which is what we use for the primary storage, which is VSAN in this case. We are using the ESA, the express storage architecture, which gives a better performance compared to the OSA architecture, so we send forms the primary storage that is available. What we've also had feedback from customers is, hey, I wanna make sure this is consistent with my on premises experience. And so if you're. Doing storage storage policy based management on premises, you want to control what your raid levels are or what your failure to tolerance is. All that's still possible. You could log in to your VCenter console once the environment is deployed for you, and you can configure these as you would do on premises. One of the. Uh, feedback we've received when we started running private preview and then we moved into a public preview is scalability on storage. Not a lot of workloads need that compute but are more storage intensive. So we've partnered with our internal service, the Amazon FSX for NetApp ONTA, as an additional storage option. The primary storage is still VSAN, but you could create additional data stores using NetApp ONTAP or Andy talked, you have full administrative access to this EVS environment, which means if you're using ISV solutions on premises like. VE or cloud, pure cloud storage for example, you have the ability to integrate with these storage vendors as well, depending on your application needs. So if you take a look at how this fits. With FSXONTA, FSX for NetApp ONTA, the primary storage is still our VSA and data store. You could create an additional file system and mount it to your ESXI host, and that could be either using NFS or ISCCy depending on the protocol, and. It becomes your additional storage. So for customers who do not want to just increase the number of hosts primarily because of storage reasons, you could have your minimum number of hosts and then work with either ISP vendors or FSX for NetApp OnTap to increase the storage. How does this look like? So if you take a look at this diagram here, customer VPC is your VPC. The EVS environment gets deployed inside this inside this VPC. You can go ahead into your AWS account, create a file share in FSX for NetApp ONTA. And as long as you enable the right security group permissions, you have access to these file systems. So this is using NFS. The same architecture is available for ICE Czi as well. You create the LUNs and then have security group permissions so that you can have traffic going both ways. The 3rd building block is networking. We've done a lot of work here. I mentioned in the beginning, when we deploy the environment, we deploy it. We take care of storage and networking. What it also means is traditionally AWS has always been a flat layer 3 network. We have a VPC. You deploy a cider block. You have subnets work great. As we started to build EVS, we also wanted to see how do we bring this VLAN subnet concept into VPC. So we've taken care of that. What, what we've done is Andy mentioned when he started this overlay networks, there's underlay networks, etc. So as part of the deployment, we take care of that networking for you, so you don't have to worry. All you have to provide us is inputs on what your appliance IP address spacing should be. And a key part of that is also using some of the existing AWS features that are available. As you think about your EVS environment, you probably are going to connect on premises to talk to an VMware environment that's there, or you want to maintain a hybrid, uh, environment. So we've used the existing AWS route server functionality. Think of it as a BGP propagation mechanism. What it does is you've got a lot of IPs underlay IPs, overlay IPs, etc. This is like your VM IP spaces or your appliance IPs. So the route server basically enables BGP communication. It acts as a BGP endpoint between your NSX edge and all your route tables, propagates your route table so you don't have to worry about any of those failovers or like IP addressing, going in and adding static routes into your route table. And if you take a step back of the full external connectivity, you can have multiple EBS environments as part of your VP as part of uh in a region. You can also have other workloads that you're running within the same VPC as well. And then I mentioned all this connects into a transit gateway. And then from the transit gateway you could either have a direct connect or a VPN connection back to your on-premises network. So it enables the full end to end connectivity. I'll quickly touch upon pricing. So we talked about Andy mentioned we are operating in a bring your own license or bring your own subscription model. So what do you pay for AWS? The first one is the actual instance cost. So this is the EC2 instance that you're running today. It's a 4 hosts minimum. All your existing savings plan and reserved instance concepts still applies to it. This is a standard EC2 instance. We're not doing anything out of the ordinary here. The second is that VPC route server endpoints. You do require two VPC route server endpoints per environment, so you do have a cost that's associated to take care of it. And finally is the service control plane fee itself. This is where it takes care of the, the, the service itself takes care of the deployment, the underlying connectivity between your appliances to RVPC space, etc. So there is a. Hourly fee billed for this environment. So these are the three dimensions that you will incur as part of an EVS pricing model. With that, I will pause. Uh, it's always good to hear from customers. So we've been working with Jignesh from NYU Langon for the last several months now. I'd love to invite Jignesh to share their journey with you. Thank you, Aarti. Um, hello, everyone. Um, Jignash Shah, manager of cloud Engineering over at NYU Langon Health. Um, I'd like to start off with a number, um, 320. That's the average number of days it takes for an enterprise application to migrate to the cloud. Um, I'll be talking about how NYU was able to bring that number down. Um, a little bit about, uh, who we are, um, a large academic, uh, health care system based out of New York City. Uh, our mission is to provide world care patient care, a world class patient care, innovative research, and a top notch medical school. And yes, the medical school is free if you can manage to get in. Um, The three pillars patient care, research, and the, the medical school, you know, that's really powered by the world-class technology that we provide to support it with the help of partners like AWS. Some key facts and and statistics, um, we've been, we've been number one for quite some time for the best outcomes, um, constantly ranked on the top for several subspecialties, whether, whether it's neurosurgery, orthopedic, pediatric, we are up there. We have about 5 large campus in the, uh, in the 5 boroughs, um, along with close to 400 outpatient centers. We see about 2 million um outpatient visits every day. And um in terms of number of employees, we have, we are close to about 53,000 in total employees. So, so quite large academia. OK, um, so our adoption, um, of EVS, I, I remember it was a few months ago, you know, I was watching Monday Night Football with my son, I think it was Giants versus Eagles, and I got a phone call from my boss and he says we have to, we have to go down from taking months to, to, to weeks to migrate our applications. So, The first thought, you know, I wanted to tell my boss that you're crazy, it's impossible, but in, in turn, next morning we, we huddled. I called my team. And um you know we have smart cloud architects, security analysts, SRE engineers. Um, and I challenged them to find a solution. To to accelerate our journey to the cloud. And being a VMwareshop on-prem, it was a natural transition to go to something VMC in one of the hyperscales. So we started contacting different hyperscalers, we came up with a comprehensive success criteria, and it was really detailed success criteria all the way from security to chaos engineering we had everything in it. Um, A few months later, we had a breakthrough with EVS. And I'll go through some of the reasons why we chose EVS, what resonated the most with us, uh, but first, our business case. It was accelerate migration to the cloud. How can we go from months to just a few weeks? And also can we leverage cloud for business continuity as you can imagine, being a health care system, um, our up time is absolutely crucial so business continuity was one of the one of the biggest use case. Some of the business requirements we went, we, we, we wanted to maintain control like Arti and Andy mentioned, we get administrative control over the vSphere clusters running in EVS. We can bring our operational cadence, um, how we patch, how we monitor, um, observability, we were, uh, security, we were able to extend what we do on prem to the cloud and make it more of a hybrid. Flexible licensing model, we, one of the requirements to us to make, was to bring your own license. So we were able to bring our existing VCF license into EVS. Multilayer security, um, because we are able to run in our own VPC not only we, we, we could use our existing security guard rails like SCPs, RCPs, but we could also extend our NSX security to the cloud. So it was really um it it was really transformative when, when we saw that that was possible. Minimizing staff turnover, one of the requirements that our management had was we don't want people leaving us, um, leverage existing skill set and then slowly upscale as needed. That was one and then EBS made that happen. Obviously reducing capital expenditure, you know, we wanted to go more from more of a capex to an Apex model, so not having to spend to buy hardwares and, and servers or, or lease data centers. We, uh, EVS becomes an OpEx model, is built hourly. We're able to cost manage it. So that was one of the requirements, um, around reducing capital expenditure. Why did we choose EVS? Like I mentioned, we're able to run this in our own VPC. Some of the other competing, uh, solutions, we were tied into the vendor managed VPC, not giving us enough visibility or control over what's happening behind the scenes and what we could do. Provisioning infrastructure as a code, we are big into provisioning everything as a code, so we wanted to leverage our existing CICD pipelines for anything that we deploy in the cloud and EVS had that um uh had that offering. I talk about bring our own VCF license starting with a pilot light, the another welcome, um, and, and a great feature of EBS is I can, we can start with a small pilot light cluster and then we can add nodes as needed. So you can start with as small as a 4 node cluster and then you can add and scale up as you migrate applications or you put disaster recovery workloads in it and on demand. We could scale out the number of nodes in the cluster in an event of a disaster. Growing IOS ISP partners because we are a heterogeneous environment on prem, uh, it was important for us to maintain the, the partner ecosystem that we use on prem whether it's, it's pure storage or it's FSX on NetApp. We wanted to keep our partner ecosystem, uh, intact and. Have as little changes as possible when we move the applications. Automated security provisioning, we're able to continue using some of our security tools that monitor um communications and traffic and they take action when they see an anomaly or a threat detection. So we were able to leverage and and and continue automating security. And the last one is one flat rate per node. I am, you know, we are really paying per node. You're not paying per VM or per EC2 instance. We're able to run as many VMs as we wish on a single EVS node. And, and that was really, um really useful to our use case. OK, uh, lessons learned. Although this was, this was a successful journey, we did run into some, uh, some bumps in the road, and, um, you know, with the help of AWS support the account team and our OEM partners, we were able to quickly overcome some of those hurdles. One was operationalizing EVS. We had to figure out a way and build a custom module to, to integrate EVS availability and performance with our service management back on-prem. Uh, things like monitoring FSX NetApp performance or, or integrating VA with our ticketing system. There was a, a learning curve, and it took some time to really operationalize EVS. One of the um. One of the issue we had was figuring out routing network routing between the, the EVS overlay and the, the VPC underlay, um, because we, we have a sophisticated network topology, uh, it took us, it took us a little while to figure out routing and, uh, and, and put those policies in place. Uh, to get the, the overlay VMs working with the underlay services such as EC-2, as well as the on-prem applications. Data ingress cost, you know, AWS always says data in is free, data out will cost you money, but in this case it was a bit of a surprise, but we, we did, we did see some ingress cost, but it, you know, we were able to work with our AWS account team and bring that cost in control. And cloud formation because we are not a cloud formation shop, there was a um there there there was a learning curve for for the NYU team to to use cloud formation to provision EVS. Looking ahead, um, today, EVS supports a single AZ. So we are looking forward to a multi AZ support. They already have multi-region support. Um, looking, looking forward to them inviting and certifying more ISV partners as this ecosystem grows. And uh looking towards a terraform support for EVS. And back to Ati. Thank you. Appreciate you sharing your journey, Jicknish. So we'll jump into a quick demo, uh, I'll walk you through the actual deployment experience. OK, so this is the landing page in the AWS console. So as you can see when you go into get started, there's a few things here before deployment. I think we want to make sure there's a lot of information we collect from you. Uh, business level support is minimum required as part of having EVS, but we also want to make sure as you think about how to get started, there's prerequisites, so we provide you all this information in terms of what prerequisites are required that helps you with planning because most customers that we've talked to, their on-premises team and their cloud team are different. There's a separate network team that handles like IP address spacing. So it's important to understand what these prerequisites are. So you'll see all that here. It's divided into like a 4, portion of what we need. EBS also interacts, as you saw, compute network storage. It spans across other AWS services. So we've provided links to other services that you'll, uh, interact with. So if you go into environments and go into create environment. So you'll see here, you'll have to give in a name for your environment and then this is where we collect some basic information. We're starting with VCF version 5.2.1 and then as part of your agreement with Broadcom, you would have a site ID. So you'd give in a site ID and provide the solution key and the visa and license key. It's important we do checks for this solution key and license key. What this means is you want to make sure you have, if you're deploying a 4 node environment, you have enough courses to support as part of this key that you are having. So once you've given the solution key and license key and then The next page is where you deploy the host itself. So these are the easy two instances. This is the compute that I was talking about. So the initial cluster, as I mentioned, is a 4 hosts minimum, and this is all deployed as Jignesh was talking in a single availability zone. You do have other options of choosing placement group settings, etc. but you can go ahead and create all the 4 hosts here. And then we go into the actual network configuration. We we launched this feature very recently for customers that are familiar. Head CX enables you with migration of your VMs from on-premises into EVS, and you could do it over private connectivity either using, uh, a direct connect or using internet connectivity. So both these options are available for you. So this is where you tell us, hey, this is my VPC that I want the EBS environment to be in. So you select your VPC. And then you select what we call a service access subnet. So EVS deploys it into your account, so we will have a service access into your particular subnet that you choose and what security group that you select. And this is a subnet that we'll use, and this model is very typical to other AWS services like the Network load balancer or RDS for example. Next comes the actual VCF connectivity options. So we deploy these stacks, so which means we also take care of deploying these management appliances for you. So what we do is, and this is part of the prerequisite from an IP planning perspective, is for you to give us what cider blocks are required in order for us to use that as part of the cloud Builder deployment. So once you get all those IP addresses, as you can see here, I've prefilled some of these things. And this is where you select what that route server, you would have to create your route server endpoint and tell us which route server peering to use. So you could select the route server peerings here. And then go into your next. And then this is standard DNS host names. So if you're using, you could either use Route 53 or you're on-premises DNS. We ask for DNS host names for your appliances. So once you get your DNS host names, And the last page is just tags, so you'll see you'll have an ability to review all these settings. It's important to note some of those IP addresses for those appliances. You cannot come and edit it, so it's important to just be sure you are filling in the right information as you go through this. So once you give us this, we collect all of this, and our control plane, our service takes care of all this bootstrapping this information and deploying it for you. The typical deployment time today is approximately anywhere from like uh uh it takes approximately 3 hours, and this involves building the VCF stack, getting the host up and running. So at the end when you see the environment when we hand it off to you, it is in a fully, you can utilize, you can immediately log into your vCenter or your vSphere credentials are managed in KMS. So I've just. Recorded this so that I can show you, but let me just show you an environment that I've created to show. So this is an environment that I've created, so you would see here that. The details of the environment are here, but this is where, this is what you gave us. So you gave us what the hosts are, what the keys are. So we go ahead and you'll see this is a standard EC2 instance. It's got an instance ID associated with it. So we deploy these hosts for you. You'll also see this is where you provided us your network configurations from your VPC to what service access subnet and route server, and then you'll see the VLANs that we've created for you. So these are the 10 VLANs that Amazon, you will see this in your account, and these are created in a special subnet that you see here. And then the DNS host names are also available for anybody who's done a deployment on premises. These VLANs all probably look very familiar to you, right? This is the same thing that you would deploy in an on-prem environment. So really the, the difference here is rather than racking and stacking, cabling, having your network team configure everything, you're providing just the, the logical information, the IP subnets, those types of things, clicking deploy. But this is nothing kind of special from a cloud perspective. This is really the same stuff you would use in an on-premises deployment. And then you should be able to log in. Once this is available in your account, you should be able to log into your SDC manager or NSX manager and continue your day two operations like you would normally do. So that wraps up our demo. We do have a lineup of sessions this week and as I was talking earlier, this is an introductory level session, but you can see here there's very like specific storage based sessions or networking based sessions that are related to EVS and. Migrations throughout the week, uh, so feel free to take a look at some of these sessions. Some of the chalk talks are not going to be recorded, so I highly, highly recommend doing some of these chalk talks. These are smaller sessions where you can dive as much detail as you want depending on what you have. We do have a getting started guide and the deployment prerequisite checklist that I was talking about, so take a look at it and Andy and I, we do this session every year. So if you have any feedback, we take it very seriously. So please make sure to give us some feedback. It should be available on the app. We're gonna be hanging out after this session. We do have some time, so happy to take some Q&A as well. Jignesh is also going to be here. So if you wanna talk to us, any of us, come, uh, chat with us, and really, really appreciate. I know it's a long week. There's a lot of other fun announcements. The only AI we could include in our session is Andy's couch, uh, but there's a lot of like good announcements and keynotes coming up. So I appreciate all of you showing up on a Monday morning to this session. Thank you. A couple of big takeaways or things I just want you to think about as you're leaving. Like one of the questions we get asked a lot as, as we're talking with folks is like when would I want to use this. Uh, and, and as Jack Nash mentioned, like a key thing for when you wanna consider EBS is when speed matters. Uh, Aarti and I have conversations, I think, probably at least once a week, if not more, where customers say my data center contract is coming up for renewal, and I need to be completely out of my data center in 6 months, or, or my server, uh, support is running up in 3 months, and I need to be out of it very quickly. So a big case for using EBS when speed matters when you need to move from point A to point B very, very quickly, this is definitely the fastest way to get from point A to point B while maintaining all the kind of people process and technology aspects of it that are the same and some of the, the real secret sauce of this, what allows this to happen is you do not have to, we, we didn't cover this, uh, tremendously in the networking, but, uh, I would encourage you to go to the deep dive sessions if you can. Uh, some of the, the kind of real magic of this is the ability to actually extend those layer two networks from your on-premises environments into the cloud. This means you do not have to change the IP addresses of the VMs as you move them. And when we talk with customers, this is one of the biggest things that they come up with is if I don't have to change the IP addresses, I, it reduces my testing burden. It allows my app teams to do less work and I can move much, much faster. Uh, again, we were trying to provide much of a higher level. This is, this is what it is and how it works at a, at a very high level. If you can attend some of those deep dive sessions, they'll go into a lot more detail of some of the, the, the magic behind this and being able to, to literally use VMware. HCX technology to move the VM from on premises into the cloud without changing IP addresses, uh, with, with very, very minimal downtime, uh, and being able to do that very quickly. So encourage you guys to check that out and, and, uh, I'll just echo what Arti says. Thank you so much. We would really, really appreciate it if you could provide us feedback. We hope you learned something and again we'll hang out down here and we're happy to answer any questions that you have. Thank you all. Have a great rest of your week. Thank you.