---
video_id: k1gwZQgCBhc
video_url: https://www.youtube.com/watch?v=k1gwZQgCBhc
is_generated: False
is_translatable: True
summary: "This session, \"Knowledge Graphs for AI and Intelligent Systems (DAT209),\" argues that traditional data structures (data warehouses, SQL, NoSQL) are insufficient for the next generation of AI because they lack context and connectivity. The speaker explains that while AI adoption is high, only 5% of projects reach production, largely due to data being siloed and not \"AI-ready.\" The solution proposed is \"Context Engineering\" using Knowledge Graphs to store data as nodes and relationships (e.g., Supplier -> supplies -> Material) rather than isolated tables. This approach, often implemented as \"Graph RAG\" (Retrieval-Augmented Generation), provides LLMs with a rich, connected web of information, significantly reducing hallucinations and improving reasoning capabilities (e.g., finding optimal supply chain routes via shortest-path algorithms). Studies cited claim knowledge graphs can be 3x more accurate than SQL/NoSQL for complex reasoning tasks. The session highlights that knowledge graphs bridge the \"left brain\" (knowledge/facts) with the \"right brain\" (AI reasoning/creativity) to create explainable and trustworthy AI systems."
keywords: Knowledge Graphs, Context Engineering, AI Readiness, Graph RAG, Data Strategy, Intelligent Systems, Supply Chain Optimization, Explainable AI, Vector Databases, Amazon Neptune
---

Uh, hi everyone, um, uh, thanks for attending today's session. So we'll go over why knowledge graphs are great for AI and you know, agentic AI, and we'll see how it, uh, makes your AI more trustworthy and explainable, right? So we'll go, go through that. So what's the agenda, uh, we'll go, we'll go through some of the AI challenges we have with enterprise data, uh, understanding context engineering. Some of you already know some of the that that term we'll go over, uh, what, what is context engineering and why knowledge grabs really help, uh, to build that context and make your, uh, data AI ready. I will not have time to go through a demo today because a lot of slides, uh, but if you stop by a booth, uh, I think it's 1212, uh, booth number, uh, we'll go through the demo and we, you can also understand, uh, our new agents and MCP servers and, and stuff like that. So let's go over some of the challenges we have, especially with the enterprise data, right? Uh, as you all know, uh, AI is a great accelerant, right, for, uh, new experiences and processes. It, it really defines, um, you know, to get new, uh, drive innovation, reduce complexity, improve experiences, uh, all of that to lower costs, uh, grow revenue, manage risk, so there is definitely a lot of adoption, uh, with AI. Uh, but you'll be surprised to know that only 5% of the projects actually go into production, right? 95% don't go, don't reach production. So this is the, the new report from MIT and Gartner study where it shows, uh, that only 20% of the projects actually do a POC and of that only 5% go to production. So a lot of the survey, uh, that we surveyed, uh, customers say that, uh, the, the, the, the data is not AI ready, right? So that's the reason why they don't go to production. The reason might be it's, uh, the data is in silos. There might be security constraints. There are a lot of regulations and, and, and stuff like that, right? So that those are the main reasons. So we'll get, get into some of, some of that. Uh, so here are some of the AI, uh, challenges around enterprise data, right? So we know there's hallucinations, obviously, but that's improving on the public Internet data, uh, but on, on the, on the enterprise data, it still needs a lot of improvement. And uh AI really is like a black box right where uh enterprise don't really get you all the data uh data uh to customers and there's a lot of regulations and compliance around data right that those are the main reasons and uh other big reason is the context, right? So you really don't have um. Uh, structured or connected context rich, uh, uh, context that, that we can give to LLMs. We'll get into that a little bit, but that those are the main reasons, right? So what we've done is, uh, we have bucketed that into 3 big buckets. Uh, there's a data organization problem where, um, you know, your data can live in many data sources, right? You, you can have data warehouses, uh, lake houses, uh, traditional, uh, relation databases, document stores, and so on. So AI really cannot access that information. So that's, that's a challenge. The other is you, you might have different schemas, right? schema, data models, uh, formats, structures, so you really cannot, uh, AI cannot really, uh, understand some interpret that information. So that's another challenge. So those first two, it's easy to interpret like a lot of enterprises are actually working on that. The third one is a big challenge where, um. Scale of query diversity, right? So let me go a little deeper on that. Query diversity is a big problem where you ask a question to LLM right now with the enterprise data you have a lot of information, a lot of, uh, sources to gather, uh, take information and query, so it's not one query, it's it's not a one question to one, query, right? So you have a lot of queries to, to gather and then, uh, get to get to a solution. Uh, let me give you an example, right? Let's say, let's take a supply chain optimization, uh, use case as a, as a, as a, uh, as a use case, and the question is, you know, you want to find the best routes from point A to point B. You ask that's, that's your problem that's your question, right? But now you have to deal with a lot of, uh, data sources. You might have to get into ERP systems, your data, uh, your data warehouses, uh, many of those sources, uh, now you ask, start asking, digging deeper, probably you wanna say, uh, you know what I wanna identify. possible routes, uh, I want to trace dependency, chains. I want to ask the delays and, uh, and the lead times. So you ask, you start asking those questions. So that basically, uh, it's a lot of query. So now you're hitting, hitting it with a query diversity problem, right? So there are two ways to fix that either give a lot more context to the LLM so that it understands or consolidate the data somehow so you have a simpler query, right? So that's exactly what we're trying to do. Uh, graphs, uh, help you do that, you know, it obviously boosts accuracy and improve explainability, and, uh, the reason why, why you're here for the, this talk is it actually allows you to get you more context and make the data AI ready, right? We'll get to that, uh, in a bit. So before that, let's understand what is uh context engineering. Some of you already know that term here it's basically um. It's basically an evolution of prompt engineering, right? So, uh, it, it, the definition by definition it says that you just give enough information to the LLM so that it can, uh, get to the next stage or next step, right? So you want the right data right at the right time, uh, at the, at the right structure to so it, it knows what to do next. So why does it matter now? Uh, I mean, traditionally, or even now, like what what's happening is you, you expect, uh, uh, one shot LLM prompts, right? So you give an answer, you ask a question. Uh, you think that, you know, you'll give an answer that's very straightforward, but that's not the case with enterprise data, right? You have like multiple, multiple, uh, data sources. Uh, you, it has to reason. So especially with agentic AI, it has to reason, it has to plan. You have, uh, multi-step actions. You call, you, you, you probably call multiple tools, uh, so they, it has to fetch data, uh, all of that, right? So again, again it comes back to the query. So it has to do multiple queries to get that information. So what we're saying is give enough context so it understands what to do next, right? So that's a basic idea. Uh, again, that's a definition by, uh, Lang chain, uh, as well. So what are some of the sources you have, right? Uh, so you have all the user interactions, um, that you give to the LLMs now that can be your, uh, prompts, uh, your feedback, and all the, all the, the interactions you have with LLMs. It keeps the state and history, so that's, that's also can be part of the context. Uh, it has a short term, long term memory within the models so that, that can also be used. You have structured output that is basically your APIs and data tools, uh, that you fetch data from, right? That, that is also part of the context. The other big thing is a rack. Uh, so now you can actually retrieve information from your vector database or your graph rack, where, where you have a like a graph database like NO 4G, and that can be part of the context, right? So those are some of the sources. And this is the same view but from a different angle where you have humans, human interactions you have, uh, you have cognitive layer of the application, you have memory layer of the models, and you have data tools, right? The APIs it's the same thing but just laid out on a different view. So the other big thing which we need to consider just because you have data I cannot give all that information to the LLMs uh it you got it's gonna hallucinate again right because it has too much information just as a context. So what we're saying is, uh, there's something called as a minimal viable context, uh, just with the definition of context engineering again it's just the right information to, to for the LLMs to do the next, next step, right? Uh, so we have to, uh, make sure you have higher signal to noise ratio, right, to, to get to the LLMs. So that's another concept, uh, basically with context engineering. So at the crux, that's what it is, right? You give the right information even if you have agentic models, uh, agents should understand what to do next. So you, you need that context, uh, information. So why graphs? Um, so before I dig in, um, oh, hold on. So before I dig in, um, what is graph, uh, database itself, so let's understand a concept of knowledge graphs, right? So it's basically by definition it's a it's a design pattern to organize and access connected data, right? You can have any connected data everything is connected, uh, right? So you let's say you have um. A supply chain you have financial data, your networking, access control, all of that is connected, right? So by definition you can have a supply chain knowledge graph you can have a financial knowledge graph, you can have any of the knowledge graphs, right? So now you, it has specific information around that, right? The way we store data is uh something called a property graph model. Uh, instead of, uh, tables and columns, we have notes and relationships, right? So think of, uh, again, coming back to the supply chain, think of a supplier and a raw materials, right? Supplier is a is a node and raw materials is a node as well. Supplier supplies raw metals supplies, it's a verb. That's a relationship. So that's how we store data Uh, and within, within the, within that information you can store properties, right? I can say, hey, uh, supplier supplies this raw materials, but what's the, what's the, uh, data it's supplied on, uh, what's the lead time, uh, what's the capacity? So those are the properties now that is the context that you can store inherently within the database, right? So that's a big, big difference. So I don't have to have joints and, uh, tables and to extract data. Everything is inherently stored, right? So think of this as a Another example, right, so you have supplier. So now I have supplier graph. I have a product graph. I have a consumer graph, uh, so now you all your business can be all connected in one view, right? So now, uh, it solves two problems, uh, like I was saying, you have the query diversity problem. Uh, it's simpler to query with, with graph databases, uh, because you have all the connected view. I can do a multi-hop query. I can do reasoning, all of that because everything's connected and inherently stored, right? The other big, the other big challenge which we solved by this is, uh, giving the right context, right? So now you can, I can give a minimal, minimal, uh, context, uh, to the LLMs to for that to do the next step, right? So that's the reason why we say it's a, it's a AI ready, uh, data because, um, so we have, you have all the connections, uh, and, uh, context within within the database. Again, it's the same thing. I'm not gonna go through that again. So think of this as a as a left and right brain, right? So right brain is basically your language, reasoning, creativity, uh, and then your left brain is basically your knowledge layer, right? So you have context enrichment together obviously you have more explainable AI so that's the whole idea. Uh, coming back to rag, this is part of the, part of the context engineering, right? So you, it, it's, you're trying to provide as much context as possible. That's the whole idea, right? So traditionally what you have is you have a retriever where you retrieve information from a vector database, right? It can be no SQL or vector database, uh, with, with graph, it's basically your, your, um. Replacing that with a graph database and that's a graph rank that's all right? But what we have now is since we have the connected view of all the information you have the context now I can provide a lot more richer context to the LLMs so that's the whole idea with with the graph rack, right? um. Now, uh, an example would be going back to supply chain, the same question I asked before, right? Uh, what's the best route from point A to point B? With graph, I don't have to dig deeper into ERP solutions, spreadsheets, dashboards, and all, all of that, right? I can just do a single query saying, you know, what does, what's the shortest path? That's a query, that's an algorithm I can use and you get the answer is as simple as that, right? So that makes it much easier. Also, you, you have other information that you can retrieve, right? You can, you can do pattern matching, path finding, uh, you have community driven algorithms that you can, you can retrieve from the graph databases. So it, it gives you an added benefit of using a graph database, right? So again just to just to uh hit on the architecture here so you have a data platform, uh, that can be, you know, since we're in the AWS conference, it it it it can be anything right Aurora, Redshift, uh, S3 buckets and whatnot. You have LLM and Knowledge graph can sit in between that as a as a context, um, layer or a knowledge layer, right. Uh, so a lot of companies, what they do is they, they project the data from your traditional, uh, data platforms into knowledge graph. You don't have to project everything. You, you can just project part of the data there where you wanna run algorithms or where you need the context from, and that can act as a context to LLMs. So a lot of companies are doing that that just gives you an idea of how you, uh, want to, uh, use knowledge graphs. And um also the knowledge graphs uh lead to more accuracy and this is not me saying it this is the public report uh which you can access uh they've run a study where they, they, they run knowledge graphs uh against no SQL and SQL databases, uh, and they, they've found that the accuracy is 3 more accurate, uh, uh, in, in, in terms of responses they get from LLMs. So just to level set, right, why is that? Um, let's go to the semantics of it, right? Let's say I have, you have a very simple example of apples and oranges on the left, uh, you can query, right? That's how it's stored. I don't have, I have, I don't have a vector representation. That's how it's stored in the, in the graph database. On the right, it's a vector database. It's a vector embedding, so that's how you store the information, right? Um, To do a search you probably do a Euclidean or a cosigns a similarity search, uh, on, on the, on the, on the left on the on the on the graph database it's very easy you can just query, right? Uh, you can do a lot more with it like, like pattern matching path finding, and a lot of, a lot of those things with the, uh, with the, with the graph database. And imagine now that you have, you have, um. You have just one information now, right? So let's say uh you have supplier graph, product graph, consumer graph, all of that information. Now you can really analyze the data. You can do a lot more with it, not only giving the context to, um, to, to LLMs, but you can do a lot more with it, right? So that, that's the, the, in essence that's the that's advantage of using a graph database. So really this is my last slide, uh, really graphs go beyond graph rack, right? So you can, like I was mentioning you have context, um, engineering where you give the right level of context, it allows you to do that. Because it has all the information stored within the graph database, right? Also, uh, when you're interacting all the user interactions you have with LLMs, you can store that as context as well, right? Within the rag architecture you can go like after the response you have all the interactions you can store that as context you can probably store that as as a property or relationships or nodes within the graph database so you have that uh as a memory, right? You can use that as a as a as a context, uh, as well. Beyond that you can obviously visualize it. The other thing is which we, we did, we didn't talk about is a cipher query. It's a GQL query just like a SQL. You have a GQL is query, uh, graph query language. Using that you can do a lot of things like pattern matching, path finding, and, and so on. So that really allows you to visualize and, you know, explore data even further. I think that's all I had. And if you have any questions, we have booth 1212, and then we can probably go through a demo. I didn't have time for the demo. I had a demo, but I didn't have time. But if you can come to our booth, uh, we'll go through a demo. We also have our agents and other MCP servers as well. Thanks for coming.