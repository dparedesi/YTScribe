---
video_id: IkK6dSsC5fU
video_url: https://www.youtube.com/watch?v=IkK6dSsC5fU
is_generated: False
is_translatable: True
summary: "This session, titled \"Scaling support, compliance, & productivity with conversational AI at Coinbase\" (IND3312), provides an in-depth look at how Coinbase has leveraged AWS and Generative AI to transform its core business operations. Joshua Smith, Senior Solutions Architect at AWS, opens the talk by tracing the rapid evolution of Gen AI in financial services, moving from tentative experimentation with RAG in 2023 to the deployment of autonomous, multi-agent systems in 2025. He introduces AWS Bedrock Agent Core as a critical enabler for this shift, solving key production challenges like long-running agent state, secure identity management, and standardized tool access via the Model Context Protocol (MCP). Varsha Mahadevan, Director of ML and AI at Coinbase, then takes the stage to detail Coinbase's implementation across three strategic pillars: Customer Support, Compliance, and Developer Productivity. In Customer Support, Coinbase has built a sophisticated three-layer chatbot architecture—starting with simple FAQ retrieval, advancing to procedure-following agents, and culminating in proactive issue resolution—that now automates 65% of customer inquiries, saving nearly 5 million employee hours annually. For Compliance, Mahadevan describes an \"agentic architecture\" that orchestrates holistic reviews for anti-money laundering (AML) and Know Your Customer (KYC) processes. This system synthesizes data from internal and open-source intelligence to generate comprehensive risk narratives, empowering human agents to make faster, more informed decisions on suspicious activity reports. Finally, for Developer Productivity, she highlights an AI-powered software development lifecycle (SDLC) where 40% of all code is now AI-generated. Tools include an automated Pull Request (PR) reviewer that saves 75,000 engineering hours per year by enforcing coding standards and summarizing changes, and an automated UI testing agent that detects three times as many bugs as humans at 86% lower cost. The session concludes with Coinbase’s vision to democratize AI, aiming to put the power of agent creation into the hands of every employee to drive continuous innovation."
keywords: Generative AI, AWS Bedrock, Coinbase, Agentic AI, Customer Support Automation, Compliance Automation, Developer Productivity, Model Context Protocol, Financial Services AI, AI ROI

All right. Hello and welcome to Reinvent into session Industry 3312. We are proud to share with you today a story about how Coinbase scaled their support, compliance, and developer productivity workflows on, uh, using Gen AI on AWS. I'm Joshua Smith. I'm a senior solutions architect, uh, here at AWS in Financial Services. I'll be joined by Varsha Mahadevan, who is the director of Machine learning and artificial intelligence at Coinbase. And let's get started. So today we're gonna start with a quick introduction. We'll be followed by an overview of some of the key AWS services we'll be talking about today. Um, these services are crucial for our customers to build scalable, secure, and resilient AI solutions. After that, I'm gonna hand it over to Varsha, uh, from Coinbase, and she's gonna go over over their vision for AI, uh, and then she'll break everything down by use cases. She's going to cover customer support, and then she'll cover how Coinbase uses Gen AI additionally for compliance and to enhance the developer experience. And then lastly, we'll close on how Coinbase sees their path forward. So taking a step back, when we talk about Gen AI for financial services specifically, um, it's important to look at where we came from and where we're going and the goals and challenges that drove us there. So back in 2023 what we were seeing is LLMs for customer and enterprise just had started to hit the market, and we were starting to get questions around trust and security of data. Um, these were basic questions. Uh, how can we trust it with our data? Retrieval augmented generation or RAG was critical to businesses, and, um, FSI customers had a treasure trove of data that they could use, but they weren't sure how to get it, uh, make it useful in a way that was safe for them. Throughout 2024, after the release of Amazon Bedrock and other solutions to manage secure data access, um, guardrails, and more, we saw customers start to begin to use the AI across a few key areas like customer support, uh, and the questions then started to be more around scale, capacity, and deeper questions around data access, streamlining it, um, granular security. And specific data storage or specific tools. Uh, customers were exploring at this point how to apply the same well architected frameworks that they were using for their traditional applications, but apply them to AI to architect them for future growth. But now finally in 2025, we with the rise of more agentic patterns, more tools, um, we're starting to see customers build fully multi-agent autonomous applications, and we're seeing customers start to ask how to completely transform their core business, um, entire departments of their business, right? And the question isn't anymore how can we build this AI chat, right, or something that where it's a singular tool, it's how do we revolutionize the way that our customers and our employees interact with that workflow and the goal here shifts into measurable impact and business KPIs. So how do we go and, and build this? It sounds great, right? Um, I'm gonna briefly talk through a few key ways. This is AWS services for AJ to AI. So whether you're looking to quickly pre-deploy pre-built agents to boost productivity, you're looking to experiment with open source tools, you want to build a fleet of sophisticated custom agents, AWS provides the models, tools, infrastructure and expertise that will help you succeed. We offer robust AI infrastructure, custom silicon, and data foundation tools to help ensure the longevity of those efforts. Um, this is based on decades of experience that Amazon has building secure, resilient, and globally scaled infrastructure and advanced controls we have for data privacy, access management, monitoring, observability to help customers confidently deploy these, and we deploy agents in every workflow, right? So we have Q Developer, we have Quiro, and Q Business for prototyping and building agents and taking advantage of your data. AWS transform. Um, is to automate modernization of legacy workloads like .NET frameworks, um, VMware, uh, and agents in Amazon Connect, and we also have agents and tools in the marketplace. And so if you look at this stack, all of this is surrounded by this investment into interfaces, protocols, security, and network enhancements for AI. So we'll start in the middle here where we're gonna focusing here today. Um, Amazon Bedrock is a fully managed service to help build, deploy and operate Gen AI applications, including agents. So it provides access to leading foundation models like Anthropic, Meta, Mistral, and Amazon through a single API and it consistently adds new models, right? So we have tools to privately customize models, some of which we launched this week, and applications with your data, and apply safety guard rails, optimize for cost and latency, and rapidly iterate there. Bedrock also newly includes Agent Core, uh, which is a set of services to deploy and operate agents securely at scale. So because Bedrock is serverless, you don't have to manage infrastructure for all of this, and again, it's based on this proven infrastructure. So Bedrock makes it easy to build and prototype agents. However, at the same time, Gartner predicted in their most recent report that over 40% of agentic AI projects will be canceled by 2027. The reasons they cited were growing costs, unclear business value, and insufficient security. So getting agents to production is still really, really hard. Um, so first, the first challenge you have to overcome is that you have to deploy. Um, in order to deploy AI agents, you need a specialized runtime. So unlike typical applications that follow predictable paths and user journeys, agents can operate over very long time horizons, and they process multiple different types of modalities and they can call different tools and services and make different pathways. The second reason is that as the underlying LLMs are stateless, the agents still need memory to, um, retain context, learn from their past interactions, and to provide personalized experiences. And thirdly, you need fine. Trained identity, right? So access control to ensure that agents can access only the systems and data sources they should, right? Who is this agent and what can they access? Fourth, you need to ensure that your AI agents can discover and interact with custom tools and data sources with the appropriate identity controls. You also need to execute multi-step workflows autonomously, and so, and you need common tools in those workflows that are shared or restricted. And then lastly, you need specialized monitoring that is that is specifically designed for agentic systems. So overall, you know, I, I, I, I talked about a lot of different problems here, but the real message here is that operating them in production is very different than prototyping with agents in vibe coding. And so these challenges are the reason that Amazon built uh Bedrock Agent Core. So Agent Core is a modular, fast iteration approach to building scalable production agents. So firstly, if we look at the top, Agent Corre is designed to simplify operations and tools for agents. Agent Corre runtime is a secure, serverless runtime that's purpose-built for deploying and scaling dynamic agents and tools, regardless of framework, protocol, or model choice. Developers can reliably run any type of agent, including multimodal, real-time, long-running agents, workloads up to 8 hours running with agents. Um, it has checkpointing, recovery capabilities, and it supports graceful recovery in the event of uh unexpected interruption or failure. Agent Core Gateway allows you to easily integrate your MCP servers, your APIs with your agents, and provide an easy way to empower them with an array of tools. And lastly, Agent Core, browser and code interpreter allow your agent to act autonomously in the browser or to execute code on your own terms, your own rules. If we look at the bottom, I think of these as supporting tools, right, that help your agents act more effectively as they carry out these tasks. We have agent core identity, which helps you build enterprise ready AI agents from a security perspective, an identity perspective. This has standards-based authentication, compatibility with existing identity providers, and native support for OAuth enabled services. It has a secure token vault to enable authentication. To have more frictionless user experiences for all your agent powered interactions. Agent core memory, as I mentioned before, uh, is going to allow your agent to store and retrieve short and long-term memory for those complex workflows, right? How do you continuously use user input, continuously history, build on top of a shared memory. And then lastly, observability is gonna help you centralize your observability stack for G AI combining logs, traces, and metrics to measure performance and accuracy of scale. So, now that you have a foundation of AWS services for agentic AI, you're set up, I'm gonna pass it over to Varsha, who's gonna dive deeper into Coinbase's use cases. Thank you. All right. Thank you, Joshua, and, uh, thank you all for being here. Uh, I know it's the lunch hour, uh, I appreciate you being here. Um, My name is Vasha, uh, Joshua already introduced me. I, um, I'm the director for machine learning and AI at Coinbase, and today, um, I'm excited to share how we're leveraging generative AI to elevate both our customer experience and our, um, internal productivity. Um, so, let's start with the bigger picture. Coinbase, Coinbase is a crypto exchange, but what is crypto and why does it matter? Right, um, so crypto empowers economic freedom. It ensures, uh, fair participation in a global economy. Uh, at Coinbase, our mission is to expand economic freedom to over a billion people. We do this by providing a secure and trusted platform for both individuals and institutions to trade and transact crypto assets uh and do so safely and globally. To truly deliver on this mission, um, we have to concentrate on three key pillars. So first is, we build trust, and that means, uh, we need to safeguard our users' assets with top tier security, um, and put in place strong protections against things like fraud and account takeovers. Second is making crypto accessible. Um, we do this by designing experiences that are intuitive and personalized with the power of AI and machine learning, um, and we simplify what can otherwise be very complicated financial products. The third is scaling globally, so we operate efficiently and move quickly, supporting millions of users across 100+ countries, and we manage billions of dollars in trading volume. So these pillars are really the foundation of everything that we do. So at Coinbase, AI and machine learning aren't just buzzwords. We, um, they're, they're, they're really fundamental to how we operate our platform. Let's take a look at how, right? And, uh, let's play, just play along with me. This is about the user's journey on the platform. So let's say the user comes in and they want to log in. Um, so at the point of login, ML models are at play and they defend against, uh, account takeovers. So one use. The second is, let's say now the user's logged in and now they want to move some fiat currency into the crypto exchange. Once again, ML models evaluate the legitimacy of the user and the risk of any credit defaults. The third is, uh, now let's say the user wants to move some funds from the centralized exchange onto the blockchain. Once again, ML models are at play, and, uh, they, they play a pivotal role, uh, to assess risks of any reversals or, uh, before the, the funds are released onto the blockchain. So that was about safety and security, but that's not all, right? So we use ML to personalize every part of the user experience. We do this through personalized search results, uh, tailored news feeds, um, we've got intuitive recommendations, real-time price alerts, you name it, right? Now, all of these ML, uh, powered experiences, uh, whether it's for security or for personalization, these, all of these use advanced deep learning models. And, uh, these models are trained on massive data sets. The training and the inference for these run on a platform called AnyScale. Uh, I, I presume many of you have heard about it. It is a cloud platform, uh, that is based on an open source framework called Ray, and we operate any, uh, any scale on an AWS EKS cluster. Now, having talked about some of these traditional uses of machine learning for um safety and personalization, now let's talk about some of the, um, what is at the intersection of blockchain and AI. Let's talk about some of the innovative work that we've done in this space. So the first one I'd like to draw your attention to is, uh, we've built an adaptive and highly scalable risk scoring system for blockchain addresses. These are based on, uh, graph neural networks. Uh, this is a powerful tool and has been instrumental in detecting and blocking malicious blockchain addresses and therefore they protect our customers, uh, from transacting with these malicious ones. Another exciting innovation is ERC20 scam token detection, um. Once again, this brings together two technologies. One is smart contract auditing, and the other is machine learning. So this solution helps us review assets before they are listed on an exchange, and therefore it provides our customers more protection. And the third one here is, um, is a predictive machine learning model. So, you know, all of us know about the volatility of crypto. I mean, how many of you are investors in crypto? Share fans, yeah. OK. Cool. Um, so, So we all know about how volatile the crypto market can be, but in the scheme of this volatility, we still want to run a very reliable infrastructure, and to do this, we have these predictive models. They allow us to scale our backend databases before a surge can occur. So, altogether, these innovations are a great example of how we are using machine learning actively to shape the crypto landscape. All right, so, now, uh, let's shift gears, right? So we've talked about all of these traditional usages and including some innovations and whatnot, but now let's talk about a new generation of AI investments that we've been doing lately. No surprise, LLMs, right? So, LLMs as we know it have transformed the landscape ever since November of 2022. I think it's like, uh, you know, it's, it's a historic moment. All of us talk about pre and post chat GPT era. Um. So, there are 3 key areas that I'd like to talk to you about where we are applying generative AI. Um, so, The first of them is about customer support. So we leverage AI powered virtual assistants, and we also build advanced tools to support our human agents, and together, uh, these two capabilities enable smarter and more scalable customer interactions. The second that I would like to talk to you about is about compliance. So JenEI is helping us streamline complex investigations and navigate the regulatory landscape. The third is, um, how can we not talk about developer productivity? Uh, I mean, all technologists in the room, I presume. Um, so, uh, yes, so I will touch upon how we're, uh, improving developer productivity, uh, at Coinbase. So, let's dive a little deeper into each one of these, starting with, uh, GEI transforming, um, customer support at Coinbase. All right, so let's take a moment to understand the unique challenges of delivering exceptional customer support in the world of crypto. OK. The first is crypto is incredibly volatile. We just talked about it, right? User activity can swing up and down by a good 50% within a month even. Um, so this kind of unpredictability puts a lot of pressure on our support systems. We simply cannot scale human support quickly enough to match uh these rapidly expanding uh user base. The second is trust. Trust is everything, right? Our customers need to feel safe and supported, no matter what's happening in the market. The third is we operate globally, so this means we have to support users across different languages and regulations and expectations requiring solutions that are flexible and adaptable. This is where Gen AI enters the arena, right? So Gen AI helps us overcome these challenges and deliver great customer support, no matter the market conditions. Alright, so, we've crafted a strategy, so I'm gonna get into the technicalities at this point a little bit. So, we've crafted a strategy that focuses both on the breadth and the depth. OK, so these are important aspects. So on the breadth, what we do is that we have an internal G AI platform that integrates multiple LLMs. And also taps into a wide range of data sources, and uh all of these access points are through standard interfaces. So we use uh OpenAIs API standards when accessing LLMs, and we also use Model context Protocol or MCP standards when accessing any of our data endpoints. So this Gen AI platform allows every team at Coinbase uh to easily leverage and extend our AI capabilities for their use cases. When it comes to the depth, we are making targeted investments in a few um high impact areas within customer support. The first is we are automating the customer facing workflows with conversational chatbots. The second is we're providing our human support agents with intelligent tools to improve their effectiveness. And the third one is we also use GEI to extract valuable insights from support tickets to help us continually improve our products and services. So, actually, these use cases that I just talked about, um, they form sort of a, a cycle, a continuum. So let's look at how, right? First, the customer comes in, the customer requires some kind of help. They first interface with the AI powered chatbot and get instant assistance if possible. For the more complex cases, they get escalated to a human agent, and then the human agents are equipped with real-time AI assistive tools. One more use of AI and then the next, if, you know, post-contact AI extracts all sorts of patterns so that we glean insights and we're able to improve our products. Lastly, once the product updates, we reduce the need for support, and we also create more knowledge to be able to automate the support. So it's this whole cycle with a feedback that works together. Alright, so now let's deep into every one of these use cases. So, um, we'll start with the customer support chatbot. Chat has quickly become the go to support channel for more than 50% of our customers. So trained on Coinbase's extensive knowledge base, our AI powered chatbot is able to Provide, uh, instant accurate assistance around the clock adapting to any kind of market volatility, right? So, um, Let's, let's look at the, you know, the, the layers in which, uh, uh, uh, the way we built the, the chatbot, we built it, uh, sort of iteratively. So, We started very simple. The first layer that you see highlighted over here, it's, it's a very simple FAQ style rag responses layer, right? And uh, so we started simple, uh, so that we allowed ourselves, uh, to focus on accuracy and build a strong foundation for more capabilities that we wanted to add in the chatbot. So now these simple queries, uh, such as, you know, sign in, how do, if users have a problem with sign in or two-factor auth or any other how-to questions, this layer is able to automate that. Let's look at the agentic architecture that sort of underpins this, right? So, um, as shown in the picture, we start with the user input and any other prior conversation history that is stored. Um, we stored it in a vector database and that serves as the memory layer for us. Um, the rat retriever is the fulcrum of this design. So it uses bedrock knowledge bases, where we vectorize and store all of the Coinbase uh help articles, and then we, uh, also use coheres, uh, re-rank models to get, uh, high accuracy from the retrieved rag articles. We also, uh, the other important component over here is, um, the, the response generation. This is sort of a mixture of LLMs, including the cloud models that are served through Bedrock to generate a very precise response. This response generation is an important step, and it actually involves a sub-agent, uh, developed in an, in an actor critic architecture. Then come the guard rails, right? You can see 22, gatekeepers over here. You have input guardrails and you've also got output guardrails. Um, these guard rails are powered with bedrock guardrails, actually. Uh, bedrock, uh, helps protect us against harmful content and leakage of any sensitive PII. Additionally, we also have some custom domain-specific filters that participate in the input and output guard rails. These help us minimize any chances of prompt injection. And you know, we also have some custom rules which help keep our responses grounded and reduce the propensity for any hallucination. All right, so we looked at the first layer. Now, let's look at the next layer that get, uh, gets added to it. So, you know, as, as things moved on, I mean, all, all of what I'm speaking about, you know, rewind time back to, uh, about 18 to 24 months ago, you know, that's when we started. And as we were building the chatbot and launching into production, we also saw a lot of movement in the industry and the capabilities of the LLMs. So we definitely knew that we could achieve more out of the chatbot than just that rag layer that we had introduced. And so that's where this next layer comes in. So, as these model capabilities got better, we enhanced our chatbot to directly follow what are called business procedures. Alright, so, uh, from conversationally collecting information to actually taking direct actions on behalf of the user, this second layer, which autonomously operates on business procedures, it achieves all of that. Um, now the best part here is these business procedures form what we call a single source of truth. This is very powerful. Just think about it, you've got these business procedures that both humans and AI agents use alike, so it becomes a single source of truth, and this is indeed exceptionally powerful, and it gives us a lot of adaptability to how we train both our humans and AI systems. So queries about the user's account or specific queries about a transaction that may have been pending, uh, all of these, uh, get automated through the second layer now. Right, now, looking at the same agentic architecture that I was showing you earlier, now this is a this is a little expanded, it has added these business procedure capabilities. We introduced what we call the Business Procedure Classifier. So, this is an important component that allows a query to be routed to the correct sub-agent. So as you can see, there is a sub-agent that is emulating every business procedure in our system. Right? And this is a router, the, the business classifier, business procedure classifier. Um, Next, the, you can also see that the rag agent that we saw earlier, it's, um, it's actually one of the specialized sub-agents, uh, it's just executing a specialized procedure which has, which involves looking up the, the rag knowledge base. Alright, so, now let's talk about the 3rd and the last layer that we added. This is the capability to, um, to actually do proactive issue resolution. So by tapping into things like the user's signals and active incidents that may be happening in, in the platform, uh, our AI agents are now able to anticipate common problems that users might be facing even before they need to ask us explicitly, hence the term proactive resolution. So, we've powered our, um, chatbot with this capability, and you can see that layer also augmented in this, uh, in this agentic design over here. Uh, the proactive issue resolution layer is another react agent, and, uh, if the bot is not able to find a proactive resolution to the, to, uh, uh, for the, uh, for the user, then it does fall back to the business procedure classifier layer that I mentioned earlier. And as you'd expect, the proactive agent is also powered uh for all of its data access through standardized MCP servers. Alright, so, uh, you've seen the iterative design that I talked about. Now there are a few factors that were very central, we held it very, uh, important as we chose, uh, made all of our design decisions. The model selection is a key aspect of it, OK. So, uh, model selection wasn't just about finding the most accurate model that works. We needed to, uh, we needed a solution that struck the right balance between accuracy, latency, scalability, um, and all of that, right? And it also wasn't a one-time decision. We realized that as the model capabilities were growing, we needed to reevaluate these choices time and again. So that was a pretty central aspect to how we decided to operate on things. The next is the tool standardization part. I did talk about this, so we specifically chose to standardize all of our tools access through MCPs or Model context protocol, and it gave us a really strong foundation, not just for customer support, but for many other domains that we were operating in, in fact. Um, we also focused on business adaptability, um, like I, I was mentioning about the single source of truth, the single, uh, source of truth of business procedures that was able to power both humans and AI, so that gave us the business adaptability that we wanted. And above all, we also made sure that the bot's responses were grounded. So the factual correctness of what the bot was saying was a, uh, was an important factor. So all of these were important principles that we always kept in mind as we were building the solution out. Now We've, we've seen all of these careful considerations, but despite all of this, it is paramount that we are able to observe and monitor how our chatbot is performing in production. So to make sure we're consistently delivering high quality responses, we made sure, uh, that we were, we were, uh, using LLM as a judge evaluations. So every chatbot response is assessed for things like relevancy, accuracy, potential bias, uh, hallucinations, and more. We actively track all of these quality metrics and monitor trends, and that allows us to quickly spot any anomalies and step in as needed. All right. Now, having talked a lot about the chatbot, let's look at one other use case that I had mentioned earlier. This is called agent assist. So what you're looking at over here, um, is a picture of uh our AI powered agent assist tool, which is designed to help our uh human customer support agents. So as you can see, the middle pane. Is that of the human chatting with the customer. Um, And on the right side is where you see this agent assist tool, and it provides suggestions to the human agent to respond to the customer. So as we've established, it's the complex issues that actually come to the. Human agent, so the human agent is actually dealing with a stressful, highly complex situation, and in that environment, the agent assist tool provides real-time assistance to diagnose the customer's issue and also mitigate it. It draws, of course, the agent assist tool also draws from account signals, ongoing incident data, past customer support, um, uh, tickets, and so on. So agent Assist provides personalized guidance and, uh, it generates very precise responses in many different languages. That's another important aspect, because as we talked, you know, Coinbase serves customers across 100+ geographies, world, uh, globally. So this is an important aspect that Agent Assist provides. So obviously, the end result of all of this is faster resolutions, happier customers, and great efficiency across the board for our support teams. Let's draw some attention to the actual numbers here, right? So what were the, what, what did the impact look like? It's pretty impressive actually. So today, close to 65% of our customer contacts are handled automatically by our AI systems. That's a, that's a big number. This automation, consequently saves us nearly, nearly 5 million employee hours every year. It's an annualized number. Which is significant cost savings to the business, right, and, and productivity boost as well. Most importantly, this 65% automated cases are now resolved in a single interaction. Now this is a very important aspect, right? So, um, you know, when cases are handled by automation, they get resolved in less than 10 minutes. But when cases go to a human agent, they can be long drawn. It can take up to 40 minutes. So, these systems, as much as they are a product productivity boost, they actually enhance the user experience substantially. So that's an important takeaway. Right, so these results are showing us how powerful AI can be when it's operating at scale and the difference that it, that it is making both to the business and to the customers. All right, so we've talked a lot about customer support. Now let's, uh, move on to another sphere, right, uh, compliance. Super important uh for a fintech entity like Coinbase. So let's look, uh, how it works, right? So, when it comes to compliance, you've probably heard about terms such as AML, anti-money laundering, CFT stands for counter financing of terrorism, ABC stands for anti-bribery and corruption. Now, as a regulations aiding financial entity, Coinbase as a company is committed to upholding the highest standards of these practices, and you do not want, uh, anybody using the platform for any such malpractices. Um, so in order to implement, um, in order to, uh, uphold these, uh, we implement several processes such as KYC stands for Know Your Customer, KYB stands for Know your Business, uh, TMS stands for Transaction monitoring Systems. Um, so all of these processes, while they are super important, they are a very heavy lift for the company and highly human intensive. And to top that, of course, we have the market volatility that we've been talking about, right, which means that you know the human workforce scaling them is not easy. The second is the regulatory bodies expect a very thorough investigation of all of these compliance cases. And they, they need absolute detailed, full explainability of all the cases that we, that go through our system. So that is a very important aspect, uh, to keep in mind. And then the third one is because we operate in so many different countries, um. We have to adapt our compliance processes to meet those diverse regulatory requirements across the board, so one size definitely does not fit all in this case. Right. So, once again, what was our strategy? Um, we, we look at the breadth and then we look at the depth, right? I, I, I talked about this earlier. So on the breadth, we leverage the same internal GEEI platform that I mentioned earlier. So the GENEI platform gives you fluid access to LLMs and the data through MCP interfaces. Then the second, um, uh, but there is something that is a little different about, uh, compliance and compared, uh, compared to customer support, which is compliance solution also entails a traditional machine learning model. OK. This model is, uh, detects high-risk compliance cases. Um, so for these, we rely on, uh, once again, you know, I had talked about any scale, which is based on the Ra framework. So we use our any scale-based ML platform to build these, uh, traditional machine learning models that detect the high risk, um, uh, compliance cases for us. On the depth aspect, with compliance, we built, um, several different solutions, right? Um, so we've made some intentional investments, uh, for example, we've built these advanced deep learning models that are able to detect high risk cases in multiple different compliance processes, including KYC, KYB, and TMS. Uh, I talked about these earlier. Um, Beyond the detection, we also use AI to automate and accelerate complex investigations. We, uh, these investigations involve gathering and synthesizing data from a variety of different sources, and we apply, uh, these rigorous approaches, uh, of investigations across all of these compliance workflows like KYC, KYBTMS, and so on. All right. So what you see over here is a screenshot of another tool, um, called the Compliance Assist tool. So, earlier, I showed you the, uh, the customer support agent assist tool. This is sort of analogous, but this is for the compliance agents. This is an assistive tool. So you can see that once again this is AI powered and the AI system actually has automatically gathered and synthesized information from a wide range of different sources. It has pulled data from our internal systems as well as open source intelligence. Um, the AI then composes a narrative summary, uh, and it and it also gathers a set of clear risk review signals. Our compliance agents, the human agents, are now handed a fully documented, explainable investigation that equips them to make well-informed decisions quickly and with a lot of confidence. So this is a great example of where AI is empowering our teams, and it's also elevating the standards of our compliance operations. So, this is a quick walkthrough of the block diagram that sort of illustrates the agentic architecture that we follow. Uh, so starting on the left, our process begins where the compliance risk models that I talked about earlier, these are the deep learning models, when they trigger alerts on high risk cases. So that's where it all begins, and this initiates what's called a holistic review. A holistic review is a comprehensive investigation of a high risk compliance case. So at the center of this solution is our compliance auto resolution engine, or CAR for short, which acts as the orchestrator for the entire holistic review process. This is where the agentic AI driven workflow comes into play. It mobilizes both automation and human expertise. We'll look at it in just a moment. So the orchestration engine coordinates human in the loop process, interacting with two different human personas. The first is our own compliance operations agents. They review the findings of this AI system and they provide essential feedback to keep improving it. And then the second is wherever necessary, the system also reaches out to our end customers for additional information through RFIs or requests for information. So throughout this process, the engine also aggregates and synthesizes data from a wide variety of sources. We talked about this internal, external, open source intelligence, all of it, and all of this access is through standardized MCP 5 data connectors. The end result is uh a robust AI generated report which we call the narrative summary. Um, now, it is important to note that the final decision always rests with our human compliance operations agent. After reviewing the AI's reasoning and all of the compliance evidence that the AI system has gathered, it is this individual, the human individual here, who determines whether a case warrants filing what's called a. or suspicious activity report that needs to be filed with the government authorities because the company is liable to that. I mean, we are, we are responsible for reporting it to the government should a particular high risk case be proven so. This approach brings together the best of both worlds, the speed and the depth of AI combined with human oversight. All right. OK. All right, so we've talked about customer support, we've talked about compliance. Now, how can we not talk about developer productivity, right? Um, we'd be doing disservice. All right, so this is a hot favorite. Um, let's, let's talk about how we're making a real difference. OK. So, let's talk about how AI is radically transforming our software development life cycle, or SDLC at Coinbase, right? So today, uh, so today, as we know it, AI agents help our engineering teams. At different stages, right, it helps consolidate tasks like coding, ticketing, documenting, you know, pull request, pull request creation, reviewing those pull requests, and more. So in short, what we really have is an AI powered SDLC that's accelerating productivity across the board. So, today I will specifically talk about 3 aspects of this whole SDLC process. I'll talk about code-authoring, code reviewing, and quality assurance. OK, so let's talk about codeauing. The visual that you see is probably very familiar to many of you. This is that, uh, this is, uh, cloud code. It's a state of the art coding assistant, and it integrates directly into your IDE or it can also be used from the command line. Developers love it. Uh, coin-based developers definitely love it. This other visual is that of cursor, yet another intelligent, context-aware IDE. Again, it is designed to make software development faster, more collaborative, and more efficient. So, as most of you would concur with me, developers are a passionate lot, and they're an opinionated lot, right? So that is why what we do at Coinbase is we offer a few of these best in class coding tools as paved paths, options to our developers, and um our engineers have the freedom to choose whatever works best for them. So, um, all of these tools, of course, are powered with anthropic models that are served through bedrock. Now, so we've talked about code-authoring. Now the next step in the development process is pull request and code reviewing, right? So the tool that you see over here is a homegrown tool, OK, it is adapted from an open source, uh, tool, and it's enhanced with cloud models from Bedrock. This agent is implemented as an AI powered GitHub action. It integrates, uh, it automates PR reviews, basically. So it summarizes the pull request and the underlying code changes that have happened. So how many, how many times, you know, as a developer, you're, you're, you're given this PR review, it, it has several tens of files of changes, and we don't know what. What is the context, you know, not, not all developers are very diligent about explaining, you know, what is the change, why have they made that change, etc. Now, uh, tools like these actually automatically summarize that change for you, and that's very informative for the person trying to review it. Right? Uh, so they summarize it, then, uh, they also generate clear natural language review comments wherever it is applicable, just like a senior engineer would. Um, beyond that, uh, this tool also enforces coding conventions. Right? That's an important aspect. So many times, you know, human reviewers, all they're doing is just explaining to a newbie developer, what are the coding conventions, how must they write the code better for, uh, for better maintainability, and so on. Right? So it highlights any gaps, um, in unit testing coverage. That is another important aspect, right? And, um, um, an icing on the cake, if there is any CI failure, uh, if there are any, uh, failures in the continuous integration system, then it also provides some useful tips on how to debug that. Right? So, very powerful tool, we've seen great yields from it. I'll talk about the numbers in just a bit. Now, that doesn't mean that, you know, developers don't have to, uh, review the code manually. It's just, it, uh what we do over here is that all of these run of the mill aspects of reviewing the code are taken care of by this automated system, AI powered automated system, and, uh, so that the human developers only look for the nuanced aspects of the code and so they can deliver higher value. OK, Next, talking about quality assurance, right? So coding assistants like Clod code and cursor, they already allow you to automate unit test generation, so we know that. But we are taking things a step further, right? So the visual that you see here is another homegrown AI powered tool for automated UI testing, right? This tool brings end to end quality assurance, uh, automation for our web and mobile UI. It converts a natural language test description directly into autonomous browser actions. This is very powerful, right, if you'd imagine, uh, it allows us to test the UI like a human would. Right, the browser actions are then performed in a variety of different form factors. Like we use services like browser stack that give us access to different form factors where we can test these browser actions, and the browser actions are also emulated through frameworks like Playwright and whatnot. Right, but this brings us incredible scale and agility to UI testing. And even better, right, when issues are actually found, this system captures screenshots and generates structured reports, making it easy for our development teams to go address those bugs and problems. Right. So, Once again, let's talk about the impact. What do the numbers say, right? Um, so developer productivity is showing a lot of green shoots, and uh we are fairly confident that this will continue to keep growing, right? So today, nearly 40% of all code written daily at Coinbase is AI generated or AI influenced, I should say. So our goal is to surpass 50% pretty soon. Of course we do understand that every line of code still needs to be reviewed and understood by a human developer, and we know that AI generated code isn't suitable for every part of the business. Nonetheless, wherever it makes sense, we do want our teams to harness the superpower responsibly and as often as possible. All right. Next, our investment in the PR reviewer that I showed earlier, uh, that's also paying off. So we estimate saving about 75,000 hours, uh, annually through these automated PR reviews. And not just that, it's also raising the bar, raising the code quality overall by enforcing coding conventions and whatnot. Next is um quality assurance. Now this one is particularly impressive. It's achieving accuracy on par with our human testers. It's also able to detect 3 times as many bugs as a human would in the same amount of time. And it is also dramatically speeding up the process of introducing new tests, sometimes as little as 15 minutes. Imagine, you know, uh, you know, how does that compare with the hours that you need to train a human tester to test some UI. Oops. And, uh, you know, when you look at the cost efficiency, we are seeing, uh, about 86% cost reductions compared to traditional manual testing. So All in all, like great results, uh, we're really stoked about it and we're looking to go places with it. Now, having talked about these three dominant domains, our investments, our impact, what we are seeing from it, etc. let's talk about what's next for uh at Coinbase, right? So, through all of these use cases that I've shared today, um, uh, we can see that we are unlocking a lot of power, but truly our mission is to put AI agents, the ability to build agents, the ability to get hands-on with it, uh, in the hands of every employee, right? And, um, and we truly believe we have a, uh, we have many a mile to go towards that. Um, so we want to, uh, empower both individuals and teams to create. Experiment, innovate, um, and not only bring benefits in terms of everyday productivity, but also reimagine how we offer our products to our customers. Right, so as we look into the future, our focus is now on scaling these capabilities for even bigger enterprise-wide impact. We are working to modernize and upgrade many of the tools and technologies that we've developed over the past two years. So, no, this is sort of ironical, right? Like, I mean, all of us have talked about software that has been built, you know, there are some sessions that I've seen about, um, about upgrades from .NET to a new framework, etc. I mean, these are systems that we're talking about that have lasted a decade, but now we're talking about. Modernizing what has been built in the last couple of years, but that's, that's the nature of this landscape, right? Like AI is moving at breakneck speed. So yes, we do need to keep thinking about how we're going to modernize these AI systems and keep up with the innovation in the industry. So, that's where platforms like, uh, Bedrock Agent Core truly come in, and we're really excited about, uh, using Agent Core, uh, for, for this next wave of expansion in our, um, AI investments. So for secure, uh, we have talked about Agent Core in many different regards. Uh, one is, of course, The secure agent deployment, the robust identity and authentication management that it offers across both agents as well as MCP tools, features like powerful memory, advanced interoperability, all of these are very, very exciting for us, and they really hold many, many possibilities. Alright, so summing it up, once again, our goal is to democratize AI across Coinbase so that every employee at Coinbase can leverage this technology and solve problems and create value for our customers and keep us at the forefront of our industry. Thank you so much. Thank you for listening.