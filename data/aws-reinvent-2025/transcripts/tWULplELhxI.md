---
video_id: tWULplELhxI
video_url: https://www.youtube.com/watch?v=tWULplELhxI
is_generated: False
is_translatable: True
---

Thank you for joining us for session SPS 318. My name is Rahul Singler, and I'm thrilled to have be here with my colleagues, Joe and Jason, to share an exciting story about innovation at the intersection of operational excellence and generative AI. I'm a senior enterprise support manager supporting global financial services customers, and today we are going to share a story about how Fidelity took a foundational operational challenge, managing enterprise scale volume of AWS health events and support case data and transformed it into strategic operational advantage. And then we'll share our thinking in applying G AI to evolve such a solution to the next step. So let me first start by con con uh setting the context for why this matters. Organizations face a fundamental challenge of growing complexities, and your enterprise environment has large volumes of accounts, resources, and events. And in this environment, reactive monitoring simply doesn't cut it. You can't wait for something to break and then scramble to fix it. You need proactive actions, the ability to identify potential issues before they impact customers, to understand patterns across your entire infrastructure, and to take preventive measures. Studies shows organizations that have comprehensive data monitoring detect incidents 3.5 times faster than those without. And that's not a marginal improvement, that's transformative. In financial services industries, every minute of downtime can mean millions of dollars in lost revenue and damage customer trust. And here's the key insight that drives everything we are going to talk about today. Different data domains, when combined together, build a holistic picture. AWS health events tell you service issues and scheduled maintenance. Support cases reveals recurring problems and their resolutions. And when you bring them together, you can correlate a spike in support cases with a health event. Or connect a configuration change to performance degradation. That's when you achieve the true operational intelligence, and that's what we mean by holistical technical hygiene. All right, let me quickly walk you through our agenda for today's session, which follows Fidelity's journey chronologically and builds on from foundation to innovation. First, we will explore AWS health and support data. Second, we'll dive deep into Fidelity's cloud event notification transport service, also called as SES. This is the data pipeline and notification platform that Fidelity built to ingest, enrich, route, and act on AWS health and support data at scale. Third, this is where it gets really exciting. We have published GAI patents that we can apply on top of systems such as sense. Finally, we'll wrap up the conclusion and key takeaways. So we'll go into the AWS health and support data. So AWS Health. So let's talk about the foundational data source that powers everything. AWS Health is your window into the operational status of AWS services and how they affect your specific resources. It provides 3 main categories of information, and understanding these categories is crucial. First is operational issues. These are service disrupt disruptions or degradations that are actively affecting your AWS resources. Second are schedule changes. As you are all aware, AWS is constantly improving its infrastructure, which means planned maintenance, hardware refreshes, and service updates. And AWS Health gives you advance notice of these changes, so you can plan accordingly. Third is account notifications, and these are very important account specific alerts that don't fit into any other category and things like billing alert, security findings, or service limit warnings, and they are very specific and tailored to your AWS account's configuration and usage patterns. Then is AWS support. As you all may be aware, AWS Support provides technical support and guidance for AWS customers with specific AWS domain expertise. And the data generated by support cases can lead to invaluable insights and delivers measurable business value while providing organizations with actionable insights from their support interaction to drive continuous improvement. Let's talk about some of the goals here which are clear, progressive, that build upon each other. Goal number 1 is ingesting AWS health events. In the enterprise. We could be dealing with thousands of AWS accounts, and each of these AWS accounts generates its own stream of health events. Then the goal number 2 is ingest AWS support cases data. And support cases contains incredibly valuable information. They document problems, solutions, workarounds, and lessons learned. But the data is mostly unstructured conversation between yourself and the support engineering. Goal number 4 is at scale, ingestion and routing. And now we are moving beyond collecting data to actually doing something intelligent with it. Different events need to go to the respective stakeholders. Goal number 4 is data-driven operations. And this is the ultimate objective transforming from reactive firefighting to proactive intelligent operations. It means using the data you're collecting to identifying patterns, predict issues, automate response, and continuously improve. And The data is what drives this, as I just mentioned, AWS health data, support data. And we have a lot of data across health and support. And basically lots and lots of data. You can literally drown in all of this data. How can we properly ingest this data at an enterprise scale? Well, please allow me to introduce you to Jason Casamiro, who solved this problem at Fidelity Investment. Thank you. All right, Jason And you drove. So. Hello everyone. So my name is Jason Casamaro. I work at Fidelity Investments and I'm a vice president of cloud engineering. It's a little bit about myself. I work within a group within the enterprise technology group that is really focused on cloud enablement and standardization practices. So as you go to the cloud and scale, you know, obviously you want things to be consistent, secure. The only way to do that is to really have a group focused on how those workloads are managed, deployed, observed, and my group sort of sits in that space. I lead a team of talented engineers who are really focused on a single problem today and we're gonna talk about it, the challenge that everyone has as you go to the cloud, you lose control. So when you go out to the cloud and you increase your surface area for failure. There's a lot more things that happen and as people get a taste of the cloud they start to grow because it's easy, right? So you expose that to your engineers and they start to go at an accelerated pace and what happens after that you start to get data as Raul said you get a ton of data. So a little bit of fidelity, a background. So back when Fidelity started in 1946, we were a simple financial humble financial institution managing one fund. What happened after that? We were lucky enough that our founders were tech junkies at the end of the day, right? When it boils down to it, they were fascinated with technology and how could it improve their business because that was the key focus. How could we get our business to differentiate itself leveraging technology. Back when hardware was introduced, computers, those came in that was a factor. More importantly, we had our first mutual fund website, right? We were one of the first to do that when the Internet happened, we saw that as a potential opportunity to differentiate our business and how technology would help our. Customers have a great experience. The same thing applied when we came to cloud. When we saw cloud and we saw how innovative the accelerated pace of delivery, Fidelity jumped in. So back in 2016 we deployed our first app to the cloud. And then oh there we go and then we kept going. So in 2019 we decided really to accelerate our sort of cloud journey. And we started to move to other clouds, right, so not a single cloud but multiple, so that introduced a number of challenges as Raul described again, more data. You increase your data ingestion, more clouds, another cloud, different types of data, things that we have to think about today. We look at about almost probably it's north of 8500 apps at this point, um. Across our entire portfolio across many clouds, right, so not just one. So flashback to 2019, we're still young, we still hadn't really figured things out. Modest part of our portfolio in the cloud 12%, about 500+ accounts in in AWS, about 200,000 resources, so still a significant amount, but nowhere near where we were gonna be and how we were gonna mature. But there are still challenges we had to sort of think about again with every resource you deploy there are things that happen. There are services depends on. There are all sorts of things that go out into the cloud that we just didn't, we didn't have frameworks in place previously to understand, and we had to sort of think about it quickly. Luckily we had a partner. And AWS AWS was a great partner and AWS Health specifically was a service that we relied on. So at an organizational level in our organizational account structure we had lots of accounts admitting things and so what we really tried to focus on was a consistent way that we could get things out and really AWS Health supplied that back in 2019. So clearly it's not the robust AWS health capabilities that you know today, but ultimately it provided a good sound foundation for us to build upon. And we knew just like the cloud they were innovating and accelerating pace of delivery at an exponential level that we couldn't think about keeping up with, so it was a great partner to have in our sort of in our back pocket. The AWS Health API specifically allowed us to programmatically sort of interface with accounts and extract data that we needed and you really think about how we might process that data in a different way and push those out to our stakeholders. So our first go at it back in 2019, keep it simple, right? There's a lot of system architects probably out there that are thinking, you know, when you get to scale, that's when simplicity matters because any complex sort of architecture at scale is brittle. It'll break down and anyone who tells you otherwise has never run anything at scale, um, so we were simple in the initial sort of go. Simple reach into an account, pull mechanism on a time-based basis. We go out there, we get our events that we care about. We get our support cases. We aggregate them back into a central hub, and we process them. Simple, clean, just get it out there. And again, we were really focused on rapid delivery. Because we are a company that focuses on get things into the hands of the developers as fast as we can and then iterate, we don't wanna sort of analysis paralysis ourselves out there. And so this is where we came. So we started to ingest and then we sent simple things, email, right? You get an email and I don't know about everyone else, but I get lots of emails. So this got old fast, real fast, um, but we, we persevered, right? So we kept going. As we start to grow So we're getting a little bit better, a little bit bigger, we're 9 years in the cloud now. We got about 80% of our apps in the cloud, almost 2000 accounts, almost 5 million resources. Over 100, almost 150,000 events aggregated in the last two years just from AWS. Again, these are AWS numbers, but we are a multi-cloud implementation, so we aggregate across multiple clouds and then we have an extension that we're potentially gonna go on-prem with too, right? So we're trying to aggregate consistent data into a place. So again, you'll hear a lot about AI and agents and all the things that you're gonna sort of change the world with here at and reinvent, but ultimately it starts with a foundation of data. If you can't get that consistent and clean. None of these fancy tools that we have out here are gonna do anything for you. And so we thought, how do we sort of think about this now? We have a scale problem. We didn't have a scale problem back in 2019, now we have a scale problem. Luckily our partner had come along with us, so AWS Health had matured as well, and we knew that was happening and that was great. One of the key things that they introduced was a few pieces for us specifically. Was a delegated administrative account, so a single account that essentially at an organizational level can aggregate all your events. That was a huge win for us just because when you start thinking about 2000 accounts and sort of seeding things into every one of those accounts, it gets dicey fast. Having a single place where all of those things are easily, uh, easily aggregated, that was a huge win. The other piece was event bridge, the native integration to services inside of AWS. I can't speak enough to how easy and seamless these things are, but ultimately everyone knows that's here. EventBridge was a huge win for us. When you start thinking about the integrations as well, right? So they start to think about how do we get these events and things of note to places that people care about. That's where all these third party innovations came in, and I think that's a huge win for as well. So whether you do them natively or you do them inside of your own custom delivery mechanism based on your ecosystem, that's a huge win on how you integrate and sort of deliver events. So we had to rethink sort of what we did. Based on some of the ways that sort of events, I mean, uh, AWS Health evolved, that allowed us to rethink sort of our processing logic rather than that pull antiquated pull mechanism, wake up cron base type stuff, right, everyone had that crontab that they lose focus and lose all over the place and all the servers they sort of placed them on. We started to think about an event driven system. One, based on the amount of resources we had out there in the real time that we wanted our users to react and understand what was happening, it made a lot more sense. The integration with Eventbridge was a huge piece. So a single event bridge role, AD AWS.health in your organizational delegated administrative account, aggregates 2000 accounts worth of events, right? And then it's just a, a hose of information that you have to process. So for us we introduce it to essentially an enrichment stage so we look at it and say, hey, this raw vent is great, but a lot of our fidelity engineers need more so we need context. So how do we sort of pull more metadata dependencies upstream, downstream, anything we can get so that they can get a little bit more action and understanding associated to the event that they just got, right? We're, we wanna get past that noisy email that just ends up in that folder called trash on the other side that nobody pays attention to. 20, I know exactly what I have to do or my team knows exactly what they have to do, and that was a huge win in the enrichment stage. Then we started to think about notification, right again back to the email part. We wanna meet people where they are. So that's a huge piece of today's society, right? They want the your phone is on you all the time. You wanna understand your user community wants their stuff the way they want it. So really sort of having a, a personalized preference on how I get engaged, that was a huge piece of our puzzle. Because ultimately anyone can send 10,000 emails a month, it's really do they get any action? Do they get any traction on the things that we care about? Because ultimately that's the most important part of it. So we thought, OK, how do we rearchitect our system? Part of it is we go from an event-based architecture, I mean from our pool-based architecture to this event-based architecture, so we start up in the corner, right? So right here is the, the, the core system. So in a single account, my single rule can aggregate all 2000 events, all 2000 accounts' worth of events. So we made a conscious choice to sort of send it out to an API and the reason behind that is again back to what we talked about we're a multi-cloud implementation to have a consistent pattern on how our events come into our system we wanted to make sure that everyone who came in and produced events sort of came in through the API. It also helped in our resiliency architecture, right? It was a quick and easy way to sort of pivot over in the event that the system that people rely on. Is available during the outages that they wanna know about, right? So those are the key pieces in our resiliency puzzle and why we made a conscious choice to use Route 53 at the top to be able to route our events in places. Once we go from there We come down right into event enrichment for health, and I'll specifically talk about the left side in a minute. So for health, what we do is essentially the event enrichment starts. So we talk about all those things that we pull off metadata, upstream, downstream dependencies. We send it off to our cash in our events table. It's just a dynamo big table really. That was a key core construct in ours. Our previous one had a little bit more RDS relational stuff. This one was straight big table, easy stuff. The other piece of this puzzle because of the netative integration. Was the ability to inject all of this information into an open search cluster so from start to finish, it's near real time to get an event into our system, process it and get it into an open search cluster that's available for our users to sort of search. And look back on events, look back on things in their systems that they care about. We were sick and tired of just did something happen and people had to answer the questions versus go to open search and fish. Teach your users how to fish because that's the only way you get out of this constant cycle of answering the phone. So that was a huge win for us and an additional capability to introduced in this system that natively was just easy to extend into. Then we get into the notification system, right? So again we talked about notification. Notification is a big piece of our system because we need to engage our users. It's not just about storing data. We need to make sure we provoke them and say, hey, something's happening or you need to think about something back to the initialization and integration. So we have some key core integrations that we talk about so everyone's gonna have their own internal systems on how you manage work, incident management, um, communicate from a communication platform perspective. You're gonna basically always have those internal tools we were able to integrate with ours again along with our default mechanism of delivery, which is our email stuff. That's a huge piece of our puzzle. When you talk about the support case side of the house. Not as easy so that's probably a challenge that a lot of you might also be tackling. AWS Health provided a single event page rule that was very easily integrated. Support case not as much. Luckily, as I had referred to, we work in a central sort of cloud group and as a part of that cloud cloud group's capabilities, we have a thing called the platform injection framework. Part of that platform injection framework is our focus on how we manage consistently our accounts. Allows us to do this at scale much more effectively. So with a single rule and a single cross account role in a package, our platform team now has the ability to deploy and manage that across the 1900 accounts for us. So I take advantage of an internal capability that makes my life 100 times easier, right? So I can deploy that to the fleet essentially. And now I start to aggregate all my support case data as well alongside my health data. So as a rule said, like this is the stuff that's important on how I sort of bring that data together in a single platform. So that we can now start to think about the next generation of processing when you look at sort of a resiliency like I said, there's a lot of things that are being released obviously at reinvent. The AWS Health just did this, I think last week or the week before, but ultimately now we have backups for local regional sort of events as well. So they had global backups as well, but now local regional events are also being back up to an alternate region. So now based on this framework again, everything should always evolve and increment. Nothing is set in stone. We'll start to increment towards that model as well. So localization essentially backup for all of our events so that in the event that USC one is having an issue, we can then start to go back, right, and figure out what alternate region do we need to deliver this from. So another piece of that puzzle that we talked about was our people data. So event data is great we can aggregate it, but as I said, really the power in the system is the engagement with our users and really we had that initial engagement with email but like everyone else said and everyone knows email stinks, right? That's a terrible way of engagement we had to come up with a better way and the only way to understand how to meet our people where they wanted to be met. Was with a system that sort of captured their preferences so we have a simple system that we sort of offer up to the enterprise that allow people to go in. And basically talk about what or log essentially their preferences on how they wanna get communicated to so their medium, their types, what things they care about and what sort of delivery channels we wanna get them to their stuff on so things like when you talk about I have a production account and that's what I care about when things happen there I want a team's message or I want a Slack channel message, whatever they are your tool of choice is. That's a different environment and a different sort of experience than I want for maybe a dev environment that has a deprecated run time that I need to think about and schedule sort of a change that's an email or maybe a a work item in my backlog sort of integration so those are the types of things that we started to think about because ultimately what this whole system is only valuable with with action, right? So I gotta be able to action into the specific things and make sure that I get my users to the place that they need to get to with the context and information. In the right time, right, so that's the key value of the system we went from a time-based poll system to now essentially an event-driven system that gets this in real time out to the users with actions that they care about. And providing the context is the most powerful part. So some of the wins, right, so things like cost, obviously financial firm, that's a big one for us, um, you go from a poll-based model that wakes up, executes a ton of step functions to essentially a single event driven system, we're reducing our cost by probably 57%, and then we're introducing more capabilities as well, right? So I already mentioned our sense platform search platform which is essentially our open search cluster. That's a huge piece, huge win for us, so we added a number of new capabilities and drove costs down at the same time. That was a big win. The other thing to talk about was stakeholder engagement. So when we initially started we would fire off I don't know, 20,000 emails a month, 30,000 emails a month, whatever the number was with limited traction, right? I didn't, I had no idea what things were getting done, which weren't. So unfortunately we still have a lot of email but we are narrowing it down now more to specifically targeted spaces right? so whether they're incidents that are raised service requests that are raised, you know, work log items that are logged, so that there's more action and tangible outcomes that we're expecting from our engagements versus just essentially off in the wild emails so that's a huge win for us too as we start to increment forward that's the things we'll talk about where we go. So we talked about goals originally we talked about a lot of ways that we ingest health support cases, but really the ingestion at scale and I can't stress enough. Nobody understands a scale problem until you have a scale problem, but ultimately the scaling routing piece and understanding how to manage that in an effective and consistent way at an enterprise level was a huge win for us as well. So we talked a lot about that. But again, a lot of this is foundational work. And so where do we wanna go? We talk about data driven operations. So obviously the whole conference, there's a lot of AI agent stuff, a lot of AI. We've built a foundational platform so we look at the maturity levels, you know, AWS does a good job of the maturity framework. We're now getting into a point we're gonna have action oriented stuff, right? So we are sort of understanding and scaling. But really we wanna get to the next so we wanna look at identifying trends, right? So there's a capability inside of our world now that we can look at all of the data items that we get and how do we sort of correlate events because that's the power, right? When you think about Fidelity at scale. 2000 accounts, I don't know, something like 15,000 technologists at any given moment someone on one corner of the globe specifically might be working an issue that already someone on the other side has already solved because they are understanding their elements sort of that are coming in a lot faster. That happened a lot when we were early on in the cloud, right? Calling another business unit and saying, hey, did you see what happened? Yeah, I already knew that and not really having that connection and the connective tissue that a lot of these data platforms provide. So that was a huge move forward and as we go, so you think about specific events, right? So guidance and sort of deprecating events. When you look at sort of things like last year was a good example where we had an RDS cert expiration across our environment and that had to drop dead August 22nd. It's ingrained in my head, right, because we sent a number of notices and because we were consistent at sort of getting that notice out into the right hands with for the right action to happen, we were able to sort of avoid any customer impact with any RDS cert renewal issues. That was a huge one for us and that can only get better as we start to leverage in intelligence and sort of automation as we start to remediate these events and then we start to get into aggregating understanding, augmenting operations. Augmenting operations is a big one, right? That's our next level of maturity. As we look at sort of augmenting operations and automating our resolutions, we have this capability and foundational data that now we need to sort of move into the next level of maturity. So how do we get there? So luckily again we have partners so Joe's gonna come and talk about applying Gen AI with Amazon Bedrock. Thank you, Joe. Oh, he's gone. All right, thank you, Jason. So You saw what Jason has built in Fidelity. Upon the data that Rahul mentioned. And you saw those future goals. And perhaps you have a similar system. How do we get there? Well, Ga. So we released recently in the ADBS samples, so that there is the GitHub link. A framework that we call machine augmented key insights or Maki for short. At a high level, it takes NDB support data and its health data, the two data domains that we've been discussing into Bedrock. For support cases, we take every single support case and we augment it with reference data. Case categories, for example. And then we send that augmented prompt into Bedrock. Those of you that are familiar with prompt engineering will recognize this as a standard prompt engineering practice. And in fact we're literally just taking the, the, the data documentation into the system prompt and calling the converse API in Bedrock. And by doing this we can achieve results like this. So this is a result of thousands of support cases passed through that pattern, and we're able to achieve this kind of identification of different categories of buckets. So this simple operation gives us that next step in Jason's goal. We're able to identify similar event trends. And also as we're passing data through bedrock, we do it in stages. In the middle you see the event level analysis, and then at the end we see the aggregate level analysis. And notice there we're using two different models for each of the stages for the event level analysis we use something like Amazon Nova Micro or perhaps Anthropic Cloud Haiku, something, uh, very lightweight and fast. And for the aggregate analysis we use something like Anthropic cloud sonnet or Opus, a more sophisticated, richer model. I think you're all familiar with the principle that you're here. Use the right tool for the right job. That applies to any infrastructure, including GAI infrastructure. And also as more and more GAA applications hit production, you have to think about resilience, right? Absolutely. So within the framework we demonstrate some GAA application patterns towards resilience, and this is one such pattern. So what's happening here is as events are coming in. If we have relatively few number of events, we send it to Amazon Bedrock on-demand Inference, and if we have a lot of events, we send it to batch. So let's walk to an actual example. So suppose you have a service event. Kind of like the one we had in October. In that case you'll probably have some support cases as well as health events coming into your system. Obviously those you want to analyze right away. And since it's streaming in, there aren't that many of them, so that you can set an on-demand inference. But a different use case, it's December, right? So many of you are doing end of the year analysis, kind of retrospect kind of work. Suppose you want to analyze all of your support cases and health events in the past year. A large organization, you may have tens of thousands of support cases. Now you could feed that to on demand, but if you do that, chances are, and I'm sure some of you have already seen this. You know, you'll probably exhaust your token counts and you may get throttled. But if you're doing annual analysis, you don't need that report right away. So you can send it to batch, and Amazon Bedrock batch inference. It allows for uh no uh stress on your throttling, and also it's far more cost effective. So that sort of pattern gives something like this. What we do in that, uh, architecture we just showed you, we take every single support case and we summarize it. So the conversation that you have with your support case agent, as Raul mentioned, a lot of it that contains golden nuggets and how to resolve different things. So we summarize it into an essay and we also point towards a specific suggestion and documentation as to addressing the support case. And we do the same thing with health. We summarize the health event, give you a suggestion how to address the health event and documentation as well. So now this gives us that next level in what Jason was talking about giving you guidance to specific events. And now the aggregate level. So this is that 2nd phase where we're looking at data and aggregate. We have health and support in one worldview, and I think Raul mentioned they're correlated data. Quite often when you have a health event you have support cases as well. So we looked at them in an aggregate and we asked Bedrock to give us an aggregate summary, a holistic view of our operational environment. And since we had that aggregate view, we can also ask for a plan. In this case, I've asked Ford to give me a plan to improve the resilience of my operational platform. And this is based on our prescriptive guidance of age of resilience infrastructure. So So that gives us the next level, an aggregate understanding of the operational environment. Now this is pretty cool and all, but I think you know some of you guys are saying, you know, Joe, uh, this is kind of cool, but this is just document generation summarization rack stuff that you've seen before at last year's reinvent. I think by now we're kind of not wowed by this kind of technology anymore. But that said, it is very effective, and, but you also say, well, this is the year of the agents, and you're absolutely correct. For the next two levels, we do need to actually use agents. So let's see how this plays. So we're back to our Maa architecture and there's another workflow that we demonstrate within the GitHub like I showed you before. So now as events comes in, we feed it into open search. And we create embeddings using Amazon Bedrock Titan embedding model. And you see there we have a bunch of tools for both support cases and health events. We have lexical search tools, semantic search tools, as well as hybrid search tools. And those tools are made available to the MCV stack on the right. It's hosted in Quiro, uh, in, in this case, using cloth on it. Let's dive a little bit deeper with that how that open search index open index looks like. So this is, I think some of you will recognize, an actual AS health event. Actually, this is just a screenshot from my open source UI like literally. And you, you can see how I keep the ADBS health event, the metadata in structured form but also having embedding as well. So, uh Let me make a bit of a point here actually. I'm going a little bit off the script, but. I mean, standing here, I think you can probably tell that I'm rather passionate about Jenny Y. That said, the pre-genetic tech, that's still pretty good. I mean if you have structured data there's no need to create an embedding for it. A structured query is still pretty good, so the metadata, I keep it structured. That said, I have the event description, right? That's natural language. So that field I do create the embedding for, and that's that array in the bottom. So now this record can be queried by a lexical search, semantic search, and hybrid search if you apply for a loss for it. In our case, we're using OpenSearch, which does allow for that powerful hybrids search capability. So So this is kind of cool, but I think um we engineers we tend to build shiny things and. Genia is very shiny. But if my shiny thing doesn't address a business problem, what have I solved? So let's look back to some of the questions that Jason and Raul were asking. So, I've been in technology for a couple of decades now. And this time of the year, December, this is the question that's always in my mind. Because things tend to expire on December 31st, and I don't want to come back in January with stuff broken, right? Well, actually, but I have all those health events in my open search index, right? And I have that nice MCP stack on top of it, so. This is actually, uh, it's a little green because I, I, I like to see it in green, but this is literally the KCLI that NCP stack that I showed you before, and I asked, do I have any ADOS health events coming up. And now I'm actually able to query it and now it's, let's see, it's finding a whole bunch looks like uh S3 related events. Respect to uh replication and life cycle events, OK. Well, good thing I asked. OK, that's good to know. Oh, it's happened in January as well. All right, so what has this done? So this has given me awareness of like what is happening. And now that I'm aware of what's happening, I need to take actions and as we have discussed, support cases are often actions based on health events. And we see that we have health health events and support cases in one worldview. So now I ask, do I have any relevant support cases, meaning, do I have already some actions already in place? Well, so now I'm back to my QOCLI, and I ask that exact same question. And now the agent is contextually aware of the health event, so notice, I know it's going a little bit fast, but it's pulling support cases that's only relevant to that SVA health event. And it looks like actually I do have some support cases in place, meaning some of my actions are already in place. All right, this is good news. I already have some actions in place. But you know, um, I have my favorite S3 bucket, you see. In fact, um, over here, get down at the bottom, I'm asking about S3 Maki-report.riv. By the way, Riv is, uh, Amazon talk for reinvent, OK? That bucket is literally what's behind that, um, pie chart that you saw before, and I want that pie chart to function after January as well. So I ask, is that bucket impacted by by health events? And let's see what that Kiro does now. Notice it's called S3 API. And it's calling specifically bucket replication configurations as well as life cycle event configurations. It's contextually aware of the health event that's happening, so asking for those specific rules. Fortunately, my bucket, um, it doesn't have any replication or life cycle rules. It already found from the SVAPI call, so I don't have to worry. All right, so I can probably enjoy the rest of this reinvent and come back in January all happy. Not really, because I'm a technologist and as a technology person, there's always something in the back of my mind and that is security, security, security, absolutely in this, in this case, critical vulnerabilities. Because I'm sure, how can we forget this guy? Or this guy here. So, at this point, I can see I'm, I'm inducing PTS in the audience just by showing this, and I'm sorry about that. But you know, I shared that PTSD with you. Oh my God, these guys are painful. Now in enterprise workflows I'm sure you already have some CVE checks in your CIDEC flow, but you know what I personally always worry about. What about that CVE that just came out like yesterday, right? Is my workflow accounting for that? I don't know. Well, so now I launched my QO CLI in the context of my developed environment. As you can see, this is my VS code. And you see that it's a little bit hard to see, but in the middle which is get underscore CVEs. That's a simple MCP agent I wrote which simply pulls the CVEs from the public record. Hello. Oh, there we go. OK, thank you. Now I ask, do I have any CVEs, um, in my, uh, that, that I should be aware of and in the, the public that just recently came out and looks like it pulled a bunch of WordPress CVs. Well, well, if any of you guys are running WordPress, I'm sorry to say you have some work cut out for you. Fortunately, my framework doesn't use any CV, uh, WordPress, but it's also talk, talking about some. Command injection and networking vulnerabilities. OK, that sounds serious. All right. 4th and actually Kier already did the analysis and gave me some recommended actions, actions that I can actually now take and apply to my code. But I'm thinking, this agent is already contextually aware of my entire repo. And you know what the vulnerabilities are. So, go find in my code, where these CVs are actually impacting. And they find them By the way, in, in the interest of time, I kind of like sped this search up, but that search went through every single line of code. It even went to the libraries in my Python environment. And once again, it gave me recommendations, action I can take upon my environment. But I'm thinking, OK, you know what the CVs are. You gave me recommendations. You know, we in the code that I need to fix this. So, Why don't you go fix it? And it does. So Think about the time When you have to address. The heart police and the lock for Jays and other issues. Think about how much effort that took. Now I'm addressing this in minutes. So, you know, the bad actors out there, they're already using Gen AI. We have to use it too. So all of this I, I've described so far is in the GitHub repo, I'll pointed towards the end as well. But now, let's really think beyond, beyond. Some of the what's already been published. As you can see, based upon the foundations of the health and support data, if we add more and more data domains into our worldview, our worldview becomes more enriched and our actions become more meaningful. What other data, data can we add here? I think the obvious one is of the ability, right? So think about those health events that were coming in. Can we correlate that with production obserability records? I think it'd be very meaningful if you do. I'm not saying it'll be easy, but I think agentic flows allows that capability. What about change management? I scan for CVAs in my code, right? What about the incoming changes? I would like to scan for those as well. What about cost? Those health events. It has to do with S3 bucket replication and life cycle rules, right? Does that mean my bucket cost will change? I don't know. Well, I would like that question answered. The more and more data we add to our worldview, the richer it becomes. Now, let's really push the envelope here, OK? Here you are at Avis Reinvent. It's a Monday and you're gonna have a wonderful time. Can we add the signal from other providers? Some of many of these guys are multi-cloud. Once again, not going to say this is easy, but, and I think this is sort of the, the holy grail of IT, right? The single pane of glass. I think MCP to me in some ways is like an API aggregator. I think it is possible. And why stop here, right? Many of you have vested infrastructure on-prem. You still have data and value coming in. Added to the same worldview, the single pane of glass. And why stop here? You saw me pull the public CV data, right? There's many other invaluable data in the public, such as news or social media or weather or financial market data. So Imagine a scenario where there is a potential black swan event happening. You see that in the same worldview and you're able to preemptively scale your infrastructure. How cool would that be? Now, at this point, I kind of run out of space on my little visualization, but I think you get the point, right? Continue to add more and more data and I think your world become more and more enriched and you're able to take better and better actions. So to conclude, right? The ADS's health and the ADS support data that Russell mentioned. Start there. This is your foundations, OK? Upon those foundational data, build something like what Jason did at Fidelity. An enterprise scale framework that ingests the volumes of data and also further enrich with your own proprietary data, make it yours, and then send it to the respective stakeholders so that the actions can be taken. That by itself will give you much value in that 23% slide that GNN showed you. And once you achieve this, To get to the next levels, you can now apply Gen AI. And in particular using the genetic framework continue to add other data domains within your worldview on top of the health and support data. You know it's just Monday and we've already seen some announcements and I'm actually very excited to see the rest of the announcements. But personally, I'm also really excited. When we'll meet again next time this year because I, I, I believe honestly that many of you will take patents like this and build amazing products and I think our world will change by next time this year. OK. Please join us at the support booth to see what else we're doing. I believe there's also a workshop that conducted on Quiro. Uh, I believe SPS 311 is the number, so you can actually try out hands-on try out what I was just showing you. And well that again is once again the GitHub link to that market repo if you missed it before and myself Jason Rahul, we thank you very much thank you.