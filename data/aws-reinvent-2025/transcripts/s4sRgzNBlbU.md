---
video_id: s4sRgzNBlbU
video_url: https://www.youtube.com/watch?v=s4sRgzNBlbU
is_generated: False
is_translatable: True
summary: "Arun and Nathan from the Cursor team at AWS present a deep dive into Context Engineering and the Model Context Protocol (MCP). They argue that the evolution of AI engineering has moved from prompt engineering to RAG (Retrieval-Augmented Generation), then to agents, and now to context engineeringâ€”the art of managing the information environment for production systems. They define context engineering as not just filling the context window, but pruning, summarizing, and reloading information at the right time. \n\nThe speakers critique the current RAG approach as passive and lacking a feedback loop, often leading to either too little information (agent failure) or too much noise (confusion and high costs). They introduce MCP as the solution: an open standard connecting AI to data and tools via a client-server protocol. MCP allows agents to query available tools, select them based on intent, and execute actions, fundamentally allowing agents to \"observe\" the outcomes of their actions and iterate. \n\nThe session features a live demo using Cursor (an AI-powered code editor) to debug a \"2048\" game. Nathan demonstrates how an agent can use MCP tools to: 1. Read documentation (AWS docs) to understand new features. 2. Run local dev servers and fix configuration issues. 3. Interact with a browser (Chrome MCP) to reproduce a bug by playing the game and verifying failure. 4. Create a GitHub issue with detailed reproduction steps. 5. Analyze the codebase, propose a fix, and even update the GitHub issue with its findings. \n\nA key highlight is the introduction of \"Cursor Powers,\" which packages steering files and MCP tools for popular libraries (like Figma, Netlify, Supabase) into a common configuration. This allows agents to dynamically load just-in-time context, solving the problem of context window saturation. The speakers emphasize that true agentic behavior requires this ability to observe reality, iterate on incomplete solutions, and leverage standardized tools without custom integration code."
keywords: Context Engineering, Model Context Protocol, MCP, Cursor, AI agents, RAG
---

Good afternoon everyone. Welcome to day 3 of Reinvent. I hope you're having a good reinvent, um, and welcome to DVT 213. Um, I'm Arun. I'm a senior solution architect manager at Quiro, and I'm joined by Nathan today. I'm the senior manager of software for the team that built the Quiro ID. So we're both founding members of the Quiro team, and we want you to take um a journey that we have been personally on, one that fundamentally changed how we build with agents. The biggest factor today, whether you'll be happy with the results that your agent is producing, is how well you're feeding with the agent, right? The big primary way to accomplish that is by providing information, what we refer to in the GI industry as context. But here's what often that's misunderstood. It's not about having more information, it's about having responsive information, information that reflects what actually is happening right now, and critically, it is about agents being able to observe the outcomes of their actions and input. So we've got a packed agenda today, so let's dive right in. Before we do that, quick show of hands, um, how many of you have used or familiar with keto here? Great. And how many of you are currently building um or using AI agents in your development workflow? That's awesome. So there's one hidden question in here. How many of you have hit context window limitations or struggled with agents getting the right information? Just wanted to make sure that we are presenting in the right place, um. So we'll, we'll go ahead with the agenda. We'll cover four key areas. First, what context engineering actually means and why it matters. Second, we'll take a look at RAG, the current approach and its limitations. Then I'll introduce you to model context protocol, MCP what it really means, uh, which is transforming how agents are accessing information today. We'll also talk about how you can leverage MCP with Quiro. And next we'll take you through our journey with Quiro and how we built Quiro with MCP. And finally we'll see a live demo of this in action. We'll take the agentic leap of faith with Nathan, who's gonna do the demo. Um, they asked us not to do a live demo, but YOLO, right? But first, let's start with the foundation. What is context engineering? Now here's the evolution that we have seen with AI engineering. So we started with prompt engineering, crafting the perfect long prompt to get good responses. Then we started adding rag to give models access to knowledge bases, and then agents giving models tools and autonomy to take actions. But now we're in the final step, which is context engineering, which is what separates prototype to production. It's not just about having tools or knowledge, it's about managing the entire information environment. The agent actually operates him. So that's what this session is about, how to engineer context for production systems that actually deliver ROI. Notice how like each step adds more complexity. Context engineering is how you manage that complexity at scale. Now you may have heard the term context is king, context is everything. So let me explain by what we mean by context is everything in the messages. When you're using cloud or any other LLM for that matter in a conversation, there is an array of messages that represents the entire conversation. It could be system prompts. It could be user messages. It could be tool calls, tool results, assistant responses. All of this goes into the messages array. That array is the context. The problem with long running agents today is that this array keeps growing. Every tool call adds more messages. Every response adds more messages. This is different from like single shot LLM calls with agents you're running in a loop. Call LLM, get tool calls, execute tools, add results to messages. The context continues to keep to grow. That is why context engineering isn't optional for agents. It's the core challenge. All right, this is a famous quote by Andre, um, where context engineering is the delicate art and science of filling the context window with just the right information for the next step. I would take this one step further. It's just not about filling, it's pruning, summarizing, and reloading context at the right time for the agents. But we spoke about what is context engineering, but let's set the stage on what are the different types of contexts. So let's break this down. First is the system context, that is your foundation, the role definition, behavioral instructions, what sets the agent's personality and capabilities. But think of this as the agent's job description manual. Uh, it always presents in every interaction. The second is retrieved context. This is where rack comes in, semantic search over index knowledge base. Here's how it works, right? Like you've embedded your documentation, your code base, whatever knowledge that you have in data sources that agent wants to access. When the user asks the question, the system searches for semantically similar content and injects that into the prompt. It's automated, which is great, but it's also passive, right? The system decides what's relevant based on vector similarity, not based on the actual need. So we'll dive deeper into the limitations of this approach in just a second. But the third type is the conversational context, right? The previous messages in the conversation, the memory of what's being discussed. This is in fact your message history. Every user message, every agent response, every tool call and result, right? This builds up over time. And here's the challenge in long autonomous workflows this can grow to thousands of messages. Oops. We missed one more, which is the tool context, and that's where context is loaded dynamically, right? And this could include MCP and API connections. Now Rag became the widespread architecture for most of 2024, giving agents access to knowledge. The pattern is simple embed your documents, store them in a vector database, and when a user asks a question, retrieve the most similar chunks and inject them into the prompt. But what does rag essentially mean? Retrieval. So when a user asks a question, the system fetches relevant content from your external knowledge or data sources, which is based on vector databases, and this is based on semantic similarity. We embed the query and search for similar embeddings in our vector database, right? And the second is augmentation. So we take the retrieved context and add it to the user's original prompt. This is the augmented prompt, the user's question plus the retrieved context. And finally, generation. The foundational model generates a response based on the augmented prompt, and it now has access to both the user's question and the relevant background information. Right Now it's elegant, it's automated, and it works, but for certain use cases, right? So first is improved content quality. Now foundation models are like trained on data up to a certain cutoff date. They don't know about like your internal documentation, your company policies, your product specifications, so rack solves this problem. It grounds the model response based on actual content in your data. This dramatically reduces hallucinations, another common term that we have all heard of. Second is contextual chatbots and Q&A. So imagine you're building like a customer support chatbot or HR chatbot. They are automatically referencing all of your policies, so you want that information to be up to date. Third is personalized search. Track and incorporate like user context, their search history, their role, their preferences into the retrieval processes which can influence the way in which the responses come through from the agent. And fourth is real-time data summarization. Now this one's interesting because it's actually a hybrid approach where you retrieve and summarize transactional data from like a databases. So for example, you could say summarize all transactions over like 100 from last week. But the major limitation is that there's no feedback loop. The model can't say I need more information or I need different information. It gets one shot at retrieval each time in a session, and that's it. This is fundamentally a passive system before the model even starts to think about reasoning. So we'll start, we're guessing what will be relevant based on similarity and not an actual need, and this is what I'd like to call it as the context conundrum. So retrieve too little and you miss out on information. The agent says, I don't have enough context to answer that. You retrieve too much and you overwhelm the context window with like noise. You're paying for tokens that aren't like relevant. So the agent kind of like gets confused. And you also have like semantic gap. Semantic similarity is not the actual need in itself, and sometimes the retrieved context may be outdated. Your documentation may have changed. Your vector DB is now with the up to-date documentation, has to keep up with the up to-date documentation. And you also end up in like a multi-hop problem as well, where you're unable to follow the chain of dependencies. And that is where MCP comes in. It's an open standard created by anthropic. That's important because it's not proprietary, right? It's not locked to one vendor. Second, it's a client-server protocol connecting AI to data and tools. And third, this is where it gets practical. MCP already has like predefined SDKs and built-in integrations. You connect to Google Drive, Slack, Jira, you name it, right? And you don't have to build everything from scratch. There's a growing system of ecosystem of MCPs. And MCPs consist of three core primitives, which is resources, prompts, and tools. Uh, we'll dive each, each one of this into detail, uh, in this next slide in the request flow. So how does the MCP request flow work, right? So the user has a query. Let's say I would want to see what is the status of my deployment, and the host, in, in our case, you know, we'll talk about Quiro being the host which consists of the agent and the combination of the LLM. Uh, it is going to request available tools. Um, the MCP client is going to then make the call for list tools, and the MCP server is gonna list tool which will probably give the list of all specific tools related to deployment question. And the LLM is going to make the choice and select the tools and identify the parameters. And let's say that you know there's a specific tool called for get deployment status, so there will be a parameter that will be required and let's say deployment ID is one of the parameters, um, it could be in the conversation which which gets sent back and we call the tool with the specific name and parameters, and that is probably going to create an API call and we are going to get an API response back. And that formatted response is what is sent back to the user, which is integrated from the agent. Right? So, the MCP protocol is everything that happens from the host to the MCP server, and then this custom logic that the MCP server or the providers that is defining the MCP is gonna make. But why is it important? You may have heard that MCP is like the USB of AI integrations. Remember before USB like every device had its own connector, and after USB came in, that that was standardized into a single port. So MCP does the same thing for AI. You build one MCP for each data source. That server works with any agent that speaks MCP. So the M times N where one agent with like 10 data sources uh is going to become like 11 plus 10, right? So, you know, that's 11 integrations instead of like, you know, 50 odd and add a new agent, it automatically works with it. MCP provides consistent implementation patterns whether you're like, you know, exposing a file system or a database or an API. Your approach is going to be consistent. This means like faster development, easier maintenance, better reliability, and simpler onboarding. But how do I deploy MCPs for production, right? MCP supports two transport mechanisms, which is the STDIO, which is the local MCP, where the MCP client and server runs as subprocessor in, in the same machine communicating to standard input and output, uh, and each agent sponsor off its own subprocess with its own MCP server instance. It's isolated, it's simple, it's fast, no network overhead, no authentication complexity. But notice that this doesn't scale to like multiple users or distributed systems, and that's where HTTP comes in. Streamable HTTP is for production deployments, right? Multiple agents can connect to my MCP clients. Um, the keyword here is streamable, so it's based on SSE, which is the server side events for real-time bidirectional communication. The agent can make a request and the server can stream back results as soon as they become available. Now up until now we've talked a little bit about how we get the agent more context and access to more tools, but what we haven't answered to a full extent is why does this matter for you and how does that enable the agent. So one thing that MCP can do that's really interesting that it can leverage these, these prompts and these tools is it lets the agent for the first time close the feedback loop and check its work in ways that weren't possible before. So up until now, uh, and in the early days of agentic development, what you saw was an agent would, uh, understand your code base. It would propose a solution, but it wouldn't be able to check its work, so you would have one shot to get the best quality result, but that may not be what you were looking for. So this is what the feedback loop looks like in action. Um, the first couple steps is very similar to what we had before. The agent was able to reason what, uh, what you were asking for with your user prompt and propose a solution. Uh, then it was able to act. So agent might edit code. It might launch a debug server if you're working on web development or you're, uh, working on an API or infrastructure. But what really changes with MCP is for the first time the agent is able to observe, so the agent can read uh terminal output, it can retrieve service logs or client logs, um, it can inspect breakpoints and code, uh, it can view rendered applications if you're working for a website or even make internal API requests to the, the server that's running. Uh, and then what, what really becomes powerful is that it's able to iterate on a solution. So based on the information it got from its observation through MCP tools, uh, it can, it can, uh, refine its work and to iteratively get towards the right approach, much in the same way that an engineer would traditionally. So where this really starts to get more interesting is with remote MCP. So with remote MCP you can make a connection to remote transport servers, and this lets you have a secure connection to external resources that's connected through HTTPS connection. Uh, it, it streamlines the authentication process because you can have an OA connection. Uh, you aren't worrying about having, uh, locally managed credentials that you might accidentally commit into your config and, uh, expose. Uh, we have that secure environment variable expansion to make sure that the the credentials remain protected. And the biggest thing that you get with remote MCP is that servers are now hosted. It doesn't require local setup. So traditionally what you, what you had as a challenge for setting up, uh, MCP servers locally is a lot of them required very specific environments. Like having Python and UV installed or having Docker or you had to have a lot of complex business logic that was deployed to every user that was developing applications for you. So with remote MCP these limitations are no longer a factor. And for configuration, remote MCP looks much in the same way that it does for local MCP. So with local MCP you would have a command that run locally. Uh, so with that Atlassian MCP server as an example, that is one that is running UVX, which is a, a Python library, so it, it runs with these local arguments, but with remote MCP, uh, you now set a URL and optionally authentication mechanisms. Um, so there's a couple different types. You can either have, uh, header-based authentication that has an access token, or you can use OOS, uh, to authenticate to that remote service. So what does this mean for the Kiiro team? Uh, we were able to leverage MCP through all phases of our, our product, uh, software development life cycle. Uh, we wanted to really look at, uh, how across the, the entire arc of software development, where were phases in that software development life cycle that we could leverage MCP. To to speed up the team because the, the first focus for gentic development was really on the implementation side and on accelerating the, the hands on keyboard or um the code authorship phase, but what we found very quickly is that even early on in the agentic development uh industry, uh, the, the implementation side in the hands-on keyboard uh was largely a solved problem, but that's only a small sliver of what we do as software engineers. So what we wanted to do was see all those phases, how, how we could leverage ACMCP to help us deliver software faster to customers. So that really started with the ideation phase where you can do things like uh retrieve backlog information, work with the product. Look at designs, um, maybe you store them in figma and the agent can automatically pull those and analyze the requirements that come with a product manager and come up with a proposal of how we can solve the things that were outlined in the product backlog. And then we go into the implementation phase, which is what most of the team is very familiar with with agentic development. But with MCP, uh, not only can the agent author code, but it can go check information to to get the latest information for, uh, reference docs for library information. um, here at Reinvent we've launched a lot of new products that I'm sure people here have a little bit of context on what was launched, but you don't have context on everything and so having an an agent that can go and retrieve that information just in time and present that to you really helps developers get up to speed faster. Uh, and in addition to that, not only can it write code, but it can also do things like control dev servers, um, uh, launch, uh, debug windows, interact with applications, and, uh, test the implementation as, as it's writing it. So once the the code change has been completed, then you can go into the testing phase where uh for us uh agent quality and speed and reliability is very important so we have a a benchmarking system that we evaluate every agent change against. So we're able to have the agent uh make a change locally to it its own uh source code and the tools that it has available and the information it uses to implement a change and then it's able to run a benchmarking suite against the changes that it made. We even use it for regression analysis so when we have a release candidate that we're testing that we have software that's staged to deploy. Uh, we distribute that to an internal group of testers and then we will have an agent locally that's running that is uh analyzing all of the service requests that are are happening against that released candidate and determining if there's there's any regression in either quality, speed, or user experience. Uh, Additionally, we have fault and acceptance testing that's doing things like fault injection in the client and verifying that that behavior is handled appropriately. Uh, and then we go to the deployment and support phase of the software life cycle. So, uh, that's something that I think there's a lot of innovation here, uh, in the industry and in our team as well. So what we'll do is if we get any user reports that there's a, a defect or a regression or, um, undesirable behavior, we can have an agent that's running locally that's retrieving our service logs and live telemetry. So that we can we can get enough information to to diagnose and root cause and then locally recreate failures so it's able to connect to production systems and have all the information at its fingertips that it would need in order to solve a problem. Things that would have taken engineers 1015, 30 minutes, maybe hours to diagnose. We have an agent that has all the tools at its disposal to automatically gather that information to make support much faster than it was before. Uh, so what we learned today is context is everything. The, the quality of the results that you get to the agent is directly related to the quality of the context that you provided. And uh what is really useful is to get the the close the feedback loop and that the agent true agentic behavior requires an agent not only to uh uh implement a change but also to observe the outcome and adjust uh and you can extend the agent reach by adding MCP tools that let the agent act outside of the editor and use remote MCP to integrate with external systems. Uh, and what we wanted to do today was leave plenty of time for demos because really it's, it's hard to understand exactly how this will impact your, your ability to build software until you see it yourself, um, so we have some time for a demo here. And what I will be working on, um. One thing that we, we really like to do, um, with spec driven development and with developing Quiro uh ourselves is, uh, build small simple applications. Um, we do use it for developing, uh, the application itself and for, for enterprise production scale systems, but really to get a feel for how it's working, uh, it's useful to, to build these, uh, simple apps to test functionality, um. So what I'm gonna look at right now is this 2048 game, uh, which is a simple sliding block game where you try to combine blocks in in order to reach 2048, and I will open up Quiro which, uh, hopefully many of you are familiar with, and we'll first look at our MCP configuration. So you, you'll see in here I have a couple MCP servers that are automatically that are already installed, um. And in order to configure these, you'll see we have a few in here like I have this AWS docks MCP server we'll make this a little bit bigger. Uh, we have this AWS DOCS MCP server. So this is a local MCP server. Uh, we do have a more powerful AWS MCP that, that allows you to, uh, configure production services, but this is a simple one that runs locally that just lets you look at documentation, um. And we have a couple of commands that are auto approved. Since this is just documentation, we trust the agent to take actions. We have a Chrome MCP server that lets it run a browser, a fetch tool that lets it retrieve websites from the internet, and then we have a couple of remote MCP servers that use one uses header authorization and one uses OAuth. So we have GitHub and Figma here. Uh, and the Figma one you'll see is, is not authorized, so I can walk through the authentication flow to see how does OAth get set up. Uh, so this is one that it will launch in your browser and you have to trust that Quiro can launch this and then you'll see Kiro would like to access your account. So with this I don't have to worry about any local credentials. Did I accidentally commit something that I shouldn't? I just give Quiro access. Authorization is successful, and I can come back in Quiro, and now it's connected and so that's all that there is to it. Um, so a very simple MCP server that we can look at. Is the AWS stocks so at reinvent AWS just. Announced a new model called Nova 2. Can you use the AWS docs tool to tell me a bit more about it? And hopefully conference Internet lets us do this and it does look like so it was able to call this search documentation tool and because I have this trusted in my list of MCP servers it didn't ask me for any approval. This is because this is a tool that I deemed safe and that I, I have no problem with the agent doing automatically um. So we'll look up here a little bit. So there's a couple. It's asking for information on Nova 2 in here and you can see it got a couple results, uh, and then once it, it understood where the documentation was located, it went in and read the documentation to get some more information and now we've got a summary of all of the new Nova models and, um. Uh, I can use this if this was something that it was a framework or a library that I wanted to integrate with. Uh, this is really helpful to get me started. Uh, but I wanna go on to doing some meaningful work now with that, uh, Nova server, and if I look at it, I think this will no longer be running, so yeah, I, I now have my local host turned off, so I want a little bit of help from Kiiro. Can you help me run my dev server? Um, so this is something every project's got a little bit different command, and I always forget it, so I just have Quiro help run it for me, and this is one that is useful. It's running in a background process and if ever it needs to check on what the output of this server was, it can, but it'll have it running here. So with Quiro's help now I have this running now I can look at this 2048 game. So if you haven't seen this before, uh, what it'll do, and it, uh, what it'll do is combine numbers in order to, uh, try to ultimately combine it up, up to 2048. Uh, this is a game that's pretty simple, but in trying to learn it, I wanted to see, OK, can we just create an auto solver here? So I have this auto solver, and it just does it automatically for me, but we've gotten some reports from users that if I, if I click new game here, it just keeps going from the last game. Um, so my product manager asked me to create a ticket for that, but that sounds like a lot of work, so I'm just gonna have Kiiro help me. This is our day to day life. Yeah, hey Kiro, yeah, users are reporting that if you have the auto solver running and you try to start a new game. It keeps going with the last game. Can you help me? Verify this defect using your MCP tools and once confirmed, let's create a. Issue on GitHub in the. AI playground repo. So what I'm doing, I'm asking Quiro, let's, let's verify it locally because I mean we, we tested it ourselves but just for completeness we wanted to have the agent test it and then it'll get some information and then it'll draft it into a a ticket so that we could track our work. And it'll be a little bit slower here on the conference Wi Fi, but normally this is a very fast process. Yep. And one of the other things if you have noticed, uh, in this particular prompt, Nathan didn't specify which MCP to use, so Kito automatically detects the intent. And then uses the GetUp MCP. While we wait, is there anything new that's gonna happen this week that folks should be excited for? Yeah, if, if you've used Quiro before, you might notice that there's a new panel here, and one of the things that you will also notice is I am already 19% into my context usage, and I have barely started the conversation. And so if you'll see I've got quite a few uh MCP tools like I have this this GitHub MCP server that has 40 tools in it, Chrome has 26, um, this is the, the biggest problem that we hear from customers is I love MCP tools and the power that it gives me, but it, uh, it uses all of my context and there's less usable space for me to actually do the interesting work, um. So what you'll see here, which was announced earlier, is a product that we're calling Powers. So what Powers is, is it combines uh steering files and MCP tools and all of the information that an agent needs to uh leverage popular libraries. You'll see a lot of them here, things like uh Figma, NetLy, Supabase, strands, and many more here. It packages all of the information that you need to leverage these tools into one common configuration. And then the agent is able to just in time add that information to its context so that it doesn't need to have everything in its system prompt and in its context window all of the time because if, if you recall back in the conversation, uh prompt engineering is not making context engineering and prompt engineering is not making sure you have as much information as possible. It's about making sure that you have just the right information at the time for the the agent's next action. Uh, so you'll see here in the side very similar to the way that we have command approval, um, with the, uh, Chrome MCP server that allows the agent to, to operate your browser so that is a little bit less safe than things just like retrieving documentation. The agent could do anything in your browser, um, which obviously there's there's some unsafe operations that it could do so this is one that I wanted to accept any command and I see it's trying to run my local server. Um, so I'm gonna let it call and it ran into a 404 because it's not running. Oh, there's already another window open. I will quit this, and now it'll fix. OK. OK, there we go. So it's launched a new window. Now it's going to navigate. Oh, So now it's opened up my project and what it's going to do is it's going to take a snapshot of the page and that'll give it some information on how it's going to navigate. And so, uh, for simplicity's sake I'm gonna approve these just so we're not flipping back and forth between the two windows. So it actually clicked autonomously and then it's gonna take another snapshot of the page. This is pretty cool. So it's going to try this autosolve, but it is already broken. Let me see. The game had already been lost, so now it's it's gonna try to start a new game. So you trust it once and yeah so with that I, I, uh, it gives you the option to run the command but also trust the tool and run it so that that allows the agent to have a little bit more autonomy as it as it's um performing actions. And hopefully at home you have a little bit faster Wi Fi than we have here at the conference, but obviously there's a lot of people here, so it takes a little bit longer than it would normally. Yeah, um, but really what this is unlocking, so there's actions that you can take where, um. The agent might be able to diagnose an issue by just looking at the source code, but this is something where for the first time it's, it's able to see it in a, a real environment and it's not something that's interesting, uh, uh, possibilities. So one of the challenges that we ran into as an engineering team is, uh, obviously the, the speed of agentic development is, is, uh, at lightning pace. And so, OK, now, now it started clicking, so it, it started the auto solver and now it's gonna see uh if I click new game, is it going to continue. So it was able to confirm the bug by clicking new game and that's that's still going it didn't stop, so now it's gonna take another snapshot to make sure OK is it still progressing so now it's it's confirmed that the behavior is still there. Uh, so I'll go ahead and stop this. So now what it's gonna do is I, it's confirmed that the bug exists and now it's gonna write an issue for me. So I'm gonna accept that it can run an issue, but I'm not gonna trust that because I don't want it to go too crazy. You don't want to random issues, yeah, so now it's, it's creating the GitHub issue for me, but, but going back to what I was saying before. Uh, what this does allow is, uh, really interesting use cases. So, uh, a speed, a team that's moving quickly with agentic development, um, it's always a challenge for a team to do things like, uh, write comprehensive regression tests or write comprehensive integration tests. And so one of the things that we were looking at is Wikiro can drive these windows and it can click through things and it can read documentation. Uh, we have pretty thorough documentation on our website already. Uh, if I go here, I can go to Quiro. Dot dev slash docs. And uh we have a lot of information here on like how how specs work, how hooks work, um examples of using them so one of the things that we thought of is hey this is all the information that a a user needs to use our tools successfully is that all the information that an agent needs to use our tools successfully so we just said go read every page on our our documentation site and go make sure that. If I follow the instructions for MCP and if I if I configure this server, does it work? And so we just got a report on not only is the tool working as expected, but is the information on the documentation site correct and if there's ever any contention between reality and the documentation, we've got to fix one of them. And uh we can go take a look and see is this something that we need our dock writers to help us uh uh update the documentation or is this actually a defect in the tool so it's things with very, very low lift from the engineering side we could get a lot of value by by leveraging these systems and its ability to um uh inspect reality. Uh my team owns the dock site, so Nathan's gonna ping me and against me, yeah, OK, so, uh, agent was able to finish creating this issue, and we can see in GitHub, uh, the auto solver continues running after clicking new game, and I think if it were me writing this, I probably would have stopped there. Um, but now we have steps to reproduce. We have expected an actual behavior. We have the test environment and additional context. So this is something that again we see the agents, uh, much more thorough than than engineers would like to be, um. And it, it's really valuable context and this, this helps, uh, delegate a lot of the, the day to day busy work that, uh, prevents you from, uh, spending time delivering value for customers. Uh, so now that that issue is created, uh, great, thank you, Kiro. Let's go ahead and start. Uh, fixing this issue before we implement a fix, come up with a proposal for how we might address this by inspecting the source. Once you have a proposal, post a comment on GitHub. Uh, so we'll have the agent take a look at the source code to try to understand what the problem is, and it also has all the same MCP tools that are at its disposal, so if it needs to go inspect the actual behavior at all, it can go and do that, um, but for now it's gonna start by just searching the code base, um. So it, it's retrieving the files that it needs and, and this is all just back to the regular agentic loop, um, but it will use MCP tools at its disposal. Um, so it's got a root cause for why it believes the, uh, game continues and it has a proposed fix. So now we're gonna add a comment to that ticket, uh, that has its findings and it added that comment. So we should see now. Uh, it's a comment from me, but it's also, it's something that if you wanna add an access token that shows that it's from the agent, a lot of times we'll, we'll have a convention from the team is if it's coming from an agent, we'll just say hi Kiro here and have the rest of the comment that that just shows people that it's from an agent and um maybe treat it with a little bit more scrutiny than you might before but um generally we, we've learned to trust the agent pretty well because it it is very thorough in its analysis so. Um, it's been able to identify the root cause. It's been able to propose a fix, and this is something that, um, we can, we can work with the teams to take a look to see, uh, is there anything that that we disagree with this proposal, and we can kind of continue the conversation and GitHub or, um. If you use Asana or Jira or any other tool, uh, generally speaking, there's an MCP server for any of them, and if there's not, it's very easy to wrap any existing API in an MCP server, so it's able to leverage the existing systems that you have, and that, that's really the, the power of MCP and remote MCP is it lets the agent act outside the editor. Uh, so we will check back to see the progress that the agent has made. It added the in issue comment. OK, great. Let's get to fixing the issue. So it went ahead and made some changes to the game. And all we had to do is this one line, uh, we turned auto solving off as soon as it restarted the game, so now it wants to go navigate to the page and reload the window to confirm the behavior. So I will come back to. Yeah. So now it's, it's verifying the behavior again and it's gonna click new game and now that it clicked new game it stopped. Um, So we were able to fix, we were able to fix that issue, but what we do see is that all the tiles are still here, um, so there's a little bit more work to do. So we're gonna let it auto approved navigating. And so this, this is what is really helpful with closing that feedback loop is it's something that if it's looking at the source itself it may have had an incomplete solution but then you're faced with the frustration of of nudging it, hey, you didn't quite get to the full solution and with this it's able to check back. Against reality and it's able to iterate and refine in in pretty much the exact same way that an engineer would because uh you start to have a solution but often times what you'll find in software is every solution has unintended consequences so this is able to allow the agent to further refine. Um, so it's, it's looking again at the logic and based on the learnings that it made from, from observing reality, it's able to come up with a little bit more complete solution. So now it's gonna, it's gonna test the changes that it made and in here. Um, It's going to update any pending movements and clear those out. And one thing that I can even do is say. Hey, our issue is now out of date. Can you update it with the latest findings and the problem. You Observed Unfortunately, even though the agent is still working and it's navigating, I can interrupt it at any time and I can say, hey, I want you to go do that real quick before we go much further. So I just wanna update that issue to make sure, uh, I, I told the product manager it was a one line fix and now it's not, so he's gotta get up, up to date. So we're gonna add another comment and we don't trust that, so. Now we'll come here and we can see. Uh, updated analysis. So now it's something that, um, obviously I can go in and check this just for demo purposes, but if I were an engineer I'm able to stay in my editor and I, I don't go out of my flow state, uh, and I can even, uh, add some steering information. So, uh, I can create an agent steering file and I can say GitHub updates. And I can say we'll get rid of these any time you're working on an issue from. GitHub, be sure to add a comment with the latest status. When we start looking. At an issue post a Proposed fix, um, so things like this where we just add, add steering and um we can let the agent take care of it and we can just continue to focus on the implementation and actually fixing the bugs and all of the the project management and the status tracking that can just happen in the background and the agent can keep us updated so that's something that. Uh, you'll find a workflow that works for your team, uh, but this is, this is tools that let you, uh, evolve so that, uh, you're able to, um, really focus on continuing to solve the important problems. This is just a basic steering file, right? We've seen very complexly architected steering file for production systems by customers. And even Kiiro, I'll cancel this. Hey, I added a steering file on GitHub. But it's pretty basic. Can you add information on our workflow of updating. The ticket with our latest findings. This is a really important thing that Nathan just showed, right, because you're not just relying on Your updates to be made manually. You can take control of the agent and then ask the agent to make the updates on behalf of you and you'll see how comprehensive it gets. Yeah, so one of Kiiro's superpowers is that in its system prompt and um in all the tools that we've built into it, it, it deeply understands all of its own functionality and how to configure it. So even things like um. These MCP servers. Uh, Say for fetch, I'm gonna call this busted. And oh, my connection now failed, so we'll close this window, we'll make sure it's not working. Um I'm gonna say, hey Kiiro, help me fix it so it's able to retrieve its own logs and it'll it'll help you debug it. Um, so things like this are really useful for any of the features that Kiiro has. It's, it's able to help debug itself, um, so it's gonna read its MCP file. And this is for simulated errors, right? I imagine if a customer is having production errors, yeah, so it, it figured out that that busted command is probably not right and that it needs UVX and so now we've already got the MCP server fixed. So, uh, things like that, uh, the, the secret sauce that we tell customers is, is just ask the agent, and most of the time it's able to resolve the problem. Oh. Uh, so that is most of the information that we wanted to cover here with the demo again, we have an innovation talk tomorrow that is going to give a lot more information on Quiro Powers, and, uh, we also have a lightning talk, so I'll be presenting a lightning talk on Quiro Powers tomorrow in case you're not bored of me yet, but, uh, we will also have a breakout session at 4 p.m., uh, talking about powers and how we have integrated with. Uh, the launch partners that we worked with, uh, we've released our blog post today in the, in the morning, um, which talks about some of the common powers that you can install, and we're looking out for more, um, so these are some of the partners that you can see here, um, you all are the first ones to actually see powers in action. So that's, that's the perk of, uh, attending our session in which phase. What, what we wanted to do, um, we really wanted to talk about the, um, the information and the, the power of MCP. But also introduce, uh, there are some challenges that that we wanted to address with MCP and the, uh, adding dynamic context and adding just in time context and being, uh, thoughtful about what we're including and, and if there's information that's actually distracting the agent, um, and so that that's what we wanted to solve with powers so we didn't wanna leave you with this talk without hearing about powers before, before it's even uh officially announced in the innovation talk because everyone has heard about MCP, right? We are thinking what's next, what's beyond, yeah. Um, so there's a lot of other places around here where you'll find Kiiro. It's actually just behind you. There'll, there'll be a lot of talks in the, um, uh, the builder loft throughout the, the event. We have the House of Kiro that's right by the Expo Center. Uh, there's a Kiro kiosk in the AWS village, and, uh, again in the builder loft there's many whiteboarding sessions and Kiro meetups as well. I should have asked, uh, Kiro to figure out the bug in this slide. Yeah, there is a Y missing in the end for Kiro meetups, so. Um, but we just wanted to say thank you for everybody that attended the talk, and I think they'll, there's always a lot of questions on MCP and, and how we leverage it internally, and then how customers can leverage it. So we'll be sure to be here, uh, after the talk. Um, we'll be, we'll be here to answer any questions, um, but just wanna say thanks everybody for interest in Cairo and in learning about, uh, MCP and how you can leverage it for your production systems. Thank you.