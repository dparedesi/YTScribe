---
video_id: -X0ksDNW8GM
video_url: https://www.youtube.com/watch?v=-X0ksDNW8GM
is_generated: False
is_translatable: True
summary: "This session, \"New Era of Platform Engineering â€“ Agentic AI-Powered Self-Service (AIM359),\" presented by Ruslan Kusov from SoftServe, discusses the evolution of platform engineering from traditional DevOps to AI-enhanced Internal Developer Platforms (IDPs). Kusov introduces an \"adaptive modernization framework\" developed by SoftServe, which integrates core AWS services (EKS, ECS, Lambda) with pluggable components for observability, security, and CI/CD. The core of the talk is \"ADQ\" (AI-driven engineering with Amazon Q), a self-service portal concept that uses agentic AI (AWS Bedrock agents, Amazon Q) to automate complex tasks across the entire SDLC, preventing bottlenecks that occur when only single stages are optimized. A live demo illustrates a migration use case where an agent analyzes an on-premise application (via AWS Application Discovery Service/Transform data), and automatically generates Dockerfiles, Kubernetes manifests, CDK code for AWS infrastructure (ALB, RDS), and a step-by-step migration roadmap, effectively enabling re-platforming at the speed and cost of a \"lift and shift\" migration."
keywords: Platform Engineering, Agentic AI, Internal Developer Platform (IDP), Modernization, Self-Service, AWS Bedrock, Amazon Q, Migration, Kubernetes, Generative AI, SDLC
---

Hi everyone. My name is Rosan Kuso. I'm cloud CV director at SoftSurf, uh, AWS Ambassador, and currently I'm losing my voice. I have one more presentation today, but hope everything will be fine, at least for this presentation. So, today I'm gonna tell you about a new era of platform engineering, uh, particularly, uh, platform engineering powered by agentic, uh, AI and self-service with agentic AI. Let me grab my clicker. First, let me start with the concept itself, concept of platform engineering. I believe most of you may be familiar with this, but if not, it all started with DevOps. Remember this, DevOps, tools, people, processes, how we connect those things together, how we build something that will be useful for our developers, and it evolved at some point in time, it evolved to platform engineering. So people, they started building what they call internal development platform. Self-service platform. The idea is that if you have a large development team or teams like 10 different teams, you would like to introduce some set of standards. Otherwise you will end up with a situation where one team, they are developing their application using. Another team, they will be using one team will be using Dataoc. Another team will be using Cloud Watch, and so on, and that will introduce additional operational overheads, additional costs, and so on. And in order to avoid that, you would like to standardize, you would like to build some sort of like abstraction layer, the platform that can be used as a self-service, so you just follow the standard and you just write your code. Pretty well for the developers, and that's why the concept became popular. And I really mean it because we researched it different sources. We worked with multiple customers, observed originally that system integrator, and we compared our data with the data from Red Hat, as you can see on the slide, 85% of customers, they are moving towards platform engineering, so organizations they would like to discover or they are already using this platform engineering. As you can see, 18%, they advanced it, 14, they are just exploring. And 2741, that's like a number in between. The process itself from our experience takes about 2 years. So if you're right now at this exploring stage, you need about 2 years to introduce mature practices of platform engineering in your organization. The problem is that there is no one size fits all approach, so simply meaning that it is a complex product, it depends on your organizational culture, it depends on, The way how you're organizing processes within your organization, what tools you're already using in your organization, as I mentioned previously, it's the way how to set standards and not to introduce any new tools, unnecessary tools. So, how we can approach at that case and at SoftSor we decided that it makes sense to build some sort of like. Framework. So instead of telling that you should buy platform engineering solution, you should build a platform engineering solution that will follow all your needs. So we introduced our own framework based on experience, based on our interaction with our clients, based on feedback that we receive, and of course on collaboration with AWS. And that ended up with this concept that you can see on the screen, a concept where we have core components, EKS, ECS, and lambda, because we are talking about microservices architecture, and all other components that will complement this microservices architecture like microservices runtime, observability components, security components, CICD because we need to build containers, we need to test them, we need to deploy. The storages, databases, third party services, and of course we have this IDP, internal Development Portal, the tool that will be your interface, the developer's interface to interact with this platform. So again, the idea is that all what you need to do is just to design integration interfaces and. Understand that in case today you're going to use Hah core and tomorrow you're going to switch to Secrets Manager, you're not going to do anything with your code, so you just update this integration interface, driver, for example, and you will get a new tool securely connected to your environment to your applications. Pretty cool idea, as I said, we call it sort of adaptive modernization platform, but it's not a platform, it's a framework. I know things sometimes confuse people, but uh we're trying to follow AWS in naming services, our services, so, uh, this platform, we started with Blueprints, so as you can see. It's all Kuberneti reference architecture related to EKS blueprints released a couple of years ago. We have multi availability zones. We have cluster components split by critical components and worker components. We have those environments isolated. We have best practices like carpenter instead of auto scaler to better manage efficiency and scaling capabilities of the cluster. And if we dive deeper, we'll also introduce some default components because again remember that not everything can be solved with a Kubernator alone. You should think about observability, security, CIC and other things. And as you can see, we built this framework considering those other components, but they are built in a way that these components can be easily substituted. So again. If for example, you don't want to use RCD for deployments because currently you're using Jenkins and you're absolutely fine with that Jenkins, you can proceed with the Jenkins, but we'll give you a framework that will tell you what gaps you have in platform engineering, how you can fill these gaps with our default solution, and also a framework that will show you how to apply this platform engineering processes and practices for your organization. It worked really well, till 2023, the year when uh people started experimenting with AI. The funny thing. In 2023, uh, that's the fact that, uh, people, a lot of people, they did not realize that AI was not something new. AI was born like 1956 with a small workshop. It evolved over the years and 2023, that was the year of experiments and the year of AI, generative AI. I believe everyone had experiments with a chat GPT with chats, bots, whatever, that's like common use cases. However, that was hype that distracted people a lot and it distracted our platform engineering practices as well. Next year, that was the year after hype, when people realized that, OK, so we created a lot of chatbots, a lot of experiments with the GI, but how we move that to production. And 2025, we're still not in the production, and you can join my second session where I will show you some specific numbers about that, but 2025, that's the year when we're trying to identify business failure of AI, AI, gentic AI, but we are trying to build a business case for our customers in order to move them to this AI era. Suddenly we figured out that it's very well connected with the platform engineering use cases. So yes they'll see. Uh, to be honest, I was not like surprised, but, uh, that was an honor for me, uh, this morning to participate in this key note from Matt Garman, and, uh, he shared the, the same idea that in terms of SDLC it is end to end process. So you cannot just take an agent for testing, agent for uh business, for the planning, uh for UI design. Because if you take just a single agent and not going to care about end to end SDLC process, you will fail, you will introduce yet another bottleneck. How it works. So let's imagine that you have a life cycle or SDLC cycle every 2 weeks, you have a new release every 2 weeks. You introduced testing agents, so now you don't need 2 weeks to test all your code. You can test it within hours, but your developers cannot develop the code within hours, they still need 2 weeks to develop new code, so you'll be waiting, sitting and waiting on the code that should be tested. Deployment environments cannot be prepared in hours or days. We still need 2 weeks to prepare those environments. So instead of improving the process, you will introduce yet another bottleneck to that process. And in order to avoid that, you need to have this end to end solution. So again, we connected that with the platform engineering. What if, considering this as you'll see as a common case or one of the best business cases for organizations to step up into this era of AI, a genetic AI, GI, and so on. What if we connect that with the platform engineering, one of the most mature cases that we had previously. And we decided to extend the idea of self-service portal with AI. So that's how we released ADQ or AI-driven uh enhanced engineering with Amazon Q. Again, don't pay attention to the names, we are following AWS best practices in naming our services. So we released this idea of self-service powered by AI, and as you can see, It's all based on the components that either are available like first party agents from Amazon, Amazon Q, Amazon Bedrock agents, AWS Transform. Pay attention to agents that AWS released today, especially security agent, DevOps agent. That's something that we tested in a preview mode, worked really well as an extension to this. MCP servers, custom agents, reusable prompts, LLMs. With LLM, it's the same situation as with engineers. Yes, so you have two different engineers with their background, with their experience, and if you ask. Them to do the same thing for you. One engineer can spend 1 hour. Another engineer can spend 2 hours. You can get different results. They will work. They both will work these results, but one result will be more cost effective and scalable, another one less secure, for example, and the same with LLM. That's why it's important to choose the right LLM and provide this power of choice to developers. So, to highlight, it is yet another iteration of platform engineering. Uh, so we just introduced an enhancement for the self-service that brings this AI capabilities for the developers. Uh, this self service, The idea of the self service is to introduce a nail gun. So if you're a constructor, you're building a new house, of course you can build a new house with just nails and hammer. That will take like months, or you can take a nail gun and use that for the purpose, for the same purpose of building a new house within a week or less. The same with the platform engineering and a couple of cases, so real cases before I jump to live demo. The first case, that's a case that we implemented for one of our customers, that's a case where we orchestrated this deployment CICD flow with the help of AI, with the help of MCP servers. Uh, Pretty simple case, so developer in this case needs to know only about programming language. So I know Java. I'm going to run or create my application in Java, and that's it. After that, I will put commit to repository, and everything else will be done by AI. So it will detect programming language, it will create the Docker file, build a container from that Docker file. Deployed to Amazon using manifest generated by another agent and will return me a status of deployment. If everything is OK, I'll get notification in Slack that it was successful deployment. If something is wrong, I will get notification that it is wrong and analysis from MCP servers for Cloud Watch and about potential root cause for problem with my deployment. The second use case is pretty similar, so here you can see an example of a model that we use. We use cloud 3.7 for that. The idea is that we build a tool for validation of deployments to Kubernators. It includes validation of application components. It includes validation of cluster components. cluster components, but by the end of that, customer receives validated Kuberne deployment, and after a production release, the customer can be sure that everything was fine and no issues happened during deployment or in case of any issues, that would be a rollback process with notification of the root cause for that fail. It works really well in production environments and we save it about 3 months of time for the customer by implementing that instead of rewriting the tool that they built originally using Goal length. So again, to highlight, we're not going to build a product, it doesn't make any sense. We built a framework. We don't have any uh software, uh proprietary software, intellectual property here, but we do have a framework that helps to. Accelerate deployment, accelerate application development, application modernization, migration, increase development productivity, and this framework follows all the best practices for the security, higher reliability, scalability, cost efficiency, so it's very well aligned with the well architected framework. Now, it's time for the demo, so it's a live demo, so apologize if it's not gonna work, but I'll do my best. And this demo about migration, that's an example of self service. Yes. That's an example of self-service that can be done for the migration. So let's imagine that I'm running my data center, and in this data center, as you can see, uh, it's connected through a VPN. I have my internal IP address for that. I can create some stuff here. Adds to my to do list, it will be added, so it's a well functioned application. Pretty simple architecture, so I have a virtual machine with load balancer, two virtual machines with the application, and 1 virtual machine with the Posgress database. And I'm going to move it to AWS Cloud. So I'm going to use the benefits of AWS Transform Service, that's a service that allows me to run assessments, uh, gets dependency mapping, qualify my service, uh, runs through right size and exercise. But Transform works well for lift and shift. Unfortunately, lift and shift, that's a strategy for lazy migration. So that's the best strategy to introduce technical debt, but not the best strategy to run in the long term, in a long time. With that, customers, they prefer to find a way how to modernize, how to introduce re-platforming and rearchitecture at the beginning, so is it possible to perform, Re-platforming rearchitecture with the cost of lift and shift, and with this demo I'll show you that yes, it's possible, and that's because of the self service that we provided to our developers. So again, on the left hand side, that's architecture that I have right now. On the right hand side, that's something that I'm going to build load balancer instead of virtual machine, I'm going to use managed service RGS with the primary and replica set up. Multi AZ deployment and my application converts to containers, containerize it and deployed to EKS. So application itself, uh, that's a Java application, as you can see, and uh what we built, we built this agent, uh, this is a fancy web UI that I added for the purpose of this demo, but uh this is the agent that can be integrated to ID of your choice. So, uh, Visual Code Studio, whatever else that you're gonna use, it can be easily integrated. And, uh, what I'm gonna do, I'm gonna show you that I have my, uh, and that's what I'm talking about. Uh, so I have my, uh, servers, and I have my servers discovered by Transform. Thanks God I saved this file earlier, so probably I'll skip this part with AWES console, so, uh, you should trust me. Uh, but that's a file generated by AWS Transform agents. So with AWS Transform, uh, what I did, I used its discovery tool, so we can read about this discovery tool to get this CSV file. So this CSV file identified instances, their IP addresses, and roles, client database, client load balancer. According to that, according to that, uh, Again, I'm sorry but I need to log in again to my console, so I'm not gonna show you a visualization, but uh we can chat uh offline after this presentation. But we're gonna uh back to this tool that we built, this agent that we built for the modernization, and all of what we need to do is just upload, uh, download our files, the CSV file and the artifacts for this Java application to a 3 bucket. That's pretty much it. Everything else is just a. Push this button, start analysis, and under the hood, that's implementation of the self-service, so, Particular version, Java containerization agent of that cell service, the use case developer who is operating on-prem, but going to migrate to the cloud with zero knowledge of the cloud itself, with zero knowledge of cloud services, but I'm going to migrate my application to reference architecture with the containers, with the load balancer, with the RDS managed service, and I'm going to use AI for that. I'm going to use these capabilities of self-service connected with the AWS Transform. So we're going to wait for a couple of seconds. Just to have it fully generated. And I will show you uh what this tool actually creates and how it can be used for the next steps. So meanwhile, just a reminder that we are going from this legacy lift and shift to this modernized environment. Yeah, still no oxes. I actually like this fact of live demo because it shows you real time that is needed to create this conversion, to generate all the files, generate all the manifesto deployment, Docker file, and actually have something that can be easily deployed to live environment. So technically within this live demo you're just watching the process of 3. Migration for this simple application and in order to understand what does it mean for you, for your cases if you have a large migration planning to migrate 1000 VMs, all what you need to do is just multiply that by 100 or 1000 to understand how much time you need for that modernization. OK, so generating recommendations. I hope it will be here soon. Uh Yeah, so, meanwhile, again, unfortunately I cannot show you what's going on, but uh AWS Transform has integration with migration hub, uh, it will be deprecated, service itself will be deprecated. However, right now through this migration hub, you can see the list of servers, you can see the dependencies, so this network map dependencies, and this file that's actually exports from that transform discovery tool. So that's pretty much what you can use and you can see in the migration hub planning your migration. But again, a reminder that Transform supports just lift and shift migration, nothing else. OK, live demo, yeah, running a bit late. Probably like people using Bedrock proactively because under the hook, under the hoods, we're using Bedrock, we're using API, we're using the connection to Bedrock and predefined prompts. So we defined LLM, we build these custom agents, custom MCPs, and we predefined prompts that can be used in order to run this request and create results that will help me to modernize my application. Wrapping up. So by the end of this demo, I hope once I'm done with my presentation, we can chat offline. By the end of this demo, uh, you will have generated YAML file, Docker file, Docker file that will help you to deploy application, YAML file that will help you to apply and deploy this application to Kubernes cluster, and you will have step by step instructions on how to move your database, so snapshot that should be taken first. Oh yeah, finally. So as I said, it took more time. So it's like results of the analysis with the old deployment roadmap, preparation step, application containerization step, Kuberne deployment, load balancer configuration, database migration, validation testing, and details. So as you can see, Docker file for your application, build commands for that Docker file, Kubernator deployment, Kubernator services, config map, variables, and configuration for other resources, including CDK code for infrastructure is a code for load balancer and CDK for the database service. With that, Coming back to my presentation. That was an example of self-service that we introduced for our customers and for our developers. It accelerated a lot our migration practices and modernization practices. So on average we can see 2 to 3 times improvements in terms of time needed for migration and modernization. And last but not least, it is the way to do a migration. With the re-platforming and rearchitecture strategy instead of lift and shift and instead of introducing this technical depth, and with almost zero cloud knowledge, so the way of proper use or use case for self-service. Thank you very much.
