---
video_id: EFXkgy3Fd_c
video_url: https://www.youtube.com/watch?v=EFXkgy3Fd_c
is_generated: False
is_translatable: True
---

Hello everyone. Good afternoon and welcome. My name is Ujwal. I lead machine learning for Healthcare and Life Sciences at AWS and I'm going to be joined today by Cassie Gregson, who's a vice president for R&DIT and Ravi Gopalakrishnan, who's the vice president for commercial and Data Science AI from AstraZeneca. And we're going to talk about the entire transformation process that AstraZeneca went through in partnership with AWS on creating value propositions and use cases that led to uh a variety of different uh optimizations in their entire uh journey of taking a drug to the market. So the agenda for today is going to go around. Uh, a couple of different points. The first thing that we'll touch upon is the impact of agentic AI. We'll talk about some of the learnings that we got during the process, how we have created ROI, uh, from a variety of use cases that have led to, uh, production deployments and how we have done it. I'm then gonna invite our speakers and guests from AstraZeneca to talk about their experience of working with AWS, the kind of use cases they've been, uh, building, how they've been building those, uh, what kind of AWS services they've been using. And then finally I'm gonna come back and and talk about some new additions uh that we have made on our platform that that makes all of this, uh, extremely easy, uh, and of course, uh, you know, through this journey we have learned a lot that we have tried to bring, uh, as part of the innovation, uh, in our stack, the gente care stack that we have so. Before I get started, I, I wanted to recognize the fact that AWS has been working on a variety of use cases across the top 20 pharmaceutical organizations in the world. And they range from, you know, content summarization, chatbots for very standard use cases, uh, getting into production for a variety of, uh, use cases in commercial, uh, manufacturing, uh, drug discovery, and we've done this through, uh, through a variety of, uh, services that AWS, uh, creates. The stat that we have right now is we are extremely proud of, uh, to say that 20-95% of the top 20 pharmaceutical organizations, uh, use AWS for generative AI and machine learning, and this has taught us a lot like during the process when we actually did these, um, you know, projects, it taught us a variety of things that have now led into, um, you know, transformations that we have, uh, in innovations that we have actually included in our stack. If I have to summarize our learnings into two major headers. What I'll say is the first one is, you know, there are no shortcuts. Agentic AI is something that's, uh, extremely transformational. It is at a stage where we're seeing a lot of value, but to get it right, uh, it needs to be, uh, uh, a journey that actually goes from data foundations that cannot be an afterthought. We've seen a lot of customers struggle, uh, on creating data assets or data products that actually matter to an agent. A lot of these data products have been traditionally designed with analytics and um you know, human interaction in mind. Agents are not the same, um, you know, agents do require specific patterns and specific assets to be organized in a certain way and bef before you know it, like when even though you want to actually do, uh, agent tech projects quickly. You will run into walls of, you know, making sure that your data assets are actually keeping up. So making sure that your data foundations are actually in line with what you want the agents to actually, you know, give you answers to is extremely important. And then moving up, um, it's how you actually package these agents that also matters a lot, uh, that's in the middle tier over there which is the AI applications. Now these applications could be hosted within production systems that are in existing larger enterprise stack it. Could be a standalone applications that run out of a browser. It could be an extension of a browser or a chatbot that actually sits within an existing application. There are many ways in which we have seen these patterns evolve, so learning from there has led us into creating specific accelerators in that space too. And then finally when you have uh the data and the application strategy fixed, uh, that is where I think the, the, the uh actual value of agents uh begin to emerge. Um, we've obviously seen agentic AI applications start with like simple summarization read only use cases that go and look for information. But now it's actually evolving into more sophisticated workflows that can be executed at scale. So if you move along these steps and actually go into a direction that ultimately gives you, you know, all the sophistication and all the automations that are needed, um, to create the system at scale. That is how we've generated a lot of ROI. Now this journey is not simple, but uh, what I would say is that the learning through the years that we have got has led us to create accelerators that has short circuited it. So instead of starting from scratch, you now have the option to actually start from the learnings you've already made. You'll hear a lot more about that when I come back, uh, towards the end of the presentation. Uh, but if you, if I have to summarize some key use cases, uh, it exists across the value chain of pharmaceutical organization. Um, it starts from the R&D, so everything from target identification, hit optimization. There are multiple generative AI models that are specifically designed to understand proteins better, uh, understands molecules better, their bonding sites and things like that. Um, so we are working increasingly hard to actually make these models available as managed services that researchers and, and, you know, lab technicians or scientists can easily make use of. Secondly, once the drug is, uh, you know, uh, optimized and, and maybe a target is identified or a molecule is identified, taking it through the clinical process is also very, uh, suboptimal in the current sense. It's very sequential in nature. It's document heavy. So we've seen a lot of use cases in the clinical space, uh, things like protocol generation or reviewing of, uh, protocol, authoring protocol, uh, finding sites, uh, or patients or matching sites to patients for trials, uh, finding the right, uh, mechanisms to report, uh, any adverse effects or adverse events during the trial. All these are areas where we are seeing increasing adoption of generative AI on. And then when you come to manufacturing, we obviously have use cases that increases, um, you know, yield optimization on the pipelines, finding ways in which we, uh, we find the bad batch, uh, you know, during the cycle as early as possible, reject them so. Automations around that we've seen a lot of success with such use cases in the manufacturing space and then finally in the commercial space where you're trying to find the right market for your drugs, you know, tracking its performance, phase 4 data, real world evidence, all of these are areas where we've seen a lot of success with customers on. So with that introduction, uh, I would like to invite Cassie from AstraZeneca to take you through her journey, uh, with AWS and the clinical development phase. Thank you. Hello, um, I'm Cassie Gregson, um, and I'm the VP for R&DIT, um, at AstraZeneca. And two decades ago, I never would have even considered that I'd be standing here talking to you today. And in fact, back then, I was a research scientist, an apprentice research scientist in one of our early discovery labs at AstraZeneca in the UK. And I always had a bit of an inkling that technology would be critically important and would transform the way that we do our research and development. But what I didn't know, and, you know, we have recently launched, is our bold ambition within AstraZeneca. So our bold ambition, emphasis on bold for 2030, is to be pioneers in science, lead in our disease areas, and transform patient outcomes. And to do that, we'll deliver 20 new medicines by 2030, so that's not application of medicines to existing uh other conditions, it's brand new medicines. Have an $80 billion company. And continue to sustain growth thereafter. I also didn't consider that AI would be so transformative when it comes to helping us to achieve our bold ambition. And so I'm gonna talk a little bit today about how we're using this, um, especially in the development part of research and development. So in my role as global VP for research and development IT, um, there are 3 key areas where I believe that data and AI will truly transform what we're doing. So that's partly, number one, in the speed and the decision making across our R&D pipeline. Secondly, increasing the probability of success, whether that is through identification of new molecules, identification of new targets, or increasing the probability of success for our clinical trials. And then finally, better predicting patient impact. So what I mean by this is identifying those patients that will most benefit from our medicines, really focusing on where we can have the most impact to all of the patients around the globe, across our oncology and biopharma um portfolios. So if, if we think about our incredible science that we have, it's led to a significant volume in our development pipeline. And by development, I mean our clinical research, our regulatory submissions, and our patient safety portfolio, as well as the quality of all of the um research that we do across the enterprise. And so, in 2024 alone, we had 191 projects in our development pipeline. 27 new molecular entities that progressed to the next phase of development, and we invested 13.6 billion in our science. Now it's super critical for us to get our medicines to our patients as quickly as we can, high quality medicines that have a positive impact. And so every minute truly matters as we're continuing to fill that development pipeline um with our life changing medicines. So if we think about data, um, we think about our global clinical trial portfolio. um, and the nature and the complexity of the work that we do across the globe can lead to disparate systems, it can lead to siloed data. And what that means is it can be really difficult to answer questions. Um, so for example, our clinical researchers may be thinking, oh, what's our highest performing sites, which clinical study sites do we go to as we're designing our clinical trials? Now the way that we've done that in the past is manual. It's hours and hours of work, it's pulling data from here, from there, a little bit of data here, transforming that data, analyzing that data, getting some insights. And as I mentioned before, every minute really matters when it comes to getting our medicines as quickly as possible to our patients. And so that's really been a key focus of what we've been doing in the AI space, is how do we accelerate all parts of the development pipeline with a keen focus initially in the clinical trial space, um, but then broadening that out to the rest of development. And this is where the work with AWS has really come in and and and positively impacted what we're doing. So when we look at um our disparate data, our siloed data, what we have done um as part of this work is really bring together all of those disparate data sources, applying contextual ontologies, bringing in all of the agentic solutions, the frameworks and the products that you see here to enable our scientists, our clinicians, um, to ask questions in a very conversational way, in a natural language way. To be able to not worry about where's my data, what is it telling me, but actually focus on the answer so that they can then make decisions about the next phase of the clinical development cycle. And so in partnership with AWS we have built an Egentic powered development assistant that I'm gonna show you a short demo of right now. So development assistant, what is it? Um, so as I mentioned, it's agentic, and I'll go through some numbers in a moment cos the numbers are always really important. Um, but the Agentic powered AI assistant development assistant looks across many different data products that weren't previously connected across our clinical, regulatory, patient safety and quality domains. It allows any user with the appropriate level of access to those data products, which is key when we're talking about regulated environments, to ask any question they have in a very natural language kind of way. So think chat GPT, the kind of ways you interact with that. You'll see from the screen that it shows the reasoning, it shows the data, it shows you where it's pulled that information from, and provides all of the insights in a very simple, easy to understand way that you can then click through to every single um source document, source data product that we have. So you can go back and you can check, is this accurate? Is this telling me the right information? Oh, that's a really interesting insight. I'm not sure I believe that, let me go and understand that. Or you know what, I've found out something brand new today that's enabling me to make that next decision as we go through. So let's talk numbers. I like numbers, I love data. So when we're talking about the development assistant, um, the real key piece here in partnership with AWS really turbocharged what we were able to achieve. In 6 weeks, we went from a proof of concept to an MVP. Reaching more than 1000 users across 21 different countries, this is a truly global technology. We pulled together 16 different data products across that clinical, patient safety, regulatory, and quality domain. There are 9 agents working together, so it's truly a multi-agent system. There are 8 knowledge bases and 7 domains, so all of this together, imagine. You know, 1 year ago, 6 months ago, I would have had to have gone in, find that data, think about my question, answer my question. Now I can just go to development assistant. Hey, how many clinical trial sites do we have? How do I find out this information about this SOP? I remember reading it a few years ago. I can't quite remember what it told me. What can you tell me about a particular phase 3 clinical trial? So all of this information is now at the fingertips of all of our scientists across the globe. And as I mentioned, you know, every minute really, really counts when it comes to um what we're delivering. Every minute. Super important, so every single minute, every week, every day, every month that we can shave off any of our pipeline, enables us to have that positive impact much sooner. But really it's not about data and technology, it's about us focusing on identifying, discovering and developing our medicines for today, tomorrow and the day after, and the patients are truly at the center of everything that we do. And so our focus is to accelerate that with high quality. And once we have that information and we have those um successful molecules, we have um the commercial er the um regulatory submissions approved by the FDA and the other regulators, we then hand that over to our colleagues in commercial. And our commercial colleagues then focus on making sure that our medicines are getting to the healthcare professionals. They're getting to the patients where it's really needed. And so with that, it's a great pleasure that I hand over to my colleague Ravi, who's gonna talk you through the next stage of the pipeline. Thank you very much. Thanks, Cassie. I'm Ravikopalakrishnan. I'm the vice president of Data Science and AI for commercial at AstraZeneca. And my job and my team's job is to kind of ensure that we serve two of our biggest businesses, our oncology business unit and our biopharma business unit. And our job is to kind of make sure that all these wonderful AI accelerated pipelines that our R&D team is delivering, how do we kind of make sure that we, we deliver that to our patients at the right time when they need it the most, right? I think that's our mission in commercial. So to achieve our ambition in 2030, you know, which is like 20 new medicines, 80 billion in revenues, you have to have precision commercial. What do I mean by precision commercial? And why do we need it? Today, as I'm speaking here and we're all here, there are many, many patients being diagnosed with either lung cancer in early stage or breast cancer in metastatic stage. And uh they have to kind of, what do they do, right? OK, they just discovered that they got cancer, so they have to go go through like multiple steps before they get the treatments that we already have that can be life changing. They have to go talk to the right specialist, they have to talk to a surgeon, they have to be tested for biomarkers. They have to kind of make sure that they get all the right pre-treatments before they're eligible for our drug. So that's what we mean by precision commercial. And in order for us to deliver precision commercial, we need to kind of look at our entire commercial organization, which is sales, marketing, medical, market access, work together, right, across three main pillars. One is around helping strategy. Helping, what do we mean by strategy, right? Really understanding our patient pathways, patient journey insights, in depth, understanding our, our HCP behaviors, are they really following guidelines or not? What are their preferences in treating certain patients? What are their preferences in doing biomarker testing? We need to have a complete understanding of all that. Are they following guidelines or not? Are there care gaps because of not following guidelines that are severely impairing patients? And then who are the, who are the influencers in like HER2 + biomarker treatment or who has done the most research, right? Who are the influencers that we should engage to kind of spread the word. So that kind of help informs the strategy for like every new drug, every new indication that we deploy. Second aspect of delivering precision commercial is around planning. Who do we, who do we engage with early on during the launch? Who do we kind of engage with? Who are the, who are the early adopters and who have, what is the propensity of HCP to kind of prescribe our drug versus some other treatment, which is not against, which is not like following the guidelines. And then things like forecasting to enable how we grow our business across the business team, right? So all this is like current planning. And then the last mile is all about executing, right? How do we provide subnational territory level insights to our field representatives? How do we provide the right level of digital and marketing and media investments to our, to our, to our marketing colleagues and our agencies? How do we create the right content that's highly personalized and delivered on the right channel to the physicians and patients at the right time? So, I mean, these are all 3, unless all these 3 things work together. You can't really deliver precision commercial at scale. Now, let's see, what do we need to do to deliver precision commercial at scale. I think we need an enterprise grade platform that, that is running on top of a unified linked data foundation. And then we have to hold, we have to kind of invest in a lot of different ways to kind of answer different types of questions. So we, we embarked on this journey of building a platform that we call EasyBrain. And we didn't start with technology. When we thought about the AZ brain, we didn't start with technology. We actually talked to all our users, our field teams, our MSL teams to really kind of understand their story. I mean, what do we, what do they really need to kind of ensure that our life-changing medicines gets to our, gets to the right patient at the right time. So we started with the use case very intentionally across everything and then started building the components to kind of deliver on that use case, to provide the right level of insights. So there are 4 key components to this, to the Ay Brain platform. The first thing is a solid data foundation. And data, as you know, as you all know, is like extremely siloed, and it comes from so many different sources. So you have like claims, multimodal claims, and EMR data which gives you all the real-world evidence insights. Then you have our own market research data. We have a lot of conversations with doctors. We have a lot of domain intelligence on our doctors and, and our patients. So that's captured in some of the format. Then we have all our medical research, clinical trial reports and publications and We have all these big events like ASCO and ESMO, where everything is kind of published and a lot of people are speaking about new data and all that, right? So that's all coming in as well. And then there are NCCN guidelines, which continuously gets updated to kind of ensure that doctors need to keep up with it, right? So I think for precision therapy, the rate at which the NCCN guidelines are changing is like astronomic, right? It's changing like every, every few months. Then we have all our internal data, right? It's all our internal domain knowledge and our interactions with HCP through our CRM systems, and all our digital engagement systems. So, so we bring it all together, build a solid data foundation. And then the next step is a whole host of AI models and services, right? Again, those are all again use case specific, based on understanding patient pathways, lines of therapy for oncology. And then we use that to kind of predict patient eligibility for a particular indication or particular drug, patient progression across lines of therapy, how patients are going to respond based on their personal characteristics. So there are a whole bunch of predictive models as well as a whole bunch of AI classification models, again, use case specific to guide our field team, to guide our marketing team, to also guide our, our, our overall kind of strategy and planning team. And then it's no good if you just have models. The models and the insights from the models, whether it's predictive or otherwise, need to, need to be delivered to the right users with the user experience that is easy for them to kind of make decisions on or take actions on. So that's why we build a whole, whole suite of products. So products can either be stand-alone applications, like what Joel said, or it could be embedded into workflows. For example, we have this thing called, we started a thing called predictive field triggers where a patient is going to show up to a doctor with certain symptoms because they've progressed from one line to another line that will make them eligible for our drug. So we provide this insight through real-time notification. To our field teams, so they have to have some water. And then they act on that. And then have a meaningful, timely kind of conversation with the oncologist, because they know that the patient is going to show up, showing like that the patient has progressed. So that's the level of precision around triggers. Uh, that's one example of a product, right? And then we have a whole host of products for Our headquarter teams, our medical teams, our market access teams. So, so there are a whole host of users and persona, right? So, so this So one is to build a platform and a whole host of products for like one therapeutic area, right, for lung cancer. Another is how do you kind of scale, right? So I think this is not just about building a platform that works only for one therapeutic area or one medicine. So scaling is a very important aspect, and that's the whole concept of platforming and building reusable components. So scaling in multiple dimensions. You have to scale across multiple tumor types. For oncology, multiple disease areas and biopharma, multiple biomarker type therapies in across both. So that's one dimension of scaling. So as part of this, and based on the use cases, We've developed 100, 500 plus experiments. Not all of them were needed or if it's like maybe half of them into production. They're all running. They're all being maintained. They're all being continuously retrained, and that's what will get us to kind of. Uh, ensuring that every patient gets access to the right medicine at the right time. And we have to scale it across disease areas, and we have to scale it across markets. We started in the US and now we have scaled to all of you can, then eventually to, to Asia and, and South America. So, so far, what I've talked about is foundational AI capabilities, right? And so, so I think now the next step that we've kind of embarked on for the last two years is to build agents. And agents essentially, so you're moving from AI driven insights into actual agents, performing tasks, orchestrating and automating workflows, and making a whole bunch of decisions on behalf of each of our business personas, guided by the human in the loop. This broadly falls into like 5 different domains. First is an agent around insights generations from real-world evidence data. Our medical colleagues are constantly mining through like lots of publications and data and manual analytics to kind of get to that. Second is, uh, around content, Everything around how do you have more agility in the type of promotional content, medical information content to kind of create it at a rapid pace and go through the, the reviews. And then third use case around this where we've seen a lot of value is around reimbursement dossier authoring, right, to get approvals for a drug in a particular market. That's a pretty laborious process too. So, so we all of a sudden, where we think agent TKI can help is around like automating some of these manual processes that used to take months, bringing it down to weeks. Same thing with like market research, heavily manual process, right? If you have a new TPP for prostate cancer. It takes about 3 months and a lot of resources, expensive domain knowledge of people to kind of actually create views like market share and, uh, and kind of that, that's kind of used to do forecasting and all that to see whether the TPP is ready to go to market or not. Same thing with our marketing team. So I think there are a whole host of workflows that can be automated through agents. So, so let's see where we are at. So we've been on this journey using. AWS ecosystem for a while, right? So, so these are all some of the agents inside IQ is an agent similar to the commercial assistant that Cassie showed that's used by the commercial colleagues that perform certain tasks. Again, it's a collection of about 20 plus agents that queries, cross, and interrogates all the different data sets and then the models and the documents and the guidelines to not just like answer questions but actually give you very concrete recommendation. At an N equals 1 level. We say N equals 1 is because every HCP, every patient is a very unique combination for targeted therapies. So I think that's the level of insight. And what we've seen is like amazing results. People who use this and engage with it generate 2 times more scripts, that's contributing to the revenues, plus reaching the patients. So, so that's a good, good learning. This is in production now being used by pretty much all our, uh, lung franchise teams to kind of drive a business. The second is around dimension content life cycle. So we've built this, this suite of agents that takes complicated scientific literature and tables from a whole bunch of approved publications and documents, and then it has to format it in a way that's very specific for regulatory authorities to kind of accept so it has to fill in. template like Germany has got one, Canada's got another, US got a third. That used to again take many months and a lot of resources to actually get because if you don't do that, if you, the more delay you have in getting approval for this, the more delay you have in. Getting patients access to our drugs. So it's, it's a super important thing here. Same thing on market research, like I mentioned, you know, we, we went from like 3 months to go from a TPP to To market share estimation and forecasting and preparing for commercial two weeks. So that's again the power of agentic AI here. Uh, so anyway, I mean, I think these are all some of the things that we've kind of worked on a lot of learnings along the way, but I think what I want to kind of say is in order to. Achieve our ambition 2030, which is we have a bold ambition. Cassie talked about it. $80 billion in revenues, 20 new medicines, transforming patient outcomes along the way. I mean, an ambition alone is not enough. You need precision. You need precision. Every patient, every HCP needs to be treated differently. And that's where AI and agent EKI kind of helps. So AI helps with the breath. Agentic AI helps with speed. And then we have our people who have a purpose, right? I mean, I think the combination of all these three things together is what is going to help us, our bold ambition. And along the way, transform care for patients. And another big bold ambition is to eliminate cancer as a cause for death. Thank you. Thank you, Robert. So as you heard, I mean, uh, this is a really bold ambition and, and to achieve such things, um, at, at scale and, and the platforms that AstraZeneca has been building, uh, it really. Comes back to the points of primitives and, and what are the specific technology assets that needs to be created that would support AstraZeneca in, in the journey that they are on. So what I'm gonna do right now is to bring it back to some of the key components that we have launched either recently or during the very recent past or, or, you know, is something that we are actively working on. Uh, and, and our ambition actually is to be the best place to build agents, you know, that is where, uh, our North Star is, and it's a very wide goal if you think about, uh, the, the ways people are building agents today. It includes a variety of different frameworks, a variety of different infrastructure deployment architectures, um, orchestration models, tooling, standards, and, and it's very important for us to understand each of these different patterns and translate them. Into services that allow for these to be executed in a manner that you don't feel the heavy burden or undifferentiated heavy lifting of taking these use cases into production. So what I want to start with is Bedrock Agent Core. Uh, this was a service that was, uh, unveiled at our New York summit earlier this year, uh, has been generally available, uh, for a few months, and we have seen amazing response from the audiences just because of the way in which Agent Core makes some of these, um, capabilities available to developers. So it provides a very secure runtime. So that's the first thing that Agent Core provides. With run time you would be able to deploy these agents at scale in isolation. So that's also very important. Uh, infrastructure level isolation is, uh, something that we, uh, continuously, uh, hear from customers a requirement, especially for regulated industries where you're trying to make, make sure that an agent can actually run in a very governed manner as far as in deployments architectures is concerned. It provides a virtual gateway that allows you to access external tools. So these tools could be either from our marketplace where we have a variety of agents listed from third parties, or it could be agents that you build and make available via architectures like MCPs, uh, you know, simple functions or tools that can be wrapped into a container, a variety of ways in which agent core enables that. Uh, it has a very unique way of managing memory. Um, you know, it's preserves both short-term in context memory as well as long-term memory and has very intelligent ways of unloading and offloading those memories between, you know, various storage mediums. Um, it also provides authentication, identification of these agents. In a lot of cases you might have seen patterns where a certain orchestration step requires you to authenticate against a database, um, like in the example that we saw earlier around clinical development agent, there were questions that were being asked by end users in natural language that were being translated into actual sequence. Queries uh that were run against the database to build that workflow end to end you need various steps of authentication. You need to understand how the user, uh, or what kind of, um, you know, access the user has, uh, does he have access to actually go and get information from that database? If he does, you know, how do you manage the authentication of that query into the back end? All that is actually heavy engineering work that Asian core identity solves for you. So these are some of the primitives that we've been like working um uh around to make uh Asian Core more suitable for these kinds of production use cases. In addition to the Agent Corps being available as a service. Um, earlier in the year, we unveiled something called an open source toolkit for healthcare and life sciences on AWS. This toolkit is actually a set of, um, templates, examples, uh, deployment scripts that are all available in an open source format under MIT Zero. So you don't really, you really need to sort of uh pay anything to get access to this. And what this allows you to do is basically get started very quickly. So even though, uh, you know, many of you in the room may be familiar with what Asian Core is, it's still a learning curve, you know, we continuously launch so many new features and capabilities into our stack. Uh, it's very hard for developers to keep up. So what we are doing on our side to make it, you know, slightly easier for the developer community who are in the healthcare and life sciences. Space are we are identifying some standard data sources or standard agents where you know it's almost necessary for some of these use cases to exist and we are taking the burden of creating a template so when you actually have to develop something similar, you don't have to start from scratch. This is obviously targeted most. Towards developers, developers who are very comfortable with our APIs, um, comfortable with code, uh, extending code, deploying it themselves, uh, and it creates a mind share. So if you are like, let's say experimenting with a few use cases, you can easily clone this repository. You can look at these examples in a sandbox environment. And you can extend it, uh, we're always seeking contributions to this repository from developers. Uh, we've seen excellent response to some of the use cases that we've already made available, and this is again something that we'll continue to maintain as Agent Core evolved so you don't have to keep up with every new addition that the platform is adding. Uh, so this is one effort that we are actually behind, um, in an open source way, in a, in a community driven way. Uh, so that more and more of such use cases can see, uh, production deployments, uh, quickly. And if you see the toolkits divided into supervisors. Supervisors essentially means, um, you know, uh, a set of orchestrator, uh, with access to certain types of tools. So for example, the R&D, uh, supervisor or biomarker supervisor. Actually has access to information on molecules, around clinical trials, around research, um, and all of this is available to the orchestrator. So when a user asks a question, they will be able to orchestrate across each of those supervisors, uh sorry, sub-agents, uh, to get to the answer. Um, similarly, the clinical, uh, supervisor actually has access to a lot of information that would, that would help it design clinical trials, review clinical trials, uh, look at inclusion, exclusion criterias, compare trials, outcomes, and then, of course, in the, uh, content, uh, sorry, uh. Yeah, content supervisor agent actually allows you to take all of this information, generate reports um for submissions, uh, search through competitive analysis and things like that. Now, while the open source toolkit is a great step in which we have seen uh developers respond and create sandbox environment and get started with, I think there's still this journey that once you get satisfied with the use case, uh, you have to make, uh, or a certain set of steps you have to, uh, take to take these agents into production, and these includes things like compatibility to your existing SSO or how do I manage these agents at scale while. Developer productivity is extremely important to get started with these MVPs and POCs. Uh, the real value comes when you actually can scale them at production grade. Um, there are questions about what orchestrator architectures could you use, right? So that's another thing that we see a lot of customers ask. Now in our effort to actually provide an answer to these questions, obviously there's no right or wrong in terms of which frameworks you choose because your end goal remains the same. But a point of view is extremely important because that grounds you into something that you can get started with and move into production, uh, with the trust that AWS brings to the table. So what we've been doing on our side is taking all of these questions and trying to see what we can do better in terms of just, uh, providing these assets, um, to, to customers. So what we recently, uh, launched was the ability for certain set of these use cases to be packaged up as assets under various. categories that you see over here and make those available to you uh in a more production ready sense. So instead of just working directly like if you're a developer who loves to sort of experiment with code, uh, you can start with the previous GitHub repository that I, uh, showed you, um, and then if you're like someone who is more into maybe creating a consulting engagement or a. Customization engagement for these use cases we have packaged them in a way that's very easy for you to do, you know, work with our, uh, consulting teams or even with your own engineering teams, uh, to deploy into production because we have, you know, gone a little, uh, ahead in terms of taking those certain use cases that we've seen great response to and made those available inside, um, inside the. Uh, inside the portal. I, I know there might be some questions, so if you can save them, uh, towards the end, so they can get through the content, and I'll address them. So, here's how things look like, you know, in terms of workflow. So if you are a native builder, you know, we have a lot of AWS services. We saw great launches, um, throughout the week this, uh, in, in at reinvent. Where we have got services like QuickSuite, Agent Core, um, you know, Kiiro with all of its additions with gente capabilities for you to get started with. So we are very, um, accelerated in our investments in that space, uh, creating capabilities for developers to quickly start and, and experiment on their own. Now, in addition to what we are doing in the, in the entire AWS stack, uh, a team of us are forking that stack and making it very specific to life sciences and healthcare. So, every pharma customer you saw a stat earlier that 95% of the top 20 pharma customers work with us. On such problems, uh, so that has allowed us to get a lot of feedback and that has led us down this route of packaging some of these services very, uh, in a very specific way for certain types of use cases, uh, for the developer community. So that's the middle ground where the AWS open source toolkit for healthcare and life sciences allows you to do. And then finally, the bottommost layer is where the portal comes in, where you'll see a proper set of use cases where you can select from them. Uh, and then once you are, um, you know, ready to actually go further, uh, you can, you know, go ahead and deploy them into production. So this is how now the stack looks like, uh, after all these new additions. So on the bottommost tier we have our infrastructure, you know, that includes our containers, uh, our newly announced ranium 3 chips, um, our ability to fine tune and train these models, which is extremely important for regulated industries and domains like healthcare. In life sciences, uh, we've obviously made a lot of investments in that layer, uh, not only from an infrastructure perspective but also APIs that allow you to take that infrastructure and fine-tune pre-trained models. You heard about Nova Forge, which is a great technology for domains like healthcare and life sciences, uh, that allows you to actually, you know, update these model ways and blend them with your own data and make use of that specialized model, uh, that truly creates differentiation for you as a customer. Uh, I always get that that if everyone has access to the same model, how do we differentiate and, and the real differentiation comes from your data, uh, but the problem so far has been that the data has only existed either through agents or through rag applications, which is great, but now we have the ability to actually make that data right, uh, rightly available at the pre-training phase of the model which really creates differentiation in terms of the specificity that you get into some of these use cases. Now on top of that, uh, we have the development, uh, services like these includes our specific models, our capabilities around guard railing and optimizing these models. We obviously have agent core, uh, that allows you to actually build these agents at scale and then, you know, these are all integrated into a variety of different capabilities that make use, uh, of these frameworks for specific use cases. Now, in addition to what I, uh, showed you in terms of. Our, our baseline stack, um, you know, the, the life sciences specific things that we have added into this is the toolkit, uh, and then of course, the AI portal that I was talking about earlier. So we are very excited about the response that we are getting in some of these uh use cases. We're seeing great uh demos being created. Uh, we have seen academic collaborations like, um, you know, uh, the, the Stanford project like Bomni, uh, is actually now available in, in one of these toolkits. So if you are in the business of actually going and looking through literature or trying to find details about a molecule. Uh, or querying the TCGA database for certain oncology related questions, they're all available as MCP servers that we have made available via this toolkit, uh, and of course, like, you know, you can blend this all with your own data sets, your own assets, your private molecules, because this is all running within the confines of your account, never leaves your account, so it's very easy for you to keep building, you know, very specific workflows that go deep into the domain. If you want to know more about these accelerators, you can go to this, uh, QR code. It'll give you a contact us form. It'll allow you to explore more, uh, look at the portal different use cases, uh, and, and we would love to work with you on some of these. And if you're sticking around, there's still time. You can go to our pavilion. We have an extremely good set up this year. Uh, we have a demo for, uh, AI powered lab in the loop that takes you through an exercise of an in silico, uh, uh, you know, molecule optimization right from. Uh, hit optimization all the way into clinical and going into the lab, uh, and then we also have a healthcare demo, uh, that takes you to a journey of a patient right from, you know, scheduling an appointment to the care delivery. So we'd love for you to go check them out and if you have any questions, uh, we'll be around and, and, you know, happy to take them. Thank you.