---
video_id: 2w2vCdiOleI
video_url: https://www.youtube.com/watch?v=2w2vCdiOleI
is_generated: False
is_translatable: True
---

Hello everyone. My name is Girish. I'm a senior solutions architect. Along with me is my peer SA Justin, and the two of us help AWS customers move all the way from ideation to production with a special focus on AIML. Over the next 60 minutes we are going to learn a few things. We'll kick things off here by understanding four key concepts that we are going to leverage to build this agent factory. From there we'll move to a coding terminal and start creating some business agents, and then we'll interact with the agent factory itself to create some agents, multi-agent systems on the fly for you. I want you all to think about one business agent that might be valuable for your organizations. We are going to take some requests and try to create those agents on demand here as well. If you have any questions, please raise your hand. We'll try to take as many questions as possible, but given the time constraints, if we aren't able to get to you, we are absolutely going to stay back here to address all your questions. We are also going to be sharing the code base with you, so to get the most out of the session, I recommend just thinking about the why behind things, and you can clone the code and you can try things yourself at a later time as well. So with that, let's get going here. So our agent factory is going to have what we call a builder agent. What the builder agent does, it will take a request from a user and then create either a single agent or a multi-agent system on demand. But what really is an AI agent? I spoke to a few of them here and still there's some confusion about AI agents, right? Everyone has their own definition. I think the simplest one that I've heard is an agent runs a loop with a model and with a set of tools to take certain actions to achieve a particular goal. And to build these agents we require a framework. In this case, we are going to leverage the open source strands SDK for three key reasons. One, strands makes it really simple for us to create agents with just a few lines of code because it depends on the intelligence of the frontier model to create the code for us. So instead of writing rigid logic trees, it will do that work for us and we tell it what agents to create. 2 strands comes with its native set of tools. So the most common tools that an agent might require, those are already built for you, so we can directly start tapping into those tools, but it also makes it really simple for us to create custom tools. And 3, strands has native support for some of these emergent protocols. So think of MCP and A2A, and our agent factory is going to use those protocols as well. But what really is MCP or model context protocol? So for our agent to talk to different tools and different data sources, there needs to be a common language between them, and that is exactly what MCP provides. You can almost think of MCP as a universal translator, where it provides a common language for agents, for tools, and for data sources to connect together and work on things together. But what if our agent factory receives a request when it needs to create a multi-agent system where multiple agents are talking to each other and working together to achieve a higher level goal? And for that, we are going to leverage what is known as A2A or agent to agent communication protocol. A2A will provide us three different things. One, it allows an agent to discover other agents around it. 2, it allows an agent to know the capabilities of the agents around it, so it knows which agent to ask for help whenever it's trying to achieve a particular goal. And 3, it gives us a common language for agents to talk to other agents. So despite all the models or frameworks that different agents use, there's a common language in between that they can use to communicate with each other. OK, so until now we have learned three things. One, our agent factory will use the strands SDK to build agents. 2, it will use MCP for those agents to connect to different tools and to connect to different data sources. And 3, our agents will use A2A to connect and talk to other agents for more complex goals. But how can we take our agent factory from a prototyping environment all the way to production? And for that, we are going to tap into Agent Core, which is a purpose-built service for running Agengen systems at scale, securely and in an operationally efficient manner. It provides us with a set of modular services that we can pick and choose from based on the requirements of a particular agent, and this might really look like a busy slide, but let's think this through together, right? Whenever our agent factory receives a request, it needs to deploy those agents and run those agents somewhere. So what does, what does the agent factory need for that? One, it needs a place where it can run the agents in a secure environment, ideally serverless, we don't want to manage the infrastructure ourselves, but there could be situations where an agent needs like 3 minutes to complete a particular task, but there could be like long running agents which require like 5 hours to run, right? And so the serverless runtime should support like small, like small term tasks as well as long term tasks, and that is exactly what the agent called runtime will provide us. But once we move things from a prototyping environment to production, security will become even more important. And for that we are going to tap into what we call the identity feature which will do a couple of things for us. One, it will ensure that only the users who are supposed to have access to our agents, only those users can access the agents, and two, the agents themselves can only access the tools that they are supposed to, can only access other agents that they are supposed to. Our agents are only going to be as smart as the things they can remember, and for that, we are going to use the short-term memory and long-term memory provided by agent called Memory Feature. For some agents which require to write their own code to execute that code as well, we are going to leverage the agent core code interpreter feature, and there might be some agents which need to browse the internet, go on the internet, fill the forms for us. For that, we could use the browser tool which provides us a really secure environment to access internet at scale. One of the key features of our agent factory is going to be what is known as an agent core gateway. It does a couple of things for us. Agent core gateway allows us to have existing lambda functions or new lambda functions and expose them as if they were MCP tools for our agents. So say for example, our agents now can connect to a gateway and the gateway talks to lambda functions or APIs so that we don't need to manage those APIs or create MCP servers ourselves. The gateway will expose them as if they were MCP servers for us. And finally, to make sense of everything, to know why a particular agent did a particular thing, or to know how to troubleshoot issues, we are going to tap into the observability feature of Agent Core. OK. So now we know we are going to have a builder agent. Its role is just one thing takes users' requests, creates an agent or a multi-agent system for us. This builder agent is built using strands. It's deployed on agent core as the infrastructure. The builder agent will have access to 3 different tools. One tool to create lambda functions. So these are the tools that our agents will use to take action. The second thing it does is it has the ability to create gateways on the fly and to associate those lambda functions with the gateway as MCP servers, and thirdly, it can create and deploy the agents themselves. So once it deploys these agents, these agents will work within the agent core environment. It will access different tools like Slack, Salesforce or any custom tools that you might have across the gateway, across the gateway, and that is how the agent factory will work. OK, so now that we know a little bit more about the agent factory, let's move to coding here. You can just turn it on. Sweet, which is Can you all confirm that it is large enough for you all to see? OK, cool. Uh, so the very first thing that I want to show you all is a simple chatbot, right? What I'm trying to show you is how easy it is for us to create these chatbots or agents using strands. To create a chatbot with strands, we need just 3 lines of code. One, I'll import the agent class from strands. 2, I'll then create an agent function. And 3, I just trigger that particular function, ask it what reinventors, and as you can see, it came back with an answer. So that is the power of strands, like it just takes you a few lines of code to create an agent and to deploy that agent as well. But there will be times when we need to select a particular model, right? In the first case, what happened was we used the base, the default model. In that case, it will use cloudsonnet 4.0. But if I wanted to use a particular model, all that I need to do is I'll import Bedrock model from. That is the difference. 2, I'll mention what the model ID is. So in this case you can see the model ID is Nova Premier, but tomorrow, say for example, if I wanted to use lamma from Meta, all that I do is I change the model ID here to lamma and run this. It gives me the ability to control randomness or the behavior of the model in terms of temperature and top P, as well as if it's a chat-based application, right? You can enable streaming for it. But say, for example, tomorrow, OpenAI creates a new model, an open source model, and we wanted to leverage that model, right? All that I do is I switch the model ID. The rest of the agent cord stays exactly the same. So this gives you a lot of flexibility to model whenever new models come into the picture, you can keep the same agent cord. All that you do is switch the model ID. We are also going to be providing you 3 different files, so if there are situations where you want to consume a model directly from Anthropic as the provider, so Anthropic provides models on Bedrock, of course, but if you wanted to consume it from Anthropic, that's an option on Strands. If you wanted to consume a model directly from OpenAI, it supports that as well. And for some situations, if you wanted to run a local model, it supports OLAMA, so you can run a model within your environment instead of running it on the cloud. But like we discussed, a true agent is what has access to model as well as a set of tools to take action on our behalf. And now we'll start interacting with agent tools. The first thing what I'm going to do here is I want to show you, say for example, our agent factory got a request to create an agent which can browse the internet, find what AWS released last week, create a news briefing of it, and then upload it onto an S3 bucket. So the difference in this case is I'm going to import some tools from Strands. Strands provides a set of various tools, and we'll give you access to what different tools it supports out of the box, but HTTP requests will allow it to access the internet. Use AWS will give it the ability to use Boto 3 library so that it can interact with our AWS environment, and current time gives it an understanding of what date and time it is today, so it goes back a week and finds what AWS released. From there, I'm using Anthropic as the model ID in this case for creating the agent. I'm giving it a system prompt where I say, hey, you're a news anchor specializing in finding AWS news and going to the internet, and then finding the news, creating a news summary of it, and then uploading it onto an S3 bucket. So that is my system prompt. The difference here is the tools that are imported. I'm telling it to use those tools for doing those things. And then I invoke it, right? Like, hey, what's the latest AWS news? So now the agent is able to understand the request, take action on our behalf. So what you can see is it first to use the current time tool. Then it used the HTTP request to find the latest uh AWS announcements, and then it is using the use AWS tool to upload that to S3 on my behalf. And here it is taking my permission. There's ways for us to automate that as well. But I'm saying, hey, it's OK for you to go ahead and create this put object request. I say yes to it, and now if I go to my S3 bucket. And refresh this. You will see, it has created. A new file And it created a news. Briefing for us. So that is the power of agents that can take action on our behalf. This could have been something which is more logical to your business, but the key thing here is give it access to a model, a set of tools, and let them do the work on our behalf. OK. So the next thing I want to show here is What if our agent factory receives a request wherein it not just needs to create new agents, but it also needs to create custom tools outside of what strands provides, but build those tools on the fly based on what the user request is. So what I'm doing here is I've created an agent which can create different tools for me. I just ran that agent. I'm going to ask it to create a tool that can calculate compound interest as an example. And let's go through the code here for a minute. The only difference here than the previous thing is one, I'm importing editor from strands. This will let it write code and execute code on our behalf. And then I'm telling it, hey, go ahead and create new tools. Add those tools within a particular directory, the tools directory, but also how to load those tools so that I can start using those tools immediately. So again, it went ahead, it is now asking for my permission here to make a right operation within that particular tools directory. So let me open that tool, compound interest tool. So this is very similar to a Python function. Yeah, please go ahead. So the question I can repeat it is uh we're we're running these tools locally generating these tools locally and then if we were to deploy this to Agent core how might how might we create those tools correct, uh, so that is going to be the next phase. So what we are doing here is running and creating these tools locally. The next phase is going to move it from our local. A Corp and it will use the same logic there. So our agent factory takes a request, it creates a particular tool or a set of different tools, then it creates a gateway associates those tools with the gateway, and then it creates an agent to give it access to those tools. So that will be the next thing we'll do here today. Does that help you? OK. Any other question? OK. So as you can see, it went ahead and created this tool for us. The only difference is the A tool decorator. Everything else is just a Python function. So that is the power of strands. You can have your existing or new Python functions and expose them as tools with the Ad Tool decorator that your agents can use to take action on your behalf. So if I now go ahead and ask it to calculate the compound interest as an example. It knows it has a set of 3 different tools. It identifies the right tool to calculate the compound interest, and then it goes ahead and calculates that on our behalf as well. This is known as meta-tooling. We are going to use this concept within the agent factory where it can create other agents and other tools on the fly. OK. So the next thing I want to show you all here is what if our agent reward was required to access NCP servers. So the example that I'm using here is I'm creating almost a solutions architect. What it will do is it will have access to the latest AWS documentation. So if something was launched yesterday, it is within the documentation. It needs to go ahead and find what that thing is in the documentation. And then I'm going to give it a request to calculate the total cost of ownership for hosting that thing on AWS. To keep things simple here, I'm creating a static website and I'm telling it, hey, host this on S3, have a cloud front in front of it, and tell me how much it would cost me to host this on AWS. So the difference here is that I'm going to make this agent as an MCP client so that it can access different MCP servers. 2, I'm giving it access to read and write files because I'm asking it to create the TCO calculations and save that file on my local machine. And 3, I'm making an STDIO client as well, so that it can interact with those MCP servers from my local machine. I'm also giving it access to certain access keys, and that is only because the pricing MCP calculator requires access keys access, but that is not always the case. Everything else pretty much stays the same. I'm giving it a role here in the prompt. Hey, you're an essay, you can write files, you can read files, you can find the documentation of different things, and then you can go ahead and serve the user's request. So in this case, let us see what it did behind the scenes. So the first thing that it does is it installs different MCP servers. Then it finds the different tools that those MCP servers provide, so read documentation, source documentation, get pricing information. Then it finds, then it actually takes the action, right? So it is now finding the pricing for different things. It is finding the documentation for different things. If it runs into an error, so in this case, it wasn't able to find data transfer as the pricing code, it will self-correct itself and it found the right code and it went ahead, took my permission. Hey, can I go ahead and write this file? I said yes. And now, I see a new file being created, which has the TCO calculation of hosting a static website along with links to those documentations. So this is how you can create MCP clients and have your agents work with MCP tools. I see a question there. Yeah, so. What An interaction with the clo the server. How does it manage the context or what if the Turn the whole panel here and how does it manage the conflict. Doesn't blow up in the outline. Did you get that question, Gish, so the question was how do you manage the, the context when they're coming back from the MCP tool? Uh, so within strands like we have provided functionality where it knows how to manage the context with MCP servers, so you don't need to create that logic yourself. All that you do is you create the MCP client, give it. Access to different MCP servers that you want and then it will take the right information like we have added for example limits in terms of how much it can access, what it can access, so it does not flood your context window so you don't really need to spend a lot of time on managing it. That logic is built into it and it can do that on your behalf. Go ahead. Yes, let me do that now. I did see that explanation. You give the qualification. Correct. So in this case, can, can you repeat the question? Yeah, I think the question is about the, the tool documentation that you provided in the code versus that living in the MCP server. Correct. Uh, so the difference is one, like it needs access to the latest documentation, right? So instead of using, so think of tools more to take action versus MCP in this case will give it access to the latest documentation if you tap into the MCP server for documentation. There's another MCP server for pricing. So rather than creating those tools yourselves, we have built those MCP servers for you so that you can start consuming them. So there's an MCP server for taking API action. There's an MCP server for pricing. Different services have their own MCP server. So based on the agent, what it needs to do, you can give it access to the right MCP server, and it can interact with it, find what's the latest. You don't need to manage those. You just create the agent and have the agent interact with it. OK, we'll, we'll take some more questions after the session. I think we need to make sure we're continue moving forward. Just hold on to it. We'll, we'll get it, we'll come back to you. Uh, so the difference in this case is I created those MCP clients. I told it, hey, connect to the pricing server as well as the MCP server, and this agent is now able to do that. But what if I wanted to create a multi-agent system which can have multiple agents working together, which could be a common requirement for our agent factory, right? So in this case, what I'm going to do is let me show you the architecture for it. I'm creating an HR system. It will take a user's request. I'm asking it to host an HR agent locally on Port 8000. It talks using A2A to an employee agent on Port 8001, and it uses an MCP server to get, it's almost like a database to get employee data. The request that I'm going to make it is, can you find me which employees can help me on a particular machine learning project? I've given it a database of different employee names with different skill sets, and it needs to identify who those right employees are. So I'll make a call request here to trigger the HR agent. Let me go ahead and do that. And while it does that, let me quickly show you what the code is. So for the HR agent, I'm making it an A2A client. So I import the A2A client provider. I tell it this is the URL that you are supposed to be hosted on. For the employee agent, this is an A2A server, so I'm importing A2A server instead. I give it the, uh, give it the URL it's hosted on, as well as I tell like, hey, this is the MCP server URL that you have access to. And this is just some Python file that I've created to replicate a database. These are the first names of employees, these are the last names, and these are the different skill sets that those employees have, right? So let us go ahead and see what the call requested. It sent a request to our server. It found what different employees have, different skill sets, and then it recommends, hey, based on what machine learning requires, the frameworks and the technologies, like these are the set of employees which are the right employees for us to work with. OK. So the final thing now I'm going to show is taking this to Agent Core now. So I'm going to deploy this particular server to Agent Core, and let me go ahead and do that. So I've installed the Agent Core CLI. I'll have it I'll have it deploy. To agent call for us. Do you ever get nervous with someone looking over your shoulder as you type? Garish is feeling that right now times about 100. OK. Asian car configure. Miss E. And I'm giving it that agent's file. I'll show you that file as well. OK. So what this will do is it will ask us what we want to name the agent, let's call it HR agent. It's asking what requirements to put into that particular agent. I've given it a requirements file, I give it what Python version to utilize, what is the execution role, I just use the defaults for it. And then it is asking me if I want to give it a memory. I give it memory as well. And I go ahead and launch this thing. OK. So what, what should happen now is it will go to the agent core file that we have created. The only difference between a local strands agent and agent Corp is 3 different things. One, I import the Agent Core app. 2, I create the agent core app, I define it. And 3, what I do is I put in the at app decorator. So this is what my entry point of the agent is. So whenever someone triggers that agent, this is the code that it is supposed to run. Everything else that we have been creating with strands stays exactly the same. OK So now let me move back to the terminal. And show you what it is doing. So what it does is it's creating the Asian core. Runtime here, it created different roles for us, it created memory for us, and this can take a couple of minutes. Uh, it is creating, uh, uploading things onto S3 after it's created the role, and now it is launching things to Asian core. And this is exactly what our Asian factory is going to utilize as well. So to see all these things being automated, let's move on to the Asian factory, and we can show these things in action, how we can automatically create and do all this work without writing that code. And for that, let me pass on to Justin here. OK, great. Well, thank you, Garish. So just to recap what we just saw, we saw a lot of stuff, right? We saw things like strands and how you can use strands SDK to build agents. We saw MCP servers and how you can configure MCPs on those strands agents. We saw A to A and how you can configure a multi-agent system using A to A clients and A2A servers. And then the very last thing we saw was how can we actually take all this and deploy it to production using Agent core. Now we have to ask ourselves the question, and that question is, is there an easier way to do all this? Gari just wrote a ton of code. He wrote it ahead of time, obviously, but ran through a bunch of code. It's a ton of work to still create all these strands agents, create all of these different tools, and is there an easier way? Is there a way for us to maybe use an agent factory or a builder agent that we could speak to a natural language and that agent could build agents for us on the fly from scratch according to our requirements and then deploy them securely and scalably into agent core runtime. And that's what we're gonna take a look at now. So Garish and I are going to do a little bit of role playing. And I'm gonna play the role of the company AI guru, so I'm the guy that everyone comes to to build their agents, and I'm always up late working at night getting these random requests from people to build them some random agent to help them with their business task at work. All right. So it's a late Friday night. I'm ready to get off of work. I'm super tired, and suddenly I get a call from Garishish. Hi, Justin. I know this is late Friday night. I have one last request for you. We have a really important board meeting on Monday morning. Can you please create an agent which can help us make investment decisions within different industries? I promise this is the last thing I have for you. Sounds good, Garish. All right, so it's 7 p.m. on a Friday. I wanna go hang out with my friends, but now I have to make a decision. Am I gonna build an agent from scratch using strands and agent core and do all of this coding and programming, or am I gonna use an agent factory to help automate a lot of that process and deploy that agent for me? And so I'm gonna pick the second option so I can go to sleep at some point tonight. So what I've built here is just a really simple CLI application that we can use to interact with our builder agent and that's what we're gonna call it. Our builder agent is kind of the key to our agent factory. So I'm gonna go ahead and just type in one here and I'm gonna kick off a agent creation. I'm gonna just say create me an agent that can perform risk analysis. Using a tool to determine risk by industry vertical. And we'll kick this off. Now the builder agent's gonna be thinking here it's gonna be doing things like crafting the system prompts for this agent. It's going to be building that tool that it needs to do any of the business logic and then deploying all of that to agent core. So while this runs rather than just stare at the screen, let's go ahead and take a look at some of the code under the hood of what's actually happening here. And we're gonna make all of this code available to you after the session, but just to take a look together, I'm gonna go into the builder agent folder, and this is sort of the heart of the project, which is this builder agent.P file. So let me make this a little bit bigger for everyone to see. And our builder agent is gonna use a lot of those same core concepts that Garish mentioned, so things like strands, we're importing agents and tools. And so if I scroll down here we're gonna see our app entry point. So this builder agent has already been deployed to agent core runtime. And so we've got our app entry point here so we know which function to invoke when this agent is called. Scrolling down here a little bit, going through all of this various payload handling, we'll get to the real logic and meat of this function. We've got our model initialized. We have our memory, so our builder agent is gonna have just a small snippet of code here starting on line 78 for our memory hook, and this is gonna give it access to short-term memory with a history of 5. So it's gonna have those 5 previous messages automatically loaded in when you chat with the builder agent. Additionally, here's our strands agent configuration starting on line 87. And you'll notice there's About 6 tools here and there's 3 of them that are really important that I wanna call your attention to, and those 3 are deploy agent, create gateway, and create lambda tools. So our builder agent is going to use all three of these different tools to automate that agent creation process. The first thing that it will do is called create gateway, and this is gonna create an agent core gateway for us, which serves as sort of like a facade layer. Gri mentioned this during some of those, uh, initial talks. It's a facade layer that allows your agent to connect to things like lambda functions or other APIs over MCP protocol. So the first thing it will do is create that gateway. Then it will create those lambda tools. So in this case for our risk agent that's running right now and behind the scenes, it's gonna create one tool that's gonna deploy to lambda that will be exposed via that agent court gateway. And then finally it's going to deploy the agent to Agent Corps runtime. Using this deploy agent tool. All right, we have our system prompt here we'll take a look at that here in a moment and then we just pass back a response, so pretty, pretty straightforward code here. So let's go back to our terminal. And we're gonna see, hey, great, our risk agent's been successfully created, it's been deployed, it's called risk analysis agents. And here's the associated gateway. So why don't we give this risk agent a try? So I'm gonna go ahead and test it out. So I'm gonna, using my agent factory, go to chat with deployed agents, which is option 2. Give us a minute to load. It's gonna pull back all of the available agents that are have been deployed to the agent factory. And here we can see Garish's HR agent from earlier and then my brand new risk analysis agent. So we'll chat with that risk analysis agent and we'll say what is the risk associated with. That technology. Industry. And while this runs, why don't we take a look at some of the infrastructure that was deployed by our builder agent to make this risk analysis agent possible. So I go to my console here and I go to Bedrock Agent Corre runtime. I'm going to see this freshly deployed risk analysis agent. I'm also gonna go to gateways and here I'm gonna see a risk analysis gateway so this is that sort of extra layer that we added in to allow us to expose lambda functions to our agent as tools. And then if I click in here under targets I see we've got this risk analysis target that's actually a brand new lambda function that our builder agent deployed for us on the fly. So this risk analysis function, it's gonna be mostly just generic logic here, but you can, you can easily think of the possibilities if you go into more detail and you want to connect to some sort of third party system, uh, the builder agent could easily write that kind of logic and deploy it as a lambda function which you could then expose to your agent as a tool. All right, perfect. So I'm gonna go back to the console here and here we can see our technology industry risk analysis of a score of 70 of 100 so it's is just some generic response back from our agent. All right, Girish, we created our technology, uh, risk assessment agent, and, uh, I'm ready to go to bed now at this point. No, I think this looks amazing, Justin. Thank you for it. I'm thinking we could also connect this risk agent to different third party systems as well as our own intelligence systems, but I have one final thing for you. I promise this is the final request. I have a set of interns coming on Monday. They are going to be traveling to different places to get training. Can we create an agent which can help them expense things when they travel? I promise this is the last request. Sure, yeah, I'll give it, I'll give it a try with our agent factory. So let's go back to our builder agent here and let's ask for, you know, create me an expense agent that can fetch. Expenses by user and. Add new expenses. And we'll kick this off. So this is gonna be great, Garish, because right now I know we're tracking all of our interns' expenses just on an Excel sheet, and it would be great if we had an agent that we could use to, uh, you know, maybe update some kind of back end data store to allow our interns to easily add new expenses or view their existing expenses. So we'll give our builder agent here a minute to to create this expense and while this, uh, while this is running, let's just go ahead and take a look at the system prompt of our builder agent. So we, we talked about these 3 important tools, and again, we'll publish this code so you can take a look at what's happening under the hood for these different tools, but we also have our system prompts this is super important to take a look at. So 4 are a builder agent system prompt. We've got some rules like only create one gateway, only create one agent. We don't wanna have any kind of duplications which can certainly happen when you're running an agenttic loop. It could sometimes duplicate efforts, so we just make sure we include these as critical rules. And then we've got a couple options here. If it's a simple agent that doesn't require a tool, it's just gonna deploy an agent with no gateway. And then option two, which is what we've been using so far, is create an agent with custom tools. So I mentioned this previously, but the first step is to create that gateway in agent core. Then we create our lambda tools, so it's basically writing lambda functions from scratch and deploying those. And then it's going to deploy the agent right here. After step 3 you're done. Agents created successfully and then stop so we don't have any kind of duplicates that that might occur. All right, so going back to the terminal, we can see our expense agent is now deployed. So let's give it a quick test before going back to Garish with our finished product. Go to go to our expense agent and say what is user 001. Expenses. So Justin, like when you are asking this question, where does it come back with an answer from? Is this data now stored somewhere? That's right, Garish. So actually we exposed our builder agent to a set of Dynamo DB tables that we have that are storing these expenses. So our builder agents intelligent enough to recognize those data sources and then write the corresponding business logic in the lambda functions to connect to those data sources. All right, so here we've got our expenses for user one. And we can see we've got some coffee and Starbucks expenses, etc. probably hanging out at Reinvent and getting some coffee, these interns. Alright, cool, Garish, we've got the expense agent completed. At this point I'm turning my phone on silent. I don't wanna hear from you anymore. I'm gonna go enjoy my Friday night. But if anybody in the crowd has an example agent they'd like me to create, let's go ahead and give it a shot. Just raise your hand. You just mentioned that you need to do. come together OK. Right data source. Mhm. Yeah, so just in the question is, um, we showed how the agent can connect to the right dynamo table. Like how does it understand the logic to identify the right sources when you create the new agent and how is it able to intelligently say connect to this dynamo DB table? Got it, yeah, so a lot of that's gonna be provided as context to the agent, so you can do. a couple of ways you can either include that in your system prompt is like, hey, these are your available data sources and this is the schema that you can use to connect to these data sources, or you can expose your agent to some sort of MCP tool. I know AWS does publish quite a few different MCP tools that you could use which your builder agent in this case could use to search through your AWS infrastructure, identify those relevant data sources. So they use AWS tool that we had seen before, that will give it access to all Boto 3 libraries, so it can go in your account, find what data sources are there, and it can connect to those data sources as well. Hm, hm. Correct. Correct. Hm? Yeah. So usually within production, you would want to have it within your context so that it limits itself to just those tools and you define like, hey, this is a dynamo table for expenses, this is a dynamo table for some PTO requests, so on and so forth. But like you could give it the intelligence in like a non non-production environment where it, you can let it figure it out itself. But in production, what we have done is we have created the system prompt and told it, hey, this table is for submitting expenses, this table is for doing X, Y, Z, so it knows what to use. The other the same. The rock. Hm? Maybe it's just uh Yeah, we will, we'll take that one after a few examples just for the sake of time, but yeah, we will get to it as well. Anyway, so if anyone has an example agent they want us to create, do you want to raise your hand? Yeah, go ahead. Mm, yes, alright, why don't we go ahead and show that. So Garish, I know we created our expense agent, right? Um, what I know our, our interns also need to take PTO. So what if we create a PTO agent that lets them do something very similar and then after that my thought is we can create some sort of multi-agent system using our agent factory. With an orchestrator that the interns could interact with and then be able to interact with the expense agent, our PTO agent, and then any other new agents we decide to, to build in the future. How does that sound? Yeah, all right, let's go ahead and give that a shot, so. Uh, similar, similarly to our expense agent, let's go ahead and, and prompt our builder agent here to say, you know, create me. A PTO agent that can fetch PTO by user and. Uh, you know, submit new PTO requests. All right, so this is gonna create that PTO agent. I'm just creating 22 sample agents here just to demonstrate A to A, um, and then we'll, we'll create an orchestrator here in a moment. All right, so we'll give this a moment to think, um, question. Um, so in this case, is it like one of the tools essentially, does it require like an API integration with whatever, you know, internal PeopleSoft application is used to manage PTO or are we assuming that PTO is being managed by Um, you know, an Excel file for these interns or some other data. Right, yeah, it could do either. So if you have some sort of external third party, as long as you specify that or give your builder agent context of that system, it can write the lambda code on the fly, um, to, to, to connect to that system right as a tool and expose that tool to your agent. Yeah, so just to repeat the question, the question was, in case if we have our system, like the PTO system being managed by Soft Choice, which is a third party tool, can we give agents access to those tools as well to manage it there instead of Dynamo DB that we are doing here, right? So, absolutely, all that you would do is the lambda function would have the logic to connect to those tools as MCP servers, and then your agent connects to the gateway, which talks to lambda, which connects to people, or SoftChoice, for example, to, to manage that as well. So you can. Like in the diagram we showed like connecting to Slack and Quip, like it, it can connect to third parties as well, right? OK, OK, so right now our PTO agents being assembled under the hood and then I also wanna just show our generic agent code. So we looked through the builder agent, which is a lot of the business logic of what's actually being created, but we also have to deploy an agent and so that's where we, uh, what we call our generic agent.PY. So really this is a pretty basic. strands agent and then we're passing a lot of these different uh environment variables like the model ID, the system prompt, the uh, the gateway ID if it needs to connect any kind of tools in as environment variables to this code and then deploying this as those separate different runtime, uh, those runtime agents that get deployed to agent core. So just to walk through this code briefly here. We've got one function here to construct A to A URLs. So for multi-agent systems we need to have this function on board so that way our agents can discover each other using A to A. And this is the URL that we're returning on Bedrock Agent core. We have this create agent function that I'm going to skip here but we'll take a look at it momentarily. And then we have our main function. So if you remember from Garish's presentation, he mentioned for A to A, there's such things as A2A servers and A2A clients. Now an A to A server, for the most part, all of our agents so far that we've created have been A to A servers or the agent mode of server and so this block of code's going to run or we create that agent. We exposed this runtime URL. And then we, we run this command here of A to a server which is gonna host this at port 9000 and this makes this agent, uh, viewable and exposed to any sort of AAA clients that might be on our network. And I'm gonna scroll down here we're just doing some basic, you know, mounting here of the server. And then in our L statement this is client mode. So if we deploy any orchestrators, any orchestrator agents, those are, are deemed as clients. And here we're gonna do some of that standard stuff that Garish did earlier with Bedrock agent core app. We run this app command and then we specify our entry point in the invoke agent command, and here we just run our create agent function and create an A to a client. OK, perfect. And then our create agent function, this is where a lot of that business logic is. So we've got some, some if statements. If we need code interpreter, let's add this code interpreter tool. If we need browser, let's add our browser tool. If our agent mode is clients, here's our setup for A to A so we can discover those other A2A agents that are on the network as A2A servers. And so here's some boilerplate code here around A to A client tool provider so this gives it access to those standard A2A tools that it would need to discover agents over A2A and then also send those agents messages. And then we've got our gateway ID so if we do have a gateway, we need to also expose our agent to that gateway so we can access those custom lambda tools that were created for it. All right, perfect. So that's most of the business logic there. If I go back to our console, we can see our PTO agent has been successfully created. And now I'm gonna do that last step, which is creating that orchestrator. So let's go ahead and say create an HR orchestrator. That can delegate. tasks to the expense agent. And The PTO agent Also allows you to give more detailed instructions right like doing it once the press there. Correct, yeah, so you could, you could easily do that um if you update your, your system prompt if you wanna do something like an iteration of I'm sorry I didn't repeat the question, but the question is could you have a more interactive process of assembling the agent. Um, you could update your system prompt here of the builder agent for the sake of the demo today, we wanted to make it quick, but you could, we, you could absolutely architect it that way where you could have a back and forth conversation with the user so they can help to further refine those requirements of what the deployed system prompt should be, what the deployed tools should look like, uh, those sorts of things. All right, so now we've got our HR orchestrator it's configured as a client agent and it has access to the expense and the PTO agent. So let's go ahead and give that a quick test. We'll find our HR orchestrator we'll ask it what agents can you communicate with. So what this is doing under the hood is it's using some of the included A to A client tools to do a discovery and see which agents it can connect to and we're expecting here to be able to see the expense agent and the PTO agent. So if I scroll up we can see we can communicate with two agents and then I can ask that same question from before of you know what is user 001's expenses or actually we'll ask it something different let's say um. You know, at an expense for user one for coffee at Starbucks. On December 2nd. 2025 for breakfast. For $15.65. All right, perfect. We'll give this a minute or two to run. This does take a bit longer than interacting directly with the expense agent because first the orchestrator in this case that we're talking to has to identify which agent should handle this request and then actually send a message to that agent to allow it to make this post command to our data store. So I'll just quickly show what's going on uh in terms of what was created here. So I go back to our console. Let me just refresh the page quickly. How is the orchestrated determining the functions supported by each of the. Individual agents. Is it inferring based on, Yeah, so I kind of, I did gloss over that detail. So the question is how can the orchestrator determine the functionality of it's the agents that it can communicate to over A to A. So part of AAA, and we didn't touch on this today specifically is what's called an agent card. And so those server agents that are deployed are advertising what's called like an agent card and that contains a description of what they can do and some of their tools, right? So you could include those details in the agent card so when the client's discovering it's, it's like, OK, this is my expense agent, this is what it can do, uh, etc. Mhm, we, yeah, we are creating those as part of the agent factory. I think I may have scrolled over that code, but you'll have it in the in the code repository, yeah. OK, cool. So now we've got our, our expenses gateway with our, our get expenses and add expenses tools. And then if I go back here we can see hey we've we've recorded this expense and then if I were to say hey what are user one's expenses we would expect to see this uh as well so we have one more question here Justin go ahead. Yeah. So the question is, in terms of managing what permissions the agent has to read the dynamo table, can it read, can it write, uh, how can one manage those permissions? Yeah, that's a great question. So a lot of that's gonna be done with agent identity, agent core identity. We didn't plug that into our agent factory for today. We're just using generic IM, uh, permissions. So you can kind of query user one, user 2, user 3, and all those queries are gonna go through. But, uh, but absolutely if like in a production system if you were to really deploy this for your end users you would wanna use things like J. tokens and things like that to identify and the claims of the token who's interacting with the agent and then pass that through so they're only accessing the resources they should be able to. Yeah, we have one more question. Sorry we couldn't get to you earlier. Please go ahead. OK. Yeah, so the question is, like, are we using the same model for generating code as well as talking to the agent? So in this case, what we are doing is we have used Sonnet 4.5 for creating agents, and when we are talking to an agent, that is Haiku 4.5, Sonnet Haiku 4.5, so we are using cloud models here. Correct. So, um, uh, so when two agents are talking to each other, like what is the security aspect of it? So we are relying on 82A as the underlying protocol. So it is ensuring that the agents can identify each other, know, know what they are capable of, and they are using the 8-way protocol to communicate with each other. So the communication would be encrypted, like it will basically use that protocol as the channel to communicate with each other, the communication channel. All right, we'll, we'll take some questions here at the end. Um, just we're, we're almost done with time here. So just last thing I wanted to touch on is we've got some resources. The code repo that Garrie and I use today is that far left link. So if you wanna play around with that, feel free. And then we also have like a strands agent starter and an agent core samples GitHub repository as well that you can, you can pull down. And the last thing we want to say is just thank you all for coming out and, and attending this session. We hope you found it valuable. Thank you all. Thank you all.