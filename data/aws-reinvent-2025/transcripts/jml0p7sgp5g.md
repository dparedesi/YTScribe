---
video_id: jml0p7sgp5g
video_url: https://www.youtube.com/watch?v=jml0p7sgp5g
is_generated: False
is_translatable: True
summary: This presentation introduces Fastly's innovative deception technology for cybersecurity, using an engaging analogy of blind golfer Charlie Boswell challenging Ben Hogan to a nighttime golf match to illustrate how the playing field can be leveled against attackers. The speakers, Rick and Memo, explain how traditional cybersecurity focuses on attacks rather than attackers themselves, missing a crucial opportunity to exploit the human psychology behind cyber threats. Memo introduces behavioral science concepts of "nudge" and "sludge," where nudge simplifies decision-making for legitimate users while sludge adds friction and complexity to deter unwanted behavior. The presentation argues that sludge can be weaponized for good in cybersecurity by imposing costs on attackers across multiple dimensions: quantitative costs like money and effort, qualitative costs including reputation damage and recruitment difficulties, informational costs from pursuing false leads, and psychological costs manifesting as frustration, shame, and confusion. Drawing parallels to historical deception tactics like the Trojan Horse and natural camouflage in animals, the speakers position deception as a legitimate defense strategy that leverages knowledge of enemy tactics. Rick then unveils Fastly's implementation through their NextGen WAF product, specifically targeting account takeover attacks. The deception system works by scrambling username and password combinations when triggered by configurable parameters such as bad bot signals, specific IP addresses, countries, or paths, making all login attempts appear invalid even when credentials are correct. This approach differs from traditional blocking because it provides no feedback to attackers about why they're failing, preventing them from adapting their tactics. Unlike conventional honeypots that require separate infrastructure and constant synchronization with production systems, Fastly's solution operates inline with the normal WAF workflow, making it cost-effective and easier to maintain. The system can be enabled, logged, or tested in preview mode through a GUI-driven interface without requiring deep code modifications, allowing security teams to experiment before full production deployment. The deception capability represents just one layer in Fastly's comprehensive defense-in-depth strategy, which also includes rate limiting, intelligent DDoS detection and blocking, and security built into their CDN architecture by design. All components are API-driven and Terraform-compatible, facilitating easy rollout, rollback, and iteration. While currently focused on account takeover scenarios, the company plans to expand deception capabilities to other attack vectors including APIs. The fundamental philosophy is to frustrate attackers by denying them actionable intelligence, potentially causing them to abandon targets or waste resources on ineffective credential lists, thereby evening the cybersecurity playing field just as Charlie Boswell leveled the competition with Ben Hogan through strategic environmental manipulation.
keywords: deception technology, cybersecurity, behavioral science, WAF, account takeover
---

How are you doing? We have, do we have any golfers? Anybody who plays golf, likes golf? Good. I have a good, a good, good golf story. Now this goes back to 1958 in Fort Worth, Texas. There was a, the championship for the Blind Golfers Association had their award ceremony for the best blind golfer. And there was a guy, his name was Charlie Boswell. He, he was the national champion blind golfer. And because of that, he got the, the opportunity to play a round of golf with Ben Hogan. Ben Hogan was the premier golfer of that era, like, uh, Arnold, Arnold Palmer, Jack Nicklaus, Tiger Woods, that kind of level. So, Charlie was very thrilled to meet them and they, he was, because it's his, his idol. Uh, but Charlie, Charlie lost his sight during World War II. He was a really good athlete, played football, played baseball. And then during World War II, he tried to save one of his comrades in a tank that was burning and he got a shell blew up and he lost his sight. So he didn't know what to do. He came back, he took up golf, never done it before. So he, he gets to meet the, you know, the best golfer of that era and gets to play with him. And Ben Hogan was in awe of him because he could play blind. So he said, Charlie said, hey, uh, how about if we, uh, play for money? And, and, uh, Ben, you know, go like, wait, I'm like the best golfer in the world. I can't play for money for you. That's not you, it's unfair. You're, you're blind. And Charlie is undeterred. He says, $1000 a hole. And, and Ben's like, I, I can't play golf. No, that's, that would be unfair. So Charlie says, are you chicken? Now, Charlie, uh, Ben is very competitive. He says, no, I'm not chicken. OK, you want me to play, I'll play. No, I'm not gonna hold back. I'm gonna play hard. He goes, that's the, I would expect that from you. Uh, so Charlie says, or, uh, Ben says to Charlie, OK, uh, what time? He goes, tonight at 10. So This is an example of how the playing field can be evened out. Now if you switch to another sport, football. So in football, who has the advantage, the offense or defense, right? The offense obviously has an advantage, right? The quarterback gets to play, calls it in the huddle, comes to the line, he sees what the defense is set. He figures out what am I going to do. You know, the defense has to guess. It's 1st down, maybe they're going to run. It's 3rd down, maybe they're going to pass, but maybe they're going to fake them out. Are they going to pass? Are they're going to hand off? They're going to fake the handoff pass, run around, you know, there's so many things that could be done. So we want to say, how can we even out the field? How can we get into the minds of the attackers and make that playing field level just like Charlie was able to level it out with the world's greatest golfer. So I'm gonna pass it over to Memo here and he's going to talk about what our new deception technology does. Thank you, Rick. Well. Now let's focus our attention to the attackers, OK, just like Rick was mentioning. By When we are defending our systems, sometimes we focus our and and and and have our attention into designing defense strategies, right? And we focus on the attacks, but not on the attackers. And by doing this, we can overlook something super important. The humans, the sorry, the attackers are, are just humans like everyone in this room, right? Humans with a brain that works in the same way than us. This is very important. Understanding this is key to implement defense strategies. Much more efficient, right? We want to Influence the decision making of the attackers. To protect our systems. Sorry. But how can we influence the decision making processes of our attackers? To answer this, let me introduce these two concepts of uh behavioral science, nudge and slouch. Both are ways of describing, um. Uh, how to influence the decision making, OK, but in opposite ways. On this side we have notch, which is influencing in a positive way, OK? Let's say make it easier, make it more simple. Like here, here we have a password strength meter to help the user create a strong password. This is a very simple example. Or on the bottom part, we have a, a reminder of an application to just do your daily exercise. This is an example of Nudge. And on the other hand, we, we have sludge. We have sludge, which is to make the process more complicated, to add, add the steps, add complexity, add friction. This is an example of sludge. And to uh in here on the center we have the a captcha. A captcha has good intentions, right? It's to block the the bad actors, but sometimes the capchas add friction, complexity. Uh, the legitimate users, sometimes they, they see this as additional steps and, and end up just giving up and going elsewhere. This is an example of sludge, and we can think of in many examples like I'm sure here everyone has experienced the subscription services on the internet. It's always super easy to subscribe. It's just one click away. What, what happens when you when you want to cancel? There are several steps. Sometimes you get an offer, one free month. Don't cancel, just extend 3 months more. This is a very common example of sludge and nudge. And in the case of the attackers, We want to use slush for good. We want to add friction, right? We want to We can impose friction to attackers in our benefit to create better defense strategies. We can influence their behavior. And decision making with Slush. And what is the cost to the attackers if we add friction? There are, there are different costs. We have quantitative cost and qualitative costs. First, we have the obvious. If, if we add friction into the process, if we make the process more difficult for the attackers, we have the, the everything that costs money and effort. We have this quantitative costs, all the foregone opportunities. But there's also the qualitative cost, and we have reputation of it. If we make them fail. The attackers. They will lose. Credibility, it will be harder to recruit. It will be more difficult to get new clients. And also we have informational calls, which it refers to the, the, the effort that the attackers put to get more information about the next targets. If we add invaluable information. We create more cost to them. And finally, and this is the reason of the title of this presentation, is the psychological cost. If we add frustration, shame and confusion to the attackers by making the process more difficult by adding friction, we add this cost. Now let's see how fastly we are using slush for good, and this is with deception. Deception has been used over the course of history in many contexts, especially in warfare. That's why we have here the Trojan horse, which the Greeks used against the Trojans to win the war. In cybersecurity, it's, uh, we all know about the concept of honey pot, which is a way to deceive the attackers to get more information about their tactics. OK. In the nature we also have many examples like animals changing their appearance to hunt their prey or um. Uh, or, or protect against the, the, the predators. Deception is not playing dirty. Deception is about leveraging what we know about our enemy tactics in our, in our benefit, OK? This is a deception. And now, uh, Rick is going to explain to you how fastly is introducing deception into our cybersecurity products. OK, so this is kind of the brainchild of our uh Product VP who has a deep security background and a background in behavioral economics, so we want to try and get into the head of these guys. We want to, uh, like you said, make them frustrated so they'll go away or they they won't bother this this uh particular site anymore. So this is just the start of what we're doing and right now the way we're going to do it is we're we're looking at account takeovers. So this is our, our WAF product, uh, NextGen WAF from Fastly, where you can set the parameters on when you want to trigger the deception to happen. So basically what it's gonna do, once we, it's hit that deception trigger. Either by a signal that says this is a bad bot or suspected bad bot or it's a certain path, certain IP, certain country, all that is open and configurable so you can decide the trigger point when you want it to start deceiving. But once it starts, gets that deception going, it's going to take that guy's going to go iterate through his username and password to try and find one that works because he paid money for it, so. We're going to make all of them bad. So if he has a good username and password, we're gonna scramble it, send it back to the origin, and it'll say, you know, that's bad, that's a, uh, wrong username and password, you'll see. So everyone will start seeing like that, and he won't get any feedback on why, what's wrong. So if we just blocked it. Ah, he blocked me. Maybe he rate limited me. OK, I logged in more than 10 times a minute, and they'll go down to 90, I, I tried this path, maybe I'll try another path, something like that. In this case, uh, he's not, he doesn't know what's going on. So we're effectively blocking him and frustrating him. So what makes this more important is, as I just mentioned, when he's under attack and he gets the signal, he can retool. He sees, OK, that's the offense, or that's the defense you have in place. I know how to get around that. I could go this way or that way. But here he, he, he doesn't know. He thinks he has a bad list. He doesn't know what they're doing. Now again, as mentioned, honey pots have been around for a while. The problem is, They're typically a separate infrastructure, so you have your production, then you have your honey pot. You got to keep them in sync. You gotta keep them exact. You gotta run two instances, you know, it'd be costly, a lot of engineering work. It, it, you know, it could be worth it, but it's a lot of effort. In this case, the genius here is we put it right in line. It's right in line with your normal WAF workflow, and we can take those triggers and again instead of blocking, we're just scrambling the password and the username and sending back, hey, that was a bad one, but we're not blocking them. So it's easy to put it in and out and tune it without having to create all this other infrastructure which is costly and difficult to maintain. So, as I mentioned, this is a start. We're doing it with account takeover and we plan on expanding it, putting it into other areas, API and other types of attack vectors that we're going to make it look de deceptive in different ways. And the beauty here is it allows security people to easily use this without having to. Go deep into the code and build things that might be more difficult and costly to maintained because it's a GUI driven interface, very easy to enable it and log it, or even try it and see what it would have deceived before you're ready to really put it in production. And this is all part of defense in depth. So we see there's, there's a whole myriad of tools that you need to have in place to protect those. Attackers and this is something that Vastly provides as well as the deception is just one part of our WAF. We can also do rate limiting. We have DDOS on the front end which can intelligently detect DDoS attacks and block them. And then we're secured down by design deep inside our our CDN and our WAF. We make sure all the code and everything there is, is secure, and you have this whole defensive depth that's all logged. It's all API driven. It all driven by terraform. It's very easy to roll it forward, roll it back, and manage it and iterate on it. So Again, we want to even the playing field, like I mentioned with, uh, Charlie and the golf, and try and fool those attackers before they can, they can do their damage. Thank you.