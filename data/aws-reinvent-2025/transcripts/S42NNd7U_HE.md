---
video_id: S42NNd7U_HE
video_url: https://www.youtube.com/watch?v=S42NNd7U_HE
is_generated: False
is_translatable: True
---

Good afternoon. Uh, welcome to the session on how to automate co-modernization at enterprise scale with Agentic AI. Uh, my name is Edo DiMaggio. I'm a senior manager of, uh, product in AWS Transform Custom. Here with me is Morgan, um, Morgan Lund. He's a senior product manager and main partner in crime for this product that we're gonna talk about today. Unfortunately, Shriram wasn't able, is not able to be with us today. Um, he's our director. He has a press event that could not move. Um, Before we get started, how many people here are um have problem with tech debt or modernization? OK. OK. Well, uh, uh, what we're gonna talk about is that we're gonna talk about technical debt in this, in this presentation. And, um, the challenge that we have is actually very pervasive. Everybody that we talk to has this issue. Um, Morgan is gonna, uh, talk a little bit about how to get started with AWS Transform and how to perform transformations at scale. Because, uh, transforming and modernizing a single repo is more kind of a proof of concept instead of actually addressing your tech that challenge, which usually stands, um, uh, hundreds if not thousands of repos. And uh uh after that, um, uh, we're also gonna talk about customization because um what every customer that we talk to um has organizations specific challenges. Even things that are, uh, common such as uh job upgrades or Python upgrades or, or dependency upgrades, they tend to have specific uh challenges that are um uh unique to each organization. Then we're gonna talk about value and pricing. So, uh, let's talk about technical debt. 20% of IT budget is currently spent trying to address technical debt. That is a lot of uh resources that would actually be spent in innovation. And that's actually probably like a lower um Estimate 23% of developer time is lost because there is tech debt. That is not the time that is spent to address tech debt, that is lost because you have tech debt dealing with all the frameworks, dependencies, trying to figure out what to do. Um, Accenture, um, um, estimates $2.4 trillion of tech that cost per year in the US alone. Of course, uh, tech that comes in many forms. Uh, there is security and compliance risk, your end of life run times. Many, many, many customers have, uh, lambda running on end of life run times that are gonna be deprecated this coming year. Um, but even without lambdas, you probably are still running applications on Java 8. Um, there's lots of stats that many, many customers are in that situation. Similar thing for Python and Nodes. You may have vulnerable libraries, things for which vulnerabilities are, are known and they're hard to migrate from. These are usually things that are harder than just going in a config file and bump up version. There's maintenance burden. You have uh unsupported framework that you have to start supporting yourself. You may have legacy patterns that you have to support and and skill your your developers in this patterns that you don't really wanna use anymore. There are performance limitations. You may leave um performance and uh and and spend higher um operational costs because you're uh you're using older versions of older libraries and frameworks and And things like that. You may also be missed on modern uh miss out on on uh modern features. Finally, there's strategic misalignment. Usually what happens is that as a result of merger and acquisitions or just organically, your different business units and teams end up like using different versions of tech stacks, and that is, that is a drag on your innovation. Now, of course, um, Many companies address tech data in a, in a manual way. Fundamentally, they just treat it as uh any other software development. There's specs, their development, you track them in your issue tracker and and just go at it. Um, there are ways to uh to make things better and to, and, and to try to automate. The existing approaches are rule-based automation, think about ASD grab, open rewrite tools like that. Uh, they usually require specialized expertise to run. They tend to be brittle and inflexible. Uh, you have, uh, a rule-based, uh, code modification recipe or rule, and, uh, that works for that specific case, and if things are different, there's usually a lot of cleanup that has to happen after that. There's usually a lot of start-up cost and it's really hard to customize them for your case. They also have a much more limited scope. There's only so much things that you can do with deterministic rules. In the end, you're basically writing a program that modifies a program in abstract, really, really hard. There are general purpose coding AI and there's many of them. These are usually focused on on an interactive execution. There's a developer that's using them, it's an assistant, great acceleration, they are great products. They're, however, less suited for for autonomous execution, and in the end, we do not want your developers spend time to do this kind of modernization. We want to automate it. There's also no easy way to organize reusable knowledge. Usually, what happens with this modernization, they affect multiple teams in a similar way and uh um with the general purpose coding agent, every team has to um um um organize the knowledge to do the modernization by themselves, and there's no way to uh share the learnings across these teams. Now, what we really want is that we want a low barrier to entry. We want a tool that's designed for automation, we wanna be able to learn once and use in every situation where that transformation or uh modernization challenge happens, and we want the tool to be able to improve continually. So, let's look at a little uh uh at at at some of the transformation challenges that our customer had. We've had our product in beta since April of this year. And uh um uh we, we work with many customers internal internally and externally to uh tweak our product and make sure that we could provide value. Um, Air Canada here Had, uh, had a problem with lambda upgrades. No GS 16 was basically coming end of life, and they had very tight security tight deadlines to to make sure that they got off of that. They also wanted to migrate to Graviton instead of X86. Internally, uh, um, our, uh, friends at Twitch, they were still running on AWS SDKV1 on their, uh, go repost. They had more than 900 reposts running on it. There was an enormous uh task to basically upgrade across all of these repos. Quad is a is a is a manufacturing company. They uh they wanted to migrate all of their customers with each own with their custom plug-in with their previous platform to their new platform. So, they wanted to translate their very specific um um um progress plug-in into their new DSL. This is a very complex, uh, modernization project and definitely very organization specific. We also work with MongoDBe that is working on how to help their customers migrate off of older versions of the MongoDB SDK and adopt new functionalities. Let's take a step back. In May, we G AWS transform and supporting uh modernization workloads specifically for VMware migrations, full stack Windows modernization and mainframe. Yesterday We launched AWS Transform Custom. This is a product that allows you to, to transform uh any code pattern. It has built-in transformations or you can create your own. It supports diverse scenarios like version upgrades and runtime up to uh um language transformations. It does have continual learning and improves uh and uh and it scales transformations to uh um to enterprise-wide scale. What are the main components of AWS transform custom? You can define transformations with natural language. You do not need uh specialized expertise. You have natural language prompts, you can provide code samples of what you wanna do, migration guides, documentations, whatever you have. Then you can execute them at scale, either through uh through a command line, interactive uh or or integrated. It, uh, in your CICD pipelines. We support multiple ways to, uh, to integrate it into your own flows using your own environments and, and, and of course, it enables, uh, campaigns across multiple repos. Finally, and very importantly, it learns from developer feedback. So, when your developers are modernizing Uh, your, um, um, your repost, and they provide feedback to the agent, that feedback is captured and reused for the different executions. Not only that, also, the agent learns by applying the same transformation over and over on your repost. So, if it tries an avenue of transformation and finds out that test doesn't work and doesn't work out, it will not try that again later. Uh, of course, all of this learning can be controlled and access controlled, and the idea is that you can define the transformation once and we use it across many, many, uh, teams and many repos. Uh, that is different than, uh, just, uh, reusing. Um, um, immigration guide or every team interactively using coding agents. We also provide AWS managed transformations for very common scenarios. Uh, Java runtime upgrade, Python runtime upgrade, Node runtime upgrades, AWS SDK upgrades, and we also have a few of early access ones, TechT analysis and X86 graviton for Java. These transformations are zero setup, we validate them on very, very wide benchmark suites, and, uh, we're continuously growing the number of transformations that we provide natively. We also, and importantly, allow you to build your own. Uh, the common use cases where we see this being very, very useful are API and service migration, of course, language upgrades for things that we don't support, uh, framework upgrades, code refactoring, custom patterns, and things like that. The idea here is that you can create, uh, you can instruct the agent to execute the patterns that are unique to your organization. At the end of the beta, Air Canada was able to achieve 90% efficacy rate for uh for the conversion of thousands of lambda code bases and 80% reduction in expected time and cost, and they're basically uh are making this product part of their operational um uh uh part of their internal standard. Quad was able to enable um uh um projects that that would take 2 weeks um uh into into projects that took just 3 days, achieving 60 to 70% production gains and saving an estimated 7500 developer hours annually. This is to convert all of their customers to their new platform. Twitch achieved 70% acceleration on each application migration. For 913 repos, they're projecting savings of nearly 11 developer years. Finally, MongoDB uh was, was able to demonstrate a big impact in modernizing and migrating Java applications specifically for the MongoDB APIs. Now, I'm, I'm gonna give it to Morgan to tell you how you can get started with AWS Transform Custom right away. Thanks Elio. So the team that built Transform Custom was very deeply involved in the initial AWS Transformer release and in the release of Q Developer, and we learned some lessons along the way. Um, one thing we learned was that onboarding on those services was harder than it had to be, so some of them required identity center set up in connection of your federated identity provider to AWS, um, which had all sorts of security, um, approvals that would need to go through. Uh, you can get started with builder ID for a Q developer, but then there wasn't a good way to graduate up to an enterprise, uh, subscription. Um, so we tried to do away with all of that as much as we could with Transform custom and really cut to the bone the bare minimum needed to set this thing up. So there is no human identity. It's all IM permissions just like any other AWS service meant to be machine driven. Of course humans can use it as well, and, and I'll show you how to set that up in a moment, um, standard AWS infrastructure, security, access control, stuff that you already know how to use. We're not trying to reinvent the wheel here. Uh, the setup is quick and easy, and I'll show it to you in a sec. It's like literally a one-line batch script to pull down our installation script and execute it, and then you configure your commit, uh, permissions just like you do with the AWSCLI. Um, it, it's works with your build system with your existing tools. Um, the transformation execution is happening locally on your device, so you don't have to like try and recreate your complex build environment in the cloud if, um, like some other, uh, services will have you do. Um, and it's super easy to compose this as a part of your broader modernization workflow, so you can write a script to pull down your code from wherever it is, execute transformation, push it wherever it needs to go, wherever you want. It's meant to be composable, flexible, um, uh, an engine that you can stake and, and put in the car that, that you're trying to drive. So I said it's easy to install. That's it. That's the command. Uh, you can go find it on our docs page that pulls down the package, executes it, installs it. We have two dependencies. You need to have Do JS installed and you need to have Git installed, and that's about it, um, and it works on, uh, Linux, Mac OS, and on Windows through WSL. Uh, no native Windows support at this time. We're, we're working on it. So this command line has human interactive mode as well as a machine drivable mode. So in human mode you have a friendly conversational agent that asks you, hey, what is it that that you want to transform? Um, it'll query our registry to find is there an existing transformation that does this or am I gonna help the user to build a new one, And it has all of our best practices encoded in it. So when you're trying to create a new transformation, you don't really know what you need to provide the agent. Like you wanna go from APIA to APIB. The agent's gonna extract from you like, well, if you have documentation for those APIs, that would be helpful. Or if you have a migration guide, maybe you wrote for human users, that would be helpful too, um, based on our, our several months of data we've run here, we've come to some really, uh, crystallized best practices, and we put that right to guide you the right way. Um, as I mentioned, the command line, uh, can be also driven machine mode with a totally deterministic syntax, so you put all the arguments up front and you hit go and it's gonna execute your transformation, no human involvement needed at all. Um, the benefits to this is it's quick to start, it's quick to start getting feedback, it's quick to figure out if this is gonna work for you, um, and ideally if it doesn't right away, transform custom, right? It's meant for you to tweak it, for you to add your own customizations. If you've got organization specific requirements or libraries or dependencies or coding conventions, you can teach it to this thing and it'll remember it and use it as it transforms your code. So as Elio mentioned, we have some out of the box transformations that we give you, um, Java, Python node runtime upgrades, uh, AWSSD upgrades for those languages as well, uh, a tech data analysis, which I think is super cool, that's, that's something we got squeezed in at the last minute. Basically it does like a complete thorough documentation of your code, all of the relationships between the various functions in there, data flow diagrams, entity relationships. Think of it like the most comprehensive code documentation you, you could imagine is what we try to generate there. And then we use that information to distill out um an analysis of technet and suggestions for things you may want to modernize. There may be libraries in there that you didn't know how to or you didn't know were were deprecated, and we try to surface that to you. Now that's early access. It's not, it's not perfect yet. We're still working on it, but we're comfortable enough to, to give it to y'all to try out, uh, Java X86 to Graviton. We're seeing really good, uh, success on our benchmarks internally on that. That one's hopefully gonna leave early access relatively soon once we have a little more data. Um, and of course if you have to do something beyond this or in conjunction with these transformations, you can build your own. You can upgrade your Java and you can replace library A with library B, or you know, you can, you can stick these things together and mix and match to solve the problem that you're really trying to solve. This. And providing So there is not an official community thing set up yet. It's something we've really talked about, um, and when we talk about transformation definition portability in a minute we'll come to that, uh, but one of, one of our tenets is you spend the time and effort to build a custom transformation and as far as I'm concerned that's yours. Um, you can keep it secret, you can share it with the world, you can, that's up to you and we try to make things, um, these things import and exportable as we can. So, let's see how easy it is to get started. Oh, do I just press now, look at that. So what you see here is I put that command in. I run it, it's installed. That's it. And now I hit type ATX, which is the, the three letter command to kick this thing off. There's the help menu, and there's our cool Aci art that that I designed. So I'm telling the agent, hey, I want to create a new transformation. I want to upgrade my, what am I doing here? Python repos? Yeah, that's what I'm doing. And it's gonna search through our registry and it's gonna say, hey, it looks like there's an existing transformation built by AWS out of the box already to to do this. You wanna, you wanna use that one? And I'll say sure, because it's a totally agentic chat, you just talk to it. So it's doing some prerequisite checking here, making sure get is initialized on the repo that I pointed it to. And finally it's gonna ask me if I have any uh special requests like you're at a restaurant and they're like, hey, you know, you want the burger, but do you, do you want onions? Do you want you can give it your, your extra little special request here which it's going to incorporate uh during this particular transformation execution. And it's off, it's running, it's doing its thing. It'll take, you know, 1020 minutes, depends on the size of the code size of the code base and stuff, uh, but that's how easy it is to get started, to install the CLI, to point it to an existing repo you have on disk and just start transforming it. Scaling up. So, OK, pretty cool, I can transform one repo, but I've got 500 repos I need to transform. How, how do I do that? So, based on our beta experiences with our customers so far, we found uh certain patterns that seem to work well um that kind of map to different uh people with different jobs within a large organization. So, first thing you wanna do is plan, figure out what do you wanna transform. Do you wanna upgrade your job at one time? Do you wanna migrate from. Dropbox to box because your company signed a new deal. Did you acquire another business and they use, uh, you know, some API provider and you have a different one that you use as a standard and you wanna migrate their code to use that? Figure out what it is that that you're trying to transform, um, and then you're gonna identify some representative targets to start with. So a code base that's not too simple, not too complex, something that you feel like kind of hits the mark of a, a good representation of all of the other code bases you're gonna have to transform, uh, that are facing the same problem. And then you try it. You sit sit down with our agent like I just showed you. It tells, it asks you what do you wanna transform. You tell, I wanna go from blah to blah. Here's some documentation. Here's a how-to guide I wrote for human users. Uh, here's a blog post. Here's a, you know, you can really feed it any text that, that you should be helpful, uh, code diffs, if you've done it before and a few repos, those are really helpful, um, to actually show, not tell the agent what you're trying to do. So you do this, you create your initial transformation and you'll notice here this is done by a by a centralized team. So one pattern that we found works well, especially at large companies, is when there is a kind of a core central team in the organization who's responsible for coding standards and conventions and practices, um, they tend to be the ones who go about creating these transformations so they can disseminate them out to the application owner teams who are actually going to run them. Um, so after you've created your initial transformation, start a pilot, do it with tens of apps, and you'll start to collect some data on like, OK, how long does this take to run? How good is it? Does it hit, you know, 70% efficacy? Does it hit 95% efficacy, just depending on the complexity of, of what you're trying to do with it. Um, and you can also get a really good idea of what it's going to cost here. So, uh, Elio is gonna talk about pricing in a little bit, but it's, it's purely pay as you go, totally usage based, no subscription stuff at all. So, and it's based on how much the agent is working. So a more complex transformation, agent works more, it's gonna cost a little more. Um, so through the pilot page you'll collect data on that and you'll be able to budget, OK, to do this campaign it's it's gonna cost us roughly this much money. And then you can start to scale it out. So I'll talk in a minute about the push modality and the pull modality, which are the two different, uh, ways of doing these sorts of campaigns that that we've seen, um, you integrate it with your source control if, if you would like to, and you can monitor and, and make sure the progress is going as you would like. And then the most exciting part about all this in my opinion. Is the learning. So every time a transformation executes, our agent goes and checks all of its work, looks at everything that it did, um, and identifies knowledge items, things that it wishes it knew at the beginning of the transformation that'll make it faster, better, um, do what the human actually intended for it to do, and it's gonna incorporate that information next time it runs. The benefits of doing this in a centralized approach like like we're talking about here is that you only have to put in the effort of defining this transformation one time um, the quality is gonna be consistent. Everyone across your organization is gonna have the same uh thing done in the same way like if I were to write a wiki page telling, um, everyone in my company, hey, we're migrating off this old ticketing API you need to use this new ticketing API. And I send that to a bunch of application owner teams. A, getting them to do it, it's gonna be hard unless you know there's a top-down mandate, but B, um, there's a decent chance just because humans are humans, everyone's gonna interpret the words in that wiki a little differently even if I try to be really explicit with it, and they may follow different conventions and do things differently with a centralized transformation approach where you define once and you run many times, you can be confident it's gonna be done roughly the same way each time. Um, and finally we, we break down those knowledge silos. So if you have a bunch of individual developers and a bunch of individual application teams that live in different cities and don't talk to each other a whole lot, um, as they make discoveries about, hey, you know, if I, if I use this function I could save a lot of work, and if I use this one, you know, there's, there's a bunch of problems and it's annoying, um, that information today is gonna be kind of siloed, but if you do this centralized approach with the centralized transformation definition, these learnings are upstreamed and, and they're shared with everyone and saves everyone some effort. So push campaigns versus pull campaigns. The way I think of a push campaign is you have this centralized team. They defined the transformation. Maybe they got to a really good efficacy, um, you know, 80, 90%. They're very confident that this thing works rather well. Um, they can directly pull down code that needs to be transformed, uh, transform it, and then push a PR to the application owning team to review. Uh, this way you're putting less work on the application owning team. They don't actually even have to install the CLI or or do anything. They just have a pull request that they need to go review and, and make sure it does what needs to be done. Um, this is especially useful for things with, with high efficacy, for things that are a little more complex or trickier, or you just wanna give the application owning team a little more, um, ownership over, you can do a poll campaign where you have a centralized team still create that consistent transformation definition. Um, and instruct the individual application owning teams, hey, we're running a campaign to go from blah to blah. You have to do it. The deadline is this. So and so important person says, says you gotta do it, but instead of doing it manually, here's a command you can just plug into your command line after you install the ATXTLI and run it on your code base, and it should get you most of the way there. It should take most of this work off of you. Um, in our, in our experience internally in Amazon, this has really helped accelerate internal migration projects because, uh, there, there's something to be said for the human nature of, hey, do something for me versus, hey, do something for me, and here's something I made, I put time and effort in to help you do it. So best practice number one, pilots, pilots, pilots, um, you're not gonna know how well your transformation works unless you test it. You're not gonna know how much it's gonna cost unless you test it. You're not gonna find the edge cases and weird little bugs and strange behaviors that that your users may run into unless you test it. So, um, highly recommend taking some time, you know, maybe a couple of days to create your initial transformation definition. Find some really good media representative repos and run it on those first. Um, then refine it, tweak it, fix those edge cases, add, you know, exceptions, uh, when needed. You may need to decompose a really complex transformation into multiple steps. That's perfectly OK. Um, we have, I've seen customers use a pattern where they use our CLI, um, syntax to invoke one transformation and then immediately invoke another one right after, kind of just as easy as one transformation for, for a user, uh, but for the agent sometimes it makes things better if, um, if you give it smaller chunks of problem to focus on at a time. Uh, learning items, knowledge items which are discovered during execution are not automatically enabled by default. Um, that's to prevent any sort of malicious knowledge item being, being discovered and, and applied to code unwittingly. Um, so the centralized team that owns the transformation is always going to be able to take a look at those and, and say, OK, the agent thinks it discovered something smart here. It's actually not smart. Let me not, not enable that one. Um, yeah, and you can measure time and cost and you can put together your, um, automation mechanisms for using this within your organization, however you all store code and do code reviews and it can slot into that. It's a really bare bones easily, uh, build on top of a bull CLI. Script and automation and integration. I, I touched on most of this already, but here's an example of how simple the syntax can be. I mean, get clone the repo ATX exec and N is the name of the transformation that's stored in your registry that's, that's been shared across your company. C is the build command, which is optional. Um, sometimes for like Python and stuff people use like a linter or something for that. It's just a way to tell the agent, Hey, here's how you check your work. Like if you run this, make sure you don't get 1000 errors. If you did, you probably did something wrong. Um, X is non-interactive mode, um, so saying don't wait for human input, just, you know, go, uh, sometimes I call it YOLO mode because it means the agent is not gonna ask for any help. It's not gonna ask for any approval. It's just gonna go do the thing. T is to trust all tools. Um, you can also configure tool permissions if there's certain tools you do or don't want your agent to, to use, um, and then it'll run and then you tell it, OK, push the PR somewhere and someone will review it. Um, you can stick this in a container. You can stick this in a pipeline. You can stick this in an AW batch, AWS batch job. You can stick this on a laptop in the basement. I don't particularly care. Um, however you want to run your, your modernization campaign on whatever infrastructure you wanna run it on, as long as it's got, you know, node and Git and you can get your code onto it and it's Linux-based or, or Mac OS or WSL, um, you can put it there, um, so we, this is intentionally making it really flexible for however you like to work. Um, what else? Yeah, GitHub actions, Gitlab CLI, all sorts of places that, that you can put it. Um, obviously first class integrations would be nice if we could say, hey, this already exists in a GitHub action, um, or if we had a pre-built container we can give you and say, uh, go, you know, just use this, we're getting there. And then I just also wanted to note the AWS Transform web application. So if you've used AWS Transform at all in the past, you may be familiar with this web application. Um, this is where our mainframe modernization, our VMware migration, and our .NET modernization experiences live, uh, the parts of AWS Transform that shipped, um, a few months ago. Um, ATX custom is mostly CLI based, but it does have some connections into the, into the web app, uh, namely campaign management. So if you are a program manager or a campaign manager or just someone whose boss is like, hey, you said you're running this campaign. Like I want pretty charts of graphs. How's it going? Um, this is the place for that. So you can set up your campaign. You can see all the repos that have been executed, um, and I think we had a video for this one, right. Yeah, look at that. So, I'm a campaign manager. I'm a program manager. I go into the web app and um I tell it, hey, I need to, I need to upgrade all of my Python lambdas. What do I do? Oh, is it playing? Nope. Oh yeah, there it goes. I wanna upgrade all my Python lambdas. The web app has full knowledge of every transformation that's in the registry, so there's the AWS provided ones as well as ones that people in your organization may have created. Um, it's gonna pull down the relevant transformation. Whatever, it'll create a campaign. It'll give a command that you copy paste, you send to your developers, tell them, hey, go put this in your CLI, execute it, and as they execute it on their repo, um, it's going to save the results of that execution like, like, did it validate? Did it succeed? Did it fail, um, and give you that beautiful UI in the web. App to to see all this collective aggregated data and because it is AWS transform um you've got the agentic chat interface you can chat with it about that data you can say hey how many of these over the last month validated how many did not um any sort of way you wanna slice and dice the information the the agent can help you with that. Customization. Thank you, Morgan. So, um, we, we looked at how you can uh transform a single repo, we looked at how you can scale it to uh multiple repos. What ends up happening is that every customer that we talk to really has organizationspecific customizations that have to, that have to be done there. This is why we call the product AWS Transform Custom, even for things such as job upgrades, you have your own target versions, your own framework, your own ways that you wanna do things. So, Uh, when you have, uh, uh, an AWS managed transformation such as, uh, the ones that come right, right out of the box, you actually also still, uh, probably need to add some additional customization. Think about your organization's specific pattern, internal libraries, output style, you may want to have your own validation criteria like a special integration test or commands that you want the agent to run to make sure that things are working properly. As an example there, uh, when you're doing like a Python 3.8, 3.11, you may want to add an internal login framework that you wanna use, you may want to have specific uh error handling that how things you want, uh, uh, you want done in your organization. So, this customization happens once. But then the agent still continues to learn your, your organization's specific things every time that is executed. So, uh, developers that run it in interactively and provide feedback or um um or ways that that basically um the agent finds that don't work or that do work, the agent will still continue to learn. Sometimes though, you actually do need fully custom, and we talked about these things. There, there's organization frameworks, maybe you wanna have your own custom libraries or proprietary patterns, you have uh uh strategic migrations, you may want to change your authentication service, migrating from AuthZero to Cognito or vice versa, going from Splunk to crowd watch or vice versa and and doing vendor changes. You may, uh, harmonize the tech stack uh uh across merger and acquisitions or do architecture changes. There are multiple ways, uh, we, uh, you, you can create custom transformations using uh AWS transform. Um, these are like some of the ways that we usually propose. Uh, one is the prompt and refine. You can start with a simple prompt, the agent will ask some questions about what you wanna do, and basically, after you have a first uh transformation definition document, you can iterate on it depending on some samples and your And your, uh, in your examples. You can also start with guidelines. You may have a migration guide that's already existing. If you have an internal framework, you may want to provide a, um, API specifications of the different versions, um, uh, or, or and or very important before and after code samples of how you want things to do. Finally, you also have a way to, to have it like do it with me, uh, uh, which is like A way in which you have like a very simple transformation definition and you basically stop the agent while it's doing it, providing feedback. Uh, very, very important is references before and after examples, and after you're done, the idea is that you publish this new transformation definition on your organization registry that is associated to your AWS account. Uh, that is can can can of course be access controlled through IM. Let's look at the demo for this. OK. There we go. So, here, as Morgan said, we can uh start ATX here, it's, it's already installed and let's say that I wanna do something custom that is not available there. Uh I want to add open telemetry tracing to my node. Backhand apps. I mean, this seems to be like a pretty common modernization thing. You, you, you, you, you may also wanna change between those things. What the system is gonna do now is gonna go and look at all the transformations that are existing in, in my registry. We have a ton because this is our own internal account, but one of the things that I wanna show is at the beginning, is the list of the AWS managed ones with the description and what they are. So, after that, the agent is basically gonna say, OK, there is uh there is no existing transformation for adding open telemetry. It will help us create a new one. And it starts asking some questions and say, OK, what kind of backend do you have? Are you, are you planning to, uh, are you planning to use a specific backend and do you have some existing logging? What I wanna say, I wanna say, OK, these are like mostly Express and uh I wanna use AWS X-ray. And uh do I have an existing um if I do, I want to remove it. OK. Um, this is also the moment where it will basically ask Do you have migration guide, documentation, a whole bunch, uh, and, and an example for doing like before and after, how do I wanna do that thing? For open telemetry, what I can imagine is that you probably wanna have, you may have your own specific attributes that you wanna put, the kind of traces that you wanna have, but, and probably you want those things to be consistent across all of the repos. That would be the moment to add all all those informations. Now, it's gonna go here and it's gonna kinda um think for a little bit. And uh, OK, I talked enough to give it enough time to, to do something. This is great. And, and it basically said, OK, this is the first draft that it that it came up with. A orbit and I'm in tracing to such and such. It has some entry criteria, it has some implementation steps. The idea is that this is a TD file. I, you usually run this inside of an ID so you can basically say, OK, this is my, my transformation definition. You can open it, you can edit the MD directly and say, hey, I edited it. Or you can ask to change something. There's implementation steps and one of the things that is really important uh are the validations and uh and and exit criteria. It says, OK, uh, packages and has all of these things. Some of those, uh, um, some of these things may, may require for you to customize exactly what you wanted to test. You may have some, some, some integration test, you may have to provide your own way to actually test, uh, um, uh, X-ray integration, for instance. Or maybe you want to run some specific integration tests that are specific to your work. Um, the idea is that you can, you can look at it and you can now apply it and see what happens. You can review or modify, you can do anything like that. One of the things that I already did is that I used one of these, one of these, um, um, transformations earlier to actually create, uh, to, uh, to add telemetry to this NodeRest API and I created a diff in this file here. So, what I'm gonna do now, I'm gonna go and say, OK, um I want to modify the transformation. To Use these samples as references. OK. And if the demo gods are with us, they're basically going to say, OK, this is a this is a file, I'm gonna take it, I'm gonna add it to the to the uh to the demo and and basically what it, what this is doing is looking at these files that can be multiple files, could be APIs and what it is doing is it's analyzing, it's creating an Ingesting it into its own knowledge base, and it's also going and updating the transformation definition document to include the learnings from those, from those files. Now, this is if you have things already available, you can, of course, run it interactively and basically saying, OK, I would like to do um um I would like to do um um uh um uh to basically give feedback directly when it's running uh on a, on a specific uh code base. Now, this is, this is gonna create uh a TD. I'm not gonna wait for it to finish. After it's finished, you can publish it and you can run it like Morgan showed. Before, um, this can be, uh, uh, here is still like working, it's adding summaries and it's doing like a lot of other things. Now, let's say that I have this thing and we wanna run it. Uh, let me, uh, Julia Child this thing a little bit because, um, this is gonna take some time. Um, let's say that I run it on this, on this specific application. And what we see here, we see the transformation definition, it has the entry criteria, and it has a set of validations. After I run it, what it does, the system provides a validation summary, given all the validation criteria that I provided. So, it tells me, OK, this is what I did, this is what what happened, and the overall status was partial. It wasn't able to validate everything, but it tells me why. Um, 8 out of the 10 fully passed. Two criteria were partially met because I did not give it any information on how to actually test X-ray. I wanted to go and see the things were, were in X-ray, and of course I didn't give it any information to do it. This is really important if you want to automate these things at scale, because one of the things you don't want to do is for agents to fail silently, to basically say, OK, I did it, and then you have stuff that's not working. Because then, that basically means that all of the ones where it tells you that uh that are completed, you have to go and recheck everything. Uh, you wanna make sure that that the validation is is specified as precisely as you can, and that will make sure that you can automate things and I really have the savings that you have that you can have. This is the validation sum. After it's done, a really uh nice thing, we do require a gift in all of these in for all of these transformations. And if you go here, you see that it created different commits in its own branch. So, you can have every step that is in your That is in your transformation definition is in a specific plan that is being created to apply the transformation to this thing, you have a different um uh step that is committed here, and you can see and review exactly what happened. So, the, the first thing that it does, which by the way, was in the transformation definition was to add all the, all the packages as you imagine, and it created a new JavaScript file with With the tracing configuration for AWS X-ray. And this is the common file that is used by all the applications. Usually, you probably want to provide something that is very organization specific. You wanna, you, you, you wanna say what it did. Then it went and said, OK, these are my route handlers, data access. Let's look at like data access. You see here there's a lot of things that were added, um, from like orders create all this green is basically all the open telemetry spans that add the various attributes or order. user ID order that category, and all of this. Things are probably things that you may take like a first stab as it proposes, but you probably want to provide something that aligns to your own patterns and organizations specific things. These are the usual things that are specified in how do we want to integrate open telemetry in our code base. You give that to the agents, you're gonna make sure that all of the things, all of the code base in your uh in your um uh Or or or organizations follow the same patterns. You can also instructed to detect divergences. And a nice thing here is that uh you can also um. When we talk about this, OK, this added, I have my updated transformation, I can publish it. One thing that is really interesting here, and let me uh um actually start a different conversation. Uh, the, the agent knows what are the things that is good at. So, if I say something, um, can you transform DNET applications into Java? This is a hard thing. Um, and the thing is that you want the agent to know the thing that he knows how to do. It will basically tell you that, uh, that, well, OK, um, This is a very high complexity transformation due to the significant differences. So, you can still try to do it and it will basically tell you uh what kind of things you can uh um uh you should think about when you wanna do those things. If you, if you wanna separate it between extracting specifications, if you wanna use strangler fake, but basically, it knows the things that are easier or not. Now, uh, let's go back here and let me go back here to my PowerPoint. Here we go So What we have here, that was the open telemetry is a code refactoring, is one of the transformations that is one of the sweet spots that we have. Code refactoring, library upgrades, runtime upgrades, we've been dealing with those kind of transformations for the last couple of years in, in, in AWS transform, and uh and we know that the tool is, is designed to do it, but you will come up with new things. We've had Customers come with us with very, very strange things and sometimes uh they were able to, to be done very, very quickly, and sometimes they they required a little bit more complex uh uh setups. How do you improve the transformation quality? How should you think about it? The quality of the result depends on two things. One is the complexity of the transformation, like .NET to Java are really hard, the two different languages. It can be even harder, like, you know, a C to rust. Like it can be really, really hard. The other thing is the input code base. You may have a .NET to Java app that is 800 lines of code, may be able to do it right away. But even an easy transformation, even a job upgrade, applied to a 5 million lines of code codebase with multiple modules and tons of dependencies. It may still struggle, so. We continue to validate um the the transformations in our sweet spots. We have a ton of internal evals on internal code base, open source, and we always make sure that we that we improve that quality. But, uh, but you still need to have some improvement strategies. And there are some of the things that you can do at definition time. Providing high quality documentation and code samples. Running pilots, super important. After the pilot, you'll usually tend to have a lot of before and after examples of things that you want. So, um, so the agent can really learn a ton about those things. You also um um uh um. Uh, test it, continue learning in order to make it, uh, to make it work, uh, better. You can decompose the transformation, like Morgan was talking about before. For instance, if you want to translate across languages, you can first extract specifications, then do code generation. You may, uh, decide to decompose based on functional layers. Some of our customers said, OK, let me first migrate the data layer, then I want to migrate. And another layer, uh, uh, so on and, and, and, and, and, and so forth. Uh, during refinement, we talked about, uh, we talked about the pilots, you want to understand what kind of results you can have, and if you, and if you're seeing that you're not getting the quality that you want, that is the moment where, where you, where you have to reevaluate and say, OK, this is a really complex transform, let me decompose. Either the transform or the targets. Let's talk about value and pricing. The customers that we work with in, in, in the last 6 months reported 3 things that they were really happy about. On one hand, they, they were of course the direct time savings. It was faster than doing things manually. It was faster than just using uh general purpose coding agent. They were able to run it at scale. The other thing was, it enabled things that they thought that they were deprioritizing because they were too expensive. Uh, the Twitch team was deprioritizing doing the, doing the AWS SDK immigration for this year because they did not want to spend 11 dev years. It seems a lot, but fundamentally what it says is that, OK, we're gonna work on a year for a team with 11 people. It's possible, but it's not something they really want to do. Um, the other thing that was there was quality and consistency. Having consistency across all those 900 repos, or in case of like Air Canada, like thousands of lambdas was really critical. Most of these things are driven from, from centralized teams, and consistency is really important. They're usually in charge to make sure that things are, are, are, are consistent across the code base. And of course, they really saw continued learning um improve, improve the quality and uh um and compounding value. How do they measure it? There's of course efficiency, how fast did did did did you go? Quality metrics was also important. How many things have to be reworked. When we talked about the efficacy rating, um, 90 90+% of, of code base, uh, for, for Air Canada did not have to be touched by anybody. That code was reviewed and sent to production. 10% still have to be, you know, tweaked. Um, but that is like, um, um, um, there's a very big difference, uh, just taking a PR testing it and just flying through your uh validation versus having to tweak and understand and like figure things out. And then there's business impact. There's cost reduction. I think these are operating costs. You may have, uh, going to like more, more modern frameworks may actually save you money, less resource utilized, better, uh, better advantages, risk reduction, you may have, you're on the latest versions, more reliability, less security risks, and of course, strategic enablement. You want to be on certain frameworks, so it's usually a reason. This is generally available. It's available in US East one today, and uh we're gonna add all the other AWS transform regions in, in, in Quan. We are in 8 regions. We do have cross-region inference, but they are uh geo-related. So, North America, North America, Europe, and, and like things like that. The pricing is pay as you go, as uh Morgan was, was talking about is $3.05 per agent minute. What's an agent minute is basically how much. It's, it's a notion of the, of the amount of work that the agent takes. You only pay for active agent work. So, if the agent is waiting for your codebase to compile on your thing, you're not paying for anything. Um, if, uh if you're waiting idle because the user is like waiting for something, of course, you're not paying anything. Um, however, multiple agents may collaborate to do your transformation. So, 15 minutes uh of uh Uh, wall clock time on the service side may actually result in a charge of 20. Um, the, uh, we have some examples there and that's why we, we suggest to run pilots on your own specific, uh, transformations to have an idea. However, the cost is small enough that it should not be, uh, hard or prohibitive to try these things. You can always interrupt, you are, you're, you're in full control of how much you spent. What we suggest you to do and uh what I, what I incite you to do, guys, is that to build confidence through uh through through progressive learning. This uh it's, it's hard to use AI to do these things autonomously. It's kind of a step level from using an agent interactively. Uh, what we suggest to do and what we see in successful is basically to start with things that are, um, uh, uh, simple and and already provided by um by, by AWS. One low risk and high value way it, it is to start with the with documentation, you can learn the workflow, you You have no code changes, so there's no risk of like messing anything up, and you can build familiarity with the tools. Uh, you can then go on AWS manage transformations. Every customer we talk to have problems with uh runtime upgrade and, uh, and, and end of life, and, and SDK upgrades. This allows you to learn the end to end workflow, to experience continued learning in actions, customize this thing, tweaking them for your own specific organization, and uh, and you can start measuring savings and see, and see what you can get with the, with this technology. You can then move on to To simple custom transformations, think about logging, adding open telemetry, trying to modernize things from, from that perspective. In my experience, every company that I talked to has one of those backlogs hidden in their, in their, in their issue trackers. And uh finally, you, you can move on to more complex custom transformations in the context of larger modernization, um, architectural changes, language changes, and things like that. So, uh, there are some resources here, uh, you can, uh, learn about AWS Transport custom on our, on our, uh, website. There's a handsome demo. It's super easy to, to get started with the CLI, no complex setup needed, runs on your laptop basically. Well, it ran on mine. Um, I'm really happy to uh that you guys chose to spend your time here with us today. I'm really looking forward to see what you guys can build with this uh with this technology and what kind of transformations you can do. Thank you.