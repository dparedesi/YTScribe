---
video_id: uOMh88Fz40M
video_url: https://www.youtube.com/watch?v=uOMh88Fz40M
is_generated: False
is_translatable: True
summary: "This breakout session from Amazon's AGI Lab introduces Amazon Nova Act, a frontier-class browser automation agent that treats computer use like humans do—looking at screens, understanding context, and taking actions iteratively. Kelsey and Ian from the San Francisco-based lab explain that legacy browser automation (Selenium, Playwright) required months of development, broke when websites changed, and couldn't generalize across workflows. In contrast, humans navigate any email client intuitively by recognizing patterns (compose buttons, pen icons, top-of-page placement). Nova Act brings this human-like adaptability to agents, using natural language rather than brittle code. The core differentiator is reliability, approached as P-0 through three strategies: (1) Intensive element understanding with training data specifically on challenging components like date pickers, dropdowns, and filters; (2) Reinforcement learning on hundreds of mock website simulations (gyms) where models explore without prescribed workflows, only validated on end-state success; (3) Real-world evaluation focus where early customers achieve upwards of 90% reliability in production—critical because 'an agent that is 50% reliable is 0% useful.' New capabilities announced at re:Invent include Human-in-the-Loop (HITL) for configuring agents to call humans via Slack or custom UIs for takeover or review, and tool expansion beyond browsers to read from Jira, Excel, and other desktop applications. The session details the full AWS service launch: a new console, online playground for no-code testing, Python SDK, VS Code IDE extension with notebook-style UI for iterative step debugging (saving up to 80% development time), CLI for packaging and deployment, and observability via the AWS console showing every screenshot, thinking statement, prompt, and action. Four use case clusters emerge as low-hanging fruit: Web QA testing (natural language tests that adapt to design changes), data entry automation (CRM updates, tax filing, license applications), data extraction from fragmented systems without APIs (healthcare, logistics), and e-commerce/travel checkout flows. Three customer case studies demonstrate production value: **1Password** uses Nova Act to build universal sign-on by deploying agents that autonomously analyze millions of websites, collecting site-specific intelligence about login flows (button locations, JavaScript handlers, form structures) that feeds back to their browser extension for deterministic, fast execution. This enables password-free login experiences across any site without manual encoding. **Amazon Kuiper** (satellite internet) achieved prototype-to-production in 5 weeks, running 200 live scenarios with 3,600 validation points across web, iOS, and Android using a unified Gherkin-to-Nova-Act conversion framework. They built a self-healing replay engine using Nova Act's trajectory exports for deterministic re-runs, with agentic fallback when pages change, saving 60 dev days initially and 30 monthly. **SOLA** (agentic process automation for Fortune 500s) uses Nova Act as a steerable workhorse for computer use, implementing fleet orchestration patterns with parallel sub-agents aggregated by orchestrator agents. They achieve near-100% reliability on core enterprise workflows like medical data entry and financial compliance. Healthcare company R1 RCM uses SOLA to handle hundreds of different payer platforms. A multi-agent demo combining Nova Act with Nova Chat (LLM) and Nova Sonic (voice) shows booking interplanetary travel through natural conversation."
keywords: Nova Act, Browser Automation, Computer Use Agent, Reliability, Human-in-the-Loop, Reinforcement Learning, Web QA Testing, 1Password Universal SignOn, Amazon Kuiper, SOLA, Agentic Process Automation, VS Code Extension, Trajectory Replay, Fleet Orchestration, AGI Lab
---

All right. Welcome everyone. We're gonna go ahead and get started. Thanks all for joining us for our breakout session on Amazon Nova Act. My name is Kelsey. I am here from our Amazon AGI lab based in San Francisco. We are a team within the Amazon Artificial General Intelligence org that is specifically focused on pursuing long-term. Research bets and the focus of our lab over the course of the last year or so has been specifically on agents. We are really excited about this paradigm shift that we're seeing in the industry from models that give us answers to models that take actions, and I know this is not the first time you've heard about agents this week. They've certainly gotten a lot of talk over the course of reinvent. We've started with the browser because this is as close as we can get to a near universal action space in the digital world. And we've been working on this problem of training models and providing solutions that allow for human-like performance when using a computer. What's been interesting about this problem is that it has existed for a long time. You've had people wanting to automate computer tasks basically as long as computers have existed, and the solutions have also existed for a long time. So some of you in this room may have used more legacy browser automation solutions that are code-based and involve basically writing a considerable amount of logic to specify exactly what you want an automation to do, to go use a computer and perform a task. So here's an example for grabbing the weather from Weather.com. These solutions were a really great starting point to this problem, but they came with certain challenges. What we hear from customers is challenge one. These solutions took many months to get up and running in many cases. Uh, they were great for one static website or one static workflow, but as soon as a website changed, they would break and so there was a pretty large maintenance burden involved with this approach. And then the biggest thing is there was really limited generalizability because as a developer you had to specify. Every step of the workflow. If you created one workflow for one geography or one SKU or one workflow, but all of a sudden you had to scale to the full scale of your organization, your business, and generalize to 50 different states or hundreds of different insurance companies, all of a sudden that problem became untenable and the technology was not really working with you to get to the scale that you need. What's interesting about this problem though is that as people, we do not run into these same constraints when we face problems related to computer use. Regardless of which email client you use and love, if I show you any email client and ask you to write an email, I'm fully confident that everyone in this room could figure it out. And the way that you would know how to do this is actually kind of hard to encode in a rules-based way because you probably look at this screenshot and you're looking for a whole combination of things. You're looking for maybe a pen icon. Or a button that says compose, maybe it says draft, maybe it says new. It's probably towards the top of the page because writing an email is a key piece of functionality for an email client. So maybe it's separated from the other functions in some way. All of this is intuition that we've built through millions and millions of examples of using UIs and recognizing these common patterns. But software doesn't have that inherently. So what we've been really excited to do as part of the lab is build models that treat computer use more like how humans do. And that's what we've built with Nova Act. So the goal here again is to train models that interact with a browser like a person. They look at a screen, they take a task, they understand what's going on, and they determine what to do next. And then once they've performed an action, they repeat that same loop. They take another screenshot, they understand what's going on in light of the. And they take another action to continue on the journey just like we do as people. So these systems are way more robust. They don't fail due to a small change. You can get up and running much more quickly through natural language, and you can scale just in the same way that we know how to perform that flow across any email client. These models can also generalize across different environments. But if you've been following the agent space, that's not the first demo you've seen of agents or of computer use in particular. The biggest bottleneck we hear from customers is reliability. We hear from a lot of customers that they're super excited about agents, they believe in the future, and they're very quick to build a prototype or a proof of concept, and then they get stuck because while these models hold lots of promise and these solutions are very exciting, they don't actually work in a repeatable, scalable way that you need when you're trying to solve real business problems. And this has been a core focus of Nova Act. We've approached reliability as the P-0 as we've been solving this problem, and we've done so in a few different ways. The first is really zoning in on element understanding. So what we've seen is for a model to work end to end in a reliable way, it needs to really understand web elements in the way that humans do. So there are a number of culprits that typically stump agents. Uh, these include date pickers, drop downs, certain types of filters. These components are different on every site, and often agents don't know exactly how to handle, you know, waiting the correct amount of time to load after you type in a zip code, these sorts of idiosyncrasies. So we spent a lot of time collecting training data specifically on these components, evaluating our models on these areas to make sure we get to that end to end reliability. The second is using reinforcement learning specifically on web simulations or gyms. So the way that this works is we've built hundreds of examples of mock websites that have the similar components and types of UI patterns that you see across the web in the workflows that our customers are performing every day. And then we tell the model to go complete a task, and we don't specify the workflow or the steps that the model should take, we just validate that that end state is successful. And so what this allows is for our model to do a large amount of exploration of these different platforms to really understand what's possible, what happens when I do A, what happens after that, um, and to really understand different patterns for success here. So this has been a really key part of achieving reliability. And then lastly, we've really kept real world evaluation as our focus. Um, you'll see some exciting benchmark results with the latest release of Nova Act. We're really excited to see that our model is outperforming models of similar size like Haiku and even much larger ones like Sonnet, but ultimately, the metrics we care most about are related to customer success. And what we're seeing with Nova Act is that early customers are seeing upwards of 90% reliability on the workflows that they're deploying in production. And this is really important to us because we believe that an agent that is 50% reliable is 0% useful. Customers need agents that actually work in production, and this is what we're seeing today that we're really excited about. Even the most reliable agents need help and need human oversight sometimes. And so, with this release at Reinvent this year, we are excited to launch human in the loop capabilities with Nova Act. So this allows you as a developer to configure the ability for the agent to call on a human either to take over on a task or to review a task before the agent continues. You can do this through platforms like Slack, um, through custom integrations in this case, a custom UI and facilitate this human supervision of fleets of agents. And then we're also expanding beyond the browser. As I mentioned, browser is the place that we started off with Nova Act. What we've heard from customers is folks are excited to extend that same level of reliability across their full workflows even beyond the browser. And so we're getting started on this in preview with Nova Act now and we see. Customers doing things like reading their QA tests from Jira and then implementing them using Nova Act in the browser or taking form fill inputs from Excel and then filling out that form in the browser. So we're just getting started on this journey but really excited to extend beyond what the browser itself is capable of. All of this is very exciting, but what we've also learned is that having a really reliable model is necessary but not sufficient for building great agents at scale. Customers run into these questions, how do I debug? How do I measure success and deploy and scale? And these are equally important questions in the journey to developing agents that really have true business impact. So now I'll have my colleague along and talk about how we've tackled this problem as well. OK. Thanks, Kelsey. Uh, my name is Ian. I'm a product manager and a member of technical staff at the, uh, AGI Lab, and it's great to see everybody here. Oops. I need this. So, let's go back a little bit to how we started on this journey. So in March of 2025, uh, we released a research preview, and since then, we've had a bunch of people using our, uh, using our product, using our system, and they gave us a lot of feedback. Some of the feedback was about reliability, about the 90% reliability that Kelsey mentioned, which is absolutely critical. But we also got feedback that in order to release an agent into production in an enterprise, we need security. It needs to be, uh, it needs to have all of the AWS um security capabilities that everybody here has come to know, know and love. So in July, we did our first, uh, integration with AWS and our first users were able to use AWS uh authentication and S3 uh for saving the logs and things like that. So that was, that was our very first. First, uh, attempt at integrating into AWS. This week, we're happy to, uh, announce that we've launched as a fully, generally available end to end, uh, AWS, uh, service, uh, fully integrated as, uh, uh, we have an AWS console, we have, um, basically everything that you expect from, uh, from a proper AWS service, and I'll walk you through them now. So, our, our new AWS service includes the following. First of all, it includes a uh Frontier class, uh uh state of the art model, as, uh, as, as Kelsey mentioned, it's as good as anything on the market, if not better. Uh, a new AWS service and console, which I'll walk you through in a few minutes. Uh, we have a new playground. Um, you guys can all go to our online playground and, and try out, uh, the product without having to download an SDK or, or write any code. You can see if it works for you online. If it works for you, then we have the SDK, which you can use for coding in Python. We've had a, uh, uh, an existing one, so this is an updated version that uses our new model and is uh uh able to work with the new capabilities like uh human in the loop and things like that. And we have a new version of our IDE extension, which I'll show you as well in a few minutes, uh, again, uh, to use, uh, uh, use the new model and the new capabilities. We've built, uh, a CLI which makes it really easy once you've built your agent to package everything up into an image and, um, and deploy it. And we have these new capabilities like human in the loop and tool use. So we're very excited about this. It's our end to end, uh, platform. Um, we feel that it provides a few, uh, benefits to you. First of all, um, frontier class, uh, accuracy. But more importantly, while benchmarks are important, um, real world reliability is actually much more important to our users. So we've spent a lot of time training our model to make sure that it can achieve over 90% reliability on the sort of typical day to day enterprise use cases. Thirdly, cost effectiveness. Uh, we've priced it, um, to, uh, very aggressively. We feel that it is the most cost-effective solution on the market for similar, uh, for similar, uh, products. Uh, and lastly, uh, time to value. We're, we're really proud of the work we've done in building a terrific, uh, developer experience, and all of these together. Um, simply put, we feel that Nova Act is the best service for, uh, creating, uh, AI browser-based agents and, and creating ones that you want to actually use in production in the enterprise. So let me walk you through that developer journey. First of all, you can prototype on the online playground, build with the SDK and our ID extension, deploy to AWS, and observability via the AWS console. And now I can show you some, some examples. This is what our online playground looks like. You can see on, on the left, you can enter natural language uh prompts. Um, on the right, we've got an embedded browser, which is uh currently running a, a web gym, a simulation of a travel site. This is a travel, we mocked up a travel site, uh, for buying tickets to other planets. Um, and on the bottom, you can see the, uh, the agent's, uh, thinking steps. So you can try out your use case, see if it works here. When you're ready, you can click download, and it'll download the agent you've developed as a Python script, which you can then continue developing. On your, on your laptop. On your laptop, you can use uh the Novak SDK and we highly recommend you try out our uh VS code uh IDE extension. It works on any VS code compatible uh IDE and it's got a really terrific uh UI that really simplifies things. On the left, you can see a notebook style UI where all of the agent steps can be broken out into separate cells. What this gives you is the ability to iterate and keep on tweaking an individual step until you've got it exactly right. Without this, you have to keep rerunning your agent from the beginning, and it's a real pain waiting for it to go through 30 steps until it gets to the one that you've that you've tweaked. Um, our initial users have said that it can save them like up to 5x, like up to 80% of the time. And um on the right, you can see, uh, we've embedded uh, a browser right in the, uh, right in your IDE. So, again, we've got everything that you need in one, in one space. Again, when you're ready, We have a deploy tab, and this makes it super easy to insert your AWS credentials. And with one click, it'll build the uh agent image that you need to deploy. So it'll use the, uh, your Python script, the SDK. It'll also um uh take care of allocating the resources for you, the uh ECR repository, uh, S3 bucket, set up your IM, uh, execution roles and things like that, and deploy everything to AWS for you. So again, super simple. And then once you've deployed your agent to AWS, you can use our console and see all of the agents that you've deployed, and for each agent you can see a record of every single agent run. So this is an example, you can scroll down and you can see all of the screenshots, all of the thinking statements, um, the prompts, and all of the actions that the agent took. So this is terrific for uh troubleshooting and for um uh customer support. Thirdly, sorry, you can also use Nova Act as part of a multi-agent framework. So here's a, here's a demo of something that we built that uses, um, uses Nova Act in conjunction with two other Nova models, like a NovaCchat LLM model and uh Nova Sonic, which is a voice model. So I'll just play this video for you to see. Hey Nova, I'd like to plan a trip to the closest exoplanet. Maybe Something warm With a beach The closest exoplanet we know of is Proxima Centauri B orbiting the star Proxima Centauri, which is just 4.24 light years away. Proxima Centauri B has abundant green oceans and beautiful beaches of fine orange sand. The average temperature is 86 °F. What date would you like to travel? In one month So, January 3rd. OK, great. Would you like me to book a flight to Proxima Centauri B? Let's do it. Got it. Let me generate instructions. OK, first, I need to find a ticket from San Francisco to Proxima Centauri B for January 3rd, 2026. So I think you guys get the idea. So the basically the idea here is that you can build really cool experiences by, uh, using multiple agents together, um, in the same, uh, in the same agent gentic solution. Um, So as we've been working with design partners and with the initial users over the last year, um, we've seen a lot of different use cases appear and in fact, if you think of Nova Act, it's, it's a very powerful and very low level primitive that can be used for innumerable use cases, literally thousands and thousands of use cases, but as we saw what people are doing, we've seen them. We've seen that 4 typical uh clusters of use cases appear most often, and these are use cases that we feel are the lowest hanging fruit and will allow you to really get, get a lot of value in the near term. Um, the first one is uh web uh QA testing. So today, if you want to build a regression test on a web application, you need an engineer who needs to write code using something like a selenium or a playwright, um, and that code is brittle. If a button moves in the website, then suddenly that code doesn't work anymore. With Nova Act, you can use natural language prompts, and it'll understand what the site is supposed to do, understand if the design has changed, and it'll just work. Next example is data entry. Every company has uh many, many workflows that involve uh doing things that involve manual transactions with websites. For example, salespeople, after a meeting, they have to come in and enter in a bunch of information into a CRM system. People have to file taxes, people have to file uh licenses or apply for licenses in different governmental websites. So there's tons and tons of these, we call them undifferentiated manual tasks that people have to do that don't really add that much value. So, wouldn't it be great if we could help you guys automate those so people can do what they, what they really like to do at work, which is, you know, be strategic and creative and do what their real job is. Similar for data extraction, there's many, many industries like healthcare or logistics and, and many others where there's thousands of fragmented businesses and websites, and none of them are going to have APIs in the near future. So having a system that can automatically reach out to these different systems and collect data from them is, is of huge value and saves a ton of time. And checkout flows for e-commerce and for travel and things like that. We've also seen as being a very, very popular use case, and people are automating thousands of these at scale. So now what I'd love to do is introduce you to some of our uh design partners. They're gonna walk you through a little bit about their company and uh how they've uh been able to innovate using, using Nova Act. So the first one, I'd like to invite Flores to the stage from, uh from OnePassword. Thanks. Hey, everyone. Hi, I'm, I'm Flores from the engineering team at OnePassword, and, um, today I'm gonna show you how One OnePassword is using agentic AI, um, to improve our own product in a way that just wouldn't be possible in a pre-AI era. And the star of the show here is really Nova Act, um, and so a little bit about one password, uh, we secure 1.3 billion credentials for 180,000 businesses and millions of users. Um, and millions of users who use one password every day to log into their favorite websites, and we don't just store logins for the developers in the room, we also store SSH keys and sensitive.n files, and these also come with native integrations in the desktop apps. So, let's talk about autofill. So we have uh a browser extension, um, and this browser extension, this, it'll add a small one password icon in the uh next to your login forms. Um, and if you click on that icon, you can choose a credential that you wanna use to log in. And um one password and does the, the tedious work of like filling out the form and and getting you logged into your website. So this has been out for a while, um, and it's been working great, but it's time now for the next generation of Autofill and. This is what we're calling universal sign-on. Um. And with universal sign on we wanna take the experience from um like hey one password, fill in this this form for me to a more high level approach where you say hey one password just log me in just do whatever it takes to log me in regardless of the login method whether that's a username password or a TOTP MFA enterprise SSO, a passkey or like the signing with GetUp or Google, which you probably forgot which one you use which with which website again, um, and so here's a preview of, of, um. Of what this looks like. So now you can just click on a website, and it'll immediately navigate to the login page, and immediately log you in a password with an MFA token, and you're just logged in like that. Now let's talk a little bit about how this works. Now, there's unfortunately not a standard protocol for logging into websites. It's basically like free for all HTML and the sort of, yeah, there's a lot of ambiguity out there. Every website does it slightly differently, um, and autofill, the classic autofill algorithm, it solved the ambiguity with, um, like a one size fits most algorithm that's based on heuristics, and it's been working quite well, and it's, it's being used, uh, millions of times every single day, um. And but yeah, so with, with the vision that we have for universal sign on, um, it's, it's, we're running into the limits of, of the heuristics that we can articulate in our code. So because right now the browser extension, it doesn't just need to know how to fill in a form, but also like how to navigate to the form, how to, how to navigate through the form, which is just a lot more complex. So to make this a success, we're gonna need like website specific logic, website specific instructions on how to complete the login, um, but yeah, as you can guess, this doesn't scale if you need to do this by hand because there's millions of websites out there that offer a login. And even if we were to, to do this massive undertaking, it'll be very, very brittle, um, because yeah, we would see, we would see breaking changes on a daily basis, which is really not acceptable. So this is where Nova Act comes in and what we've done, we've built an AI agent that uses Nova Act and that goes out and browses all these websites and yeah, it'll collect the necessary information about the, the specific oddities of, of, of each, each website and then we have a second agent that then gathers or that sorry that that validates this intelligence that we've gathered and then it passes it on to what we call the site intelligence engine. And the site intelligence engine makes it available to our browser extension, and the browser extension runs on the user's device, um. And the, the nice thing about this is that all the, the information gathering and validation can run on our infrastructure out of band, and the browser extension, the login flow will remain blazingly fast and also deterministic, which is, which is really important. And the validation, we can also run this on a periodic basis to see if the, the, the intelligence that we've gathered is still accurate and correct and if not invalidated. So let's look at an example of a Nova Act agent in practice, so. Here it's gonna navigate to the AWS reinvent website and this is actually a pretty simple example um because its job here is to get to the login form and as you can see on the top right it has a big login icon so this, this is a this is a pretty simple one. Let's see if it's able to find it. There we go. And now it found the login form and it knows that it completed its task. Now let's look at a slightly more complex example. It's a bit more tricky. This is Duolingo, and this one doesn't have a traditional login button at the top right, but it has a button that says, I already have an account. Uh, and also to make it more complicated, it doesn't have uh an HRf tag. It's, it's a Java, it has a JavaScript handler, and, and this would be a bit more tricky to, to build with a heuristics-based algorithm. Um, but yeah, for humans it's super easy because it's, it's just as I already have an account and because Nova Act takes the same human approach it's able to just as easily get to to the login form here as well, um. Cool. Now let's have a look at, at the, at the logs here. So along the way, Nova Act will, will log the steps that it takes as part of the evaluation loop, um. So here you can see it, it really thinks like a human. It's, it, it, it, it knows what what it needs to do and it's, it says, uh, it, it found the button off that says I already have an account, um, and then it figures out that it should click it, then it does the actual click and then it evaluates the result again and it knows that it's on that it found the login form and it knows that it completed its its task and that it needs to return now. So to recap, the website specific intelligence can meaningfully improve the, the one password products, and Nova Act is, is really, um, the thing that enables us to do it at this scale, uh, and in a way that we just couldn't, could not have done in the, in the pre-AI era, um, and we still have a long way to go here. We're just scratching the surface, but if you can already try out the, the new universal sign on UX in the latest beta version of the one password browser extension if you're interested. Cool, I'll pass it on. Perfect. Thank you, Flores. Super interesting. And now I'd like to invite Matthew from Amazon Leo. Bye. Hey folks, uh, so I'm Matthew. I'm from Amazon Leo. Amazon Leo is the next generation of satellite Internet connectivity that Amazon is building. Uh, we currently have 158 satellites in space right now, always launching more. Um, and space always elicits like a little sense of like wonder and whimsy, right? And so as we get closer to launching our beta product, we had this like really big task because we set zero like critical customer bugs being reported across like our web and mobile browsers. And that's like really aggressive, right? We have hundreds and hundreds of test cases we need to perform. Um, you know, we have an aggressive timeline because we're always building, we're always shipping, and we have like weeks to do this, right, not months. So, I'm gonna talk a little bit about how we leverage Nova Act to go from like a prototype into like a production grade QA automation system today. Um, so, traditionally, you kind of see like, uh, our like traditional automation has really complex code. You have to work with multiple frameworks. Each of those are really its own unique specialty, right? You need people who understand like Appium selectors for mobile if you want to serve like Android and iOS. Uh, you need somebody who really understands selenium or a playwright and knows how to like handle page jitter and like, how long should you wait? You gotta get it just right. Uh, Nova Act likes to invert that, right? I don't need to know that anymore. I don't need that specialty. Um, and so what I can do instead is turn something else into it. So what we've done is we've taken a little bit more opinionated approach to natural language. We had hundreds and hundreds of these like G Gherkin test cases, you know, given when, then, uh, for our customers. And so we built like an agentic framework around it. And so, uh, on one side, we take this given when done statement, we use a strands agent like we saw earlier today, and we convert that into the Nova Act command on, on the fly. Uh, then we determine like what type of test is this? Is this a web test? Is this a mobile test? And so if it's web, we use the playwright, uh, actuator that comes baked in with Novakc. Uh, for mobile though, Novak doesn't support it, but they do have a really extensible, like SDK framework that allowed us to write our own Appium actuator to go in and start performing these actions in our mobile app. So we have one SDK, one unified interface, with no like platform considerations anymore. You just run the test, it figures everything else out for you. Right? And so, one of the other things we talked a lot about today is, you heard the 90%, right? And the 90% and the 90% and the 90%, uh, when you're running QA automation, and you're looking for like, Understanding the perfect customer experience, uh, you need that to really get closer to 100%, right? And so one of the other things that Novak provides us is the ability to like export a trajectory. And what that is, is every piece of information that Novak performed during the test, it saves. It saves a picture of the page, it saves the DOM, it saves where it clicked, it saved how it thought about the problem. And what we can do is then replay that deterministically for our next run. Right? And so we've built a self-healing replay engine too. As our page changes and our customer experience is like changing, our core mission of the test case hasn't changed, but the page has moved around a little bit. And so, we will fail our test case because we couldn't necessarily match in the deterministic way anymore. And we will rerun gentically, and then save that. And then the next time through, it'll pass. So we're running 3 times faster. Uh, there's no more like non-deterministic behavior that we're worried about over and over and over again. And we get really good confidence that our experience is shipping the way we want it to. Right, so let's take a little look at like what this kind of looks like in action. Right, uh, so you can see like step one, given a user successfully navigates to Leo.amazon.com. Step 2, when the user clicks on the join the list button in the header. Step 3, and the user enters Leo user at Amazon.com into the email input field. Step 4, and the user enters 98052 into the postal code input field. Step 5, and the user selects United States from the country dropped out. Step 6, and the user clicks the submit button. Step 7, then the user should see a confirmation message indicating successful submission. Awesome. So what you got to see is that we transformed everything on the fly, and we're running this in real time, right? And we get to see how our systems are thinking about it. It's very easy for us to debug, and it gives us really high confidence in both when we do see a failure, why are we failing? And um when it's passing, we know exactly why, right? What was it thinking? How did it get there? Right? And so we can see like this is the type of customer behavior that's gonna happen in real time. Right? So, again, uh, prototype to production in 5 weeks. Um, the 1st 1 or 2 weeks is really setting the groundwork, right? Making sure that like our agents, uh, you know, if. You got to handle throttling, you know, all those little fun things when you're engineering. Uh, weeks 3 and 4, we're getting a production ready, moving it into like accounts that, uh, can hold and manage all the data that we're running through. Week 5, we're now running 200 live scenarios, 3600 validation points across web, across iOS, across Android. Um, you know, we think we've estimated and saved about 60 dev days to date, and we're saving another 30 every month. So thank you and I will bring up uh Neil. Cool, thank you, Matthew. And now I'd like to introduce uh Neil from SOLA. Thank you. Everyone Hey, I'm Neil, co-founder and CTO of ZOA. As we know, enterprise work today happens across more systems, teams, and tools than ever before, and process automation remains a massive challenge with teams struggling to get value. Oh So what do we need in this next generation of process automation tooling to automate meaningful core operations of businesses? We need the tool to understand what people do. That means observing their work, figuring out their process, and capturing logic and context effectively. We need it to generalize across all these systems on browsers, on desktops and beyond. We need it to handle challenging and dynamic digital work. And of course, we need the solutions we build to scale to enterprise volume. This is where Solar comes in. Solar is an agentic process automation platform. Some of the largest enterprises in the world, Fortune 500s and the largest private, uh, enterprises across verticals and industries use Solar to power their businesses, building intelligent, uh, intelligent, flexible automations that do everything from medical data entry to financial compliance to legal back office and much, much more. Solar automation sit on top of systems and interact interact directly with digital applications and underneath the hood, this is powered largely by CuUA or computer agents. They're the systems that everyone's been talking about today. Uh, they are systems that can see, understand, and operate applications just like you and me. So In this video here, we can see a solobot running a generalizable track and trace workflow. So let's see. Oh, OK. Uh, the Solobots can understand how a workflow is done by watching someone do it, converting their process into a visual diagram that users can modify. Then it can execute real executions of these workflows, adapting to dynamic interfaces and automatically updating the diagram based on encountered scenarios. It does all this while providing observability and learning from human intervention when needed, becoming better and better over time. These bots help handle some of the most complicated manual workflows for businesses at scale. As mentioned, a lot of what powers this is KUA models, and we use a variety of them under the hood. Novak in particular though, fills an important niche for what Solar does. It's a powerful workhorse for our computer use needs. Oh, sorry, let me. Yeah. Uh, computer use needs, it's steerable. It adheres to complex instructions reliably. It allows us to enforce strict guardrails to guarantee the reliability that enterprises need, and it's able to handle complex interfaces with state of the art intelligence while operating in real time. Here's a simplified diagram of how a solobot can use Nova Act, and generally it's a reliable framework for using KUA. If there's an instruction that's been scoer Nova, the solo bot will hand off the task to an orchestrator agent. This the agent has those instructions along with context about the workflow, the current execution, previous executions, business context and logic, and more. Given all that information, the agent will break down the task into subtasks. In this case, we have like action A, action B, etc. The actions will be handed off to SOLA, uh, sorry, Nova Act sub-agents, which will go off and complete those tasks. Then given all the context described before, along with the output of the Nova Act subagent, which has transparent reasoning and action traces, the orchestrator can validate that action and plan and update subsequent tasks accordingly. Nova Act is specially built for this kind of UI automation. The piece I mentioned before is just one part of our Asian harness. We have a ton of places we use CA models. The Novak SDK makes it really straightforward to integrate across our entire platform while also automating the, uh, while also supporting the observability that we need for monitoring. Its extensibility allows us to set up custom tools, uh, to complement the rest of our harness. As a workhorse model, it's fast and reliable, keeping workflows moving in real time, while also automatically handling those edge cases like complex error states and conditional logic, while also effectively calling human in the loop when needed. Here's a more advanced fleet orchestration pattern that the Solobot can deploy off, which I also think is a good framework example. Similar to before, the orchestrator can break down actions into tasks, but here, these are handled by Nova Act sub-agents in parallel. The thinking and action traces and the results of each of these Novak subagents are aggregated via an aggregation agent that's then passed back to the orchestrator to plan and conduct future tasks. With this kind of system, we can achieve near 100% reliability on these core enterprise workflows. Here we can zoom in on a specific case. Here on the right we can see a representation of the visual diagrams on the solo platform. Uh, on the bottom left we can see an example of a portion of this workflow where it's logging into a medical portal, it's navigating to the patient, updating the patient field, and on the upper upper left we can see the agent traces. So this is the model doing that update patient field. In this case, it's non-trivial, the, it's not just updating one specific field. The model needs to understand, that needs to click on a button to add an entry, and then it needs to look over the entire form, figure out exactly where in the form that update needs to happen, and then put the relevant information in very reliably. So SOLA is a customer of Nova Act, but downstream of that companies like R1 RCM, one of the largest revenue cycle management platforms in the US with tens of thousands of employees, use SoLA to tackle back office work. Uh, and for definitions, RCM stands for, uh, revenue cycle management. It's basically how your doctors get paid. Because Solo workflows are adaptable, they can handle the hundreds of different, different pair platforms that a portal like R1 needs to interact with on a regular basis. Nova Act has been integral to the Solo platform, allowing us to push the boundaries of what computer use models are capable of, to conduct real world work for enterprises. With partners like AWS we're able to support automating the most core and critical operations of businesses today. Thanks, um, I'll hand this off. Oh, thank you, Neil.