---
video_id: 5wp6W_I7B5E
video_url: https://www.youtube.com/watch?v=5wp6W_I7B5E
is_generated: False
is_translatable: True
---

Hello, hello you all. Welcome to this presentation. I'm going to be talking about the AI offering that we have at Hiroku. Uh, before we start, I'm going to introduce myself. My name is Julian Duque. I'm the principal developer advocate for Hiroku, which is a salesforce company. And being a salesforce company, we are a publicly traded company, so please don't make any purchase decisions based out of things that are not yet publicly available. I mind me mentioning things that are not yet fully GA. So Erou is a platform as a service. We have been in the business since 2010, 2011. We were the first platform as a service for Ruby on Rail's applications, and now we support more than nine programming languages and some other managed services. We are renowned for offering. A great developer experience and our developer experience is that good that a lot of companies, open source products have created the Hiroku of X. They try to mimic our experience and create something out of what we do. So a couple of years ago we asked ourselves this question Who is going to build the Hiroku of AI? Who is going to bring the developer experience of building AI applications that offers Hiroku? And of course the answer was ourselves. We are going to be building the Hiroku of AI. So basically building AI applications and agents is challenging. You will need to make a lot of decisions and take care of things that are not usually pretty much obvious. For example, we need to select the right models. The large language models we are going to be using for our application, if it is like a text to text model, image generation model, if we are going to do embeddings, we need to make sure that we are using the right model for our app. Also, how are we going to integrate with the other applications and services? How are we going to allow the LLM or the model to access data securely? Because right now one of the risks about building AI. is that data leakage. We are giving access to our data to a third party that can access to it and it might be vulnerable to certain to certain security issues. And also, how are we going to operate the infrastructure behind AI? There are like a lot of hidden things that we don't know like managing GPUs, being able to maintain the models running. There is a lot of complexity behind. Also, it's hard to make things easy for developers, easy for the company to operate and manage. Eroco has been working in a platform for a while, so we already have an integrated platform where you can use and deploy your applications and agents. We have great developer experience and operational experience. We already selected a list of curated AI models that we know are um Used in the industry and that are working for these new type of applications and we also added extensibility through the model context protocol, which is this protocol that allows the LLMs to have access to more context through prompt resources and tools. And getting life, getting to production is hard. We need to make a lot of decisions that are complex. For example, when we want to take an application or an agent to production, we need to choose where are we going to deploy this application, what is going to be the underlying operating system and the network configuration that we will use for our app. How is the CPU and memory going to be distributed for our application? What is going to be the data stored, the logging, the observability? So there is a lot of moving pieces that are related to deploying an application to production. With the Roku, we simplify all of this choice and we are giving you an opinionated platform. So you can focus on building the application, using our developer tools to deploy, and then operating your application by using the tools we are giving you to scale your app, to monitor your app, to do the observability, and we take care of the rest. We take care of the observability. We take care of the metrics, we take care of the support, and we give you the tools for you to scale and maintain the application. And this is increasing developer productivity. This is reducing the money that you are spending on DevOps and infrastructure operation, and it is increasing the return of investment of your application. So let me tell you about the different AI offerings that we announced and released this year, and this is why we became the AI platform as a service. First, we have managed, inference and agents. So we allow you to provision AI models to an app just with one click or with one command. You can select from a list of curated AI models that allows you to do text generation, image generation, or embeddings with just one click. This is something that is available right now. We recently launched support for Cloud 4.5 Sonnet, for Cloud 4.5 Haiku, Amazon Novalite, Amazon Nova Pro, GPT OSS 120. We also added support for MCP, the Model context protocol, and this support is in two ways. We have an Erou MCP server that allows developers and DevOps people to use our MCP that knows how to manage Erou resources. So this is for builders, but we also have a platform for you to securely deploy MCP servers that you are building. So you can deploy and host your MCP on Eoku and access that MCP remotely through an HTTP interface or directly from within the agent endpoint that we give you with the managed inference and agents. We also have support for vector database through PG vector, which is an extension of PostSQL to create vector databases to perform similarity search and create retrieval augmented generation pipelines. And we also back in October, we released the pilot of Erou Vibes, which is a tool that allows you to build web applications using natural language from the web, and this tool. Lets you build the app and deploy the app automatically to Erou so you don't even need to worry about the infrastructure behind. We are taking care of everything and just with one prompt and a couple of adjustments if you want to iterate over it, you can have an application from an idea to production in minutes. Let me show you a couple of demos that I have here that shows you first the Heroku manage inference and agents and how I built an application that uses our Eroku AI to get access to data and to be able to perform smart actions within an application. And another example of Eroku vibes which can let you build applications using natural language. Cool. So I built this application which is a dashboard for a solar energy company. Let's say you have a solar installation in your house or in your business and you want to monitor how much energy are you producing, how much energy are you consuming, what are going to be your savings, and get some insights about the application. So this dashboard already go and access my PostRSQL database that is deployed on Eoku and creates the dashboard, but this is your typical web application. I want to also ask questions using AI to get access to insights from my data. So how can I do this? Usually people build retrieval augmented generation pipelines, so you get data from the database. You pass that data to the inference model, and then you perform some inference on top of that data. What we did here is that we are using agents. We have an agent using the Heroku endpoint and tools, tools that we maintain which are. Pretty much MCPs that are hosted and brought in oneroku to give my agent access to the database. I am not giving my database credentials. I am just giving a read-only access to a follower of my database so I can safely retrieve data and analyze that data. So let me open the agent here. I already have two queries that I did, but I'm going to be doing something here live. The first one, I ask about what was my lowest production day this month. So I want to know from all this month, what was the day that I had the lowest production. So it is performing a tool execution which is the database query. It's generating this query, so my agent already knows the shape of my database, but we also have tools to retrieve the schema of the database so it doesn't hallucinate the shape of your data. It's generating the query. It's running the query and giving me the response, and then the inference is taking care of the answer. So pretty much we are feeding the context of my prompt with tools. For the other question, I want to chart or to create an image of the hourly production data of today. So it's going to be pretty much the same. I need to go to the database, but then how can I create that image? So for that, I'm using another tool which is code execution. In this case I'm using Python and the Python dependencies to generate images like matplotlib, pandas, Nompii, etc. to create the image on the fly, and I'm uploading this image to Amazon S3 and then returning a pre-signed URL. So we can see here that we have the database query. This is fetching the data hour by hour of the day. And then it's passing that data to a Python execution tool. Since you can run any application on Erou, what we are doing here is we are generating this code. The LLM is generating this code. It is spinning a dyno on Erou, a virtual machine, running the code sandbox safely on Erou and getting the return. So you are just only consuming the the seconds that that application was running. I get the return, which is the uh pre-signed URL on Amazon Street, and now I have the answer, which is the report and the analysis. So let me trigger another prompt here. So what was the peak production in the past 7 days? So the same, I need to use a tool to get this data. In this case, I am expecting that my agent, who I configured is going to perform a database query. Getting that data from the database and then doing an analysis over the data. So this is the query. It failed. Amazing. So now it is trying another query. Now it got the response, so you saw that it has like a self-healing capability and this is not scripted, this is a live demo. It failed and now it got the data and created the report that I just asked on the flight. So how does this work? How I provision this model to my application. So this is an application that is deployed on Hiroku. It's an OJS application, an API that access the Hiroku AI services. So how can I provision these AI services as any other service on Hiroku? I am on the Hiroku dashboard. I'm on the resources. And I will search for Erou manage inference and agents. It will provide a list of the supporting models that we have. I can select the model. Let's say we want cloud 4.5. I click on the order form provision. And now I have the model available to my application. How can I access from my application to that model? Basically this is giving me an API URL and an API key, and now I can use an SDK or directly performing an ACTTP request to the inference endpoint and get the response. This is everything working on Erou infrastructure, so your data is not going out to a third party. Everything is within the same infrastructure. It is staying safe and is trusted, getting access to the database. If I go to the settings of my application. I revealed the configuration variables. You might see here the different API keys and API URLs for the models I have provisioned. So what I have to do on my app, I will show you the code. This is my agent. I have a system prompt. In the system prompt that I just specifying, this is what you do. You are a solar energy agent. This is the type of tools and libraries you have access to. As I mentioned, I'm giving access to the library to upload to a3, to do math plot lib and the charting on Python. I'm specifying everything here, being very, very specific. And after defining the prompt and the tools, you can see we have Erou tools. So these are tools that run on Erou, not tools that I have to write. I'm giving access to the database to those tools. And then what I'm doing. It's an ACTTP request. Just call it an API. And I'm using the same OpenAI API shape. So if you are using an SDK that talks that that specific API, like for example, Langchain or the Bel AI SDK or Pedantic Lama Index, depending on the technology of your choice of building agents, you can use Eruku AI for that. So now let me switch to the other AI tool that we are offering our people. This is more like pro development for developers, for builders that can use the services. This other is more for business users, people that are not 100% technical, that they want to also build applications and deploy to Eroku, which is Eroku bikes. So here on Irou bikes, I start from a prompt. I need to define the prompt of the application that I want this to build, so for this example. I'm going to be building an agenda builder for AWS Reinvent 2025, so I'm asking to create this agenda builder application so I want to track my sessions, store the information on local storage, but I can also store it on a postreSQL database on Eoku. It will take care of the back end, and I'm giving a data source, get the data from this CSB that lives on the internet. And now I'm going to create that application. So there are like a couple of things that are going to happen here. First, it's going to enter into plan mode. It's going to create a plan, a step, step by step plan of how the agent is going to build this application. You can approve the plan. Or suggest changes to that plan. And once you have that plan approved, it's going to start building. Since I just have 2 minutes in my presentation, I'm going to show you exactly this prompt and the whole process and a couple of iterations that I did changing this prompt and the final result. So here you can see that I have like a long conversation with the agent. But it started with the same exact prom. I want my agenda builder. This is how I want it. This is where you are going to be storing the data, and this is where you are getting the data. It provides a plan. I approved the plan. And then it went and implement the application. And since we are using Erou here, it is deploying the application directly to Erou. So the application that I have here is the final result. It's living on Hiroku. You can see the Hiroku app domain. It is live. And I can just use it. I can just add sessions to my agenda. Go check the agenda, and that's exactly what I asked for. I then ask for some changes. For example, I want to have like dark and light theme, or I want to change this color to be something different, or I want you to have like a back end and store the information on a positive scale database. And that's the iterative process that you are going to do with these AI tools to build an application and take it live just using a prompt and going to production. So that's what Zoku has for you. One, which is the Herou AI services for you to build custom agents, deploy them on. And then we are giving you also a tool for building applications using AI that simplifies that process. That's pretty much it. Thank you so much. If you have any questions, we are located at the booth 838 just right next by the Salesforce booth. You can go there, visit us, ask more about what we have for you to build AI applications and other types of applications. And also you can like please complete the uh session survey on your mobile application and thank you so much for coming.