---
video_id: -aKGRHK5zRg
video_url: https://www.youtube.com/watch?v=-aKGRHK5zRg
is_generated: False
is_translatable: True
summary: "This breakout session, \"What's New with AWS Cost Management (COP203),\" features Bowen Wang, Matt Burke, Corey Quinn, and Matt Kasser presenting a comprehensive overview of new tools and features designed to simplify cloud financial management. The session is structured around three main challenges: breaking down organizational boundaries, improving cost reporting and governance with intelligence, and optimizing ROI with new purchase options.\n\nTo address organizational boundaries, they introduce \"AWS Billing View,\" which allows customizable sharing of cost and usage data across accounts and even across different payer organizations. This is complemented by the new \"Billing and Cost Management Dashboard,\" a customizable landing page where users can drag and drop widgets to track specific KPIs. A major announcement is \"AWS Billing Transfer,\" a \"payer of payers\" feature that streamlines billing operations for complex organizations with multiple payer accounts, essentially allowing one payer to centralize billing and payments while maintaining autonomy for individual units.\n\nFor intelligent reporting and governance, the speakers unveil enhancements to Cost Explorer forecasting, extending the forecast horizon from 12 to 18 months and the historical analysis window from 6 to 36 months, all backed by AI-powered explanations. They also introduce \"Intelligent Cost Monitors\" within AWS Cost Anomaly Detection, which automatically scale to track costs for new member accounts or cost categories without manual reconfiguration. The session highlights the integration of AI via Amazon Q Developer, enabling users to ask natural language questions about their spend and receive detailed analyses across instance types and savings plans. Additionally, they announce support for the FinOps Open Cost and Usage Specification (FOCUS) version 1.2 to help normalize billing data across multi-cloud environments, and the inclusion of Kubernetes labels in split cost allocation data for better granularity.\n\nFinally, regarding optimization, the team launches a standardized \"Efficiency Score\" in the Cost Optimization Hub to help organizations benchmark their optimization efforts. A significant improvement in commitment management is \"Reserved Instance and Savings Plan Group Sharing,\" which allows users to prioritize or restrict sharing of discounts to specific groups of accounts, solving the \"tragedy of the commons\" where dev environments might consume production discounts. The session culminates with the long-awaited announcement of \"Database Savings Plans,\" offering flexible commitments across the entire AWS database family (RDS, Aurora, DynamoDB, etc.), a feature Corey Quinn passionately celebrates as a major victory for the FinOps community."\nkeywords: Cloud Financial Management, FinOps, AWS Billing View, Database Savings Plans, Cost Explorer Forecasting, Intelligent Cost Monitors, FOCUS 1.2, Efficiency Score, Savings Plan Sharing, AWS Cost Optimization\n---

Good morning and welcome to our breakout session, which might be the most announcement packed breakout session ever. Um, so before we get started, let's take a quick look back in the past 2 years of our cloud financial management journey. So 2 years ago, we made our cloud financial management services more accessible and easy to use. We integrated the billing and cost management console. We launched AWS data exports, which is a flexible way for you to download reports from AWS such as cost and usage report. And we introduced a very important initiative called split cost allocation data, which helps you calculate and distribute costs associated with shared resources. So last year, we tackled standardization and accuracy. So we launched data exports for Focus 1.0. For those of you who operate in multi-cloud or multi-source environments. We also launched the authenticated pricing calculator, because we know when cost estimates are wrong, they're not just useless, they can be dangerous. So what about this year? Well, this year, we're not just improving what exists. We're also rethinking what cloud financial management services can help you achieve your use cases from how you access data to how you forecast to how you optimize. So the theme is simple. We want to meet where you are. Now, you may be wondering, who are we? Why are we bold enough to tell you the story about how AWS is renovating the cloud financial management solutions? Let's do a quick introduction. So my name is Bowen Wang. I'm part of AWS billing and cost management service team. As the principal product marketing manager, I get to witness the product innovation. And the best part is to announce them. And today I'm joined by my long-term co-presenter, Matt Burke, and two legends in the industry, Corey Quinn and Matt Kauser. Hey, everyone, I'm Matt Burke. I'm a principal technical account manager and I lead our technical field community for cloud financial management. I'm Corey Quinn. I'm the chief cloud economist at Duckbill, where I help folks at very large enterprises manage their cloud spend from a variety of different perspectives. I've also been working a very long time with AWS billing constructs, which is why I'm completely dead inside. Oh, this is gonna be tough following Corey most of the time. Uh, hey everybody, my name is Matt Kasser. I'm the principal product manager for Focus. Uh, I work with at the Finns Foundation. I also happen to be an ex AWS employee. Very cool. So let's see who you are. So if you are in audience today, you may be a fin ops manager or finops practitioner. You try to standardize the finops practices you set centrally while decentralizing the cost management responsibilities across functions, while in the same time try to win trust from leaders from business, finance and engineering. If you're an application leader or a business unit leader, then you're looking for native cost reporting that meets your unique set of requirements, or you're looking to optimize your set of AWS accounts. If you're a reseller, then you're looking to do all of this at scale, and you're looking to do this in the most simplified centralized way possible, uh, to allow you to better serve your end customers. And if you're an end user, you just want the damn thing to work. You have a job to do. You're trying to get something out the door and having transparency into what the thing is actually costing, and not hear the Charlie Brown teacher yelling at you from somewhere over the rainbow about costs and allocations. That's not what you're there to do. You're you're there to get something else done, presumably. So, what do all these personas have in common? Well, you're operating in a mature organization and a complex AWS environment. Think multiple payers, multiple business units, non-integrated entities, and complex billing. So when we look at to build our roadmap, we work backwards from customer feedback, whether that's the feedback you share with your account teams, whether that's at industry events like FinOpps X with the FinOpps Foundation, or even here at Reinvent. So a lot of the launches and features that we are gonna talk about today are aiming to address those challenges or gaps when operating a mid to large enterprise on AWS. So in the next hour or so, we're going to introduce a few solutions that can help you tackle the three main challenges. First, how you can break down the organization boundaries to meet your specific reporting and the billing requirements. Next, how you can improve cost reporting, governance, allocation, standardization with AWS managed services and intelligence. And finally, we will let you know how you can optimize your ROI with AWS with the latest technology and purchase options. So now I'm going to turn to a mat to help us get started with the first section. Thanks, Corey and Matt. See you later. We're gonna start off with talking about breaking down organizational boundaries, rethinking how we think about that payer account structure, and so we're gonna tackle this from 3 different features and 3 different challenges, the first being the data access challenge. Then next we're gonna move on to cost reporting, and then finally we're gonna talk about the billing complexity that comes with operating multiple AWS payer accounts at scale. So, let's talk about data access. You either have access to the payer account of your organization to look at that consolidated view across all of your linked accounts in Cost Explorer or AWS budgets, you're able to see and filter out your organization's cost and usage data, or you don't. And if you don't, then you're generally logging into the linked accounts across maybe tens or hundreds to get the information natively that you need to look at the latest cost and usage data. And you might be thinking that the FinOps admins, well, they're, they're lucky, they might have access to the payer account to do their jobs, but even then they might be running into some of the same issues, which is that they are logging into multiple payer accounts, managing and looking at spend across multiple payers. And so the question becomes, how can we make this simpler? How can we somehow give you access to the data you need where you need it, while also gaining access to a payer account, which is generally a good security best practice, Bone. Yeah, so Matt, what I'm hearing is customers like you might be um having the need to access the level of cost and usage data exactly at the way you want, whether it's across accounts within an organization, which is in between payer and a member, or across payer accounts. Now it Billing view will be able to help. We launched abase billing view at last reinvent and we've since added lots of features to this service. So with this AWS billing view, you will be able to scope the exact level of cost and usage data for your stakeholders and securely share with them. So let's see how does it work. So as a payer account owner, you will access billing and the cost management console. Under the preference settings, you'll be able to create a filtered view using dimensions such as cost allocation, tags or member accounts. That is to save the view for your business owners or application owners. Or you can choose to create an unfiltered view, which essentially includes all of the costs and usage data for your organization. Once the billing view is created, you can decide to share and within an account that account could be within or outside of your organization. And that account will be able to have that access view within database costs Explorer, budgets, and the billing and cost management dashboard, which will share more details on that. And very recently, we've made the multi-source billing view available. And that is a game changer. Because remember that account that can receive the shared billing view from any organization. And that same account will be able to combine the billing views from across up to 20 different payers. So that is essentially a unified billing view from your entire adverse estate. Behind the scene, the magic happens through Amazon Resource Access Manager, because each billing view has a unified Amazon resource number. But from the day to day experience, you do not need to worry about Resource Access Manager. You just come to the councille, create your filtered view, share with any account and that account just need to accept and start using it. So now we move on to our next challenge, which is cost reporting. And generally you probably thought about this when I was talking about the data access issue, because that's how most of you are approaching this today. You're trying to share your cost and usage with your decision makers, so that generally results in some kind of dashboard, whether it's using our cloud intelligence dashboard solution, which we have on the screen, or you can use a cloud formation or terraform template to create a billing pipeline. With all your information, push that to Athena and Quicksight, and we have a bunch of different templates for you to leverage with all the data that you might need. So you either could be leveraging something like that or a third party BI tool or even a third party FinOps tool to help get that information in the hands of the right folks. But you've asked us to make this easier, something in between deploying an entire dashboarding solution and potentially managing subscriptions, and something like a saved Cost Explorer view on the left side, like the easiest thing where, you know, if you're just going into Cost Explorer and you're, you know, putting in filters, your group buys, you can save that view so that the next time that you log in, you don't have to do it all over again. So what would be in between those? Something, you asked for something that was flexible, customizable and easy to share, not just within your organization, but with any AWS account that might need access to your cost and usage data. So Matt, that's exactly the reason why we build the billing and cost management dashboard right in the billing and cost management console. So think about this dashboard as a landing page, a blank canvas, you can drag in a job up to 20 different widgets of KPIs your organization care to track and monitor. And while behind the scenes, again, we use Amazon Resource Access Manager, but with you once you create a dashboard, we'll be able to share that as a view only version. Maybe with your VPs and CEOs, you do not want them to explore too much data, or you can share an edible version with a business unit um leader so you can collaborate on dashboards. Um, so again, when you create a dashboard, you have two paths. You can either use a predefined widget, which are the pre-populated KPIs we believe a lot of customers care to use that as monthly cost per service per member account, easy to hourly cost, marketplace costs, etc. Or you can choose to use custom widgets, which you can customize the widgets from data sets such as cost, usage, reserve instance or savings plans utilization and coverage rate. And you will be able to create a dashboard. And the great thing is you can change the graphs or even create one template you believe every stakeholder will need and be able to drill down to specific dimensions for specific stakeholders. So now we're going to launch into a demo of these first two features, and we're gonna start with the billing view. So from the billing cost management console you have the drop down to look at your views and we're gonna create a new billing view now. So you can choose to filter your cost management data data either by account or by cost allocation tags that you have already configured, or you can do no filter at all, which means that you're just sharing that raw organizational consolidated view with any account that you choose. If you're picking to just share a grouping of accounts, let's say for a business unit or for a project, you can select those accounts that you want and then title the view, so I'm just giving it a test name. And then give it a description of what that view looks like so then when they're looking in the billing cost management console from that drop down, they can know what they're looking for. So once that's created, then you're gonna wanna share that view. So you can either share it within your organization and we'll pre-populate all the linked accounts, or you can share it with any AWS account as long as you have that AWS account ID. We're doing this through Resource Access Manager. We're using the Resource Aes manager role. So if it's an account outside your organization, they'll just have to accept that view on their end. And then once they accept it, it'll be in that drop down. And next we're gonna talk about the dashboard. So it's very similar to billing view where we'll create a dashboard and we'll start by you can name the dashboard, give it a description, and you can put in up to 20 different widgets. So think of them as 20 different cost explorer views. You can set your date range from either an absolute date range or relative date range like the last 3 months, and then you can start to add your widgets. We can have some predefined widgets, so these are the most common cost explorer views like monthly cost by service. You can add your group buys, your filters there to customize it. Um, you can also add things like easy to running hours cost. So you can drag and drop that into the page, and you can also then resize and move around the widgets to, you know, wherever you want them on there. And then you can add things like Custom widgets. So this is now getting into your just your straight up cost, your usage, your savings plan, RRI coverage or utilization. You can pick from each of these and then drill down with those costs explorer filters and group buy. So here I've got savings plan utilization 100%, which is great. And I'm also able to, you know, edit the titles of the individual widget and the description of each of them as well. So once you're done building out your dashboard and you can make a bunch of these for specific use cases, then it's time to share it. So you can share it with any account within your organization. Again, we'll pre-populate that or just with any account that you want, and you can choose between a edit or a view only role so that either the person can just see it or collaborate with you on it. Once you add the recipient, you send it over to them and they'll be able to see that dashboard when they go to dashboards in their console. That's it for the demo. And now we're gonna move on to our 3rd and final challenge of this section, which is billing complexity. And we started to address this challenge last year with the launch of something called invoice configuration. So if you needed to send an invoice, like that was scoped down to a specific subset of accounts, you can create invoice units and then use that for chargeback showback. But that wasn't all the way that we wanted to go. If, if what, if you're managing this across multiple pairs, then you're then configuring this across multiple places, and your feedback said to us, hey, we really would like to decouple billing. So that while we're scaling, whether that's through mergers and acquisitions, whether that's spinning up new landing zones for specific purposes, or if you're a channel partner and you're just growing your business and signing up new customers, that you, we weren't creating billing complexity for you. So how can we create some sort of pair of payers, Bowen, that allows us to manage all our billing cost management preferences in one place. So the challenges related to billing can be difficult to manage if you have a lot of payers. And that is why we're very excited to announce AWS billing transfer. So AWB billing transfer essentially is a new way for you to streamline billing operations, payments and cost management. So think about this as a payer of payers. Now you can designate it one payer account to centralize the billing payment invoices, settings for all of the payers. Um, it's just one place for everything. Um, with billing transfer, even though it's very powerful, at the same time, you will be able to give autonomy for individual payer organizations. So they will be able to keep their root access and will be able to manage um security access, etc. At the same time, if you are Reseller or even larger price enterprise customers, you want to really protect your unique pricing information. You can also do that because it was billing transfer is integrated with billing conductor. So be able to configure your own pricing information and cost visibilities for your customers. So let's take a look at billing transfer in action. So now if you access billing cost management console, under the preference setting, there is a billing transfer landing page, right? You have two perspectives. Inbound billing is where you assume the billing responsibilities from other organizations. Well, outbound billing is where you delegate them. So let's say you want to establish a relationship, which means you want to assume the billing responsibilities from another organization. You are given a name. Let's be as descriptive as possible, right? Maybe the billing starting period time or the organization name. And you also need to get the email address and the payer account ID from the another organization to make sure you address to the right payer account. That billing relationship can start at the very next billing cycle or in 2 months. And in terms of pricing configuration, you can either keep the straightforward basic pricing. Or you can use billing conductor to customize the pricing. And AWS will also give you a little warning. So once you pick like say for this demo purpose, we'll use basic pricing. They'll give you a warning to remind that an organization to download the very recent cost and usage report. Because once this relationship is set up, they will no longer be able to receive updated current report. This is to protect your pricing information in case you want to configure in a pro forma rate for them. So now if you send an invitation, they accept it. Let's say the relationship is activated. AWS will automatically create two billing views for you. One view is called my view, which is the true cost you owe to AWS. Another view is show back and chargeback view. If you have used billing conductor to configure any unique pricing items. So let's say you are the pair of payers. You go to Cos Explorer, you'll be able to turn on billing view and a toggle between the my view, which is your true cost, and my charge and showback view. So let's say you want to see the my view, which is the true cost you owe to AWS. In this case, my average monthly cost is about $17. And if you switch to the chargeb showback view, oh, you can see for your end customers visibility, they owe you $37. So the in between Delta is essentially the markup you have set up using billing conductor. So the dual view with costs Explorer really give you the transparency you need and also meet your cost allocation needs. OK, I'm gonna step off the stage and welcome Corey for the next section. Thank you. Let, let's go in a little bit into how we can enhance some of the visibility into these things, uh, through automation and intelligence, artificial or real intelligence as the case may be. Um There are a few aspects to this. You've got the whole forecasting bit, the monitoring bits, the data normalization pieces, and of course allocation. But let's break down into those things individually one by one, because trying to take it all at once is like the last 10 minutes of yesterday's keynote, um. So we care a lot about forecasting and planning, and what we have today is of course Cost Explorer and the pricing calculator. Uh, specifically in Cost Explorer, customers can project 12 months of data based upon their past 6 months of historical data. Uh, and now we have some things that folks have been asking for like extended planning horizons that align with fiscal cycles starting in Q3 or Q4 because some of you people absolutely suck at reading calendars, uh, deeper usage pattern recognition, uh, for seasonal trends, holiday peaks, and those fiscal year-end variations. Uh, you, you really shouldn't be blindsided by the fact that this week is reinvent, for example, though somehow I always am. Anomaly detection to identify and highlight spending outliers that the giant spike there has a fancy root cause that I'm just going to shorthand down to Greg and don't worry, we fired him, so don't take that spike into account when we're doing our future projections. He's not welcomed back. And having transparency into how you arrive at the forecast has been a big ask. Understand the why behind predictions, because do not question me from a computer in this age of AI is more than a little ominous. We want to have it explainable. And when it comes to the trend approach, there are a couple of different ways you can look at it, when it comes to forecasting itself, you can do go either with trend or with driver-based. Uh, trend is always forward looking extrapolation of historical time series data. It's good for forecasting organic growth of existing usage and cost. Uh, longer forecasts, the longer you stretch it out, they have less certainty and a lot more fuzzy. Uh, it, it doesn't account for future changes in your business environment. And of course it's super crappy because you have this spiky history and then suddenly it's a straight line. Nothing is more suspicious than that except possibly round numbers. So did the business suddenly bring order to chaos, or are we just hand waving over a whole bunch of uncertainty and claiming otherwise? We all know the answer, and it's the bad one. With driver base, it accounts for business and other demand drivers. I mean, we're in December now and my Christmas tree business is booming and we're picturing an even bigger January. Maybe there are some challenges there. Uh, that's ideal for planning costs and highly dynamic and flexible environments. The world is evolving. Cloud is no longer just a crappy data center analog. It's becoming more dynamic, and that decreases your ability to project it accurately versus traditional methods. I mean, you don't wind up showing up one day and finding 5 more servers in your server unless someone's doing something weird. It's also useful for improving the accuracy of the long-term forecast, because you can start to bake some of that seasonality and less of a flat line into it. And the brown side of course is that it does require additional time and effort upfront to implement the process. And, and that is sad because you have to invest time into it to get value out of it in the form of better outputs, such is life, but it does seem like that's something a robot might be able to help with. Bowen, do we have one of those? Yes. So Corey, just like you mentioned, um the traditional cost forecasting, what is your the correct factor or your seasonal business confidence can be inherently challenging. And the customers like you deserve confidence and transparency when it comes to cloud cost forecasting. And that is why we are excited to announce three major enhancements to the cloud forecasting capabilities within Cos Explorer. So first, we are extending the forecast time horizon from 12 months to 18 months, which is to align with your normal annual planning cycle. And the second is we are extending the historical cost analysis window from 6 months to 36 months. So these are not just additional data. You are essentially giving Amazon machine learning technology more business context for us to understand who you are. What is a unique spending pattern? And the third enhancement is now you're having this AI empowered explanation. So no more black box, you'll be able to understand how can we come into conclusion of this projected number. So now imagine after reinvent, you'll be able to use these three features and walk into your Q4 planning meeting and very confidently understand your total 2026 it spent. So once again, you do not have to learn a new tool. It's right in AWB Cos Explorer. If you access costs Explorer, you will see a little flash bar introducing this new feature. You'll be able to use the very familiar date range to choose the next 18 months into the future. And once you do that, there's a little button called generate explanation forecast. And if you do that, you will see a little write up. Um, AS will let you know how can we get this projected cost number for you? What's the historical day range we have used as the baseline? And what's your spend pattern? It is consistent trending up or downwards. And what's the probability you can be confident about this number, that's the 80% and the top three cost drivers we have identified. So this AI enabled explanation is currently in public preview. So if you use that, please give us feedback. There's a thumbs up or down button here and tell us specifically how can we make this more useful for you. So we really want to make sure you understand the why behind the forecasting. So the current state of cost monitoring is grim. AWS has a few services that help customers set up the right guardrails, such as AWS budgets, AWS cost anomaly detection, and the close your account button. But at the payer level, one can generate up to 501 monitors. But you, you really only need one that says holy crap on it in all caps. Now, fortunately that 501st is a global service monitor to do exactly that. Uh, it evaluates all the AW. US services that are used across your individual AWS accounts for anomalies. So when you add new AWS services, it automatically begins to evaluate what those are, so you're not constantly chasing it. You don't have to manually configure it every time someone uses a new service, which often they're surprised to discover that they're doing. And then there are 500 additional monitors you can configure for a lot more granularity around accounts, cost categories, and tags. But now that giant global holy crap button that alert is going to get even better. Could you please explain what it does in less apocalyptic terms? Exactly, Corey, we definitely want the cost governance to be more proactive and scalable, even though the 5001 cost monitors you. Mentioned is very forgiving. But we actually do not want our customers to spend time to create and maintain hundreds of cost monitors. And that's why we're very happy to announce this intelligent cost monitor within database cost anomaly detection. So how does that work? So right now you can create one database manage cost monitor to track costs and usage underneath one specified dimension. And that's monitoring well, grow with your organization. So let's say right now you can use database cost monitor to track all the costs and usage for my member accounts. So that means all the costs and usage incurred by the member accounts within your organization, whether it's existing today or newly added will be automatically tracked by this cost monitor. Similarly, you can create one cost monitor to track all the costs and usage associated with one cost allocation key or one cost category name. Let's say use cost category, which is our rule builder to group your accounts and the resources, and you have a cost category named department. So anytime you add new resources or accounts in this department, where this marketing, sales engineering will be automatically tracked. So just one initial setup, this intelligent cost monitor will be able to scale as your organization grow. So every talk in 2025 must be smothered with AI like their Waffle House hash browns, and AI for Finnops sounds like something that a LinkedIn influencer is going to post between their various hustle quotes. But this is actually tentatively useful, and Bowen, thump thump goes to the bus as it drives over her that I just threw her under, is going to explain why it's not just vibes. Bowen. Yes, AI is definitely very trendy. But in reality, AI is also transforming how we do fops right here at AWS we spent a lot of effort in the past year trying to make sure AI solutions actually making a difference to your day to day finops practices. We have things add more use cases to our AI solutions, make it more intelligent, and give you more ways to interact with our services. Um, so let's say right now we can perform a cost analysis, do your cost forecasting, investigate cost anomalies, and within those very granular costs and usage data. And with the launch of bill in a cost management MCP server, for example, in the past August, you can now integrate the cost analysis right in your development environment. Or you can even build your own AI Phoenix agent if you want by connecting with our services. So to large enterprises, what does that mean you will be able to now do lots of the custom calculation within minutes and be able to get involved with most stakeholders and give them this ability to self-serve. So I'll give you two quick examples, Cory, and to see how that works. Um, so we just launched this enhanced cost management capabilities right in the Amazon Que developer. So let's say many of you are Pinops agents or hoops analysts, you're in charge of the spend within your organization. You do not want to use all the different tools. So you can ask Amazon Que. Uh, maybe you're interested in easy to spend in the past 3 months. Um, you can just ask Amazon, can you tell me my EC2 cost, uh, maybe virtual CPU our cost in the past 3 months and then give me analysis of my trends and maybe some suggestions and what I should do next to make it more cost effective. Once you do that, he will start to retrieve information, granular cost and usage data from Cost Explorer. And maybe also from savings plans, coverage rate and utilization rates because those information can also be helpful to help you cost optimize. Then after they have all the granular information, the next thing they will do is perform some very custom calculation, maybe divided my EC2 cost by the number of hours or understand the mix of easy to instance types mix, um, and then give me a quick breakdown. So previously, I have to download those data sets from multiple sources and they do lots of manipulation in my Excel sheets. But right now, within 2 minutes, I'll be able to get a breakdown of my EC2 cost amongst the various EC2 instance types to understand whether I'm using more cost effective instances or maybe less so. And do I have opportunities to maybe purchase more savings plans to cover more eligible usage. And again you can use the thumbs up or thumbs down for feedback. So the next example is we mentioned the the billing and cost management MCP server we launched last August. Um, so a lot of the developers have already let us know that they have attached it to their development environment. So let's say you are a software engineer in Q environment. You are trying to build up a video processing pipeline, but you do not know which architecture design options is more cost effective. So you'll write up this rough design document in key role and ask This AI technology to maybe evaluate the different cost implications of different options. So can you please review and update my design documents with different cost estimates? So I'll be able to make some trade-off. So we can see that because I have mentioned different services in my design documents such as EC2 elemental media converter, S3 ECS on Fargate, AI technology will start to retrieve pricing information from the different services and the resources I intend to use in my design documents. And once they have the information, they will update my technical design document with those cost estimation and assumptions they have made in the process. So again, with those information, I do not have to wait and deploy this architecture and have to cost optimize after the fact. I'll be able to make trade off between cost versus availability and maintainability and be able to do my cost optimization right before the deployment. So I'm gonna step off. Thank you. I'm going to invite one of the mats back, preferably Cowearch, but we're not picky here. Uh, every cloud provider speaks a different dialect of cost. AWS calls it X. GCP calls it Y. Azure calls it Steve for reasons that are not at all clear, and Microsoft refuses to expound upon. Uh, it's comparing cloud costs across these different providers is like comparing a giraffe to a teddy bear. Technically they're both assets, but that's about as closely aligned as you can get, unless you want a very upset zookeeper. You you can't optimize what you can't compare, and you can't compare that which is not normalized. Your CFO wants one number, you have 47 numbers that might mean the number that they're after, but probably doesn't, and all the screaming doesn't help. Finance teams should not need a Rosetta Stone to uh to wind up equivocating costs between different providers and different platforms because without normalization, you're doing cost analysis with a blindfold and a dartboard in a bird sanctuary so. We force everything into the same shape, uh, like teddy bears, but less cute and slightly more compliant. And this is where standards come in. Wouldn't it be nice to have such a thing? and and why we're going to talk about focus. It turns out that the Finnops Foundation had thoughts about this chaos, as embodied by my friend Matt. Yeah, so today we're pleased to announce that data exports for FinOps open cost and usage specification, or uh we colloquially say focus, uh, now supports focus version 1.2. So it's now easier than ever to be able to normalize your cost and usage data across the number of providers that you're working today. So when you think about focus, uh, it, yes, it is a format, but it's also a language that you can use whether you're generating these reports yourself or you're pulling them down from your providers. And what this is gonna allow you to do is have consistency across the reports that you're generating and so the standardization of cost columns like build costs and effective costs, uh, having service categorizations and account categorizations make it easier to understand. Uh, how it is that your data is being represented across the providers that you're using. This also means that when you add a new provider, which you inevitably will, you don't have to learn a brand new language. It just extends into, uh, what your team already knows. It also makes it easier for you to be able to do invoice reconciliation across your providers, uh, as we're using the same language across. So I just wanna do a quick rundown on the, the actual standardized cost columns that we have in place today. Uh, for build cost, that's what you're gonna expect to see on your actual invoices, uh, effective cost, or if you're familiar with the, the View and Cost Explorer, your net amortized cost, uh, it's gonna be inclusive of your, your discounts, including your, your RIs and savings plans. List cost is exactly what it sounds like. It's the published rates. Uh, this allows you to effectively evaluate what your optimization, uh, efforts are giving you, and then if you have any sort of, uh, contractual agreements, uh, the contracted cost allows you to represent that difference as well. Next time. So new to uh what you're getting as a part of AWS supporting Focus 1.2 is actually a capability that that Focus introduced in 1.1 for capacity reservations. And so, uh, capacity reservations are super helpful when you're trying to ensure that Uh, you're actually leveraging the, the the capacity that you're reserving, and this is primarily for, uh, GPU intensive workloads. And so now, uh, all within the same reporting structure, you'd understand if, uh, your reservations are used or whether they're not being used and, uh, for AWS specifically we're talking about your on-demand capacity reservations as well as your capacity blocks. We also introduced a virtual currency. Uh, so virtual currency, uh, represents the difference between, uh, the pricing unit that you're observing within your individual provider. So as we see more and more SAS-based consumption, uh, specifically around, uh, platform services like data bricks and Snowflake. Um, you're gonna observe that you're consuming credits or you're consuming tokens, and it may be more difficult to understand, uh, what you're actually spending within those within those individual services. So, uh, we introduced this concept of a virtual currency which allows you to track. Uh, your credit and token purchases burned down and it also allows you to do, uh, if you're billing currency and you're pricing currency are in different values, and so anyone that's operating outside of the US, um, where ADBS primarily will bill you or they're priced in USD but they're gonna bill you in whatever currency you're asking for, uh, this makes it super easy for you to be able to validate that that conversion, uh, is accurate and consistent with your negotiated agreements. All right, so if you're looking to get started with, with Focus, it's, it's a super straightforward piece. So the first step is to actually create the report itself. You can do this within the billing cost management console. Um, there's a section there where you can create the focus export for 1.2. Uh, once you actually have the report in hand, there's a number of different ways to use it. So if you're looking for the dashboarding capabilities, uh, there's a focus dashboard from the, uh, the kudos team. You can engage with this either via the command line or they have cloud formation templates that are easily available for you to be able to use. We have use case libraries that are available on the, the foundation site. Kudos also has use case libraries, and then if you're looking for additional training, the foundation has, uh, intro to focus as well as focus analyst training, um, and we continue to, to add to those all the time. Remember, the best way to do, uh, SQL queries is of course copy and paste. Oh God, I hate those my favorite. Uh, so this is just an example of what you're gonna get on the Focus dashboard itself. Uh, I was actually sat in a session two days ago where, uh, we were able to see this in practice and so it's, it's cool to, to see, uh, that you get this unified view of what your effective cost is, what your build cost is, like how does your service categorization usage span across the various providers that you have in place. Uh, and, and so this, this is the simplest, easiest way to, to integrate with Focus if you're already running AWS and you have other, other providers in place. So, containers are great at running your applications, but they're terrible collectively at telling you what they cost to do that. Uh, Kubernetes sees pods and nodes, your CFO sees dollar signs, they talk to you, you see stars, and these things are not the same language. Uh, shared nodes mean shared costs. Shared. Cost means someone's getting blamed for someone else's bitcoin miner, to put it directly. Speaking of virtual currencies, is it your fault that the note is expensive, or is it your neighbor who requested 47 cores and then uses 2? When 10 teams share infrastructure, 9 of them think that they're subsidizing the 10th. They're all right. You can measure CPU requests. You can measure actual usage, but good luck explaining why those things are different to finance. Without attribution, you're doing showbacks with a Ouija board. We chargebacks become political negotiations instead of math. We've all seen that play out in our organizations. Teams optimize for looking cheap, not for being efficient, which is why we need better primitives here for cost allocation, help. Yeah, so, uh, the next feature we wanna announce is that we have, uh, Kubernetti's labels are now a part of the split cost, uh, application. So, uh, previously you were operating off of your system label tabs, but now you can, you can also pull in custom Kuberneti's labels, so you're not just, uh, working with the system tags at the cluster name and name space level. This is really important back to Corey's point around, uh, how do you think through allocation and if you can't get the allocation right and it's not at the right level. Of granularity you're either gonna do a misattribution when you're allocating costs or there's some follow-on activity that you're requiring your finance and um engineering teams to be able to get to the right values. There are a bunch of ways to do it, but if they're they're all equally valid, but you have to be consistent with it. Good luck with that bottom up, yeah. So again if you're looking for the easy button here we have a a split cost allocation dashboard that incorporates that same level of uh Cuberarti's label granularity that you that you're looking for. So if you're, uh, the most common dimensions are gonna be represented within the workload explorer, um, and again if you're using those more granular labels and pods, those are also dimensions you're gonna be able to create, uh, more customized reports for. Thank you very much. Um, I'm going to invite upgrade from a Mat C to a MatT B at this point because I couldn't get a map A, and he's going to take us through some of these things, and it's his turn to suffer my slings, arrows, etc. Thanks, Corey. So in our third and final section we're gonna be covering 3 new launches around optimization through the lens of cost management. So for the next slide we're gonna talk through cost efficiency. How do we measure it? Commitment sharing uh sharing commitment purchase sharing preferences, it's a mouthful. Um, how do we share our RIs and SPs effectively in the groupings that you want versus just across the entire organization. And then finally you might have caught at the end of Matt Garman's keynote he mentioned a new savings plan option. Corey has a lot of thoughts about that one. So, let's talk about the measurement problem. Uh, here's the thing, we all know that we should measure efficiency, not just cost. You want to cut costs, turn everything off. That's not really viable for some of us. The problem is that nobody agrees, really agrees on what efficiency actually means in the context of an organization. Finance wants cost per dollar of revenue efficiency. Engineering wants cost per transaction for efficiency. Product wants cost per user, and they're all different numbers that tell completely different stories. What's even worse is let's say you pick one. It matters not which cost per transaction, let's say. Great, you optimize it, you bring it down 30%, and now you're a hero. Then product ships a new feature and suddenly a transaction means something different today than it did yesterday. Your metric just became meaningless and you didn't change anything. And here's where it gets really painful. You have no idea if you're actually good at any of this. We all feel like we're sort of impostors on some level, like how do I demonstrate this? You think you're efficient because costs are flat year over year, but your competitor might have just cut their infrastructure spend in half while scaling way faster than you. You are flying blind here. There are no benchmarks internally or externally. There is no context. It is just your own costs versus your own history. The cloud providers give you cost data. They don't give you efficiency data, and those are very different things. So every company at some point on the maturity curve builds their own framework for this. Every team interprets that framework differently within the org. Nobody trusts any of them, but we keep building more because, hey, now we can look busy. At least, but maybe the 18th 1 is finally going to be the one that gets it right, just like reorgs. We have been asking for a standard way to measure this forever, something comparable, something that doesn't require a PhD to interpret and a board of elders to make decisions on, something that tells you if you're doing well or just doing OK. So that's why we've launched the new efficiency score. So you'll find this now in the cost optimization hub. So if you've got that turned on, and you should, it's free, you'll see this new efficiency metric when you log in. Now this efficiency score is calculated by taking your potential savings over your total optimizable spend. What that means is, the more optimization recommendations that you take from the hub, the higher that this score will go. So if you're purchasing a new savings plan, if you're cleaning up idle resources, if you're right sizing that particularly large EC2 instance, the score will go up. Not only can you track this historically, but now you have a common KPI to game. Whether that's working with your teams to see how quickly and how high the score can go or maybe some friendly competition between pairs, you can set those targets and benchmarks and you also can programmatically query this via API with the list efficiency metrics API. All right, let's talk a little bit about sharing reserved instances and slavings plans. Speaking of friendly, uh, across accounts within your organization. Uh, right now it is all or it is nothing. You either share your commitments across every single account in the org, or you don't share it at all and every account is responsible for its own. There is no middle. Ground this creates a beautiful problem. You want to share because otherwise you're leaving money on the table and Mr. Rogers would be proud of the adult you have grown into, but you're terrified to share because the moment you flip that switch, some other account is going to effectively consume all of your commitments, including that one account. You know, the one that that acquisition that's technically hasn't been integrated yet, or the sandbox that is still running because no one realizes it's there, the account that someone created for a demo for a talk 3 years ago that nobody remembers but is mysteriously still spending money like clockwork every month, so you're stuck. You bought a million dollars in savings plans for your production workloads because that's the right number. They could be shared with your dev accounts. That would be efficient. It means your company is now getting. The best discount possible, but your dev account is in the same org as I know, Karen's machine learning experiment that's going to train a model any day now and currently has 403.16X large instances sitting there just to get ready, but they're sitting idle. If you enable sharing, suddenly Karen is consuming all of your discounts. Your production teams are subsidizing Karen's GPUs that are now 3 generations old. What does this turn into? That's right, politics. Your production team bought the commitments, so should Dev get to use them? If you have uses them and then Prad gets charged back, who's tracking this? How does it reflect for internal costs? Finance wants utilization reports by team, but the commitments are floating around the org like freaking ghosts, and nobody knows who's actually benefiting. We know the customer is, but that's as far as we can go. And the worst part is, is the fear, the psychology behind that fear of the one bad actor. It prevents you from helping the 20 good actors. We see that everywhere in society. Uh, so you leave sharing off, your commitment utilization dies, it's at 73% month after month, and everyone is just slightly worse off because you couldn't trust everyone. We have been asking for years to give us more granular controls. Let us share with these accounts, but not those accounts. Greg, you know the ones. Let us set guardrails around sharing. So that's why we have new RIN savings plan sharing preferences available. So by default, the sharing has not changed. You'll start with open sharing, which means that within your organization, if there's any unused commitments in a particular account that will float to the place in the organization that has the highest discount, we're still optimizing the savings for you overall. However, if you want to change that, we have two new options. We've got prioritized sharing and restricted group sharing. For prioritized sharing, you're feeding us the the usage that you want to prioritize that grouping so that if a commitment is unused, it'll float between that group first and then move to the rest of the organization. But if you want to restrict that group sharing, if you don't want Karen to get your savings plan commitments, then you can just restrict it to your specific cost and usage, and then if there is waste, well, then you'll pay for that too. So how do we set this up? Now, we have a scalable grouping mechanism for this in the form of cost categories, because you don't want to be manually maintaining a list of accounts that says this is one group and this is the other, and oh wait, we just added two accounts last week, so we have to add that in. Now, so with cost categories you can set your rule-based allocation methodology. So if you wanted to set a rule that was based on the nomenclature of your accounts or by tags, you can. And once you create that cost category, you can set it to be the sharing boundary. Once you set that up, then the savings plans will operate as usual. You can now use your Cost Explorer in the same way to check your utilization and your coverage rates, but you can also monitor and model. The savings plan purchases. So if you want to do a what if scenario with pricing calculator, and if you haven't used the new authenticated pricing calculator in the console, please check it out. You can do so by doing what's called a bill estimate. So you can take those savings plans, you can add new ones, and then you can model that what if scenario for like if last month I bought another $100 of savings plans, what would that look like under this new sharing preferences? And you can get that output and the estimated savings that goes along with it. I've been talking a lot about the savings plans, and finally Corey gets to talk about our newest one. Database savings plans are here. They cover RDS, Aurora, Elasticash, Neptune, Document DB, Dynamo DB, TimeStream, the whole family. I would like to thank the Academy, my parents, and the heat death of the universe, which we almost reached first. I have been asking for this since 2019, when savings plans originally launched. 2019, my hair was a different color. I had different enemies. Some of you in this room weren't even in cloud yet. When this happened, you were innocent. You were unscarred by the reserved instance management experience for 6 years, 6 years. AWS said, oh, just use reserved instances for each service separately and manage them like a medieval warlord moving things on the table. You're telling someone to use different currencies for each type of purchase at the grocery store. Oh, groceries and gas, you better maintain separate wallets to wind up doing that with separate. Exchange rates and separate commitments terms totally reasonable, highly normal Compute got savings plans again 6 years ago and that same year I started asking for database coverage, but databases were stuck in our island for this long. You could have raised a child to kindergarten in that interim. Uh, I'm not saying that. Look, I'm not saying AWS moves slowly. I would never say that. But I will say that geological epochs have been popping into my DMs asking if AWS needs motivational coaching for this. My newsletter subscribers have heard me complain about this so many times that they have reflexive wincing and PTSD from it. I have like the Muppet Statler and Waldorf here heckling from the balcony. What about savings plans for databases for context? This is the pricing commitment flexibility we have had for EC2 all this time. But for the databases that power literally everything of substance that we do that is stateful, because let's be honest, your compute is replaceable, but without your databases you really don't have a business. That's where the business lives. Our eyes were commitment without flexibility, relatively speaking, a prison of your own cost optimization making. Now we have commitments with flexibility across services. You can move between a. Aurora and other RDS, which is kind of Aurora, but not because that's weird. Without sacrificing any of the commitments you have made, you can shift from Elasticash to Dynamo DB without starting over. I asked for this as a young man with dreams, but I am now old and bitter. But I have database savings plans, so I guess that everything worked out. They're here. They're great. They only took 6 years in the collective screaming of the entire FinOs community. To achieve thank you AWS. This is huge. It saves will save real companies real money and operational headaches, but what took so long, you absolute maniacs, thank you for doing this. Next up is me asking AWS why it costs more to move data between regions than it does for me to literally move my actual furniture between states. So I'll see you all in 2031 to follow up on this. Back to you, Matt. So after all that, you might be wondering how do I get started with database savings plans. So there's the option for no upfront one year commitments. And who here has purchased a compute savings plan, an EC2 instance savings plan, or a Sagemaker savings plan? Raise your hand. You already know how to do this, so you can go and check your recommendations in the console, and you can just go with that if you want, but if you want to model a specific amount, let's say $20 an hour, you can use the new savings plan purchase analyzer that we launched last year. It's awesome. And it'll give you that savings that you'll get, and it'll give you a graph to show what that would look like for that commitment. And just like compute savings plans, you have 7 days to return it if it turns out it doesn't fit just right. It's like buying pants on Amazon. And so you can just add that to your cart and purchase it and then you'll be able to monitor your coverage and your utilization of database savings plans in the same way that you do for all the other savings plans. You can use Cost Explorer to check those reports. You can use your third party, your dashboards, your FinOps tools, or you can use the new billing cost management dashboards that we showed a bit earlier. And then you might be asking what, what do I buy more? What do I do? And for some of you, you're probably gonna take that recommendation, hit purchase, see the amount of savings you're, you're going to get, and your bosses will be very happy. Other folks, I've seen the best practice to be laddering. So by smaller commitments over time, giving yourself the flexibility and the checkpoint within either your fin ops teams or with your business unit or other stakeholders to say, hey, maybe we can. purchasing more next month, have a monthly or quarterly checkpoint that way you're getting a little bit more flexibility and you're able to see that ladder of the coverage over time. So that's database savings plan. I'd like to welcome my other co-speakers back on the stage to do a wrap up. Great, we covered a lot of today. So let's recap what all the announcements in this session. So we talked about how you can exactly customize the level of cost and usage data sharing, whether it's across accounts or payers with AWS billing view, and you can consolidate all the KPIs in one dashboard experience using billing and a cost management dashboard. Both billing view and a dashboards can be shared with any accounts within or outside the organization. Billing transfer. So it's a new way to streamline. Um, you can designate a payer of payers to, to centralize all the payments, billing, cost management across payers. You get 18 month forecasting with AI powered trademark sign, an explanation behind it that starts to give a lot more clarity to how you're predicting what your business is going to do. You get scalable anomaly detection with AWS managed monitors without having to play constant whack the mole, just track what your service teams are doing. Uh, you get enhanced cost management for things, which is just an absolute delight in Amazon Que developer because you can start acting like a he's asking questions like a human being, instead of a frustrated DBA. You can create your data exports and Focus 102. It allows you to normalize your billing data across the providers that you're operating in, and you can now, uh, split your split cost allocation data now supports Cubanetti's labels so you can get to the right level of granularity during your allocation. And finally, we've got the new cost optimization efficiency score. You've got a standard way to measure your efficiency over time. We've got the new reserved instance and savings plan group sharing. So now if you want to prioritize or restrict sharing to a specific set of usage, you can. And then of course, database savings plans, they're here and available for no upfront one year purchases. So to learn more, these QR codes should take you to the relevant places, provided that the website monkey didn't fall into the box of juice boxes again last night. And we'll see how it plays out. You can bookmark these, uh, AWS CFM teams are gonna continuously share new releases, best practices, etc. Uh, and here's what we want you to do on these things, is don't overthink it, don't wait. Don't, oh yeah, in March, we should really go back and look at that. Make an appointment on your calendar to go and look at these things in the somewhat near future. It's, it's worth the time. It really is. Uh, your future self will thank you. Your CFO will probably thank you if they're aware of what you're doing, and your sanity will definitely thank you, otherwise you turn into something vaguely resembling this. Thank you all for coming. We've enjoyed having you. Uh, please make sure that you fill out the session survey and give us high scores, otherwise we have to go back in the box and then they'll break out the duct tape and no one wants that. Uh, remember to give us useful feedback so you don't have to suffer through these lame jokes next year and thank you very much for coming and thank you to my co-presenters for tolerating me. Thank you. Thanks everyone thanks everyone.