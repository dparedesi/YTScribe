---
video_id: -GuZhm4XGxM
video_url: https://www.youtube.com/watch?v=-GuZhm4XGxM
is_generated: False
is_translatable: True
---

Welcome everybody. I'm Nate Salmons. I work for NASDAQ in enterprise architecture, and today I'm gonna talk about how we build resilient, high performance systems for financial services. I'm gonna talk a little bit about NASDAQ and our cloud journey, then go through strategies for disaster recovery, talk about our solution um in hybrid infrastructure mode, and then talk about a couple of architectural considerations as well as operations and then future looking um uh view. So NASDAQ has been at the forefront of innovation for decades now. Um, we were the first electronic exchange, and now we operate over 30 different exchanges of, of different types of instruments in, uh, the, the, the Nordics as well as in North America. Um, we are both a system operator, right? We're operator of these markets as well as a provider of software to over 130 marketplaces globally. And that includes trading systems, clearing systems, risk management, anti-financial crime, the whole, whole range of different solutions, and we deliver those as traditional managed or traditional software installs, as well as managed services and SAS. Our journey to the cloud started some 15 years ago now, and we've been working our way towards our most critical systems during that time, right? Matching engines and and market systems. Over that time, we've moved a number of systems. We started out with sort of T+1 backups, that sort of thing, progressed towards more and more real-time systems, you know, T+1 reporting, then uh intraday and now hard real-time systems with with our markets. Um, at the same time, we've gone from, you know, obviously less critical systems to far more critical systems. Really systemically important for, uh, national economies around the world, including the US, and, um, just very important, uh, workloads going. Along the way. Right, we've seen a bunch of challenges. Uh, first and foremost, we have systems that provide ultra low latency transactions, right? We measure things in microseconds and nanoseconds and millions of messages per second where we can't drop anything, can't lose anything. We also have to do this in very specific physical locations, right? I, I talked about proximity and latency, um, you know, we have a, a big, uh, business that, that lets customers bring their own hardware into our data center, right? And so we operate an ecosystem, and so if we decide to move, you know, we have to move our customers with us, right? So we have to be in specific locations for now. We also have a high resiliency target, and our customers expect 100% uptime all the time, every day, uh, you know, as long as the market is operating. And then of course we have regulatory oversight, right? We have to do this in not just the United States, but again we deliver these systems globally, so we, we operate in a wide variety of different regulatory jurisdictions around the world. So I think everybody's seen this spectrum a couple of times, right? Talking about different, different ways you can accomplish uh disaster recovery, um, all the way from, you know, backup and restore, which is kind of where we started to multi-site, active, active, multi-region, everything is hot all the time, um. I'm not really going to drain this slide, but the, the main point here is that you as technologists and you as business people need to really agree on where a particular workload lands on this spectrum, right, and understand that, you know, you can hit your RPO and RTO targets if you, you know, progress your way along this spectrum far enough, right? And that it's super important. That everybody understands uh what's going on and when a disaster actually happens, that nobody is surprised at the response, right? That you, you know ahead of time and, and you're prepared. So the rest of this talk, we're really gonna talk about the far end of the spectrum on the, on the right side here for critical systems that have to be live all the time and, and can't go down, right? So the rest of this is all about uh those types of systems. So first we're going to talk about hybrid compute with outpost that lets us place workloads in our data center but still manage them with, you know, the EC-2 API and use Amazon infrastructure. We're going to talk about an architectural consideration of failure domains, which lets us model how the system is going to respond to various types of issues. Then we'll talk about static stability, which is another architectural consideration around how you plan ahead for, um, for some of these issues. And then we'll talk about disconnected operation, which is a little bit more on the, on the runtime operation side and how we protect ourselves from, from any sort of issues. So if we talk about outpost, right, this is a pretty simple diagram of left side, we've got the, the region. Obviously, that's where the control plane runs and all of, you know, identity and all that sort of stuff. We have a direct connect circuit, actually multiple physical circuits uh in, in all of these cases, but that leads to our data center. There's some racks of hardware with uh EC-2 servers in them, right? Um, we hook up the, uh, the EC-2 network to our management network, and I'll get into that in a second. But this lets us put uh or use hardware as a managed service, right? Where we can just subscribe essentially to uh to these services and, and hardware shows up in our data center. Um, it's a little more complicated than that, but it's, that's the basic premise. Um, and then, you know, of course, To meet our needs, we were able to work with Amazon to add ultra low latency network interface cards to each of these EC2 servers. That's actually generally available now. If you see the BMN SF2E and other series there, that's, that's a bare metal server, right? So we talk about having bare metal on the EC2 side, but then the network in this case is also bare metal. So we have a fully physically separate data plane for for our market systems. And critically for for equal access and one of the regulatory requirements that we have, we use equal length cables and multicast, right? So we use hardware multicast on these systems and the bare metal nature of the EC2 instances combined with the network side lets us do a bunch of performance tuning on the network. We use kernel bypass and all sorts of other tricks, right? So this is the basic physical hardware setup that we're using. If we then move towards failure domains, this is a way to think about uh the, the different bounds of your system and which items have common uh shared fate with, with each other, right? So, first of all, we'll talk about servers, right? It's, it's relatively obvious. We, we have EC2 servers and they have our software running on, on those servers. Um, if something happens, right, we run multiple servers, right? It's, it's not, uh, super complicated. We also run hot spares in the rack, right? And this will get to, uh, uh, the static stability side of things in a minute, but these are pre-provisioned DC2 instances. They're up and running. They're not running our workload yet, but they are provisioned, they're ready to go. We can use them whenever we need to. And of course we run AB pairs of every software component, right? So we have a backup for every single thing, and we don't run those AB pairs on the same instance, right? Um, otherwise they'd have shared fate and, and you might have issues. So then at the rack level, if we keep sort of expanding the scope of these uh failure domains, right, the AWS outpost rack, you could lose power to the entire rack. Obviously we take great pains to not have that happen, but uh it's possible, right? So of course we run multiple racks, right? Um, and then for every AB, um, software component, instead of just running it on, you know, running the A pair on the first server and first rack and the B copy on another server in that rack, we spread those workloads across racks just so that if an entire rack goes out, we're not gonna lose, you know, the A and the B copy of any particular component, right? Not super complicated. Then at the physical site level, right, our data center, um, we run, of course, multiple sites, right? So we have a, a primary in New Jersey and our secondary uh site for these markets is in Chicago for the, for the US side of things. And critically, For these setups we run a separate outpost, right, a separate logical outpost in both of those locations, but then each of those outposts is owned by different AWS accounts and each of those, um, outposts is also paired with a different region. Um, the account side of things is a little more on the cybersecurity blast radius, uh, perspective, but it all, you know, kind of rolls in here, right? And then of course at the region level, for anything that we're running in the region, we run multiple regions, right? Um, in most cases for all of these uh critical systems, we are hot, hot across multiple regions, but again, I'm really talking about the, the outpost side of things here. Now, if we're looking at at this setup, I've I've talked a lot about physical infrastructure here, right? Servers and buildings and racks and and this sort of thing. You can do the same exercise logically with your software and, and you should, right? You should understand all of the component boundaries, how they interact, what happens if one piece goes down, how do you, how do you respond to that, right? And then for each of these items we've, we're talking about how we build and design it, but off of each level in this sort of failure domain hierarchy, you need to have operational runbooks as well, right? What happens when a server fails? We do A, B, C, D, E, right? What happens if a rack goes down? We do this and that. All of those procedures need to be covered well ahead of time, worked out with all of your operations staff. Nobody should be surprised at what's happening during a disaster, right? You should be surprised that a disaster happens, but all of the responses to that disaster should be very well choreographed and, and basically, you know, second nature to everybody involved. So then if we move on to the next um architectural concern, right, uh, static stability. You may have seen this with uh a number of Amazon services uh are, are statically stable. In this case, we've got, you know, a simplified diagram here. We've got the, the region on the left with a couple of services that we need, and our data center on the, on the right with outposts and a service link in between. Well, what if, you know, somebody runs a trencher through a bunch of optical cables in a farm somewhere and, and cuts that line, right? We can't have. You know, market's going down just because somebody ran over a line with a, with a tractor, right? Like that's a, that's a really bad situation to be in. So obviously we have multiple cables and all that sort of thing, but static stability is all about not changing the system during the day, right? We're not flexing up and down on, on any of these things again, just for these critical components, right? But it really means that. You know, in some cases there's, there might be an issue with the EC2 control plane, for instance, you can't provision new servers, right? That's why we have all of those hot spares in the rack already ready to go, right? So we don't need any kind of connectivity to start using them. We don't need, you know, to talk to the control plane, we just start doing it, right? Obviously under regular circumstances, we would go through the normal channels, but in disasters, we, we don't always have those options. We're then very careful about what services we actually deploy onto the outpost, right? Um, in region we use all kinds of services. On the outpost, we're very careful because we want to be able to run in this sort of configuration where we're able to keep everything running on that outpost and, and not really deal with any, any issues. We use local boot on all of those instances, right? So they have local disc assigned to each machine. We're not using EBS in this case, um, just because of a shared fate. Um, and then we also use that local gateway for break glass access, right? In normal cases, if you're SSHing in, you're coming in through that service link and down back to the AC2 instance. But that local gateway lets you just SSH directly in, right? Um, you need to make sure that, you know, you're not hairpinning your, your traffic to the region or anything, but it lets you do all local control, right? So the, the whole plan here is that, um, we're able to manage those systems locally. Um, we also did a, a deep dive with AWS service teams on all of their internal dependencies, right? For the, for the things that we're running on the outpost, we need to know everything. And then we've also done a ton of testing obviously on, on this. Uh, then if we talk about, uh, disconnected operation, right? This is where we wanna be able to survive those issues where somebody cuts that network line, right? Or if the, if the region is having an issue or, or whatever, um, this is really about testing all these failure modes, right? We. Disconnect our our our outpost for a week or longer, um, just to see what happens basically, right? Like in some cases, services are re-upping uh SSL searchs or they're checking with IAM for various things. Like you need to be aware of all of those operations that are happening so that you can either avoid them or just be aware and, and understand the failure modes of, of those systems as well, right, during, during your outage. Uh, again, make sure that that local gateway is accessible, right? Um, that is kind of our, that's our break glass access into those machines and, and we need to make sure that that's active, even if, even if the region's down or even if, you know, the, the service link is having an issue. And again, really this is all about If there's an issue, we can cut these systems off from essentially the rest of the world and make sure that everything is still running locally. Market's going to be fine. We'll do the closing cross. We'll do all of those things. Everything will be, will be good. Um, that's really what we're, we're after, right, is no surprises. Everybody knows what's going on. All these systems are very well tested, and, um, you know, there's a bunch of patterns here that you can use with your own systems, whether they're on, whether they're on outpost or whether you're deploying in region with more traditional um deployments. So again, the review, right, we have, we have outposts in our re or in our data center. We're analyzing the whole system with this fault domain concept, right? So that we understand which components, um, you know, live together and have their shared fate on the same server, uh, or same rack or same building or same region or etc. right? It's, it's a very careful planning there. And then we test for static stability, we design for static stability. That makes sure that we can, you know, continue running even if there's issues. We don't have to like scale the system up, don't have to do any of those things. And then again disconnected operation is, is just where we're, we're able to keep going even if those lines are cut. Um, that is really um the only item here that's specific to outpost, right? You don't think about disconnected operation if you're in a part of a, a region, right? But for these systems, right, if we cut over to DR that is a big deal, right? It's a reportable event to the regulators. All of our customers are mad, we have to explain ourselves, so. We go to great lengths to not cut over to DR. We, we have a fully functioning DR system and we can definitely, you know, run there. We've tested it, uh, but we go to great lengths to not do that, right? So that's probably the, the biggest difference between kind of a regular workload and, and something that we're running on, on these ultra low latency outposts is kind of that extra step, um, in case of, of more issues, right? Uh, but in general we run multi-region, we run multi AZ in the, in the primary, at least, if not in both the primary and the DR, hot, hot everywhere, um, you know, it's, it's not a lot of rocket science, but it's a lot of, of really diligent work and being very careful about dependencies, about failure modes, about understanding how your system is going to respond to any sort of, of issue, whether that's, you know, man-made or a flood or whatever, right? So then let's talk about where we're going in the future. You know, we want to do a little more dynamic deployments, right? I had talked about how we lay out, you know, AB components on different racks and that sort of thing. We actually plan all of these deployments on outpost. We plan them down to the individual CPU cores on every single machine, right? So we do. for both resiliency purposes, right, to make sure that if a server goes down, we don't take the A and the B copy of something out, but we also do it so that we're not overloading the PCI bus on a particular machine, right? So we do a lot of performance balancing as well as resiliency balancing. We wanna get um to where we can do that with a lot more rules-based setups, right? Where we do affinity and anti-affinity patterns and those sorts of things. But we're not quite there yet with the performance side. That's one thing that we're we're really interested in doing. Um, like I said, you know, we're not scaling these systems up and down during the day, but as we move markets into regular public cloud, that is something that we wanna be able to do, right? So these are all kind of um stepping stones on our way to, to being able to run those markets in, in public cloud. The other thing we're experimenting with is Graviton, right? We've had really good luck with Graviton 4. we're working very tightly with the, with the Amazon team on, on the next generation of those CPUs and testing them in outpost and ultra low latency network cards for Graviton and a number of other um uh advancements there. Then you know, accelerated compute. I didn't really talk about that in this in this session, but we use FPGA in a number of different systems. We're experimenting with GPUs for, you know, risk, like real-time risk analysis in markets, that sort of thing. We want to be able to bring more of those components into the outpost, right? Um, and the other angle on that is that we're selling these systems externally to third parties, right? And so we want to be able to offer them a more and more compelling offering with more, more functionality and more services, right? So, um, custom silicon and FPGAs and GPUs all very, um, very square in our, in our future vision. And then of course more services, right? I, I talked about we're very careful about what services we run on that outpost. Um, EKS local clusters is, is really the next one that we're looking at, and that's, that's kind of towards the dynamic deployment. As well as just like an easier way to manage things, um, but we're very careful about adding more services, right? Like we, we do those deep dives with the service teams and understand failure modes, but we wanna just continue to up our game on, on service availability and on the functionality that those services are able to offer in an outpost in these sort of um constrained, very critical systems, right? So that's kind of where we're going and where we've been. Thank you. Uh, fill out the form and, uh, yeah, have a good reinvent.