---
video_id: emgHNG0n7zQ
video_url: https://www.youtube.com/watch?v=emgHNG0n7zQ
is_generated: False
is_translatable: True
---

Good afternoon everyone. Uh, I'd like to thank you for coming, uh, for this late afternoon meeting. Uh, today I'm going to talk about discussion control plan. I'm going to talk about how the operations will change in the next two years. Like whatever you are dealing with software for running software, you will deal with it differently, like either yourself or by using your product. I just like to talk about this, this quote from Dario Amode, CEO of Antrofi. But in March 2025, like eight months ago, he said AI will be writing 90% of the code software developers were in charge of. So like, I don't know if you agree with this sentiment. I, I don't think that we are there now, but I think we are coming to that. If not 90%, it will be like around 50% today. And like considering that where we were two years ago, I think this is quite a leap, and like even if we are not at the 90% now, I think we will be in a very, very near future. So that actually sounds super exciting so that like now we are not, uh, you know, doing the daunting task of writing code. But this means that you will be responsible for the alerts that you got at 2 a.m. About to quote that for the 90% of it you have no context, even like maybe less context on the issues, and you also will have no context about the issues that like the, the, the blast use of this issue on the other systems that are probably written by AI again. So like, this area requires something that is like a new operational patterning for SREs and also. For the ops engines and whoever is responsible for waking up at 2 a.m. So, even today, like, you know, without even any AI getting into space, the, the modern ops is already very siloed, so like people are responsible for different parts of the systems and they don't care about the rest. They're always reactively coming up with action steps, and even if the round books are coming like piling up, it's, it's about the lessons learned from the other stuff. So, uh, it's like the, the people are just like looking at the dashboard, trying to query data, just acknowledging the, the, the errors, and then it is all with the old school tools. Here I'm saying that like you cannot resolve tomorrow's problems with yesterday's tools. That's why er we will be introducing today something we are calling as discussion control plane, where your agentic SAE teammates or any other teammates will be talking with others uh with your systems. Before jumping in more, let me just introduce myself a little bit. So this is my like an er almost a decade I'm working on observability, and first I started my journey with observability with er observability. And that's how I got to become a server hero back in 2020, and I'm actually an ex-developer who got, who become a product manager accidentally. Now I'm becoming an uh developer again with the powers of AI and I'm at my seventh AWS3 event this year, and I'm really, really feeling the the energy here about like how AI changes everything, about like every role and how, how it will be. Changing in the next year, so I'm, I'm already full of questions about how it will be for next year. So agenda for the rest of today is that we will talk about like what I mean by teammates. So we will talk about what is assistance and then what is teammates, and then we will then talk about the, the challenges of running LLMs on streaming data, and also we will, we will uh link it with the guard rails on data on telemeter pipelines, because you just cannot send everything to an LLM, right? And then we will talk about a cultural shift while after AIT mess like, OK, AIT mess here, so what I'm going to do is Like a normal teammate. So, let me talk about Assistants versus teammates first. So AI assistants are just like the, you know, you, you see them everywhere in the website, so in every website there is now an AI teammate that's great at fetching, fetching relevant information for SLE use cases, it's always like, OK, I'm I'm asking a question, I'm curious about something. OK, it's helping me to query my ask in in prom or in. Whatever creative language that you are using, it's good at retrieving data from a dashboard, but it's not like, you know, it's you need to be following up with the discussion. You need to be telling that, OK, I got my answer, but like is this actually helping me? So they are always like by design passive helpers. So they are not just there to actually resolve the issue for you, but they are just there to answer your questions so that you can resolve the issue. But I, you know, this is, this is good, like this is like what we have been using AI for, for quite a lot of time, right? But like, this is kind of passive. So the, the actual difference between a teammate and assistant is, is rooted from, An action versus information with AI team mates versus an assistant. As I said, like the AI assistants are like respond to prompts, uh, and just like, you know, uh gives an answer and waits for the next question, while AI teammates can proactively initiate the actions and uh start, uh, how can I say, doing a research about the issue uh while you you didn't even ask about it. And uh for for AI, it's scope and the memory is all about like the the questions that you are asking. It only remembers the previous questions and the previous discussions. And the AI teammates is like the multi-turn, and they are like, OK, I did something, but it didn't have the solution, so I need to do something else. And from that perspective, like you can see AI assistants as helpers while you can look at the AI teammates, your collaborators, like almost like your junior junior engineer that gets better and better with everything that they are learning. Again, the context of it is like the IT inmates can know like something other than the prompts that you are giving to it. You can learn about like the, the, how is your service map looking at, how is your dependency map is looking at, and like you can, you can understand that like the IT mates know your systems more than you, and then that's how actually you can trust on them. And uh. And they can act anonymously within the boundaries that you put them for it, so that you can say that, hey, I want this AIT mate to do this stuff, but not that much. Maybe you can just limit some actions and you can say that, hey, I want certainly an approval permission for this type of things. So let's like, let's talk about a real life scenario that we have been uh having at that like we are anonymizing the names here, but you know, this is like a way to start, one of the ways to start a discussion with AIT mess. Like as a human you can just go and ask a question to it, but there might be other ways, like a monitor can trigger a discussion before, or like an external event or a periodic task can can trigger a discussion. At this time this is like a human asking a question about, OK. I am, I'm like I'm seeing something wrong. I'm not sure if it's an incident. I'm just like, I just want to check something happening, so like this is normally how you would behave on Slack, right? So you will say that, OK, yeah, something seems off, like can we just check? And then it starts here. So there is an orchestrator for this all AIT mates that that knows all the AIT mates in your system. So let's say you have like 10 AIT mates, and then one is responsible for SRE, one is responsible for writing code, one is responsible for design, let's say, and like, Uh, orchestrators, in our case it's Eco AI at A Delta, like looks at all these teammates, looks at all their tools, looks at all their permissions and looks at all their memory and picks a teammate that is the most suited for this question. In this case it is like the SRE and it's giving it a prompt about like, hey, I want you to run this analysis to answer this question. And it comes with these questions, but I'd like to take your attention to this approved thing, because like it is asking for a permission before moving on. This is like how you actually can configure uh a system to, to act in the bound in the boundaries that you set. It's asking humans to get an get an approval for this, and then it starts its analysis and it pulls the first shot it can retrieve. Right into the thread. Then then it, it goes back to the orchestrator and the orchestrator says, yeah, I did some analysis, maybe like there can be some other stuff, but like do you want me to go it, go for it, and then the human user says, oh, I, I see what's, I, I have some idea what's, what's, what can be happening now. So I'd like to ask more, more questions about it and like can I also like look at the lock patterns? And then uh again uh the orchestrator peels up the other, other teammates just to look at this, this uh. Uh, question, and then the other teammate is asking for another uh approval and then pulls this data, but like I, I, I really want to, uh, take your attention to hear that like normally if you will be, you know, this person who's who's trying to resolve this issue, you would switch between tabs. You would say, OK, now I need to look at patterns, now I need to look like you would go to some dashwoods and like all of a sudden you will find yourself like this, like the 1010 browser tabs open at the same time. But here, everything is actually in a context with just in a threat. And then, you know, this conversation takes long and then after some time. The, the, the, some other teammates came in, like the SAE reported and then code analyzer identified the problematic comet in the latest deployment, and then it's asked for like, do you want me to add a rollback, and user requested to rollback and it is the rollback and. Uh, and, and then the next step would be like, OK, you can maybe continue analysis, but then you can continue for watching for issues. So it is like the, the issue is resolved like with minimum human involvement, and this, this human doesn't need to know about like how to query data, how to orchestrate the actions. It's just like the. It's just like Asking questions in a naive way and then let the the AI teams do their work. So, uh, I just wanted to, to talk about one more thing that here that like, as you can see now, like in these threads, it's all preserved. All the charts that are, that all the data that is retrieved for this purpose, all the charts that are uh that are drawn for this purpose are now preserved in this thread. You can always go back as a human user and see what actually happens, but like more importantly, your AI teammates can go back and see what happened there. But uh joining elements on streaming data is, is, you know. More difficult than set. So, like some of the telemeter data sets are kind of more suitable for running with the AI. So logs and events I have stars on on them now because they are more compatible with LLMs because by their nature, they are like the words that are tokenizable by LLMs and that like any log line is actually can mean something to. LLLM similarly and like events like the Cubanic events, such events actually mean something and like the LLM says enough context about those. So but like they are easy to understand for LLMs, but they are not easy to, you know, just feed LLMs for because like they they come in the petabytes of scale and you need to actually find a way to like, you know, allow it to, to feed the LLM. In in a distilled way, metrics entries are also, you know, interesting. Like you cannot just like expect LLM to reveal the trends for you. So you will need to do a boring job of like, OK, there's a metric anomaly, so I need to pass it to LLM and similarly at traces, I will do a distributed tail sampling on traces and pass it to the LM so that the LLM can do analysis after all. You cannot just like. Just dump all the metrics and traces to LLM because in this case you will go bankrupt. So it is, uh, as I, as I say, like it's efficient data processing requires for uh terabytes of petabytes of data, but it allows you to run the queries in English. But the scalability, of course, is not, is not the best thing that can happen. So for that thing, actually like I see people that tokens are getting cheaper, like, you know, we can maybe in the future just feed everything to LLM. You know, no matter how cheap they will be, like it will be still very expensive at scale. And like the training, like the fine tuning models with the, with the your own metrics is infeasible for most of the data. And actually not very spoken truth about data flowing to AI is that we are just letting everything out, so we are just like, OK, LLM just read everything, read my code, read my data, read my like all my intellectual property, it's all yours. And it is like exposing a risk and teams are now busy with managing the data following to LLM. And at this point, like we we come to telemetry pipelines. So when telemetry pipelines are first out, they were being used for like, hey, like let me just compress this data, archive it in a destination, and it will just like make me, you know, store my uh telemetry data sets in a, in a like in an estuary bucket, and then it is just like keeping the data safe. And then like we, we discovered a nicer ways of like seeing data and we like the cost actually, you know, go by like another like 100 times. So we could have, we could send the data to Sun or Datadoc, but you know, like if you just ingest all this data to do, so you will also go another bankruptcy. And then uh that's why telemetry pipelines came into space to uh to reduce the data, to filter the data in a in a in a in an intelligent way and to mass data. And this was actually the the what we know as telemeter pipelines today. This is a good value, like, but it is not strategic. It is about like, OK, uh now I'm reducing the cost, but like I don't still make the data speaking to itself. And for that value now we have LLDs. Now using telemeter pipelines now which is also costing 100 times more. Using telemeter pipelines, you can just provide high value to AI but by still keeping the data under control. And there's also, you know, I know a lot of companies just, they're just like complying with all these security things, but like, uh, security certificates, but they are just sharing their source code and their, their uh architecture just bluntly with LLMs. And then like with telemetry pipelines actually, you can say that, hey, I'd like to really mask the data that goes to, you know, LLM. I can just say that, hey, I don't want to send my, you know, anything about like any, any information about uh. My users any information about their their their PII and also about like my own code, my own service topology. I don't want to just leak the important details. And actually when you have the masking and filtering capabilities. Before the data goes to the elementary pipeline, sorry, before the data goes to LLM, it's actually protecting not only you but also your customers and also your new hires that you will, you will hire in next, next month about like uh they will not be bluntly using it. So you may say that like uh. Now Agent Tri is here now, like, are they taking our jobs? Like what's the role of us in this new paradigm? I believe this is like a more like an elevation rather than just like replacing them. So as, as human people, you will still be responsible about the risk management. You are still responsible of the mistakes that LLMs can make, and then LLMs can actually create the problems. So you will need to focus on. How they behave, you will need to change their behavior by just changing the tools that they are using, changing the models that they are using, and changing the data that they are using, and you will need to actually be managing them. And you will also move in like an upper layer in the in the organizational risk management perspective and then you'll focus on more complex case and you will just like maybe go shifts left on the on the uh development flow about like how to respond to issues uh before, before they actually push the production. And you will be the ultimate decision makers about like how elements behave and like how humans should be, should be focusing on these jobs. So, uh, this brings me to the end of my presentation. Uh, so if you have any questions, we have a booth over there, uh, a data booth, so, um, we will be, we will be happy to talk about these questions there. Thanks a lot for listening to me today.