---
video_id: oA8YjULXmKw
video_url: https://www.youtube.com/watch?v=oA8YjULXmKw
is_generated: False
is_translatable: True
---

Good afternoon everybody and thank you for coming out to hear us talk. Um, a little disclaimer before we get started, the majority of the images that you'll see in our slide today were created using, uh, the Nova Canvas model. So a little shout out to AWS Gen AI there. Oh. The NBA is an always on enterprise. By that I mean that they've got a global fan base that wants access to content 24 hours a day, 7 days a week, 365 days a year. Um, they've got to be able to deliver that content and services to their fans, to their partners, um, and in that context, how do you migrate a, a global fan, uh, leading global sports league like the NBA, a full scale scale cloud migration in just a matter of months? How are we gonna do that? So today we're gonna be talking about that with you. My name is Mike Lally. I'm a senior solutions architect at AWS and I have just the great privilege of working with these two gentlemen, uh, Jesse Robbins and Mark Bennett at the NBA, my awesome customers. Thank you. On October 1st, the NBA and AWS announced a five-year strategic partnership. This partnership is really, really special, and one of the key things about this partnership is that it's designed to power a new era of innovation not only for the NBA but really for AWS and we're, we're really working together to collaboratively drive innovation in sports. Yeah, that's right, Mike. Uh, we're super excited the NBA. We're working lockstep with the AWS to bring our fan engagement up and bring them closer to the game through unique stats and advanced technology. We're also committed to deepening our fan engagement through a diverse, uh, fan base so let us show you what that looks like here on the screen. prayer. lets it fly. prayer. All right, yeah, isn't that great? So let us talk about our strategy. So you know when we're thinking about going to the, you know, moving to the AWS cloud, there's a lot of principles and strategies we wanted to make sure we got right. The first one we're gonna talk about is to go slow to go fast. Now, what does that really mean at the end of the day? Well, one of our objectives was to get all our design requirements, our principles, get all those key architectural decisions agreed upon. So we spent a lot of time, Mike. I think if we did about 15 sessions on a well architected review with many iterations of those sessions, making sure that we understood what each of the service components would do, what were objectives of those, and making sure we had tight agreements around that. Now that slowed us down. But as a result of getting all those agreements ahead of time when it came to execution, we could go fast. So why are we doing this? Well, for us from a strategy perspective it's always about the fan, you know, you saw in the video we wanna drive better fan engagement. We have a global fan base and we wanna make sure everything we do within the platform, within our designs is focused around the fan. But at the same time we have to keep the long term vision. Intact So what does that mean at the end of the day? So when you're building the foundation through your design, you know you needed to get there fast. We had what, less than we had to be ready by summer league of July. We had a few months to get everything going, but we also knew because of that speed we couldn't do trade-offs long term and so we knew that whatever we built how to handle key moments at the NBA. So think of critical moments like NBA Finals, our draft. Um, those moments we needed to be able to scale up and build a handle at the peak capacity. So in our project timeline, you know, you covered the discovery, you got planning, execution, but we had to get that done fast and having that speed and scale was critical for us. So by that, like I just mentioned, by summer league we had to have everything ready to go, production ready. Mike had mentioned the partnership, uh, October 1st, so I think we're 3 months being ready to go so that way we could test workloads so come October 1st we could be launched into the new season. Jesse, you wanna talk about team commitments? Sure, so for a project like this, um, it really requires commitment across upwards of 15 disparate technology teams. The migration planning included deliberate reasoning, cross team debate, and alignment on key architecture decisions. We never allowed perfect to get in the way of good, uh, aligning early. Uh, ensures, um, fewer bottlenecks and antidote opinions across the project timeline. That? So, uh, speed and scale, uh, embracing change, we work closely with AWS and embraced our multi-account architecture, granting our DevOps and engineering teams more autonomy, but also ensured ambitious standards for things like identity management, compliance, and security. That I'll turn it over to Mark. Talk more about speed and scale. Yeah, let's talk about speed and scale. So when we were thinking about, you know, that short time line where we had to get services out quickly, you know, I mentioned the July time frame a few months to go. It was our time to embrace change as Jesse had mentioned by leveraging coordinated products across AWS. So things we took advantage of at our disposal was things like control tower so we could get configuration management through AWS config rolled out. IPA, where we struggled in the past of managing RP space. We also had the ability to roll out different space assignments as a result of that Route 53. Um, and then most importantly was cloud one. When you're managing lots of accounts, lots of EPCs, the ability to manage that at scale was critical for us. Having those native products in our suite enabled us to go really fast. Now, at the same time, we gotta handle scale. Well, having those products allows you to scale across multi-regions. We could leverage the AWS multi-account architecture and then really put us in a great spot for high availability, the resiliency that we need to run a high-end consumer app. So with speed and scale comes span of control, and we knew we're gonna have lots of accounts, we're gonna have lots of services running across AWS and we needed control and so one of the things we wanted to make sure we did as part of our deployment implementation was to be to have. Um, service control policies rolled across key accounts, key services, and using things like AWS config, we wanted to make sure those, um, certain flags were turned on across our accounts. We wanted to make sure certain routes were in place through cloud W, but having those key service control policies gave us the control we needed. In counter in contrast, we can also then segment our accounts if needed so not only does it give you the ability to control policy, but when you're managing multiple accounts and managing multiple services, if we need to segment accounts or segment services we could do that with um AWS and now we're just super excited uh uh that we have that ability where in prior prior um situations we didn't. So here's a look at some of the services we use at AWS. I mean, the ones I've been highlighting is Cloud WAN. Um, you can see there's a ton up there's Bedrock, Nova, uh, AWS config. We have that as a key service for us, AWS Lamba. So you can see how many native products we're using across the AWS infrastructure to really help us out. So Jessie, you wanna talk about the consumer? Sure. So the scope of our platform services for the migration encompassed across three pillars. Uh, first, our middleware components which are made up of our core platform, our core API deliveries, our identity platform which powers NBAID, our media services which, uh, is effectively our live streaming orchestration platform, all of our VOD delivery, uh, for encoding, streaming, ad delivery. And our back end systems including our content management system and our game media scheduling system as well. So leveraging AWS services across these three pillars allowed us to achieve significant performance and scalability improvements, uh, specifically around, um, moving to a service like Memory DB, for instance, which allowed our core platform and API services to, uh, scale and, and improve proved our performance significantly, so much so that we had zero critical production issues since the start of the season. Um, a highlight also, uh, is, uh, an improvement to our VOD closed captioning generation which was improved by 60% using the AWS transcribed system. Uh, and finally, uh, a key highlight for us too was leveraging the new S3 file system out for our content management system which also helped improve our, our performance and scalability on that platform. That side. So, uh, with a project like this comes some challenges along the way, um. Real-time video processing at scale, uh, for us is incredibly important, uh, so our multi-region red redundancy set up really uh helped us in that, in that area. Some of our legacy systems also had to be refactored and rebuilt. We moved to, uh, container containerized applications, moved on to EKS, um, and a lot of our third party and vendor systems were also doing some migration in parallel. So these are some of the challenges that we, we experienced along the way, but in the end we're able to, uh, deliver successfully for the start of the season. So some of the services that are key to us on the platform side, obviously EKS for all of our managed Kubernetes, uh, Amazon S3 for storage, lambda for automation, we, we leverage SQS for our Q-base services significantly, and on the database side we use everything from memory DB, document DB, uh, all the way to, uh, AWS OpenSearch, um. And with that I'll pass it back to Mark for analytics and logging. Yeah, thanks Jesse. So one of the key decisions that we spent a lot of time in the front end was talking about how to log reservability. And so when we were doing the well architected review, I think we ended up with about a 56 page document. I can't remember, it's pretty long, where we had laid out all the agreements that we're gonna do, the options, and one of those sections was explicitly on analytics and logging and what we knew at that time is we wanted to bring everything back to a centralized, uh, painted glass for AWS. So as part of that mapping we identified the key elements that we wanted to bring into our logging system. Bringing that back in to CloudWatch enabled us to get insights across the infrastructure um in a way that we didn't have before. So now we can compare regions we could compare services, we could do a lot of different things that we couldn't do before in in our monitoring now. We talk about distributive monitoring too. It's not which one is better. We do both. We have a lot of spoke monitoring and now we have an enhancement on top of that, that monitoring that gives us a full capability, uh, a full view of our insights across the application. So that oversight now that we have really puts us in a position to monitor and alert more effectively. We can leverage workflows to generate tickets to AWS. We can now integrate into our digital operations center, the AWS IDR team, get quicker response and get more engagement, a faster engagement and hopefully reduce our MTTR at the end of the day. So that rapid response in live game live broadcast, we all know it's milliseconds, not seconds, and we have to get teams quickly engaged with our analytics and, uh, analytics and logging on cloud watch in addition to our other monitoring. We can then get teams to engage quickly, get things fixed, get our MTTR down to zero, hopefully that's always the goal, no, no issues. But in addition with that, now we have parallel teams responding to incidents. We have our NBA SRE teams, our DevOps teams, our developers teams engaged to get to, um, engaged to get incidents fixed. But in addition, now we have AWS working in parallel with us. So let's talk a little bit about the benefits of enterprise infrastructure. So running at scale you need governance. We have security governance. We got compliance governance, and one of the things that I would tell you most importantly to do at AWS is embrace that multi archit multi-account architecture. Use the service control policies. Use tools like control tower to work across your different workloads and the different accounts. It also provided us opportunities, Mike. I think you're talking about like IPA where we can manage IP space differently. So having that flexibility where we can do different things at at the governance scale where we couldn't do before, but having clear ownership across your accounts is key and having that governance is the way to do it. When you have your control policies, that means you can push more autonomy out to your teams. That means your dev ops teams can have, you know, more ownership to manage their accounts because you're now putting governance on the account at the enterprise level versus, you know, us coming in and trying to come back after the fact and tell them what to do. We just pushed out from the front and then they can operate effectively. Remove the engineers. I know this is probably, you've heard this many, many times, but you don't want your engineers. I think even at the keynote we're talking about the new DevOps agent, which is kind of cool. The less people involved in change management, the better, the more automation we can do. Is better and for us one of the challenges that we had was in our, uh, you know, in our prior life we had to really manage a lot of IP space and deploying products like IPA really gave us a lot of automation and removed a lot of our engineers out of the way so then we could scale out and do things differently but any of those instances where you're struggling with manual work really dig down deep. Challenge yourself and then think about how to remove that engineer because you'll be thankful at the end of the day. It's a common one I see everywhere, you know, in your pipelines, in your deployment, your config management, your automation through the platform. Control tower is a good example. Cloud W, we really embrace that from the get-go. We spent a lot of time in our design trying to figure out how to make sure we didn't have any manual intervention. As a result of manual intervention, you know you're gonna have reactive work because someone's made a change you're not aware of, but if you're coming through the pipeline, coming through the process, it's easier to understand the impact and um as a result of those changes. So one of the things we wanted to make sure was happening was infrastructure is code everywhere, but when you get to that point, it moves you into the concept of infrastructure service because the engineers aren't in the way. Everything's coming through the pipeline and then change management can happen more fluidly. So let's talk about the trusted advisors. We knew at the NBA we needed our subject matter experts doing this work. We needed well trained, um, individuals to come in and help execute in the short time fine. We also needed the right people in the design session, so we identified those key people. We also identified areas where we didn't have the skill set. And then we brought in people to help with that. And Mike, do you want to talk a little bit about how AWS came in and helped with some of that trusted advisor work? Yeah, Mark, you know, it's, it's interesting, uh, when you work on an account like the NBA, everybody wants to help out, which is awesome. Uh, so it wasn't difficult for me to find the specialists that I needed when we had to dive deep on something like, uh, memory DB, as Jesse said, or DocumentDB and understand trade-offs between different services. Uh, we were able to get those folks pulled in very quickly. Um, and having that deep bench of specialists and, uh, service teams at AWS really willing to, to dive deep with the NBA and help us out on those design decisions was really critical to, to getting the trusted advisors that we needed to make those decisions. Yeah, I just wanna add one thing to that, you know, as part of that design review, one of the things you need to be open minded to is healthy challenge. When you're in those sessions, don't think you know it all the time. Hear people out, make sure you're thinking through some of the, you know, the challenge back about maybe how to do things because that's why we wanted to spend so much time in the front end working through those agreements. So it's really key that. You, you lean on them, kind of trust some of the guidance you're getting, and that's not just from AWS, that's really from all your engineers who have maybe had different experiences. Sometimes there is a different and a better way to do things, yeah, and even related to that, uh, you know, some of the meetings that we had our product teams were able to learn from the NBA and that drove what we call product feature requests that we were able to then feedback in so it, it really was a a collaborative, uh, situation there. Um, the other thing that that we figured out is that, uh, it takes two, right? Um, we had one team, uh, really focused on day to day operations, another team focused on design and implementation, and that was actually across the board. So on the NBA side and AWS side we had both of those teams working, uh, jointly and in parallel, um, and that helped us, uh, determine things like the, the right way to engage with the NBA for a support model. So what is our. Enterprise support and our technical account manager team and our IDR team, what's the best mechanism and the best path for us to engage with the NBA? Is that using Slack channels? Yes, it absolutely is. The NBA loves to use Slack. We all do, right? Um, and using Slack was just a natural way for our support teams to engage with the NBA, uh, when they ran into issues or even just testing to make sure that we were prepared to address issues as they came up. Um, but from design and implementation we also had your solutions architecture team. We had the service teams engaged to ensure that throughout the entire migration step and really going back to the very early stages of planning, we knew which services mapped best to meet the requirements of the NBA. Jesse, sure, um. So with a project like this, um, even the best decisions may change, and there will be many failures along the way, and that's perfectly OK, that's fine. What was the expression you used before? Yeah, it was also, you know, saying you can't, you can't, uh, miss a shot you don't take, so you know, basketball, yeah, exactly. So get it working, scale up the resources you need, and work on cost optimizations and deploying the right level of resources that you need later down the road. It's really don't let the. Object of perfect get in the way of good, so. Is that what made the integration successful. So Mike, yeah, so one of the key things, and, and we've touched on this, uh, quite a bit already, so probably a variation on a theme that you're hearing, but, um, we just had a really strong one team approach to the entire migration, just incredible collaboration between the NBA and AWS. We both really leaned in, uh, to, to make sure that this was going to be successful from the beginning. And that went back to before we had a single bit of code written before anything was ever running in AWS we were working through what the best way to architect these solutions and workloads for AWS would be. Uh, we looked through the best way to make sure that we had all the pipelines for analytics and logging built out and all that was designed and we had all the stakeholders aligned on how that was gonna work. And what that allowed us to do was jointly make sure that we had from planning through execution uh true alignment on goals and priorities, and that was absolutely key to making sure that this migration was successful. One of the mechanisms that we employed very frequently and as Mark alluded to earlier, uh, sometimes iteratively, was the AWS well architected framework, and the well architected framework is comprised of six pillars you can see on the screen there operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability. And for each of the workloads that we migrated to AWS, we applied a well architected framework review to that workload, and sometimes the review was focused on maybe one of the pillars like security, other times it was focused on multiple pillars like reliability or sustainability. And for some workloads we're really deeply focused on cost cost optimization because we knew that was an area where there's a great area or a great potential for improvement for that given workload. Mark, how about you tell us about automation? Yeah, I mean, I think this one's self-explanatory, you know, everywhere. Just automate everywhere, you know, use the tools you see ICD everywhere. You gotta, you gotta think that from the beginning. You have to identify those opportunities. If not, you're gonna be in the manual work, the toil, if you know, um, and that's not a place you wanna be. So think about those opportunities and where you can go and think through the pipeline, think coming through the build process and making sure that you automate those as much as possible. So that's, that's on the automation side. On the other side of it is you gotta think scale. So as you're thinking across the services, you know, we flashed up there a little bit earlier, all the different AWS services, you know, when you're thinking of the connectivity that's happening through all your, your, your, your, your logging and analytics, you know, quotas, for example, when you're about to hit a quota, do you have, the right you know, scaling alerts that are happening, do you have the right scale triggers in place for the. Service you're using, do you understand what the scale trigger and how long it takes and so spending time in defining those and making sure those triggers are effective will get you into a highly scalable environment. That's it. Thanks Mark. So for again for a project like this, alignment, communication, collaboration, transparency are key. Um, during the course of the project, specific to our internal teams, we conducted regular team syncs. This helped ensure and maintain momentum and also helped us quickly resolve issues along the way. And Lead into key takeaways next, yeah. So you know some of the key takeaways that we wanna make sure you, you know, take home with you today is leverage AWS. I know you hear that all the time, but leverage them. Use the well architected framework. It will help you, you know, work out bad decisions, spend the upfront time. Think about your tooling and how to automate it. You have to use those native services effectively. Just don't use them. Really think about how to automate through the native tools, you know, we talked about IPA. We talked about cloud WAN, AWS config. You really have to think that the security tools, and then when you're thinking of your scalability, understand the quotas, the triggers that you need in place to make sure those things scale it effectively. The more you do in that space and invest time. The more successful you're going to be. So empowering the teams, especially across 15 disparate over 15 disparate technology teams was really key, empowering those teams to take the reins, help get the project over the finish line, trusting your leads to make the right decisions, um, defining clear roles, it really helped accelerate our innovation and accelerate our, our, our delivery timeline. So another key aspect, um, yeah, I just wanna add to this, I mean. It's not an understatement to say you really You know Matt even said trust and verify, but the trust part is probably the more important part because when you have as many teams working on the deployment and execution that we had, I think it was 15+ different work streams happening to execute. You have to trust everybody's working towards the objective. You have to make sure everybody understands the objective. The only way to get there is to make sure you're giving them autonomy and trusting them to deliver when things go wrong, and they will go wrong, it's how you handle the wrong that makes sure the teams are still empowered to go forward, and it's such a critical thing how you lead from the front in in those critical moments going to really define the execution of your project. Uh, Jesse touched on this, uh, a little bit earlier, but progress over perfection, um, you know, don't let done, don't let perfect get in the way of done. Uh, I had a, uh, an old manager who had this huge poster, uh, up on his, his wall in his office that done is better than perfect, uh, and that, that's, that's true, right? Um, you can't get stuck and mired down in analysis paralysis trying to get to the perfect solution when sometimes a good enough solution will get you there, um. And by doing so, you know, you have your team, you give your team the ability to adapt and to continuously improve and iterate over a solution to get it to closer and closer to perfect. Uh, at Amazon we have a concept called one-way doors versus two-way doors. And a one a one way door decision is a decision that you walk through and you really can't easily turn back and fix it. So um if we were to choose, you know, a given service that had a very distinct set of criteria, we wouldn't be able to change it very easily. A two-way door is one that you can make the decision. But it's relatively low impact to go back and change that decision if if you find that your initial decision was not correct, um, and a great example of this was when we were going through the exercise of determining uh memory DB as a solution. So um we'd already decided that probably manage Reddis was not the right way to go, and at that point it became a decision as to what type of key value store we want to look at. And we were looking at Dynamo DB and memory DB at the same time. Both, you know, highly performing key value stores, they have slightly different value propositions for sure, but based on the requirements that we had at the time, really either of them would have met the requirements. But the decision to go with memory memory DB because. Of the lower latency ended up working out and you know we had zero production impacts as a result of it but that was a two-way door decision and had we chose Dynamo and found out that it didn't work, it wouldn't have been a heavy lift to then switch the code to utilize memory as a result. So we're a global international sports league, global direct to consumer business, scalability, reliability are, are sort of a tenement of, of our business. So leveraging AWS, our multi-region redundant architecture, uh, we were able to achieve those goals successfully as part of our season launch this year, so. You know, on the operation side there's always kind of like I did it one time I got it fixed, but there's a concept of repeatable operations and when you're in the process of designing, you know, the platform and you're scaling out especially on the infrastructure side and how you're thinking about things, you gotta think about repeatable operations and everything repeatable operations and how we do security, how we scale out, how we deploy. How we manage configs, how we manage IP space, and the more and more you get into that mindset of repeatable operations, the more sustainable you get. And for us that was a key objective we wanted to make sure that at the end of the day when we get into AWS our services are running that our services are in a repeatable operational framework and so I would highly, highly suggest that you spend a lot of time thinking about that operational bucket that a lot of people don't wanna spend time on it's not the, it's not the fun stuff it's not the innovation. It's not, but it is critical because if your team is spending time on operations they're not spending time on innovation so automate that workout. Yeah, and I'll just just highlight one area, Mark, where I think NBA truly has a best in class solution is what you guys did with Control Tower and Account Factory. um, the way that you guys designed and implemented SCPs and the way that accounts are automatically created. You touched on IPA. I mean, you have different t-shirt sizes for different IP ranges. It's, it's truly a best in class solution, uh, and as a result of the fact that we spent so much time on the front end thinking through what that had to look like. Um, the last thing, you know, is to build for the future, and this actually kind of harkens back to where we started with uh go slow to go fast. Really focusing on the well architected framework reviews, ensuring that there's a solid foundation architecturally, not just from an account structure, but for all of the applications that are getting deployed in those accounts, all the connective tissue through things like Cloud Win, really thinking through all of those things ahead of time before you get to. Point of deployment is key, and it allowed us to very quickly achieve this migration, but it also is going to allow us to innovate in the future. And so when we get to those next innovative workloads and how those get deployed and how those rapidly scale up and rapidly scale down actually because that's another important part of thinking about scaling, the fact that we've really thought through all of this and we know that we've got a solid foundation that's built for the future, I think is going to lead us to that success. So with that, now you know where to go watch the game. And if you don't know where to go to watch the game, NBA.com, click on the game and watch now, and we'll take you to the right place. And also make sure that you check out the uh NBA AWS um cloud, I'm sorry, not cloud, excuse me, Play Finder experience uh in the back there. It's really, really cool. Uh, so with that, are there any questions?