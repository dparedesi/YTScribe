---
video_id: CepG9H-aFLk
video_url: https://www.youtube.com/watch?v=CepG9H-aFLk
is_generated: False
is_translatable: True
---

Welcome. I hope you're having a great reinvent. My name is Brian Zambrano. I am a senior deep learning architect at AWS, and if you're wondering why a deep learning architect is talking to you, it's because I come from a background of development. So before this, I was a, a specialist, a serviceless specialist solutions architect, and a regular account solutions architect before that. I come from a long history of building applications, so today we're gonna be talking about, uh, building real-time applications at scale and with me here today is my colleague over here who'll be talking to you in a bit named Kim Kim Went, uh, so we're really happy to, to be talking to y'all and let's get into it. So If I threw this out there, building applications. What's the first thing that comes to your mind? Building applications is what? Easy, hard, challenging, complicated. I think even in today's world of GN AI things are still kind of complicated. I mean, building a real-time, uh, an application in general, you've got to deal with monitoring your application logic, databases, caching. There's a lot going on when we're building any kind of an application today. So now what happens if we add in something else, so building a real-time application. What does that mean? A real-time application is something where something happens and we're gonna produce some event or or push some data out to the other, another user in real time or near real time. So what is that? That's even harder, right? Again, even with the tools that we have today, this, this adds additional complexity that you have to deal with. So what about now if we're adding another component to this? Building a real-time application for millions of users is what? It's really hard. There's a lot going on that you have to consider here. So you're gonna be the scared cat trying to figure out what do we need to do, what do I need to do in order for my business to succeed when we're dealing with a real-time application and millions or thousands and thousands of users. So we're gonna go through a lot of that today and how you can do that and take that back to your organizations and be successful. So, to get started, we're gonna do this in real time. So let's play a little trivia app. So this is the time where you all get to pull out your phones or your laptops, scan this QR code, and you are gonna end up at our trivia application that Kim and I built. So I'm gonna swap over to here. And I'm gonna be running an admin so we're gonna play 80 bus trivia now, all right, so I'm gonna come over and do you, do you guys need the uh. The QR code, there you go. So while you're doing that. I'm gonna load it up on my side. Does everyone have it? All right, I'll give you guys a couple more seconds. Are we good? Yep, OK. OK, so this is gonna be AWS trivia, so you should have it on your phone. If you click the link that you on the landing page that you, you, you landed on, uh, you'll be in a, in a spa a state where it says waiting for the game to start. So does everyone see that waiting for your thumbs up if I see that. OK, great. So let's play, um. These are kind of hard questions, and for that you can blame Kim or actually Kiro. She, she did a lot of these with, with Kiro, uh, using G G AI to come up with the questions. OK, so let's start the, let's start the game. Which Amazon bedrock model provider is known for highly efficient long context processing? So I see a bunch of answers coming in. The answer is uh A, all right. We'll go to the next one. What does Amazon Sage Maker Pipelines provide? All right, CICD for ML workloads. So you'll notice here, you'll see that the leaderboard is changing, on the bottom right we're getting the answers coming in, streaming as you're all clicking buttons. Let's go to the next one. Which Amazon Bedrock feature supports multi-turn conversations? 2 more seconds. Knowledge bases, nicely done. What command launches hero in interactive chat mode? Kiro CLI chance is the right answer. Told you these are kind of tricky. Which StageMaker feature provides granular hardware profiling insights? And we see all the answers coming in over there on the bottom right, which is really fun. Profiler I'm gonna make this one notch bigger. Next question, which sage maker feature helps reduce foundational model training times by up to 40%? Hyperpod. Alright, our first place is at 274 points, so there's 10 questions, so we've just got about 3 or 4 more. What capability does Qiro have for AWS resource management? Full AWS CLI integration. OK, last couple. Which Amazon Bedrock capability allows models to take actions and call APIs? Agents, yeah, hopefully people got that one because agents are the name of the game now. 2 more. What type of evaluation does Amazon Bedrock model evaluation support? Both automatic and human evaluations. All right, last question. What can Qro do with local file system operations? Read and write files. Alright, well, congratulations for playing ADBs trivia. You should have something on your screen that gives you your, your, your username is actually at the very bottom of that, and it's gonna give you your your, your total score. Uh, so if you are user 548, this one over here, congratulations, you, you, you're in first place. Uh, so if you guys wanna take a screenshot of that and, and, and claim your first or second or third place prize, which is just a pat on the back, feel free to do so. Uh, but hopefully that was fun and a good way to kind of kick this whole thing off. OK. So that was a real-time application. So what are some other examples of a real-time application? So we're here in Las Vegas. Um, you might have noticed some, you know, you're using a ride sharing app. So the location of the, of, of the rides that are going on, um, that's an example of a real-time data that is being pushed all over the place. Some other examples would be, um, sports scores. So I happen to be a a Denver Nuggets fan. So whenever the Denver Nuggets are playing, I see a notification on my watch from Alexis that giving me. The game is starting, the score, halftime score, things like that, um, price changes, um, betting odds, updates, things like that. Gaming is another popular example of a real-time application. So these are, these applications, applications are all over the place all around us today. Um, there's also different versions of this which are collaborative real-time applications. So look at the one I, I mentioned earlier with ride sharing. So we all, if we're looking at a ride sharing application, we all together see the, the, the locations of the, the rides at the same time in real time. Um, some other ones would be, can I mention a multi-turn game application. So we're all playing the same game. We're all seeing the same data move in tandem together. So if your organization came to you and asked you to build this, where would you start? How would you start thinking about this process of, of building this type of an application where data is being shared in real time across many, many users? Well, most of us, myself included, have used polling. Who here has used polling in the past when they're building some sort of an application? You, you need to get updates to your, to your users. Yeah, most of us, and there's no harm in doing this. There's no problem with using polling. Um, it's fine to get started with, with this, and the way it works is that the front end or the application is gonna keep going back to the server over and over again saying. Is there an update? No, there's not an update. How about now? Is there an update now? And so this, this pattern goes on over and over again, and eventually you're gonna get that there is some new data available like it's pulled into the front-end application or the application, and then you, you move on. You, you, you, you can present that information to your user. So while this is not inherently the wrong way of doing things, it does break down at scale. You do waste compute cycles. You waste network bandwidth, so it's fine to get started and is an easy thing to to use at the beginning, but eventually you're going to want to graduate to something that is a little bit more sophisticated and more efficient as your application and your user base grows. And so for that, a better solution is bidirectional communication, and for that we're gonna leverage web sockets. And if you're not familiar with that, uh, the way it works is that the client is gonna make a request to the server, and the server is gonna respond with an acknowledgment saying like I have I've acknowledged your, your request for a connection, and at that point the client and the server. Have established this connection and both of them can push data back and forth between those that that connection and it's persistent, so hence the term bidirectional, the client can push data to the server and the server can push data to the client. So again, the challenge now is that we're adding scale so this can become more and more complex as your application grows. So the first thing is that everyone who's connected, so all of you in the audience when you were connecting to our, our, our trivia application, we have to know who you are. Each one of you had a unique connection. To our back end system and so if you're building this on your own, you're gonna need to keep track of that. So who is the user? Who's this this user in the front row who's connected to the back end? How do I know that that user has, has sent me this specific, uh, answer to a question? So you have to keep track of all that. The next thing is something known as fan out, so that is. As you noticed when we were playing the trivia app, the admins, the admin page was showing all of the updates coming from all of you users. So as you were sending that to me, that was coming into the, to the admin interface, as I'm sending things to you, I'm fanning out the questions so that all of you receive the next question. So how do you do that? There's probably, you know, maybe, maybe 150 of us here in the audience today. So how do you do that with hundreds, thousands, 10s of thousands of users where one message is now broadcast out to many, many users? So doing this on your own, you're gonna have to keep track of that. How do you do fan out? And then along with that is as the application grows, as you're supporting more and more users, how do you scale that? So maybe you start off with 100 users, but then the next week you have 1000, and then after that you have 10,000. So how do you scale the back end infrastructure, the servers to handle all of this? So the bottom line is that over over time as your app evolves as the skill increases, a lot of the work that you would need to do managing this yourself would be what we consider undifferentiated heavy lifting. So this is not your core business, but it's things that you have to keep track of when you're building your application, um, again, keeping track of scale. OK, so we're gonna go through a lot of these, these challenges and give you some solutions. Uh, so the agenda is, uh, going through this bidirectional communication and how you can handle that and solve for that with ADbus, uh, app sync events. So that's gonna be the core of the technology stack that we're using that powers our trivia app. So we're gonna go through how that works. The other thing is how to manage your back end, how to design your back end for scale. So I think considerations and solutions for for challenges there. We'll touch on application hosting. So if you're doing front end application hosting, we'll talk about a solution there, and then finally wrap it up with some monitoring and observability and a final wrap up. So with that, I'm gonna hand it over to Kim, who's gonna get into App sync events. Awesome thanks so much Brian. uh, so you've all have heard about the challenges with building these real-time applications. uh, Brian talked a little bit about how building web sockets can be pretty complex, uh, but bidirectional communication seems to be the way that we can make these real-time applications. Work better. So, so how do we solve that with one of our AWS services? Uh, so who here has heard of AWS App Sync events? Raise your hand. OK, we've got some hands up. Uh, so, uh, this might be a little bit of a review for you folks, but for the folks who haven't heard about AppSync events, let's talk a little bit about it. Um, so AWS App Sync Events is a fully managed pub sub service. Its core competency is making it easy to build an API that can provide that real-time communication between publishers and subscribers. We do this by reducing the. Operational overhead of managing and operating web sockets at scale we provide things that help you do authorization for your APIs, a way for you to inject business logic into your API when you're publishing and subscribing, and we do this at a very, uh, low total cost of ownership for you when you're building these APIs. So let's talk a little bit about how it actually works. So your publishers, those are on the left-hand side of the screen, these might be your application clients, right? Your mobile app that you were just using to play our trivia game is a good example of a client that might be publishing information. But this could also be back-end systems like a lambda function or an Amazon event bridge event that's coming through, publishing information or triggering a publish. On the right-hand side, these are your subscribers. These are the entities that are interested in the information that you're publishing. These can also be application clients, again, like the mobile device that you were using to receive the questions in real time. But these could also be back-end systems as well, maybe a container that's listening for information over that web socket connection to do some processing based on the events that it receives. All of this behind the scenes is managed through WebSocket connections. So AWS AppSync events takes away the heavy lifting of managing that WebSocket infrastructure and provides built-in connection management out of the box. What that really means is that AppSync Events is tracking all of the connections that are coming through to the API and keeping track of which connect connection is interested in which information. And additionally, it also handles all of the fan out capabilities, right? So all of the questions that you were getting is a really good example of a fan out process. We were publishing once and you all were receiving that. Appsync events handles figuring out who needs to get that information when we send it over a publish operation. At the heart of this is the event API. This is what you configure, uh, to leverage AWS App sync events, and one other important thing to kind of connect your publishers and subscribers together is this idea of a name space. Um, we're gonna talk a little bit more about that next, but think of this as kind of that segmentation of information and events. So what is, what is a channel name space? Let's kind of double click on this a little bit. So, while you were playing the game, we were using different channel name spaces to support different parts of the game. So, the first part of your channel name space is the name space. This is the highest level of cardinality that segments different events that you might send through your event API. So before Brian was talking about sports, um, he mentioned, I think the, the Denver Nuggets for, and I think that's basketball if I'm remembering correctly, um, I'm definitely a big football fan and so we might have an API that supports a bunch of different sports and the highest level of cardinality to kind of split those might be. The league, so it could be the NFL or the MLB or the NHL, right, the highest level of cardinality that can split your events for our use case, we have a name space called Game that allows us to handle different joint operations as you're connecting and interfacing with the game itself. The second portion of this channel name space, these are the channel segments. And what's really interesting about these is that these are dynamically created, so you don't actually have to predefine these channel segments when you're thinking about what I should include in my channel name spaces. The only thing that you define up front is that top level name space to kind of. Organize your events. The channel segments then are created as somebody publishes to it, or somebody establishes a subscription to it, and so it gives you a lot of flexibility in what information you can send and at what level of segmentation. So let's dive a little bit deeper into kind of how this works and tie it into our trivia game that y'all just played. So our publishers um are the application clients for some of our use cases, right? So you had your mobile phones, and you were actually publishing your answers to an answer name space. That answer name space then had a segment that was the game ID, right? That RIV 2025, that helped us segment the different games that we might play. And you published over a WebSocket connection. So, you, when you opened up the Trivia application, you created a WebSocket connection behind the scenes, and you're publishing information over that WebSocket connection. But we also have cases in our trivia app where we might be publishing from back-end systems, so AWS lambda functions, some of you might know, are ephemeral environments, so it doesn't really make a whole lot of sense to open up a web socket connection from within a lambda function and then send information through it because that's only gonna be open for about 15 minutes at most, probably less. And so for that use case when we're publishing the. Questions we're actually doing so via HTTP post operations, uh, and this is a really unique differentiator I think in A sync events is that you can do both. So for the cases where you need that web socket connection open, like for an application client, like a mobile device, you can publish over that same web socket connection, but for cases where you have back end systems, you might wanna just publish over HTTP because it's an ephemeral environment. But then for our subscriptions, so again, our clients that you guys were using, you'll always subscribe and get updates over a WebSocket connection. That's how we get those updates in real time. So now let's dive in a little bit more to how we built our game, uh, and I know with this audience we're clearly not scaling to millions, but what we're gonna try to do is talk you through how we built this game, and we thought about, well, what if we had, you know, thousands of people playing our game? Like how would we build this? Would it scale? So I want you to keep that in mind as we're going through. There's 3 main portions to our game. The admin side is pretty boring. Um, we actually just used rest APIs to do it. There wasn't really a whole lot of real-time stuff that we needed to do from an admin perspective and so we're gonna focus more on joining the game and then I'll pass it back to Brian to talk about playing the game a little bit later. So when we thought about well what does it mean to scale the join process there were kind of 4 main areas that we thought about for when we were designing this for scale. So the first one was, hm, well how many people might try to join our game. At the same time, right, in this audience we probably have 100, 150 folks, but I feel like trivia is something people really like, and so we're hoping that, you know, we might get 10,000 people try to join our trivia game. How do we handle that if everybody tries to join all at once? What happens if a user can't join the game initially? What does that experience look like for them? Are they gonna be frustrated? Are they gonna have to keep retrying? What does that look like? How should we associate a user to a particular game, right? How do we know that people are joining the reinvent 2025 game versus another game that we have? And then how do we identify users, especially in an environment where we don't want everybody to create a user account to play our game. So these are some of the skill considerations that we thought of when we tried to design this trivia application. So the first part of this process is talking about OK how do we get folks into our game and so this is our kind of simplistic architecture that we thought about for what it looks like to get included into our game so you have your client application you're opening it on your phone. The first thing you need to do is establish that web socket connection so that you can get the questions and answer the questions we probably. We want to persist that information as well into a data store so that we can keep track for doing things like scores and leaderboards and so this was the general flow that we came up with to start, um, and this, you know, this worked pretty well, but then we thought about, well, again, what if our game really takes off? What if we get 10,000 people that wanna play it? How can we scale this to make sure that everybody is able to connect and join the game? Um, that really sounds like the thundering herd problem, right, where you have a lot of users try to join something all at once and you have to scale to support that load. And that's what we kind of came up against, uh, so we thought about those 10,000 users and what that experience would look like if they tried to establish that web socket connection to our AppSync event API. Uh, and one really important thing to note, um, and this is true for all of our AWS services, is that services have quotas behind the scenes that kind of help us manage all of our users that use the services, and one very important one for A sync events is what's called the rate of connection requests, um, and by default this is 2000 per second in each supported AWS region. And so we thought, OK, that's the default limit. It is adjustable, but we wanted to kind of work within kind of that base starting range for our trivia app. So we said, OK, if that is the quota that we're working within 2000 connection requests per second, how can we architect to make sure that we handle the case for those other 8000 users? Um, we don't want our ASync event API to fall over. We don't want our users to get frustrated because they can't join the game. So how do we build this in a way that will scale very well? And so we thought about, well, we have other services that can do this really well like API Gateway. API Gateway has built-in rate limiting through usage plans where you can effectively define how many requests to let in to a particular route in your API or even at the API level and how many you can return with a 429 throttling error to kind of control the rate at which users can use your API. So we thought, OK. If API gateway has that built in, maybe we can use that as a gating mechanism to kind of help us control the rate of requests for connections to our A sync event API. So in this flow, the 1st 2000 users hit that API and they get a 200 response back, and they can hit on establish that web socket connection. The remaining 8000 users that try to join are gonna get that 429 back from API gateway, but what's really transparent to the user behind the scenes is the fact that your application client has built-in retry logic and exponential back off. So that's a design choice that Brian and I made in the mobile application that you guys used to play the game is it automatically will retry, uh, and do that exponential back off. So eventually the remaining 8000 of you will be able to join the game. Um, and this worked really well for us and again it's super transparent and it is the best practice when you're designing for that scale. And so this really became our player entry control, so we had the application client hit an HTTP get route with our API gateway that also allowed us to validate the game ID, so it kind of doubled as player entry control, but then also making sure that you were joining a valid game ID and one that, you know, we hadn't created. Um, we fetched and validated that that game ID existed in Dynamo DB. Uh, and that allowed us to then also apply that rate limiting on the API request. So then once you receive that 200 response back, you're able to establish the web socket connection to ASync events and off you go playing your trivia game. So a couple other things came into our minds when we thought about, you know, designing this for scale. Um, one of those was, well, validating the game ID is a super read heavy operation, especially if you're all validating the same game ID, uh, and so we use API gateway. Cashing to essentially cache the validation response so that we're not constantly reaching back out to Dynamo DB to say hey, is this a valid game ID? hey, is this a valid game ID? So that was a really good scaling mechanism and one that is very beneficial to use for those read heavy operations on your APIs. The second thing that we did, um, and you'll see it here, we use the first class service integration between API Gateway and Dynamo DB. Um, if you're not familiar, API Gateway can directly connect to a lot of AWS services without the need for any compute in the middle, so we didn't use a lambda to do that get item operation from Dynamo. DB we just use some request mapping templates, uh, to essentially format our requests to do that operation directly to Dynamo DB that saved us compute. It saved us on cost and it saved us on potential cold starts for when we're just starting up a new game. So that's a really good best practice for designing, uh, that REST API integration. Uh, and then the last thing that we did again to mitigate that thundering herd problem was we used API gateway rate limiting, uh, with our usage plan to make sure that you couldn't go above that 2000 limit. So 2000 might be pretty low, and again we kind of worked within the default quotas, but this again is a really good best practice to kind of control that rate of entry into your applications and using your APIs. So essentially what that then looked like after we went through our player entry control is you're able to establish that webSocket connection and you were able to subscribe to all of the relevant name spaces and channels that are needed to play the game, uh. One of the most interesting parts, and I'm gonna talk a little bit about this is, so you subscribe, you establish that connection, how are we essentially tracking who's joining the game, right? Again, I mentioned this as one of our skill considerations. How are we identifying users and how are we making sure that we're able to track them for their score and leaderboard updates throughout the entirety of the game. That to me sounds like some business logic, right? We wanna be able to track and maintain who's joining the game as they're subscribing to the different name spaces. This is a really great use case for. A little bit of code uh and what's called an event handler in A sync events and so effectively what this looks like is when a user subscribes to our game name space for a particular game ID we run a little bit of business logic to effectively capture their user ID which we're including in their headers. Uh, and I'll talk about why that is in a second, and we're persisting that to Dynamo DB all as part of the subscribe operation, so there's no additional, you know, API call that's happening behind the scenes to persist that user ID. We're just doing that as part of the subscription, so it happens really seamlessly for you as a player. Uh, we automatically capture that user ID and persist it. So I'll come back to kind of why we're persisting or passing the user ID in the header. So we wanted you all to be able to play this game very seamlessly. You probably have come across things where you have to create accounts and do verification codes, and that all takes a lot of time. And so for really making this a simple game to play. We decided to just generate random user IDs on the client side and pass those uh as part of the header to identify each user individually. Now ideally you would probably want a little bit more sophisticated auth, especially if you want to track player statistics, but this is something that worked really well for us and allowed us to capture those user IDs and persist them. So this event handler, it looks a lot like something that you might run in a lambda function, um, but interestingly, these event handlers are not lambda functions. Event handlers and A sync events are pieces of code that you can run to perform business logic. They run in what's called an ASync JS environment. This is a lightweight JavaScript environment that has a subset of JavaScript capabilities that allows you to do. Things like event enrichment, validation on subscription, persisting data into different data sources, uh, and it makes it really simple to do that all while making sure you're not introducing additional compute and potential latency into your API operations. So again, this is not a lambda function. It looks like a lambda function, but it's not a lambda function. It is an app sync JSFA handler, and they're really, really efficient for running this type of business logic. One thing to consider though from a scaling standpoint is well how do I make sure that I'm able to run all of my subscriptions and and not hit any limits from a scale perspective. Event handlers uh use request tokens in A sync. So let's talk a little bit about request tokens and kind of how that factors into scale. So, for every request that you make to your AppSync event API, whether it be a connection, a publish, or a subscription, those are all requests that consume tokens. When you make a request, you get a login cloudwatch logs, provided you have them enabled on your API, and it actually will tell you how many tokens that request consumed. And so this is a best practice as you're building and designing these APIs to test and see how many requests on average, am I consuming for the different operations. The reason that this is important is because again, there's a quota that we need to consider when we're designing. It's very similar to the rate of connection requests, but this one is the rate of request tokens. Um, it's 2000 as well per second per region. Um, generally speaking, when designing this for scale, most, uh, requests only consume about one token. This can vary though depending on how complex your business logic is. So if you're doing a lot of complex operations inside of your event handler, this can change, um, but that's why it's so important to do that kind of validation during testing to figure out how many request tokens you're actually consuming for the different types of request operations. All right, so to kind of summarize, what are all the things that we need to consider when joining the game? So the first thing that we need to consider is using direct integrations with AppSync events and data sources. So when we're persisting user joint information, we were doing so via that event handler, right, that we just talked about. That event handler had a direct connection to a Dynamo DB table. So again, we didn't have to introduce additional layers of compute into that flow. AppSync Events supports a variety of different data source integrations from Dynamo DB to RDS databases that have the data API to OpenSearch, uh, Lambda, HTTP data sources. Uh, there's a handful of others, uh, but these are really good because again you're not introducing additional latency into that flow. Uh, additionally, we used Dynamo DB on demand capacity mode. Uh, Dynamo DB, if you're not familiar, has two different capacity modes on demand and provisioned. On-demand is really, really great for scaling, um, especially when we don't know what our load is gonna look like, um, and for this case we didn't really know how many users are gonna play our trivia game, and so that was a really great scaling mechanism for us to take advantage of. Uh, and then the last thing is again to use that built-in app sync JS environment, um, along with those helpful utilities, uh, to interact with Dynamo DB and do that lightweight business logic and processing. So that is joining the game. I'm gonna hand it back off to Brian to talk about playing the game. All right, thank you, Kim. OK. So Kim talked about now you're all in the game, so you're in the game, we have you, what happens or what happened when you're actually playing the game? So we're gonna go through, through that. So, first of all, I, the admin, I need to send you questions. So I need to send, get a question and broadcast out to all of you. So we'll talk through that, how that works. Next is that all of you need to send that back to me, the admin. So I need to get all of your answers back to me, run some logic to figure out if that was the right answer, calculate your score. And then you need to see your individual score, so you all had individual scores that were cumulative. So again, that's application logic that I run on my side, but I need to get that back out to you. And you don't wanna see that across all of your neighbors, right? I'm just wanna get that out to each one of you as a as an individual. Uh, and then finally you can see on my side the admin screen did have the cumulative leaderboard, so we have the top 55 users there. So let's go through how that looks, uh, so the first thing that we'll talk about is how me as the admin can send all of you the questions, and these are the different channel name spaces and the components that we're using here, so we're gonna look at the first one. So in the first one. I click the button, I click start game, or I click the next question, uh, from my admin panel. That actually goes to a lambda function, and the lambda function just runs a little bit of logic, not much. It's gonna grab the question from Dynamo DB, create some little payload, and then publish out to this channel name space, and the channel name space is slash question. And then the game ID which was RIV 2025 and of course you know we are using an API gateway in here the the back end, the front end application rather does just send a regular HTTP request to API gateway. API gateway then invokes the lambda function, and the lambda function is executing that publish that publish API to our channel name space. And what the published payload looks like is what I said earlier, which is the question, so it's the text, the question ID, and then you have all of those four answers. So on your screen you saw the 4 answers to choose from. So we're just getting that again from Dynamo DB, doing a little bit of formatting and broadcasting that out. Now the nice thing here going back to scale is that here we had 100, maybe 150 people. The nice thing is that if we had 1000 people or even 10,000 people, I don't have to change anything. AppSync Events is gonna handle that broadcasting for me. There's nothing extra that I need to do. It's got me there. It's gonna, it's gonna, it's gonna handle all that for me. So it's a really, really nice feature if you're doing this yourself with, you know, homegrown web sockets, you're gonna have to deal with that. You're gonna have to handle how can I scale this out as my application grows or as I need to support more and more users. So this is one of my favorite parts of, of Appstic events is just that automatic broadcasting. OK. Uh, how does authorization work? So Kim mentioned, uh, that, you know, here we want to, we, we, we want this to be really, really easy. So there is no login authentication. So we kind of fake it in some ways where we just create a random user ID, um, but still we don't wanna have this completely open to the world. So how does this work? We use two different types of authorization in this in our application. So the first one is uh a traditional IAM role. So this is what most people are familiar with. That's, this is when you have the service to service communication. So in this case, we authorize our lambda function, publish access to our app sync event channel name space. So that is this lambda function is allowed to call publish on ASync events. So that's the authorization method here. So if you somehow got a hold of, of my credentials and uh try to to to to publish to this, um, you wouldn't be allowed to, right? So we, we, we trim this down really small and have least privileged access so that only the lambda function has access to, to publish to this, uh, channel name space. On the other side, who is allowed to subscribe to this channel name space? And so for that we're using an API key, and an API key is something that we created within AppSync events that's actually embedded into the front-end application, so you all have access to subscribe to that. So if I had, if I was trying to open up a website connection to our channel name space without that API token, I wouldn't be allowed to. So it's, it's somewhat coarse in that, in the sense that anyone here can use it, but again, because we're using essentially anonymous users, all of you, this was the route that we took, and it does work out quite well. So how does authorization work with ASync events? So there's something known as a default authorization method. So A couple, couple points here. One is there is a, a default method to subs to create the connection to the A sync events, uh, and for that you can use either an IAM role or an API key, like I was mentioning. There's also a publish default authorizer and a subscribe uh and a subscribe default authorizer and so with this, the default authorization method for both of those connections for both those those actions rather is an IAM role. And you might be thinking that doesn't really make sense because how do you use an IM roll if you're subscribing. So the nice thing here is that you can actually override this on a per name space basis, which I'll show next. So here we've got our 4 channel name spaces. And the authorization scheme works where we have Aabus lambda publishing to the 1st 3 channel name spaces, so publishing questions, scores, and then the, the leader board. And again for that we're using the IAM rule. The lambda function is allowed to publish to those channel name spaces. On the subscription side. We're using API keys, like I mentioned, so all of you are subscribing to these channel name spaces or the admin interfaces is using the API key. You're all using API keys to subscribe, as is our admin interface. So API keys on that side for the for the subscriptions. You are also also publishing you, the consumers or the the the the players are publishing answers to our channel. And for that we also use the API key. Now you'll note here that no one can subscribe to your answer, so if each one of you is publishing an answer, we wanna prevent someone else from being able to subscribe to that, and snooping on your answers and cheating. So if you think back to what I had earlier, where the default authorization method for the answers name space was an IAM rule, but we overwrite it here with a with an API key for the publication, but nobody can subscribe to it. The only way to subscribe to it would be with an IAM rule, and none of you have IAM rules, so there's no possibility of cheating here. And you know I'm talking about two different authorization methods, IAM rolls and API keys, but this is not, these are not the only ways that you can do this. So you can use a Cognito user pool for this, uh, custom lambda authorizer, um, and, uh, one more which is the open API, uh, authorization method. So you have those options available to you if these don't suit your needs. OK. So now I've explained how I'm sending all of those answers and broadcasting, sorry, the, the questions and broadcasting those all out to you. So what happens when you need to, uh, to, when you answer a question and send it back to us? So there's our diagram. This is the next section, is you are all publishing to the answer name space. So answer and then then our game ID. So you're literally sending the front-end application is sending the uh a web socket, uh, public publish to that name space. So what happens? So behind the scenes, what's happening is that we have connected a lambda function. To that that that channel name space remember Kim was talking about these uh the um the app sync event handlers so now we're gonna be back into the world of lambda because this thing is gonna need to do a run a little bit of application logic and what it's gonna do is receive the payload from each one of you. It's gonna do a little bit of validation logic, so it knows the question that's being answered, it knows your answer, and we need to figure out, is this right or wrong. So if it's wrong, you don't get any points. If it's right, we're gonna go and calculate your score. So that's what that that highlight is there, which is the the the validation logic like is this correct? We're in a little bit of application logic like I said, and then after that we're gonna send back something to you which gives you your cumulative score, whether you were right or wrong, and so that's what's highlighted here. So we run that application logic, score you, and then the lambda function is now publishing back out to a new channel name space which is specific for your users. So that's why each one of you was getting a specific or a unique response back with your score, whether you were right or wrong, how many points you got, and things like that. So again, there are no event handlers here in the AppSync with from the AppSync event world. This is a regular lambda function that we're using here. And this one happens to be running a an asynchronous lambda function because here if you think about it, you know, asynchronous response is I'm gonna send something and wait for the response to come back to me, but in this case we don't care about the response because we're in the WebSockets world, right? We're using appsy events, so the publication goes out, the, the, your, your, your message goes out to us with your answer. That's an, it's not waiting for for the response back from AppSync events. Uh, we get that message, do our work, and then our communication channel back to you is another publication over this channel name space. So again, we're leveraging the asynchronous, uh, asynchronous version of a lambda function. OK, I'm gonna hand it back over to Kim to go over the next bits of playing the game. Awesome thanks Brian. Alright, so you've sent your answers we validated your answers, and now we gotta score you. So let's talk about how scores go out, um, so we're focusing on kind of this area of our game now. So one really critical thing because I know if you're like me you don't want other people to see if you got an answer wrong like I'm really protective of the answers I get, especially when they're not right um and so you don't want other people to be able to subscribe to your scores to see what your score is and so we're able to. Actually do a level of enforcement on subscription. So when you subscribe to the scores name space, we actually embed your unique user ID into the channel segment that you can see on the left hand side. Once we do that in the event handler, we can actually enforce that you are only able to subscribe to a channel segment that contains your user ID, right? So we look at the headers, we get your user ID, and we validate that those match, and that's that little bit of logic right here. If they don't match, we essentially return a result that says you're unauthorized, you can't establish the subscription. And this is really powerful if you think about a use case where you only want users to subscribe to notifications that are designed and destined for them. This is how you enforce it, um, so this little bit of code in the event handler is a really powerful capability for kind of enforcing that level of of authorization on subscription. And then to actually publish out the scores, this is also happening in that asynchronous lambda function that Brian talked about where we validate the answer we then just publish out the score update to all the individual users. Um, one thing that I wanna highlight, um, is that we are using, um. Async again for this purpose because we're doing a lot of logic in here and it's gonna take a little bit of time uh and for that it really makes sense to use a lambda function uh we're writing to Dynamo, we're fetching from Dynamo, we're publishing over another name space. These are all additional operations that we need to do in a lambda function where we can't do all of that inside of an event handler, and that's really one of the differentiators between the two, and that's that little bit of code down here. So then, everybody needs to be able to see the leader board on the admin view so you can kind of see where you are in the state of the game. Uh, and so for this, we take a little bit of a similar approach, but we introduce an additional service, or a part of our service, which is Amazon Dynamo DB streams. And so, effectively what happens here is when we write the scores to the Dynamo DB table, we are actually enabling a Dynamo DB stream to do change data capture to get updates to that Dynamo DB table. The lambda function that we have here is consuming from that Dynamo DB stream in batch. There's a lot of configurations that you can do on that event source mapping between the Dynamo DB stream and the lambda function, and so we're able to process a bunch of those batch records all at once to reduce the number of times our lambda needs to be invoked. Inside of that lambda function we're essentially doing a query to get the top 10 scores and publish those out once to our leaderboard name space. We're doing this effectively to reduce the number of leaderboard publish operations that we have. Um, we thought initially about publishing every single leaderboard change. That was quite a lot, especially as we have. Many, many, many users playing the game and so we decided to reduce that down to just getting the top 10, uh, so this is why you see the code, uh, that you do here, um, but we're still publishing out to our leaderboard name space from within a lambda function and so, um, this is very similar to what you've seen before where we're publishing out scores, uh, and we're publishing out our questions, uh, for the rest of our game. So we've talked about a lot of different things for joining the game and playing the game, so let's kind of summarize all of the different things that we thought about when designing this for scale for the back end part of our application. So the first thing, and you've probably hopefully picked up on this as we've been going through the presentation, is we really focused on segmenting our channel name spaces by game function. This became really important because each part of our game serves a different purpose, right? Questions need to go out to you, need to be sent from the back end, answers need to come from you, sent to us, scores, leaderboard, and so on, and all of these things have different capabilities from an event handler perspective, from an authorization perspective, and so it was really important for us to design that level of segmentation at the channel name space level. That then enabled us to do use case driven authorization, right, so having IAM rules where it made sense, having API keys where it made sense, uh, and that is only possible by having that level of segmentation at the channel name space level. Additionally, we leveraged a lot of the great AWS A sync capabilities that come out of the box like message broadcasting, fan out, connection management, all that good stuff. We didn't really have to do a whole lot there. We kind of got that out of the box with the A sync events, um, but that's why we chose it. It, it scales very well when it comes to things like that, um, and that was one of the reasons why we, why we went with that service. One of the other things, I don't know if you caught it, hopefully some of you did, um, but in our async lambda function that's handling the answer logic and the score updates, we actually used, uh, power tools. How many of you have heard of power tools before? OK, great, I love it. Um, I'll have to tell the power tools team. They'll be super happy. Um, if you haven't heard of Power tools, definitely look it up after this session. It is one of the easiest things that you can do to integrate observability into your lambda functions. In this case we are using it for logging and sending metrics, but we're also using it because, uh, the Power tools library has really nice, uh, lambda decorators for different types of event sources, and they have one specifically designed for app sync events that allows us to handle the integration between. App sync events and the lambda function, um, a lot more seamlessly. Get nice typing if you're using TypeScript and then compile down a JavaScript, um, so definitely check that out. That was something that really helped us and again when you're designing for scale building that in is a necessity from a logging and metric standpoint, and Power tools just makes it all that more easy to do. And then finally, uh, async lambda invocations for those longer running processes. This is one of those best practices that might seem a little repetitive to some, but I talked to a lot of customers, uh, who are still using synchronous operations for everything, and I think async is really one of those things that when you're. Designing for scale, you really need to think about does the caller of my API need that response right away or can they wait? And especially for this application being it's driven by WebSockets, we're gonna have the updates sent anyway over a different channel and so using async was really, really powerful in that sense. So we talked a lot about the back end probably way too much and we didn't talk enough about the front end so we wanted to highlight a little bit about how we are hosting the application that y'all interacted with, uh, and talk about how that is designed for scale, um, so. I don't know about you. Hopefully some of y'all have tried to host like a single page application, uh, on AWS before. One of the things that always pops into my mind when I'm trying to host like a react application is, oh, just stick it in S3, uh, and I might front it with a cloud front distribution. This is a really simple way to get a single page app spun up on AWS. Um, it actually, uh, S3 actually has like a really nice, uh, hosting way to do this, uh, out of the box, um, but you probably wanna put Cloudfront in front of it to get that, uh, CDN capability. But then if you think about it, OK, how do I extend this, uh, and scale it out for like enterprise level, you're probably gonna wanna stick a web application firewall in front of it just to make sure that your application can't be DDoS. You do some level of control from who can access it, all that good stuff from a security standpoint. You probably will then also need to look at getting a certificate, especially if you wanna put a custom domain on that cloud front distribution. So you're gonna need to incorporate certificate manager to make sure that that URL can be accessed over um TLS or SSL and HTTPS. And then you're probably gonna need to use RA 53 or some domain domain name management system to register that domain and connect it up to your app. All of this is involved in hosting an application, and what started off really simple with S3 and Cloudfront now becomes a lot of operational overhead that you then have to manage and worry about and operate and monitor and all that stuff. And so there had to be an easier way, uh, and there is, uh, and that's AWS Amplify hosting. So AWS Amplify has a lot of components to it if you used it before. The one that we're specifically using in this trivia application is the hosting component, uh, and so amplify hosting does all of the things that you saw underneath. All for you, you can bring your own custom domains. You can connect up a web application firewall. You can host both single page applications and server side rendered applications with a variety of different frameworks. And so this was a really easy way to host our application and that is what we're using uh and what you interacted with when you're playing the game. I wanna spend a little bit of time talking about monitoring and observability because again when you're operating at scale there's a lot of things you need to look at and make sure are scaling properly and not falling over and so we wanted to highlight a couple of different metrics and things that we considered when we were designing uh this application and so there's a lot up here, uh, but a couple that I wanted to highlight are. Our AWS app sync events metrics, um, so these come out of the box. Uh, one that's really important is that connection request rate. So remember I mentioned this is one of those things that has a quota of 2000 requests per second. Um, so you wanna monitor how many users are trying to connect at the same time. Um, an important note I wanna highlight is that there's no. No limit on the number of actual connections you can have. It's just the rate at which they can connect and initiate those connection requests. You can also track, and it's really helpful to track the number of active connections that you have so you can see how many people are connected at any given time, also how many people are or how many clients are subscribed at any given time. There's a lot more when it comes to app sync events, but these are a couple that we wanted to highlight, uh, as really critical for AWS lambda functions since we have a few of those in our application, we definitely wanna take a look at the number of indications as well as our concurrent executions to make sure that we are within our limits. Um, those are also generally raisable from an account standpoint. And then we're using Dynamo DB like I mentioned in on demand mode and so we really wanted to also make sure that our read and write usage was kind of on par with what we expected and so these are some of the ones that we decided to take a look at uh and monitor within CloudWatch. As we're wrapping up here with a couple of minutes left, um, I know it's Tuesday. I feel like it's already been 4 days to reinvent. There's still 2 more days left, and so I wanted to plug a couple more sessions. One that we have tomorrow morning, um, with yours truly is a builder session, uh, focused on real-time applications. You'll actually be able to get hands-on with A sync events in this one. So definitely take a look, come to the wait line if you don't have anything scheduled. There's some other good ones like Serverless Espresso, where we are actually using App sync events to give you updates on your coffee order. Definitely check out this workshop or go see it in the expo hall or the training and certification lounge, and then who doesn't love best practices for serverless developers? Also wanted to leave you with a couple of resources. Uh, I'll give you a second if you wanna grab a picture of these, but this talk will be up on YouTube probably in the next couple of days. AWS App Sync events user guide, the Power tools documentation again, can't stress that one enough. Power tools is super easy to get integrated and really, really beneficial. And then Serverless land, which has a ton of useful content, a lot of sample code that you can take and leverage to implement some of these patterns, uh, definitely check those out. Thank you so much for sticking with us. Uh, at the end of Tuesday, for those of you who are sticking around, I might have a prize-ish for playing the game, so come see us after, um, but Brian and I will stick around if you have any questions and please complete the session survey. Thank you guys so much.