---
video_id: nXBqxnp5ybY
video_url: https://www.youtube.com/watch?v=nXBqxnp5ybY
title: AWS re:Invent 2025 - AWS Networking Fundamentals: Connect, secure and scale (NET208)
author: AWS Events
published_date: 2025-12-02
length_minutes: 58.63
views: 590
description: "Dive into AWS networking foundations, starting with the fundamentals of Amazon VPC in a single Region. Learn essential skills for IPv4 and IPv6 selection, subnetting, routing, DNS, and security before scaling to global, multi-Region architectures. In this session, explore various VPC connectivity methods, hybrid network integration, and secure traffic management techniques. Discover how to implement private remote access for cloud resources and optimize service-to-service communication while bui..."
keywords: AWS reInvent 2025
is_generated: False
is_translatable: True
---

Welcome to Reinvent 2025. Thank you for joining us for our session. And uh this is the first session that you have. So, thank you for uh coming in and I appreciate you giving us, uh, starting your day with us. Um, this is Net 208 AWS Networking Fundamentals, uh, Connect secure and scale. My name is Rohit Aswani. I'm a principal uh networking solutions architect within worldwide Public Sector at AWS and I'm excited to be joined by my colleague. Hey folks, my name's Dave Dirico. I'm a networking specialist technical account manager, which is a mouthful, but I'm part of our enterprise support team here at AWS. Thanks, Dave. So the agenda for today's session is we will start with global infrastructure, then we'll dive into the fundamentals of Amazon virtual private cloud. Once we understand those fundamentals, we will go into the different connectivity options. We'll cover internet connectivity, hybrid connectivity, application networking, your remote access connectivity. Uh, then we'll dive into the DNS piece of it, followed by how you can do traffic inspection with various types of firewalls on AWS, followed by how you can monitor and uh monitor your network along with the observability. Before we begin, this is a 200 level session uh designed to give you basic building blocks of the networking on AWS Cloud, and we expect that you have some familiarity with a uh uh fundamental constructs such as cybernotation, DNS, IP routing, and so on and so forth. Um. You can take some pictures along the way, but we will be posting these slides on the AWS event page, so you will have access to that slides later on as well. With that, let's start with a view of the AWS global infrastructure. AWSs global infrastructure includes 38 regions. We have 43 local zones and we have over 146 direct connect points of presence, and all of this global infrastructure is connected with the AWS backbone that we have built. It is the most secure, reliable backbone network that we have built, and you can scan this QR code that will take you to the page on the AWS Global Network that you can take a look at it afterwards. Now let's zoom in a bit more into the construct of region. So AWS has the construct of region, which is a physical location around the world where we cluster these data centers, and all of these data centers are interconnected with each other with high speed, high bandwidth and throughput and low latency links. We encrypt traffic when it leaves our secured facilities. And a cluster of these data centers is what we call it as like an availability zone. So here you can see there are 3 availability zones that I'm showing, and all of these availability zones are also connected with high bandwidth, uh, low latency links, and we also encrypt traffic when it leaves these availability zones. Now, having talked about region and availability zones, you then create what we call it as like Amazon virtual Private cloud, which is a logically isolated part of your network that you get to define similar to your data center. Now within this region, you have availability zones, and availability zones have data centers, and within these data centers, we have different racks, and your EC2 instances lives on one of these racks here. Now, with this understanding of global infrastructure, let's start to understand the IPV4 and IPV6 addressing options that we have on AWS. But before we do that, let's define how AWS thinks about public and private IP addressing on AWS. The way we define this is in terms of advertisement. So AWS considers public IP addresses as those advertised on the internet, whereas private IP addresses are the ones that are not and cannot be advertised on the internet from AWS. Now with this definition, There are different options that you can, you can think about it. On the left hand side, we have IPV 4 and IPV 6, and at the top you have public and private IP addresses. So let's start with public IPV 4. So you can get a public IPV4 address space directly from Amazon or you can bring your own, uh, uh, bring your own, and you can follow the bring your own IP process to, to advertise that from the AWS. You can also get a contiguous IP block as well from AWS. Uh, that's also possible. In case of private IPV4, this is something that you must be already familiar with. This is RFC 1918 range, which is 1016, 172.31/16, so on and so forth. We also have the career greatnat that you can use for your private IPV4 addresses, and you can also choose to bring, uh, choose to use a public IPV4 address space, and you can assign it to the VPC. However, we will treat that as private in this case. In case of public IPV6, these are global Unicast addresses that you can use, and you can get this either from Amazon or you can bring your own. And in case of private IPV6, these are similar to your RFC 1918 range because these are not advertised on the internet, and you have the option of using unique local addresses. You can also use a public IP space as well for your VPC cider, and you can also use private IPV6UA space for your VPC cider as well. So far we have talked about IPV 4 and IPV6, and we will be showing IPV6 throughout the session. So what we are, what I'm going to do is we are going to define how IPV6 on AWS is supported. You have IPV6 configuration that you can define in two different modes. You can have a dual stack as well as IPV6 only. Then we have AWS public service endpoints that you use to access AWS services, and the last one is the private service endpoints powered by AWS Private Link, which we are going to see in the uh in the following slides as well. So as of today, we support 150 plus AWS services that support IPV6. Now you may be asking, where do I go find all these 150 services. So here's a QR code that takes you to a central page where we list all the all the AWS services that support IPV6. OK Now let's dive into the fundamentals of Amazon VPC. So now you want to build your first VPC. We talked about a region and region has availability zones. Here I'm showing two availability zones. Your VPC is a regional construct, and you define a cider range for a VPC. Here I'm choosing a 10/16, and an IPVC cider range for your VPC. And when you do that, this makes your VPC as your dual stack VPC. But now you might be thinking, This is a single VPC, single region. What if I'm operating in multiple accounts and multiple regions? How do I do this at scale? To do that, you can use Amazon VPC IP Address Manager that allows you to automate IP address assignments. You can plan and track your IP addresses on AWS. We'll start with an example of Private IPV4. So we talked about the IP addressing options on AWS, which is public and private for both V4 and V6. So we'll take an example of private IPV4. So when you integrate with Amazon VPC IP Adress Manager, also known as VPC IPA, we define two scopes, a private and a public scope. A scope is nothing but like a container. Within a private scope, you then, uh, since it's a private IPV4, you define this into the private scope. You create a top-level pool. Here I'm showing a slash 12 as an example, and then I'm operating in three regions, for example, and each region has a slash14. Now, the way I'm dividing this uh IP address space is based on my uh organizational rules. So, for example, you have a dev pool and a prod pool, you can have many other pools like staging and test as well. And here I'm showing like a slash 16. And if you're operating across multiple accounts and multiple regions, you can integrate with AWS organizations and you can share these environment pools such as dev and prod with different accounts, and then each application owner can go ahead and request 24 as an example to get that IP address space, and you can do this across all different regions as well. Now, what about IPV6? So here's another example. Uh, I'm showing an example of bring your own IPV6 with GA, which is an advertised space. So as I mentioned, you have different scopes, you put that in the public scope and you can have the rest of the hierarchy as the same. Now, let's bring our dual stack VPC that we just built before and now apply these constructs. So you get this IP address range now from IPA and assign it to your VPC. Within a VPC, then you create different subnets. Since we have IPV 4 and IPV6 supported, you can have an IPV4 only subnet. You can have a dual stack subnet, and you can also have an IPV6 only subnet as well. Now for IPV4, we support creating a subnet size of 28 to 16. And in case of IPV6, we support anything from 44 to 64 in increments of 4, basically. Once you define these subnets, subnets are tied to a specific availability zone, as you can see, and you can have many subnets that can reside within the VPC. Now each subnet has a route table associated with it, and when you have both IPV4 and IPV6 sider assigned to your VPC, by default we add a local route within the VPC that allows you to connect with resources within the VPC, and you can see here a route table. There are other things that we will see how you can enable connectivity to the internet and hybrid and so on and so forth, and we will talk about examples on how those route tables will look like. Now, once you define that, you can then create and launch your resources such as Amazon EC2 instances, your RDS load balancers, and so on and so forth. Uh, and when you do that, here I'm showing an example with dual stack and an IPV6 on the subnet. Each instance gets an elastic network interface from, uh, and it gets an IP address range from the subnet that it is created in. Um. Once we create these instances, now instances also have some local services that are available to them. And for example, we have Amazon EC2 instance metadata Service. We also have Amazon Time Sync Service and Route 53 resolver service. These are services that are available to your instances locally, and you can use, for example, Amazon EC2 instance metadata Service to get the user data and so on and so forth. Um. Keep in mind here, we have both IPV4 and IPV6 endpoints that are supported for these services. And for IPV6, we uh you can uh do access this using a nitro-base instance types. Now let's look at the Amazon VPC DNS. So every VPC comes with a purpose-built DNS resolver which we have at the VPC Cider 2 range, and we also have the IPV6 address space that I just talked about. And we will see these examples about VPC DNS when Dave talks about in the further part of this session. Now, let's talk about uh the uh fundamental security that you get uh on AWS. We'll start with network access control list. Uh, we also call it as like NACL. Uh, Network access control lists are stateless in nature, and you define this at the subnet level. And when you define this at the subnet level, you can do both allow or deny rules, and based on how you define your rules, your traffic will be either allowed or denied and um. The second option here is to use security groups. Security groups are stateful in nature, which is basically like a firewall that you can apply at the ENI Elastic network interface, or at an easy to instance level. And you can control access. It can only have allow rules and by default with security groups, you can, if the traffic is allowed, if the traffic, if you have an egress rule that allows traffic to access a database, for example, by default the inbound traffic is automatically allowed as well. Now we are talking about IPV6 only subnets, and, but we are living in a world where we have both IPV4 and IPV6. So how do we ensure backwards compatibility in that case? So here I have an IPV6 only subnet, and I have an instance within that. If that instance makes a query to an IPV4 only domain, it goes to the Amazon VPC DNS server that every VPC gets that performs a recursive lookup to Route 53. And it gets a response back with an IPV4 address space. Now you have an instance that is IPV6 only, but the IP address it's getting is IPV4. How does the backward translation happen here? To do that, we support DNS 64. It is a setting that you can enable on the IPV6 only subnet, and what this does is that is when, when it makes a query to the Route 53 DNS resolver, it gets a synthesized IPV6 address space in the hexadecimal format. So here you see a hexadecimal format of the same IPV4 address space that I got from that instance. Now DN Explorer is just for getting that address space that the instance can then reach out to, so we will see in the further slides in terms of how you can apply these constructs when you want to actually enable connectivity to an IPV4 destination. And with that, we will transition into talking about how you can establish connectivity to the internet from your VPC. So we will start with public subnets. A public subnet is something that has a route table pointing to an internet gateway. So you create an internet gateway and associate with your VPC. You can then this internet gateway does the translation of IPV4 to private IPV4 to the public or the elastic IP of that of that instance, and you add a route into the VPC route table pointing to the IPV4 default route. And once you do that, your IPV4 instances can establish connectivity to IPV4 destinations. Similarly, in the dual stack subnet, you then add a default route for IPV6, and then it can also connect to IPV4 destinations. But for IPV6, it can also go via the same internet gateway. So Internet gateway supports both IPV4 and IPV6 traffic. Keep in mind that here the translation that I'm talking about here, the 1 to 1 gnat that Internet Gateway is doing, it's for IPV4. Now we also talked about public IPV6 only subnets. So in this case, you can, as I mentioned, Internet gateway can connect to IPV4 IPV6 destinations. But in case of IPV4, what you can do is you create a NAD gateway, which is a network address translation service from AWS that allows you to translate traffic from IPV4, private IPV4 to to to the internet destination. And here you can enable DNS 6.4 since it's an IPV6 only address space, and what you do here is that is you specify the 64FF9B, which is a well-known prefix pointing to the NAT gateway. When NAT gateway sees this traffic coming from this well-known prefix, it knows that it needs to translate from 6 to 4 automatically, and this is something that can be done on your existing NAT gateways. You do not have to create any new NAT gateways to do that. And keep in mind here I talked about a zonal NAD gateway, but a couple of weeks ago we also launched a regional NAD gateway as well that you can use for these purposes. What about private subnets now? In case of private subnets, we know that you have to create a public net gateway that can then route via internet gateway to go to the IPV4 destinations. Same thing works from another dual stack subnet on IPV 4, but for IPV 6 you can use what we call it as like an egress-only internet gateway that allows you to connect and initiate outbound connectivity from your VPC to the IPV6 destinations. Similarly, for private IPV6-only subnets, you define an egress-only internet gateway to talk to IPV6 destinations, and again you can use the well-known prefix via NAT gateway to talk to IPV4 destinations, and that can give you that backwards compatibility with 624. Now so far we talked about having internet access, but you may have a requirement where you want to block that internet connectivity. And you can block that using what we call Amazon VPC block public access. It comes in two different modes, a bidirectional and an ingress-only mode. In bidirectional, we block both internet ingress and egress, and ingress, in ingress only we can block only ingress, but you can, you can apply this at AWS account organizations or at an OU level. But if you want to also create exclusions, you can do that as well. Uh, uh, for, for your egress inspection as well. We talked about Amazon VPC so far, and this Amazon VPC is tied to an AWS account, but you have different subnets within that, and what you can do is you can share your subnets that are part of the same VPC with different accounts using Resource Access Manager. And those shared subnets can then allow the participants to create resources within that. This is helpful if you want to conserve your IPV for address space and you have separation of duties between the networking and security teams to do that. You can still control access between different subnets using security groups, networks that we talked about, or by putting a firewall in between them which Dave is going to talk about later on. Now, we talked about connectivity to the internet. What about connectivity to AWS services? So you can use gateway endpoints to access AWS services such as S3 and Dynamo DB. And what it does is that is you create a gateway endpoint, and we support both dual stack IPV4 only and IPV 6 only as well. What it does is that is it automatically adds a prefix list for that service within your VPC route table. And you can do that for both IPV 4 and IPV 6 now, and this allows connectivity from your EC2 instances to S3 and DynamoDB over AWS backbone. It is private and secure. You do not have to create any other gateways to establish that connectivity. What about other AWS services? We also have interface VPC endpoint for AWS services, um, and what you can do here is that is you create what we call it as like an interface endpoint, also known as like private link endpoint, which creates an elastic network interface within the VPC, and we support both IPV4 and IPV 6 and dual stack, and the instances then send traffic to these AWS services privately and securely to AWS services, and you can access these services. And we support over 170 plus services here. Let's talk about VPC to VPC connectivity. The simplest way to connect to VPCs in a region is to use Amazon VPC pairing. Here you can see you have two VPCs that are non-overlapping. We create and update the VPC routable pointing to the pairing connection ID of the other VPC, and the instances can communicate with each other. Is this traffic encrypted? To do that, we just introduced VPC encryption controls. This is a new capability that you can use to audit and enforce encryption in transit for all of your traffic within the VPC and across the VPC in a single region. And what you can do that is it comes in two modes, a monitor and an enforce mode. In monitor mode, you can monitor your traffic within the VPC and look at resources that are not encrypting traffic. And you can use VPC flow logs which they will talk about. And in the enforce mode you can enforce which services and resources encrypt traffic, and you can also create exclusions if you want to internet destinations and some other destinations as well. So how does this work with VPC encrypt controls? You create an enforce encryption on your VPCs that then you can encrypt the traffic between the two nitro supported instances over that VPC pairing connection. You also have pairing that supports across regions as well. And everything works the same. But what if you want to have VPCs that want to scale more than what VPC pairing supports, and you want to have transitive routing as well? You can do that with Transit Gateway. Transit Gateway is a layer 3 routing, virtual router service that allows you to connect multiple VPCs, and you can define your VPC route tables and point to the Transit gateway as the next stop for both V4 and V6 traffic. You can have transit gateways in one region or in another in the same region, and you can pair them together, or they can be in different regions and you can pair them. But in this case we only support static routing and in case of static routing, uh, which means that if you add another region or a VPC, then you have to add statically add routes across all your network, and that can become cumbersome. To address that challenge, you can use AWS Cloud V and build that global. Van connectivity to do that. Here I'm showing a 3 region deployment where you can manage this network using a JSON policy document and you can show your 3 regions. And what it does is that it creates a transit gateway managed by AWS and we support dynamic routing across this network. Transit Cloudvan also has a concept of segments which is nothing but like a VRF that you folks might be familiar with. You can have these segments either globally or you can have a regional segments as well. And you can also and resources that are VPCs that are connected to the same segment enable connectivity, but you can prevent that communication by setting this flag. Then your VPCs can attach to the cloud van, but the way you can do that is by attaching the policy, and you can define saying that if there is a specific tag, go ahead and associate to the specific segment to do that. How do you share routes? You can do segment route sharing, and again this is also controlled through the policy as well. Now let's talk about hybrid connectivity. The first option is to use AWS Direct Connect, which is a private dedicated connection from your corporate data center to AWS bypassing the internet. The way it supports that is you connect to one of our AWS Direct Connect locations. You can either have a dedicated connection or a hosted connection. It comes in different speeds. And at this location you have an AWS router, and you may either have your own router or you can work with a partner that has their own router and create a cross connect between them. And extend connectivity to your corporate network through that partner network. That's your physical connection. Now, what about the logical connection? You create a logical connectivity using virtual interfaces. You can create a public web to access public services, and when you do that, we set up an EBGP which supports both V4 and V6, and we advertise all AWS prefixes back to your on-premises. You can also connect to a VPC using a construct called a Direct Connect gateway and a virtual private gateway. The Direct Connect gateway is a global construct which is highly available, highly redundant. And it allows you connectivity to multiple VPCs in different regions as well. And in this case, direct connect gateway has a construct called allowed prefixes where where all the VPCs that are connected through that direct connect gateway via a virtual private gateway, we advertise those prefixes back to your on premises. What about transit gateway? You can create a transit wiff connecting to the direct connect gateway, which then connects to the transit gateway, and then on the direct connect gateway you specify what we call it as like allowed prefixes. These are all the prefixes of your VPCs that you advertise that you want to advertise back to your on-premises network. What about cloud van? Cloud V also supports with a transit and interconnect with direct connect g Gateway there. Now, let's talk about site to site VPN. Uh, site to site VPN connection allows you to create IPSec encrypted tunnels from your corporate data center to AWS. On the AWS side, you can terminate this VPN connection on a virtual private gateway, and each, when you do that, we create two tunnels. Each tunnel is 1.25 gigs, and only one tunnel is active at any given point of time. We do not support ECMP in this case, and we support both static and dynamic routing. What if you want to connect to multiple VPCs now? You can terminate that VPN connection on the transit gateway instead. And with Transit gateway you get additional benefits such as you can have an IPV6 also supported. We just recently announced larger bandwidth tunnels where you can have up to 5 gigabits of bandwidth on each tunnel, and you can also do. Same thing uh works for AWS Cloud One as well, where you can have uh multiple uh VPN connections that are supported and you can do ECMP in this phase and the other features that I just talked about. What if you now want to integrate your SD-WAN appliances? Here you have VPCs connected to the transit gateway or cloud van, and you have corporate data center. You can deploy these SD-WAN appliances within the VPC with the VPC attachment as the underlay, and on top of it, you create a GRE tunnel and exchange BGB prefixes from these SD-WAN appliances with either transit gateway or cloud van, and you can further extend connectivity to your corporate data center with either virtual private gateway or internet. What if you don't want to have those tunnels to manage and you want to get the full bandwidth, you can do that on cloud van where you don't have to manage those tunnels and you can get the tunnel-less connect with cloud van. All right. Let's talk about uh elastic load balancing now. Um, The first option in elastic load balancing is application load balancer. This is a layer 7 load balancer that allows you to load balance incoming traffic on HTTP and HTTPS to your applications. Here on the application load balancer you can see. We support advanced request routing. You can do cool things such as like path-based routing, host-based routing, query string, and so on and so forth. And we recently announced a couple of months ago a header modification where you can modify these headers before it gets sent to the targets. And when, uh, and the application load balancer can then uh uh load balance traffic across these instances, and you can use different types of load balancing algorithms that we support here. Uh, The second option is to do is to use a network load balancer, and with network load balancer, the beauty here is that it supports static IP addressing, which means that you can use these static IP addresses to either allow list your specific firewalls or specific clients that you want to do that, and we support both TCP, UDP and TLS, and we recently announced support for Quick Protocol as well on network load balancer. Uh Once the load balancer receives that traffic, it can load balance traffic across your targets, and we support both V4 and V6 targets. And here the target group, we recently announced where you can do weighted targets with network load balancer as well. And with that, I will hand over to Dave. All right, thanks Rot. Alright, now, so far we've been focusing on layer 3 connectivity between our VPCs, but there's another way we can think about connecting our applications together, and that's with application networking. So application networking is a little bit different if you're not super familiar with it. Essentially we focus on connectivity between resources and applications instead of networks. So to do that we'll create an endpoint in our client VPC, and then that endpoint will be configured with listeners appropriate to our applications that we've got over on the provider side here. Now those applications are going to appear native to that local VPC. So for example, when my client here does a DNS lookup, they're going to get an IP address for that endpoint local to that VPC. And there's two services we'll talk about that can provide this kind of connectivity, AWS Private Link and Amazon BPC Lattice. Now, regardless of which one of these we use, this will allow us to use identity-based access controls alongside network controls like things like route tables, network ACLs, stuff that Ro was talking about earlier. And this brings us into a position where we can start to talk about zero trust as well. Now I'm not going to read the whole definition of zero trust there, but essentially it's this idea where we use identity-based controls alongside network controls to improve our security posture. Now I mentioned there's two services. Let's start with Private Li. Now with Private link we can access AWS services. Roe had mentioned that earlier, but we can also access custom defined services, whether that's for our own internal consumption or maybe we're sharing those out with a third party. So to do that we'll need a network load balancer to start and then we'll define target groups based off of the different types you see here, and these can support different listener types from TCP or UDP with a call out that if you're gonna do UDP it does need to have an IPV6 target. And then we'll use a VPC interface endpoint to access that service from the client side. And these clients can be IPV 4, they can be IPV 6, or they can be dual stack as well. And that allows us also to not only communicate across different types, but also have those endpoints be in different, you know, V4 V6 as well. Now from a from consideration here, you'll notice that I've deliberately highlighted these overlapping IPV4 sighters. So if you're in a situation where you have overlapping IPV4 sighters, Private Link allows you to still have that connectivity between them. Now, these clients and services can be in different regions, and they can also be in different accounts. Now from a security perspective, the first thing that you should know about Private link is that this is unidirectional connectivity. Providers cannot initiate connections to client resources. So as a consumer or as a client, I can connect to those resources through private link, but the provider cannot initiate a connection back to me. They can only respond to traffic that I've started. Additionally, from the provider side, I've got some additional controls. First, I can define service permissions, which basically are IAM policy saying which principals can access my service, and I can also then when someone tries to connect to my service, allow or block access to that service when they try to create that endpoint. Now from a DNS perspective, Private Link is going to create an endpoint specific DNS host name for each service that we have. So it'll look something like what you have on the screen, and when our client goes to resolve that, again, they'll get an IP address local to that VPC using that long custom DNS name. But what if you don't wanna use that? Well, in that case, you could also specify a custom DNS name for your endpoint service. So in this case I'm gonna use appone.example.com. I need to validate that I actually own appone.example.com before I can, you know, use that, but once I do that validation process, I can then use that, and when my clients go to look up appone.example.com, that'll now resolve to those private link IP addresses within the VPC. All of that requires having a network load bouncer though, and you might have some resources like these that don't require a network load bouncer. And if that's the case, that's where you could use VPC resources. Now this is slightly newer, we launched these last year at Reinvent, and these provide that same kind of secure private unidirectional connectivity without needing a network load balancer. So instead we'll have a construct called a resource gateway, and with this resource gateway we can then define what are called resource configurations for each type of resource that we want to use, and the supported types are up there on the screen. We support FQDNs, IP addresses, and you can also specify resources by ARN and we support RDFs on that today. Once I do that, I'll create a resource endpoint in my client VPC and I will be able to access those resources that way. Now a couple of callouts here because this differs a little bit from private link. First, these are regional constructs. You're not going to do these across region today. You can however share them across accounts using Resource Access Manager to create that resource configuration, share it with other accounts. And each resource, just like with Private Link is going to have its own unique endpoint with a unique DNS name, and it's going to look again something like that on the screen here. And just like with Private Link, if you don't want to use that, you can create a custom domain name for these resources as well. We just announced support for that fairly recently, so if I want to use resourceO.example.com here. I can now use that from my client's side and that will resolve to my endpoint. Now one other call out here. So we've got a bunch of resources. As I add additional resources or want to access additional resources, I'm going to need to create additional endpoints for each one of these, because this is functionally point to point connectivity. So that works at, you know, maybe a small scale or if I've only got a few resources I need to access, but if I want to manage this at scale or if I have a lot of resources and services I want to connect to, well, that's where VPC lattice is going to come in. Now with lattice, not only can we use those same resource configurations we just looked at, but we can also create constructs called services. I'm going to take a quick moment and talk about services here. So services, you can think of these as layer 7 constructs. They're very similar to what we talked about when Roet covered application load balancer a few minutes ago. They're layer 7, HTTP, HTTPS, TLS. So we'll configure these services with listeners and target groups. And then we'll take those services and we'll associate them with a construct called a service network, and that service network makes those services accessible from clients, and I'll talk about how that works in a moment. And we can also apply off policies, and these off policies are functionally IAM policy documents that we can apply either broadly at the service network level or at the individual service level instead. Now from a client perspective, this is gonna look pretty similar to what we saw before. I've got 2 client VPCs here. My first option is gonna be a service network association. I can only have one service network association with a given VPC, but if I've only got one service network, that's a good way to go. And this works with route tables. So just like with a gateway endpoint where it adds those routes into your route table automatically, the Service Network association works the same way. Otherwise you can do a service network endpoint, and this endpoint is gonna again use an IPV4 or an IPV6 address right out of your VPC there. Either one of those will allow you to connect to your service network and you can apply those additional controls like security groups and network ACLs on top of that. So between the off policies and these additional constructs, you're again going back to that idea of zero trust where you're layering these additional ideas on top of each other. And both of these, like I said, will give you access to your service network. And finally, using those same resource configurations we looked at earlier, we can now tie all of this together into a single service network so we can access our services and our resources, and both will be accessible via that service network endpoint and that service network association. So for a scale, this is going to be your better option. Now I've started talking a little bit about DNS as well. And earlier Rowe had explained how the Route 53 resolver works within a VPC. You've got that.2 address and that V6 address. Using the Route 53 resolver is gonna give us access to some additional capabilities. First one being resolver DNS firewall. Now with DNS firewall, we can create either blocklists, so domains that we explicitly want to block. Or we can create allow lists where we take the opposite approach and say we only want to allow DNS resolution to these domains, taking that walled garden type of approach. So we'll define those, we'll define any actions we want to take on that. We can define if we only want these rules to apply to specific types like a records, quad A records, etc. and we'll associate all of these rules to our VPC. And then we can optionally use some additional controls to prevent against things like DNS tunneling and domain generation algorithms. We can then start to use resolver query logging separately or in conjunction with this as well, and like the name implies, well, this is just going to log your DNS queries that go to that Route 53 resolver in the VPC, so it'll include source, destination, any responses, but it'll also give you any information about rule actions or any effects that were taken as a result of your firewall rule groups. So you take that, apply it to your VPC. And this can be super useful not only for just understanding what DNS traffic you have, but also if you're trying to troubleshoot any kind of like firewall rules that you may have created that maybe you're having some unintended consequences. I'm going to put those aside for a moment. What if you want private DNS like you might have in your data center today. For that, we have this idea of a private hosted zone. So I'll create a zone here, in this case for apponeexample.com, and I'll define records within that zone. I'll then take that zone and I can associate it with a VPC. Now as the name private hosted zone implies, this is a private hosted zone. If it is not associated with that VPC, nothing in that zone will be resolvable. So in this case, when I've got my instance, I'm gonna query food applo.example.com because of that association, I can successfully resolve that. I can also associate multiple private hosted zones to a single VPC. I can also take those same private hosted zones and associate them with multiple VPCs, that'll give me a multi-VPZ view of my DNS. Now what about our data center? We don't want our poor data center to feel left out of all the DS fun, right? So for that, what we can do is we're going to take these private hosted zones, we'll associate them with our VPC, and then we're going to create what's called an inbound resolver endpoint. And that endpoint when we will allow us to resolve those private hosted zones from our data center. So to do that, we'll create a forwarder in our on-premises DNS server. And as long as we have some kind of private connectivity path, so like direct connector site to site VPN like we talked about earlier, we'll then be able to resolve those, and we can optionally choose to encrypt that with DNS over HTTPS as well. So from a flow perspective, we've got our DNS server. It's got our forwarder That server receives a query for food.aone.example.com and then that will now go to our inbound resolver endpoint so we can resolve those private hosted zones. Now what about the opposite direction? Well, we had an outbound inbound endpoint. Now we've got an outbound endpoint. The same idea here before we had a forwarder in our on-premises server. Now we're gonna create forwarding rules instead, and these forwarding rules will point to our on-premises data center, in this case for corp.example.com. We'll take those forwarding rules, we could also choose to delegate if we want, and we'll associate them with our VPC. Once we do that, we can again optionally choose to encrypt those queries, so from a flow perspective, it'll look something like this. We'll query in this case for bar.corp.example.com. We'll see that we have that forwarding rule associated with our VPC. And then that will send it to the outbound resolver endpoint and then to our DNS server on premises for resolution. There's a lot of associations here. There's a lot of constructs here. There's a lot of resources. How do we manage all of this at scale, especially if you're operating in a large environment where you've got a lot of VPCs? So for that you can take all of these and put them into what's called a Route 53 profile. We actually just added support for resolver query logging like you can see there. Once you do that, instead of having to manage each of these separately, you can take this one profile and associate it with many VPCs either within your same account or across multiple accounts using Resource Access Manager, giving you that, you know, complete multi-account view of your DNS. very So we talked about DNS firewall and earlier Rojot was talking about some of the basic security concepts, but when we think about our environment too, we'll probably want to think about adding a firewall in somewhere. So there's a couple of different places we might do that. We might wanna add a firewall to inspect traffic between VPCs, maybe between subnets. Maybe, you know, on premises, in or out to or from our data center or out to the internet. Now with the internet, let's use that as an example. It would probably look something like this. I've got a workload in a private subnet. I've got a net gateway in a public subnet and ideally I want to place my firewall right in the middle there in some kind of an inspection subnet. Now there's 2 approaches we can take, depending upon what we want to use to actually do that traffic inspection. So to get things started. If you're using 3rd party firewall appliances, you could use AWS Gateway load bouncer. So Rowe had talked about two types of load bouncer earlier. This is a 3rd 1, but this is specifically designed for third party appliances to provide native load balancing. How it works, we've got our load bouncer. We'll take our firewalls and we'll create them and define them as targets for this gateway load balancer. And then we'll use an endpoint powered by Private link, a gateway load bouncer endpoint, and this will give us a bump in the wire traffic inspection. It's transparent to the source. It's transparent to the target. We're using route tables to steer traffic to that endpoint to the gateway load bouncer. Load bouncers will do what load bouncers do best. They'll send it to the targets. If that's allowed, the traffic will return to the gateway load bouncer back to the endpoint, and then route out to the internet. Now the consideration here Is that even though we are using native load balancing capabilities, we still have to manage these firewall appliances themselves. If we don't want to do that, Instead we could use AWS network firewall, and with network firewall this is a fully managed native firewall service that gives us the same basic capabilities where we can allow and block traffic, we could do logging, things like that, but it gives us all these additional capabilities as well, including some recently launched features like managed rules from AWS partners and a managed proxy which is currently in preview. Architecturally this is going to look exactly the same way. Instead of a gateway load balancer endpoint, we have a firewall endpoint. We'll route our traffic to the firewall endpoint which will pass it to our firewall service. That traffic is allowed through, it will return to that endpoint and then go out to the internet. Now the key takeaway here, regardless of which one you use is that both gateway low bouncer and the appliances and network firewall will support the same inspection architectures. What do I mean by inspection architectures here? Well, here's an example using that one we were looking at. That's an example of a distributed model where we have an endpoint in the VPC that's doing the actual inspection right there. And we could do that for on-premises in or out if we're connecting directly to a VPC, and we could also use that for traffic between subnets. But we didn't really talk about how to do traffic inspection between VPCs yet, so for that we're gonna need a different type of model, and this is gonna be a centralized inspection model, and this is going to use either AWS Transit Gateway or AWS Cloud WAN. And once we start to think about centralizing our inspection, well, we can centralize our on-premises inspection, as well as centralizing our internet ingress or our internet egress as well. Let me show you what I mean. So, taking transit gateway as an example, I've got some VPCs connected to my transit gateway. I can choose one of two approaches with Transit gateway. Either I can create a dedicated inspection VPC that has the firewall endpoint in it, and if I do that, I do want to configure appliance mode to make sure my traffic is symmetrical. Or with Transit Gateway, you have the ability to create an AWS network firewall native attachment, and that will basically remove the need for you to create that inspection VPC. I'm going to use the network firewall attachment for this, but you can do the same thing here. With the inspection VPC functionally from the VPC's perspective, you route traffic to the transit gateway. The transit gateway passes it to the network firewall attachment. The network firewall attachment returns it to the transit gateway if it's, you know, been inspected and allowed through, and then routed back to the destination VPC. For on-premises, again, assuming we've got some kind of private connectivity here, the flow is going to look very similar. Instead of sending it back to a destination VPC now, we're going to send it to our on-premises data center. From the VPC's perspective, it still has that route to the transit gateway, and the transit gateway handles that routing for us. Now Internet egress is a little bit different. This is my personal opinion here. You could go through the network firewall attachment and then go through, you know, a centralized egress VPC. I think it's a little easier to do this. So we'll take our inspection VPC and we'll add in that gateway and we'll add an internet gateway so we have a path out to the internet. Once we do that, Now our VPCs can send traffic to the transit gateway like they did before, but instead of having to go through the transit gateway twice, we inspect and we egress in the same VPC. Now that was with Transit Gateway. Cloud wind is pretty much the same thing. So with Cloud WA earlier we talked about how you know you can have different segments there we'll attach our VPCs and our connectivity to our segments. And then we'll create what's called a network function group, and this is a special kind of segment specifically designed to manage the routing for these firewall appliances for us. And we'll attach that inspection VPC to the cloud WAN network function group. We don't have the native attachment available today. But from a flow perspective it's gonna look largely the same. So again we send our traffic in this case to our Cloudwine core network. That core network rides it to the inspection VPC, gets inspected by that end point, returns back to the core network, and then routes it to the destination VPC. For on premises, same thing, we're gonna go through our core network, the inspection endpoint takes care of the inspection for us and then routes it back to our on-premises data center. Then finally for internet egress, same concept applies, we're gonna use that same inspection VPC where we're inspecting and we're egressing all in the same VPC. So the takeaway here is whether you are using AWS Cloudland or Transit Gateway, whether you use third party appliances, whether you use, you know, AWS network firewall, these concepts will apply the same, giving you that flexibility that you want for this kind of inspection. Let's take a quick moment to detour and talk about remote access. Earlier we talked about this idea of accessing networks versus applications and resources, and the same concept applies here when we talk about remote access. So for network access you could use AWS client VPN. This is a fully managed remote VPN solution. It'll automatically scale up or down based on how much you use it, how many users are connecting. And how this works, you can define multiple authentication options including a certificate based off, and then once you do that you can create authorization rules and these rules will allow you access to specific networks based off of the authentication information that the VPN receives. You'll notice here in this case I'm connecting, you know, this engineering group can connect to this particular cider block. Once I do that, I can configure other things like connection logging, client route enforcement to prevent route leaks. And then from the target side, a couple of things here. First, my clients can be V4, V6, or dual stack, and my targets can be V4, V6, or dual stack. And in addition to accessing resources in that one VPC, I can also connect to resources in that same VPC or outside of that VPC again as long as I've got some kind of a routable path to those. Now, what if I don't want access to networks, but I want that different approach, it's more that application networking based approach? Well, for that I could use verified access and with verified access, again similar to what we saw with VPC Lattice, we're providing access to applications and resources without requiring a full VPN connection, and we can add additional group and app level policies on top of that as well. This will support HTTP and HTTPS applications and TCP resources again, very similar to what we saw with Lattice earlier. Now for the first one, HTPHPS applications will configure verified access with trust providers, and these trust providers will include not only identity information, but we can also use device information. So is my laptop up to date? Do I have all of the right security patches, things like that? Do I have any software that shouldn't be on there? I can configure all of that, and then based off of that information from those trust providers, I can now craft policies, and I can do these policies per group, or I can do them per application or per endpoint. Configure access logging and because these are layer 7 constructs I can also choose to optionally integrate AWS web application firewall as well. From a target perspective, I can connect to elastic network interfaces attached to an EC2 instance or load bouncers, and these do need to be private load bouncers. And then once I do that, I can define those per app policies as well. So remember, thinking back to what we saw with Lattice, the same concepts apply here, broad at the group level and more granular at the individual application level. And that will allow me to provide that connectivity, and those policies will then be used by verified access to provide that continuous authentication in real time. TCP resources are gonna be pretty much the same thing. Only in this case, instead of using HTTP HTPS we're connecting to er via services via TCP, SSH, RDP, things like that. My targets will be the same, I can apply resource policies on those as well, but I've got now the ability to connect to two additional resource types. One is going to be an RDS database, which I can connect to directly, or a network citer, and a network citer is going to be super useful if I have auto scaling resources that, you know, are very ephemeral. They scale up, they scale down. I don't want to have to manage connectivity to all of those. Verified access will make it so I don't have to manage that. I can just connect into each one of those as they appear and disappear. It'll take care of that for me automatically. Ultimately I can use the same construct to access both of these, whether it's HTTP HTPS or TCP resources. OK. Now we've covered quite a bit here. How do we have an understanding of this? How do we reason about all of this, these network constructs? Well, the first is, and Roe had mentioned this earlier, so I wanted to make sure we came back to it first, is flow logs. Now flow logs you can apply them at a VPC, at a subnet within a VPC, or at a network interface, as well as on a transit gateway, and this will give you flow level visibility, essentially metadata about your flows. This is not a packet capture. This is Metadata about those specific flows, so include things like source and destination, port protocol, bits, and then any actions taken as a result of network ACLs and security groups. And then all of that will get emitted into our logging destinations, Amazon Cloudwatch logs, S3 or Data fire hose. We've also sticking with Transit Gateway, we can register our transit gateways in Network Manager or if we're using AWS Cloud WAN, we can use Network Manager to get some additional metrics and events from these two services, and this will include things like topology changes, so as we add or remove attachments, routing updates as routes are added or removed, and for SDNAN and VPN, any status updates, so if they go up or down, all of those will get admitted into the same logging destinations as flow logs. Network manager also is gonna give us visibility into infrastructure performance, and these are metrics that we at AWS publish that give you insight into network latency and performance between regions. Between availability zones within a region or within an availability zone, so think back to that graphic we saw earlier where an availability zone consists of multiple data centers. This gives you that visibility. Now these metrics will be available on the console, but you can also publish them to a cloud Watch subscription and then action off of those accordingly. Now speaking of CloudWatch, CloudWatch has a number of tools that we can use here. So for starters, let's say I've got some public internet resources, a cloud front distribution, workspaces, a public facing VPC. I've got users who are accessing that. I want to understand what's impacting their connectivity to those resources. For that, I could use Amazon Cloud Watch Internet Monitor, and this is going to give me internet performance and availability metrics by ISP and location. So functionally, it'll give me something like this, a map of the internet weather that would be affecting connectivity to my applications. Now that's for the internet. What about hybrid connectivity to my data center? So for that, we can use network synthetic monitor. And this will give us metrics like a round trip time and packet loss for either site to site VPN or direct connect. So in this example here, I'm using Direct Connect. I'll set up probes in these VPCs in the source subnet, and as part of that configuration, I'll specify the type of probe that I want. I can do TCP or ICMP, and I can also specify the port and packet size for TCP. And then I can specify an IPV4 or an IPV6 destination on premises, and this will give me that round trip time and packet loss. And for direct connect, this will also include a network health indicator metric, which is a probabilistic value and that will give you some insight as to whether that network degradation is within AWS or external to AWS. Sticking with CloudWatch, we've also got Net network flow monitor, and this is designed for traffic within AWS and this will give you performance and availability metrics about specific network flows. By installing agents either on EC2 instances or you can also apply this onto your EKS clusters. Once you do that, you'll specify local or remote resources, and this could be any of the resources you see here, a region, a VPC, an availability zone, a subnet within a VPC. It could be a remote region, and it could also be AWS services like Dynamo DB and Amazon S3. And this will give you TCP metrics, a network health indicator just like we had with Direct Connect a moment ago, as well as bytes transferred so you can see what that flow looks like. Now what about troubleshooting? We've got a lot of components in here, right? So if we even just take this example here where we've got a load bouncer targeting elastic targeting an elastic network interface on a VPC, well, there's a lot of things that could go wrong in the path, right? There's route tables, there's security groups, there's those network ACLs. So if we want to troubleshoot this, this is where we could use a tool called VPC reachability analyzer, and this gives you hop by hop visibility of the path between a source and a destination that you specify. And crucially it'll also tell you if there's anything in the path that is blocking connectivity from that source to the destination. In this case it's a security group on my application load bouncer that's not allowing that traffic through. So in addition to load balancers, reasonability analyzer supports all of these intermediary components like network firewall, transit gateways, peering connections, and ultimately this is going to be the best tool in your, you know, sort of tool bag here for fine grain troubleshooting if you've got a specific case you're trying to solve. Stepping back a little bit more, if you wanna understand if there are any unintended paths to access your network, you can use network access analyzer, and with that you define what are called network access scopes. Examples here, maybe you turned on VPC block public access you wanna understand the impact of that, or you want your instances to only be reachable via a load bouncer but not publicly facing any other way. So you define this intent and the network access analyzer takes that intent and uses automated reasoning to determine whether there are any unintended or non-compliant paths that don't line up with that access scope. So this is going to be best for that broad evaluation within an account or within a region. OK, we're just about at time here and we have covered a lot in the last hour. We could easily have spent a whole hour on each one of these topics, but. Fortunately there are a whole bunch of sessions that are running this week. Um, if you're catching this later or somewhere else, you might be able to catch some of these on YouTube as well. Please take a moment, grab a photo of this. These sessions are ones that Roha and I picked out specifically. They dive deeper into additional networking topics that we've started and kind of covered here today. And you can find all of the information that you want to find out about these, where they are, times, etc. in the session catalog. I'll leave this up for just another moment, give folks a chance to grab a photo. And with that, I wanna say thank you all so much for joining us. Thank you for starting your reinvent week with us. I hope you have a wonderful rest of the week and if you have any questions, we'll be around. Thank you so much.