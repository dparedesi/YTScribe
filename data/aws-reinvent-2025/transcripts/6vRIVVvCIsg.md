---
video_id: 6vRIVVvCIsg
video_url: https://www.youtube.com/watch?v=6vRIVVvCIsg
is_generated: False
is_translatable: True
summary: |
  Ahmed Rafat frames generative AI success as a balance of people, process, and technology—pointing out that roughly 80% of pilots never reach production because teams fall in love with tech rather than business problems. He advises starting with clear outcomes (customer experience, operational efficiency, employee productivity), cataloging data so teams can discover and reuse it, and striking a balance between centralized governance and decentralized innovation. On AWS this maps to a three-layer stack: infrastructure (with SageMaker), Bedrock and AgentCore for foundation models, guardrails, policy and evaluation, and higher-level tools like Q, Q Business, and QuickSuite. AgentCore components include runtime, gateway, identity, memory, monitoring, code interpreter and browser tools, plus new policy and model-evaluation features announced at re:Invent.
  
  Professor Bogdan Enache then details how The Economist—long data-driven since its 1843 founding—modernized with AI across its newspaper and Economist Intelligence Unit businesses. Four priority use cases guide their roadmap: personalized content recommendations to keep readers engaged; translation workflows that preserve The Economist’s tone and policies; summarization that retains intent and meaning; and an EIU co-pilot that helps analysts query multi-modal data and draft reports faster. Traditional machine learning still plays a role: for recommendations, the team trained a transformer with attention to predict the next article a user will read, using SageMaker for experimentation and a multi-account CI/CD path for validation, monitoring, retraining, and production deployment, all underpinned by strong data governance and auditability.
  
  For GenAI, they employ Bedrock to build retrieval-augmented workflows, generate JSON blueprints, and deploy entirely via infrastructure as code—no console click-ops. Bedrock services such as embedding models, prompt registry, guardrails, and flow composition underpin these pipelines. A rag-based EIU search experience answers subscriber questions with citations, but complex multi-part queries exposed limitations: long, tangled responses and difficulty handling nuanced filters. To address this, the team is experimenting with agents orchestrated through Bedrock and AgentCore. Agents break down tasks, ask clarifying questions, call internal tools to query knowledge bases or the web, and assemble comprehensive reports, all while enforcing access controls and providing traceability through Bedrock’s span and trace views.
  
  A consolidated platform architecture now lets The Economist move from idea to production in days rather than six months. Standardized accounts for experimentation, operations, and production; IaC templates for both ML models and Bedrock agent blueprints; and monitoring loops for data collection and retraining create repeatable pathways for new use cases. The guiding principles are to keep humans in control—editors still author the journalism—while using AI to accelerate translation, summarization, discovery, and analyst workflows. Rafat closes by urging teams to pick a business-centric first use case, empower cross-functional groups, and leverage AWS references on data strategy, secure AI adoption, and Bedrock best practices to start the flywheel and scale responsibly.
keywords: generative AI, The Economist, Bedrock, AgentCore, recommendations
---

Good afternoon everyone, and thanks for joining us in the industry 399. As you know, around 80% of the PUCs doesn't actually, of the GI doesn't actually make their way to production. And it's not about the technology itself, it's about people, process, and technology. My name is Ahmed Rafat, so I lead the machine learning specialist solution architect in the UK and I'm delighted to be here today with Professor Bogdan from The Economist to tell you the story of how they'd be able to productionize generative AI from an idea to the production in The Economist. So let's crack on. We're gonna go through a little bit talking about how you can actually vision and build your strategy on generative AI. Then I will be handing over to Bogdan, will he walk you through more on a deep dive, how we build that, including the architecture, the design, and demos as well to make it more exciting for you. And then I'll back again to the stage to close it and tell you how we actually can do with your next steps. So you've already been seeing so many use cases on generative AI across the last couple of days and as well Avian before. I'd love also usually to categorize or group them under three main categories, but it's different from customer to customer based on your own use cases. But just to make it very simple, you can think. About 3 main use cases enhancing the customer experience which you see there on the left hand side. Then on the right hand side you've got 2 usually internal main categories, and then so many under use cases come under that under that, which is how you can optimize your business operation and how you can actually increase your employee productivity. But it's all great ideas, and as I mentioned at the beginning, you can be very, very excited within successful PUC, but when you move it to a production, you start to face the reality about where is my data, what is the security, how I can take it to production, how I scale it, and that's why we are here today to tell you the story of The Economist and help you to move fast from an idea to a nice plateau of productivity and instead of spending so much time on this area that doesn't add much value. So if we think about building a Gen AI and a data strategy, I always think about it in the three main things. First of all, a mindset. You need to be always thinking about business problems. Yes, AI is a fantastic, Gen AI is super, Asiantic is like really changing everything we do, but don't forget about the foundation. You need always to start focusing on the business problem. And then you walk backward on that. Always fall in love on the problem, not fail in love in the tech, which I fell in love in tech, but you need to follow up with your business problem. Next is about your people and how you group them and organizers and technology, which we'll dive deep on it. One thing that is very important for AIs, you know, is about data. There are two types of the organization we see when it comes to data. There's some organizations that are very much focusing on having everything centralized. The other is decentralized. What we advise is have some right balance in between. And the idea of that, that you help your entities to have some sort of what we call data catalog. So if I'm working on a data within the organization, I need to index that and publish this, so you, for example, here can use and consume this data to build in your G AI use cases. This will transform your organization to be a more data driven, and that will take you to the step for tools to build with generative AI. And that's what we've been building in AWS for many years now with our stack of Agente, and as you see, it's three layers, you've got the infrastructure with Sagemakers sit in, in the middle with agent core and Bedrock, and in the top you've got things like Kiru and Quick Suite. It's not enough time definitely to cover this stack in more details, and I read Suwami today and Matt Gorman yesterday covered all this more in details, but quickly a recap about Bedrock. Always remember Bedrock is the best place for building the platform. It's a platform to build your generative AI from model selection to customize it, and we announced so many different customizations today as may be so. Securing this with guard rails, automated reasoning has been covered today as well, and also how you can productionize that and integrate it with tools, and that is actually taking you to Agent Core, which is Agent Core is a component sit within. Bedrock and it has actually 6 more components and we added 2 new components yesterday which is not in the slides here because this space moves so fast, but we are talking about moving from runtime where you host your agents securing and. through a gateway, adding memory as also has been announced today about the Abu functionality of memory, and then you monitor your agent and you must have an identity. And then we have two types of tools which is code interpreter and browser tools, and we added two more functionalities yesterday which is very critical. The first one is about how you can actually apply policy, and the second one, how you do model evaluation. So That is enough from me, it's like a quick thing to just remember that you need to have this 3 components between the mindset, the technology and tools, and with that to bring it to reality, I will hand over to Professor Bogdan to talk you through the lovely journey of The Economist. Thank you. Thank you, Ahmed. Everyone, um, so I'm just gonna give you an overview, um, in the time we've got left on the journey that we went through starting almost 200 years ago, um, so, uh, presenting basically where the economy, the economy started and and where we are today. And the kind of infrastructure that we had to put in place and the processes and the people that had to be involved in that to basically achieve the infrastructure and set up and tooling that we've got today to be able to build all this wonderful technology. So The Economist has 4 main areas that it operates in 4 businesses. The most popular ones that most of you would be familiar with is the newspaper, and then also there is the Economist Intelligence unit where macroeconomics and other types of indexes and so on are served as a service for other businesses to consume. Those are the two main areas that I'm going to focus today on that basically we've implemented quite a lot of AI now for the last 2-3 years that we've been looking into. So the journey basically started in 1843 where we had a businessman, a hatman to be precise, James Wilson setting up the newspaper trying to look into ways of fair trading and so on and so forth and being able to publish the opinions of many people at that point in Scotland. Since then this has moved quite a lot. About 100 years later we had the Economist Intelligence Unit looking at forecasts and indexes and Eventually it was one of the first newspapers to digitize the content and make it available on a website and applications and so on in 1991 and then today we are employing all these AI technologies which I'm going to talk to you about today. But one thing is very interesting because from the very beginning, and if I put up the first article that was published, what you will see is that everything is based on data, especially if you look at the bottom there is a table that indicates. Data from exports of UK exports to the US and shows the differences and so on and so forth, which is very interesting to see that data has been at the frontier of the economist from the very first article in order to publish their opinions. So data for us is a key vehicle to basically build our applications and serve the content to the people. So today I'm going to focus on 4 main use cases and then I will go in deep a little bit more on 2 of them just to show you the 2 different types of AI workflows that we have developed using the AWS infrastructure. One is recommendations. It is key for us that we are able to basically understand the user journey and how they read the content and be able to provide them with the next article for them to read so that we can keep them engaged and save them time from reading things that might not be as important and so on because today who has time to basically read given the pace that we live in, so making this a bit easier is a key thing. So the recommendations, for example, is one of the key use cases that I've got another slide to go into a bit more details, but we also looked into translation. And we used AI for that. We built in bedrock workflows that allows not just to translate using a single function, the content into another language, but eventually also ensure that the workflow contains checkups to make sure that the styling of the economist remains the same, that the meaning doesn't change from one language to another, and that is expressed in a way that is compliant to the policies that the Economist has. Summarization is another use case similar to translation. It's not just about summarizing. The question would be, is the meaning of the message that this article is trying to put forward remaining within the summary? And how do we ensure that it contains these key elements to provide the story in this short few bullet points, let's say. And finally for the EU that I was mentioning earlier, we built a co-pilot because that services can be quite complex and usually it is used by analysts to eventually write reports and it takes them a very long time to search through and understand the data and we have multi-modal data as well into this use case. How can we build a support tool for the analysts to basically ask questions and generate reports more or less on the fly? So let's dive deep into one of the UK use cases, which is the recommendations. The reason I put this up is that traditional machine learning is still a thing, right, so not everything is generative AI, and I wanted to show how similar the process remains between building an architecture that supports machine learning using SageMaker more or less to deploy a model. To then building workflows with generative AI. So what you see here is basically utilizing Sagemaker more or less into an AWS account to experiment and build the model. In this particular instance we used a transformer model that basically checks in a similar way that you would predict the next token. We are predicting predicting the next read of the user. And we're using an attention mechanism as well for that based on all the data that we are collecting from the users and eventually that model is operationalized, is checked, verified, tested into several accounts, and eventually ends up into the production account where it gets monitored and eventually data is collected and if needed it comes back to be retrained and deployed again. So this is one of the key use cases that we put together and of course that will scale to many multiple similar use cases that we have in place. Another one that is utilizing the G AI approach is the last use case I talked about, which is the EIU Q&A co-pilot. So in this one I'm going to also demonstrate it later on, and I will show you how we extended that to now use agents instead of just a large language model to basically generate the output. So what you will see that is very similar now is that we still have this experimental account where we put together using Bedrock all the necessary workflows to basically try and experiment with the different large language models that are available in the fronts. But then we create a blueprint out of that, so you will see from bedrock basically you can extract a Jason that can be productionized in a very similar way that you would do with a model. Obviously there is no model deployment as such. What we are deploying now is the actual blueprint of the bedrock Jason, so all that can be tested in an operations account and then eventually productionized and made available to the subsystems within the economist. One other thing I wanted to show here is that how we utilize the bedrock architecture as well. So basically this is this is the blueprint I was referring earlier to where all the processes are built using flows and eventually utilizes the embedding models, the generative models, the prom registry, the guard rails, and everything that is available through Bedrock in order to generate, create this workflow that is then deployed into production. So no click-ups. Everything is utilizing infrastructure as code to be deployed eventually into production. OK, now if I was to put it all together, very complex architecture, so I'll put it up there just to show you more or less how we've got everything now together. This is what allowed us to basically more or less build everything AI within the Economist. This architecture shows you the platform that we created in order to move from sometimes it used to take us about 6 months to push a model into production. Now it's taking us days without even exaggerating to basically take some ideas, experimenting, and eventually productionizing those into into an account to serve the different needs of the business. So yeah, quite an interesting concept. The thing that really allows us to do that is, as Ahmed mentioned earlier, is putting together the processes, the people, and the technology. The technology we found through AWS and eventually we build the processes and with the team that we've got together now we're productionizing this in a few days. Now this is the demo I wanted to show you, so it won't take more than a couple of minutes. Just to give you the context of it, for the EU co-pilot, we run a query into using the typical Gen AI workflow for creating a rag mechanism to search through the documents. So the query at the very beginning is manufacturing and retail risks Southern East Asia, which is a very typical query that somebody might want to run, so. This is now available for the subscriber of this. They can type in the query that they want to search for and eventually, as you have seen many examples before, answers will start being generated, and eventually there are references to the articles that they can carry on reading about and they can click through and examine and understand what's going on and and they get an answer to the question they were asking specifically. So this is great because it helps to a degree with a typical rag mechanism, but then I thought, what about if we challenge this a little bit more? And although we have the knowledge base that we have trained and we tried many different ways, many different embeddings, and so on and so forth, and we created for the knowledge base all the filters that were necessary. Then when we run complex queries like this one here, It was becoming very difficult for a typical rag mechanism to basically provide an answer, so I couldn't really, so what we had to do is simplify the query. So if I simplify it a bit, then we were getting some answer. That answer actually was quite long and it was kind of getting lost trying to answer everything together, so it was not ideal for us. So this is where we start looking into agents. Now this is not into production yet, so I'm going to give you a peek on behind the scenes on our own built-in system, how we now run this query, but what is interesting about it is now that there are multiple agents working together to basically deliver on the different queries that were originally requested. And now what we see is that the agent itself is starting to analyze and think about the process that it needs to do. It's breaking down the different areas that it needs to operate on. This is basically based on the instructions obviously that we provided, but it's also going to start communicating with the user to ask questions and say, What exactly are you looking for so that users can start interacting with the agent in real time to provide the necessary feedback for the agent agents to carry on working on this and eventually that is producing quite good outcomes. Waiting for the um just to show you very quickly a couple of seconds of um of these outcomes as well. And the other interesting thing is that obviously it's going to start using Tooling to basically query the knowledge base, get access to internal data, search the web, and so on and so forth until it provides the comprehensive reports. So I'm going to skip through now this one just to also very quickly show you that this is the console. Within Bedrock now we can see all the traces of what's going on and all the spans on all the activities that the agent has taken and basically we can verify that the steps that the agent has followed are all accurate and up to date with what we would have expected so that was really great to see. All right, last slide from my side and I'm gonna give you no seconds to close up. I just wanted to say that we're looking forward now to building even more within the Economist and one thing that I wanted to mention at the very end is that. We obviously have hundreds of editors that are helping us across the world to build articles, and those are still humans. We're using AI to support them, and we are not using AI to replace them, not at least at any point in time soon. So thank you so much. Thanks, Bogdan, and great to hear that still when I read The Economist, it's been written by humans, it's not with robots yet. So again, thank you everyone for joining us here today. I would just say by like always start walk backward from your business needs, select the use case, empower your teams, enable them, make them feel, as Bogdan mentioned, the business people, the tech people, that AI has helped them to. Accelerate and do their work better and start by an idea. Just take it to a production that will start the flywheel and then when you get more excited on the organization and I will closing by some references for you here. You can read about data strategy, how you can secure this production through cloud adaptation framework for AI. An executive inside G AI for your executive, you can give it to them and definitely with the details of Bedrock and with that, with that, I want to thank you. Please do the survey. We really, really appreciate it if you do the survey for us and enjoy your lunch. Thanks again for joining us here today.
