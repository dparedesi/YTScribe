---
video_id: yDhR5VwcnYo
video_url: https://www.youtube.com/watch?v=yDhR5VwcnYo
is_generated: False
is_translatable: True
summary: |
  Chris McPeak and Haggy Park present comprehensive security best practices for AWS serverless applications, using a fitness tracker application architecture as their working example throughout the session to illustrate key concepts and implementation strategies. The foundational security considerations begin with establishing proper account boundaries to separate development sandbox environments from production deployments, enabling developers to move quickly while maintaining structured CI/CD pipelines that enforce security controls during the deployment process. Encryption is built into most AWS serverless services by default, including encryption in transit for all services, with API Gateway only accepting HTTPS requests, though developers must consider additional encryption for sensitive data in Lambda environment variables using KMS keys and enabling cache encryption in API Gateway when utilizing caching features. Identity and Access Management (IAM) forms a critical security layer with distinct control plane and data plane considerations, where service control policies (SCPs) at the organizational level can enforce compliance across multiple accounts, while resource-based policies control access to specific services like Lambda functions which uniquely employ both resource-based policies for controlling what services can invoke them and execution roles for defining what resources the function can access during execution. The principle of least privilege requires scoping IAM policies to specific actions rather than using wildcard permissions, and developers can be empowered through permission boundaries that limit the scope of policies they can create, ensuring they cannot inadvertently open security vulnerabilities even when given broad development access. For API integrations and database access, services supporting IAM should use IAM policies directly, while legacy systems requiring credentials should leverage AWS Secrets Manager rather than hardcoding secrets, and throughout the development lifecycle, teams should implement security scanning using Amazon Inspector for dependency vulnerabilities and the newly announced security agent for source code analysis, with Amazon GuardDuty monitoring VPC flow logs at runtime to detect anomalies from potentially compromised dependencies. Input validation can occur at multiple layers using AWS Lambda Powertools for strict typing within functions and API Gateway request validation to check schemas, query parameters, and request bodies before invoking Lambda, while AWS WAF protects public endpoints through IP filtering, geographic restrictions, and third-party rule sets available via AWS Marketplace. The session transitions to identity-aware applications with deep exploration of OAuth 2.0 flows, explaining the authorization code flow for user-facing applications where users authenticate and approve access through an interactive login experience that exchanges authorization codes for ID tokens, access tokens, and refresh tokens, versus client credentials flow for machine-to-machine communication that bypasses user interaction. Amazon Verified Permissions offers an alternative approach using the open-source Cedar policy language to define fine-grained permissions declaratively, allowing security teams to specify which users or groups can access specific API endpoints and actions. The presenters conclude by discussing how these security patterns extend to agentic AI applications built with Model Context Protocol (MCP) and the newly announced AWS Agent Core services, including Agent Core Runtime for serverless agent execution, Agent Core Gateway as a unified front door for agent tools, and Agent Core Identity which simplifies OAuth implementation for both inbound authorization from users or AWS services via IAM and outbound authorization to access AWS resources or external APIs, ultimately recommending defense-in-depth strategies that combine least privilege policies, multiple security layers, deep AWS service integrations, and automated security checks throughout the development and deployment pipeline.
keywords: serverless security, AWS Lambda, OAuth 2.0, IAM policies, Agent Core
---

Alright. Hey everyone. Welcome to this session. Uh, we're gonna be talking today about, uh, security best practices for our Servius applications. Just as a quick introduction, my name is Haggy Park. I'm a solutions architect here at AWS. I've been here about 9+ years. Uh, I spent a lot of my time, uh, here at AWS focusing on Servius and more lately is spending a lot of time with agentic applications. Thanks, Higgy. Uh, my name is Chris McPeak. I'm also a solutions architect here at AWS. Been here about 7.5 years, uh, really focused on erless application development and working a lot with our erless teams. Uh, so we're gonna be diving into this topic today around security best practices for serverless apps. Now, if you've never been in a, a silent session before, these can get a little bit weird, right? Um, it's hard for you to hear me through, uh, headphones, um. Uh, versus over a speaker, we like to get feedback, so head nods and, you know, thumbs up if something's resonating, uh, definitely appreciate, but I wanna do something a little bit different this morning or this afternoon. Uh, on the count of 3, I would love everybody just to cheer. Uh, that helps me. That also tells everybody else you all chose the right session. OK? Ready? So we're gonna do this together, ready? 123. Thank you. Awesome. OK, so as we dive into this, uh, I'm gonna start off and go into a little bit of a, uh, a survey of some different, uh, uh, security practices, uh, for civil applications, some foundation items, uh, that we need to really kind of talk through to get started, and then I'm gonna have Higgy come back up and he's gonna dive deeper into some specific, uh, use cases, especially around some of the more, uh, modern application development, um. Uh, that we've been working on, especially with Agenta AI and, uh, some of the identity awareness that we need to think about with, uh, with er security. Now to help us out, uh, what we're gonna do is, uh, is kind of frame this in the idea of a fitness tracker because I think sometimes it's a little bit hard to get our head around, uh, security without having an actual application to talk through or an architecture to talk through so we're gonna use this idea of having a fitness tracker and the basic architecture that we're gonna work with is, uh, we're gonna have our uh our athlete. Uh, I love cycling. Uh, I've done a lot of cycling in the past, as you can tell though, I haven't been cycling a lot recently, so instead we're gonna use Higgy. Uh, Higgy is, uh, training for a marathon right now. Uh, actually ran a marathon last week and, uh, loves using fitness trackers, um, and, uh, collecting all of his data and figuring out how he's doing, uh, with running. So we're gonna have this basic architecture, so an API uh that's gonna collect that data from our tracker, uh, that's gonna feed into an API gateway. From that API gateway will trigger a lambda function that's just gonna take that data and write it to a Dynamo DB table. So as we go through and talk about security, we'll be talking about some of the security that you need to consider on each of the different layers of this application. OK So the first thing that we need to talk about actually is account boundaries. Now I realize this isn't necessarily a serviceless uh concept, but it is something important to consider, uh, as we're developing applications. Um, uh, how many of you in the audience are developers? Awesome. How many are security engineers or, uh, focused on compliance? Great. So as developers we love to move fast. Uh, we love to build very quickly. Um, oftentimes we'll have access to, uh, a a sandbox environment where we can develop quickly, uh, run our tests, and, and move fast. But this can pose some risks to a production environment, uh, when we're deploying directly into that account. So by creating these account boundaries that actually allows us then to separate those areas of control so that you as a developer can move fast and test and and develop um and then as you're deploying out to production uh then you can have a structured deployment uh pipeline uh where as a developer you can commit your code and it will run those automated tests and deploy that out to production for you. Uh, so that's a really important sort of distinction between, uh, accounts that just helps provide a good separation of concerns. Encryption we all love to talk about encryption and, and, uh, it's very important, uh, for us to consider with AWSerless services, uh, a lot of security is already built in for you, but there are some things to consider as you're using some of the different services. So for example, with, uh, if you're using lambda functions, one thing that you wanna think about is, uh, your environment variables and whether or not you're storing, uh, data in environment variables that needs to be encrypted. And you can use a KMS key to actually encrypt those environment variables and keep them safe. Uh, if you're using API gateway and using a caching feature with API gateway, uh, again, you want to make sure that, uh, that the cache is actually encrypted, and API gateway gives you the ability to turn that on. So for each of the different services services, uh, those are available. Some have the option to use, uh, just an AWS uh KMS key, and in some cases you can also use a customer manage key, uh, to encrypt that, that as well. Now all of the er services do have uh encryption in transit by default, uh, so we manage that for you. API gateway only accepts HTTPS requests, um, so you can't even accidentally create an HTTP endpoint that doesn't run encryption on API gateway. OK, the next, uh, area that we need to think through is IAM, uh, so identity and access management, uh, very important, uh, as you're building serviceless applications that control plane, uh, where you're making API calls to AWS to make changes to lambda functions or access different services is one plane to think about, uh, making sure is secure, and the other is the data plane. Uh, so this is where your application is calling different, uh, services, uh, and, uh, your application is running, and so there are a couple of different tools in IAM that will go through, uh, to consider as you're as you're building out your applications. The first is at an organization level and I'll dive into this a little bit deeper in a moment, um, AWS organizations, uh, policies, uh, uh, or SEPs are gonna be scoped at an organization level that can be applied across multiple accounts, uh, versus resource policies, uh, are going to be policies that you're gonna apply to a specific service, um, and so that will control access to that specific service. So, uh, as you start digging into IAM policies at different layers, there are different areas that you can protect. So when we think about our architecture for our activity API, uh, controlling what APIs are being called and how API gateway is invoking our lambda function, uh, we'll want to make sure that we bound those permissions very closely. OK, so with lambda functions, um, uh, specifically I wanna talk a little bit about resource-based policies versus the execution role of that service. So this is a little bit different than how you might consider security for, uh, maybe an application running on an EC2 instance. So with lambda functions you have two different policies that you're gonna work with. That resource-based policy is what gets applied um uh for any service that's triggering or invoking your lambda function. Um, there's a couple of other services that also follow this pattern such as event bridge, uh, and so you wanna make sure that you think through that resource-based policy, uh, for what services can invoke that lambda function. Now the execution role is on the other side of the lambda function. That's the policy that's controlling, uh, what that lambda function has access to as it's executing. So maybe it's a Dynamo DB table, um, uh, as we mentioned before in our architecture. Uh, so, uh, that gives you a different, uh, policy to control, uh, what that lambda function is accessing. So for example, based on our application that we're working with maybe that API gateway we wanna give it access to invoke our lambda function as those activities are coming in, uh, and need to be processed. So we'll create a resource based policy to do that, uh, but we'll also give it that execution role so the lambda function can write those activities out to Dynamo DB. OK, another concept that's really important, um, that maybe as developers we don't always think about, uh, but is, is a really foundational, uh, uh, ideas is around lease privileges. Uh, now I don't know about you all, but, um, this was a little bit hard for me to get my head around as a developer, uh, because I like to move fast. I like to try things, and sometimes it's just easy to scope something very wide open. Uh, but for those that are, uh, security folks in the room, I can already see the cringing, right, with, uh, having wide open policies. So least privilege, um, is very important as you're developing in the cloud. Um, you wanna make sure that you're scoping those policies down, uh, to only the actions that, uh, that service is allowed to take. So if you think about your resource policies or your execution policies, you wanna, uh, not give it a wild card star. But instead, uh, uh, give it only the API actions that it's, that it's allowed to take. Now we can think about this in a little bit of an iterative way as we're developing as well, where we're setting permissions, running tests, verifying actions, uh, and we can all do this in our pipelines as well to verify that we have permissions set well, uh, uh, to meet the compliance for our organization. Now, uh, the other side of that is as a developer, um, you know, I might set, I might wanna set the, the policies for my services, uh, wide open, right? We already talked about lease privilege there lease privilege also matters for me as a developer, uh, so making sure that I don't have access to things I shouldn't or I can't take actions that, uh, that might, uh, cause problems down the road or open up issues down the road. And so one way that you can handle this is is by actually empowering your developers to create the policies they need but also use permission boundaries applied to that developer that actually limits the scope of what they can open up. And so you can actually set uh specific actions to deny or or allow uh on those permission boundaries um sorry, no allow uh just deny um so that you're limiting what a developer actually can do uh in their account. Now this is gonna be a little bit different than uh the SEP roles, uh, SEP policies that I mentioned before where SEPs are organizational wide, uh, a permission boundary is gonna be just scoped for that role specifically. So let's take a little bit of uh an example here. So for our activities, uh, API that I talked about before, um, maybe I want, you know, full access to all the lambda APIs, uh, full access to Dynamo, um, and API gateway. I set a policy for any get actions, uh, so I can see what my API gateway. But my security team really doesn't like that. They want me to scope that down a little bit further. Um, they can actually put in a a permission boundary in place that only gives me access to lambda invoke function. And Dynamo DB update item. An API gateway put method. So you can see effectively when I bring these two permission boundaries and the policy that I put in place uh together, the actual effective permissions is just lambda invoke function and dynamo DB update table. So even though I've given myself some wild card uh um policies to, uh, permissions to move fast. Using that permission boundary actually scoops what I have access to down very tightly. OK, so let's go back to SEP again and uh and talk about this a little bit more, um. Usually when you get to an enterprise level uh organization that's doing a lot of serviceless um uh application development, a lot of times we don't wanna have to apply uh specific controls at every single role. Maybe there are some policies for compliance that we wanna apply across uh our our organization. Uh, across all of the accounts that we actually have and so using SEPs, uh, you can actually apply these policies across the entire organization. So this just uh limits the scope that any of those policies might have access to. Now to help, let's talk through, uh, maybe an example of, of something that could be helpful. um, in our case, uh, we have that API gateway sitting out front and maybe what we wanna do is we wanna limit, uh, access to that API gateway, uh, from the public side. We don't wanna create a public API endpoint. So what we can do is we can actually just allow private endpoints using SCP. So as any of our developers create an API gateway, they can only create it as a private endpoint, not a public endpoint. Now we need to make this a little bit more real, uh, let's talk a little bit about a different scenario. So in this case, uh, we want any of the traffic coming from those trackers to actually flow through a different VPC because in this case maybe we wanna run some, uh, some security validation, uh, or we wanna route traffic a certain direction, uh, within our, our AWS network. And so what we can do is lock down that public API access so that we can then just create a private API endpoint and stick it in its own uh VPC. Then as traffic is coming in it's gonna flow through that uh that broader VPC. Maybe we do some again some security analysis on that traffic um we'll create ENIs in that account in that VPC that then allow traffic to flow into our API gateway uh VPC on the back end so that just provides a little bit more security, uh, for our API endpoints if we have a need to actually flow traffic through VPC. OK, last sort of, uh, foundational area, uh, to think about. API integrations. So I'm not gonna talk too much about API integrations, um, because Higgy is gonna talk through some of that in a few minutes, um, but databases, um, is, is also an important area now in our case, Dynamo DB table and Dynamo DB supports IAM so I can give access to that lambda function using an IAM policy, uh, to access that, that, uh, Dynamo DB table. But what if my database doesn't necessarily support uh IAM? Maybe it's a, a database that I'm just running maybe on an EC2 instance. Um, so in that case you might think about using something like managed secrets, but the last thing you wanna do is take those secrets and actually apply them in, uh, hard code them in your code, right? Uh, so that's where, uh, Secrets Manager is a good place to store those and have your lambda function actually access, uh, that secrets manager to be able to access your database. OK, a couple of other areas just to think about as an organization. If we think about the development life cycle and all the different stages that we have in in the development life cycle, uh, there's a number of different, um, uh, security things to, to just keep in mind, uh, whether it's whether, uh, how you're authoring your applications and where you're storing, uh, that code, making sure you have least privileged permissions there, um, or even pushing code into repositories to trigger your pipelines, making sure you have IAM scope down. So that your pipelines are uh are only uh deploying code uh from the right people. Uh, another area that's really important to think about, uh, is just analyzing that source code, um, looking for maybe, uh, dependencies that have come in, uh, that were applied that maybe have issues in them. Um, Amazon Inspector is a good way to do that, uh, to have Amazon Inspector look at your code, uh, and, and, uh, uh, provide any of those dependency issues that maybe have crept in, but I will say if you. Matt Garman's keynote this morning, uh, he. Pretty agent Uh, we know that was, um, that that was available then. Did everybody still my mic is cutting out sometimes. OK, we'll have our folks in the background. I'll, I'll keep talking and they'll check on it, OK, so, um, so Matt Garman this morning, uh, talked about a security agent, uh, that, uh, that we recently released. This is also a really good tool to make use of, uh, to analyze your source code. OK, so, um. Another possible scenario is let's say you weren't inspecting your code uh and you allowed a dependency to be applied uh in your application, uh, that got through some of your testing. So in this case you might want to, um, uh, look for application anomalies, uh, to detect that maybe that dependency got through, uh, and so at a run time Amazon guard duty. Uh, can look at your VPC flow logs as a way to detect any anomalies, uh, that are maybe happening in your application because something was missed earlier on. OK. Event payloads, uh, another important, uh, area to consider, uh, as you're thinking about security. So with event payloads in lambda, there's actually a really good tool out there called Power tools, uh, that makes it really easy for you to, um, uh, add, uh, things like strict typing, uh, to validate that input as it's coming through. Um, so you can see here this is, uh, this is just a brief example where we're importing that power tools, um, uh, dependency, uh, and that's gonna actually help us to validate very easily, uh, in lambda. Uh, there's some really good power tools sessions going on this week. Uh, that's, uh, uh, there's a team at AWS now that's actually developing that and, and owns that for us. Uh, so I definitely encourage you to take a look at that. Um, but what if we could also look at those payloads before they come to lambda and look for, uh, maybe differences in schema, uh, before a request actually comes in. And so within API gateway, uh, we can validate that input, do input validation, uh, make sure we're getting what we expect to get from a schema perspective before we pass it on to that lambda function to actually run. So 33 available configurations so you can look at the body, you can look at query string parameters, uh, make sure they're what you expect, uh, or you can look at all the above, uh, to validate that event that's coming through. OK, last couple of sort of foundational items, uh, protecting your API endpoints. So before we talked a little bit about, uh, taking our endpoints and making them private, um, another, uh, tool that you have access to is AWS WAF. Uh, this gives you the ability to protect those endpoints, uh, based on IP addresses, uh, based on, um, uh, you know, geographic regions, uh, that you might want to, uh, limit access to that API gateway. IO SWAF also has the ability to take in rule sets from third parties. Uh, so this is a really helpful way to, uh, uh, you know, have a, a subscription applied, uh, that will actually protect those endpoints based on what's being seen out in the wild. Um, there's, uh, if you go on the AWS marketplace, there's a number of providers that will provide that, uh, subscription for you into AWS WAF. So those are some really good ways of, of protecting your endpoints uh uh using uh an outside tool like WAF. Now I'm gonna hand it over to Higgy who's gonna dive into uh some identityware applications. Thank you, Chris. Can you guys hear me? Alright, sweet, um, so Chris gave us a really good broad spectrum of a lot of different things that we need to be thinking about as we're building our serverless applications. What I'm gonna do is over the next, uh, maybe 1520 minutes we're gonna actually dive really deep on one particular, uh, kind of application stack security consideration which I'm seeing as a very common use case, especially as we start to think about both serverless applications but also agentic applications, which is a common thing that I see a lot of my customers starting to think about so. We're gonna go back to um that uh the application that Chris uh presented before again we have our fitness web application, so this is the first component that the user is gonna be interacting with of course that web application is gonna then interact with our Servius API gateway. Um, this is gonna be the activities, routes, etc., those APIs, and then of course the business logic will reside within our lambda functions. So a bunch of what Chris talked about already is going to be these resource policies, execution roles, perhaps even those SEPs for doing deployments. The part that I'm going to spend a bunch of my time on is going to actually be here on this, on the left side thinking about user authentication, authorization. How do we make sure that the user, so let's say Higgy is interacting with this fitness application. is doing um things that he is allowed to do and is accessing resources that I am allowed to access, OK? So Before we get into that, uh, let's, let's take a quick look at our Servius uh application. So this is our, um, the, the one that Chris had introduced before, and again we have these different API endpoints that he had introduced before. The thing to notice that again Chris had talked about was we have a number of different of these APIs that again you can think about as the architects in the room. We're using like domain driven design some um and these are some bounded contexts. These are the domains of logic so you can imagine different teams are provisioning these different APIs and maybe they have different off schemes and we're gonna get into that momentarily. The key thing that a lot of organizations will do when they're protecting these type of API endpoints is going to be using a uh a standard called OOF 2. And we're going to dive pretty deep into OOF 2, but before we do, why don't we go over a couple of the terminology that we're going to be using throughout the rest of this talk, so. Um, when we think about OA 2, there are a number of different entities that we want to be aware of. So the first is the owner of that resource. So you can imagine maybe there's some amount of data we are trying to protect, and let's say Higgy, again, maybe I'm a Strava user. I really like to run. So I have some of my data in this service, and I own, I in theory I own the data or I should be the one that grants access to that data. I then use maybe a web browser, maybe a mobile client in this example we'll we'll just use a web browser that is going to be the user agent, so that is the mechanism by which I'm going to be interacting with these protected resources. Then you have the web application. So my web browser of course connects to a particular web application. Maybe I have it deployed in Fargate. Um, that web application or client then interacts with the API that we are trying to protect. So this is that serverless API that Chris was talking about before. And last but not least, of course there is the authorization server, right? So we need some entity, some identity provider to be able to determine who is allowed to access these resources and what resources are they allowed to access, OK? So these are the five key kind of entities that we're gonna be thinking about throughout this entire flow. Another thing that we want to think through is how do we actually get access to the resources. So there's some process by which this access is going to be granted. So there are actually a number of them in this talk we're just gonna talk about two really we're gonna talk about one and then we'll see how when you learn about one you've already learned about the second one. So the first one is authorization code or code authorization flow. Um, and this is the most common one that probably you're familiar with, so you may be familiar with like when you click on, uh, a web page and it says do you wanna allow access to this particular application for these resources, and that is an example of code authorization flow. The second one is client credentials flow. So where the first one is, uh, end user facing, so I'm, uh, logging into a web page and then I'm gonna allow access. Client credentials is typically used in machine to machine communication. In the former, you have, um, this user interactive experience where someone is gonna be clicking, it's essentially allow. In a client credential scenario, you want a machine to be able to do that so there is no user that's gonna be clicking that approve or allow button. OK, so these are two flows we're gonna talk about. Uh, we're gonna dive really deep in code authorization, uh, and then you'll see how you've already learned about client credentials. Some other things that we wanna think about, so the relevant credentials that uh you wanna be aware of. So when you are creating an application or maybe when a developer, you as a developer are building an application, you actually need to register that application with your identity provider. So the first thing that you end up creating is what we call the client ID and perhaps the simplest way to think about it, it's not exactly like this, but you can almost think of this like a user name. So me as a as a as an entity interacting within the system. Maybe Higgy has a username that is associated with me. Well, for an application, you would have a client ID associated with that application. So when you register with the identity provider, it will vend you a client ID. Um, next then is the client secret and again as you can imagine, this is somewhat similar to having a password, so a username password, um, but this would be essentially the client ID and client secret for the particular application. And these two together are used to then essentially authenticate that this is the application uh interacting with the identity provider, OK? All right, one more set of tokens and then we're gonna kind of dive pretty deep into it and then we're gonna apply this to our servalus application, right? So these are a number of different tokens that you then get when you exchange your client ID and client secrets and my user identity, right? So the first is an ID token. This is a short-lived token. The the really simple way to think about this is this ID token identifies who is interacting with this service, so it might have information like my username, maybe my email again this is all dependent on what you want to include in your application. The next is the access token, and this is perhaps the one that is most important. This is the one that defines you've authenticated now this defines what are the actions that you are allowed to take. So we call these scopes. This will say I'm allowed to, you know, have read access to this particular endpoint. Maybe I have write access to this particular endpoint. And then last but not least is what we call the refresh token. So you can imagine in the code authorization flow as a user interacting with it, it might be painful to every 15 minutes or every 60 minutes to ask that user to reapprove that request while the refresh token is then used to actually do that automatically. So you may, this may be a longer lived credential. Maybe we're going to allow this credential to live for 24 hours and we'll refresh the the the user's tokens by using this refresh token, OK. So, um, these are the credentials, tokens, and some of the identities within it. So these are all the components necessary when you're building serverless applications or as we show in a little bit, we're gonna see how this is gonna be used for your gentic applications as well. Thank you, thank you. All right, so the first phase, I'm gonna talk about two phases. So for the code authorization flow, there's really two phases, and, and in this first phase, really you, what you wanna think about it is the user is essentially logging in and getting an authorization code, right? And so you have this user, so Higgy, I'm gonna log into the web browser. Uh, you can imagine I'm gonna get redirected to a login page, right? And so again this is probably familiar with all of you. Um, after I log in, then you get that little, um, that pop up that says you wanna allow Higgy access to this particular resource and it'll have a bunch of check boxes. We're gonna go ahead and and hit approve. Once you hit approve, on the back end is the identity provider will generate an off code, and so this is just basically a long string. It's a one time use string. It then sends that back to the front end. So the front end application receives this off code. It already had the client ID and client secret, so again this is something that you uh registered with your identity provider when you created the application. When you now deploy the application that gets deployed alongside um with the application. So now the application has the client's ID client secret that it uses to authenticate with the identity provider. It now has the off code which is now user specific, and it uses that to then exchange for a set of tokens. So this is the first phase that is user interactive. Now the second phase is, OK, so we had this front-end application, it was deployed with that client ID in secret. It just received that off code, that exchange that we just did. It is now gonna go to my authorization server. In this case, I'm gonna use Amazon Cognito, and it, it sends the client ID, the client secret, and that off code. And when, uh, what Cognito will then validate, uh, these strings and, and credentials, it will then provide back the uh, the ID token, access token, and refresh token to the front-end application. The one thing that I want to stress here is as you're building your serviceless applications, um, you are not going to expose these ID. Uh, tokens, access tokens, and, uh, refresh tokens to the web browser. You wanna make sure these stay within the bounds of the front end application. These are not things that your end users should actually end up seeing. This is all happening in the back end. So what happens is you'll send, let's say the ID token with API gateway that goes to the authorizer. API gateway will then take that ID token, go back to the um the authorization server, and go and validate is this a valid ID token. Um, so again it'll go in and say, OK, I see this is an ID token from Higgy. He wants to then go and access, you know, the, the backend API. API gateway, it once it receives that validation, it sees, OK, this is an allowed request. It will then, um, oops, I guess I didn't have it in there. It will then allow it to, let's say, uh, invoke the lambda function on the back end. And as Chris had talked about before, this assumes then, uh, you had already configured, let's say, a resource-based policy with your lambda function so that API gateway is allowed to actually invoke it. OK, so we talked about phase one is with that uh the end user interaction. Phase two is on the back end where you have the, again the client application, the front-end application, doing a bunch of these token exchanges. The reason we break this up into um. Actually I think I'm skipping ahead here, so this is actually a quick uh a refresh of the whole flow. So user comes in, connects to the front end application, um, logs in, gets the off code, sends it back to the front end application. Um, it then validates that invokes the API. Um, the API gateway will check with the authorization server, and then here's where we have that lambda function that then gets invoked with that resource server. So what's nice here then is within lambda again for those folks that have built with lambda functions, how many of you guys have deployed a production application using lambda? OK, a lot of you folks. So you know with your lambda functions with your handler, you have two parameters there. One is your event payload and then one is your context payload. So you can actually see within the context payload. Um, a bunch of identity information. So this could be something where maybe as a developer you know that this was an authorized request, but maybe there's some additional things that you may want to do within your business logic. Maybe you have like a, like a, uh, a grouping of users and based on a certain entitlements you wanna allow them to do certain custom actions. This is something you could then custom code into your lambda functions. So this is a lot of additional information you have available to you, uh, even after you've already done the all off flow. So what I was getting at before is um we talked about phase one and phase 2. Phase one is the user interaction. Phase two is that machine to machine. Well, with client credential flow, you can essentially strip off phase one, that login piece and the exchange for that off token, and now for client credentials it's just phase two. So you've now basically learned both. So here you see that web application, it gets deployed with the client ID and client secret. Now it just exchanges the client ID and client secret for that set of tokens, that ID access and refresh token. In this scenario, we no longer need the off code because this is not interacting with any particular user. So again now we just do that same flow we send uh maybe that bearer token along to API gateway. It then goes and validates uh with your identity provider and then invokes your lambda function. So you're kind of asking like, OK, that was a lot to try to understand OOF too well. With a lot of both serverless APIs and also with a lot of agentic applications, OOF 2 is the foundation security mechanism for ensuring that users have access to the appropriate downstream resources. So for folks that are building serverless APIs or if you're thinking about even building agentic applications, this is going to be a core flow that you're gonna want to understand, and we're gonna talk about how we make this a little bit easier for you in the next couple of slides. So we covered OA, but what about, are there other ways for your serverless APIs to think about doing the, the same type of mechanisms for fine-grain permissions? Well, there is, so you can also do something with Amazon verified permissions. So similar flow, you have an end user coming in. They're gonna authenticate with the the identity provider. Um, you will then try to access, so I cut out the the client because you can just assume it goes through you're gonna then try to access your API gateway endpoints and here you're gonna include that token uh uh as a bearer token within the header. And in this case with API gateway you can actually use now a lambda authorizer so you can configure an authorizer to then interact with our uh verified permission service, right? So you can actually take the header, whatever that token might be, um, and then it will then go and do a verification. So here's the token that comes in, uh, run it against Amazon verified permissions. Amazon verified permissions will then come back and say allow or deny. Um, and then based on that we'll then perhaps invoke the back end if that was allowed. Now you may be asking like how do we know or how do we actually define like who's allowed to do what? Great question. So with verified permissions, what it actually does is it actually uses a uh a policy language on the back end, um, and this is actually an open source policy language called Cedar. Here's a little bit of what that might look like. So this is an example. So maybe for the security folks I saw when Chris was asking before there was maybe a third or maybe even a half of this audience, you're, uh, you're really focused on the security side of things. You can actually using code define the, uh, the allowed actions for a particular, uh. Of resources. So here's an example where perhaps uh we have a particular name space. So I wanna include, um, so here at Reinvent we have a bunch of APIs um that are defined for demos here at Reinvent. There's actually also a group of users, so maybe the audience here um in this particular session um is going to be uh included as part of this permission, uh, and then this is then the cognitator user pool. Uh, along with the cognito user group, right, so this is the principle, this is the allowed identity that is gonna be defined by this particular policy, and then this then is the allowed action. So the audience here, if you were to make a request to my particular API that uses this lambda authorizer, will be allowed to make a get request to the slash products, uh, API endpoints or maybe the slash activities, uh, API endpoint. So this is an example of a policy I can define using Cedar. I would then, um, uh, essentially configure verified permissions to then use this policy when API gateway makes these type of requests. OK, so a number of different ways we talked about OA in depth. We talked about using verified permissions to be able to identify users that are coming in, make sure we have these identity aware interactions with MyServes APIs, so. Let's try to push the boundaries a little bit and think about is there a way we can continue to innovate from a security perspective. In where we're seeing a lot of new applications being built. So coming back to our servius fitness application, we have our traditional application. We have again our different API endpoints. So one thing that we may want to think about, uh, and you may have heard about some of this again even in the keynote this morning, um, Matt Gardman was talking a little bit about using and building agents. And so one way we can think about maybe transitioning our erless fitness application into an agent application is using something called tool calling. Right, so within our agents now we're gonna build this agent using an agentic framework. We have an ability to then create and define what we call tools. The simplest way to think about this is, is a tool is just another function that we're gonna annotate as a tool, and we're gonna then call our different serve as APIs. So the activities, routes, socials, and support API that we already have for our er as fitness application, we're just gonna essentially wrap it in a function and annotate it as a tool. The nice thing then here, so these are the tools that we're going to be able to create. The nice thing here is that Our, uh, agentic application here as it interacts with a model, an LLM, it is able to very easily gain access to the data that is, uh, accessible from these different APIs. So you can imagine maybe Higgy as a runner, um, I just did, let's say for the last 30 days I did 10 runs over that period of time, and I actually wanna do a little bit of analysis. I wanna try to understand, you know, what is my average heart rate over this period of time for a particular weather condition. And am I actually improving in my fitness or am I actually getting worse? Is there something that I need to change in that? So this is certainly something that in a serverless application I can go and build and write, uh, imperative code to be able to do this, but maybe as a developer, maybe there's a simpler way to do this and maybe I can actually leverage an agent application to be able to do that on my behalf. And this is, this is perhaps where some of the ideation can come and why we may wanna actually move into this direction. OK, so thinking about tool calling, then you may be thinking, OK, do I have to like write, wrap a lot of my APIs, uh, and do a bunch of work in order to be able to bring this data, bring these this API data into my agent? Well, Fortunately we've actually created or we didn't create uh anthropic created an open specification last year, uh, and you may have heard of it. Anyone ever heard of the, the, the acronym MTP? MCP, so number of handfuls. So MCP stands for model context protocol. It is basically a specification that um that standardizes the way that you do tool calling within energetic application, right? So this is where you can now as your fitness, uh, agent. Can essentially have a singular MCP client and now uh the different data providers can then provide an MCP server, right? And so again you can imagine with the activities, routes, socials, and support APIs, maybe those are actually by different development teams within your organization. So you can imagine Team A is doing the activities API, Team B is doing the routes API, etc. So each of those teams as a data providers or as API providers would be responsible for vending an MCP server. Now you may be asking, OK, what does this all have to do with the security talk that we're really focused on here? Well, in this whole process there are continue to be security considerations. So here's an example where all of that OO 2 stuff that we just talked about and learned we're gonna apply that into this agentic application. So you can imagine as an end user interacting with a uh an agent, maybe there's the code authorization flow, right? And so again as an end user, maybe I'm accessing this through a web browser. I'm gonna log in and then I'm gonna click authorize and now I have access to this fitness agent. You can imagine then I asked that question that I asked before of like help me understand the last 30 days of running. Can you do an analysis on my data? Am I improving? And do I need to change something in the way that I'm training? The fitness agent will then make a determination and say actually make a call to our activities tool uh which will use the MCP clients and talk to the MCP servers. So again, because this is a machine to machine communication, maybe we've configured client credentials to allow my agents to be able to talk to this MCP server. But that's actually not the last step. The MCP server itself is going to then talk to my serverless API, right? And so maybe we have a, a set up here where we're gonna also use client credentials because this is also a machine to machine communication. You may also want to think, actually I want to make sure I'm propagating, uh, identity information from Higgy as the end user accessing the agent all the way down to the activities API, um, so maybe instead of our client credentials, maybe we actually wanna use the code authorization flow. And for the astute in the audience you're probably thinking how do you do that? My MCP server and activities API is way far in the back end. How do I actually propagate uh that end user request? Well, there is a way you can actually stream that that request back all the way to the front end so that I as a user can actually hit the accept button. OK, so we talked a little bit about, you know, we have our Servius fitness application. We're thinking maybe, uh, this is an opportunity to, to build an agentic application. We spent a bunch of time on, um. The OOF 2 flow we talked about Amazon verified permissions. This is a lot of security stuff that we want to think through. Is there perhaps a simpler way that we can do this? There, there is a simpler way, or perhaps an alternate way to do this. So, um, again, in our session in the keynote earlier today, there was a bunch of announcements around Agent Corp. So there are a couple of services to actually make this simpler. So Agent Corre runtime is a serverless runtime similar to Lambda, similar to even to Fargate. To be able to run your agent applications. Uh, on top of that is then something called Agent Core Gateway, um, similar to API Gateway where API gateway is the front door for all of API front ends. We think of Agent Core Gateway as a front end for all of your tools that you're gonna then expose to, um, your agent applications. There are a number of managed managed tools that you have available to you. So again, browser, if you want your agents to be able to go and do research on the internet, maybe you want to hit other websites to be able to glean information about the particular query that the user is coming in. You could use Agent Core browser. Code interpreter is is a situation where maybe your your agent is actually gonna be generating code on your behalf uh and this is untrusted code. You don't want to actually run this within the context of your perhaps your enterprise. You want this code to be actually be isolated and this is where you might actually use something like agent agent core code interpreter. Uh, where we'll spend a little bit of time in the next slide is Agent Corps identity, where we think about all of these OO considerations, all of these security considerations in this off flow, and is there a way that we could actually make it simpler? Agent Corres Identity aims to make that process simpler, and we're gonna, uh, dive into into the next slide. Uh, there's also agent core memory. So in your, um, experiences with different agent applications, one of the key, uh, experience benefits that we've seen customers, uh, wanting out of these applications is this personalized experience. So this desire to see, hey, it actually remembers that this is Higgy interacting with this fitness application and remembering even some of the last queries about the particular application. So memory will allow you to do some of that. And then of course there's observability so observability will allow you to understand the full flow uh of the uh actions that are happening within this particular application. It will also give you an idea of the type of login activities and the tool calls that are being made with this application. But again, let's talk a little bit more about identity and how we can actually apply some of the OA flows in this agentic application in a simpler way. So before we talked again about maybe there's the user, maybe there's the interacting through the web browser, and now we want to actually interact with this particular agent. So on the front end side there's something what we call inbound authorization off, and the idea here is if this is an application perhaps running in on an EC2 instance, maybe it's actually being invoked by a lambda function. We could probably use something like I am. So I am, you can then do all of the things that Chris was talking about before. So I am basically defines what are the actions that this entity within AWS is allowed to do. So if there's an app running in EC2 in Fargate, or even in Lambda, that execution role would then be would allow us to invoke this particular agent. Alternatively, if it's actually, um, maybe external to your organization, this is not actually running an AWS, this is running in your own infrastructure, um, and you don't have an IM role associated with that particular infrastructure, you're likely gonna then use OOF 2, which we went to, uh, in great depth. Then we have what we call outbound off, and outbound off is basically configured based on whatever the target might actually be. So if your agent is going to be accessing, let's say an S3 bucket, so if your agent is going to try and go and extract additional information out of PDF documents in an S3 bucket. You'll just use an IM, uh, role for that. So similar to what Chris was talking about before, depending on what you're gonna be accessing is what you're gonna actually end up using. So again, maybe an estuary bucket, maybe a dynamo table, maybe, uh, something else within your AWS account. This is where you'll use, uh, an IM role for your outbound off. Otherwise for anything else you're going to end up using OOF 2, and this is why we spent a bunch of time on that OAF flow to really help you understand when are you going to be using those different flows. So if you have an end user interacting with a particular protected endpoint, that's likely where you're going to be using the code authorization flow. And then if this is machine to machine communication, you're likely going to be using something like the client credentials flow. OK, so why don't we uh have a couple, um, I guess key takeaways from, uh, this talk, so. The first thing that that uh one of the things that Chris talked about here is again implementing least privilege policies so. If ever you're writing a policy in your AWS account and there is a star there in your policy document, it should give you pause and think, should I really be doing this now that said, there are some policies that do require a star and so in that scenario, sure that is OK, but. If you're gonna be accessing a um a particular dynamo table or a particular S3 bucket, you wanna be as explicit in the resource and you wanna be as explicit in the particular actions that you're allowing in that in that policy. So again, least privileged policies. Uh, defense in depth. So we get Chris talked through a lot of different ideas, uh, in how you can actually secure your surveillance applications. The idea here being don't just apply one or two of these, apply as many as possible. So you're gonna use, you know, IM execution rules. You're gonna use your resource-based policies. You're gonna use WAF to protect your public endpoints. You're gonna use uh SEPs to make sure that developers aren't deploying resources that don't comply with, um, organizational policies. So there's a lot of different mechanisms that you as an organization can apply to ensure that you have a secure serverless application deployed. Uh, leverage the deep integrations across AWS and so, um, one of the beautiful things around, around building, uh, serless applications, whether these are synchronous APIs or what we didn't spend a lot of time on is like async event driven patterns. The fact that AWS will manage those integrations on your behalf. And a lot of times you're gonna configure IM roles or or resource based policies, create those least privileged policies, and let AWS do a lot of those integrations on your behalf. This helps, um, kind of ease the burden of a lot of the undifferentiated heavy lifting of configuring these different integrations. And last, you know, automate these security protection mechanisms, right? So again, Chris talked about things like guard duty, so you can configure it so that you get runtime protection, um, in your CICD pipelines as Chris talked about before, you can implement a bunch of these, uh, protections whether you're on the developer machine, whether you're committing code to a repository and triggering your CI actions, or even as you're deploying into your environments you wanna make sure that all of these checks are being included as part of that deployment process. OK, um, so I think that, uh, concludes. We have a number of other sessions that we wanna recommend that you go take a look at. Um, these are, uh, a bunch that are really relevant for as you're thinking about building and securing your er applications. There are a number of other resources that are available to you. So these are some service, uh, resources that we recommend you go check out, um, and with that. We want to say thank you for coming.