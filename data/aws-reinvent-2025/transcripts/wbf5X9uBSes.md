---
video_id: wbf5X9uBSes
video_url: https://www.youtube.com/watch?v=wbf5X9uBSes
is_generated: False
is_translatable: True
---

We're, uh, we're, we're about to find out all about Kinesis Data streams under the hood. Um, so this is the 400 level talk and, uh, ANT 423. So thanks for joining us. And, uh, my name is John Markel. I I'm a director of software development. And, uh, when I'm not speaking to nice people like yourselves, um, I lead the team that uh owns Kinesis DataStreams. And, uh, joining me today is my colleague, Ali Alemi. And, uh, Ali is a principal data streaming architect. And he is gonna be taking you through some of the finer details of Knesus data streams. And, uh, looking forward to getting into it. So, uh, just a very quick overview of what we'll cover today. Uh, I wanna just give you, uh, just a quick show of hands. I know this is maybe not everyone's favorite part of the talk, but who here has used Knesius data streams? OK. Great. Uh, a lot of you, uh, obviously gonna be quite familiar with some of the terms, but just a level set, I'm gonna introduce some of these concepts, um, just so that we're all speaking the same language. And, uh, we're quite excited about some of the new features that we've, uh, launched in the last month that, uh, have answered a bunch of our requests that customers have been, uh, making of us. So I'm gonna quickly, um, go over The, the highlights there. Uh, then I'm gonna dig into a demo where we actually, this is a great, it's a live demo. Well, it's a, it's a demo that you can download yourselves and run for yourselves. Um, it was put together by Ali. And uh I'll talk through a, a real-world streaming application that um demonstrates some of this new functionality that we've just recently launched. And then I'll hand over to Ali, who's gonna take us through the real interesting parts of Kinesis data streams under the hood. So What is Kinesis? Many of you already know. Uh, fully managed serverless, uh, data streaming service. And, uh, Uh, with any data, uh, with any streaming application, you collect and you process and analyze data in a real-time setting. And, uh, Kinesis data streams, uh, sets itself apart because it is server-less, it can scale, it's elastic, um, it is highly secure and highly available. Uh The average streaming application looks something like this. So on the left-hand side there of this diagram, you've got your input for your streaming data. This could be click streams, it could be IOT devices, it could be mobile apps. It could be um You know, logs coming from your application servers, uh, all sorts of different, uh, sources of data, and they could be on your production network. They could be on the internet. Uh, they can come from wherever. So all of this data gets aggregated into a single point. Um, and these, uh, these sources of data we call producers. So the producers on the left-hand side send their data to Kinesis data streams here, which is your aggregation point. And then, uh, it is It is uh consumed by a, a suite of different options here. But we've got services such as managed Service for Apache Flink, uh, Spark on EMR, Firehose, Amazon EC2, Lambda, if you wanna write some custom code to process. And these consumer applications are sort of the heart of the streaming, uh, streaming application architecture. And then, once you process this data, you will store that in some sort of a repository, either a data lake or uh some sort of uh analytics database for you to be able to use, uh, and derive business value from. So Another show of hands. Who bought something on Amazon on Prime Day this year? OK. So, uh, like me, if you bought something, you were one of the people who pushed Kinesis data streams to a peak of 807 million records per second during Prime Day this year. Um, to give you an idea of the scale of that, uh, The, the global credit card transactions that are processed in a day. Um, we could do that in about 3 seconds at this rate. So, uh, pretty, pretty phenomenal amount of information being processed through Kinesis data streams during that event. Uh, every day, we, over the 3.4 million or so, uh, streams that customers have on Kinesis data streams, we process about 70 petabytes of data. And, uh, zooming in a little bit onto the scale of an individual stream, uh, customers are sending as much as 10 gigabytes of data per second through one single stream. Now, that doesn't necessarily sound like a big number, but it's gigabytes with a, with a big B. And, you know, that's about a 4K movie every second. So, some serious data that we're talking about. All right. So we're zooming in even more from this very large, you know, wide scale that KDS can operate at to the scale of a single Kinesis data stream. So you can have, uh, on an individual stream, gigabytes per second of data of ingest, gigabytes per second of data of fan out and, uh, to your consumers. And then, uh, as part of all of this data, you're processing potentially up to millions of records per second. And this can all be within a multi-tenant, uh, solution. So you can have different applications producing data and consuming data all within a single stream. So Kinesis DataStreams is what we call a foundational AWS service. And uh this foundation is underpinned by 4 pillars. So firstly, Kinesis data streams is elastic. Meaning that it will automatically scale up and down as you need, as your load, uh, necessitates. Um, it's easy to use, which is honestly one of the greatest parts of Kinesis data streams. You don't have to manage any infrastructure yourself. You don't have to worry about patching. You don't have to worry about network connectivity. All of that is taken care of for you because of the ease of, of use of Kinesis data streams. And Uh, it's reliable. So it operates in, in the small with very low latency, predictable latency, and you can scale that all the way out and you get the same performance, um, the same, um, The same performance envelope. So it, it's a, it's a really uh solid building block for any, uh any application to be built uh uh built with. So, and then the last piece, as you would expect from any AWS service, it's highly available. So we, uh, architect our service across multiple availability zones. There are many redundancies that we have built in under the covers. Uh, Ollie will touch on some of that just now. But you can, without having to think about any of these complexities, be assured that you've got the best availability that you can get for a streaming service. All right. Now we're really zooming into the fundamental unit of a Kinesis data stream, which is the shard. So a shard is the atomic unit of scale. Um, it's got very well-defined limits. So a shard can do 1 megabyte per second of, uh, uh, writes and 2 megabytes per second of reads. Uh, we support about 1000 records per second rights, 2000 per 2nd, 2000 records per second reads. Um, and this is the building block from which every streaming application can scale. So, uh, the Uh, one of the interesting things about, uh, how a shard is used is you have a partition key. And your partition key, uh, is something that you specify when you write any data to Kinesis data streams. Um, that is then hashed and distributed across your shards. So it's the, the, the mapping between your partition key and your shards is something that is automatically managed for you as your application scales up and down. And it's this, this level of uh indirection that really helps you build really horizontally scalable applications using Kinesis data streams. Now, There are pros and cons of having this type of a concept of a shard. Uh, it does enable, as we said, things like scaling. Uh, it's, it's a convenient way to manage your capacity in discrete units so you can pay as you use or pay as you go. Uh, it's, it, it gives you this fundamental elasticity, uh, as far as when you're thinking about how much capacity you're using. Uh, but there are some of these challenges. As I mentioned, there's mappings between your partition key and your shards. And sometimes this is not obvious, uh, uh, at first glance. Um, there is also some complexity when things scale back in. Uh, when data gets redistributed across the different shards, where does it go? How do you handle that? We'll get into some of the ways that Kinesis data streams helps you there. And you can also have challenges where your consumers are potentially having an uneven uh load across them. So, uh, shards, uh, although, uh, very convenient as a building block, are not a panacea. And there's some interesting things that we've done, uh, to be able to make them useful for you. So some of the things that we've heard our customers ask for on Kinesis data streams are They don't much like managing capacity. Uh, Servius obviously helps a ton with that in that you're provisioning things in generally abstract units of capacity. But on-demand scaling was something that customers were really asking us for. And so, in, uh, about 4 years back, we launched the on-demand version of Kinesis Data streams where we would automatically monitor the amount of load. Uh, that you were sending through to a particular stream. And we would add shards and merge shards, uh, as needed. Um, This meant that if you had a traffic spike, you know, an unexpected uh surge of, of, of records came into your stream, we would automatically add new shards for you. And uh you wouldn't have to worry about that. That would just happen transparently. Uh, the other thing that customers are also asking us for is the ability to write larger records to Kinesis data streams. So, up until quite recently, as we'll go to, there was a limit of 1 megabyte for a record. And customers had to jump through some hoops in order to work around that. So the, the real, uh, benefit of the on-demand, um, the, the on-demand version of Kinesis DataStreams is you had totally hands-free capacity management up till, you know, the top end of what we see with customers on uh streaming applications which is about 10 gigabytes per second. Uh, this scaling happened for you automatically. You didn't have to set any, uh, any, any kinds of thresholds or anything. It was just, uh, just done as soon as you were, uh, using the on-demand version of Kinesis data streams. And you had the same performance envelope as you would normally have had if you were hand-provisioning or hand-managing your provisioned shards uh in the, in the original Kinesis data streams provisioning model. Uh, and then the other advantages with on-demand, you didn't have to worry about shard hours and, uh, you know, maybe unused shard. Uh, you were simply just paying for the data that you ingested, which was, uh, quite attractive as a pay as you use, uh, model. So let's show you here in these uh CloudWatch graphs, what it looks like to use uh either provisioned or on-demand mode. So you can see a workload here. We, we are happily handling, uh, uh, we have about 5 shards provisioned. We are happily handling a load of about 4 megabytes per second. And then there's a traffic spike. And you can see the amount of uh throttled records, which is the um the, the upper line there in that, in that top graph, uh, jumps up to about 60%. And now, that's not good. Obviously, you're dropping data on the floor. Now, uh, in this case, what happened was, we enabled on-demand capacity, which is something you can do for an existing stream. And you can see that automatically the system detected that there were, uh, that the load on the existing shards exceeded the throughput. It, uh, provisioned, it split the existing shards, and provisioned new shards. And the amount of throttled, uh, throttled data on the ingress side drops down to zero. So this is super, super simple. You can see within a few minutes, uh, totally hands-off. The scaling problem was addressed for them. So Some of the challenges that Uh, builders such as yourselves have had, uh, that we've heard about building streaming applications are. They want Uh, predictable performance at scale. They wanna be able to have costs that are predictable as they scale up and down. Especially say with spiky workloads. And they want the performance envelope to be quite consistent. These are all Considerations if you're trying to build a streaming application. Um, and One of the things that we launched last month is Kinesis On-demand Advantage. Now, there are 2 key features that this new version of on-demand provides. The first is the ability to specify warm throughput. So if you know ahead of time that you're gonna have an increase in load, uh, instead of having to overprovision yourself and pay for, you know, potentially idle shoard hours, uh, you can just say, look, I'm expecting this amount of data to be coming in at my peak. Uh, so I'm just going to give you a heads up that I'd like to have this amount of warmth throughput available for when I need it. So it's really uh simple to use. You simply enable the um Uh, you can either create the stream using the command line tools or in the console. You can just specify what you would like your throughput to be. Uh, or you can even specify this on an existing stream. So, uh, the, the second thing that is, uh, as a feature, I think, of Kinesis, uh, DataStream's on-demand advantage is that it's about 40% cheaper than regular on-demand. Now, Uh, the reason that we've been able to do that is, uh, we, we, we did some, uh, we did some work to figure out that with, uh, committed workloads, we were able to support this price point for, uh, customers that had all the reasons to want to use on-demand with the reactive scaling, with the pay as you use model. But if you were able to commit to a certain amount of usage, we could then provide it to you for a much better price point. So Uh, undermined advantage is, um, Really, really an interesting thing to look at. I, uh, I, I would suggest you take a look at it. It's, uh, you can take a look at that in the Kinesis Data streams docs. The next thing um that Uh, customers have had challenges with is, uh, large records. So Yeah, a large record, uh, if you, if you needed to ingest data that was larger than a megabyte, typically what you would do is you would store it in, uh, an offline, uh, in another data store, say AS3. And then you would store a pointer in your, in your data stream. To that record. And then your consumer would understand when it sees this point or it has to go and fetch the record. Um, and, uh, this presented a couple of challenges. Firstly, there's a bunch of complexity in there that you'd have to build into your consumers. Secondly, uh, now, the amount of data that's going in through a, a particular shard isn't actually representative of the amount of work that has to be done. By a particular consumer. So, uh, you can get a fair amount of, uh, imbalance between your different consumers because these, these larger records are sort of, uh, opaque to the, to the scaling system and the balancing systems. Um, and you can, you can, you can end up with some pretty significant, uh, stalls in your consumer performance. So, uh, What we did was we added large record support. We, we've increased the maximum uh record size by a factor of 10. So you can now send records up to 10 megabytes um in a single shard. Uh, it's super easy to enable. It's just a saving on your stream. And there's no additional cost to use it. And uh one thing that I'll explain here, which is kind of interesting is how does this work with, for those who've been paying attention, the uh 1 megabyte or 2-megabyte read, 1 megabyte write, 2 megabyte read limitations of an individual shard. So how, how would I be able to write 10 megabytes of data to an individual shard with these throughput limitations? So I'll get into that in a second. So the way we actually do the throttling. Uh, for an individual shard is, uh, with something called a token bucket. Now, we keep, uh, a bucket of tokens where as you're using per second, uh, your amount of throughput, uh, we deduct from that bucket the amount of tokens that you've used and we replenish it at a certain rate. Now, in this case, the, these buckets replenish at a rate of about 1 megabyte per second. Um, so, uh, when a large record comes through and you consume in one big burst, all of the bucket, all of the, uh, available tokens. So in this case, there were 1010 tokens in this bucket. Um, That, that's OK because that was able to successfully go through cause we had that burstability, those microbursts, uh, uh, allowances within the, the, the model that we still have for the, um, the, the hard provisioning on the shards. Um, so you can see there that we've, we've exhausted our bursting capacity. And we're able to continue to ride at the 1 megabyte per second level. But what would happen if another burst comes through is, uh, Because there are no available tokens in the bucket beyond the, the 1 megabyte per second that we already have, the, those would be throttled until uh you back off a little bit on your throughput. In this case, you can see we backed off to about 0.5 megabytes per second. And then that token bucket refills at a rate of about 0.5 megabytes per second. So Uh, a little, uh, a little bit of a subtlety to how to think about the large record feature and how it works. Uh, but we think this is a pretty seamless way, uh, to be able to use it. So, uh, one of the, the things that, uh, Ali and I thought was quite humorous when we were, uh, working together for this, uh, talk was, uh, we found out that we were both, um, parents of twins. And, uh, it's an interesting, uh, thing to be working on a, on a, a horizontally scalable service, uh, such as Kinesis Data streams and be a, a twin parent. Uh, we've had to both learn how to scale ourselves horizontally, while our children have also scaled horizontally. So Uh, I'd like to take you through a demo to, uh, to kind of maybe stretch this analogy a little bit far and, uh, show you how we can use, um, Kinesis data streams to handle many things going on at once, such as the chaos that happens in my household. Uh So let's imagine we're all building, uh, we, we, we've built a new product and we want to do a launch. Uh, one of the things that, uh, is, is really good to do is to follow the social media sentiment of your launch. Um, so what we've done is put together a social media sentiment analyzer. And, and I'll remind you that this is a demo that you can actually check out for yourself. It's on GitHub. I'll, I'll put a link to the, to the demo in a bit. Uh, but the scenario is this, at, at 11 a.m. we're going to launch, make an announcement, and there'll be some amount of uptake. Then 5 past the hour, a celebrity picks us up and reposts it. And all of a sudden, the activity around this launch starts to mushroom. And eventually, we reached this viral moment where about 45 minutes after launch, we're seeing an insane amount of engagement and our poor little social media analysis, uh, streaming application is really trying to keep up with all of this. And then eventually, the hype bubbles down. And we're back down to a sort of a baseline of traffic. So that's, that's what we need an architect for. So let's take a look at how we would do this. So on the left-hand side here, we've got our event producer. This will be the, the data feed from the social network. Uh, we're, we're feeding this data. So the producer of the data is sending this data into Kinesis data streams. We then have a stream processing, uh, consumer here, which in this case, we built using lambda. Uh, this could be doing all sorts of things like using a large language model to do the, uh, uh, sentiment analysis for you. And then we store the data results in a data lake, uh, later for using for analytics and for also triggering for sort of further events. Uh, so we'll use, uh, data fire hose to put those data into Amazon S3 tables. So this is phase one, after the initial launch. We're seeing about 100 messages a second. Nice and easy to handle. Nothing too bad. We're, we're well, uh, scaled for this particular load. Um, and I will just show you here the results of a list shards API call. You can see we've got 4 shards open. Everything's going great. Now our celebrity picks us up. And their followers are uh alerted to the, to this launch. And you can see um what happens is we see this pretty significant increase in engagement and our sentiment analyzer is, um, Well, what's actually happening is the, is the incoming records are actually being dropped on the floor because we're seeing more uh input from our producers than the stream is scale to be able to take. Uh, however, we are using on-demand, so the stream does scale up automatically. And eventually, the throttling, uh, uh, records, uh, subsides back down to baseline. Uh, you can see here that the original 4 shards that we had, those were split, and we created some new shards, um, which is great. You know, this is all handling the scaling for you. Um, and as we hit the viral moments, we split those shards even more. We end up with Um, With, uh, the peak of our, uh, of our sentiment, uh, records coming in. And this, uh, this particular workload is now scaled up to about 50,000 records per second coming in of social media posts that we need to analyze. And so by the end of all of this, we've automatically scaled the stream up till 128 active shards. But you can see all the uh shards that we've split there and closed. So, all told, we processed 55.1 million records, but unfortunately, we dropped 2 million on the floor. So there was a bunch of data that we lost. Unfortunately, in this case, uh, due to the, the, uh, initial scale not being, uh, enough, that's, this is how our social media senti sentiment analysis uh application fared. Now, if we were to do the same thing using On-Demand Advantage with our warm throughput, uh, what we can do is we can go into the console and we can just, uh, specify what we would like in terms of warmth throughput for the stream. Uh, you can, it's just a setting and you specify it in, uh, megabytes per second. Uh, this is a really neat tool here, though, in the console where you can actually use either test data or even production data. And you can, uh, get an idea of what you should be setting your warmth throughput to. So you can say, well, I expect this much load, what should I set it to? And so this helps you through that process, which is quite handy. Um, so we start doing this, uh, with on-demand advantage. And you can see we start out at the gate with 128 yards. Even though we've only got, we've got no, we've got a very low amount of traffic, uh, at, at the beginning. And, uh, we see our traffic spike up when the celebrity, uh, Shares this on their network. And as we get to Uh, the, the end of the result here. We were able to process 57.2 million records. We didn't drop anything on the floor. Um, and we got a much, you know, cleaner signal from the social media analysis. And you can see that we didn't create any new shards. We were perfectly adequately, uh, scaled up to be able to handle this load. Uh, and I think that was kind of a, a really interesting demonstration of how warmth throughput can help you with these. You know, business events that you can anticipate, such as a launch. Uh, as I mentioned, this is available on GitHub. If you're interested, you can take a snap there of the QR code. Uh, you can check it out. You can run this for yourself. Uh, it's a really, really interesting example of, um, how on-demand Advantage can make your, uh, peak events a non-issue for yourself. Great. I'm gonna hand over to Ali to take you through the rest of the uh under the hood details. Wonderful. Thank you very much, uh. Awesome. John mentioned a lot of amazing features about Kynes's data streams. As John mentioned, I'm a streaming architect with AWS and I work with customers every day. Um, very often I help them to set up, configure, and fine tune their self-managed streaming storages according to the best practices so they can scale when they have a large event, so they need guidance sometimes and then we help them to scale their infrastructure. Very often, scaling from 1 gigabyte per second to 10 gigabytes per second needs weeks of planning. And it became a point of curiosity for me, how can a status stream can do that without operators doing anything. That's very interesting. So I, um, had a conversation with engineers. I reached out and with John's permission, I got connected with some of our amazing folks and I asked, can you walk me through how you designed this system, how this is different. They shared a lot of under the hood uh facts with me, and I'm here today to share all those under the hood details with you today for the first time. Um, just a refresher to John's, uh, part, Kins's data stream principles are, it should be easy to use, it should be highly available, secure, durable, with low latency at the very largest scale. Millions of data streams, and also um hundreds of millions of requests per second. Engineers shared with me one of the first difficult decisions they needed to make was to how the system should scale. Well, John mentioned that short is a unit of a scale, and then we horizontally just scale up, right? Easy, is it? Well, so, uh, one implementation, uh, which I know other streaming storages also work like this, is to just simply add shards, right? So we have shard one, and then we just add another shard. How many problems are you able to identify with this? One 2. 3 I identified 3. For one, what I'm showing you on this slide, you can see that the messages could get out of order. Why is that? The messages have the same key, by the way. Well, why is that? So, if you pay attention, Um, when we introduced the shard, there was a part that shows the producer uses the hash algorithm to encrypt the key with the hash algorithm. And then depending on how the hash algorithm divides into the ranges, and then each range maps to each shard, the message will belong to that shard, will be sent to that shard. That's how the system distributes messages, right? What happens when we just go from one shard to another to two? Well, the shard range is splits, then the messages were all belong to one shard range, now could belong to another short range. So then message C with the same key could end up in a different shard. Consumer will read them out of order. Problem number 2, Are we supposed to scale back in? Can we just go from 2 shards to 1 now? No. What we're gonna do with the data? Are we gonna just read that data, somehow merge it into another shard? We can't do that. And then there is another problem. Well, so when we want to even balance this load on the back-end nodes, and I will talk more about the back-end nodes later, then we end up with shards with so much data in it, like a shard could get easily to 10 terabytes, even more. How are we're gonna be even balance this load across different worker nodes? Then we need to copy that data all over from one node to another and then from one node to another. It takes a lot of resources, it takes a lot of time and it's not. It's violate the principle that I mentioned should be predictable. So engineers, um, were very innovative in the approach that the way that the shard actually scales. So the shard, we just, the Kinesis data stream just does not add another shard. It splits the shards. What it means is that the active shard, AKA parent, will close. Two new shards will be added, AKA children. And then the consumer first read the messages from the parent, and then it goes and reads messages from the children. So, when we take a screenshot, when we describe shards of a stream, this is how it looked. It looks like. The parent shard is closed, 2 new shards have been opened. And same way when we want to scale back in then two previous parent charts close and then the uh children's chart will be added. All the messages from the producer will come to the new chart, the children's chart, and then the parent chart closed. The consumer can consume the messages from the parent charts until they're finished, and then we can split again and then we can merge again. One good thing about this architecture, as you might have guessed it, is First of all, it just solves the problem of messages not getting out of order. With this approach, we can scale back in without any data loss, without any um problem with message ordering, and then number 3, each of these shards could be in a different worker node. If we have a chart that does not dislit, does not merge, and then the size is reaching some limit, we can decide to close it and then move the rest of it and open a new shard and move the rest of it to another worker. So then we don't need to copy the data all over because we are doing it all, you know, uh, even load balancing on the back end. So here's what happens. Um, the workers are actually those storage nodes that they persist your data. And then because the workers um are in 3 availability zones, we, you see the 3 columns for them and then once the shard closes, then a new shard could open on a different worker with the replicas and other workers, and then the data will go there and then the previous chard is there but it's closed. The producer cannot write data to it and then the uh the new workers accept the right and then the reader will first read the parent chart and then comes to the children's chart. So, another principle that John mentioned is that um Kinesis data stream must be highly available. High availability means that we, for any copy of data that you're writing to Kinesis data stream, Kinesis Data stream actually stores 3 copies of it, and, and then puts them in 3 different availability zones. Why? Because each availability zone is a containment zone of a failure. So then the data will end up in 3 availability zones. At the event that we lose the entire availability zone, still 2 copies are available. So with the previous architecture that I mentioned, um, and also the fact that the, uh, nodes are replicated across 3 availability zones, there is some complexity. One of these nodes always gonna be the leader, the node that accepts the right, and then two other, two other nodes gonna be the replica. When a consumer and a producer wanna read or write, they need to connect to that node. They need to find a way to connect to that node. Therefore, they need to do a discovery. They need to find out how to connect what's the DNS record, what's the IP address, how to connect to it, and then they make a connection. And then if the replica or a leader fails and then another leader takes over, they need to also know that and then can re can make a new connection. So that violates another principle that the Kins data stream needs to be easy to use. Therefore, engineers built the entire um front end fleet and abstracting all that complexity away from customers by exposing a single API. Through a single API you would be able to collect data across various sources. And then bring that into your network infrastructure. So you don't have to manage network infrastructure. You don't have to worry about the scale of that infrastructure. You don't have to worry about any DDoS attack or any um bad action that could happen, um, for you, for the APIs that you need to build, and that API is available. And that API takes care of auto balancing and load balancing that data across multiple availability zones. So now that it is the responsibility of the Kinesis data stream to figure out how the request that is coming in from a customer gets routed to the back end nodes. In order to do that, engineers had to build 3 internal services that is hidden from you. cash service, a membership service, and a timer service. We'll talk more about those. There are some customer responsibilities as well. The consumer and producer responsibility is to be aware of the shards, to know that each Kinesis data stream has shards underneath, and then for a producer to load balance the data across many shards and not exceeding the limits of the shards, and then for the consumer to be aware of the uh processing threads, which one is reading from which shard and doing some sort of a process that we call it the lease management, but we'll talk about that more. Kinesis's data stream will continuously monitor all aspects of the back-end nodes. If you add another consumer. With other streaming storages, you need capacity planning all over again. Because you need to make sure there are enough network throughput and disk throughput uh to sustain the throughput that is coming in and still have buffer for all the background operation and also have enough capacity for an additional consumer to read the same data. With Kinesis DataStream, you don't need that because Kinesis DataStream has a feature enhanced fan out that recently made a new launch to support up to 50 distinct consumer groups off of a single Kinesis data streams. So let's talk about that um API layer a little bit more. So for those of you who raised hand and said, um, you're using Kinesis data stream, thank you for that. But then the chances are the data that you're writing today is stored in the same node as somebody else in this room today. So the API needs to make sure every request that is coming in is authenticated and the user who's trying to access has access to access the resource that is indicates and also make sure that it's not exceeding the coda overdriving those back end nodes and also making sure that they're and then encrypting the data with uh with the keys to encryption in transit or TLS and also making sure that the data is encrypted with the customer managed key or with the AWS key on the back end. And then also, um, if you have a requirement for using IPV 6, a single API as part of a dual stack APIs will give you IPV6 or IPV 4 through 8WSDK you can enable that. If your requirement requires or uh you're required to use FIPS endpoints in the US golf club, you can access Kinesis data stream with FPS endpoints, so you don't have to build that. If you want to do access control, um, you have access to the uh resource based policy for controlling the access to the, um, resources at the stream level and also you have, um, you know, access policies through the IM, uh, identity, um, in AWS, uh, identity and access management or AWS IM. So, the front-end service, each of those front-end services do that 100s of millions of times every second. Let's, let's see how it does it. So these APIs need information regarding with which member wants to access which resource and then which shard belongs to which stream and which member so that information also, you know, could look like this also indicates who is the leader node, who is the replica node, and then, um, that that's how the routing happens when the request comes in. So a naive approach is to just store that in the database and then every request that is coming in, we just go and load um with the shard ID or with the Kinesis uh stream ID and then load that information from database and then find which node we need to route the request and then we do that. Well, we know this design doesn't work. Why is that? Because if we are building cases data stream for a massive scale, then we need a database service even bigger than that because, um, we, we need to make sure that the service is reliable. Also, the latency wouldn't be very low because the databases tend to have, you know, double digit, you know, latency, and then the API latency will be even higher than that. So like any other engineer that would say, let's put the cash in front of it. Would this work? Well, this definitely improved the performance, but not always because what if the cash fails, then we need also a cash service that is um giving us, you know, with the capacity that is even bigger than the Keynes' streams and also the cash could get out of sync with the database for a variety of reasons. So engineers went back to the basics of how a database actually work. If you think about it, what a database does for us is gives us a consistent view or a snapshot of all the change blocks. For all the change logs that are coming through, it will give you always the latest and accurate snapshot. At the time that the read occurs. So engineers thought, hmm. What if we just replicate that to all work, all the different components, the, uh, front end host and also the cache layer. So then each of these components independently can build that snapshot so then when the request comes in, we can just read that information from the cache in the memory of the worker. Does this design work? Those who think this works, raise your hand. Great. Not quite. We're getting there, but not quite. So the problem with the different with that design is we are operating a distributed system, and then this distributed system could go out of sync for many reasons. Node could fail, change log could be replicated, get processed twice, could get processed out of order, the system could get out of sync, and then it wouldn't work. So for that reason, engineers added additional information to the chart map entity to indicate how long this record is valid. So if a node has any record, it also checks if this time has passed. And if this time is passed, that means this record is stale. So it needs to go and load, get the new record. All right. So let's put that in place. Does this design work now? Raise your hand if you think this works. OK. Still, still one more wrinkle that we need to iron out. Well, the time runs differently, turns out across distributed systems. So when they want to compare the time, they should compare with what, what, with a reliable clock. What is the reliable clock? Is the system time at different components reliable enough? No, milliseconds matter here. We're talking about hundreds of millions of requests every second. And if, and if you get the request that is going to the wrong node, and you get an error, and then you have to retry again, that's not a reliable system. Therefore, engineers built another service called Timer Service. So a timer service is the source of truth for the time across all these different components. It doesn't matter what system time they're showing on their system, they need to compare that time, time to live with the timer service. And they constantly pull the timer service in order to refresh that, and then they will use that to compare with the time to live. And then if that record is a stale, then they will go get it from the cache. If it's not in the cache, then they will go get it from the data, database. OK, one last thing, does this design work? Those who think this works, raise your hand. Well, that's, that's what you got, so this works. All right, so with that. Let's talk about the consumer responsibilities. Um, as I mentioned, consumers need to be aware of the sharks, because we are processing the data in a distributed way as well. So there are certain aspects that the consumer needs to manage for one is the state of which processing thread which worker is consuming from which chart. So then the mapping between the chart and the consumer's instances or consumer processing threads needs to be kept somewhere and then that needs to be constantly monitored and managed. So there are some best practices for consumers if you're writing your own consumer application from scratch and you wanna write your own client library, make sure that you do proper handling and make sure that you monitor your clients and you are doing a good job of keeping the track of the estate. If you're using any of these native services or third party applications, there is an integration already there between Kinesis data stream and these applications. So because of that native integration, you don't have to, uh, write any code and you know, as soon as the data lands into lands in the Kinesis data stream, you can consume it using any of these, um, services or third parties. And if you need to write code and you do not wanna use AWS Lambda for that, then, um, Knes's client library takes all the heavy lifting, all the estate management. So unless you're really interested in doing this, you know, Kinesis client library is the easiest way to package it with your code and, and write a custom code to consume from a uh from a Kinesis data stream. And recently Kinesis's team, uh, released a version 3 of Knesa's client library. How many of you were aware of Kinesis's client library version 3? Great. How many of you have, uh, moved to version 3, upgraded to version 3? OK, so if you haven't done already, it's the best time to do it because, uh, there are so many enhancements in it. Um, one of those enhancements, my favorite, is that it detects which one of the processing trails are overloaded and then it even balances. It basically takes the lease from one and then it can override and takes the lease from one worker, give it another one. It even balances the load across workers that will, uh, return to you cost benefits. All right, going back to this. So, When you use Kinesis client library, Kinesis's client library manages the estate across 3 separate dynamo DB tables. The state table um keeps track of of which one of the workers is leader. The lease table keeps track of which one of the workers is and processing thread is consuming from which um chart and then how's that subscription and mapping looks like and then there is a metric table that uses in order to Kinesis client library version 3 users in order to know which one of the workers overloaded and then um even balance it. It also emits all the client related libraries to uh Amazon Cloud watch for you so you don't have to worry about that integration as well. It has components to do that. So on the left hand side is the worker which is in charge of polling. There is on the right hand side the processing threads, and these threads are decoupled from each other. So those who have done multi-threaded programming know how difficult it is to run a, uh, multi-threaded programming without any memory leak and other issues. And then there is a scheduler which is acting as like a timer runs everything. Here is how a lease management, uh, record looks like. It has a key. It has a checkpoint, so each of the processing threads as they progress, they frequent the checkpoint, and the checkpoint information is stored in the lease management table and, um. It also has a a lease expiration time similar to the time to leave. The purpose it serves is very crucial. When a lease record is not updated, means that this time stamp is not up to date. It means that the processing thread has failed silently. And it detects it and then the other worker will take over it and then the, the whoever wins or which one wins, the first one obviously who takes the lease, that one will take over from another worker. What if the, when the leader fails? So when the leader fails, another worker basically will take over and then if a worker fails, the leader could take a lease from the previous worker and give it to another worker. So that's how a distributed system. And a stateful distributed compute system should work and it works with Kinnes's client library. So let's talk about the producers now. Producers also need to be aware of charts in a different way. Is it efficient if a producer for every single record makes an API call? When I speak with many customers, they acknowledge that it's not efficient, but they do it anyway because they think they get the lower latency this way. Turns out network calls are not cheap. Network calls are not free. Um, network calls have overhead, as I mentioned, every single request needs to be authenticated, check for access control, check with the access limits, and then routed through. So if you're sending one request for every single record, and by the way that record is very small, you're not using it efficiently. So we recommend customers. To batch up the records into larger payloads and then also if they is possible, send those larger payloads in batch as well. Kinesis, data streams have two APIs for writing records. It's PRecord and put records. So, we recommend anytime possible you use put records API in order and, uh, in order to send multiple records with a single AP network call. And then with input records you can put up to 500 records. What if the record, and what should be the size of that record? We'll talk about that more. If you're using these native services or those third parties. Those, there is a native integration. There are native connectors that will help you to write data to kinesis data streams. So those best practices already built in. But if you're writing your own code and you wanna call the APIs, make sure that you also do aggregation if you have very small records. We recommend the record size should be somewhat around 10 kilobytes. If your record size is way smaller than that, one of the techniques is to build larger payload out of a smaller pay, uh, records. So let's say we have click stream record which is only 400 bytes, so we aggregate them into a 1, uh, 10 kilobyte batch, and then we can even compress that so we can, we can even pack more click stream, um, records and then compress it to become a somewhat around 10 kilobytes and then. Uh, we can use the put records in order to send all of that in one, network call. Um, although it is counterintuitive, you will get better latency and you will get better throughput this way because if you have a very large throughput of click stream data, which is small, um, the network overhead is gonna be the one that acts as a bottleneck for all that throughput to move through the pipeline. And if you do not want to be worried about these best practices and if, if it's always been followed, if you do it, you know, implementation of them correctly, you can use Kennesis's producer library. That's another library which is, by the way, open source and, and I'll provide the link in a moment that you can use in order to aggregate all the smaller records into larger batches, even compress them, and there, there are options that you can enable or disable. And then you can also put them into um once you put them in the larger batches, then it has a buffer to buffer them and the buffer is reliable if if a node fails then the you know um it it it has a system that you can basically make sure that uh the records are there and then the collector and the retrier and limiter will help you when you hit the throttling so then it retries to make sure that the buffer gets flushed into the um Kins data stream. With limiter to make sure that you're not exceeding those codas, you're not exceeding the limits that the Kansas state your stream imposes. And then it emits those metrics in terms of how many records get throttled, how many records went through, how many records were successful, what's the latency of the pipeline and everything into Amazon CloudWatch. And then it, it reliably can uh work across many of the instances of your producer. So I will leave you with additional resources here um if you want to uh get more familiar with the Kinesis data stream um and you wanna get more details uh you can go to the first QR. The second one is the demo that we shared with you today so that will take you to the link to the GitHub to try out the demo and if you want to get more, um, um, you know. Information in terms of reading the code or finding the project of the Kinesis producer library or Kinesis client library, you can go to those two on the right side QRs that will take you to the GitHub, um, and you can check those out. So, um, what I would like you to do is after this session, um, try out our demo and see how you can, how Kate to stream can deal with the peak of, um, going from 10,000 to 100,000 or 500,000 or even millions, millions of records per second. And monitor the whole pipeline uh in a live demo in your environment that that comes with a lot of best practices that we shared today and you can use a reuse a lot of those components if you're writing similar application you wanna build a serverless pipeline that it all scales out by itself, um, using that as a baseline for your projects. And then another um call to action is please please please um you will receive a link from the survey and please fill out those surveys because those are really important for us. We use your feedback in order to improve the content, improve these sessions for the future, and those surveys are always important for us with that, I would like to thank you all for coming today, staying late with us tonight, and, uh, sitting through this presentation. Thank you.