---
video_id: imnB4Cmob4g
video_url: https://www.youtube.com/watch?v=imnB4Cmob4g
is_generated: False
is_translatable: True
summary: "This session, \"AWS RTB Fabric: Real-time bidding workloads with your AdTech partners (IND379),\" introduces a new purpose-built AWS service for the AdTech industry: AWS RTB Fabric. Presented by Sergio Serra, Fernando Gamro, and Duke Chow from Ilmo, the session addresses key industry challenges like high latency, excessive costs, and slow partner integration. RTB Fabric is a regionalized service designed to slash typical cloud infrastructure and networking costs by up to 80% while delivering millisecond latency (even microseconds with modules). It simplifies connectivity between Supply Side Platforms (SSPs) and Demand Side Platforms (DSPs) using \"gateways\" and \"links\" that route traffic efficiently, often eliminating the need for traditional, expensive load balancers. The service includes built-in \"modules\" for traffic management (filtering, rate limiting, error masking) and supports third-party modules for data enrichment. Duke Chow shares a customer success story, highlighting how RTB Fabric reduced integration time from weeks to days, decreased timeouts, and increased win rates and revenue. The service aims to be the foundational infrastructure for a composable AdTech ecosystem, allowing companies to focus on innovation rather than plumbing."
keywords: AWS RTB Fabric, AdTech, Real-Time Bidding, SSP, DSP, Latency Reduction, Cost Optimization, Programmatic Advertising, OpenRTB, Infrastructure as Service
---

All right, am I audible? Great. How many of you believe that cloud computing is too expensive for RTB fabric, well, for, um, uh, cloud, uh, sorry, for RTB workloads, and, uh, how many of you believe that the latency that, uh, the clouds deliver is not necessarily at the level at, uh, the RTB workloads need? Hi everybody, my name is Sergio Serra. I'm an R tech veteran and uh I recently joined AWS to lead RTB Fabric, a purpose-built, uh, service for RTB workloads, uh, that will help address, uh, and will help address, uh, these two challenges and these two questions I just asked, along with many more, um, many more challenges that are endemic to the tech ecosystem. And uh um let's start with taking a look at the agenda today, what we will be covering, uh, first of all, today I'm actually joined in this presentation with Fernando Gamro, our senior solution architect, and, uh, uh, Duke Choo, uh, the chief technology officer of one of our, uh, uh, customers, beloved customers, Ilmo. And, uh, just jumping right into the agenda, uh, I will start with, uh, listing down and distilling the key challenges of, uh, uh, art tech industry and, uh, then, uh, Fernando will help diving deeper into, uh, the intricacies and architecture of RTB Fabric. Uh, then we will try to understand how to onboard into the service. You will see how, how easy it is actually. And we look at the capability of the service in terms of observability, in terms of metrics and telemetry, and then we will go to probably what I believe to be the hottest topic at the moment, which is how we can help you release those cost savings that RTB Fabric is supposed to help drive. Um, then we will, uh, hand it over to, uh, Duke, uh, because at AWS and Amazon in general we are customer obsessed and we really believe that there is no better way to talk about our products than having our customer talking about the experience they've been having with the product itself. And finally I'm gonna, uh, take it back and, uh, just drive some insights and key learnings that uh we went through today. With that, uh, let's start with the challenges that are endemic to the ag tech ecosystem today. Starting from the top left, uh, you can see that um. The very first, uh, natural problem is for demand and supply to discover each other. You are a DSP. You wanna know what supply side platforms. You wanna know what publishers are available, and if you are, uh, SSP on the other end, you wanna know what DSPs are specialized for, uh, specialized for your, uh, potential supply, especially if you are not an omni-channel SSP, you wanna go, uh, by vertical, you wanna focus, for instance, on performance versus brand demand or in-app versus CTV or other channels. When you, once you realize who the partners are, uh, and you decide to peer with them, the next challenge is to go into integration, and the integration, of course, is based on the leg the legal and business bit as well as the integration from the most, uh, technical standpoint. And speaking about the technical standpoint, we have learned from our customers that a new integration can take. Anywhere from 34 weeks to actually 5 months depending on the, uh, you know, on the size of the the platform that you're trying to integrate. Once the integration is done, the other problem of course is how do I make sure this integration delivers um the latency we need? How do I make sure I co-locate? I go as close as possible to, uh, my, my partner's workload and, uh, uh. Another problem that is very endemic to the industry, and I know this from firsthand in my previous experience is transparency, right? So we are an industry that moved from 2nd prize to 1st prize because of, uh, the, the black box when someone, some, some publisher sends a bid. They don't know the response that is coming back and what processing happened behind the scenes. Same, same thing actually holds true for the DSP. They submit their bid and they don't know what's going to happen. And for the SSPs, if they are reselling again, they have no visibility into what happened in between. Uh, and this leads also to data fragmentation, uh, which is, uh, a problem that is endemic to any, uh, two-sided marketplace like this one. You have demand that knows perfectly, perfectly well, uh, what, what are the campaigns, what is the demand. for specific uh advertisers, but they don't know uh how the supply is gonna behave and the the supply side knows very well, uh, about their users, about their placement where the ad will be rendered, but they don't understand the demand landscape necessarily. Uh, finally. We have a team on models optimization. Uh, you know, you might think that sometimes DSPs do the, the hardest when it comes to ML and artificial intelligence, which is of course true when you think about, uh, finding the right, uh, ML model for, uh, improving your roles when, uh, you talk about, uh, budget capping, uh, frequency capping, budget pacing. Um, but on the SSP side, there is also an equally important problem when it comes to yield optimization, right? So dynamic margins, dynamic floors, add quality. So ML and modest optimization is a, is a problem that is common across the marketplace, so demand and supply. But the very common denominator right among all the uh tech, uh, companies is cost optimization. In fact, uh, the lingua franca, when you talk to any uh tech leader, especially on the technical side, is what is your cost per billion. And so, um, that's exactly why we decided to, uh, come up with a new service which is the first, uh, RTB purpose built service for, um. Real-time auctions uh called RTB Fabric and the service really allows you to achieve many benefits for your RTB workload starting from top. First of all, you can connect no longer in a matter of weeks or months but actually hours. And uh you can connect with the new DSPs and new SSPs, but more importantly you can now co-locate right away with third party vendors, so third party applications, and we will dive a little bit deeper into how this is achieved through RTB Fabric. But the second thing that is probably the most important for many of you is, um, RTB Fabric allows you. To really save up to 80% when it comes to typical cloud infrastructure costs and networking costs, and so this is of course a huge benefit that allows and democratize access to hyper scales for small DSPs and small SSPs too and helps improving the bottom line for the big ones too. Um, all of this is, uh, also achieved, uh, in milliseconds, uh, you know, when you talk about, uh, RTB fabric, keep in mind it is a regionalized service, although we allow to communicate to the public internet as well, so it's not only for companies that are within the RTB fabric service, but you can also talk to your DSPs that are outside, uh, on the public internet or your, your DSPs if you're on the other side of the equation. Um, but, uh, uh, when it comes to, uh, third party integrations, uh, that's where we introduced a new, uh, very novel concept, uh, which we call modules. Modules are really applications that run within the network path, so they are ultra fast, can be built by either AWS, can be built by you, so SSPs, DSPs, or. Third party vendors that work on data enrichment work on identity addressability and all the the the business logic that is helpful for RTB workloads. So specifically these are container images that are deployed within your RTB fabric gateway and so by doing so. We are able to move the latency from milliseconds really to microseconds. So in fact if you look at our P99, we are really talking about 500 to 550 mil microseconds when it comes to to talking to models. Uh, I will just cover one last slide before handing it over to Fernando, just going through the key components of RTB fabric. On the top left, uh, you find the, uh, RTB gateway. So, uh, keep in mind that we try to abstract away, uh, the, the jargon of hard tech when it comes to bidder, um, you know, uh, DSP, uh, SSP publisher, uh, buyer, seller. So we, for, for as much as we are. Concern we have a responder that responds back to bid response uh to bid request, and we have a requester that sends bid request to another, uh, responder and so you have uh RTB gateway as a requester and an RTB gateway as a responder if you are acting as a responder, specifically for the second category. So if you are a responder, the beauty of the service is that it also comes bundling, uh, bundled with a, um, very tiny layer of load balancing. We do, uh, uh, DNS traffic distribution and by doing so we can be extra lean and extra cheap and of course lowering the cost we can reflect this upside into the price into a lower price for our customers. And so again if you are a DSP or if you are a bidder or if you are even an SSP receiving traffic from publishers, you don't need to use another self-managed or managed load balancer. You can just use RTB fabric, uh, to process all your incoming. Um, all your incoming traffic. And then finally, as I mentioned, we have, um, uh, advanced traffic management models. These are the models that are built by AWS and come bundled with the price. So specifically we have, uh, uh, open RTB filter. So if you are receiving supply from a requester, you can decide to filter request based on any selector of the open RTB path. And so the good thing is that, uh, you can decide to filter those requests before they even. And hit your fleet, uh, saving a bunch of CPU cycles. Um, the other module that is offered bundled into the service by RTB Fabric, so included in the price is a rate limiter that allows you really to set a specific limit of, uh, QPS you wanna achieve from each one of the links you have. So each one of the, um, SSPs requesters that are sending, uh, requests to you. And the last one is a error masking which really allows you during deployment if you're uh if you are terminating some instance or recycling instances you don't really wanna have spikes in latency that your SSPs will see or returning, you know. HTP status codes because we know SSPs very often use circuit breakers so you don't want to have fluctuation in the in the incoming supply. We allow you to instead wrap all those errors into a generic 204, which is really a no bid and so the temporary. Uh, downtime can be covered by a bid and then whenever you are back ready, uh, you will not see any, any, any fluctuation in traffic. With that, I think it's time, uh, to dive a little bit deeper into, uh, the architecture of RTB fabric, and I would like to hand it over to Fernando. Thanks Ajo. Hello everybody, uh, I'm Fernando, um, as you mentioned, I'm a solutions architect within AWS. I've been working quite closely with the, with the team, uh, helping to look into the service and get it on boarded, uh, with customers and that sort of thing, so. Now that we've covered the basics, let's dive deep on what the RTB fabric architecture looks like, uh, covering those components, uh, in, in a bit more detail, but first. There's, uh, a bit of hands up. How many of you are dealing with programmatic advertisement, um, you know, on boarded uh SSPs, DSPs. Cool. So we have a fair, fair few of you. So for those less familiar with, uh, a tech programmatic, let's cover a bit the standard set up so that we have here. Um, so on the left hand side we can see the publishers which basically are our digital advertisement, um, in the ad time and space they are always on the lookout for best partners, best deals, cost effective platforms where they can actually get these ads from. And they are looking for affordable subscriptions and those advertisers or that chain of um. Ad campaigns that is giving them the best back for for the for the space that they are putting out there so. On the other hand, we have the ad agencies, and these are the companies that are managing the launch of the distribution of those campaigns. And in the in the middle, we have this fabric. Um, we have a supply side, we have a demand side. And the idea is to be able to connect us to in a very easy way and that's what we are building the RTB fabric for. Um, SSPs will help you to connect with the publishers. And DSP is connect the uh ad agencies and the idea is to build this ecosystem in an easy way. So that's where the RTB fabric comes uh comes uh to play and we can see that as leveraging this EC ecosystem within AWS to help that on boarding. So we covered the first component is the gateways, uh, as Sergio mentioned, the gateways is the core networking feature that we have in RTB fabric. You will see that there are 2 types of gateways. We have the queer site, which connects to the supply, and we have the responder which is connecting to the demand side. Now, The connectivity between both gateways that they sit in each of the um different partners is done through what we call the link. A link is just basically a Network path that we create between the two gateways. And then on top of that, we apply the modules. Uh, as Sergio mentioned, this is a Management components that can configurably be attached to the links and they run in line so they are not adding extra latency to this and they help you to do filtering, they help you to optimize and even control the RTB traffic. Now because this implies that you are sitting within AWS same region, it means that you would need to have those partners co-located. But we also have the capability to allow both the supply and the demand to communicate to external partners, uh, and this we do it with uh what we call the uh external links. We'll cover those more in detail, but let's go deep into each of these components and how they look like. So let's start with the requester gateway. The requester gateway, in reality we try to make the least amount of changes to your applications. So you have still your SSP applications still receiving traffic from your publishers, but instead of having to leverage traditionally from a BPC and a gateway which can be very costly, very expensive. The idea is that instead of doing that, we are gonna on board through the RTB Fabric Archestra gateway and that's gonna help us to create a network interface. That network interface is created in your own account and that allows that communication between the SSP application and the gateway in milliseconds, really fast connectivity, very low latency, which is what we want to achieve. On the other hand, when we are looking at the responder gateway, exactly the same topology applies here where we have a DSP application that traditionally you will have a public endpoint like an application load balancer or even if you are doing something internally or something like cloud map to lower that that cost cost associated to the load balancer, you still have to maintain that. So we don't want to make changes to that necessarily. So the idea again is the same is we on board a responder gateway, we create a network interface on your account, and then we enable that traffic to go through, but we still take advantage of your load balancers um in, in this case, so. Right. So once you have these gateways, we're talking about how we create that connectivity between them and this is where the links come to play. These, these are the core connectivity mechanism that allows you to establish the connections between that supply and the demand partners on the ecosystem. We talk about internal links, standard links. And then they just basically helping you to connect when both partners are in AWS onboarded to RTB Fabric and in the same region. The links need to be initiated by one of the partners, uh, and the other partner needs to accept it, so there is no automatic trying to like the discovery is not automatic. You need to exchange those IDs to be able to do so, but once they are created, they will provide a private and a secure connection between the two partners. Uh, it all happens within the RTB Fabrics service. The traffic, the traffic will flow through this link and it's a single millisecond because as Sergio mentioned, we are taking advantage of this uh DNS based um balancing capability. And they are also very scalable. They will support millions of queries per second as a throughput, so you can really scale it up. Um, and on top of that, we will attach the modules, but we'll cover that next. Remember that we mentioned external. So let me introduce you to the concept of the external outbound links. Here is when we have the need for a Rochester gateway sitting in RTB traffic to talk to a DSP that um lives outside different region still in AWS potentially or in AWS but not on boarded to the RTB fabric or even all together outside AWS. And similarly we have the external inbound links and that will help you to get connectivity from your supply partners that are not in AWS connecting through the responder gateway and talking to your uh. DSP application Right, so let's move on now. Um, let's cover the modules. As we mentioned, the modules are configurable traffic management components, and that will help you to bring your own applications, potentially, bring your partner applications securely in a compute environment that then is used by the real-time bidding. Um, they run in line. So we are trying to minimize the amount of throughput uh or latency that is added by them and they help you to define whatever logic you want but initially filter optimize and control that RTB traffic. They are supported, they are designed to support containerized applications, um, and eventually you can bring even your machine, machine learning models or your, uh, GAI agents to, to do additional enhancement of that transactions. Mentioned earlier on that modules are attached to the links. In reality they are not standalone services. They operate in line within the link infrastructure between the requesters and the responders, but they are attached to each of the sites. So each partner can create its own set of modules or attach its own set of modules. Right, as As you mentioned earlier on, uh, at lunch we released 3 built-in modules, and these are the rate limiters, the open RTV filter, and the error masking modules, um, that is gonna help you to protect those workloads. OK, so if you remember when I was describing the RTB, uh, fabric, the responder gateway, we were talking about still having that load balancer there between the gateway and the DSP application. But that's gonna still incur some cost on the low balancer. Now if you have run, if you're running your DSP application on an EKS cluster, for example, or you are deploying into, uh, EC2 instances but leveraging easy to out scaling groups, we can take advantage of that and allow you to completely remove the need of that load balancer and that's what we call the managing points. So the idea behind the manages points is that. Instead of we having to specify the domain where the traffic is gonna flow to for that load balancer, we have the capability to query either through the EKSM point or the auto scaling group what are the IP addresses of the nodes or the instances that are part of your cluster and then record that in a private hosted zone in rows 53 and we use that. But the the the the responder gateway we uses that to balance the traffic across all your nodes effectively removing that that that need for having that load balancer simplifying your architecture reducing your cost and still maintain that single mil uh digit millisecond latency. Right. Security is always paramount at AWS is a top priority for us. Hence, we had to make sure that the RTB fabric was built to ensure that the traffic is private and encrypted. So when you create a requested gateway, for example, you're always gonna get an HTTPS endpoint. Uh, all the traffic that happens between the requester and the responder gateway is, uh, secure, is private. But that doesn't mean that your responder applications also need to be uh listening on HTTPS. We support you to have the, the last mile, call it last mile, uh, to be unencrypted to support HTTP. Now if you still want to do that end to end encryption, that's totally supported. Um, but you need to maintain your fleet of certificates on the nodes because now we are not terminating on a low balancer, especially when you're using a manage endpoint, so you have to have those TLS certificates on the node. And if you're using a private CA, and this is quite important, we need that CA certificate because the RTB fabric, the gateway, is gonna do a proper TLS validation, um, so quite important to keep it in mind. Right, so as you mention, as we mentioned earlier on in Sergio cover earlier, it's very time consuming to on board, especially when you have different partners that they, they have to spend weeks or months to do that integration. They might have very complex network setups as well, even if they are in AWS. Um, and there is a high operational overhead. So let's cover how you can on board to A2B fabric with three very simple steps, uh, which is gonna help you to create those gateways, create the links, and then just start routing the traffic, um, you know, and start taking benefits immediately for, for those partners that you are on boarding. So let's start from a scenario where we have An SSP that is in AWS and a DSP that is also in the AWS both in the same region but they're all talking over the internet, um. So, we're gonna cover how to onboard those ones. And additionally, we're gonna cover how to start communicating with external partners as well and you'll see, you'll see how it is also to do so. Right. So Both the DSPs and the SSPs need to create a gateway um within the RTB fabric. Now this can happen in parallel. There is no sequence here. I don't need to tell DSSP you need to create the gateway before the the DSP creates the gateway. So, but for the presentation, let's cover this this in sequence. So the first thing that we have to do when we have this. Requester or the uh the need to SSP to create the requester gateway is to identify the BPC and the subnets where the SSP application lives. We want to ensure that the network interfaces are created on those subnets so we, we can take advantage of that BPC connectivity. We want to create a security net, uh, group because we always want to attach a security group to the network interfaces that we are creating. But that's to allow traffic coming from the SSP application into into the fabric. Ultimately what we get is a domain name. This domain name is gonna be important because it's the one that we are gonna be using to instruct the SSP application to start forwarding traffic to the RTB fabric. Similarly, the DSP is gonna create their own gateway, um, that's just purely for the responder side. But here we have a bit more information to provide. We still need that BPC, we still need that subnet information, but we want to know. The protocol that the DSP application is listening on, if it's listening on what, what is the port that is listening on as well, and also the domain name. Remember we're saying for those not managing points we need to know the DNA's name for the uh load balancer, for example, that it needs to point to. So we provide that information. Again, we also need a security group to created. And at this point in time, once both parties have created the gateways, they're ready to share that information with each other, so they have to share the ideas of the gateways that they've created, and then we can start creating the links. So. Again, in this case, we are gonna get the requester to create the link and the responder to accept the link. One key point to make is you don't need to create a requester or a responder gateway for every link that you create. gateways support multiple links, all right. So, what we need to create that link is for the responder gateway in this case to share the ID and the requester then just creates the link using the peer gateway ID as the responder ID. Now, by default, when you create a link, all the traffic is gonna be encrypted end to end. Again, we want to have the best security posture here. But if the responder application is listening on HTTP on link creation, we need to be explicit that we want to be able to use HTTP. Again, it's an opt-in, explicit opt-in that you're on purpose saying, hey, I, the last mile is gonna be unencrypted. Once the link is created, the request there. The SSP is gonna say, hey, this is the link I created, now go and accept it. So the responder goes and accepted the link. At this point we're ready to start sending traffic through the RTB traffic, uh, RTB fabric, sorry. So all we need to do is to change that endpoint that it was configured on the SSP application and said now we don't want to use that endpoint that was directly talking to that DSP. Now we go through the RTB fabric, so we build the URL. The URL is very basic. You take the gateway domain name that we got on the requester. We attach the link ID and then we continue using the same um the same um path that was attached at the end of the request. So, that's simple. Right. Once we have traffic flowing, then you can start deciding which modules you want to attach. Again, each side has the capability to attach modules that fit best to their requirements, so, and each of them are independent, so. In this case, for example, we are attaching a RTB fabric open RTB fabric filter that is helping us to only accept traffic that uh has the US dollar as the currency specified but as you can see it's attached on the gateway ID that is associated to the requester gateway um you can have more than one module attached to each side. And you can also build dependencies uh between those modules. So if you want the modules to be executed in a particular order, you can specify that as part of the CLI command. Similar, the responder also can attach models to their site. And in this case, all we are just doing is attaching uh a rate limiter which is just basically saying, OK, I'm only gonna be accepting 5 requests per second. When the gateway drops that that request because it's exceeding that rate as Sergio mentioned, we are going to be getting a no bid response, so we don't really drop it. You still on the requester side, on the supply side, get a response back. It's a no bid response, so. Cool. So we've seen now how a DSP and an SSP can integrate when they are in the same region and both in AWS. But we mentioned earlier that we also support partners that are not in AWS or not integrated to uh the RTB fabric. So in this case we want to create an external outbound link so that is the speed that is on boarded now can talk to a DSP that is not in. Uh, in AWS, so we want, we want to create an external outbound link. So by doing so all we need to do is to specify the public end point of that DSP that we want to now send traffic through, um, and that's as simple as that we just create that and ultimately when you are sending the request to the uh requester you just use that link ID and it knows that it needs to send that, um, external back. Similarly, we can also leverage the RTB fabric for traffic coming to DSPs that have been onboarded. Uh, so in this case, what we do is we create an external inbound link. Here we don't really need to provide any information because when we create the internal inbound link, what we are doing is creating a domain name for you to share with your SSP partner so they can send traffic to you, all right? Cool. So we've covered implementation. We've covered the, the details of the components. So let's talk a bit of, of observability. Uh, what do you get with RTB fabric? So, first let's look into logging. We are using cloud watch delivery. So, but it's quite important to keep in mind that Logging is configured at the link so we get a lot of information from the link and because the nature of RTB traffic where the volume is really high we're we're expecting. In the in the order of billions of queries per day, for example, it's quite important to be able to configure sampling for errors or or filter logs that we create. Now we don't really use cloud watch locks directly. We use cloud watch lock delivery, so that means that you'll be able to bend your locks either through cloud watch locks, Amazon S3, or Kinesis Farhos. But this is not enabled by default. So if you create a link, you're gonna need to configure the log delivery if you want those logs in. In your account. Now with the metrics is slightly different. Metrics are owned by default, um, and the metrics are also delivered to your account. So you get metrics for each of the generated links and for those metrics we have what we call dimensions. So you're gonna get information about the HTTP. Status code. So every request that is coming like a 200, 2002, 204, a 500, you get that information on the metrics um for all the traffic going through. But you also get the statistics so you can see P90 P99 traffic going through the RTB fabric. Those are metrics that we also get um delivered to to your account and you also get raw uh link traffic so you're gonna get information. Like total request, latency, and so forth. And because cloud watch metrics are integrated natively with your account, you'll be able to build your own dashboards and create your own alarms so you can respond to problems as as they occur. Cool. So we've covered now observability as well as dive deep into the components, dive deep into the onboarding with those three simple steps, but now to complete the picture, let's focus on the cost and performance because this is where it's gonna be super important. So For the RTB fabric, we've built the price model to align with RTB economics. We are focusing on high volume of transactions, so quite important. As a result, you don't pay for the RTB fabric gateways as you create them. You're only paying for all the requests that you sent, not even the ones that you receive, so there is no upfront commitments. And you pay for the number of RTB requests or responses that you send monthly on a price per million basis. Because there are two types of links covered internal and external or external and external, the prices are gonna vary based on the traffic that you send, based on the type of link that you use, OK? So that's another dimension that you need to take into account. But we will apply a volume-based tiering discount, so the price will differ for your 1st 2 trillion transactions and then anything above those 2 trillion transactions per month to support the needs as you scale up on RTB Fabric. Now there is a standard size for the RTB transactions included in the transaction price and with each RTB transaction we include 2 kilobytes of data for free. Now when you exceed the payload for the response of the request exceeds those 2 kilobytes, then you're gonna be paying for those transactions, that that uh extra extra payload on a price of per gigabyte basis. Now there is also a fee for the not bid transactions, but that's a much lower rate than for the bid transactions, right? When it comes to performance, you can really rely on RTB fabric to deliver. You're gonna get consistent single digit millisecond latency even with millions of queries per second, so that's pretty impressive. Consider a traditional integration where you see often uh 50 to 100 millisecond latency. RTB fabrics can help you to deliver that sub 10 milliseconds consistently. And also RTB fabric is available across multiple regions. So you want to place your workloads close to your partners. So we we we're reaching for global uh global scale here. So. Right, so far you've seen the architecture, you've seen the boarding process, you've seen the benefits as well from performance and cost. But let's hear from a customer that has experienced this firsthand. So, um, I'm gonna invite Duke Chow to to join me on the stage, um. Gilmo is one of the first customers that we onboarded, uh, and they've been running in production, uh, traffic, and they've seen the measurable improvements, uh, across their business. So he's gonna share with you some real results, not just the promises of what I've been talking about, but actual production data. So Duke, over to you. Thank you, Fernando. Hi everyone, I'm Duke Chow. Today I'm gonna talk about how RTB fabric has helped us create a win win win across our partners. It might look simple on paper, serving the right ad, the right person at the right time with the right creative, but in practice, it's much more complicated than that. I've been doing ad tech since 1999. I've seen a lot of trends come and go. Some became standards, Open RTB pre-bid. Some fade away, flash, a few other things, but the one common thread amongst the ideas that became a standard was that it was built on a solid infrastructure, a solid foundation, and that's what R2B fabric promises us and that's why I'm excited to see R2B fabric evolve. RTB Fabric allowed our demand partners to see more bids, allowing them to have more opportunities to deliver outcomes for their customers. For us, it improved bid efficiencies in the form of lower timeouts, increased win rates. resulting in higher revenue. For the supply side, they get an increase in yield, ultimately being able to deliver better advertising experiences to their customers, creating this flywheel to drive their customers back to their products and their services. When people talk about programmatic or real-time bidding, they like to anchor on what I call above the bid. So let's kinda talk about the concept of above the bid and below the bid. Above the bid is generally things like how you serve an ad, how you match an ad, security, privacy, all the various optimization techniques you apply to creative as well as optimization. But you can't do any of that without what's under the bid, which is a reliable transport layer. If you have an inefficient transport layer, cost compounds, latency compounds, So you have to have this solid foundation for us to do all the things we wanna do above the bid. That's the promise of R2B fabric. Let's talk about some of the results that we've seen as early customers of R2B fabric. We've seen Auction time, timeouts reduce, we've seen bid rates increase. I'm most excited about the last two, a decrease in cost, cause it's running across one of the largest private networks in the world. And I'm also extremely excited about the integration time. We've seen the process go from weeks to days. The example I like to use is, it's very similar to a LinkedIn request, or a friend request on Friendster, MySpace, Facebook, you name it. So this process of going back and forth in a very laborious process has now Been made very self-service and very asynchronous. So that's extremely important because it allows innovation to happen, and it removes the burden of custom integrations. Why does this matter to the ecosystem? We're all in this room because we want to deliver ad experiences that are meaningful to the customers. With a solid foundation, we increase market liquidity. We optimize our costs. And we also futureproof. The tech stack for the ad surveying ecosystem. And that piece is not a small feat. I think composable ad tech components is where the world's heading, and I think RTB fabric is the start of that. So think of the world before AWS. If you had to do something, you would have to stand up a server, update a load balancer, update DNS entries. Now we don't think about it because it just works. R2B fabric, division, very similar to that. For AgTech, All the technologies that you're building today that require very custom solutions will likely go away. Whether you need to write a throttling system, whether you need to Instruments, um, additional data on top of the bid stream, or whether you just need to support different versions of Open RTB. Think of a world where that just becomes easy, because you have a solid foundation to do that on. It allows you the bandwidth to think about other stuff, such as new business models, new partners to connect with, new innovations, because it just works. Fast is good But predictable is better. And I'm excited to see the innovations that are gonna come out of this process as people start adopting R2B fabric and all of the infrastructure that it's gonna be deployed to the um the, the, the AWS ecosystem. So with that, I'm gonna hand it back to Sergio to kind of take us home. Thanks Luke. This was amazing. Uh, I mean, it's always great to really hear, uh, the feedback from our customers, and we look forward to hearing your experience as soon as you start, uh, you know, playing around with RB fabric and, uh, releasing these cost savings and, uh, uh, latency efficiencies. Uh, I think we learned a lot today, uh, and so. Just to summarize, we learned first of all, that getting into RTB fabric is extremely easy. It really takes you a bunch of uh uh CLI commands and specifically 3, to get on board, to be uh in the system with your own RTB gateway. Um, and then, uh, with that gateway you are able to communicate ultra fast within the RTB fabric ecosystem, but you can also use your RTB gateway to talk to external partners. If you are an SSP, you can send request to external links which again are really one on one relationships with your own, uh, DSPs that sit outside AWS. You can still do that. Still gonna be more cost efficient than public pricing and. Um, the majority of private agreements, but, uh, If you stay within RTB fabric, of course the synergies go up because you have much lower latency, much lower cost, and so look at RTB Fabric as the foundational layer for, uh, incrementing synergies between AWS and your partners that will be in AWS. So the more partners come to AWS, the more, uh, RTB workloads are on AWS, the more efficient, uh, you will become as an RTB platform. Um, I think the. The second, uh, uh, interesting thing actually I would say the 3rd interesting thing that we discussed today is the con the concept of modules and, uh, uh, you know, we have modules that are built in and bundled into the price as we discussed, uh, super helpful for responders, uh, in order to process requests before they even reach their own fleet. Uh, but helpful for, um, the requesters, uh, especially when you think about what's next in future, we are working with many, uh, independent software vendors to deliver their own application that today, uh, RTB platforms integrated to, uh, integrated with in a, in a very, um, uh, custom way. Everyone has his own API. Everyone has its own, um, you know, latency, SLAs co-location is a nightmare. We take all of this away. We just allow you to integrate with these third parties with a button, literally one click you attach their application into your RTB gateway, which again is a single tenant cluster that is co-located with you, so latency becomes extremely low. Um, cost of transferring data doesn't exist anymore with third party applications, um, and again, uh, you just become more efficient, efficient even from an operational standpoint, um. So really I think my personal opinion on on RTB fabric is that it allows you to buy velocity business velocity. So if you wanna be fast in integrating with new partners with taking all the new ad tech, uh, you know, trends into account and integrating them into your, your stack, I think it becomes a no brainer because this is the platform that allows you to build, react, and build the game. Uh, with that, um, I would like to thank everybody for, uh, joining this session, and, uh, um, please feel free to take a survey. Uh, we love your opinion. Uh, we can get better, but more importantly, do check out the RTB Fabric official website and, uh, uh, start playing around with the service, start releasing those synergies and those cost efficiencies that we just spoke about, and if you have any questions, please do talk to your account managers and reach out to us. With that, thank you so much and uh looking forward to new customer feedback.