---
video_id: 8WH3zCwlLJ0
video_url: https://www.youtube.com/watch?v=8WH3zCwlLJ0
is_generated: False
is_translatable: True
summary: |
  Nick Boudreau from Coveo explains why grounding large language models on enterprise data is mandatory for production-grade GenAI and how to combine Coveo’s retrieval platform with AWS AgentCore (and Bedrock/Q Business/QuickSight) to do it. He positions Coveo as an enterprise search provider already powering portals for Dell, Nvidia, Intuit, and Vanguard, and notes that even agentic systems depend on reliable data access. Grounding ensures factual accuracy, contextual relevance, traceability through source attribution, and dynamic knowledge updates beyond a model’s training cutoff, ultimately reducing hallucinations and aligning answers with brand-approved content while letting users verify sources.
  
  Boudreau outlines what makes an effective retriever: deep coverage across large corpora to avoid dead ends in multi-turn chats; contextual awareness via user identity and history to enforce personalization and permissions; high relevance because the model is instructed to rely only on supplied passages; speed so users still see streamed responses quickly; support for multiple formats (passages, links, full documents) to match simple Q&A or deep research; and concise outputs to lower prompt cost and simplify model reasoning. He reminds audiences that retrieval happens before streaming starts, so latency tolerance is low. Coveo exposes these retrieval capabilities through an MCP server, offering passage retrieval, answer generation, search results, and full-document fetches to ground LLMs or function as tools within agents, and preserving fine-grained access controls so confidential documents stay protected.
  
  A reference architecture places an AgentCore-managed agent in the center with short- and long-term memory, connecting through the AgentCore gateway to the Coveo MCP server. Identity from AgentCore flows to Coveo so access controls are enforced and no sensitive documents leak into responses; agent outputs can also be personalized with project context, activity, or history passed into prompts. The “secret sauce” is meticulous prompting and tool descriptions: define a clear global directive for the agent, specify how and when to use grounding versus session memory, require source citation, and spell out tool behaviors. On the MCP side, use clean, unambiguous tool names, concise 1–2 sentence descriptions that frontload requirements (e.g., authentication), and consistent schemas so the LLM can plan tool use correctly. Schema governs runtime calls, but descriptions drive the model’s decision-making, so precision here directly affects agent quality.
  
  He notes that grounding workflows mirror teaching a child: initially prescriptive prompts and tool metadata guide the agent, but once tested and tuned it can act autonomously within guardrails. Because grounding shifts the LLM’s role to linguistic synthesis over trusted inputs, poor retrieval instantly produces poor answers, so teams should prototype, iterate on prompts and tool specs, and validate results before scaling. Boudreau encourages attending Coveo’s booth and AI masterclasses for deeper dives on prompt templates, tool design, and integrating retrievers into agentic applications on AWS, emphasizing that grounding and retrieval discipline are what move GenAI from demo to production.
keywords: grounding, enterprise search, retrieval, AgentCore, prompting
---

Hi everyone, thanks for taking some time from your, uh, busy, uh, reinvent schedule to come and, uh, listen to this session. Uh, we're gonna talk today about, uh, grounding Gen AI with enterprise data, uh, working with, uh, Agent Core and Covelo. I'm Nick Bordero. I, uh, work at Coveo. I look in, uh, uh, I work in the product crelation, uh, team. Uh, looking forward to, uh, give you some information around grounding on enterprise data. Uh, so the, the agenda for today we're gonna be work, uh, talking about why grounding is so important. Uh, a couple of notion to, to cover there. Also a bit of architecture about how to integrate Covil with Bedrock. Uh, the secret sauce, uh, no spoiler alert, it's gonna be prompting. Everything is about prompting in LLM and the LNM world and a few next step after that if you wanna learn more. Um, I wanted to start by, uh, not bragging, but I wanna set the stage a bit so that you understand who we are, what we do, uh, also give, give some credibility so that you should listen to what I have to say. We, uh, we are an enterprise search company. We've been working with many customers, helping them get Gen AI to production. This is an example of Dell. Dell is using Coveo to power multiple of their portal. If you wanna buy a laptop, if you wanna buy material from them, it's gonna be powered by Coveo. If you go and look at the support section, also, it's gonna be also powered by Coveo. They have real complex product, and they, they, they use us to provide answer to their user when they try to solve their issues. Same thing with Nvidia. Nvidia has all the money in the world. They could be building that solution. They decide to partner with Coveo to offer, uh, question answering to their, uh, to their customer through the Covio solution. Uh, into it decided to integrate Coveo inside of their own application. So if you're into Intuit, if you're looking to find how to work with the product, if you have questions, also gonna be Coveo there and Vananguard, uh, in the financial, the financial services area, uh, is also a big customer of Coveo. They, they use Caveo all across the board internal and external, and that's an example of their personal investor portal. Uh, if you're looking to get information around their product, not investing information, but information around their product, that's gonna be provided by Coveo. So we help our customer go to production with Gen AI. We build a whole solution, but we also have options for our customers if they wanna integrate with, uh, solution from A from AWS to be able to build their own solution. So what I've been talking about so far is the left side, yeah, left side of that slide. Uh, where we, we do everything basically, we, uh, we index your content, we build an index, uh, we ground the prompt, we build the prompt, and then we also provide the UI component for you to be able to deliver that on whatever portal you want, you want to deploy it. Um, we decided to help our customers to offer, uh, the rest of the platform as a retriever, uh, and then offer integration point with Bedrock, Agent Core, Q Business, and also QuickSuite. Uh, and that's what we're gonna be covering today, basically, uh, how to integrate Coveo into, uh, the second one into Agent Core, but it's gonna be pretty similar if you wanna work with QuickSuite or other solution from AWS. Um, that's a slide I stole from, from AWS that they, uh, that they presented a couple of weeks ago. I thought it was interesting. I fully agree with what's in there. Agent Tech is probably the, the, the future that's gonna be enable the LLMs to be fully used to, to their full potential. I, I was really interested to see that there's, in any case, there's always a dependency on data if you're working with Gen AI, you need to ground the, the, the, the LLM based on enterprise data. You need to ground them so that they don't hallucinate. So there's a strong dependency on data. This is where we come into play. Same thing for gente AI. There's always a strong dependency on tools and data so that these, these agents or those models know how to behave and know where to get uh fresh information. Um, so let's jump into the, the, the, the, the meat of this presentation, why LLM needs to be grounded. Uh, they need to be factually accurate. So for LLM to be factually accurate, uh, you need to provide them some information. They've been trained on data that is basically dated. And they don't know what's true, what's not. If you're asking a question, they're gonna answer and they're gonna basically give them, give you back the information that they got in. If it's not what your brand thinks about what, what should be told to your customer, they don't care. They're just gonna give back the information to the user on the other side trying to get information. If you ground them, it's now a source of truth that you're giving to the LLM, and they're gonna be able to provide more most accurate information and be factually accurate. Uh, if you want your LM to be also contextually relevant, you need to ground them. Uh, LLM don't know much about the users on the other side of, uh, uh, asking the question. Uh, you want to be able to provide project information, user history, those kind of things needs to be added into the, into the prompt that can be done by grounding the LLM to make it easier for you. Uh, traceability and trust. When you ground an LLM, you can now do source attribution if you want your users to be able to trust what they read. Uh, you want them to be able to, to see where that information is coming from. If you don't ground an LM, the information is coming from the LLM itself, and there's no way to trace back where this information is coming from. When you are grounding an LLM, when you're, you're basically providing them the information that they should be using to, to give back an answer, uh, this is where you can do source attribution, and then the users can then navigate those links, and they can validate if the information is, is accurate, and they can gain confidence on the system. Uh, dynamic knowledge update, another important one. basically, um, LLMs have been trained on a set of data that is fixed on time. Uh, if you wanna be able to provide them update on data, you need to provide that as grounding information. So, uh, maybe your the information that you wanna, you wanna expose in that LLM is already available out there, is already public, yes, but it's dated on the last time the model has been trained, so you need to be able to provide grounding information to those models for those reasons. The, the holy grail of grounding is to reduce hallucination. You want LLM to be able to answer factually with information that you trust so that it don't provide false answer to your customers. Um, LLMs are really good at lying and having us believe that that the information that they provide is true. So by grounding them you're able to reduce the amount of hallucination that they are doing. And in enterprise it's just, it's just a mandatory. There's no, not enough information about your enterprise available out there so that the models don't know about your data. You need to, uh, you need to ground them so that they are fully accurate. Now a bit more on what makes a good retriever. Um, so a good retriever need to have a good depth of knowledge. You need to be able to look at a large amount of data. It's fairly easy to build a vector DB to be able to get a small set of data, to be able to ground your model based on a small set of data, uh, but what the, what we see is when in users these days is that they. They, they go and talk with an LLM. They ask the first question, and then they don't go back to in the Google day you were looking at a result and then you were navigating that result, and then you were, now you were gone. You were on your own trying to find the information. With an LLM, people go there and they ask one question. They refine. They ask a second question, so you don't know exactly what's the scope of what they're gonna be looking for. So you wanna be able to provide a larger set of information so that when they talk with that LLM, they're always able to get an answer out of, out of that LLM. They don't, they don't end up in a, in a dead, uh. Dead end where there's no information to be retrieved. Um, just like the LLM needs to be grounded, uh, good retriever needs to be contextually aware. Uh, you want the LLM, uh, you want the, the retriever to be able to know about the users in front of you. You need that information to be able to personalize the information being returned. Uh, based on who you are, based on what you have access to, based on what you've done before, retriever need to be able to take that information into account and retrieve a set of information that's gonna be used to ground the LLM based on who you are, based on what you're currently trying to do. But that's extremely important that that retriever are able to be contextually aware. Relevance quality is, uh, is probably the most important one here, um, because you are, uh, providing information in fact to DLLM before the inference time, uh, ELLM, you're basically telling D LLM just to use his linguistic capacity. You don't want is to, you don't want him to use his own information. You're basically telling him answer user question or decide course of action based on the information that I provide you at the bottom. Don't use anything else. Use what I'm providing you here. So if what you're providing is not relevant, is not, is not accurate, then you're gonna provide false sensor, and that's, that's by design. So relevance quality is, is extremely important when you are working, uh, with a retriever. Uh, execution speed is also important. Um, retrieval, the retrieval part of a rag pipeline happened at the first, uh, the first stage, basically. So when you talk with the LM these days, if they're not grounded, the answers are gonna be coming fast, and then you're used to see the, the answer being streamed. So as, as the answer is generated, it's being returned to you, and you consume, consume that information. When you are grounding an LLM, that information is retrieved at first. So there's a, there's a first step that's gonna be the user basically waiting on the LLM to start to generate an answer. So you need that retriever to be really fast so that user can start to see the answer as soon as possible. Format supported, um, you can do multiple things with a retriever. You can do multiple things with a dam. You can do deep research. You can ask them questions to guide you toward exploration. You can do multiple things. The, the classic way retriever work these days is by returning chunks of information, passages of information basically are. Parts of information that are useful for ELM to to be to be able to answer the question uh is being asked, uh, but sometimes you just wanna have links so that people can go and can navigate those links to do the further exploration. Sometime you wanna do deep research or you wanna answer a really complex question. And you don't need some some passages of a document. You need the whole document so that the LLM can look at the whole information and make a mind of itself and answer the full question. So I think a retriever that is able to provide you various formats of information is extremely important as well. Uh, and concisely being concise and precise, returning the right information, uh, in the shortest format as possible will make the job of the LLM easier, uh, because it's easier to consume smaller, more portion of information. You don't have to decipher what you've returned. They already get the right passage of information to answer the, the, the questions. And it's also going to be cheaper for you. The more information you put in that prompt, the more you're gonna have to pay for those input tokens. So, uh, if you have a retriever that is concise and precise, in the end you're gonna be paying less for that LLM inference, although input tokens are not the most expensive one. In the end, it shows up anyway. We offer a, a, a tool set of retriever retrieval, uh, tools, sorry, we offer that through MCP, uh, quickly we have, uh, in that tool set we have a passage retrieval so we're able to extract passages from your documents and retrieve those documents so you can use them to ground. Uh, whatever tools you're trying to build with LLM, we also have an answer generation tool in that, in that MCP server, uh, where if you're looking to get an answer and use Coveo more as a, as a, as an agent, basically in a in the answer question answering agent, you can decide to label, leave off the prompt, but simply get answer, uh, from Coveo as an API and then provide those answers to your LLM on the other side that might be specific to do something a bit more simple than answering complex question. Uh, we also have search and document retrieval. So if you just want to get a list of results for users to explore and do their own things with the, uh, with the data, we can also offer that and also full document retrieval, as I was saying before, for a deeper research and for a more complex question, getting access to the full document, not just passages, not just stacking passages one to another, getting the full document, let's say procedure to, uh, to, to rebuild a, a complex engine or stuff like that. You can get those from Coo, making the job of the LLM much easier. This is an architecture that we suggest to our customer when they wanna get started to build an agent. Uh, pretty simple, uh, nothing groundbreaking in there. In the middle you have an agent. That agent obviously use an LLM. There is long term and short term memory at the top so that they can know they can, they can have a session. They can work in the context of a few interaction. You basically have a conversation with that agent. That agent is connected via gateway. That's a service from Agent Core, uh, to the Cavio MCP server, and on the side you have all the, the tools I've been talking about are, are offered there on the side. Uh, via an MCP server, so the gateway is going to be, uh, registering those tools now. The, the agent has a set of tools that he can use to do whatever job you wanted, you wanted him to do. And we're also leveraging the, the identity provider from, from Agent Core so that, uh, actions that are performed on COVO are performed as a user who's authenticated on the other side. So if I go, if I try to ask a question to an agent, if I don't have access to some specific part of the information that is on the COVO index, uh, those information won't gonna be be coming true to the agent. So there's no leakage of information. So that's also an important part. Uh, to, uh, to add in there to have some more contextual information based on who you are basically. Um, secret sauce, uh, it's, it's a, it's a combination of a, of prompt and MCP description basically you are, uh, building an agent. You are giving him a set of tools, so you need to be extremely explicit around what those tools are, when to use those tools, what they're for, how they work, and all these things. In the end it's a it's a model that's gonna be using those description to decide what to do and how to use your tools. So this is a kind of a meta prompt that we, uh, we work with a, with a few customers, um, global directive, who you are, what's the, what's the main job of the agent. So that, that's up to you to decide what you do with it, uh, but you wanna talk about grounding, you wanna talk about memory. You wanna talk about sources. So there's gonna be grounding available, uh, that's gonna be done with the, with X Y Z tools. So you need to be explicit with that. Uh, make a clear distinction also between memory and, and fresh information from the retriever. Uh, so it, it's another source of information. Memory is also information much more limited. Uh, but it's another source, so you need to be explicit when to use both. Uh, if you want your, your source to be cited, you also need to be explicit around that. So it's, uh, it's a bit like taking something by the end, uh, a young, a young child by the end, but in the end you, you do it once. You, you, you test it multiple times, but you do it once, and at some point the agent become into autonomous and be able to use those tools, uh, autonomously. Uh, we have some questions that go as far as defining some types of questions, uh, what is coming from memory, what is coming from retrieval, so you can, you can go much further, but if you build something good at the top, that's a really good starting point to be able to use a retriever in a, in a, in a good way. The other part is, uh, is the MCP description. So you have an agent, you told them how to use, not how, but you told them basically when to use the tools, what to do with these tools. On the other side you have an MCP server that contained these tools. What we provide by default is pretty simple. It's, uh, there's a retriever agent that which is not retriever, but there's a retriever which is Coveo. Uh, you have tools for search, for retrieval. Uh, you have to tools for full, the full document, but we don't know what you're exposing in your, uh, in your index on the other side. So you need to be explicit around what's going to be available through the, through these tools. So you want to, um. You want to first, uh, use the the net tool naming standard. We see so many confusion with customers using dot in the name of the tools, so avoid dots, go with snake cave, um, maybe dashes, but tool tool naming is, uh, is quite important. The most important one is probably having good description for the, for your tools. Uh, stick to concise description. Once again, that's gonna be, uh, that's gonna be used by an LLM on your side. So the more precise your tool descriptions are, the more the, the easier it's gonna be for the LLM to use those tools properly. Stick to 12 sentence, uh, front load the information if you're, if the tool is to create a case requires authentication, start with creating a case requires authentication is secondary, so put that secondary, uh, verbs, uh, verbs and, uh, and type of object that's gonna be retrieving. So lots of guideline we can, can provide more information around that, but defining your tool the right way is gonna make a, is gonna make a model, uh, for, uh, the difference for your, for your LLM agent to use them. And also, uh, schema versus description when you use an MCP server, uh, you get a whole schema, an adjacent schema for that, for that MCP server, uh, which contain description for the tools. The whole schema is what's going to be used at run time for the for the agent on the other side to call your tools. So procedure description, uh. Uh, arguments, all the things, uh, all the things that are required to call your tools are gonna be in there, uh, and, but the only part that the LLM is gonna use to, to basically decide when to use and what to use as, as of tools are gonna be the description. So they are part of the same bundle but they're used for different things. So make sure that you provide good description for your, uh, for your tools. Um, that's basically what I had planned for today. We have a booth around the, the Atlassian booth. If you make the tour of the Atlassian booth, you'll, you'll find Coveo is booth, 1529. We also have an AI masterclass series that those are webinar. I think there's probably one around every two weeks or every month. Uh, it can be used. You can use the QR code here or you can go on Kyoto.com to find the latest, uh, AI masterclass. And uh I have to tell you to go to the app and fill the, fill the survey. Uh, actually that I'll it'll be appreciated if you fill a survey to uh to know how to improve and uh there's a few, a few more minutes if if people have questions, happy to answer a question or if you wanna come talk, I'm, I'm also available. I'll be at the booth for the rest of the day as well. Thank you.
