---
video_id: CkJzQB1dB_g
video_url: https://www.youtube.com/watch?v=CkJzQB1dB_g
summary: "In this technical session, \"Monolith to Microservices: A Field Tested Accelerated Path to True Modernization\" (CkJzQB1dB_g), Jay Runkle, a Distinguished Solution Architect at MongoDB, unveils \"MongoDB’s Application Modernization Platform (AMP),\" a specialized framework designed to de-risk and accelerate the complex task of transforming legacy monolithic applications into modern microservices. Runkle begins by carefully defining \"modernization,\" distinguishing it from the common \"lift and shift\" strategy which merely moves technical debt to the cloud. True modernization, he argues, requires breaking apart 20-year-old monoliths—often riddled with thousands of stored procedures, complex ORM layers, and outdated runtimes like WebLogic—and refactoring them into agile microservices independently scalable on MongoDB Atlas. He posits that MongoDB’s flexible document model and unified API (handling transactional data, vector search, and analytics) provide the necessary \"AI-ready\" foundation that rigid relational schemas cannot offer. A significant portion of the talk is dedicated to \"lessons learned the hard way.\" Runkle speaks candidly about the pitfalls of naively applying Generative AI to modernization. He recounts early failures where simply asking an LLM to \"rewrite this PL/SQL to Java\" resulted in impressive-looking but non-functional code, especially when applied to massive, 6,000-line stored procedures. The debugging time required for this \"vibe coding\" approach often negated any speed gains. To overcome this, MongoDB engineered a \"modernization factory\" approach—a rigorous, assembly-line methodology that blends deterministic analysis tools, specialized AI agents, and human expertise. The AMP methodology follows a strict \"Test-Driven Transformation\" loop. It starts with Deep Analysis, where code crawlers generate \"galaxy charts\" of dependency graphs to identify logical seams for splitting the monolith. Next comes Sliced Transformation: instead of converting huge files at once, the system breaks code into tiny, manageable \"slices\" (e.g., 10-15 lines). For each slice, the system *first* generates automated unit tests based on actual database values, *then* uses AI to transform the code, and immediately verifies it via Side-by-Side Testing. This validation step runs the old legacy code and the new modern code in parallel, comparing inputs, outputs, and database state changes to ensure identical behavior. If a test fails, the AI retries automatically before flagging a human, keeping engineers focused on high-value architecture rather than syntax errors. Runkle concludes with compelling real-world evidence of this factory model's success. He cites case studies from financial institutions like Lombard Odier and Bendigo Bank, where the AMP approach delivered a 63% improvement in efficiency (roughly 2-3x faster than manual rewriting). By automating the tedious \"heavy lifting\" of analysis, test generation, and code translation while reserving human judgment for design and complex debugging, MongoDB’s platform offers a pragmatic, field-tested path for enterprises to escape legacy technical debt and unlock agility."
keywords: Application Modernization, Legacy Migration, Microservices, MongoDB Atlas, Generative AI, Test-Driven Development, Refactoring, Relational to NoSQL
is_generated: False
is_translatable: True
---

So my name is Jay Runkle and I am a. Distinguished solution architect at MongoDB and today what I'm gonna do is walk you through Mogadibe's application modernization platform, and that is a set of capabilities that we've created to enable our customers to rapidly modernize legacy systems to MongadiB and it consists of a combination of some tools, some of which are deterministic and some of which are Gen AI that we've created. Some methodologies that we've designed, learned, and I'll talk about this through kind of the hard way by actually trying to use Gen AI to modernize applications and. Uh, a team of people that are experts in doing legacy modernization. So just a little bit of background about me. I've been at Mongadi Be for about 12.5 years. I spent most of my time as a solution architect, so working on the pre-sale side, helping customers understand the value of Mogadi Be and how to architect solutions with Mongadi B. Before Manga DB I worked at another document database company for about 4.5 years, so I have close to 16 or 17 years of document database experience. And for the last 2.5 years at at MangadiB I've been working on MangadiB's application modernization platform team, excuse me. So we're going to be talking about today is modernizing legacy systems. So I'm specifically talking about systems that were built 20 or 30 years ago, built on a relational database, usually it's Oracle or SQL Server. They've got a lot of business logic and stored procedures. Typically there's an ORM layer to deal with the complexity of mapping from lots of tables into. Objects in a programming language, often there's a cache. Usually they're running on some old outdated runtime, JBOSS, WebSphere, WebLogic, or maybe an old version of .NET. And they often have other components bolted on, maybe a search engine or something like that. And we're working with customers that have this really drive to modernize, and there's kind of two big drivers. One is there's all the traditional drivers around um. Just needing to be able to scale the application, add new capabilities faster, change the way the business operates, those types of things. And then with the advent of AI, that's put even additional drivers where now we need to incorporate new types of data, create new types of customer experience, maybe getting a competitive advantage, and those are really hard to do those types of new applications are hard to build on a legacy app, so that's also driving modernization. And what we found is companies that have worked with us really have this situation where they want to Maintain or gain a competitive advantage by being agile and innovating quickly. But the challenge often is, is that they have. These fairly large IT budgets and much of that budget is just spent keeping the lights on, doing upgrades, putting plying patches, doing bug fixes, those types of things, and there's really not a lot of resources or money available to do modernization, so we've been working and saw Gen AI as a as an opportunity to kind of really address this. So what I'm gonna talk today about is 3 main topics. First, what we mean by modernization, so something very different than just lifting and shifting to Mongodi Bay. The second is. I'm gonna talk about all of the mistakes we made and all of the things we tried using Gen AI to modernize legacy systems and all the things that didn't work, cos what I find is that often our customers before they come to us, tried all the things that we tried because they're the obvious things to try. And then I'll talk about how we actually do things at AM and why it's different and how the benefits of it. So let's first talk about what we mean by modernization. So it's probably obvious to everybody in this room that modernization is really hard to take some monolith like this and turn it into a set of microservices that are all on modern components. Just quickly go through this, you know these are really complicated architectures. These are technologies that are really old. Most engineers that you see in organizations are not familiar with them. These apps were built 20 or 30 years ago. They're poorly understood, these technologies, and these monoliths are large, complicated balls of spaghetti. And they've been patched and hacked together for 20 or 30 years, which makes it even worse. And I'm talking about really large mission critical applications here, not like I, I love when you go and some vendor introduces a new Gen AI. Uh, tool for doing coding and they show like, you know, this 50 lines of code example and it works great. Yeah, those really small examples work really great. When you start looking at really, you know, mission critical applications that run companies' businesses, they're really large applications. This is one of our customers where. Their particular application that they ran their insurance business on was 3500 PLSQL stored procedures, over 100 user screens, 1.5 million lines of code, and a database that consisted of around 2000 tables and 6 terabytes of data. So we're talking about real complex applications. This application was about 25 years old when we started the project. So I want to talk a little bit about how these legacy systems got so complex, and this also sets the foundation for why Mogadi B should be, you should think about Mongadi B as a player in this space because it enables you to avoid some of history's past mistakes. So if you look at a legacy application, like the minimum set of components typically is a relational database, an ORM to essentially map from the tables to the business objects in the Java application. And when you deploy an application like that, the first thing you do is you run into performance issues because you've got to do Nway joins to create instantiate these Java or C objects. It's in 15 tables. That's a really expensive operation, so you end up deploying cache so that you can minimize the number of times you need to do those operations. And then Because the data models are so complicated now, we need to add a stored procedure layer because it's not realistic that every developer or organization is going to understand the schema and all the nuances required every time you update a customer or a product or a purchase order or something like that. So you add a set of stored procedures to encapsulate the business policies and the rules on how you update all the business entities in the database. And often these databases back in the day were shared across many legacy systems, so this was even more important to do this. Then you know the internet happened, right, and now all of a sudden you've got more scale and you've also got lots of different applications that are interacting with the data in new ways. And you need to add more query capability, you need to add more performance, you don't want to stress this relational database any more than you have to. So you might add a search engine or something like that. So you have other technology components, maybe add a NoSQL database, what have you, something like that. And then you know now you know when you start talking about the internet, even mobile and things, now all of a sudden JSON and unstructured data and all those types of things need to be added to the system, so you maybe you add another, maybe you add a NoSQL database, maybe you add, uh, you know, start trying to use some. JSON column in your relational database or something like that so you get more complexity and then finally you know AI now all of a sudden we need to store vectors and you know embeddings and those types of things so you're essentially adding your legacy system is getting more and more complicated and more and more difficult to add functionality. So one solution that is often proposed is just lift and shift this from uh you know, where, you know, on-prem in this legacy stack into the cloud. And there is definitely some, you get some benefits now some other organization is managing the operational complexity for you, but you've also moved a lot of the technical debt into the cloud as well. You still have this really complicated architecture, you still have all of these components. Many times they haven't been updated when you do this operation, so you haven't really solved a lot of your problems. You get some benefits, but that's not what we're talking about today. What we're talking about today is to do something like this where you take the legacy application, you break it up into microservices. Each of those microservices is on a modern technology stack. In the Java world for our customers, it's usually Java Spring. In the Microsoft world it's usually a modern. Recent version of the .NET framework and all of the data is on MongadiB Atlas with a with a cluster for each service and then that enables you to leverage all of the capabilities of AWS and Bedrock as well as by doing that. And the idea about doing this modernization is to essentially pay down all that technical debt and end up with a system now where the development teams can really focus on adding capabilities and innovation and not having to just keep the application up and running. And do upgrades and just you know all of the mundane work that often bogs IT organizations down. So we're really talking about modernizing the data tier to MongoDB and modernizing the application tier into a set of microservices on modern technology stacks. So We believe really strongly that in order to get a modern architecture that is AI ready, the the data platform should be MongoDB, and I'm not really gonna spend, I'm only gonna have two slides on why MongoDB is so important for this, but the high level summary is, first, for the data model itself, the document model is incredibly flexible, enables you to store all different types of data when you now when we're in. AI world and we need to have more unstructured data, text, images or embeddings. The document model supports that as well, so it makes it a really nice platform for modernizing applications. And then the second thing Mongadi provides is a single API for any data operation you need to perform. So crud operations, complex analytics. We have full text search support, vector support, single query language, single platform, so you modernize to MogadiB and then as your application evolves, as your requirements change, you just can leverage all the additional capabilities we provide without having to bolt on new components or without having to do additional migrations. Alright, so let's talk, that's kind of the context, what we're doing, breaking up the microservices on Longo DB. Let me talk about what we tried and why it didn't work, because that'll set the context for what we're actually doing. So this is, so if you think about it, day one on this, you've gotten the budget, the funding, you have the team. You're going to break up your monolith into a set of microservices. You grab whatever your favorite agentic IDE is, you open it up, you load in the million lines of code, all the PLSQL and all that, it's in there, and then what do you do? You come try and. You try and start prompting vibe coding your way into a solution, right, so you can go, please break this thing up into microservices based abound in context. I want you to generate test coverage. I want these, all of these uh services to be orchestrated, you can imagine a really complicated prompt. I don't know if anybody's tried that, that's not gonna work, right, you need to be a little, you need to have some sort of methodology around this in order to actually solve a problem at this scale. So what we've really deci based upon and you know that scenario is that's something that we tried early on, you know, that that was one of the things that some of our folks tried. So what we've quickly figured out is that what you really need to do is you really need to think about what are the sequence of steps that you're gonna need to perform to do this modernization. And build tooling for this entire process. So early on the the application modernization program the MoDB, we used to call it modernization factory, and that's because we, what we're conceptually doing is building a factory that enables us to modernize a legacy application. And once we switched to that factory kind of approach, we started to get some real demonstrable results. So what you see on this slide is different types of steps along if it's the factory model, different little. Stations in that factory assembly line for different tasks and that you have to perform in order to do a modernization at certain some of those tasks we were able to apply generative AI and some tools that we built to get really good acceleration, you know. Other parts of this process, if you think about that assembly line, are still manual, so there's still a guy in there with a screwdriver and a and a hammer and all that doing things manual, and when you roll it all up, what we are able to show is that we can typically take modernization projects and do them somewhere between 2 to 3 times faster, depending upon. Situation, so the, you know, things like figuring out what the bounded contexts are and what the set of microservices are and how we're gonna orchestrate them, we still do those manually, but some of the other steps we have built tools to really automate them and you roll them all up, you really get like a 2 to 3x productivity improvement. So One of the things when we started out, we did all the things that you've all probably done where you can, you know, use chat GPT, grab a PL SQL store procedure, ask it to generate Java for you or C, and if, if it's small enough, it does a really great job, it's a really powerful demo, your boss is all excited, we're gonna crush this project. But what happens is, is you actually, when you start looking at real legacy applications. It's a real rude awakening. For what you find often is that there are class methods and stored procedures that are hundreds and even thousands of lines long. We worked, I worked with one customer where they had, let's say around 100 store procedures that were in the 50 to 6000 line length. When you try and copy that into chat GPT or ask whatever your IDE is to convert that to whatever target language you want. It's not a great experience. Um, what happens often is it generates lots of code, really easy to get them to to get a tool like that to generate a lot of code, but it doesn't work often. And then that means you as the engineer has to figure out why, and the amount of time it takes you to understand that machine generated code and where the bug is essentially eliminates any value you got from the LLM. So we ran into that problem really early on and then we said, all right, we're smart engineers. What we'll do is we'll just break this up. We know that if the If the code, the starting source code is small enough, usually around this was in like around early 2024 based upon our testing. If, if it was if a block of code was 50 lines or less, then we got really high accuracy once we went over that 50 lines longer, it um. We started hallucinating and introducing bugs, so we said, alright, we'll take some really complicated block of code, we'll break it up into 50 unit chunks based upon reasonable boundaries in the code. We'll have the LLM translate it one at a time, we'll wire it back together. And that that will work. Well that didn't work and then we started, you know, doing crazy things with the context where we summarized the preceding code and all that stuff and we got better accuracy, but still you end up in this situation where too often a human engineer has to fix a problem introduced by some LLM and that meant that any benefit we were getting by using Gen AI was eliminated. So essentially as we started looking at this, what we started to realize is that. There's so much work that has to happen in order to do a modernization that just focusing on code transformation was kind of really the wrong thing to do. What we really needed to do was do a whole bunch of analysis up front and. Automate all of the different steps that are required to do modernization. So you can, uh, I'm not sure that this particular slide correctly identifies all of the categories of tasks that you need to do in order to modernize a legacy application, but I'm showing it just because it illustrates a large number of the things that you need to do. And what you find out is when you start working with an IDE it's really focused on that code migration step. And if you have set things up properly, when you finally get there, you can get really good results, but you have to do a lot of upfront work. And that's really what I'm going to talk about is how we've kind of changed the way we tackle these types of problems. So by the time we get to code transformation. It, we're in a position where we're really high degree of success. So it's back to this assembly line approach, and let me kind of walk you through what that um assembly line process kind of looks like. So the first thing is. We at Monga DB are not selling like the next generation or a better version of whatever your favorite Agentic IDE is. It's really a combination of three things. It's a combination of some tools we built, some of which are deterministic, some of which don't use any JNAI. You'll see that in a second. We've also based upon our experiences in doing modernizations at lots of customers, we've developed methodologies for doing things like TSQL to C conversion or doing Java upgrades. So those we'll call techniques, those methodologies define how you can use different types of tools to accelerate modernization. And then we have teams of folks that are experienced in doing this. So the combination of those three things, the tools, the talent, and the techniques is how we deliver these types of projects. So let me give you a feel for how we do things differently. So the first thing we do is we analyze a legacy code base, and I'll show you some outputs of the analysis in a second. But the idea is to understand all the different software modules and components and the dependencies between them. And we're doing that for multiple reasons. One is we need to break up this particular application into services and use a strangler pattern to do this modernization journey, so understanding the dependencies is really important there. The second thing is, is that we want to avoid getting in a situation where we. Have translated a really large amount of code and then having a human to fix it, so that means that we need to understand the application and kind of how to break it apart into smaller pieces. And then finally we need to know the order in which to do the transformation because one of the key tenets that we have is because the LMs are going to make mistakes or hallucinate whatever you want to call it, we need to be able to test every block of code. That gets translated immediately after we translate it so we don't really allow the, you know, um, a situation to happen where we ask an LLM to go update a project and make 28 changes because we don't wanna be in a situation where we have to debug that if something goes wrong. So what we're doing is we're doing a lot of upfront. Analysis, figuring out how to break apart the app, figuring about the dependencies so we can do things in the right order so we can immediately translate and then test and the reason we can test is we will translate in the order based upon the dependencies so we know that once we've translated a block of code, all of its dependencies have already been translated so we can immediately test it. So we will. Do this analysis and then this slide shows kind of like a stream of blocks coming out of the analysis, those are the stream of code units that we're going to transform in a particular order. And then for each block of code that we're going to translate, we're immediately generating test coverage because we can't transform, or we don't want to transform any code that we can't test because that's, you know, if you do that multiple steps, you introduce an error somewhere along the way, you're never gonna be able, well, you'll never be able to find it, you'll be able to find it, but you'll have to spend a lot of time. And then once we have. That test coverage will then transform the code and we use um for code transformation, we'll use you know one of the commercial IDs out there. We've also some of our team has built tools that just depends on the situation, so there's nothing magic that we're doing there. I'll show some output from some of our tools in a second, you'll see that. And then the final step for us is to do a side by side test, and we do this side by side test after every transformation of. Block and for that what this means is we take the legacy code and we run it on the legacy technology stack and then we take the new code that we've just translated it and run it on the you know the mangadi be modern stack and we compare inputs and outputs and we also compare the database state changes and we validate that those are the same and if it passes the side by side test we know we correctly translated that code block and then we go back. Now this sounds like. A lot of steps and a lot of complexity. So what that means is that we have to automate this loop. So that's what we spend when we think about the coding that we've done and the tools we've created, it's about creating some of these different tools around analysis and test generation and doing the side by side testing and then creating the infrastructure to automate that loop as much as possible so that. Humans only get involved when something goes wrong, when, you know, a test fails that the LLM can't resolve, that's when a person gets involved. So let me kind of give you some feel for, you know, if there's anybody interested, you know, we're happy to set up a meeting with some of our teams and we can show you this stuff live, but let me just give you a taste of what some of these tools look like. So first of all for analysis, we have code crawlers and parsers that go walk through the code bases and just identify all of the constructs, the classes, the methods, the procedures, those types of things, and then the dependencies between them. And you end up with these graphs that look like a galaxy. So this is only, I believe this is around only like 6 or 700 stored procedures, but you know when you do this for a first pass on a legacy app, there can be you know hundreds of thousands of dots on a diagram like this, and it just kind of looks like you're looking at the Milky Way from far away. And then um when you drill into something like this, what you get to see is that each one of those dots as you drill in in a different color, identifies a different coding construct, a function, a procedure, a method, a class, a table, and the arrows identify the different types of dependencies between them. And what this does is allows us to break apart an application based upon its dependencies and figure out which order to do transformation. When you get into transformation, um, this is just kind of taking a drill down a little bit further, drilling into kind of the transformation step that we just, uh, I talked about at a higher level. We have to often take a stored procedure or an old Java class and what we call slice it, because it could be 1000 lines long and we know if we send it to the LM occasionally more than often it's going to generate code that doesn't work and we don't want to have a person to try and figure out why it doesn't work. So what we often do is we'll take some of those long stored procedures or long class definitions or method definitions and slice them, which means just grabbing the 1st 5, 1015 lines and transforming that amount of code. Inserting it into our new modern project and running our tests, and if the side by side tests fails, so we can grab, let's say it's a PLSQL stored procedure, we can grab the 1st 15 lines of that, translate the 1st 15 lines of that to Java, run those side by side. If they both do exactly the same thing, we can then grab the next 15 lines and continue on in that process until we've repeated the whole thing. So the idea here is just like I talked about before, is to do everything in small units, everything test driven, and automate these loops as much as possible. So most of the projects we've done thus far, we have, when we build those loops I just showed, we have just created those uh processing loops in Python. We are beginning now as we've done more and more projects we have, um, engineering folks who are bound to be building graphical user interfaces so that we can build these custom transformation processes, uh, via a drag and drop approach, um, uh for each new project. So let me give you a feel for what it looks like when you actually do a transformation. So because most of our projects have been, there's no UI, it's all done in CLI and in in in Python, you know, the output of the transformation as it works is actually just text. So you know, command line output. So let me kind of talk. So what will happen is if let's say we're working on a team where we've identified our first microscope. Service Based upon our analysis, we know the set of files that contain the code that we need to modernize. What we can do is we can start this transformation process and the first thing that will happen is the engine will look at the code, figure out the set of functions and methods and procedures that need to be transformed. And if they're too big it will break them up into smaller units. It will also sort them in dependency order so that we know like in this list from 1 to 13, when I look at process order, the reason. The reason why it's at the end is because we need to have translated all of those previous functions and methods because it depends on those and that so that the, this is all based upon dependency order of which functions and methods call other ones so that when we get to, you know, get user orders at 7, all of the methods and functions of calls will already have been previously translated so that we can test it. And then, um. When you, so this part here shouldn't seem any, uh, is not criminally unique to anything we're doing. We're basically using, uh, other code transformation tools out there. We're, you know, we create our own prompt saying, hey, you know, here's a process order store procedure that was for Oracle. Here's the Oracle schema for the tables it uses. Here's the new MogadiB document model, you know, here's the definition of our microservice and the Java classes that and everything, and then it will put together a plan on. What it needs to do in order to update in order to make this code work and what changes it needs to make. The other thing that we're doing is we have a set of tools that are generating unit tests here, so it will look at the source code and identify the parameters that need to be defined for the unit tests. It will also query the database and find out what values for those various parameters or what a reasonable mix of values are. So that when we do the translation we can immediately test. And then the final step is to do the side by side testing, and this is just the output of it saying hey I'm running the original PLSQL on Oracle. I'm capturing all of the the inputs and outputs of the stored procedure as well as the state changes that were made by the stored procedure to Oracle, and then the second part of this is running the new Java code on MogadiB and capturing the inputs and outputs and capturing the. Database changes made to Bongo DB and then just comparing them to make sure that they are identical, so that we can validate that the uh transformation was successful. If it isn't successful, we usually we just try again a few times because you know, sometimes, you know, working with LM sometimes it'll give you the right answer, sometimes it'll make mistakes, it usually is worthwhile just to try again before you get a person involved, and then if it, if the LM can't resolve it at that point, that's when it would be a human would get involved in. To essentially figure out what went wrong. So just to give you another example of what we've been doing, we worked with a a Swiss bank called Lombard ODA and they were in a situation where, They were on a 6 or 7 year legacy modernization journey because you know, even though their customers are tend to be uh. Older wealthier people, they were starting to get um pushback about how their online and mobile experience didn't match the experience those customers were used to when they're working with normal retail banks, but in order to provide that same high quality mobile and online experience they needed to modernize all their legacy systems, so they started working with us to do that and this shows you some some data from those projects in terms of how we were able to. Accelerate test coverage generation, migrate a data access layer from Oracle to MogadiB, and then upgrade to a modern runtime from JBOS to Corcus. And you know, depending upon the complexity of different technologies and things, we usually get like I told about earlier, we usually get somewhere from 2 to 3x productivity improvement. So I've been talking a lot about tooling. I've kind of been uh. Also talking about how we apply the tooling as part of the methodology that we use, we have based upon our customer experience, we have documented uh the methodology we use we use for different transformation activities and we call that the um application transformation framework and the idea behind this is that when we first started doing these projects you got one team on one side of the world, you know, working on an Oracle migration you got another. Team, uh, on the other side of the world, uh, doing a similar project and they would all learn different things and learn different approaches, but we had a hard time making sure that as a company, as a team, we continued to leverage from each other so we started to document and define what we call the application transformation framework and it's kind of our bible that defines what we know and what the uh and what we've learned as the most effective methodologies for different modernization tasks. So I'm not going to go through that today, but basically it talks, we've defined, um, based upon lessons learned how to solve different modernization problems, and we get it narrow it down basically to the different technologies like in this case PLSQL to Java, um, what are the various steps and what are the various tools you use at each point to get, um, different accelerate to get a lot of acceleration and how do you avoid problems that we've seen in other projects. So just to kind of, uh, you know, wrap everything up just to review our the the Moby application modernization platform is a combination of some tools both deterministic and Gen AI. Some methodologies for applying those tools and then it's delivered by a team of people that are trained on how to deliver modernization. And one more uh customer example, um Bendigo Bank, it's a mid-tier bank in Australia. They've got a similar type of benefits in terms of if you do their analysis, they get 63% improvement. If you're wondering how we get these numbers, which is kind of a good question I would think, is what we do at the start of these projects is we do the um, Typical type of agile uh planning poker type of thing where we get a team of people together and estimate how long it would take to do all the various tasks to deliver the modernization project, and we put together that estimate, and we file that away. We do the actual delivery project and then we can compare the actuals to that estimate. I mean, the best way obviously would be to have two teams of people, one do a modernization without AM and one do it with, but that there's no customer that's gonna pay for that. So, um, this is kind of the best we can do. And the other thing I think that's interesting about this graph is like I've showed before, there's certain activities that we do that are just manual like the design step and uh deployment. We're not using Gen AI we don't have any fancy tooling for that. That's done traditional way, but other activities in these projects like analysis, generating test coverage, doing code transformation, we have figured out ways to get significant acceleration. And with that I uh thank you for your time and you're listening to me today and I'm.