---
video_id: cf-WOKVn768
video_url: https://www.youtube.com/watch?v=cf-WOKVn768
title: AWS re:Invent 2025 - How Amazon Teams Use AI Assistants to Accelerate Development  (DEV403)
author: AWS Events
published_date: 2025-12-03
length_minutes: 63.47
views: 604
description: "Learn how Amazon developers achieve real productivity gains using Amazon Q Developer, an AI-powered coding assistant. This code talk demonstrates proven techniques for accelerating development workflows using Prompt-Driven Development and Agent Scripts. Through live examples, learn how development teams cut feature development time from weeks to days while maintaining code quality. Discover practical strategies for leveraging these patterns in both familiar and new codebases.  Learn more: AWS re..."
keywords: AWS reInvent 2025
is_generated: False
is_translatable: True
---

All right, let's go ahead and get started. Welcome everyone. Thanks so much for for coming over here for this code talk. My name is James Hood. I'm a principal software engineer at Amazon. I know it's kinda late in the day on day one. we are. We're gonna make sure to keep it interesting for you. Uh, you'll definitely wanna stay for my part, I have a very ambitious code code exercise that I'm gonna do for you also. We'll see how it goes, uh, but first I wanna hand off to my thank you very much, James. Um, firstly, thank you all for choosing us over the expo hall. There's more swag tomorrow. Don't worry, you can, that's more than enough for everybody else. My name is Mishao Casing, and I'm a senior developer advocate with AWS. I work in the marketing organization. And before we start, um, there's a couple of things I'd like to get off or clear. Firstly, I have two hearing aids. So if you have a question, first, put up your hand, I can see, not very well, but we can see. Put up your question and please speak loudly so I can hear properly because we don't have a mic running around the room, that's number 1. Number 2, we are working with Code assistants, which means, means the code is whatever when you work with the code assistant, it's non-deterministic and James will give you the actual good way we use that word per perfectly how we try to use it at least internally. And number 3, because I'm gonna be typing and James is gonna be typing, a part of this, James, this talk is gonna be done sitting down over here in front of the laptop cause it's pretty difficult to do that while, uh, while we're standing up. So, um, How did this come about, which is actually quite interesting because um I was watching a Recording of a video that James did for an internal, what we call. Principal engineers that give on a regular basis, they give talks internally in Amazon and I was looking at one of the videos and I said, This is something that we have to talk about a Greenvent. And um I said, James, do you want to come and do a session? I said yeah, why not? So the reason we did this is because. Um, I think the story that we have to tell is, um, In Amazon itself or in AWS specifically, we have kind of adopted generative AI tooling with open arms. We use it all day, every day, anywhere and everywhere, and we are here to share a bit about how our story goes, how we do this internally inside Amazon. We are not going to be giving any trade secrets, a lot of it is common sense, but it's good to see it like um written out in a proper way so you can understand how that works. And what we did internally in Amazon, we use a something called a mechanism. Has anybody heard of an AWS or an Amazon mechanism? Mechanism is a tool which we do where when something works. We like to share that with the rest of the company and we take it and we codify it or put it into a tool and put it, we call it a mechanism and this mechanism works very, very well with one of our leadership principles which is invent and simplify. Where we take a virtuous cycle and it reinforces the behavior for other teams that can use it. So instead of everybody having to reinvent the wheel, one team does it, gives it to everybody else, and everybody starts contributing, sorry, starts contributing directly back into the tool to make everything, everything better. So, um, Should we start jumping in? First things first, um, can we move over? Yep, yep, thank you very much. The code that is being used here today is on GitHub repo. If you want to take a screenshot of that and follow along, you're more than welcome, some of it. For example, the examples that I'm gonna give are um available here as an open source repo that you can use and catch them later and also some of the work that James is gonna do afterwards of how we use this also in strands. So, let's first go to how we use this internally and forgive me, I'm gonna go and sit down. So when we are talking to an LLM, we have Something what we call 0 shot, 1 shot, and a few shot prompts. When you talk to an LLM, there's a number of ways you can do that in different means and different interactions. The first one is a what we call a simple shot. In other words, you ask the LLMma question and this, of course, is I'm working over here in the Quiro CLI. It can be done in any um coding system, but we are gonna do everything over here in Quiro. So, asking a coding assistant question will give you an answer. And not necessarily always the answer you want. So in this case, for me it is creating code because, and it does it all in Python, which is based on whatever the LLM has been trained. And slowly but surely will give me the code that I want and will give me what I asked in this case was a script which will validate an IEM policy and this is working very, very slowly, but we will have to deal with it, OK. So, it gives me the code that I want to create and that is one way way of interacting with an, with an LLM, but we have found that there are better ways to do this. Here it gives me the function, the word exactly what I asked you to do, what the function, what the function does, and it, what it, what it will return. But That is a 0 shot. In other words, you just ask NLM to do something for you. But if you provide more context to the LLM, for example, I know how to write a function which does in this case a validation of an email. This is what I know, and I ask it to continue to do the same question. In this case, things are gonna change because firstly, it understands I didn't want the, what the code that I wanted to be generated would not be in Python because I gave an example in this case in JavaScript and it gave me the answer. So, we said, the first is 0 shot, you just ask a question, the second one is a 1 shot, you give it an example, and when we have a few shot prompting, you can give it multiple examples, which gives it even more context. In this case, this is what I know, create the same function. And we'll see that the LLM when it answers you a question because you have provided more information to it, it will give you a slightly different answer in this case. There is a very, very slight difference. In other words, remove the example policy usage or the usage for the example which I wanted to explain to me because it understood that I'm pretty much, I know what I'm doing, so I don't have to generate extra code. When do we use this? This is what our best practice for this this kind of work is when you have A very simple task, use 0 shot, just ask a question, but when you have a more complex tasks, And that needs to follow more of a specific pattern like we will see further on. Use a few few shots prompting in order to provide more context to give you more something which is more relevant to you. Another way we use this as well is something which we call um providing more information to the LM is what we call, when you start prompting to an LM you use the system prompt. A contextual prompt or a role prompting, and how does that actually look? So, let's have a look at that here. The system prompt again is a question. In this case, I ask the LLM to create an EC2 script for me with a specific tag and give it to me as a bash function. So, the LLM will go and start thinking, create pretty much what I asked for it to do, a bash function with everything inside. And this is fine. This will work. You can run the bat, the bash, um, dispatch function or dispatch script, and it will, and we'll, we'll start querying all your EC2 instances of with the specific tag. But I can provide also in this case some context. And in this case I'm giving the LLM as part of the same question more context of how I would like you to think. In this case, I'm saying IRT manages multiple instances across multiple accounts, and we give and the way we organize our project. So I would like you to create a script that will also be suitable for this. I could have given that same prompt, but when we use the actual context prompt, we start giving the LLM more information about how we would like to work, and it will create the best script for me with the examples and whatever else it is. And so this will currently um go through and print them out screen by screen. The last one we have is a raw prompting. Raw prompting is OK. It's pretty much the same as a syn uh as uh as what we call con um context prompt, but in this case we say, OK, you are a. A lot of people use this and when you start prompting you think you are a spec a specialist in, um, nuclear technology. Please create something for me or you are a radiologist that knows how to, um. diagnose different MRI things. So you give the the LLM which you are working with different context, and in this case I am asking if you are an AWS senior solutions architect or a solutions architect and you manage infrastructure and start creating a script for me. So in this case, probably the script will be very, very similar to the first one, but there might be extra nuances because it has already some kind of idea of what kind of information you are looking for and perhaps how to cater that information directly for the person for you. Any questions so far? No question. No question. Perfect. OK. The best practice that we have for this is of course is to use this, is to combine these techniques when you when you're talking about complex tasks. Start with the context, then define the role, and then specify the task and the desired output format. In other words, be as specific as you can when when interacting with some kind of coding system so you can get the most benefit out of these tools as well. The next thing I would like to show you is um something which we call self-consistency prompting. This is a powerful technique that improves Quiro's CLI or in this case, in our case, some kind of reasoning by generating multiple different independent scenarios or solutions to the same question and same problem and asking you to select that same behavior. Let's have a look at an example. Um, self-consistency. I ask you a question. I need to design a complex architecture for multi-region, highly available applications. I would like you to explore 3 different approaches to this problem, and these are the factors it has to take into account, in this case, cost, operational complexity, latency, and After it's considered these three different options, to select one of those and give me a recommendation. So Assuming this works and we'll see if it doesn't or not because I had some problems before, it will start going through the scenario. OK, you want to build something and active, there are 3 different ways of doing it, active, active, active passive, and active with, um, read replicas, and it's asking me to give more details. I could, of course, get, I want this as a front end application, whatever else it is. In this case, I'm just gonna say there are no more details, go for. It will start building whatever an application it decides, but now it will start going through the tree. These, there's 3 different multi multi-region deployments, 3 ways of doing it active, active, active with the global database, active, active with the primary rights with balanced, and it will give me, these are your recommendations. The way we use this in is um enable us, this way it works is because the technique encourages the LLM in this case Quiro, to generate diverse reasoning paths for the same problem. By by exploring multiple perspectives. Kiiro in this case can identify more robust solutions. And the final answer that we get from it, because I asked you to choose one of the three out of whatever it is, will probably be more consistent basing on if I do this more than multiple times. When do we use this this self-consistency model, when we have complex architecture decisions or problems we're trying to solve, troubleshooting with difficult root causes, some kind of security analysis, and of course where we have like performance optimization, we'll see that example in a second, that need to be considered and we need to think very, very, um, specifically how, what the options are and how we have to, we have to um. Address the problem. And the best practice here is, of course, always ask the LLM to generate more than one answer, so it can give you more options. Firstly, because you don't have to always trust, you will start thinking for itself and provide you multiple solutions and ask it to choose out of the three. Giving things more options, more than one option will be very, very beneficial for you. A Another way we use this as part of self-consistency is what we call a tree of thought, also for solving problems. So a tree of thought is Essentially asking the LLM to solve a problem for me by giving it explicit directions how I wanted to solve. In this case, I wanted to consider 3, in this case, 3 possible bottlenecks for my problem, which are cold starts, memory constraints, and external API calls. For each of those bottlenecks, give me 3 different possible solutions, and for each of those solutions, evaluate the pros and cons. I'm going from I have a lambda problem, these could be my different issues which I'm trying to, these, what I think could be the problem. For each of them, start looking at different options, how I would solve them, and in the end bring this all together to give me some kind of a recommendation. So in doing this, of course, It allows Quiro to start. Working and trying to actually solve a very, very big problem. You define a structured exploration with multiple branches. Each of the branch represents a different aspect or approach to the problem, and Quiro explores each of these branches, and eventually it comes out with some kind of recommendation with an to identify an optimal solution. When do we use this again with complex problems with multiple variables and of course decision making with numerous interactions and factors which we have to take into into account. And the best practice here for tree of thought is of course you have to structure your prompt with very clear branches and evaluation criteria. You say, OK, just do a tree of thought and figure it out for me, it won't really help. You have to give it very direct instructions how you want this to work, and it will give you a much more comprehensive analysis. And you can actually combine the two. So, um, you can combine tree of thought and self-consistency. In this case, it's even more complex. I want to design a disaster recovery solution, a tree of thought to explore, 3 different ways for each of those to start analyzing. So in other words, we are combining even more of a complex way, but we're letting all what we love to call the undifferentiated heavy lifting over to the LLM, and it provides me with an option or a solution. So, here it goes to the different um options as you can see. And the way we use this of course is designing multiple, uh, when we use for mission critical system design or we have architectural decisions that we have to take and we know that they have um high risks on one way or the other, so at least we can get the information, and from here it starts giving me an implementation and gives me a different kind of approach. Before the last time I did this, it actually gave me a matrix, but now I see it doesn't, so that's the wonderful thing about LAMs, it's not consistent. But still, when combining these techniques, be very explicit against how you want Quiro to follow this kind of trail of thought, providing clear guidance in how you want to organize the explorations and although this will give you a full, uh, a full clear picture of what you would like to get. Um Expanding these tools with context. So we've been talking about, I've been talking about context a lot over here, and the more information you provide, the more, um, the better answers you will get. And of course with Quiro, for example, almost in every other tool, you can add context. So in my case, I'm going to, in Amazon we have a kind of peculiar way of um Writing stuff OK, we have a writing style internally and in my case, of course, and it will be the same thing. Usually these things have been documented up the wazoo and everything is working correctly and you have a knowledge base of how that works. So if you add that into your LLM you can use that as part of the way you can use it to help you. So in this case, I've added the way we write narratives, 1 pages, 6 pages, PRFAQs into the context, and I'm going to ask Kiiro to um Write me a narrative, and of course this is not a real product, so please don't shoot the messenger, whatever it is, but I would like to start how it helps tadpoles to grow into frogs. But because I've already loaded all the context and the way we write documents, it knows exactly how to structure it. It knows exactly what questions to ask me in order to help me fill in. The way to make a more clear and concise and comprehensive document which I need in order to help me. So in this case, there's success metrics I need to add in, and there is recommendations and the market opportunity, everything we know how we usually write the document, but using these kind of tools in L to help you do these kind of, to write, write these documents makes things a lot, a lot, lot easier. The last thing I would like to share just before I hand it over to James is one more technique which we use which we call explore, plan, code and commit. So, Um One thing which LLMs are very, very good is they are understanding what you've written. So you can provide it the code, and in this case, tell it to, I've got a code base over here, in this case, 3 different JavaScript files where I've written code and this with my codebase, and you can do this on large code bases if you would like, and it will start reading all the documents and understand all the different dependencies and I remember James showed me an example of how you can do this to create all the documentation and the diagrams and the flows and the APIs and you might even show that later on. So, in this case, I've got 3 different files over here, which does a um authentication mechanism for some application. So, The LLM now understands what I have in my code base. I can ask, as we said, the first one was to explore, then I would like it to. Plan based on what you've already understood from my code base, please implement a password reset feature. So again, the style is already there. The way I write my code in the same um kind of um style as well is also over there. So I can go in to see and I I gave you more some more some more um instructions to take in security considerations that has to be robust, etc. etc. and it gives me a plan of how I'm going to implement this feature. And then of course we we plan, plan, sorry, explore, plan. I am going to ask it to now create the code for me because it already has, and of course I can iterate on this plan and make it more robust to add in more information according to what I would like, but based on what it already knows in this specific example, I am going to ask it to write the code for me and make the changes. So, This is the way which we use, we use this mechanism of what we say explain, explore, plan, explore, plan code which is generating the code in this case. And it will be where over here at Mercury function and of course commit we can also use in this case. I can ask it to commit the code for, for me if I would like, but in this case I'm not connected to a production system, so I'm just gonna ask it to use my internal style that I have of the way we write code, uh, commit messages with the best practices, links to whatever documentation it is, and I could also say also commit it and submit the PR if I would like to, but it's not connected to a repository. But here, in this case, there are no changes, but in other words, this would be the implementation, this would be how you would do it, and etc. etc. These are some of the techniques which we actually use internally every day all day, and the good thing is we have codified a lot of it as well. And in the repository which we have shared in the beginning of the session and if you want at the end of the session we didn't take this QR code, we will put it up again, or actually I know what I will actually put it up now it's easier. Whoever hasn't taken a picture of the QR code can use it now. The actual code that I just with all explaining all of these examples today. is up there as part of the the open source that you can actually use it and see how you can of course implement it internally in your organization or expand on it and add whatever kind of best practices you have that you have learned from your things. And with that, I'm gonna hand it over to James to um talk to us a little about um strands, agents, SOPs. All right, thank you. Do you mind grabbing this? All right. For those of you who came in late, my name is James Hood. I'm a principal engineer at Amazon. I've been with the company 16 years. Most of that time in AWS. I spent about 5 years in retail fulfillment software in the middle there. And uh I am also a former AI skeptic. Um, I, my previous experience with AI, uh, before this year was trying out a bunch of flashy demos on real world code and watching it crash and burn and, uh, feeling very skeptical and not very satisfied. Uh, that changed for me this, uh, this year early in February where I realized that some of these techniques that Maish was talking about, uh, it's, it's really the combination of the tools, um, like, you know, reasoning models got better, MCP became, uh, much more popular, and then, uh, but my big aha moment was around the techniques that we use. So today I'm gonna spend, I have a very ambitious, uh, code talk for you. Um, I'm gonna talk to you about Agent SOP, which stands for Agent Standard Operating procedures, and this is something we just open sourced, uh, less than two weeks ago. It's something that was actually an innovation internally by our builder community, and I'm gonna show you why they're so cool. They're a deceptively simple concept that is incredibly powerful when you use them. Maish was just showing you a lot of great prompt engineering techniques and to use these LLMs and be successful with them prompt engineering is an important skill to have. However, did you notice? He was copying and pasting a lot of prompts right earlier this year that was happening around Amazon. People copying and pasting these kind of magic incantations, and we decided there had to be something better, and that's what agent SOPs, that's where they came from. So SOP stands for Standard operating procedure. A standard operating procedure is a document that gives a detailed step by step list of how to accomplish some routine task. So I'm going to start out with um I I actually have the agent SOP let me see if this is the right window no um all right so I'm in the agent SOP directory right now and I have the. As part of this open source, um, offering, we released the strands agents SOP MCP server. And this MCP server includes some prompts by default. And one of this, one of these prompts is called code-base summary. And I'm gonna go ahead and run it. What this does, this is an MCP prompt and agent SOPs you can think of as kind of a super prompt for, for an agent. They, I'll, I'll get this one started and then I'll break it down for you. So this one is going to help, uh, help me summarize my code base. Uh, codebase path is a required parameter and it said it'll default to my current directory, which is what I want. I also want to consolidate it or I want to generate a consolidated. File and the default is agents. MD. So I'm just going to say consolidated true. OK. And then it's gonna get going. All right. So now, let's take a closer look at this code base. Summary. This is the agent SOP repository. And if I pull up the actual codebase summary SOP, what you'll see is it's actually just marked down. And it has a title. It has an overview of what the SOP does. It says it analyzes a code base, generates comprehensive documentation. It does support this parameter section with some of them optional and some of them required, the optional ones having defaults, and then it's a list of steps that says step one, set up and directory structure. So initialize the analysis environment and create necessary directory structure. But this is where the magic happens. So step one is set up in directory structure. Step two is analyze code-based structure. Step three is generate documentation file. But what you'll notice is that on each of these steps, not only does it give a one-liner of what that step is, it has this list of constraints, and these constraints use this RFC 2119 style keywords like must all in caps or should or must not or may. And it constrains the behavior of this step. It adds these constraints saying you must validate that the code-based path exists and is accessible. You must create the output directory if it doesn't exist. If we look further down, you can see here you must use mermaid diagrams for all visual representations, so. What these, what we've found, uh, so again agent SOP title overview parameters optionally and then steps with constraints finally examples because LLMs work very well when you give them examples. And then troubleshooting steps as well. Uh, let me, these are still examples, yeah, and then troubleshooting steps. What we have found is that agents and models are extremely good at following these instructions. They, this, this took us from kind of models going off the rails all over the place. Like I could just prompt it and say explore this code base and write up some documentation for me, and I, I could run that 20 times and get very differing results, but with this SOP format. Um, I've been talking and showing you this. In the meantime, it's been generating these files. So codebase info, uh, this gives an overview of the code base, uh, gives a description, gives the technology stack, it gives the product, project structure. And it will do this every time, every time you run it, this document will contain these, these sections. Um, there will be some variants in, in what it describes, but it'll have your codebase info, your architecture, which if you remember I said to use mermaid diagrams, so it draws up these mermaid diagrams of kind of the architectural structure of this code base. You can see that, uh, it does components. Oh, it just added interfaces and so it's running and then it's gonna generate all of these summary files and then from that because I said consolidate true, it's going to generate a consolidated agents. MD file for my coding assistant that is made up of all of this information that it found. So now my agent is gonna be ready to go. Uh, I'm a principal engineer. We have these principal tenants at Amazon like have, have resounding impact. One of them is called. Technically fearless, and I can tell you that thanks to AI and these agent SOPs my level of technical fearlessness has grown orders of magnitude this year because I can go into any code base and I can run this and then my agent has it. I can read it obviously I can read uh what the code base is like and then my agent is also geared up at that point to then help me navigate that code base and even implement features and changes in it. Mice showed you that context feature. Uh Yeah, Maish had showed you that context feature. I actually wrote that. I went from concept to PR in 2 days. It was in a code base that I, I wasn't on that team. It was a code base that I wasn't familiar with in a language that I didn't know, and, uh, it went from concept. I thought I was building a proof of concept. It went concept to PR in 2 days, and then, uh, concept to production in 7 days, which was wild, and that was kind of my mind blowing aha moment, um, from earlier this year. OK, so you may be looking at this agent SOP and, and first off, like these, we've made these for agent SOPs available to use, uh, because they're really from internal Amazon like we actually use these internally. These are by far the most popular ones, um, now looking at this codebase summary SOP you may be thinking. Boy, that looks like a pain to write. It's very long and arduous, and I don't recommend you write them by hand. Uh, I write them with my AI agent. So what we've done is we've created a steering file. And so we've created a rule, a steering file that defines this SOP format for the agent. Um, you don't need to worry too much about this, but. When you install the agent SOPs, um, so we have this strands agent SOPs CLI that you can use it to run the MCP server. You can use it to convert, uh, convert SOPs over to, um, agent skills from anthropic if you've heard of those. And then there's this rule command as well where you can say a rule and then it outputs that rule and there. Instructions in the read me on how to put that into a cursor rule if you like using cursor or put it into uh a Kiro steering file or um the nice thing with Agent SOP is that it's it's even tool agnostic any LLM right any AI agent that can take an SOP um can work with this. So I wanna show you really quickly authoring what it looks like to author uh agent SOP. So I'm going to add. Uh, I already copied that rule into my Quiro steering files, and so now you can see that this just pins this format file into the conversation context. So even if I run clear at this point, um, so I've cleared my conversation history, the context command makes sure that this stays pinned. So I can say, create an agent SOP that uh given a person's name. Create, uh, outputs a short fun poem incorporating their name. And then over here, I'm gonna open up. So I've preconfigured now that uh that MCP server can take an additional parameter um where you can specify different folders for it to look for SOPs in and so I'm authoring this into one of these SOPs so now I have this like name poem SOP. And so if I start up another session of Kro CLI with that MCP server loaded, and then I check the prompts. All right, you'll see that now my name poem prompt is here. So, I can run my name poem prompt. And it'll say, OK, I need the person's name, so I'll put my name. Oh wow, it's confirming the spelling. You gotta love LOMs. That's awesome. All right, so here's my poem. OK, so create a poem, um, now let's say, so we can take a look at the. We can take a look at what it generated. Right? So it generated, it's following the same format, this title, overview, parameter, person's name is required. Right, and then it just has these steps and then an example, um, but let's say I wanna change it. Let's say I wanna say, uh, update to include an optional hometown pram, um. And, uh, yeah, I'll, I'll just say that. Let's see what happens. And then I'm gonna have to reload this after, OK, so as the hometown. And then hopefully it'll know, I mean to incorporate it. OK, should incorporate the hometown if provided. So it's making those updates because it knows the format. It's making those updates to the constraints. So you can just chat back and forth. You can try out your SOP and then if you see it behaving in kind of an odd way or a way that you don't expect, you can go back to your authoring chat and say, hey, I want this to behave this different way. It's doing this right now and it'll add constraints, uh, which the model then mostly respect. Yeah, we, uh, these are still agents and, um, so I'm gonna say name poem now you can pass in user input. I don't know if you, if you're kinda eagle eyed, you saw that this parameter is actually called person name. When I pass in the parameters, I'm passing it to the LLM so I don't have to be exact, um. I could put, since I'm from Tucson, Arizona originally. Um, but I could have put my name is James and I'm from Tucson, Arizona, and that could have been my input and it will figure it out. OK, so now I gave a little poem that talks about the desert and saguaros and stuff like that. OK. All right, so. No, I, as a former AI skeptic, um, cute stuff like this is fun, but I like real world stuff, right? That's what's most convincing to me. I just wanted to give you a simple example so you could understand the SOP format, but why don't we create another SOP that you might find slightly more useful for your job. Um, how about create an Asian SOP that triages GitHub issues for a given repo URL. Let's try that now. Keep in mind I have the GitHub MCP server loaded up in my agent's context, so as it's authoring that SOP, it knows what tools are available to it, and it can, uh, so that's, that's, you need to have the MCP servers that are relevant to what you're trying to do. In here Anyone else want a poem about them while we're waiting? Uh, any questions at this point? I have one hand right before yours, uh, not I guess exactly on topic, but something that was mentioned earlier when you're providing code, um, to the LM, how do you, what are your recommendations for making sure that sensitive information isn't included in the in the source. Yeah, so the question was, when you're providing code to the LLM, how do you make sure that there isn't sensitive information in the, in the code that you provide in your prompt, or like what would you consider information that you wanna not have provided to the LLM. Like obvious, you know, usernames, passwords, things like that, but anything else that you. Yeah, yeah, so the question was, um, is there anything that you would be careful about having provided to the LLM, um, I, I do have to say that internally we use Amazon Bedrock which, which essentially provides you this like account level privacy and is not sending your, it's not sending your request to like third party model providers, um, so I would say internally we're a little less, we worry a little bit less about that. Um, uh, about like sending that kind of information, um, I, I still just as an engineer I don't, uh, I don't have passwords or credentials in source code like that's just a general security don't, um, so I don't generally like that's not gonna go to the large language model because of that, um. So would you say it's, it's heavily dependent on the LLM that you're using, right? Like, you know, yeah, yeah, I'd say I, so I'd say that, uh, I guess. The main thing I would say is with Amazon Bedrock it's much less of a worry because uh AWS is very concerned about that privacy and about just like all of our AWS services where you have to explicitly give permissions and and IM permissions for any any of your you know resources or data to be touched so similarly um Bedrock follows the same paradigm. But I think that's important to point out Bedrock guarantees that. Yes. With like a separate entity from the model provider so they don't share your bedrock data with the model like say you're running local. If you're running local assuming the model's not, you know, running on safe code and send the results up. It's not You've got a level guarantee. That's right. All right, so I have my, so I have my GitHub issue triage, uh, SOP here. It takes a repo URL like I said, and then it retrieves open issues, analyzes each issue, recommends labels, and then generates a triage report that it's looking like it's gonna write it to a file. Um, that's not exactly what I want here. I'm gonna say, um, for triage, uh. Search for issues with no labels. Those are the ones to triage. I also want. You to comment. Uh, a triage. Comment in each issue and apply relevant labels. Um Don't Write the report to a file, just output it and also add a dry run flag, um, that won't actually make the comments and just print them out. All right. That dry runs just for demo purposes. OK, so you can see it's adding the dry run option, defaults to false. Uh Close this out And sorry to rush along here. I'm, like I said, I have a very ambitious, uh, I'm gonna see how far I can get coding uh actual feature in front of you all. All right, so I just updated my issue triage. I'm gonna start this up again and I'm going to use it. Poetry is fun and all, but. How many of you would benefit from automated GitHub issue triaging? Yeah, maybe. No. Nobody triages tickets here. Wow. OK, so we can see this prompt has appeared, GitHub issue triage, and I'm going to run it. It's going to ask me for my parameters, and I will say my repo URL is this and dry run true. And now, again, since the GitHub MCP server is loaded, it's searching through issues. You can see that it's searching for no label specifically, it's looking for, it's listing the labels associated with my repo, and then it's found admittedly this is a relatively new repo, so there's not that many issues. But you can see that it gives me this summary where it says, OK, recommended labels bug, documentation, and then for this issue, this is a feature request or enhancement, and then this one, documentation or a bug. All right. OK, so this one stands out to me a bit, this issue number 22, because I read it earlier. This is, I didn't open this, this is a real issue. Um, where they're saying these MCP prompts are really nice, but it'd be really cool if we could have a list SOPs tool and uh use SOP tool, right? Um, that then the model can automatically try to use it, uh, so let's implement it. Let's see, am I in the right directory? OK, so at this point, um, if you remember, we'd run that code-base summary, and so if I look at my context here, I now have this agents. MD that was generated by that codebase summary. I'm gonna go ahead and clear my context here and I'm going to run this, this agent SOP called PDD, which is stands for prop-driven Development, which was an internal predecessor to Kiro's spec-driven development that we came up with. So it takes a rough idea. And then it takes you through requirements, clarification and research and everything, uh, in order to, and then comes up with a design and implementation plan. So it says, what's your rough idea? I'm just putting a link directly to this issue. OK. And then we're gonna see, we've got 20 minutes. We're gonna see how far we can get. All right. So it's gonna do some bookkeeping first. It creates this directory structure of these folders that are under this planning folder and one's called research, one's called design, one's called implementation. Then it creates this rough idea. MD file where it writes, it just wrote what it read from the GitHub issue into here and then. And then it creates this idea honing file which and then gives me this instruction to add this expression to my context. So basically anything that gets written into that directory structure will auto add to my context. So it says, OK, do you wanna start out with requirements clarification, which is the default, or do you wanna start with some preliminary research, or do you wanna provide additional context? Um, I'll just say requirements clarification. OK, at this point, it turns into a requirements coding partner where it starts asking me questions, one at a time, saying, uh, it starts asking me clarifying questions. So it says, what specific functionality should each tool provide for list SOPs? Should it return just SOP names or descriptions or parameters for a use SOP? Should it return the full SOP content? Um, so I'll say list SOPs, uh, return name and description. And entire parameters content. So I'll say that and then use SOP, uh. I'll say take this is because I, I wrote this so I know. So take a look at the MCP prompt implementation and use the same XML output format but without the run this part. So I told her to take a look at the MCB prompt implementation, so hopefully it should. Let's see. No, maybe not. The agents. MD probably has that information. OK, so next question. Agent autonomy and invocation, how should agents decide when to use SOPs? Should the tool be available at all times? Um, these are MCP tools. They'll be in context at all times. All right. External SOP support. So should the new tools support external SOPs, which is this flag that we support? Yes. Yeah, so this may not make for, uh, like I'm, uh, I'm like the, the. I'm like the anti-flashy demo person and so I love doing like real software development in front of here and you may see some like thinking time being spent and stuff like that but this is real software development like this is how it actually works, right? Where you do requirements clarification says tool parameter and return format return structured format or plain text, uh, list SOPs can can return, uh, Jason output. Hughes SOPE. Um, Yeah Um, I'm on the auto model right now and I think by default it tends to use the, um, like cloud 200K versions, uh, cloud Sonnet 200K, um, tokens, but, uh, we do have the 1 million token on here as well, uh, cloud Opus, um, I just I'm not explicitly using it. Uh, let's see, use SOP should. We should take the SOP name, and I think that's it. Good enough. This is one of those features that's kind of in the middle ground where I do wanna clarify some requirements, but I'm not, uh, like it's kind of a smallish feature so, so yeah, uh occasionally I'll come in and just say like, hey, why don't you just ask and answer like all the questions you have first and then I'll tell you what I think of it. um, I'll do that on occasion, uh, error handling. Um, list SOP should just return empty list. Use SOP can return. A helpful error message. Alright, so it's, it's saying I think I've captured core requirements again. I'm, I'm not usually under like the 20 minute time deadline that I am here, uh, so sometimes I'll say, I'll say, uh, oh actually it does have another question. Let's see integration with existing, how should these new tools integrate with existing MCP prompt system. Uh, yes, both prompts and tools should be available. Um, sometimes when it says it'll kind of decide like, uh, I think we have enough requirements, and sometimes I'll say, well, give me a list of questions you might have asked, and then he'll give me maybe like 8 or 10 questions and OK, so it's uh we've covered the essential requirements, um. OK, I think we're good. So now I'm gonna say, uh, research fast MCP. And how Tools are implemented. Or I'll just say research how tools are implemented in FA MCP, the library we're using. And write a doc to the research folder. OK, so it's gonna do a web search. Yeah, so I can have it do this research. Um, there, there are things where, you know, large language models are very good at pattern matching. I happen to know in this code base that we just have MCP prompts in here. We don't have any tools. If we did, if we had tools already, I probably wouldn't tell it to research this. I just, because it's really good at kind of like exploring the code base and then. And then just copying what it sees, um, but I wanna hopefully ensure some success here and, uh, so I had to do some research on the web to understand, like read the documentation and understand how adding tools works. But we'll see if it works So this PDD script will write findings to this research folder. So you can see this whole time we, we have this kind of planning folder that was created. My rough idea ended up in there. The idea honing, this is the documentation of all these questions and answers and then research. Well, there will be something in research soon and design. Uh, OK, so now our research, I just wrote this research document on fast MCP, and again, part of that agent SOP I've written that it needs to, um, let me, yeah, it needs to include references and the links of where it found all of its information in here. So all of those details, like that's not something you would wanna repeat over and over again and manually writing prompts, that's something that you can encode right into that SOP and then, and then it works. Uh, let's see. So in the interest of time I'm gonna have it move on to design in the real world, like real world scenarios, um, I would spend much more time reading, like reading the research information, um, especially when it comes to design for this one I'm gonna do like a really quick skim which is very common when you look at AI demos. It's like, yeah this looks good and then move on. Um, I spend like. When I, I, I used a form of this, this was before we invented Agent SOP, but I used a form of this with manual prompting to implement that context feature way back in March and, and. If it were really as simple as just I don't care what you wrote, I'm just gonna keep saying yes and move on, I, I wouldn't have gone concept of PR in 2 days, it would have been concept of PR in 2 hours, right? But. I was and this is where I really distinguish what's going on here from vibe coding, which is a very popular term from back in February for me vibe coding is I'm not even looking at the code. I don't, uh, you know, I'm just kind of letting the agent do its thing and I'm kind of manually testing and, and my experience with vibe coding is it's amazing for prototypes, amazing for a little. Games I wanna make for myself not very good for production code, uh, because in production code we wanna make sure that there's high quality. We wanna make sure that, um, the design makes sense and it's vibe coding. It's very easy to code yourself into a corner like really, really quickly and get to a point where you're telling it to fix something and it fixes it and breaks something else and then you like tell it to fix that and you just code yourself into a corner. All right, so I have this detailed design at this point. And, uh, I'm gonna have it keep going, but its next step is it's gonna create an implementation plan, but you can see it creates this detailed requirements and then it creates kind of this architecture overview of what it's going to do and again, normally I would spend a lot of time reading this. This is a big part of teaching AI fluency internally in Amazon is teaching these practices, especially to people who are newer to this technology or newer to software development in general, um, like I said, when I built that context feature. Yes, I didn't know the code base and yes I didn't know the language, but I've also been programming for over 20 years, which means that while I couldn't write the language easily I could still read it. I could still read roughly what it was doing and what was going on, um, and so I was, I was there with it as it was, um, as it was, you know, implementing this. OK, so I'm gonna just cancel it. I was just gonna create a little project summary to wrap up, um, but this SOP, this is a very involved and interactive SOP, so you can see the how powerful these can be, um, but it went ahead and created this like implementation checklist which. 10 steps is way overkill for this. So I think what I'm gonna do instead. I'm actually just gonna remove that. Um, And I'm going to run this other. Uh, agent SOP called Cotas Generator. And this is another one that we use internally all the time. All right, so input is uh. Create code tasks for implementing. Uh, the design in your context. And Output directory. Yeah, I guess I'll just say implementation folder since I had it. OK, so what this one does, this one's really good for like kind of smaller tasks where you don't need this like really huge involved one. this one kind of prompts you first and says, OK, here's my proposed task breakdown. So I, I read everything that you have in context and, and here's create this SOP registry and metadata extraction, implement list SOPs and use SOP tools, integrate tools with existing MCP server. Um, let's do it in one step. I'm giving a demo. Do you Um, so this one there's, there's kind of mixed, um, that's, that's an area we're still exploring in general we're seeing things head toward that direction where you end up committing there, there's kind of two levels of context and, and you'll see it's really useful for agents to kind of like write a bunch of stuff down and if you need to clear the context window and then it's still there and kind of like. When there are documents that are more durable over time like design documents that stick around for a long time, those absolutely should go in the source code, but then there's more ephemeral kind of like notes as you implement and you'll see when I get to this implementation, all right, this one created this code task and the file it created looks like this and code task uh generator SOP, it basically creates like. Like if any of you have an issue tracker, it's like the issue you wish everybody wrote. It's like this very detailed issue with description, background, reference documentation, technical requirements, dependencies, implementation approach, you know, acceptance criteria. It's like, if only, right? Well, guess what, with AI we can do that. All right, so now that I have that. Now I'm going to run. This, uh, agent SOP called Codesist, which is fantastic. Um, code assist. Again, these are like super prompts. OK, so it said proposed parameters. Oh wow, I actually already found my test description. Nice. Um, I'm going to say yeah. Yeah, this all looks good. So, uh, Codesis takes the task description, which can be a file path or it can be you can manually type what you want, um, and then a task name and then a mode so it can either be interactive or auto. I'm gonna go auto for this one and then a documentation directory. Oh, actually I'm gonna adjust documentation directory, um. Oops. All right, I'm gonna adjust it to be that and then, yeah, and then the repo route in your current directory is the route default. So the codesist SOP leads, leads the agent through a much more opinionated way to implement code well. It uses test-driven development best practices, so it breaks it up into a red phase, a green phase, and refactor phase. Red phase meaning it writes the test first and then. verifies that they fail and then the green phase is it implements the functional logic until those tests pass and then the refactor phase is where it runs the other tests to make sure it didn't break anything, and then refactors the code to kind of more concisely match the style of the existing code. And do any cleanups and then it commits it using a conventional commit messages um and yeah so all of that rolled into an SOP uh for anything other than like a trivial one liner this is the only way I code now uh I use this this agent SOP it's fantastic. Yeah Yes. And then Yeah, so the, the question is kind of how do you differentiate between like green field versus brown field, right, like existing code base, um, this is an existing code base although admittedly it's a fairly simple code base right now. It's not, it's not, uh, like I, I, I spent my last 5 years working on AWS cloud formation that's uh over 10 year old, you know, code base. It's highly complex, highly asynchronous, right? Um, running code-based summary on that, definitely more challenging. That's generally internally when we're doing any, uh, any, um, AI tools that, that codebase tends to be my stress test for any of them. Um, so the code base summary does help with existing code bases, and there I will say that there is a limit to like how well, how well these AI systems can do depending on how complex and how large the code base is. If there is a massive amount of cognitive load that you, you need to have in your head to make like a one line change. Not, not gonna help you as much. So, so an analogy that I like to give is that like you can think of a commercial plumber who spends 3 days walking around a big industrial building and then tightens one bolt and is like fix your problem and, and they say there'll be $1000 and they're like $1000 you tighten one bolt, and they say, well, OK, $1 for the bolt, $999 for knowing which bolt to tighten, um, so. That's there there is code that we have that's very much like that where the actual change itself is not big, but the all the knowledge and cognitive load that you need to make that change, um, that's where kind of the scale comes in. I've found that I tend to use AI for, uh, that walking around the building for 3 days part. I can cut that down, uh, that time down and then still make kind of the manual code change myself. Yeah, so when you start using agent SOP, like I know this is a code talk and I'm doing coding, hey, look, all my tests failed, um, that's good, right? That's, we know we're, we're good on that. So, uh, when we do these, um. Uh, uh, so once you realize that these SOPs basically just automate an agent to do things with MCP tools that it has, you start realizing how many different applications there are. One of the reasons I was so excited to open source this is because we, there are literally thousands of these SOPs internally in Amazon, and we're using them all over the place because you saw how easy they are to author and, and use, and people are using them to automate operations. They're using them to automate coding as you can. See, um, even productivity if you have like uh Outlook MCP and, and, uh, a Slack MCP and if you have like the right MCPs in place, you can start, uh, like I, I have a, a productivity agent where I can give it a like a, a recording of a meeting and say hey transcribe this, add, add a meeting notes document to my obsidian vault that has the task breakdown for everybody and then it creates like separate documents for each person and maps the tasks over so I can click on that person and say. Oh yeah, those are the tasks I'm tracking for that person, right? And AI helps me do all of that. So it's pretty wild. I think Yes Yeah, the tasks I've shown are like a user story, is that your question? Yeah, yeah, the code task is like a user story. Would that then that. Is there a way that you can that you can do you know? Oh yeah, yeah, using, yeah, so MCP is the way to connect your agent to various different systems. GitHub has their own MCP server and you can also look at MCP servers elsewhere. Um, another thing we look at is anthropic launched this thing called Skills which. Um, with skills you can, if a tool has, even if a tool doesn't have great MCP support but they have a really good CLI, for example, you can write a skill that that gives it all the CLI commands and tells it how to use it and then that's another way that you can connect it. Falco. Yeah, Yeah, absolutely. All right, well, I was, I was really hoping to get to a point where I could actually like show you that this works for real, but I think we're out of time. Uh, maybe I'm saved by the bell, I guess. But anyway, you can see, so it's implementing this code. The tests are now passing, uh, yeah, it just passed with 97% coverage. It's gonna update this progress document that it's been keeping and then it's gonna do a commit, um, yeah. Cool, so, uh, that's all the time we have, but hopefully that gives you some insight into how we use agent SOPs. I really encourage you to check out the agent SOP GitHub and, uh, if you wouldn't mind giving us a star, I'd really appreciate it as well. But thanks so much for your time today.