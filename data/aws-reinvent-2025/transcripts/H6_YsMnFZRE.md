---
video_id: H6_YsMnFZRE
video_url: https://www.youtube.com/watch?v=H6_YsMnFZRE
is_generated: False
is_translatable: True
---

Hi, everybody. I am Jim I'm Vlad. So today we're gonna talk about coding an MCP server for Amazon Aurora. Um, for those of you that have never been to a code talk, this is gonna be a little different. Um, you're gonna sit here and watch me code for the next hour, right? Um, so it, it's, I'm a bad typist giving you that heads up right from the beginning. So I'm gonna use Quiro to do a lot of this stuff for me, otherwise you'd be watching me having typos constantly. Um, but let's keep this interactive. Um, let's turn this into a giant paired programming exercise. So if you see me making typos, shout it out. It's OK. I won't be offended if I, you see me making a typo to make things go faster and if you have questions. Let's have them as they're coming along. Vlad's gonna be walking around, um, with the, with the microphone. So let's just keep it interactive, um, while we're doing things, um, so what we're gonna talk about today is MCP. Um, It's already Tuesday. You probably have had a few sessions about MCP, uh, model context protocol. This is a universal framework in order to be able to expose out your back end data to LLMs to for Gen AI. It is still a, a, a new and, and maturing specification. It's only a year old, got released about a year ago. Latest spec just came out last week. Um, haven't had a chance to deep dive on it, but there's a lot of cool security stuff in there that I'm excited about because I, I thought that was something that was missing before as you were thinking about how do we push this into production into exposing things externally outside of your internal, uh, internal infrastructure. Uh, we're gonna leverage one of the AWS MCP servers, the Aurora Postgrass MCP server. There's a bunch of them around a lot of different services. They're all on GitHub. Um, feel free to, to download and play with them. MCP really is uh made up of a bunch of tools you're exposing out a bunch of services out to the LLM and it gives you an API in order to be able to do that and it's more in free text, right? So really how the LLMs determine what those tools do is by the code descript by the description that you type there in in human readable format. Um, what you type there really matters in a lot of cases. We're gonna use Aurora Postgress, um, so when we talk about Amazon Aurora, we have Aurora Postgrass, Aurora MySQL, and Aurora D Sequel. Um, we're gonna focus on Aurora Postgrass, but the stuff we're gonna do today really would work across any of the post grass variants even. Open source community posttress, uh, we're not doing anything specifically Aurora. Um, some of the MCP server stuff uses the, the data API for it, but the code we're writing is really Postress code, not necessarily Aurora code. We're gonna lever Bedrock. Um, again, this is probably something that you, you're seeing in a lot of sessions this week, um, but we're gonna use Bedrock to, to be able to host our models. So what we're building, we're gonna start with a real basic strands application that's it's gonna be an entertainment hub where just right and then we're gonna build an MCP server that has two tools in it. Um, it's gonna have a tool called get, get movie characters and get actor roles. That's gonna, those are gonna pull data from an Aurora Postress database and then it's Strands is gonna use uh bedrock for, for the LLM in order to be able to use that data. The MCP client we're leveraging from strands, right? We're gonna start with a, a simple time MCP server so we can tell what time it is. Um, just those are one of those sample MCP servers that actually end up becoming really, really useful because LLMs don't know what time it is. So if you start asking questions about time, it needs to know what the current time is for different things. So if you, you wanted to say show me all the log history for the last hour, it kind of needs to know what time it is for different things like that. So it needs a source of truth for that. So it ends up being fairly useful for a lot of different things. We're gonna use uh a data model. Uh, this is from the IMDb data set. Um, I created a data model that's more of a traditional normalized data model foreign keys, something that you would expect in your old school legacy OLTP databases, um, so there's gonna be some joints, right? So this way it's not just a simple, uh, single table. It needs to think a little bit in order how do I get this data out, and it's some of it's ugly data, right, of just being. How does it get, get out like when cer certain things are null, what does that mean? Because that's real life with data models that's evolved over, over a period of time instead of rolling out new columns. Sometimes people change the meaning of those columns as they put in new data types, data into them. And we're gonna focus on securing our database, making sure that we do this in a secure way, because it's uh. You're opening up your database to an LLM to me as an old school database person, that scares me. So I wanna make sure that we're doing this in a secure way and different things that we could put in along the way to make sure that what it's doing with the data is only what you intended to do. So that you, you don't want it to be able to just query everything and post it out to the internet that if somebody has some prompt injection attacks, how do we protect from those sort of things. So let's start writing some code. All right. So this is our application. Let's. Right, so we won't be in this screen very much. So this is just the basic thing. So just a heads up, the, the, right at the end of the session I'm gonna put a QR code to a GitHub repo that's gonna have all the code that we're gonna write today. So this way you guys could go download it. I'll upload it on when I get back home after reinvent probably on Monday, right? But I'll post it all there. But this way you'll get everybody have the link for it. Right, so let's just kind of show you a little bit what it is, so this, the simple streamlet app. Who has a simple login page, nothing, nothing crazy. So we have a list of movies, right, and then we have our MCP server there. What time is it? And if we have a decent internet connection, everything's gonna sit there, returns the time, so that, that all seems to be working just fine. OK. Now our data model here, this is our, our list of tables, um, primarily what what we're gonna be looking at is the titles table that has really all the information in there so it has a handful of columns in there as a primary key, a title type, the title start year end year, a bunch of indexes, foreign keys. Right, the, the other thing that we have here is on this I added descriptions for everything that's there. Inside a Postress using the comment command here. We could put in a description that's there. The MCP servers can use that in order to have the right context of what's in there. So that that's something that you know when you're working with developers or or DBAs, everybody kind of knows what's in all the different columns. So we need to be able to share that knowledge with the LLMs. Using the native tools inside of Postress that allows you to put comments and everything lets you really be able to jump into and do that. So like you have things like your end year like only TV series is gonna have an end year. It's null for all everything else. So having that sort of information in there so this way the LLMs know about it, um, or this one here, the, the TS vector for the full, full tech search for Postgress, putting a description of what it is and even how to use it. Right, so this way the LLM knows how to use that sort of column, right? So outside of just for LLMs, that's a great way for sharing that knowledge with developers. If you need to be able to, you know, tell everybody what's in your schema, use comments. We, we put it inside our source code, put it on your, your, your database objects too. You could put them on tape, you put it inside a Postgra. You could put it on basically every type of object. Use it. So let's, let's start by creating a uh. There's a little lag here with the Internet. So we'll go Create that. So we're going to use Kiro to do all our heavy lifting today. And we have a couple. MCP servers that I. Did I? There we go. So there's some built-in. We have the, the Postress MCP server and we have the, the weather MCP server just as, as something to be able to do it, uh, make sure the MCP is working. What is the Whether In Vegas. And the cool thing that if Kiro, it actually asks you whether or not you wanna, uh, do, do a lot of operations is based on whether or not it's trusted or not. So it returns back the, uh, the weather, right? Cool. The MCP that you could have the weather and you could have post grass all in the same thing, right? It'll be able to determine kind of what you wanna do. So I could also say what tables. Can I query. Right, it's gonna think for a second and then it's gonna say, hey, do you want, am I, can I run this, uh, off the information scheme and they get the list of tables, right? I'm also doing this to build up a little context for Quiro so it knows what tables that are there, right? So those are the same tables that we're seeing inside of Postress when you look at it that it's there, so. So let's start with, you know, whenever, for me, I, being a database person, whenever I'm writing some sort of function or whatever that has to pull data from the database, I start with the query, right, um, when I'm using tools like Hero, um, or other ones, I, I tend to use it the way I code in the same order, in the same, same chunks. So I start with writing the queries and then I start building around that, right, uh, a query that returns. All of the. Hopefully the LLM could get that, that typo, right? Otherwise, like my OCD would drive me crazy for some of these things. All the characters and uh. Actors who played them. For a given movie title. So now it's gonna ask if you could see the schema. So I'm gonna, so this is using one of the built-in MCP tools to get table schema. It's gonna get the table definition. So I'm gonna trust that because it's a, a query that I, I know and I trust versus just being able to run a, a random thing. So a big question, is that actually calling an MCP server from Quito? Yes, yes, it is. That is not related to our effort of pulling data from movies and weather, right? Weather and movies are part of our build, and then what you're doing is the ID portion that's reaching out to the database through a database specific MCP server. Yeah, it, it's, it's using the Aurora Postress MCP server that I have preconfigured connecting to my database. So I, I gave it the connection string user ID password so this way it's all set to connect to a database in my development environment, right? So that's, it's kind of pulling it live, right? So it, it produced a. Yeah, you know, a 4 table join here using the full tech search that we're talking about, right? Um. So we could say test the query. Right, and it's gonna go run it. We wanna run it, sure. You notice there's a a little latency as it's kind of going there. So if you're thinking about doing kind of text to sequel, um, keep that in mind. So queries worked, right? It's like, here's an improved version that's gonna pull out some of the JSON elements. We don't really want that, right? But the other thing to think about is it's doing a full text search on. Uh, on, on the name, but the, the Godfather has multiple things. They got The Godfather, Godfather 2, we can forget about Godfather 3. We'll pretend that never happened, um, but it will return multiple things. It's coming along, right? So, you know, let's, let's make it so this way it only pulls 11 particular queer, uh, movie. Sure. Creating that. Mhm They're gonna do an explain analyze. And it'll show you the results that explained while while they're there. So a lot of times what I'm doing if it's running slow, I'll ask it to do that and say suggest, you know, ways to improve the query. Um, it's pretty good at doing that and analyzing progress explain outputs. Right? So it's, it says it's using a gene index and a primary key index, right? So let's change the query to. Only return the most popular. Title. Or multiple matches let's see what it does with that. So it wants to check the ratings table. And it's gonna put it in there as a sub query, right? I don't like the fact that it's doing a full text search twice. So let's have it. To only use full text search once. So now it's gonna do it as a CTE, so it, it could do pretty sophisticated queries, um, but the, you need to work with it a little bit in order to kind of massage it to get to what you want. But that's the same way that I would write a query. It's like you write something to kind of get the data and then you switch it around, optimize it. So let's just test it again. I never trust when it's gonna run sequel directly if I don't know, so I, I always wait and check to make sure because sometimes it does weird things. Right, so it works. So, like the query to uh So what I'm doing is I'm saving that off that context that so this way we could use that later um, one of the things about using these tools, um, if something happens and you lose your session, right, it loses all the context that's there, um, and we wanna, as you're doing things you wanna build things up, save it off for a little while, be able to use that again later, right? Um, so as I finish one little piece of it, it's like I wanna save off that file so this way I could use it and, uh, as, as we're building up the bigger solution. Um, there's a lot of tools we saw them in some of the, the, the, in the keynote this morning about being able to do it in a much broader thing, but as you're kind of learning and being able to, you start using these tools, it's a lot of times using it the way you would normally code and, and do it that way, it's a lot easier to start, start being able to learn how to do those sort of things. I was thinking in a really long time to be able to just write out a simple query. Um, this happens sometimes, probably if we have a, a whole bunch of people who, uh, also, also using Quiro in one of the workshops or something like that. We have 60,000 people here, uh, probably all playing around with Quiro all at the same time, um. So Sorry, where's this MCP server hosted right now it's just in a subdirectory for my application. It's local, yeah, so. No. The MCP server does not call on LLM by itself. Hero, absolutely, yes. How do you preserve the sessions of day one you come and That Come back day two. You want to preserve the session. That's what you were saying, right? How to remember the session in Quiro itself, right? And you, what did you do specifically to save that? This one I just told it to write the query to a file. Right, um, so just right, so the, the prompt I gave it was write the query to a file called queryone. SQL, right? So this way it's just saving off the query that we built. So the plan here is that if you're building it in multiple days, this one, you just leave the uh keto IDE. Open, yeah, for, for the, for the way that I'm using it now, using the CLI, there's other more sophisticated tools that have longer term memory. Maybe Vlad knows some of the, the ones he, he tends to use those things a little bit more than I do. I'm, I, I, I'm going beyond VI right now, so this is, uh, sophisticated for me. You're using the Kira ID then you do have access to multiple sessions, threads, and are able to switch between them and keep different contexts for different tasks and so on. So we're going to write our other query now, write a query that returns all the roles and the. Movie. Titles for given actor. And, and it had its context before so it's writing a query a lot faster using that same sort of uh same sort of thing but we also put that in the comment there um so this way it knows that I'm thinking it should use that. Except Test it again, make sure that's all working, um. Things usually work, um, but sometimes it makes some, some tactical changes, um, little typos, um, sometimes it goes off into some weird loop. Right, it, uh, it all depends really on what the context is. It seems like it's, uh, right now we're trying to figure some things out because it's, uh, it's trying to run it multiple times. I ask another question. On the one that we are building, the MCP server that we are building, that is, your plan is actually to write a sequel and then wrap it in the MCP as a name function, right? And give a description, and that's how it's gonna, LLM is gonna know, hey, if I want to have movies, movie list is, is your MCP server's target definition or something like that, and then you have a sequel behind it. Yeah, exactly. So we're gonna write those two tools and so we need two SQL queries. Each one of those tools is gonna pull data from the, from the database. I, I, I've, I've always done database stuff, so I think in terms of write the query first and then wrap it. Other people start with the API, right, and then figure out the other direction, right? That's just the way that I, I tend to code. Uh, other people think about it differently, but you could do it either, either way, uh, but that's just the way I'd, I'd rather, rather do it. When you have the next break, I'll ask my next question, follow-up question as well. So what seems like there's something wrong here with the connection, so I'm just gonna write the context out. Jim is trying to do here is essentially called the canned query pattern. So we're essentially taking queries, wrapping them into tools, and they become deterministic tools that. With the with this MCP with the RR MCP server you can always ask it by hand, hey, give me this data from here, here and here, but what's happening behind the scenes is the MCP uh agent's gonna think about trying to discover the schema, figuring out what tables to ask, what joints you might need to make, and then come up with a query query may work or may not work. It'll test it. So you're going through a lot of agent loop cycles just to find the right query which works if you're just doing data exploration, right, but if you're writing it for a front end application you probably don't want that type of uh complexity, let alone latency, so. The application is gonna call predictably a certain set of deterministic queries. So let's take those queries, wrap them into tools. And then expose them to any end users. And that's the that's what we're trying to do here. But we're starting with the queries. So one way to do it is to expose it as tools, right? So each and every query that you need, you want to expose it as tools. The other way is why can't you basically say, these are the tables that are available along with the metadata that he already had, right? And then let the LLM decide how to join those. You absolutely can, but there's two, there's two practical implications there, right? Who are the users of that tool? If it's you or Jim in front of there, then he can afford to go in and, you know, let the LLM figure out the query. That's perfectly fine, right? That's the purpose here. I imagine there's 10,000 of Jim's sitting there and doing that at that scale. Does that make sense anymore, right? No, because then you're consuming a lot of tokens it's gonna be very, very costly for you to offer that capability, but if you know that the people are always going to ask the question about the actors. Go ahead and take that query, wrap it around into its own tool, and it's gonna always going to call that single tool. It doesn't need to go through multiple loops of the LLM. It doesn't need to consume extra tokens. It doesn't need to wait and have extra latency. So there's a trade-off there, right? But what Jim is doing there is, is giving him flexibility to design the right tools. But what uh if this would be an agent that I would be using as an as a consumer. That wouldn't be cost effective for whoever is operating that service so Jim is building the tools for me essentially as a consumer. R. You can basically say with the default local MCP server, you can let it query the scheme and say, write an MCP server because that's also an LLM right? Write an MCP server, look at these tables, but have, uh, the tools defined as one for movie and one for actors. Write an MCP server with two tools, right? Yeah, yeah, you can absolutely design that way, or it can be 1000 queries or tools. It doesn't matter, right? It's the use case optimal. Correct, yeah So writing a prompt now to really write the MCP server. So I'm telling it I wanna have two tools. I gave it a reference to the weather MCP server as a template. It does a lot better if you point it at something of what you basically wanna look like, right, in order to do that, telling it to connect to the database using Psycho PG 3. Use the, the, the queries that we generate as templates, and then we wanna load the connection information. From my, uh, file called. Dot NV. Now I'm gonna think about that for a second and it's gonna wanna go check that tool, that, that other MCP server so we could see what's there. It's gonna go find those queries. Now it's gonna build that MCP server writing a a a lot of Python code a lot faster than I could do it. Right, then I can type it. So. This is what it's given us. Right, it's movie server creating a database connection. Right, it's uh only getting the database URL um. We need to change that. Right here it's pulling in that query that we had. Right, um, here's the other one pulling in the other query, right, and then it's the the main thing. So let's tell it to change the. Get DB connection. Like User and password. Instead of full you uh. I'd much rather have distinct things so this way you have to go change your password, right, or you, you should do this thing instead of having the full connection string. It's just way I'd prefer it. So let's see if it did that right. Right, there we go, right, pulling that all together that way, we say, yeah, let's. Let's save that off. Right So now it's. Now we have this movie server. We'll copy the ENV file here. Right. Let's get out of here and let's test that out. Yeah, I gotta go up one more. Now if we could go through this whole session with this thing producing no errors, it would be the first time ever I've run through this thing, right? So I'm anticipating something going wrong, right, um, especially since it's, uh, you know, things are non-deterministic as a, as a database person that drives me a little crazy, right, because you don't know what you're gonna get. So let's see in Star Wars. Right. And because it knows what Star Wars is, it just pulled it off the internet. Right, so we didn't fix. You need to be able to tell the user app to be able to use it. Let's go back to Kiro here. Change. Directory. So the, the way I tend to interact with these things with the prompts is just the same way as if I was talking to somebody next to me and, and trying to like have them code for me, right, assuming I, my fingers weren't working if I was gonna have somebody do it that's kind of knows how to code a little bit, right, and extracting them, it's like, it tends to work. So you're a backseat coder basically, yeah, yeah, it's, uh, that that's definitely what it is. I'm, I'm really embracing the, the, the two person coding rule there and having somebody else do all the typing. I'm a, as everybody's seeing, I'm a terrible typer, right? So now we're adding that in there, added that second MCP server. Right. Let's go try that again. But that's kind of how we're using it too even inside of RDS and how, how everybody's starting to use these tools. It's, uh, it is kind of a paired programming thing for a lot of people in order to really accelerate your development program. Now let's see if we can find that tool. There we go. Found the tool, get movie characters, so it's running the query in the background. Right, gets back the list of them there and then it displays it. So that's something there that is out on the internet. So you know, it's not really showing anything because it is a kind of public. So let's, let's go create something there that's not there, right. So I have this. Simple app here called admin. Instead of you watching me write a bunch of stuff inside of a sequel. Just this basic thing over top of it. So let's create a new movie called 4:29. Coding and MCP server. And we'll make this a TV movie. Had a person. It's Jim Come on. Yeah No, there we go. And that's Ed Flat. Now, let's put them in that movie. Jim. Everybody in the postgrad community calls me Jimbo, so that's, that's the character name. Let's go, Vlad. And we got Mr. Vlad over there in the back with the the microphone. So now we have a movie there that's not out on the internet. Right. That's one. Um, And I just killed my session there. Right. You know, streamlet's still running. It is. Let's kill this sucker. Let's see if we could go find that movie that we just created because that's only gonna be in our database. Right, same as if you had your own internal stuff that's not the models haven't been trained on, right? Who is In the movie. To that 4:29. Boom. I was able to find that so this way it, it, it had enough reference there to be able to know, hey, it's, it's a movie. Let the movie tool so this way you could get that doesn't have to go out the internet to get it. It's pulling off my local database. So even though we're using public information there, a lot of times you wanna build these tools, uh, uh, these MCP tools using your own internal stuff that you're not training public models on, but you still want people to interact with, right, um. But how do we secure this stuff, right? This is still if you're putting this out on the Internet, right, if you wanna be able to do that you wanna be able to secure that a little bit better, right? um. One comment I would make there is the LLM is not necessarily going out on the Internet and doing a search, so whenever Jim searched for Star Wars. Star Wars was part of a training data set for the model itself, so it. And the LLM got invoked. It figured that it can answer that question directly without invoking any tools. For the first time when Jim asked for Star Wars, give me the characters for Star Wars. The LLM actually didn't go through any sort of tools. It simply just answered, generated the answer because it had it most likely, it's such a popular thing that it was most likely in the training data set for that particular model that is used underneath Kiro and. But in this case, right, this wasn't, so that's when it decided that this is potentially an obscure enough movie that it needs to use the tool to access it. It's nondeterministic, so there is no, it's not a rule that says, hey, first ask your tools and then do if you can't do the other thing. When the when the when the agent sends that particular prompt to the LLM, the LLM is going to decide what is the best course of action. That's it. You have no control over that at that point. You might have control using steering documents and uh using the prompt itself. You could potentially tell it, hey, always look for this information in the tools before answering, or you can do that. But even then you don't have a full guarantee that it's, it will do that, right? Fundamentally what the LLM responds back is going to be. Relatively nondeterministic, right? So let's go ahead this question, uh, this is an interesting topic, uh. When doing stuff with MCP, is it possible to create sort of like a shadow of knowledge by having the agent select. Specific MCP server to ask for a solution that it already would have access in the model. And so, therefore, you could make it not aware of certain things. Um, maybe, yeah, that's the answer, um. You can. You can tell the MCP server to use certain tools and within certain frameworks of building it, uh, an agents you can define what some of the steps are in that. So for example if you would be using something like line graph, you can define nodes that need to be transitioned through before it goes to the LLM for the decision. So in those situations you could force a step at the beginning, hey, always look here right into this data set before you invoke the LLM but that's not. That's not MCP that's enforcing that that's not your tool that's enforcing that that's the the way you're building the agent itself that does that, yeah, a lot of that stuff, it's, it's how do you force some determinism into something that's inherently nondeterministic. Right, it's, uh, you have to force it in some way, right, and, and that's kind of what, what we're gonna show here a little bit too of like how do we lock down some of this data based off the user that's logged in, right? So you know if we look here at this titles table there's 11 million entries in there, um, but you know for this one we wanna lock it down by the title type that. You know, Jim could only see title type of one, that's movies. Vlad could see them all, and test two could see 1 in 5, right? It's like we're using that for titles. A lot of times you might have a, a tenant ID or some, some other determining factor of who could see what data, right, based on some roles, right? So using that we could see if we have this sort of we clause where title type equals any because this is a, a post-resson array, right? We have. 700,000 titles in there. Movie titles of 1 in 5, we have 8,872,000. Uh, so it's like that's kind of the wee clause that we wanna inherently have all the time, um, putting that something inside of the MCP server and being able to pass that thing there, it's like having the LLM put the right thing in there. We can never trust that. So we wanna make it in a more deterministic way. So tools like Postgrass have that ability. So what we wanna do is, uh. Use low level security in order to be able to lock that down. So, um, let's go do that. So what I'm going to do is set an environment variable inside of post grass. So this way we can start building what we want for our policy to be. So there's a, a function called set config that'll set that so this way now we could go here and instead of having that string we'll get. The current setting So now we set that to just having one, so that should match our, our 719,000 rows. So this way now we, this is really the wee clause that we wanna set. So this way based off what we set that RLS that typed environment variable to, right, that wee clause automatically gets appended to it. Great policy ROS types on titles. Using Let's copy and paste this wee clause. OK. What's your table titles. Enable road level security. OK. Now we are currently running as the table's owner, so row level security won't apply to that. So let's connect as. The MCP user, not as the MCP owner. Right. Now, if we do the. Just do this one. So when we run that is that you get nothing because we have nothing set. So when you set, you create your policy for something like role level security. You wanna make it so this way if things aren't set, you get no data, right? So now we wanna explicitly allow to be able to see some of that. So we'll go back and set the config here. And now we could do that again without putting that wear clause in there. Right. And we wait that and now we get the right answer there. So row level security with postgrad, so automatically add that in there. So when we're thinking about things like context like MCP or things where you're not quite sure what's gonna happen as things get passed in there, we wanna add that determinism in there, especially around securing your data, um, things like if you're in the Oracle world, virtual private database, there's things like that. There's other, other ways of doing that inside the database that we could be sure that's there, um. Right, so now let's use those tools that's there. So let's go into the, the movie server. We'll go back to. Hero Change the. So what I'm going to do is to take in. Command line parameter because that's how the uh this MCP server is taking things in through standard IO. I'm telling you kind of what library to use. Now I get to. Call it. Config. Right after Making a database connection. Use the following as a template. Right. You notice I'm always telling it to use a template because I usually try these things and then once I know it's gonna work, I don't let it try to figure it out a second time, I just tell it how to do it. Right, ends up being a lot faster that way instead of trying to figure it out. I So. Pulled that import in there, set that to none. Right after the connection we're gonna call that with the value that that that gets passed in yep, we're gonna allow that merge that patch. Mhm Right. And now it's parsing, getting titles type, yep, we want that. Cool. So let's go change. Parent directory. To pass. Title types to the MCP server. Load entitled. Types. From the users. Table When logging. And See what it does with that. It's always an adventure with this, seeing what it's gonna kind of code it's gonna spit out at me, right? It's, uh, you need to be able to look at things along the way. Yeah, we'll trust this. Yeah Wants to be able to go see that, sure. So added that into select that's getting there. But that's coming back as a, a postgress array. Python doesn't handle that so well, so. Change the query to cast. Titled types as a text. We want that coming back as a string so it's easier to pass around that one I've run through a bunch of times and run a bunch of errors, so just save everybody the time that I, I know we have to cast that as a text. Right Right now it's putting it in the session. Now it's passing in the args that are there. Right, so this is another thing that I noticed because this thing is in a different memory context there it's not gonna have access to that session, right? So this is another one of those things I keep bumping into, right, so. I So, Entitled. Is Asked to the. RX as a local variable. I haven't tried this prompt yet. We'll see what happens. I just know that that code that it spit out is gonna be a problem. Right. There we go. We put it there, put it in there. That looks like it'll work a little bit better. Right. Cool. Now we gotta go up one. I go This is taking a lot longer. Right, so, and it's not spitting out any movies or anything there because we have the row level security. We didn't change user app. Py in order to handle the row level security. We're just passing it to the MCP server. 4429. So call the tool. Right, couldn't find it, right? It's because when we created that 429, that, that movie, we set it as a type of uh a TV movie, not a regular movie, which has a, a code of 5 instead of 1. Jim only has access to. Uh, only has access to titles of one. So if you log in as lad. Glad I stole your password. Oh no. Now Vlad has access to all the types. Still couldn't find it. Maybe that's a session thing. Tell this isn't a pre-cam demo because the. If the cool stuff didn't run, let's try this guy, see if that one works, test 2. Still couldn't find it, so the sucker is locked down pretty good. Right, um Not quite sure where that's going that, but there, there's being able to pass in the determinism here, um, is, is something that. The LLM isn't gonna be able to do that's that's why we were, we're passing it in here through logging it in, right? so getting it there and then passing it in down here so it's probably that I'm not passing it in through this, this entitled types properly, um, right, it's. Yeah it's probably this sort of thing. Let's let's just put it here and that's probably gonna give us an error, but let's try that. This is the point where I would honestly try logging. See what the the variables are or, you know, try mocking, yeah, yeah. Yeah, we could, but we only have a few minutes left, so going ahead and trying to go through that and having to go do all that is is. It is a little finicky about how you pass some of that through. did it. Yeah, there's the error, so that that was, that's the error that I was trying to avoid. Right, um, where I can't find that key, the missing key here. Right, so that, that comes down to Python streamlet stuff that I don't really want to debug in the in front of everybody here because I don't know where that's gonna go and we ask Kiro, it's gonna go off into little tangents, um. But the, the main idea there of using low level security in order to lock down your data because that's the deterministic part. If the LLM is passing something that's there, it has policies that, as you can see, you get no data if it's sending things in the wrong way. Um, that's what you want the default to be is don't expose out your data in some sort of way. Um, you'd rather get no data than putting out the wrong data. Uh, as we're using these tools and it's moving faster and faster, we have to remember good security practices around our data and the privacy and the aspect of that, um, so it means leveraging the features inside the database in order to be able to do that, um, because those are the deterministic parts. If we wanted, if, if we added another parameter to the tools that's passed in like the user ID or the entitled types. Maybe the LLM will put it in there right. Maybe it won't, right? Um, it might just say, hey, I, I want access to all the movies, so then it'll try to log in as Vlad, right? It's like it'll pass in a like a a random string that I'll give you all, all the things that are there, um, but, uh, right, that's, that's the main thing that's there. Let me flip back over here. So as As we get, uh, That QR code goes to the GitHub repo, um, that I'll post this code that's up there. um, I will get it working right with that last little bit, and I'll, I'll leave comments in the code, uh, of what I changed from what we, what we have here in our session, um, so this way everybody can see that's there. What did it quite do wrong with passing that thing and, uh, that entitled types parameter across, um, but for. You know, for folks are doing that, you'll be able to see it and you'll be able to run everything. I also have scripts on how to create the database of downloading the files, being able to recreate everything that we did. It'll be in that GitHub repo probably Monday morning. When you're doing it in a development environment. We saw a lot of the loops as, as we were going here, but if that was a main your main production application, you have, uh, basically the internet doing there that all of a sudden if they ask questions, all of a sudden your bill goes through the roof. You have no way of determining that. Right, it's like it becomes a problem, uh, so like, like Vlad said, it's, uh, if you're sure you're gonna need that context every time, just add it, right? We, Vlad and I did a code talk of last year about rag where it was more deterministic of, of doing some of that stuff where we took movies, created a JSON document it, put it, putting a vectors vectors on it, and then use that for semantics, for, for, for nearest neighbor searches and stuff like that for semantic searches. Was more deterministic than this, um, but it was less flexible because we had to pre-can all the vectors ahead of the time. So if we were gonna add the movie, we had to go create the vector of that new movie, put it inside the database in order for it to find it. This is just using standard SQL. Thank you everybody. Um, please fill out the survey. It, it really helps us in order to make everything better for, for you. So please fill out the survey and leave some comments for us, even if it just says hi. that'd be cool too. Appreciate it. Thanks everybody. Thank you all.