---
video_id: DhfN2uX9XqI
video_url: https://www.youtube.com/watch?v=DhfN2uX9XqI
is_generated: False
is_translatable: True
---

Um, first off, let me introduce myself. My name's Mike Mariani, but everybody I know calls me Mariani. I am the Intel vice president. Of sales covering Amazon. When I say I'm covering Amazon, I cover the whole thing. From driving global retail to. Intel-based PCs that are sitting on Amazon stores, of which Intel is the largest, sorry, Amazon is the largest PC retailer on the globe, to simplifying edge compute development with lines of business like Zo's autonomous driving, Alexa, and even Amazon Leo satellite communications. And of course, why we're all here. Cloud. Of which Amazon Web Services is the first and largest hyperscaler in the world, and. A definitional customer for Intel. Now, Intel is in over 450 distinct instances with AWS. And that's what I think I'm most excited about today. In September of last year, we announced a partnership with AWS for 5 years, driving technical collaboration on silicon. But just this August, we released 8th generation Intel instances based on Xeion 6 architecture. Now it's based But it has some extra added value in there. It has the highest performance and faster memory of any other Intel instance in the public cloud, meaning you get your best performance and your best experience with Intel. And it's exclusive on AWS. Now It's only been 1 year into this 5 year partnership, and we are just getting started. I want to talk about the partnership today. That we have with AWS and what it means to you. So, before we kick off here, it might be good for us to have our leaders just say a few words, and you can hear it directly from both AWS and Intel leaders. AWS has a long-standing relationship with Intel, actually dating back to the launch of Amazon 2 all the way in 2006. Intel's relationship with AWS spanned more than 18 years and continue to grow. Our collaboration runs steep. Today, I'm excited to talk about our most recent launch, AWS 8th generation Intel-based instances. Our latest Xion 6 with Porre technology delivers reliability and performance to cloud providers like AWS and their customers. The new Intel instances offer up to 20% performance improvement over previous generation Intel-based instances across diverse workloads. For real world applications, we believe the performance gains will be even higher. This isn't just about migrating existing workloads to the cloud. It is about unlocking new possibilities through nimble and data-driven development pipelines. With the 8th generation Intel instances, AWS is adding support for instance bandwidth configuration or IDC, a new feature that we launched last year with our 8th generation Graviton instances. IBC will give X86 customers the flexibility to optimize their network and storage performance based on their specific workload needs. Our 8th generation custom Intel Xeon 6 processor CM&R instances offer new Flex variants. That have been designed for customers whose workloads have variable compute patterns, they offer a cost effective alternative to standard instances and provide the easiest way for customers to achieve price performance benefits. The future of cloud computing will require even more powerful, flexible and efficient solutions. And Intel is proud to be driving that transformation alongside AWS. We're excited to see how our customers will use them to drive their businesses forward. You know, I think, uh, Dave and Litbo said it pretty well right there. I think. This is uh about the partnership with Amazon and Intel and what it actually means to you. Bringing the best possible outcomes for our customers. And when I say best possible outcomes, I'm talking about consistent year on year performance improvements. I'm talking about software optimizations and an ecosystem primed to help you get the most out of your existing hardware. And perhaps 3rd A global supply chain to enable that you have the compute infrastructure where and when you need it. Now the foundation of all of this. Is this relationship that we have with Amazon Web Services Elastic cloud compute. Intel's been working with EC2 since the very beginning of the cloud. But I think what I'm most excited about is what we've done just this year. So here to talk you through our partnership together. Please welcome Sudeep Sharma. Hey Thank you. OK. Thanks, Mariani. Hello, everyone. My name is Sudeep. I work as a principal product manager in the Core EC2 Instance team. And today, I'm super excited to be talking about the AWS and Intel partnership. So let me talk about the three key pillars that define this extraordinary partnership. The first is the collaboration, as Mariani mentioned that we have been collaborating for nearly 2 decades now, ever since we first launched our instance back in 2006. So there has been a collaboration between different cross-functional teams, be it our engineering teams, our marketing teams, or even our leadership teams with a common goal of meeting the customer requirements. This is not just a vendor relationship, but it's a strategic alliance that has helped shape the cloud computing. Second is an integration. The numbers speak for themselves. So we have more than 450 different instance types powered by Intel processors. And when I talk about instance type, M8i.large is one instance type, M8i x is another instance type. This represents the widest selection of instances available by by any cloud provider powering Intel-based processors, giving our customers unparalleled flexibility to run virtually any kind of workloads in cloud. The 3rd and the most important pillar of this partnership is the innovation. We have partnered with Intel to not just select any off the shelf roadmap SKU, but build a custom chip with Intel which is exclusively available only for AWS to meet our customer requirements. This commitment to custom solutions demonstrates how we are not just using the technology, but we are advancing it. As Mike mentioned, that we recently introduced our GEE Intel-based uh instances powered by Intel Geon 6 processors. Let's take a look at some of the features that we added to these uh instances. The first and the most important is an innovation angle as I mentioned earlier that these are not any standard CPUs which are available in the market. We partnered with Intel to have a custom chip available exclusively to AWS. An example of a differentiation that we created is the memory speed. So we are using DDR5 memory speed, offering up to 7200 megatransfer per second speed versus the other CPUs that are available in Intel. They are capped at 6400 megatransfers per second. So that's an example of a differentiation that we have created. The AWS Nitro system along with this custom chip has allowed us to offer the highest performance and the fastest memory among the comparable Intel processors there out in the cloud. We have been able to deliver 20% higher performance compared to our previous generation Gen 7 Sapphire Rapid-based Intel instances. And the gains are even higher for some of the other workloads. So if your application is running. A workload like web, uh, web servers, uh, you might be using something called as NGNX to test or benchmark these kind of workloads. With NGX we observed a performance improvement of up to 60%. And for some of the AI deep learning recommendation model, along with the Intel AMX feature, we observed performance improvement of up to 40%. Versus the previous generation Intel instances. In terms of price performance, we see 15% better price performance compared to the previous generation instances. And we also have the variants or the flex instances which Dave and uh which which Dave also um uh shared in his video. Um, so we, we are offering even better price performance uh with, with the flex instances. More to come on the flex instances in the subsequent slides. Most importantly, we were able to deliver 3.9 gigahertz consistent frequency at all levels of load. This was one of the critical feedback that we got from our key customers like Pinterest and Netflix when they tried out our Gen 7 instances. As far as new features are concerned, we, we launched in new sizes, the 96 X large, which allows you to scale up to 3 terabytes of memory with an R instance. So it's particularly useful for workloads like databases workloads, uh, wherein the, the, the requirement of high memory is pretty evident. We also doubled our networking and EBS bandwidth going from G G 7 Intel-based instances to Gen 8 Intel-based instances. These instances now offer up to 100 GBPS of networking bandwidth and 80 Gbps of EBS bandwidth. There were new features like instance bandwidth configuration, which they've spoke about in the video as well. Now some of these feedback or some of the feedback from our customers like Netflix, Pinterest, or Salesforce was the reason why we innovated and added some of these features. Let's take examples of a few features that we added with Gene Intel instances. Let's talk about IBC or instance bandwidth configuration. Our customers told us that they need an increase in networking and EBS bandwidth with our gene intel instances which we offered, but what we realized during our communication with customers was that they were either using networking or EBS bandwidth and were rarely using both of them together. So this led to innovation of a new feature called an instance bandwidth configuration. So what instance bandwidth configuration allows you to do, it allows you to increase the networking or EBS bandwidth by up to 25%. So for example, if you increase the networking bandwidth by 25%, correspondingly you lower the EBS bandwidth by the same amount. Think of it as a car moving in a freeway wherein you can adjust your lanes based on the air traffic requirements. These features has allowed the customers to optimize resource distribution for specific workloads. And customers running databases, queries uh have seen faster processing performance and faster query processing time with, with this feature. Let's take another example. So post COVID, our customers told us that they were in a cost optimization journey. They wanted the latest and greatest, but at the same price point as our previous generation of instances. So when we were working on this problem, we realized that the average CPU utilization for the workloads that most of the customers run was pretty low, so more than 80% of the instances that we run had an average CPU utilization around 40%. So in a nutshell, we realized that the majority of the workloads use significantly less CPU, yet the customers were paying for performance that they don't use. There was a lot of idle compute capacity and there was an opportunity for us to give our customers a lower cost and our latest offering instances. So this premises led to a new innovation of what we call as flex instances. So since Gen 7 in Intel swim lane, we have launched Flex instances. M7 iFlex was the first instance that we launched, but because of overwhelming positive feedback from customers, we were able to launch C7 iFlex in a subsequent year, and with Gen 8 Intel instances we raised the bar even further by launching the R-shaped Flex instances as well, the R8 iFlex. So with Flex instances we offered. The latest generation performance for most common workloads, be it web uh web servers or mid-size databases or virtual desktops, at a cheaper price versus our corresponding core instances. We reduce the power consumption versus the comparable core instances to meet the customer's sustainability goals. We were able to give flex instances or offer flex instances to our customer at a 5% better price performance versus the corresponding core instances, which means that we delivered the best price performance in Intel swim Lane with our Flex instances. We offered flex instances in sizes from large to 16 x. So what does it mean for you? A simple way to think about the Flex instances is to think about it this way. If you have a workload for which you don't need high CPU utilization, or you need a smaller size from large to 16X large, simply go with Flex instances. This should be suitable for your workload. This should be the default choice of instance. But if you have a workload that needs sizes larger than 16X large, some of the databases workloads would need that, or some of the gaming servers' workload would need that. Or you need a metal size. Or a continuous high CPU, then go with our regular core instances or non-flex instances, the regular CMR instances. So in our 8 journey, if you attended today's keynote from uh Matt, then you would have realized that we did not only launch the compute optimize, the memory optimized, and general purpose instances, but we also announced the preview for two additional instances, the X8I, which offers up to 6 terabytes of memory, and VCPU to memory ratio of 1 to 16. And also C8INE instances that is also available in preview that offers 2.5x higher memory bandwidth versus the previous generation C6N instances, particularly suitable for. Workloads uh requiring smaller packet sizes or larger PPS. My talk would be incomplete without talking about the customer success stories. So with our G8 Intel instances, Netflix was able to observe a consistent 3.9 gigahertz of clock speed at all levels of load versus the previous generation. They even gave us a quote on this which is there in our on our website. Another example is Hertz. It's a car reservation company. So they were able to offer up or they were able to get up to 25% reduction in cost using Flex instances when they moved from Gen 5 Intel instances to Gen 7 Flex instances. And the beauty of this is that they were able to do all of this migration without any work, so there was no rework required. It was a straightforward migration. Another example is our Salesforce. Salesforce was able to observe more than 30% higher throughput on RAI, particularly on their 48X-large sizes for their hyperforce workload. So it's super fascinating to see how different workloads are being run on our Intel-base instances. It's a perfect segue for me to hand it over to Mike to introduce our customers, to talk about the suc suc the successful stories. Thanks Sudeep, thanks, um. The foundation of this partnership is really what enables these success stories we're about to hear today. I'm really excited for our next speaker, Naresh Kumar from Salesforce. Sales Intel, oops, sorry, Salesforce and Intel have been working together hand in hand on platform and um performance optimizations for years on both cloud and on-prem. But what was really cool is that they adopted the latest generations of Intel instances early for their new cloud platform, Hyperforce. See, they saw the performance improvements that really led them to want to make this plunge. Here to talk about it Is twelve-year Salesforce veteran, principal architect. And cloud capacity and cost management leader Naresh Kumar. I think In terms of an introduction. Salesforce, probably a lot of you know about Salesforce, the. Sort of customer demographic for AWS and Salesforce seems to overlap a lot so I won't get into too much detail here but obviously as the number one sort of AICRM, um, at global scale and by global we really mean sort of 25 regions when Sudeep launches and instances we're like, OK, where will, when it, when will it be available every sing, you know, in every single region, uh, that kind of a scale and then sort of operating crucial critical workloads for. Industries across sort of across the spectrum for industries, so we're talking about hundreds of thousands of customers, millions of works, we're talking about 250 billion. Data points being ingested 500 billion automated sort of actions being taken every month to keep sort of our AIs grounded in the in the reality. So that's kind of the scale we're talking about and for us it becomes extremely crucial to get every ounce of performance from our processors to get every ounce of sort of, you know, reliability from our from from our instances, and that's where we, a lot of our partnership comes together. So moving on to sort of the actual deep collaboration, you'll hear me say a few things and sort of wonder. I've never heard of it or you know, how come we don't get this kind of, uh, a support and then I'll uh for that I'll say reach out to your CSMs. This is the kind of support that all of you can get. And so we've really been grateful for the, the Salesforce X Intel XAWS partnership which is extremely deep and I'll sort of walk through some of the things that we have done. We're not talking about sort of, you know, so you know, here's what I need and here's how much I need. We're talking about deep strategic partnership, co-engineering partnership, you know, partnerships where Intel is aware of our workload, how it behaves, partnership where our feedback is going back to sort of not just the instance design but actually the process. Design in in some cases so that's the level of partnership we have and sort of we we in Intel, our partnership with Intel goes way back compared to our partnership with AWS. So Intel actually seamlessly transitioned from supporting us into our, in our first party to supporting us on public cloud and on public cloud we, as everybody else does, as all the SAS companies running in data centers do, we try to lift and shift, and it was a disaster. We try to not think about it, but even then Intel was sort of there when we were sort of trying to run. You know, Oracle databases on it in 60B 112 extra large. So trying to fine tune performance there. That was, you know, Intel was there. From there we have kind of transformed into running this truly this, this entire the amazing migration journey that Salesforce has had moving to the cloud. Intel has kind of been a partner for us. AWS is gonna obviously been a deep partner for us. So talking about sort of deep structural, you know, engineering based partnership. On that front, and this is one thing I'm gonna mention here, I'm just trying to remember the facts here, but, uh, one of the things that has been crucial for us is the early access aspect of it. So when we're running at at Salesforce scale, we can't really afford to kind of find out about an instance from a blog post. And so, and it becomes, you know, it's probably too late for us, and we, there might be something that just won't work. And so, and actually let's move to the. Actual example here, the RAI, which is my most recent and sort of, um, you know, amazing proof of our partnership here, we're talking about the instance the processor is announced. We know AWS is going to use a custom processor, but Intel works with us and says, you know, here's a preview. Of what the processor will look like we're able to set it up in our demo labs and we figured out, oh, with, you know, this, this generation of instances there's going to be an opportunity to go one of two ways HEC and non-HEX, and they're kind of doing some deep performance testing and Intel kind of was aware of it and then, you know, really grateful for that partnership. Then we sort of bring in AWS and say, you know, AWS obviously is sell. Has given us a heads up that this is coming so we partner with Sudeep's team and also again sometimes it feels like, you know, with, with Slack again plug for Slack, check out the Slack booth, um, with sort of the, the partnership across Slack, Intel and AWS is gonna become so seamless feel like one team. So we're partnered partnering real time sort of troubleshooting, getting the right, you know, kernel in there, figuring things out, and we're able to establish what will be the best pattern of what are the sort of nuances that'll work best for Salesforce for our workload. And that's where once we sort of, once we, once we finalize this is how we're, this is how we are going to go ahead. The other aspect of it is it is a twofold problem at our scale we also need to know how this will play in terms of capacity because when we, if you roll out just an instance type now with a, you know, slight price increase, uh, across our fleet one is to one, our cost will go up utilizations will drop, so we truly need to understand the gay ratios we so going back to our partnership here because of this preview access before because of sort of the testing and because of all the input that we were able to provide. We were able to establish a very clear sort of gay ratio and say, OK, this is how it's going to look like this is what we will need globally and. The CTS impact on sort of OK how much, how much, how much of a positive, you know, uh, cost reduction, uh, support will we get, we'll get, will we get from this to sort of continue supporting our other initiatives. So with all of that said, then we sort of switch, switch the, the weight on Sudeep and say this looks good. Our, you know, our principal architect on the database side was able to actually know that you, you read the quote, um, he was thrilled about it 30%. And price performance improvement is absolutely sort of not trivial. We are at a point where we are eking out 1%, 2% cost reduction from sort of massive high effort initiatives, um, so just moving instance types from R7I to R8I with sort of it's all of its single NUMA 96 extra large, no contention awesomeness. We're really excited about the, uh, you know, R8I, uh, instances. To be available globally, Sudeep, again, just a, you know, reminder here. So yeah, we're looking forward to it. We'll be rolling it out in 27 regions. Our, our other teams are already looking at M8I. This is going to be an amazing journey for us, and we are really grateful for the partnership with Intel and AWS. With that, I'll hand back to Mike. to uh sit, uh, to Albert. Can you have uh yeah. Yeah, thank you Naresh um, those performance numbers really tell the story, don't they? Um, I love this example from Salesforce because like I said, I'm a chip head and I'm a sucker for speeds and feeds. So when we get to see the real true value of hardware, um, generation on generation improvement, it, uh, it curls my toes, um, but what you might not know is that there's also plenty of performance improvements and optimizations that can be made through software in our ecosystem. Now our next customer needs no introduction, but they're gonna get one anyways. They're the curators of the coolest stuff on the internet. That's right, it's Pinterest Pinterest holds a special place in the heart of AWS and Intel because they are a really active part in how we approach the cloud. And our next speaker, Ambad Sharma, leads efficiency. He's gonna walk you through his partnership with Intel around performance improvements and optimizations through software. But Thanks, Marine. Um, thanks all for, uh, um, attending this talk. Um, a little bit about Pinterest, uh, we are a visual discovery platform, uh, uh, here to inspire the world to, uh, try to create a life they love. Um, a little bit about our company from a business perspective, um, right, um, as of Q3, 600 million monthly active users, um, $4 billion of trailing, uh, or $4 billion of trailing, um, uh, revenue, um. For the last 12 months, um. And that just gives you a sense of scale that for us to be able to operate um similar to our, our, our peers, um, efficiency and performance becomes a front um a front and center conversation. And in order to solve that, it's not just a simple prob problem of um just use CPU for what it is or pick an instance type and and just run it. It's about deeply engineering, working with Amazon, working with uh with Intel uh to try to get the best price performance. Before we get into the performance aspects and the efficiency aspects, uh, let's talk a little bit about our collaboration with Intel specifically. Um, we've started, uh, since 2022, um, and worked together, um, across three, big stroke initiatives with Intel. Uh, the first one is to improve hardware, and that's providing active feedback to Intel on how to improve chip, uh, and what sort of features and performance expectations do we have on our workloads, um, so deeply engineering and partnering, profiling our workloads and sharing those insights with Intel. Uh, the second aspect is to work with Intel on optimizing software. So we are a big user, uh, and proponent of open source software, um, and working with Intel on trying to find what are the optimizations that can be, uh, made available to the entire community that are globally useful to everybody here. Um, would be something that we can co-engineer and partner with them and we worked extensively on those aspects, um, and the third one is to develop tooling that allows us to further speed up this process of finding efficiencies and making the entire process of performance engineering simple. Let's talk about performance a little bit, um, with Intel Xion at Pinterest, um, at this time we're rolling out, uh, Xion 5 Emerald Rapids CPUs, um, and we've seen 30%, uh, improvement in, uh, price performance, um, or efficiency, uh, compared to the previous generation that we're running, uh, based on our database workloads, and this has been amazing, um, because it has allowed us to right size our workloads, our database, uh, uh. Applications um on this new i7 IE platform uh from AWS, um, and this has been great. We're also excited about Xion 6, Granite Rapids, our 8I instances where we've seen 20% improvement in gen over gen performance. Uh, we are an extensive user of Intel instances today, um, across a wide variety of our workload. So these sort of step function improvements in performance and efficiency really, really help us, uh, deliver towards our margin goals, um. The next thing that we're looking for, uh, obviously is our workloads are heavily IO bound, um, part of the discussions around network bottlenecks, uh, where we've provided feedback of improvements in price performance, um, um, we're actively waiting and eagerly, uh, looking forward to the disc-based instances, uh, on based on Xeion 6. Let's talk a little bit about deeper about one such uh deep uh partnership with Intel uh between Pinterest and Intel around profiling and tooling and this is gen genuinely an open source community effort. It's under Apache license, um, again, uh, usable by the community and what we're truly trying to aim for is to improve the, uh, time to market on efficiency, being able to find these efficiencies, make the process extremely simple because, uh, one of the problems with. Performance engineering is, it's difficult to scale it. You only have a handful of performance engineers in the company and it's very, very difficult to work across all of the, the, the, the hundreds of microservices that you may have in your company. So it's important for us to be able to take the learnings, make it available in a platform that can automate it and, uh, make the process repeatable. So when you know that there is a known performance issue, it's very easy to find it and provide the fix to the end developer who can go and make, uh, changes to their application. So G profilers and the Performance studio, um, it's something that we partner with uh Intel, uh, worked on open sourcing uh uh with Intel and it's under Apache license we're uh a maintainer, um, along with Intel, um, some of the things that it delivers is continuous profiling so what that allows you to do is. Um, you can just deploy it and it's continuously monitoring and you can have a historical track record of how your applications are doing as applications are being changed and developers are adding code, you can continuously try to see how that that evolution's happening, what commits or what changes in the code had negative performance implications. The second part is it can do ad hoc profiling and it's a feature that Pinterest contributor allows you to be able to pinpoint, uh, the profiler. It could be running silently across your entire fleet and you can activate it remotely saying, hey, I want to activate profiling on this workload on this application or this sidecar, and I want you to be able to tell me what's, what's happening. So can I get the flame graph for it? Uh, and one such exa example is the screenshot that we have, uh, shared here. Um, the next one is deeper hardware layer level profiling. So the hardware has capabilities to allow you to see what exactly is the bottleneck. Um, the CPU is not a single monolith. It's made up of many, many, many components, and they're extremely complicated to understand what, what, where are the bottlenecks, where is the stall happening. And for that, uh, top-down micro architecture analysis, which is, uh, something that is available with, um, Intel's perspect tooling is integrated into G profiler again making the process really, really simple for you to go from, um, just having an application, having no insights about it to. Understanding what are the bottlenecks and what can I actionably do about it, um, again, we're, we're actively working on evolving this and we're our goal is to make the process more automated and do it in a community way so when you learn something you can share it with the community and we can again get to a more, uh, optimal state, um, across the board. Um, and again, we're running this across thousands of EC2 instances today, and, and if you have, uh, interest in using it, you can check out the QR code. Um, uh, the project is available on GitHub. Uh, again, we once again thank, uh, both AWS and Intel for the extensive partnership we've had in delivering high performance, um, and efficiency. Thank you. Thanks man. Thanks, Ahmed. Um, I really like that example from, uh, Ombud because it really speaks to the value of hardware and software sides of what we're building together. Now, our next customer and final customer is from Newtonics. Newanics is another huge partner of Intel's that has, um, been working with us for years, uh, because they see the value, not just the performance improvements that they've seen from Intel. But also the world class supply chain, ensuring that they have the capacity for their customers when they need it and where they need it. You know, when they were deciding to roll out their, um, latest generation Newtonic cloud clusters, which is a platform designed to simplify the, um, hybrid cloud infrastructure on AWS, uh, they picked Intel. Mainly for the compute footprint that we offer globally. So guys, please welcome Michael Laska, vice president of cloud and database Partner ecosystems. Got a bunch of things here to hold on to. Um, thank you, Mike. Um, so I'm gonna take the next few minutes to. Let me go to talk to you guys, um, a little bit about cloud migrations and how our partnership with Intel and AWS supports, um, your journey to get to AWS for your on-premises workloads and, uh, before I get into that, I wanna talk a little bit about, uh, Newtonics and, and, uh, introduced, uh, introduced Newanics to you for some of you that may be a little bit less familiar with the company. And I'll do that in the context of our partnership with Intel and with AWS. So our partnership with Intel actually, as Mike mentioned, goes way back to over 10+ years. It goes back to actually 2012 when we, uh, launched our first appliance in HCI hyperconverged appliance, and we actually launched that, um, based on Intel processors. That initial appliance was actually an ESXI hypervisor. We then went and actually created our own hypervisor. Uh, of course, uh, prioritize making sure that that is optimized on Intel processors again, but at the same time we really started seeing a lot more demand for, uh, migrations to AWS and in general for hybrid cloud solutions. So we knew we, we had to have an answer for that. So we launched a product called NC2 or Nanis Cloud Clusters. Now, when I say we launched a product, we actually didn't launch a new product. All we did was we took our existing on-premises platform and extended it to the public cloud to AWS. And again, for us it was a very clear choice of which processor we wanna support first and which cloud we wanna support first, right? Uh, for many, for some of the reasons I'll, I'll touch upon. But. Um, Uh, sorry, I lost my track. Um, um, so what I was mentioning is, uh, Newtonics cloud cluster is not a, not a new product, right? It's just an extension of the platform. So basically all you're doing is instead of taking the Newtonics bits and launching those on, um, on-premises hardware, uh, you're basically taking those same bits, uh, and putting them on top of dot metal, uh, uh, EC2 instances powered by, by Intel processors. Um, and then. So then, then we entered into a strategic partnership with AWS, of course, that in turn and naturally expanded our partnership with Intel, uh, to go beyond just the on-premises, uh, portions and into, into the cloud portions, um, on AWS. And now today Newtonics is a launch partner for every dot metal, uh, new dot metal type or a shape as well as every new region, right? And today, we're actually um globally available across 34 regions live and across 11 different instance types or shapes that we like to call them. So that gives you a lot of flexibility as you're thinking about your migration strategy to AWS with some of your on-premises workloads of where do you want to place them and then of course, of course different instance types for the different workloads that you may have, right, whether they're compute heavy, storage heavy, and so forth. And again, it's all about optimization of the costs, right, as you get to the cloud as well. So Newtonics um actually runs some of the largest, um, organizations and governments, um, around, around the world and some of the most critical mission critical applications and we're fortunate enough to partner with over 29,000 of these organizations across the globe in various verticals whether that's FinServe healthcare or uh public sector. And we're here to support all of you on that journey, whatever that may look like for, for you, right? So, uh, there isn't really a one size fits all when we, when we talk to customers about how do they wanna go and, uh, get to AWS leverage, um, AWS and, and build out their hybrid cloud strategy. Um, but usually the way that, that conversation starts when I talk to customers is, well, I need a single secure platform. That's able to run my apps, my data, now my AI workloads, um, I also needed to support VMs because most of my legacy applications are written VMs and I also needed to support containers because all of my latest and, uh, greatest applications are probably built on a container platform, not a VM. And I don't wanna have 20 different platforms to manage all that. I wanna have a single platform that lets you manage that consistently across all these, um, all these environments. And then so that was the idea behind uh Newtonics is that we're able to provide you with that single consistent platform let's lets you simply manage that and let's you actually focus on how do I go and innovate and take advantage of the latest and greatest services up in AWS and ultimately deliver innovation for your organization. And I think there's kind of three key pillars when I, we're not pillar, uh, there's 3 key critical critical aspects you have to think about. One is speed, right? So how quickly can I get to AWS and then there's a balance there between, do I just rearchitect everything. But of course that, uh, you take on quite a bit of risk there potentially, right? You don't know what you don't know there. Um, the second one is simplicity. So even if you get to the environment again, how can I manage this thing, uh, given that I'm now running VMs, I'm running, uh, containers, I'm running things on premises, I'm running things in the AWS, can I actually manage this in a single, consistent, secure manner? And then obviously how do I get to modernization? That's, no one wants to migrate for the sake of migration, right? They wanna migrate because there's a reason behind that. And usually it's to go and take advantage of the latest and greatest services and innovations that are happening across with Intel and with AWS. So let me give you guys an example of what that looks like from a customer lens. So Goulding is a company um that's in the mining um um business out in the east coast of Australia. And they've been in business for about 75 years. So they've gone through many, many digital technological transformations in their lifetime. And they had um they had a requirement to get off of their existing platform for licensing costs and other various reasons. I'll let you guys figure out what platform that was, um. And um one of the workloads that they were looking at is a uh DR solution, right? There's other just pure migrations they were looking at to get to just uh AWS and those are just lift and shift to AWS. But one of the, one of the critical workloads was how do they protect their on-premises estates and how do they do that? How do they get to a new platform that allows them to do that quickly, right? Obviously how do they do that in a cost efficient manner and of course they have to meet the RPO and RTO objectives, right? Um, so they looked at one solution was, we're gonna do everything on premises, right? Well, that didn't work because, uh, the cost efficiency wasn't there, right? They have to run two data centers. Um, they have to, you know, basically have this backup data center that's sitting there. They're buying hardly depreciating that hardware, and the bigger their footprint, the worse that problem gets for them, the cost efficiency there. So that didn't work. Uh, their second option was, well, we're gonna do everything cloud native. Well, the time that they had that they migrate off of their existing platform didn't work, didn't get, they, they just couldn't, uh, get there in time, so that wasn't an option. So I ended up going with the Nanis cloud clusters on AWS, and they leveraged a technology called Zero Compute snapshots for their DR solution. And what that basically means is they're they're running their primary clusters on premises and periodically they're taking a snapshot to S3 buckets and they have basically a pilot light on, right, which is a very small amount of compute that's running up an AWS. But in the case of a DR event or when they're doing their regular testing, they're able to quickly rehydrate that environment and spin it up in AWS so that. Got them the efficiency that they needed in terms of cost, right? They no longer have to purchase and run a parallel data center and not only that, like even within AWS, they're not actually running, um, those resources when they don't need them, right? They're really running in a very minimal fashion and, and only consuming those resources when, when they need them, right? Um, they were able to actually get and build up the solution in, um, in the time, the timeline that they had. And then I've actually ended up exceeding the RTO and RPO um uh objectives there. So again, um, it's about speed, right? simplicity, right? So even if they're able to get TWS, uh, quickly, if you don't have a simple way to manage all this, it's, it's gonna then slow down your moralization, right? And how do I go and take advantage of the latest and greatest services that's offered to me. So if you wanna learn more about uh Newtonics and NC2, uh, visit, um, either the Intel booth, the Newtonics booth. You can take a, uh, scanning a QR code there and uh, uh, give it a go yourself. And we're also gonna be hosting a roundtable, uh, on Thursday afternoon. So come by, ask us questions. I'll be there. We'll have the intel, we'll have some of my team members there. We have the intel team there. Uh, and come talk to us, ask us questions, happy to answer any questions and, and see if this is a, maybe a, a solution that's right for you. So with that, I'll hand it back to uh Mike. Thank you. Thanks, buddy. Thank you. Thanks, Michael and um thank you to all of our speakers today. You know, I was sitting over there just kind of mulling through these uh success stories and it's 3 things that really jump out as key takeaways. Number one, and it's obvious to me, it's also not very sexy, but hardware improvement does matter. It's, while it's not sexy, it's absolutely critical to your cloud modernization journey. Because when you get to the cloud, you wanna make sure you have the performance to be able to run your applications. Number 2 Software and ecosystem optimizations. You heard it from Ombud. You actually heard it from all of our speakers. Um, it's not just about hardware anymore. It's about this ecosystem that we're building together to get the most out of our existing infrastructure. And 3rd and final. Supply chain Definitely not super glamorous, but again, definitely critical. When you are moving to the cloud or or bringing customers onto your applications and solutions, you want the confidence to have the highest, uh, highest end technology when and where you need it. So if I had one. Call to action for you guys today. I think it's this. Don't make your cloud modernization journey a solo climb. Think of it as a partnership with Intel, with AWS, with the whole ecosystem. The generation on generation hardware improvements are there. The value of software optimization in the ecosystem is clear, and access to the latest technology globally is available at your fingertips with AWS. The only question back to you is what are you going to reinvent with it? Thank you guys for joining us today. We, uh, we're gonna end a little early so that, uh, we can answer questions. If any of you guys have them, please come up to the stage. Uh, if not, enjoy the rest of your reinvent, um, come visit our booth, come, uh, see one of our round tables that, uh, Michael was talking about. Uh, we have various industry ones throughout the, the rest of the week, uh, or come join us at one of our mixers that we have in the evening. Thank you guys very much.