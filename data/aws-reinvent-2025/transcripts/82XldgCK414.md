---
video_id: 82XldgCK414
video_url: https://www.youtube.com/watch?v=82XldgCK414
is_generated: False
is_translatable: True
---

Hello and good evening everyone. First of all, thank you very much for joining this session, and I wish you a great start to the reinvent. My name is Samanir Fan and I work as a senior specialist solutions architect here at AWS in the analytics team. And in the next 20 minutes you're going to learn how Amazon Redshift data sharing can improve the agility of your organization by sharing live data with relative security and ease across Amazon Redshift warehouses for analytics as well as AI workload. So before I start the session, I have a quick question for everyone here. Who here use Amazon Redshift in production? OK, so even if you're not using it in production, I am sure that if you learn about this capability of Amazon Redshift, you will start thinking about using this. So let's first deep dive into the agenda of for today's session. We are going to start with a brief introduction of Amazon Redshift data sharing. We are also going to talk about some of the technical aspects of the data sharing architecture in Amazon Redshift. Then we are going to dive deep into some of the use cases that customers use data sharing architecture for and some of the customer success stories who have implemented the data sharing in Amazon Redshift and seeing business as well as technical benefits. We're also going to be talking about how in a complex data sharing topology, AWS lake formation, which basically centralizes the permission management of the data shares, can improve the governance aspect of this data sharing architecture. I'm also going to talk about some of the best practices and considerations so in case you want to start the data sharing journey with Amazon Redshift, this is going to be important learnings for you. And then in the end I'm going to conclude this session with providing you with some of the artifacts that can help you get started with Amazon Redshift data sharing. So let's first look into why traditional data sharing is broken in most organizations today. So if we look at the traditional data sharing, it often involves manual data copying and movement, which is basically a tedious as well as a time-consuming process. Customers have to build and maintain complex ETL pipelines which are complex to uh in terms of maintenance, and it requires constant updates as well as monitoring and in case there is a delay in the ETL pipeline, which means that the data becomes stale, and by the time it reaches the end users, it's often outdated. Now in this whole situation, security becomes a nightmare because each data copy creates new governance challenges. Results team working with inconsistent and incomplete data leading to poor decision making. Now these are exactly the challenges what Amazon Redshift data sharing was designed to solve. With Amazon Redshift data sharing feature, you can share live data with relative secure with live data securely and easily. Across Amazon redshift warehouses, be it provisioned or surveillance in the same AWS account, across different AWS accounts, or even across different AWS regions as well for read as well as write workload. And it does this by giving you instant granular and high performance access to your data across Amazon Redshift warehouses without the need to copy or move it manually. And just to reiterate, data sharing is not a new feature of Amazon Redshift, it's already a well established and mature capability with thousands of customers using this feature in production environment. Now let's take a look at how this data sharing works behind the scenes. So as you might be aware of the redshift architecture that it supports isolation of storage and compute, and this is what powers the data sharing architecture. So the storage layer of Amazon Redshift, we call it as Amazon Redshift managed storage that you can see in this visual. Now you can have multiple producer warehouses. Sharing the data for read as well as right purpose through redshift managed storage to the multiple consumer warehouses for the read and write workload. These consumer warehouses can also share the data that they own through redshift manage storage to the multiple Amazon redshift warehouses. And this all happens without having to copy the data and user as well as applications can see the most up to-date and consistent information as it is updated in Amazon Redshift warehouse. Now, let's take a look at what are the different options to create those data shares and to manage the permission and to perform the permission management of these data share. So the first option is a redshift manage data share. Now in this option you can create the data share inside a producer redshift warehouse. You perform the permission management of these data shares inside the redshift warehouse, and then you directly share these data shares with multiple consumer warehouses, OK. Now we recommend this topology to customers who have a relatively simpler data sharing architecture to implement. They have few number of producers and few number of consumers, and the management of the permissions in this case inside the richer warehouse is relatively simpler to handle. The second option is lake formation managed data share. Now in this option, you create the data share inside a producer warehouse and instead of directly sharing these data shares with consumer warehouses, you share those data shares with AWS Lake Formation. Now AWS Lake Formation is an AWS service which centralizes the permission management of your data and gives you the ability to easily share the data across your organization and externally. Now, in this case, the permission management happens centrally at AWS Lake formation layer, and based on those permission management, the excess is granted to multiple consumer warehouses, warehouses according to the permission that is managed at the AWS Lake formation level. The third option is AW's data exchange for Amazon Redshift. Now this option is, uh, uh, this option is used by the customers who actually want to monetize their data. Behind the scenes uses AW's data exchange for. Amazon Redshift uses AWS data exchange where you can basically share your data as a data product into AWS Data Exchange and then subscriber, subscribe to that data product and get the subscription to the data. The, all the management of, uh, the, uh, uh, the, the billing as well as the collection of, uh, the, uh, collection of money, everything happens in the AWS marketplace entitlements service. OK, now let's look at what are the different use cases that customers use the data sharing architecture for in Amazon Redshift and then looking at some of the customer success stories who have successfully implemented these architecture for according to these use cases and seeing the business as well as technical benefits. So there are 4 common use cases that customers use Amazon ratio data sharing for. Again, it's not just limited to these use cases, but these are the 4 common use cases that we see customers adopting. The first one is the workload isolation. The 2nd 1 is the cross-group collaboration. The 3rd is to deliver data as a service, and the 4th 1 is the development agility. I'm going to dive deep into each of these use cases, but at this point in time, just make yourself familiar with these use cases that customers use data sharing for. Now if we look at the customer's Amazon redshift deployment, so they often start with a monolith redshift warehouse, OK? They have the data coming in from the wide variety of sources, and then in the end they have different tools which they use to perform analytics or data visualization of the data using some of the visualization tools, OK. Now in that monolith warehouse, they have a wide variety of um workloads running such as ETL, business intelligence, data science, and ad hoc, everything running inside that single monolith redshift warehouse. Now Redshift supports workload isolation. OK. Behind the scenes, Redshift supports workload management capability, and that offers the workload at some aspect of the workload isolation. But as your workload needs grows, your data volume grows, there comes a time where there's a resource contention starts to happen between these read as well as write workload. And when this happens, what we recommend to our customers is to move away from the monolith architecture to a multi-warehouse architecture using Amazon Redshift data sharing. Now if you look into this visual, what we recommend to our customers is to split up your workloads into separate redshift warehouse. So have a separate reds of warehouse for ETL processing, then use the data sharing capability to share the data from ETL warehouse to, let's say a separate warehouse for the ad hoc workload, a separate warehouse for the dashboarding workload, and a separate warehouse for the data science workload. The good thing is that you can size and scale each of these warehouses according to your workload, price and performance requirement. You can easily onboard new warehouses in case there's a new workload that comes in. Just take an example, let's say an R&D workload. You can simply plug in a new ratio warehouse and simply create a data share from that ETL warehouse to that warehouse, OK? And you can create, you can have the producer and consumer warehouses either provisioned or surveillance again, depending on your workload requirement. And one of the best things is that you can pause and resume the producers and consumer clusters necessary. So what we see customers is that let's say they have a provisioned ETL reer warehouse and they run an ETL nightly batch job. So once the nightly batch job is done. They pause that warehouse in case if it's serverless it's automatically paused, but if it's provision, they pause it and even if it's paused as the data is shared at the redshift managed storage level, the consumer warehouses can can seamlessly query and access the data. OK, so this is one of the uses of how you can perform workload isolation using Amazon Redshift data sharing. Now one of the customers who successfully implemented this workload isolation use case is Peloton. So as many of you may be aware of Peloton, it's a fitness equipment company known for their internet-connected exercising bikes with fitness classes that are streamed on demand, and they have basically performed, uh, implemented this workload isolation use case by splitting a monolith rich warehouse into a multi-warehouse architecture. They have an ETL rich warehouse, and then they have multiple consumer warehouses for ad hoc workload for lucca rich. Workload on for Tableau, uh, a business intelligence workload with this architecture they were able to easily, quickly and easily start new data warehouses. They were able to share the data across teams, vendors, and systems. And as they have onboarded Redshift service into this architecture, they were able to save $3000 annually using this architecture in Amazon Redshift. The next use case is to enable cross-group collaboration. Now think of it. You have multiple teams in your organization. You can have finance team, sales team, marketing team, R&D team. Instead of all these teams using monolith redshift warehouse, they can have a separate redshift warehouses which they can again size as per their price and performance requirement. And this also, um, uh, uh. And they, they, they are able to seamlessly collaborate across business groups for broader analytics and data science and analyze cross-product impact. Each of these virtual warehouse can be producer as well as the consumer of the data and in case if let's say sales team needs to answer a question, for example, what are the total sales for product and customers and in in for that case they need the data from finance or marketing team, they're able to easily get it through Amazon Redshift data sharing. Now, one of the customers who successfully implemented this cross-group collaboration use case is Fennemi. So Fannami basically has the data across Amazon re warehouses and data lake, and they. They use their data to build up a central data marketplace and publish their data as a data product in that central data marketplace. And then from that they were able to access the data using for different use cases such as data science, business reporting, BI dashboarding, query and self-service, self-service analytics. So with this capability they were able to um perform enterprise-wide data catalog for easy discovery and access and they it it's it's they implemented a data mesh kind of an ecosystem using this data sharing capability of Amazon Redshift. The 3rd use case is to deliver data as a service. Now customers can use Amazon, a reds of data sharing feature to offer data and analytics as a service within. And across organization and even with external parties using AWS data exchange for Amazon Redshift, they can securely share live data with Amazon Redhi warehouses in the same or different AWS account and as the data provider basically owns this data set, they can monitor and track the usage of the data and retain control of the data sets. The 3rd, the 4th use case is to share data between environments. OK, now what we see at our customers and that they have different reds of warehouses for different environments such as development, test, and production, and what we see is that they basically copy the data between these environments and create a data replication and duplication. Now they can avoid this data movement and copying of this data using Amazon Redshift data sharing. And they can easily, uh, they can easily provide the production data to the development or test environment and vice versa. And with this, they can improve the agility of their organization by sharing the data between these environments at any granularity, OK. Now we have seen different use cases for Amazon Redshift. Let's take a look at what happens if you have a very complex data sharing topology to implement how AWS lake formation can simplify and build up an enhanced governance model for you. So let's take a look. So let's say you have multiple producer warehouses and you have multiple consumer warehouses. Now in case you need to establish a data shares between these producers and consumer warehouses in M2M fashion, it's going to look something like this. Now in this situation, the permission management of the data shares can be a nightmare if you have to manage the permissions in these redshift warehouses. Now how you can simplify the permission management in this complex data sharing topology is to for these producer warehouses and consumer warehouse use AWS lake formation in the center. Now Amazon Redshift supports simplified governance of Amazon Redshift data sharing by using AWS Lake formation to centrally manage the permission of the data being shared across your organization. With Amazon Redshift data sharing implemented with AWS Lake formation, you can manage the permission grants, view access controls, and audit the permission on the tables and views in the redshift data sharing using lake formation APIs or even through AWS uh console. Now just to summarize, you can centrally manage the permission. You just, um, implement those policies once and enforces across multiple virtual warehouses. There is no manual scripting or complex quering involved to implement this, and it basically simplifies the whole data sharing architecture for you if you have a very complex data sharing topology to implement. I'm going to conclude this session by talking about some of the best practices of Amazon Redshift data sharing that are very important if you want to start your journey with Amazon Redshift, uh, data sharing. So in Amazon Redshift data sharing, the producer warehouse is charged for the data storage only. And the consumer warehouse is basically charged for the compute it used to access the shared data and query the shared data for the same in the same AWS region. In case you have to implement a cross-region data sharing because Redshift supports cross-region data sharing, then the consumer warehouse is also going to pay for the cross-region data transfer fees as well. Data sharing within the same region is free of cost. The query of the speed. Solely depends on the consumer cluster compute capacity and have zero impact on what's happening on the producer cluster. OK, so that's very important to note. In case you have to implement a cross-region data share, it might have high latency because the data needs to transfer across region and there might be some network latency involved. Amazon Redshift also supports concurrency scaling for handling unpredictable workload and uh some kind of a burst workload, and this concurrency scaling feature is basically supported on both producer as well as consumer warehouse, and we recommend customers to use concurrency scaling feature if you have to improve the throughput of your Amazon virtual warehouse in case of period of when there is a peak utilization period. F Redshift also offers some of the system tables that you can use to basically audit the data share usage and changes and in terms of security, data in transit is completely encrypted and data at rest is also encrypted using KMS keys and even the producer and consumer warehouses can have a different KMS keys if you want to implement. Some of the call to action, I have compiled a set of resources for you that you can take along once you scan this QR code, you will get access to some of the blog posts, some of the best practices documents that you can basically help you get started with data sharing journey on Amazon Redshift. So just simply scan the QR code and you can get access to all of the documentation. With this, I conclude the session and I kindly ask you to provide the feedback in this, in the session, uh, for, for the session in the mobile application. Thank you very much.