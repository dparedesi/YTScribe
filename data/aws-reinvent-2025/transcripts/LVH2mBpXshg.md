---
video_id: LVH2mBpXshg
video_url: https://www.youtube.com/watch?v=LVH2mBpXshg
is_generated: False
is_translatable: True
summary: "Mike Gillespie from AWS and Dev Rishi from Rubrik discuss how to deploy AI agents at scale with confidence and control, addressing the common challenges that prevent organizations from moving their AI initiatives from proof-of-concept to production. Dev Rishi, who was the co-founder and CEO of a generative AI infrastructure startup called Pretabase before joining Rubric, shares his insights from conversations with over 180 organizations. The core of the discussion revolves around the rise of ""agentic AI,"" which they define as large language models (LLMs) with access to tools that can take action on behalf of an organization. While building an initial agent has become easier with tools like AWS Bedrock Agent Core, the real challenge lies in operating and governing these agents at scale. Rishi outlines four stages of agentic maturity: experimentation, formalization, proliferation, and autonomous. The transition from experimentation to formalization is the most critical and challenging for enterprises. The primary concern for organizations is managing the risk associated with agents. Agents are powerful but unpredictable, and they operate with non-human identities, making them difficult to govern. This risk is not theoretical, with real-world examples of agents recommending competitor products, hallucinating information, or even causing production outages by deleting databases. This is where Rubric comes in. Rubric, traditionally known for data backup and resilience, is now positioning itself as a key player in the AI transformation era. The company has evolved from protecting against natural disasters to cybersecurity threats and now to the risks posed by AI. Their new product, the Rubric Agent Cloud, is designed to address the challenges of operating agents at scale. The Rubric Agent Cloud is built on three pillars: 1.  **Monitoring and Observability:** It hooks into environments like AWS Bedrock Agent Core to automatically discover agents, create an inventory, and provide visibility into what tools and data they can access. 2.  **Governance:** It allows organizations to define and enforce AI policies, providing the ""teeth"" to ensure that agents are operating within the established guardrails. This addresses the common problem of having AI policies that are difficult to enforce in practice. 3.  **AI Agent Rewind:** This unique capability, built on Rubric's core DNA of resilience and recovery, allows organizations to ""undo"" destructive actions taken by an agent. By correlating agent actions with previous healthy snapshots, it provides a one-click rollback mechanism. The Rubric Agent Cloud is designed to ""unleash agents, not risk,"" by providing a single pane of glass for monitoring, governance, and recovery. This helps organizations overcome the inter-organizational challenges and scaffolding required to deploy agents responsibly, and ultimately, to see a real return on their AI investments. The product is now available in preview."
keywords: AI agents, governance, risk management, Rubrik, AWS Bedrock
---

Great. All right, thanks everyone for joining us today. My name is Mike Gillespie. I'm a principal solutions architect with AWS. I've been with AWS uh a little over 9 years. Deb, hi everyone, I'm Dev Rishi. I'm general manager for AI at Rubric, a data cybersecurity and resilience company. So we're here today to talk about how rubric can help you roll out agents at scale with confidence and control, but first I'll talk a little bit about. Uh How customers come to me and oftentimes they will say we really want to take advantage of agents or we're having trouble with our organization, you know how do we get better control and visibility into the things that are happening within our account, like especially when you talk about agentic AI and and Dev will talk about it shortly, you know that's a big concern for our customers and a real big roadblock from going from POC to production. It's probably the number one thing that's stopping people from doing that. So how do you get over that hump, and that's why Dev is with us today, um, and also how do you do that cost effectively? And the, the important thing is if you're an AWS customer, you know, working with Rubric, uh, we work hand in hand very closely together, so we're very good partners. They're very familiar with the AWS environment, and Deb, why don't you take it from there? Yeah, absolutely, and thanks for the introduction, Mike. I think just to uh give you to give everybody a little bit of the background on myself, uh, I'm Dev. I, as I mentioned, I'm general manager for AI at Rubric, but that's actually a relatively new job title. Uh, until this summer I was co-founder and CEO of a generative AI infrastructure startup called Pretabase. We were essentially the model backbone for a number of customers that were deploying high volume large language models into production. Um, and so a lot of these organizations were really on the cutting edge for where AI was actually already being deployed. Especially in really high throughput scenarios, and we joined forces with Rubric this summer to think about what would it look like to bring some of the same classes of technology that we had built and piloted with some of the leading tech companies over to the Global 2000 Enterprise and beyond. And for those of you that may or may not be familiar with Rubric, Rubric's actually a little bit of a difficult company to define when you join a company via an acquisition. You need to come up with your own framing for what that company does. The way I actually think about Rubric is it's a company that's helped organizations accelerate different enterprise transformations in the past. What does that actually mean? Well, Rubric started off in its, you know, core as a data backup and data resilience company, uh, around the same time that we were making that graduation from tape, uh, onto digital, Rubric really started to revolutionize the world of backup and recovery. The next big shift, you know, I'd say in large part thanks to our friends at AWS, was the shift to cloud, uh, and one of the key considerations as organizations are making that shift to cloud was really around security, and that's when Rubbric uh rolled out the Rubric Security cloud as a way for it to become a lot easier as you make that transition and have more cloud native opportunities. And now I think we're on the advent of the next transformation era, which is the AI transformation era. Within this, you've probably heard a lot about AI transformation at Reinvent already. Yeah, it's hard to walk past the booth without it saying AI. The underlying trend that we've really decided to be able to underwrite is what we call the rise of agents or agentic AI. Now, many different people have different definitions for what agents are, so I wanna start off with my own. The way that we define agents are just LLMs with access to tools. So you can think about that as models that are capable of interacting in a production setting. Uh, and taking action on your behalf or on an employee's behalf. Over the last 4 months since I've had a chance to join Rubric, I've talked to over 180 different organizations, existing customers, as well as net new prospects in IT, in security, in engineering, and in AI organizations, and probably the most clear trend that I've seen is that agents are coming. Uh, in fact, in a lot of our slides that I've used, I've had this slide around agents are coming, and the enterprise has told me no agents are already here. The challenge that I think that a lot of organizations have is no longer what it looks like to be able to build agents, thanks to really great tools like AWS Bedrock Agent Core, as well as a number of other agent builder tools, it's actually never been easier to start to build your first agent today. Hooking an LLM prompt up to a few models may only take days or weeks in order to be able to really validate the end to end experiment. But what customers tell us is that their real concern is around what happens after that initial experiment, how do I actually operate and govern these agents really at scale? After the 180 conversations that we had, um, you know, we created something that we call the four stages of agentic maturity. These are the four stages that I see customers really go through as they go from ideation on we should do something with AI all the way to what I consider AI native enterprises. The first phase starts with experimentation. This is usually the area where you're starting to build maybe your first or your second agents. The second stage is what we call formalization. I think that graduation from phase one to phase 2 is actually the most important one that enterprises go through, so where the agents builder experience goes from cool prototype or demo to something that actually operates within a context that the enterprise can consume. We'll talk a lot more about what this actually requires in just a minute. The really interesting thing I think about the rise of agentic AI is then stage 3, which is proliferation. One thing we've noticed is it can take weeks, uh, it can take months or quarters, sometimes even a year to get to stage 1 or 2. To build your first agent, your second agent, even your third agent can take quite a bit of time. But by the time you've actually done that rinse and repeat process of building your 1st, 2, or 3rd, we've seen organizations scale up to hundreds quite quickly. That's what we call the proliferation stage. Then finally we have autonomous, which is relatively uncommon, but this is when agents are actually operating with full right permissions and actually acting on behalf of organizations. Out of the 180 customers that we spoke to, this is how we classified, you know, the breakdown. Over half were still in experimentation phases. About a quarter were in what we call formalization. Uh, and you can see the balance here. The ones that aren't represented, about 13%, uh, had not yet started on the AI adoption life cycle. Just out of curiosity, out of a show of hands for everyone in the breakout, who would classify themselves as still in the experimentation or not yet started phase? OK, and I'll just assume that the balance are probably, um, you know, in the next phases or so beyond. As organizations start to make that shift from experimentation to formalization, one of the key concerns, I think that are, uh, you know, we've heard reported is that it's no longer necessarily the difficulty of building these agents, but it's how to think about and manage risk. Now this is a problem that is actually very close and near and dear to Rubric's heart. Um, I mentioned a little bit of how rubric had evolved across time. Turns out the data backup market had evolved across time as well. Data backup used to be about protecting business continuity in the world of natural disaster, fire, flood, then it became about cybersecurity because the number one threat vector was no longer a flood, it started to become a ransomware. And I think, and I think our view is that in the future. You know, the real threat vector that organizations are predominantly concerned about now is going to be AI in nature, whether that's malicious or inadvertent, like an example of a coding agent earlier this summer that went viral because it got access to a production database and decided that the best way to optimize a subroutine would be to drop the database and delete it altogether. And so we see that agents and AI have this capability to be able to do 10x the damage and potentially 1/10 the time. And the truth is agents are, you know, are powerful for the same reason that they're difficult to actually govern. Um, they are unpredictable, uh, and oftentimes they're what I would consider weakly supervised in a lot of organizations. There's a governance process before they could get rolled out where someone has to approve what it is they do, but rarely does that actually have hooks into what they're doing at production time in real time. In addition, they're operating with non-human identities, which I think makes it really difficult to think about them at scale. And uh one of the most consistent questions that I think I hear from enterprise organizations is how am I supposed to rationalize all the different things that AI agents can do, the nondeterministic way that they might operate as well, you know, they're probabilistic systems in nature with the fact that they have production systems, how do I actually, uh, how do I actually have a framework for thinking about what could like what do I do when something goes wrong? Um, and for better or for worse, you know, these instances of where things can go wrong are not theoretical. We see them even in the very early days of AI agent adoption today on things like AI agents recommending competitor products, hallucinating things like refund rules, or, as we showed earlier, potentially deciding that the fastest way really to optimize something might be to delete it altogether. If we think about the common refrain you've probably heard, you know, in the news or even here, it's about are enterprises seeing ROI from AI adoption. My view is that enterprises aren't quite seeing that ROI yet because AI is not even necessarily being able to be pointed in attacking the most important problems, because the most important problems are too risky to be able to place directly in these agents' hands. And I sit on Rubric's AI governance committee, so I actually feel very viscerally why some of these challenges are hard to be able to enforce in practice. One of the things I told you by definition of how we discuss, uh, described agents is that agents operate on production systems. You can think about this as Salesforce 365, your AWS environment, but they operate on these systems that weren't necessarily architected to be able to support an AI native workforce. And so what we typically hear from customers is this um thought process that AI is moving quite quickly and so the proliferation of agents is either going to start, has already started, or something they see happening over the next 6 to 12 months. But they don't actually have a system that gives them the initial set of answers that we kind of consider table stakes on the single pane of glass. It oftentimes starts as simply as do I have a good answer to be able to say what agents are in AI is actively running inside of my ecosystem today? Can I quantify the risk on what tools and data they can access all the way down to what do I do when something actually goes wrong and how do I recover. I think a lot of these same types of concerns is what we saw at Rubric as we were a first party building out agents and Asian platforms internally. What we saw was that building that initial proof of concept was something we could typically do with IT or engineering in about 2 weeks. Where we got stuck was when we had the need for approvals on each marginal project. I see a few people nodding their heads, which I assume means that people have been through this process before. You know, the frustration I think here really stems from the fact that we're asked to go very quickly, but that we also are continuously needing to uh review and approve each individual project. What our team really asked for was rather than having to go through the system where I need to then go resubmit new approvals every time I go and you know my initial timeline goes from weeks to months, give us a framework that we can operate in and as long as we're operating within that framework, let us build the different types of agents that actually are, um, you know, sticking close to that so we can get to our end goal of really being able to deploy into production. So that's the long road that I think exists today and to be frank, I don't think a large part of that role today road today is actually necessarily technical in nature. It is a lot of interorganizational challenges and scaffolding. But those challenges are very real because of the risk that AI agents can pose if not properly governed and if not properly operated. That's why Rubric's interested in this space, as a company that's helped organizations and enterprises through business transformations, we just released our newest product, which we call the Rubric Asian Cloud. The Rubric Asian cloud really takes some of Rubric's core understanding on what we call data and metadata. So if you remember, Rubric started off as a company with a rich understanding of what was the data that needs to be backed up and metadata, which is essentially what's the application context for where that data goes. Rubric layered on an additional set of offerings in identity. The observation was that most production and ransomware attacks actually happen because an identity system is compromised. So Rubrick said we not only need to know where all the data is, but we need to know what are the identity systems that are underpinning this organization and who has access to that data. Rubric started off with these two. Components and then with the acquisition of my company this summer we brought in an LLM and AI platform that users were using for agents and agenttic deployments and so we think that these three ingredients really uh position us well to be able to solve the challenges that exist around operating agents at scale. And if you're, you know, like a number of folks that I've talked to, this slide sounds good, but then the first question is what does agent operations actually mean? Uh, and to us, agent operation really means three key pillars. The first is starting with monitoring and observability. You can't govern, you can't improve, you can't fix what you can't see. And so what Rubric Asian Cloud does is it hooks into the environments that you have, including through our integration with Bedrock Asian Corp, to automatically discover agents and populate what we call an agent inventory, providing you a software defined non-manual way that you can actually see what are the agents that are running inside your ecosystem, what are the identities associated with those agents, and based on those identities and agents, what are the tools and data they have access to. The second pillar is something we call governance. Uh, I asked, you know, who here, uh, who here has an organization where there is an AI governance committee as an example? Your organization has AI policies. OK. I think most most of the folks actually in the room are, are probably in that boat. One of the, I think, um, unfortunate realities is a lot of times governance includes a lot of policies that are very difficult to enforce in practice, so we say things like AI agents should not be able to give financial advice on behalf of the company or AI agents, um, you know, should be read only by default but not write. And while this gets approved at, like, you know, a point in time, very few places offer like essentially the teeth that are able to stick into any sort of agent flow and actually monitor to determine whether or not those governance policies are being appropriately followed and so our governance pillar really has just the two abilities of being able to define policies and then enforce policies that agents or other systems need to be able to track. And then the final capability that Rubric Agent Cloud brings to the table is something we call AI agent rewind. Agent Rewind is a unique capability based on rubric's core DNA to be able to help with resilience and recovery. Agent rewind allows you to undo a destructive action by an agent if it's taken on any sort of protected property that rubric already protects for your business. So if your agent, for example, went off and deleted a production database by mistake or made the wrong edits to the column in uh Salesforce, Agent Rewind allows you to correlate those agent actions with the previous healthy snapshots that exist inside of Rubric's backup and do a one click, uh one click undo, essentially using both of those components of our technology. Our view is that the Rubric Asian cloud helps solve one of the most compelling challenges that organizations face when it comes towards responsible deployment across AI and really faster deployment across AI and with that, you know, we've really built the rubric, um, agent cloud to be able to unleash agents, not risk. Hopefully if you've been around Vegas and the Strip, you've seen that a few more times, uh, but to be able to unleash agents and not risk building on top of the same primitives as the rubric Security cloud. We have been really in large part motivated to be able to solve this challenge based on the same types of experiences that we saw with Rubric as Customer zero. We saw a lot as well as the customers that we've spoken to over the last, um, uh, over the last 4 to 5 months. What we've seen is that even at Rubric Customero we see this where we have hundreds of use cases for agents across organizations, complex sets of requirements because we need to balance infosec, legal, IT, and others. And policies that need to be made in the process and be audible as well. So we've taken really I would say a mix of our experience first party as well as the experiences that we've had interacting with a lot of our customers and prospects uh over the last uh since this summer and we've started to combine them into the actual platform that's now available in preview today. So with that, um, I just wanna thank you for thinking a little bit, uh, for attending the talk. I'll skip through this, uh, animation, um, but for attending the talk that we're, uh, able to give here in terms of how to be able to actually accelerate AI adoption in the resilience and AI era. And if you're thinking at all about how to be able to deploy AI and AI agents more effectively at scale, please do come check out our booth, uh, where we'll be able to show you some live demos of how the Rubric Agent cloud actually works in practice. It's difficult to miss on the expo floor, or please grab me right after this, uh, and more than happy to talk through this further. Thank you everyone.