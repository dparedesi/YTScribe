---
video_id: 5mYomWdYM0g
video_url: https://www.youtube.com/watch?v=5mYomWdYM0g
is_generated: False
is_translatable: True
summary: "This session, \"How Sophos modernizes security data at scale with Cribl and AWS (MAM105),\" features Cam Amir and Ed Bailey from Cribl discussing how Sophos, a major cybersecurity company, revolutionized its data strategy. Facing a 60% annual growth in telemetry data and unsustainable costs with legacy SIEM (Security Information and Event Management) tools, Sophos adopted Cribl Stream and Cribl Edge to act as a \"universal receiver and router\" for their data. The core of the strategy is \"data tiering\": routing high-value data to the SIEM (saving ~48% in license/infrastructure costs immediately) and low-value but necessary data to cheaper object storage (data lakes) like Amazon S3. They also used Cribl to de-risk their migration to a new SIEM by \"forking\" data to both the old and new systems simultaneously for validation. The talk emphasizes the concept of \"Data Independence\"—owning your data format and destination rather than being locked into a vendor's proprietary ecosystem—and standardizing logs (e.g., fixing timestamps) before they hit analysis tools."
keywords: Cribl, Sophos, Security Data, SIEM Migration, Data Observability, Telemetry, Cost Optimization, Data Tiering, AWS, Log Management
---

Hello and good afternoon everybody. My name is Cam Amir. I am with Cribble. I will be taking, uh, over for Chris O'Brien, and with me I have Ed Bailey. Uh, thank you very much. My name's Ed Bailey. I'm Cribble's Field CISO. I just wanna say, uh, we're, we're really missing Chris not being here. He had a family emergency, and so Chris, we're just, we're thinking the best thoughts for you, but we're here in, here, we, we'll be here in spirit. We will try to sound sophisticated as you do. But we will fail. But we will try our best and thank, thank you everyone for being here. Thank you again. Uh, and for this session we're gonna talk about how, uh, SOFOs use Cribble to modernize their data security for, uh, their AWS data and other data sources. So, first things first, just kind of put the agenda out here. Uh, we're gonna talk about the challenges that they faced, the solution they came up with, uh, the outcomes that came from this solution together, lessons learned, best practices, we're gonna do the best we can, obviously, channeling our best Chris impression. Uh, quick demonstration and then questions and answers, so please feel free to ask us some questions at the end. So to tell you a little bit about Sophos. Sophos is a just a company with an enormous footprint across the world, specializes in MDR analyst and coverage, 600,000 customers, just unbelievable wave of data. And where Cribble comes in is to help, help secure the infrastructure, help secure the software, help give Sofos the ability to control costs, but also provide better solutions. So it's just, it's really important. This is for a key global company and just, uh, one of, one of the more phenomenal security vendors out there. Absolutely. And about Cribble, so Cribble is a late stage startup. We've been around for about 7 years. Uh, we have a, uh, roughly, you know, 1,000+ employees. Uh, we've been in the data space for quite a while. We kind of pioneered this data pipeline telemetry data, uh, solution, and we're backed by a lot of leading, uh, venture capital firms. So the challenges that we all had was just that I mean the exponential telemetry growth. I mean we see for most companies 28, 38, 3, you know, 28, 30% is common. So folks, it's more like 60, so much data and that generates an that generates a corresponding amount of, of data coming off the systems that needs to be collected, needs to be secured for observability and security. And this and just incredible diversity of sources as well, you know, every cloud, every endpoint, so many types of data, and this is what we see in the IT space, IT and security space. It's the wave of data. It's the diversity of data. It's all coming out of there. And finally then cost, and then this, the legacy tool sets just cannot keep up. We tried very, very, Sofas tried very, very hard to build its own set of tools, tools, conduction of commercial collection of open source and. It, the cost, the engineering cost wasn't sustainable. The cost of SEM wasn't sustainable. The storage cost wasn't sustainable, and they needed to look for something different. And this is where Sopos then came to Cribble to start looking for something new and a way to solve these challenges. And this is a story that we at Cribble have heard many, many a time, uh, from what we see in the industry, roughly 30% Kager, uh, year of year growth of data, telemetry data is primarily what we're talking about here, laws, metrics, traces, uh, and there's also an additional component here where AI is starting to kind of kick up even more data that's being generated at scale, and both of those are kind of leading the charge as far as how much data is being generated, but everybody's budget typically doesn't grow at the same rate. What we're seeing is that the. Major difference between what the data growth looks like and what their budgets look like is significant, and that's kind of where Cribble is found. Yeah, but add on to that. I mean this is something that we see a lot. This has been going on for quite some time. The oldest, oldest conundrum in IT and security is I got 2 terabytes of license and 10 terabytes of data. How do I make this work? I never forget this is just before I, I discovered Cribble completely by accident in 2018. I get pulled into a meeting with my, with my CIO complaining about what you're, you're spending so much money. I thought I was doing pretty good containing costs to around 30% when my logging volume was growing 200% and so, and the, the irony was I'd just come from a meeting with a bunch of VPs complaining about I wasn't giving them enough data to do their job. And so this is something we feel deeply. We see everyone's out there because you, you, you know, you need more data. You need to meet all the challenges, but how do you maintain the cost? And that was something that was just really unique is being able to thread the needle between manage your data but also have better quality because at the end of the day. Um, high quality data solves problems. Less data doesn't solve problems. Good data is what solves problems, and that's where Cribble comes in. And that's kind of where Sofas came in and started to see the value of Cribble. And with that they're able to start to see these kind of exactly. And then the modernization was huge, being able to start replacing piece by piece. Displacement costs are a huge issue in any enterprise. You have some vendor that comes in and says, Yeah, you gotta replace all that stuff right away. You gotta install our agent everywhere, and the, the cost of installing agents. Like for me, you know, early on if I had had. To put a cribble agent on 200,000 endpoints, does not would not have happened. Instead, I was able to start simply by the idea of I could put a couple 100 stream servers in place, use the endpoints are the sources I already have, and start getting value, and then grow my footprint over time. So now I can manage my displacement costs and get fast value. I think. And later on you'll see that how just how completely transformative that was. And when Sofos then put stream in place and then they started to push, push the, the cribble edge agent out a piece at a time so they were able to then manage the cost but still get value from the entire solution. And then they started working for optimizing for volume cost. This is where I think data tiering is incredibly important. You always have to think about that. Here's my data set, and this is where people get in trouble with, with monolithic SIM vendors is you have to put all your data in the same place. You typically your SIM is gonna run you about $1 a gig. And you have to always ask yourself, does all the data in my SIM, is it worth $1 a gig? And more often than not, that's not the case. So you always have to look at, you know, what's worth $1 a gig, and if it's not worth $1 a gig, we need to start looking at what putting it somewhere else. You, you just work with a lot of customers. What do you see with, um, especially with data tiering solutions that, that makes sense for, you know, for most customers? Absolutely. I mean it, it starts with. The legacy solutions that they have in place. So we back up a little bit and say, look, I have a bunch of Syslog servers. How many of you love going into SIS log servers and modify configuration files multiple times? That's not exactly what I call a fun job. So here Cribble can kind of put itself in place to help fix that one problem and then slowly look at your WF if you're trying to collect Windows events, WFWC. That's a joy to do. Oh, I got the wrong certificate. I got the wrong configuration set up. So here's another solution that Cribble can come help with. And piece by piece when you start putting these things together, then you can start going down the path of now that I have all the data that I'm that I need, or at least a subset of the data, I can start optimizing that data. So all the debug files, all the debug laws, all the things that are generating. So much waste in my SIM and so much waste in my infrastructure, I can start to, you know, tune that out and make it so that I'm getting way more signal than I am noise, and that's where we start to see a big plus for Cribble. And that's a key piece by with by having stream in the middle, being able to understand, OK, this is my detection event, this is my IR event, this is my compliance event. Being able to understand your data and then route accordingly gives you that power to now scale so that you can make sure that hey, you know, we're gonna drive the best quality data we're gonna power our detections, get the best results, but still maintain control, have all the other data. I think last night I thought I put it really well with the idea that there's data you have to have, there's the data you might want, and there's the data you don't want, but you have to take it anyway. Split it. Stuff like that, start using stream, then start managing, start, start putting the data where it starts matching cost and value. And so then you can then, then that, that way you can then focus on how do I get more value from my SIM. And this is another big project for Sophos was migrating off their SIM. SEMs are risky. You see it all the time where companies will, will routinely, you know, come to us, you know, we spent 1 year, we spent 2 years trying to migrate to a SIM. We started problems we couldn't migrate. Now we have 2 SIMs. We don't like this. And this is the thing that the idea about stream was so powerful. This is something I discovered early on. This is the same thing with Sophos. The idea of my data is coming through. I can, I can put a copy of my data to my legacy SIM. I don't disrupt my posture. Nothing changes. Then I put in, I fork a copy of that data over to my new SIM. So now you have the entire production volume going to your new SIM. You can now start building your content. You can now start validating. Did my legacy SIM get a hit? Did my new SIM get a hit? Oh, you know, back and forth, back and forth to make sure that your content works. This is an underappreciated issue. SIMs are complicated. You gotta validate. You, you have to cover your edge cases. You need more data. So having stream in place makes that possible. And we just recently with a really large insurance company, they were on a, a legacy SIM provider for about 10 years. We helped them migrate to a, to a next gen center, next gen, um, SIM option. In about 5 months this is something that previously just would not have been possible and so we're so proud to then bring this and help Sofos do the same. Anything you wanna add about that? Oh, absolutely. So a lot of the times when you're talking about a SEM migration. You talk about this hard cut over right where you're saying, OK, I'm on my legacy SIM and now I'm gonna go to a new SIM, yeah, the Viocon Dias moment. Oh yes, oh yes. So all of a sudden you turn on their agents, their collection things and going on, and none of the detections work, none of the dashboards light up, and now you're kind of up some creek without a paddle. Here with Cribble, you're, you know, forking the data across multiple SIMs. Actually we had a couple of customers that have tried multiple SIMs in a POC to pick the one that actually worked best for them. So again, giving you that choice and control of your data, you can see that in any SIM that you want to try out and it leads to customers having a much more satisfied approach to getting their SIM and then being able to cut over to it in a very soft and kind of easy manner. Yeah, we've had a number of customers that will, they'll, they'll cut over to the new SIM, but they'll leave the data to the old SIM going. I don't wanna see, so just like, like, I wanna see what happens for 30 days. I wanna make sure that we, we, we didn't forget something. It was really powerful because at the end of the day when they're ready you literally go to a button inside a stream, you turn it off and you're done and it it makes that transition to a new platform so much easier. It's easier in your teams. It takes the risk away and also from a cost perspective it's not unheard of. You're, you're, you're, you know, even for a small sim implementation you're gonna be paying, you know, a million a year. And the idea is that, so my, I'm not gonna be able to get value for my selementation for 89, 10 months a year. So that's an entire, entire million dollars potentially you're not getting any value from and being able to accelerate that process to say go to, you know, 5 months instead of a year, you're now recovering that that money. You're not recovering that value for your company, yeah, especially if you're talking about the ARR model now. Before it was like, OK, I paid for a license. I got that license. I can let it sit on the shelf. If I buy a SIM now, I have 3 years at least, maybe 1 year to get that thing to be valuable for me. So if I can accelerate that so that I can actually start getting value from it from day one. And thankfully with cloud it makes it a lot faster because I remember the days of Splunk where you had to go set up indexers, set up search ads, and do that fun dance. Here you have everything running in the cloud. Only thing you're missing is getting the data to the SIM. Now we accelerate that. You start seeing value. Your boss sees value. Your boss's boss sees value. Suddenly that investment in the SIM and investment in Cribble is well paid for, right? And that's why we always talk about the idea of solving problems with better data, you know, options. That's where a choice. To control comes in and just this is just it it's an important concept so but always remember the idea about data tiering matching cost and value and then de-risking your SEM migration. There's nothing worse than being stuck with a SIM that you don't want and so this is the idea of making a modular component gives you a lot more options at the end of the day. And now, here's kind of the way that it all happens. So what I'm gonna show you are, this is our portfolio for Cribble. We have Edge that effectively sits over here on the source side. So if you have an agent, great, you can still use your agent to get data into Cribble. We can also use Edge, which is kind of a replacement for an agent to get that same data Trevor, uh, transited through Cribble stream or directly to your destination. Then in the middle is our flagship product Cribble Stream. This is where the magic happens. We effectively are using that to collect data from sources, any typical protocol we can collect the data from. We can then transform it, route it to multiple destinations, enrich it. Uh, we can also look for PII, and if there's any sensitive data, take it out, encrypt it so that it doesn't land in your SIM. Great story about that one. We had a very large company that was sending PII to their SIM. Big no no and they had to basically go back, take the data out of their STEM. This was a fun one. Replay it with Cribble after they sanitized it. Cribble was able to sanitize the data, put it back in the SIM. Everybody was happy. Compliance was restored. What a nightmare. I know, uh, and then the other two components here, very briefly, we do have a lake offering. So this allows you to basically leverage object storage at scale with your organization with built-in role-based access control. This makes it so that lighting up an S3 bucket is typically fun. Uh, in an organization we have to ask for the right policy, the right roles, the right, uh, retention policies, all of that's built into Cribble Lake. Uh, we also have the ability to accelerate that data in Cribble Lake with Lake House, so you have fast search. And finally you have Cribble Search, which kind of is the umbrella across all these components that allows you to query the data at rest through APIs, a lot of very fun things. We actually have a new integration with Security Hub, so come by our booth, I'll tell you more about it. And so how Sohos is used in the current portfolio, starting with Edge, and this is, I've, I've, I've, um, managed thousands and I mean tens of thousands, probably close to a million agents in my career, managing agents is a true pain. There's nothing, there's probably a few things that waste more time than trying to manage agents at scale. And the thing I just love about Edge is it centralizes all that complexity. Get it installed. You now have a policy-based way to manage everything from the same place. You can upgrade it, monitor it, understand your data. You can customize it, add scripts, do everything you need all from one place. Gives you scale. It gives you ease of use. And most importantly, for like when I was an engineering manager, the idea is that how you can then out, you know, I can have junior people manage this. I don't need, I don't need someone senior who's managed, who's figured out the, the YAL, the, the YAML syntax of the day. Just make it easy. Give you what you need. Get your data and, and move your engineering time off your endpoints and move your engineering time to getting value from your data. Also using Cripple stream, so Cripple stream in the middle. So Cripple stream is con is getting all the data, all the sources, including from Edge. And then giving that ability to now parse, enrich, tier this data, route this data as you share it across the enterprise. This is something at the end as we start going through the our, our, our demo is to start showing the value of sharing data throughout the enterprise. I think that's really underappreciated is every time that you share data you're not compounding the value. So you take something as prosaic as firewall logs, can help solve problems for the SOC, the Knock, your DevOps team, your network engineering team. You may laugh, but you would be surprised how oftentimes network engineers don't have access to their own laws. And so these are the kind of things where I just share data to get more value from it and streams in a unique position. To share data across the enterprise and do it safely, I think that's a key as we work, work with security teams. The idea that, you know, here's the pieces we can share, here's the pieces we can, and stream gives that ability to do so. I've really been impressed with how sophisticated Sophos has gotten and just in, in, in being able to make sure that they're maximizing the value of their data because then at the end of the day you have. Go back to your business and show what's the point? You gave me all this money. How do I benefit the business? How do I move the business forward? How did I save money? How do I enable new capabilities? And when you start speaking the language of business, business leaders are much more likely to invest in you, invest in your program. It's just really important. Always remember you gotta move the business forward every day. And one more thing on this slide. Actually two more things. Number 1, there's actually AI built into Cribble where it keeps the operator in the whole process here. We're not gonna put you through a black box and say, hey, look, magic's gonna happen. We're gonna help guide the operator to get their job done. So the AI components allow operators to build a proper pipeline, and you're right in the middle to make sure it's done right, to maybe write a natural language query that makes sense that you can actually pull data and understand what the data is that you're collecting in Cribble Lake. So we have all of that and the best part, the best part about all of this is that you can actually try this out yourself today with a free Cribble cloud tenant and you know, see the value for yourself with your own data. Uh, we do have a free tier up to 1 terabyte of data per day, so I wanna make sure you remember that part. Yeah, we gotta remember to say AI a lot too. I mean, look at someone counting in the audience, how many times you say AI. So we gotta, you know, but, but that's part of the issue, and I think this is something I'm really pleased with Cribble's approach to AII. How can you use AI to help your users just get more value from the tooling? Remind for the search interface is wonderful. I had a, uh, I owned a large searching platform and I had 5000 people using it, and keeping everyone trained was a nightmare. And so having AI in place for a cripple search, the idea is you, you have your own personal helper of how to find your data, how to search your data, just a better query, a miracle upon miracle when you make a dashboard, it's gonna help you make an optimized dashboard by default. You're not gonna have to know about the magic of a base search. And so these are the kind of things that just help, help just get more value from your tooling. And this is also as we're starting to roll out more gentech workflows to now find the data that matters, started to help putting a, there's a background helper that we're about to load up into stream to help look for data that might be of concern, you know, you know, AWS access keys, PAI, PHI, all sorts of different shapes of sensitive data that you may not know are there. It's just little by little help solving these big problems to help make you more productive and at the end of the day get more value from your data. One of my favorite features, by the way, this is a little side note, is within Cribble there's whenever you make a configuration change it's a Git repo behind the scenes that gets updated. Normally, it gives you a little text box to say, OK, go ahead and type out exactly the changes you made. Forget that there's a little GAI button that you push that actually tell you all the changes that were made in that configuration modification, puts it in the get notes or the, the, uh, commit notes, and there you go. Simple little things like that. So that 6 months from now when someone goes back and say, what changes happened here, you actually have legit notes, not I configured cribble send. It's actually something useful. I know I spent years yelling at my engineers and code reviews about not writing notes, and now you have a little button makes it easy. I mean, they would literally write me notes about, you know, FU because I'm not doing this, you know, kind of thing. So I mean these are the ideas that, you know, the idea make use AI to make your lives easier, make the tools easier, and get more value, especially get, get it faster. Let's talk about the outcomes, and this is something I think just, and this is why Chris did such an amazing job with rolling out Quibble. I mean, 48% cost savings within the 1st 30 days. That's awesome. And this is the idea that start being able to show your bosses, you know, that dramatic rise in cost. Here's how we can put fast, immediate and real controls around it. And this, and this is where governance comes in because there's a whole program to make sure to look at your data. Always look at your IT and security data. It's changing, it's churning. You make sure you understand that so. Constant looking, constant reporting what's there. Data independence was one thing I'm really impressed from a strategy standpoint that SOFAs implemented early on. The idea from a first principle standpoint, we want our data to be portable. We want it to be, be useful. We want it to be high quality, and this is the idea of data independence, I think is so important because too often with the, with the modern SEM vendors, you got a proprietary agent talking proprietary code or protocol to a proprietary back end that runs a proprietary search language. The idea by making all this portable and independent. You know, it's my data. It's not my vendor's data, it's my data. I can now have my data inside of a data lake. I can now use something like Cripple Stream to do a replay to put my data into Slok Elastic, data bricks, Snowflake, take your pick. I can use that data anywhere I want to. It's no longer stuck. And so just I think it's a very powerful, very powerful idea of how we can get more value from your data. Bring the discipline to too many that, that, that you see all the time in BI institutions of business value. Bring that discipline over into the IT and security side. You can see enormous value. This is where we started in governance. Secure by design is something I think Sofas is very proud of. They spent a lot of time. Making sure that their software, their hardware are secure, unlike some other vendors that seem to make an RCE, you know, a feature instead of the bug, they're very careful about that. And so that's something they do early on by making sure they're instrumenting everything coming into Cribble. They're and they're looking for things all the time in order to make sure everything we release is secure by design. And finally, the idea of, you know, we, we've talked about better data now we can maintain cost effectiveness. So we're showing value, but also managing within our budget, and that's very, very important. And one thing about cost effective, I just wanna kind of double down on this one. Typically the reason if you saw it, remember the first chart I showed you, 30% Kager growth, and it's, you know, exponential. One of the things that you're trying to do with this data is you're trying to basically make that. You know, hockey stick chart look a lot more manageable, a lot more like your IT budget where it's predictable, so you can start taking data that you didn't get before your proxy logs, your DNS logs, all those rich valued data sources that you just can't afford to put into your data, your data destinations actually affordable again. So this is kind of the big win that you have with something like Ribble. Yeah, this is, and this, and that's really important. So even I'm gonna double down even more. The idea is that you're rarely gonna have less. You're rarely gonna have less. So you have your established budget. You're getting in trouble because you're going 25, 25% more every year. If you can get it down to 5% because most, most businesses accept there's gonna be 567, 8%, that's just unavoidable. 30% is a problem. You're rarely gonna get to less. And so the idea is flat. Out that cost curve and that way you can then talk about here's how we can get more value from your data. Collect the right data, control it, but still maintain your costs. Absolutely. And now one of the most important things I think most practitioners here are gonna come for is a lesson learned and best practices for this. So here's what Sophos was able to learn, right? It, it, this is, this is something I think it's important for everyone to have a plan. You're not gonna get a single control plane across all your data on day one. Just not gonna do it. Have a plan. A long term plan. The idea of bite by bite, we're gonna advance across the enterprise across every line of business to have a consistent strategy to collect your data. It's always important. Think long term, you know, plan, you know, plan long term, and then, and attack that little by little because it makes what ordinarily be an enormous project a lot more digestible. And so this is one of the big lessons. It's just, it's important to have that visibility. Imagine you have a data plane across your entire organization where I can see where my data is coming from. I can see where my data is going to. I can detect if a data source is down. I can detect if the data source is degraded. I mean, who, I mean, anyone who's been in any kind of incident, it has, has figured out all, all of a sudden my, my data source stopped working. It stopped working 3 months ago, and the only time you found out is because now I need to look at it. It's typically very difficult to monitor. So having that having that centralized data plan gives you a lot of options. Filtering and optimizing data early, I think is important too, where this is in this is also from a long term perspective. Start building up and as you look at your data, start building up a long term backlog of, OK, this is what we want to do with our data. Here's what we can do. Here's what we wanna do. One of the big struggles is, especially with data that's being used, is you gotta work with your users to update your content to reflect new formats. And so you have to have this this careful planning and communication process like I did with my team. I had, I had these thousands of users, so we had communications of every couple of days we started rolling out changes. We notified our users. We managed our risk, and kept moving forward. And so just make sure you have a plan to do that. Another big key as well, and this is something I really appreciate with Sophos going into the data tiering, is start looking at the data you're not using. I will guarantee you if you look inside your SEM. You're gonna find 20-25% of the data that's not getting touched in 90 days. That's the first thing, first thing you do. If you're not using it, don't put it in your SIM. Move it to your, move it into your data lake, and now you freed up 25% of, of your, of your SIM just by and without any kind of disruption. So just really look at that long term. And I think that first principle everyone talks about with data tier is match cost and value. Is the data worth $1 a gig? If it is, absolutely that's what the SIM is for. If it's not, put it somewhere else. And finally, the phase migration approach which we've, we've talked about. Anything you wanna add? Yeah, I just wanted to say, you know, on that data sharing piece, you know, most SIMs are running on very expensive disk and without even talking about license cost, the disk cost, the people cost to get that data in, it's not cheap. And if you can save on those as well as you know, potentially a license help, I think that's where you get a real big win just long term. Yeah, we've seen this repeatedly even with companies that have an ELA for their SEM, for example. They're still saving tens of millions of dollars by moving data that they're not. Using out of their SIM and that's just from the storage of compute cost alone, especially if you're running it, if you're hosting yourself in cloud. The costs are just astronomical from an optics perspective. So I always take a really hard look at, and from a governor's perspective every day understand what people are using, what people are not using in order, in order to just have some controls there and then also make it part of your onboarding process, have a set of, you know, the idea that you have to be able to say no like this data has no value. We're not putting it in here. This is where, this is where the governance and policy process is really key to just help provide answers because otherwise you're gonna drown in data, you're gonna drown in cost, and eventually you're gonna have that meeting with your leadership who, who aren't happy. And I will say this, when you have a centralized approach to this logging solution that immediately gives you options that also gives you the little more control of this data, and you can make it repeatable so that you, the security operations person. Is not going in and having to build these pipelines, build these things, you can actually push this down to maybe the application owners. So now they have the ability with the tooling in place to build these repeatable processes to onboard applications, on board things on their own, and so it becomes less of a burden on you to do it. So yeah, and I think that's a big thing as as teams mature using Cribble's tooling, be it the ability to expand and become a service owner becomes key. And and this is also I encourage everyone, it's not just a security solution, it's also an IT and observability solution. Huge chunks of data. And the thing is I've seen there's a lot of crossover, lots of security data gets used by ops teams. Lots of ops data gets used by security teams, and having it under a common control mechanism gives you a lot of power and a lot of flexibility. Absolutely. Now let's take a look at what the tool looks like. Yeah, this is really fun. So this is the dashboard that Sohos uses. So this is, think of it as a heads up dashboard to understand what's my consumption. I are things working? Are we seeing load, load issues? They have a much more detailed dashboard, and this is something I, I encourage everyone to take a look at Cripple Cloud. We have a new product called Insights which is gonna give you a much more expanded view of this data. It's AI driven. It's also gonna give you a lot, lot broader view of your data. And so this is a very natural, uh, you know, this very natural way of, of, of expanding what we're doing with their data. And so before, I mean this is all very blind. This is something so us really struggled with something if the data source stopped, they just typically didn't know about it until they needed the data. And so this is the idea is, you know, how do we bring in this data? How do we get this value? And you can clearly see, you know, you, you can see the data coming in versus the data going out. And so they're able to get just, it's just, just a lot of value, you know, going forward. Great point. And obviously this you can see on your own Cribble Cloud tenant when you go download and play with it, right? Absolutely. And this is something just really great. So if you don't wanna, so from the cry from the Cribble website you can get a free Cribble Cloud tenant, click a few clicks, you're gonna have the full suite. So that's gonna be lake. That's gonna be search edge and stream. Also have options for what we call our sandboxes, so sandbox.cribble.io, where click another button you're gonna have a guided use case through using the actual tools that are hosted in AWS so you can get an idea. Does this make sense for me? Trying to address this, you have several use cases and just, that's the big thing, you know, does it make sense? You wanna get your hands on the product. No, you know, no one's gonna bother you. You're not gonna have to go through sales to get it. You'll be able to get access. We just, we wanna be able to put this out there and make it as easy as possible. So this is really fun and this is, so the idea first to talk about is we have what's called a route. So as data is flowing through the system, it's flowing flowing through the system, starts from the top to the bottom. You're now looking for a filter and you can see where the idea that we're using, looking for user off events, and we're now going to redirect any event that contains this string. We're going to put this into a pipeline. Do you have anything you wanna add about it it's a what are common like best practices, yeah, I mean for the most part when you start with ribble, you'll see, oh, you know, filter equals true, so you're basically all your data. But as you start to get refined and understand how to properly route the data based on what you need, you can start building your filters. One of the best features of Cribble, which is what kind of sold me when I was kind of coming to Cribble, is the fact that you have helper buttons on each one of these steps. It actually pull in the documentation, still have the UI, but I have the documentation sitting right next to you, so you can actually do. You know, oh, how do I do a JavaScript filter in, uh, regular expression? Here's how you do that. So very, very helpful. And so one thing I wanna point out at this, and this is something that's common. So Sohos drives from this 11 route, drive detections, drive audit, drive compliance, and so that's that idea that I'm gonna help drive. I'm looking for pieces, and this is something I think is misunderstood. You see a lot of times like we're gonna do detections in the stream. More often than not what you're doing is you're picking out interesting data and highlighting this may be important in order to stitch it together in the back end of your SEM. That's one thing Sofas has done a really nice job of, of finding those interesting events and then raising the visibility to their sock with, with their, with their new back end. The tool, but then from an audit perspective they're now retaining it, driving it into, into their analytics platform so now they can query it and understand it from a higher level and, and the idea is you're, you don't have to do this all in one place and this is like the perfect example of breaking it apart and making it more service based to give you more flexibility. And here you can basically see kind of the progression they're adding multiple routes they're adding multiple kind of filters so that they can properly diagnose the data, send it down to the right pipeline, leveraging packs, which we'll get to in a minute, which kind of just helps accelerate the adoption of these data sources that also make it repeatable. And one of the cool things that they're doing as well is they're pulling data for their next gen firewall. They're now adding enrichment to it. I think it's a very underappreciated part of a better data story. As data comes through, that's, let's make it better. Let's add context to it. One thing I did, this is from an IT perspective, is we started adding in playbook, so we had a well recognized error message we would add in by using a lookup, we would add, we'd add in a link to the to the wiki playbook that then the the knock team would use to then react, and we did the same thing with security. So we're always how do we make data better, how do we make it more actionable, and this is a really, this is a really great look at how they're doing it with, with their firewall tool. And this, and so it's and you can see as it's coming through that you're now you're sharing data and so the idea is to start with the top and then this notice that there's a little button called final. That's the idea is once the data hits the right filter, it's finalized, it doesn't fall through. One of the fun things. You can always do is as you especially as you share data is flip the final flag. So now the copy of the data falls to the next route, and that's how you enable the ability to share. Imagine, imagine where you start with my first route goes to my object storage, my second route goes to my SIM, my third route goes, say, say, to Kafka. So that's the way you can put the same events in 3 different places and have full control over where it goes. And so this is something that the very amount high volume, this is a great example of this with this pipeline in particular they were able to get something like 60% reduction by just making a simple change about how they manage the data and how they classified it. Yeah, always very powerful. Yeah, and look, and look at the way that now you're structuring your data. So this is a good example of how from a, from the idea of I always wanna talk about detection engineering as being the end result of good data engineering. So but what you're seeing here is now Sophos has chopped up an event. They've added structure to it. And this is also one of the fun things that you can that with very depending upon the back end te vendor you can actually accelerate these fields as well by by doing this. So not only do you get a better format, it's more searchable. Typically it's gonna be smaller, it's also gonna be more consistent. This is something that Sofas didn't do this, but also I encourage you to consider fixing your time stamp here as well. Yeah, normalizing your time stamp is very, very powerful. And so just the idea of every time you run into a data problem, this is where you look to fix it. One of my favorite stories around the time stamps, we're talking to an executive for a very large security firm, and they came to us as, why do we need Cribble? And clearly I was like, have you ever had an issue with the time stamp? Do you know that people don't always use UTC, use time zones? And when you go look for an event, hey, magically it didn't exist until you do either all time or you go look in the future. Oh look, there's the event. What's it doing out there? Yeah, yeah, I'll never forget the, uh, I got called to a bridge and. Their their new application that they had deployed in Central Asia wasn't showing up and the data was exactly 11.5 hours off and I'm thinking to the millisecond and you know you're looking at the data, looking at the data, you know, an hour later it suddenly hits me that the developers had hard coded the central time, the Central Standard Time zone into the log into something that was deployed in India and so that was the kind of thing where just, you know, time stamp controls were really important. So after that I never trusted a time stamp ever again and so the idea that the data is coming through Cribble. Cripple is gonna. The idea is I'm gonna fix the time stamp. I'm gonna fix the time zone, and then I'm gonna alert me that there's a problem because it's it's just a fundamental issue of you always need better data to solve problems and like time time zone time stamps are still the devil. I mean, I can be this, uh keep talking about this for a little bit. There's. One customer that I had back in the day where their developers had 15 different ways of doing time stamps, literally 15 different time stamps. So yeah, good luck finding that in your logs. Exactly. And so these are key things, and I think one I also want to mention that from a detection you're doing they're actually using ripping apart the output of NetSstat. If you're, if you're looking at net net status part of standard out, you wouldn't think that was something that was very easy to structure, but this is an example. By since you're running the script, you get the output, and by using this exact same template, they're able to get the structure they needed, make it make it repeatable, and get a just the just because there's so much you can do with that kind of data once it's structured correctly. So this is part of the kind of conversation where we're have like question and answer. I'll skip this just to show one more thing here. We'll definitely have a question and answer section here, but really quickly just wanted to reiterate the fact that Cribble has our university training which is free training and certification. You can go get it. You can go tell your friends about it, uh, and you can also get these certifications that employers are actually asking for these days. It blew my mind. I was at Cribble and both of us were very early on. And when we saw that people like companies are actually saying hey we need a criminal level 1 admin or engineer uh level certification to get this job or to apply for this job blew my mind and I was so proud to see that. Well, I mean it's just free training that that blew my mind. I mean, as a customer, I spent hundreds of thousands of dollars in additional money paying, you know, paying to learn how to use tools I'd already paid for. And so that that was just, I was just like really? I mean that sounds like too good of an idea. So I mean it's just, and I've seen, I know with your customers you see the same thing. The idea that Cribble we try to look at the idea is, the better you know how to use the tools, the better results you're gonna get, you know, the better the relationship. I think that's, that's the way it should be for everyone. I think training is everything and our docs are also not behind the paywall. Yeah, that too, always a big win, right? And also from the AI perspective you can always. As co-pilot and the co-pilot will look up the docs for you. So it's really nice and we mentioned, I already mentioned sandboxes. Sandboxes are a great piece because it's just, you know, you wanna talk about data reduction routing. You wanna talk about, you know, putting, putting data in object storage. It's all right there. You're gonna have a really nice rich way of walking through it and get hands on right away, just, you know, a 10 minute investment in order to try some, try all these different use cases out. Thank you for coming and we're gonna be here for a little bit. So if you have any questions, please come by. Thanks so much. Thank you.