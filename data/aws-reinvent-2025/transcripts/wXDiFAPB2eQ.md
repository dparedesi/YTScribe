---
video_id: wXDiFAPB2eQ
video_url: https://www.youtube.com/watch?v=wXDiFAPB2eQ
is_generated: False
is_translatable: True
summary: "In this session titled \"From collecting tools to an autonomous SOC\" (SEC206), Nick and Joe from SentinelOne present the concept of an \"Autonomous Security Operations Center (SOC)\" as the necessary evolution to counter the increasing speed and sophistication of modern cyber threats. They open by highlighting the unsustainable nature of current SOC work, where analysts are buried under endless alerts and manual triage, while attackers leverage generative AI to automate attacks and create polymorphic malware. Nick cites examples like \"Prompt Flux\" and \"Malterminal,\" where adversaries use AI to generate new payloads every time malware executes, effectively bypassing traditional signature-based detection and automating 90% of the attack \"grunt work.\" To level the playing field, SentinelOne positions its \"Purple AI\" and \"Singularity Platform\" as the foundation for a high-autonomy defense system. They outline a maturity model for SOC autonomy, moving from Level 0 (manual) to Level 4 (high autonomy), where human analysts shift from \"firefighters\" to \"mission commanders\" overseeing virtual teams of AI agents—analogous to a passenger directing a self-driving car. Nick emphasizes that autonomy starts with data, highlighting their acquisition of Observo AI to ensure \"perfect data, zero noise\" and a 20x performance improvement in their parallel query engine. He shares an anecdote from a recent \"Capture the Flag\" event where the system was so fast that they feared participants would use a \"cheat code\" query (star contains string) to bypass the challenge, yet the system handled even those inefficient queries instantly. Joe provides a compelling demonstration contrasting the \"old way\" with the \"new way.\" He shares a personal story where a simulated phishing exercise led to his account being \"nuked\" by Microsoft, forcing a colleague to spend 4-5 hours manually investigating the false alarm on a weekend. This is contrasted with a live demo of an autonomous investigation where Purple AI triages a similar \"impossible traveler\" alert for a user named James Sebala. The agentic system autonomously pulls identity data from Workday, hypothesizes a compromise, reaches out to the user for validation via hyper-automation, checks Proofpoint for phishing indicators, and cross-references EDR telemetry. It ultimately suggests a comprehensive set of remediation actions—such as suspending the Okta user, rotating AWS credentials, blocking the attacker IP, and restricting S3 access—while also autonomously drafting a new detection rule to prevent future occurrences. The session concludes with the announcement of the \"Purple AI MCP Server,\" an open-source tool that allows developers to build their own agentic workflows on top of SentinelOne's data using the Model Context Protocol (MCP), and an invitation to their \"Mortal vs Machine\" challenge where novices using AI consistently outperform experienced human analysts."
keywords: Autonomous SOC, SentinelOne, Purple AI, Agentic Security, Cyber Threat Intelligence, Generative AI Malware, Security Automation, MCP Server

OK, good afternoon, everyone. Nice to see you all here. Thank you so much for coming to our talk today. My name is Nick. Uh, I lead product management for cloud security and exposure management here at Sentinel One. I'm joined by my colleague Joe, and my name is Joe Pointer. I'm a senior solutions engineering director at Sentinel One. Yeah, um, and we wanna talk to you all today about autonomous SOC moving from a collection of tools to using an autonomous SOC, and I'd like to lay out maybe the groundwork for you a little bit. So where I'd like to start is the current challenges that security operations centers or SOCs face, what the current attack landscape actually looks like. And then how we can leverage generative AI and agentic workflows to move to a more autonomous security model and at the end we'll tell you a little bit about how you can get hands on with these tools after the presentation if you're so interested. Um, now, before I get started, I'm gonna ask you guys a quick question to make sure everybody's awake. Has anyone in here ever worked in a security operations center or works in one now? OK, more people than I expected, that's awesome. Um, so look, I think those folks know and the rest of you are about to learn, security analyst work is super unsustainable today. Right, so if you think about the current sort of security operations center life cycle, it's incredibly manual, it's incredibly intense. Stock analysts have to go through an endless number of alerts. It can take hours just to triage those alerts and even more time. To then investigate the things that need to be investigated, ideally respond to threats if they do exist in your environment, and forget ever trying to get proactive with risk management and preventing these things from happening in the first place. It takes days at the best of organizations. So our mission is to make this better for all of you. Um, and we're starting to do that today with, uh, well, actually before I talk about that, let's talk about why. So, we can use AI to make those things better for you all and we'll learn that in a second. But on the flip side, while you defenders are hampered by governance and policies and maybe even politics in your organizations and org charts, attackers are not. They're completely unencumbered. They can use whatever tools they want whenever they want to, to get the job done, and we're seeing that live in the world today. Google Threat Intelligence released an interesting report of new polymorphic malware, uh, generative AI generated payloads that are different every single time the malware executes called prompt flux. I'm sure everyone here. Probably saw a very interesting report by Anthropic about um attackers using AI to automate attacks at scale, both reconnaissance and initial access. Now what I think is so interesting about that example. Is that the attack itself, if you go read the anthropic report, which I highly suggest all of you do if you're interested in this space, the attack itself wasn't particularly special, right? Find an open port, find a vulnerable application, find your way into the environment, right, these are the types of things. That we all deal with every single day. Humans have been doing them for many, many, many years. The special part about this was that attackers were able to automate away 90% of the grunt work and do this at scale without ever having a human touch the keyboard. And yes, at the end it'll need some adjustment, some fine tuning to really drive through and breach those environments, but they're able to get zoom out of the grind, and defenders haven't been able to do that. I mean, can you imagine, uh, you know, I myself, I use Gen AI to write a lot of my emails and it's fantastic for doing that. I jot down a couple of sentences and I say, hey, beef this up, make it look a little bit more professional. Who here remembers when you used to get a spam email and the way that you would detect that it was spam was because of misspellings or because of. Poor grammar. I mean we've all seen it, you know, Grandma calls you up and says, I think I've been hacked, and you see the email and you're like, how did you fall for that? But we're at the point now with Gen AI and attackers can use these tools rather than us using them for good. They're using them for evil and so they're coming in with now emails. Images that are perfectly crafted that even somebody like myself who lives in this day in and day out, I take a look at one of these and I can't tell anymore whether it's spam or whether it's an actual valid email. It's really getting terrifying out there. Yeah, so, so two pieces here, right? Um, generator of AI malware like Prompt Flux or what Sensil Labs found malterminal, which uses GPT-4 to auto generate new payloads, and the automation of processes at scale, at machine speed using AI to do that and getting rid of the grunt work. So we're fighting adversaries that are rewriting their playbooks every single day, um, and ultimately moving faster than a human can. So what do we wanna do about that? At Sentinel One, Purple AI is sort of the engine in the brain that powers our response to that problem. Um, it provides not just your normal sort of chat GPT style natural language interface, which it does also do, but it provides human level reasoning inside of the Singularity platform. It can do auto triage and investigation like you'll see in a little bit. Joe's got a cool demo for you all. It also integrates with our automation platforms. So it can orchestrate and take action on your behalf um and we even run our own proprietary models that we've trained using systems like AWS Bedrock. We have a set of models called Ultraviolet, including, you know, even our machine learning models to detect malware at the agent level um and broad threat intelligence through partnerships and private feeds internally. So AI is going from assisting you in doing all of this work to doing all of the work for you and getting your approval, suggestions, changes. And this is a really, really important change in the industry, right? This is how we start to scale what we can do in response to the AI age of threats in the landscape. So imagine a world where instead of, you know, an analyst going through 10,000 alerts in a single day. Which I have seen in real life before, you have an AI agent go through 10,000 alerts and surface what it thinks might be the most interesting 500, right? Um, imagine a world where instead of going and doing all of that work yourself you are simply supervising and managing your virtual team of AI genic sock users. What I think is most exciting about that is, you know, when I was in college a long time ago studying to be an analyst. I had visions of a world where I was that guy on the keyboard hunting down attackers very CSI style. Little did I know that once I got out in the real world, no Joe, sit down in this chair, you've got a queue of alerts that are coming in and you need to handle several 100 of these alerts every single day. Somebody would've told me that that was what security life was like. Uh, I would've gone and become a used car salesman or something else. Now the, the industry has been promising these types. Of advancements for a long time, but we're now finally at the stage where analysts can stop being firefighters and they can truly transition into a more strategic role like you said managing these AIs, doing that grunt work, being more of that CSI style, you know, threat hunter rather than just a ticket handler. Absolutely and you might notice something um and this may be surprising, hopefully it's not. What we're not talking about today is replacing humans in the security workflow. No, I don't believe that will ever happen. What we're talking about is using what humans like leveraging humans to do what they do best. Um, another good example, I think, uh, an, an analogy that we can use here is self-driving cars, right? Has anyone here this week used the Zook's self-driving taxis? OK, you're braver than I am for sure, um, but look, even when you get in that car, you still have to tell it where to go, right? You're in charge of the mission. What is the journey that you wanna go on? And so we believe humans are the mission commanders of the security operations center. They may not be the boots on the ground forever, but they're an absolutely instrumental part of this forever. So we started to talk about autonomy and self-driving cars. Sensor One has come up with an autonomous sock model, maturity model, very similar to like a self-driving car maturity model. And back in the day we started at zero, right? Uh, we're. We're writing our own simple rule detections. We are doing completely manual investigation and look, over time in the industry, this has gotten better. We moved to having automated playbooks. We even moved into a world many years ago of AI assisted. Automation, right, I would actually claim that when Sentinel One was founded, it was founded in this level 2 phase. We've been using machine learning models to detect malware, at scale across customer environments, and we call this static AI for many, many years. It's what the company was born on. Today we believe we are at level 3, partial autonomy, the ability to. Reason and predict potential threats to to create detections and detect suspicious activity and more importantly start to go down the second half of that life cycle, right? triage investigation response but it is definitely still AI is assisting humans and not necessarily humans assisting AI as much yet. So what's next is what we believe is high autonomy, level 4. This is where you become those mission commanders, and it's what we're building right now at Sentinel 1. So autonomous security is already real. Like we said, we're at level 3. We have some level of autonomy in the SOC and Essential one, what this looks like is not just at the end of the cycle, or auto triage investigation, all those things. It actually starts at the very, very beginning. Uh, security operations center is only as good as the data that it can be pulled into that security operations center and so we've built, uh, or acquired Observo AI which helps us pull in the right data at the right time. In the right ways, right? We say here perfect data, zero noise. I actually think about this a little differently. Make sure you have all of the data that you need and none that you don't, right? If any of you have worked in the SOC, and a few of you have, hunting through meaningless, like security valueless data as you're trying to go through an incident is incredibly infuriating. You already have enough work to do. Now you have 10 times as much data to sift through, 90% of which is completely useless during that incident. So you wanna pull in exactly what you need and nothing that you don't. We also need to be able to answer questions incredibly quickly. It's why Sentil One has made huge performance and scalability improvements to our query engine. We have an industry leading query engine and AI SIM, and that's going to be incredibly important for the identic and autonomous sock as well. These tool sets don't disappear. What uses them changes. So what took humans hours or days to do will take agentic users seconds or minutes, but in order for that to be true, the query also has to return at that time scale, right? It needs to be able to ask the questions and get the response it needs, which is why we've built this massively parallel query engine as as the basis for our security operations center and finally. Because we have these tool sets, we plan to offer a bunch of out of the box agentic workflows to all of you on our platform, and Joe's gonna show you that in just a minute, but that will be generally applicable for all users and all organizations that partner with Sentinel One. We're at reinvent. Most of you build stuff you're coding or you're doing low code or maybe you're using things like cloud code to prototype. I know I am. I used to be a software engineer. They haven't let me touch that in a really, really long time for good reason, but uh I'm starting to play with it again in my personal life and it's really fun. So we've also released um the ability to unleash that data for your own agentic. Agents and work flows uh via our Purple AI MCP server and we'll talk a little bit more about that in a minute. One of the things that I like to highlight on this because as a as a solutions engineer focused person. I love these slides that they come up with, but whenever I see 20X performance upgrades, it always makes me a little bit like, well, is that just a number, or do you really mean it? We just ran something called the Satin One Thread Ops World Championship where we ran 3000 people through a capture the flag exercise. And I built it, me and my team, and one of our biggest concerns was we had part of our game where they would have to craft queries and we wanted to see how quickly they could do it. Our biggest concern was they would figure out our cheat code. Our system is so fast that you can do star contains and then a string. And it won't tip over like a legacy SIM or a legacy data platform or take a week to pull back the data. You can literally do this across weeks or months of data and it'll handle it just fine and that's what the 20X performance upgrade is even on inefficient queries like that, the back end is so strong and so fast that we were literally concerned if one of our players figures figures. Figures out that they don't have to write a query they just do star contains the thing and find it. The game would be over. Luckily nobody figured it out. Nobody knew our cheat code and our game went on and was a was an absolute success. I would love to see an agenttic system. They might take that approach, but um, yeah, so, so, so this is, this is what we have today. This is all available right now, um, and so what does this mean? Like, let's go back to the human user for a second. All this helps enhance and accelerate that human user, right? So we start with gaining visibility, that's getting the data in. We see 80% reduction in noise and 100 times faster than legacy SIMs. That's what we see in our benchmarking with our current systems. It means, and because of that we'll have faster, more real-time detection. What does it say? It's a little small for me right now, but in the 60% range of detection efficiency increases, and because you're able to detect things faster, you can move through to investigation faster. You can get that done faster as well. So triage and investigation with purple AI and the autonomous sock 40% faster than it was without these tools, and all of this leads to just generally. A 55% increase in the ability to respond, remediate, and move forward, right? So these are very, very real efficiency gains for our users and for organizations, um, but it really is still about that analyst experience. So we've talked a little bit about the analyst experience. You've seen the sort of like life cycle from visibility to response. What are the actual capabilities in the autonomous sock that drive these improvements? It starts with auto triage through purple AI helping you surface what you should or should not care about upfront out of the large number of visible like signals and maybe even large number of detections depending on your organization. We can then help you hunt and investigate with dynamic agent-based reasoning. We can even help you enrich and ask further questions via our hyper automation, uh, platform. So something that are actually our internal stock Essential One does is they use agents embedded in um in hyperautommation workflows. That not only decide what questions to ask, but how to branch to the next step in the automated workflow to pull that back and reduce the time that a human needs to spend on each individual incident and of course you have things like recommended actions, detection rule creation as you move towards that more proactive model of security. All right, I think this is my chance to turn it over to Joe to actually show you, right? Seeing is believing. So let's start to talk a little bit about this. So let me start with a very quick story, um, again, what I do, one of the things that I do is I give demonstrations to people like Forrester and Gartner where they give us scenarios and they say, Joe, we wanna see this thing in live in your environment and how you interact with it. And so I'm setting up infrastructure for Forrester and they say Joe, we wanna start with a phishing email, then we wanna see a lateral movement compromise and we wanna see all this other stuff. So what it basically happens is I have to build hacking infrastructure in order to show them it's fine. So what do I do? I turn to a cloud provider and I choose Microsoft Azure and I say, OK, I'm gonna spin up a domain called Forrester, but it's gonna be F0 Forrester. And I'm gonna set up a fake login page for Octa. That's where my users are gonna go and be tricked and give away their credentials. I set it up and the thing only needs to live for maybe 3 days, and I say Microsoft is gonna catch me because they're good, they're Microsoft, but it'll, it'll take at least 1 week, OK. I'm out in the backyard with my kids, we're playing on Saturday and all of a sudden my phone rings and I pull out my phone. And it's a guy, a famous guy in our, in our company named Jags, and he, his name is Jose Andres something Guerrero, but I'm not gonna butcher it, but he runs our Sentinel Labs research team here at Sentinel. Literally his name, everybody just calls him Jags. Why am I getting a call from Jags on a Saturday and he pick up the phone. Hey Jags, what's going on? Never talked to the guy before in my life. I just know he is kind of famous. And uh he goes, so Joe, we think your account has been compromised, and I'm like, oh, it's not good, you know, what do you need? He says, well, there's some hacking infrastructure in Azure, we think an attacker is using your account to create this infrastructure and they're impersonating Forrester and like uh we, we've got all hands on deck, we're about to nuke your account from orbit, and I say, oh, don't worry, it's not an attacker, it's me. And of course he goes, What do you mean it's you? And I said, let me explain. And I explained to him the whole scenario, and he goes, Well, it's a little bit late. Microsoft has destroyed your entire environment. It's gone. Good luck. And afterwards I asked him, I said, Well, you know, what was the process for you? And it was interesting to see, they got a call from Microsoft, one of your employees is compromised. He then researches me. Does Joe have any alerts inside of our console? Has Joe traveled anywhere? Uh any potential password compromises? And they had 4 or 5 hours' worth of work, 4 or 5 hours' worth of work that I feel really bad about, OK, because they didn't need to do it. Before they called me to say Joe. Is this real? 4 to 5 hours. It's a lot of work on a weekend. I felt really bad. I sent him a couple of 6 packs of beverages for it, because I felt so bad. But what we're talking about with all of this, with AI. Is no longer 4 or 5 hours on the weekend. We're talking about the AI doing all of that work for you, looking at is Joe Poyner compromised? Has he received any phishing emails? Has he gone anywhere suspicious? Has he been traveling? Anywhere that's what we're talking about. So let me show you the very first step is our agentic AI coming in and automatically triaging all of our alerts. And so we've got a possible compromised identity, and we're gonna tell it start an investigation. And what it's going to do is going to process through the various steps, and not just a static list, OK? Not a static list of A, B, C, and D, but a reasoning model where it takes a look at it and says, is this a possibility? No, we've ruled that one out. Now let's try other possibilities. And so what we can see is it's conducted the investigation. And then highlighted now that it needs review, and this one in particular is very important that we want a human in the loop. So we can see, here are the investigation steps that it went through, highlighting things like initial discovery, an alert analysis, and impact assessment, and these are all dynamically generated and executed. Now, what this is, is that our agentic AI allows you to do this at scale. So, if you think about it, where we were talking about earlier with Jags, my poor, suffering Jags who had to investigate my false positive, I imagine there's not just one alert on the weekend for Joe Poyner. But there's 10. We've now eaten up his entire weekend. He's now investigating all of these, and most of them turn out to be false positives. He chases them down the rabbit hole, but then eventually he gets to Joe Poynter and says, no, it's, it's, it's OK, don't worry about it. The AI though, we can let the AI churn on these types of repetitive tasks, and then it'll bring it to us, and then all we have to do is make the five minute decision of yes or no, we agree or disagree. So, let's see this in action, where Purple AI kicks off the investigation for the impossible traveler alert that we showed on our first page. So what it's going to do is it's going to take a look and say, who is the user? We have an impossible traveler alert. Let's take a look at who the user is, in this case, it's James Sabala. He's a cloud engineer. We've gone over to Workday, pulled all of his information. And we've noted he's logging in from an unusual location. So at this point, Purple AI hypothesizes and says to itself, hey, he's probably had an account compromise. So what do we need to do? Just like what Jags did with me, is he needs to reach out to the end user, and that's the power of Purple AI is that it can reach out via hyperautommation. And ask the end user whether or not they are actually compromised. Now, once we've confirmed with that user, we wanna go ahead and review proof point alerts. We wanna take a look and try and establish how has that account been compromised. Was it compromised by phishing or something else? If we take a look though, we also have other pieces of telemetry that we need to pull together by querying systems like EDR telemetry, by looking at other sources like Workday or even AWS logs to see is has this user account been compromised in some other way. Now, our AI doesn't stop at investigation. Purple AI agentically surfaces pre-approved recommended actions via hyper-automation, our automation suite. So for example, we can see here, it's gonna suggest that we rotate AWS credentials, block the attacker IP, and even restrict S3 access, and of course the most important one, suspend the user in OCTA. Now, the last, very most important piece that I personally like is it says, guys, now that we've detected something in our environment, we understand how this attacker potentially works, let's detect them sooner. And so that very last step that you saw in the video was one where it asks to not only take action on the single user, but let's create a rule so that any similar detections down the road are detected sooner and understa understood quicker. This is the dream, guys, of Ge AI taking away so much work that we do every single day. And simply automating it and I for one welcome our machine overlords if they wanna take my my boring work away from me I say let them do it. Thanks so much Joe. So look, that went really fast and I think that's kind of the point, but if we think back to the really painful, time consuming grind that we started our presentation with, that grind has become um less burdensome and more interesting, uh, something that a human can really dive into, um, and use their time effectively. No more are we doing endless triage of alerts. No more are we pouring through tons of noisy data in the SIM. Um, we're not even necessarily having to build out our automation playbooks anymore. It's all being done by Purple AI and the autonomous sock. So across the entire life cycle, right, from triage all the way through to proactive risk management, we've seen how agentic workflows can take away the burden and leave users in control and in command. So from frustrated and very frustrated and hours and days of work, the stock analyst life changes. From hours to minutes, maybe from minutes to seconds, from barely keeping up to always staying ahead, I think that makes for a happier socc team. I'm sure it would, I would feel a lot better if I wasn't doing 10,000 alerts worth of triage every single day, but most importantly, I think it helps you keep your organizations much, much more secure, especially in a world where attackers are trying to leverage the same types of technologies in the reverse order, right, or in the opposite way. All right, so, um, we talked a little bit about how Sensible One is doing this itself just as a quick reminder, you guys are builders, you may wanna use AI in your own ways, you may be building your own agents or leveraging other models and agents that exist out in the ecosystem. We believe that the Singularity platform and Purple AI enables a tool set for those agents, and those agents could be ours at Sental One. They could also be yours. This is why we recently launched GA, our Purple AI MCP server. It's actually fully open source. It's available on GitHub today. So you know personally what I'm really hoping for is that I'm gonna go home and next week I'm gonna go take a look and see all of the amazing stuff that you all have built on top of Purple AIMCP using the autonomous sock and some of the ideas that we've talked about a little bit today. Alright, how are you, how can you use it this week, Joe? What can we do? Oh my gosh, if you wanna see this, so we've talked about a lot of really cool stuff, but if you wanna actually come and see it, there's a couple of different things. One, we have the Security Social, that's an invite only exclusive event. If you've been invited, we hope to see you there. But one of our cool events that we do is Mortal versus Machine. This is our booth on the expo, and we have an analyst with 10+ years of experience. The guy is good. And we invite somebody up from the audience to take him on. He doesn't get AI, you get AI, and you have 3 questions. So far we have demoralized him very badly because he's lost a vast majority of the time, but it truly does highlight that somebody with no experience inside of the Sentinel One platform can pick up AI and become as good or better than somebody with 10 years of experience. We also have our AWS game day experience on Thursday. We welcome any and all to come sign up where you're going to be able to play for some prizes in AWS game day and see how Sentinel One and AWS come together into a cohesive system. And then AWS on SentinelO.com. So we ask if you're interested in any of this stuff, please go out to these resources, test us, you know, say you guys said some cool stuff, let me get my hands on it to actually prove it out and see if you mean it and I'll just say thank you everybody for attending our talk today and everybody have a nice rest of your conference. If you guys have any questions, please come up and ask we'd be happy to answer them, um, and I hope you enjoy.