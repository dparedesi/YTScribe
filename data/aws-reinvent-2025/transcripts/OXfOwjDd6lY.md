---
video_id: OXfOwjDd6lY
video_url: https://www.youtube.com/watch?v=OXfOwjDd6lY
is_generated: False
is_translatable: True
summary: "This session, \"Hybrid connectivity at scale: A deep dive into AWS Direct Connect (NET403),\" features Steve Seymour, Worldwide Tech Lead for Networking, and Josh Dean, Product Manager for Direct Connect. They provide a comprehensive guide to AWS Direct Connect, covering physical layer details, virtual interfaces (VIFs), and advanced routing configurations. The talk explains the process of establishing connectivity, from ordering ports and managing cross-connects (LOA-CFA) in meet-me rooms to troubleshooting layer 1 issues like \"rolling fiber.\" It details the three types of virtual interfaces (Public, Private, and Transit) and how to architect for scale using Direct Connect Gateways. The speakers dive deep into BGP routing strategies, including using local preference communities and AS path prepending to influence traffic paths for active/active or active/passive configurations. The session also covers MACsec encryption for security, SiteLink for direct location-to-location connectivity, cost calculation examples, and a brief mention of the new AWS Interconnect for multi-cloud connectivity with Google Cloud."
keywords: AWS Direct Connect, Hybrid Connectivity, BGP, Virtual Interfaces, Direct Connect Gateway, MACsec, SiteLink, Network Architecture, Cross Connect, Multi-Cloud
---

OK, good afternoon everyone. Welcome to the session. This is Net 403, hybrid connectivity at scale, deep dive into Direct Connect. So thank you all for coming to the session. Um, I wanted to start out with a very simple question to all of you, which is what was on my mind when I joined AWS a number of years ago, when someone said, hey, can you talk to some customers about Direct Connect? And my thought was, how hard can it be? It's just VLANs, we just need to know a little bit about 802.1Q, a bit of trunking, that sort of thing. Little bit of BGP need to know about AS numbers, that sort of thing, configuring filters and and prefix lists on routers. Of course, the AWS side of things, we need to configure things in the console, um, and of course the, the piece of equipment, the router on the other end of it. So how hard could it really be? Now, something I wanted to get out of the way. Um, my name is Steve Seymour. I'm the worldwide tech lead for networking and solutions architecture at AWS. Uh, I spoke about Direct Connect back in 2016. And one of the things that I just wanted to remind people of was, as you can probably tell from my accent, I'm from the UK, um, we say roots, and I did explain that back then. Um, it didn't quite sink in, so I had to go the next year, tried again to explain what a router really is, um, and this year I've kind of given up, so I asked someone else to, to join me. So, yeah, so I'm Josh Dean. I'm a product manager on the Direct Connect team. I was also born in the UK, so I was a router guy, but now I'm a router guy, so, so I'm a convert. So hopefully between us, we've got people covered, whichever, whichever one you prefer. So another, another question, who's used Direct Connect? OK, a fair few of you. There, there's one or two that didn't put their hands up. But I wanted to maybe give you a bit of history here because at Reinvent back in 2014, we actually used Direct Connect here at the conference. We used it for a couple of demos, a couple of launches that we did that year. And if you came to reinvent the following year and came in 2015, it was actually being used to deliver most of the event network. So if you went to anything on AWS. In 2015, you would have been using Direct Connect. And perhaps unsurprisingly, this year, Direct Connect is a key part of the network infrastructure that we deploy here for Reinvent. And it's been that way for the last couple of years. So actually, if you've used the Wi Fi here at Reinvent and accessed anything at all that is on AWS you have used Direct Connect. So perhaps that's everyone now in the room. OK. So let's get started and, and obviously when I say how hard can it be, there is quite a bit more to Direct Connect. And we're gonna walk you through in this session, everything from physical infrastructure, so looking at direct connect locations, looking at the different interfaces that we have, how to organize cross connects, where partners fit into things. We're gonna look at the logical infrastructure, the various types of virtual interfaces, and of course we can't avoid BGP it's gonna be part of this session. And then the other end of this, the, the cloud infrastructure, the AWS side of it, of course. So that's the plan for this session. So what is direct connect? Well, it is a physical connection between your infrastructure and the AWS infrastructure. And I say physical connection because it does involve cross connects, connecting pieces of fiber between equipment to enable traffic to flow from your infrastructure into the AWS backbone and into our regions. Originally, it supported a couple of connections, perhaps in a location to one region, perhaps one VPC. But Direct Connect has evolved a lot over the years that I've been talking about it. So Direct Connect now supports connectivity to multiple regions using Direct Connect gateway, and of course multiple VPCs as a result. And it also supports now connecting into things like cloud WAN, transit gateways, etc. So Direct connect has evolved over time as you would expect. But we're gonna go right the way back to the beginning in terms of establishing these connections. So that physical connectivity. When you're establishing your first direct connect with AWS, one of the first decisions you need to make is where are you going to do it. So as I like to say, it's a location, location, location discussion. You need to go look on our website and look at the different locations that we have around the world for Direct Connect. These are locations where we have infrastructure and we can provide ports for you to connect to. When you look at that table on our website, we list out the locations, we list out what is called the associated region, and the set of features available at that particular location. So if you wanted a particular amount of bandwidth, you can look down that that table and recognize, hey, this particular location, it supports the bandwidth that I need. And we support 1 gig, 10 gig, 100 gig, and 400 gig ports. Not all locations have all of those um different bandwidths, so check the list for which one makes sense for you. You're also going to be making a decision there based on where your infrastructure is, and it might be that you have your network infrastructure already in one of those locations, which makes the choice really quite easy. If however you're connecting to some on-premises infrastructure or another data center, then you'd be choosing the direct connect locations that are closer physically to that data center. Because you're gonna have to order the connectivity from our direct connect location to your infrastructure. Now, creating a connection is really quite simple. Give it a name, choose the location from that list. There is an option at the bottom there which says you would like a Macsec enabled port. And I'm gonna talk about that a little bit more later on. But that's also listed in that table, which device, which locations support Macsec. So if you plan to use Macsec, this is the time you make that decision, it's not something you change later on. If you would like a port that is capable of Macsec, so encryption. Choose it when you, when you order the connection at the beginning. You're gonna notice throughout the, the slides here that we have these boxes down in the bottom corner. Um, these are just to call out some of the quotas that we have around Direct Connect. Um, many of these you can just request an increase for. Um, but in this example it's 10 connections, uh, per location per region. That's your starting point for ordering Direct Connect connections. OK, so we've ordered our connection, we've clicked through on the console. Well, the next step, surely we just need to get ourselves connected. We just plug in, don't we? Well, the photo that I'm showing you here, this is an example of a meet me room. So this is Equinix TY2. Um, and as you can see, it's full of a lot of fiber, a lot of ports. Um, this is actually a, a very, very tidy, neat, uh, meet me room. And this is where your port from AWS is presented for you to consume. So when you order that connection, we then issue something called an LOA CFA. So an LOA is a letter of authorization. It is your permission to plug into a particular port. And CFA is the connecting facility assignment. It's basically where is that port. So this document contains everything you need to be able to plug into that direct connect port on our side. Um, it's gonna contain other information such as the connector type. So LC connector is typically what we would see. Um, it's a single mode connection, the different standards that are required for the different bandwidths for our ports. So you've got all that information, so surely now you just plug in, yeah? No, that's not quite how it goes, because in reality, you personally as a customer, probably do not have access to that meet me room. So in reality, you're gonna have to work with the co-location provider now to arrange for something called a cross connect between that port that we've allocated and your infrastructure. So when we think about getting connected, um, unfortunately, there have to be multiple people involved in making this connection. It's not something that you can own totally yourself. There's always gonna be at least 3 parties involved. There's obviously AWS on one side, providing the direct connect port. There's your side of things, your infrastructure, and in the middle, we've got this co-location provider that needs to make the cross connect. The reality also is though, if you're connecting to a facility that is outside of that particular co-location facility. Then you're probably gonna have to work with some sort of telco partner, carrier, maybe even a, a separate last mile provider. And unfortunately, all of the people involved probably have their own processes, their own ways of doing testing, and I'll come onto this later on. Perhaps their own polarity on their ports causes some interesting challenges. So, I've been doing this for quite a few years. I've worked on a bunch of customer projects and internal projects involving Direct Connect. And I thought I'd just share a couple of tips from my experiences. And the first one is, I would say, always draw out a really simple diagram of what you're trying to achieve with Direct Connect. Put AWS on one side, put your infrastructure on the other, and then work out all of the pieces involved in the middle. Doesn't have to be fancy, just a very simple diagram that shows all the locations, perhaps all the devices that you're aware of that these connections are gonna go through. On that diagram, identify who owns each component, because they will all have different owners. And then every port ID, every circuit number, everything you see written in an email or said to you over the phone, just add it onto that diagram, and this will become your reference for everything to do with that particular direct connect. I also find it quite useful just to note on there things like support details, contact details for the people involved, because this, as I say, just becomes your reference going forwards. So how do we put all the pieces together here? So what I wanted to start with was the example where you've got infrastructure in your own facility, perhaps your own data center. It's not within the Direct Connect location, so in, in my example earlier, the Equinix TY2 facility. And we want to establish this connection from an AWS Direct Connect port all the way through to your equipment. Now it'd be really nice if you could just fire off an email that says, hey, partner, could you just make this happen? Here's the LOA from AWS, here's my equipment, could you just connect the two together? I'm not gonna lie, there are some cases where you can do that. There are some excellent partners who have all of the ability to deliver this end to end. But unfortunately, the reality is there are usually many more components involved. But let's stick with the example for a moment where we've asked a partner to deliver it. And in which case, they simply build all these connections. So perhaps they arrange the last mile from your data center to a point of presence in your city for their infrastructure. Um, maybe then they configure across the, the backbone that they have, uh, over their optical network into a location, and they arrange it all, fantastic. They plug it in, ports come up on your router, happy days. As I say, the reality is a, a little bit different. Now, the infrastructure I mentioned there is in place typically, so there will be points of presence in your city. There will be infrastructure in these co-location facilities from the various telcos and carriers. Also, there is the meet me room infrastructure that I mentioned a moment ago. AWS's equipment is already pre-cabled from our devices directly into that meet me room, into what you saw in the photo earlier on. And the chances are that the large carriers and telcos in these facilities are also pre-cabled to the meet me room. So what that means is we still have a few gaps, but it's not quite as bad as I showed a moment ago. But to make all these connections happen, you can imagine, there's gonna be a lot of communication going on. There's gonna be the request from the owner of the, the telecoms equipment to request the cross connect in the first place. There's gonna be provisioning of ports and circuits across the infrastructure. There's probably gonna be some ordering of running fiber across a town. There might even be involvement of, you know, logistics to dig up the road to run fiber. All sorts of things could be involved. But when it comes down to it, if you break down that simple diagram and do it in stages, the first piece is that cross connect in the meet me room. So in this case, the telco has had to ask Equinix in our example to make that cross connect. The telco has then had to make physical connections between patch panels in their rack and their equipment, configure circuits over their network, deliver it to your local city, perhaps dig up some streets, and then deliver it into your location presented on a port ready to go into your router. And at that point, we might have a connection. The other variation on this is if you are located inside that co-location facility already. Now if you're in there, things are clearly a lot simpler. You don't have any of that external telecoms work to do. So you'll have your rack, your equipment, uh, chances are you're also pre-cabled to the meet me room. Um, if you're not familiar with that experience, typically the first time you order any sort of cross connect in many of these facilities, they will install a whole set of fiber between your rack and the meet me room. And what that means is you can now interact directly with that location provider. So it really is as simple as then sending the email that says, please can you make this cross connect. And of course it might not be an email, different providers use portals, you might upload the details, provide the document we give you as evidence. But effectively you just order that cross connect and it's done. I've said cross connect a couple of times, a cross connect really is just a piece of fiber being plugged into one port on one side and another port on the other. There is nothing more to it. I, I regularly get asked what is this cross connect thing and there is, it's very simple, it's just a piece of fiber. So at that point, our connection comes up and hopefully the thing you see in the AWS console is that your port goes from being down to now showing as available, the link comes up on your router. We're in a good place. But let's just go and verify that everything is as we expect. So we have cloudwatch monitoring for Direct Connect. There's a whole bunch of the, the metrics that you would expect to see there, bandwidth usage, etc. But I wanted to just draw your attention to the connection state, which is a very simple metric you can look at that indicates is the connection up or down. If it's one, it's up. Anything else, it's down. The other interesting ones to look at here are the light levels. Particularly the RX, so the received light level. And you can see on there I've, I've made a note of the um the ranges that are considered good. Um, effectively if you get down to, to -12 dBM you're, you're OK, but you could be better. Start getting beyond that, this connection probably isn't coming up. And the reason I'm, I'm mentioning this is you can have a situation where everything is plugged in and connected. But you haven't got a link yet, and it's good to come and have a look in the console and actually see what the light level is, because it may well all be connected absolutely fine, but you might have some dirty fiber somewhere that wasn't cleaned when it was connected or something like that, that's attenuating the light, that means we've not got enough signal getting through. So always go take a look at the cloudwatch metrics. Everything I've been talking about so far is what we refer to as a dedicated connection. And it's exactly what it sounds like. This is a dedicated port on a piece of AWS equipment that is assigned to you. You requested it and we allocated it to you. You get full use of that port and the bandwidth available on it. It will support multiple virtual interfaces, which we're gonna explain a little bit more in a moment. But that's effectively multiple VLANs and BGP sessions because you're in control of everything about that port. Fundamentally, it is physical connectivity that you're responsible for to get to the port that we've allocated to you. Hosted connections are a little bit different. What happens here is we allocate connections to one of our direct connect partners. And we actually call them interconnects at that point, you may see that term around. And our partners have already then taken care of all that physical connectivity between their infrastructure and ours. What they then do is allocate smaller amounts of bandwidth on that connectivity to you and provide it to you perhaps over an existing fabric or service they might have uh with you as a customer. In that case, our partners can increase their connectivity with us by combining connections together. They can create lags, just like you can, and we'll, we'll explain that in a moment. But they can increase that capacity, but we don't let partners oversubscribe those ports. So as they allocate bandwidth to you, that bandwidth is passed on to you and they have to expand their connectivity with us over time. The thing about a hosted connection is, you can only have one virtual interface per hosted connection. So it's quite common for our customers to have multiple hosted connections if they need them for different workloads. Perhaps some for virtual private gateways and some for transit gateways, etc. I mentioned there lags, link aggregation groups. So what a link aggregation group is, is it allows you to combine multiple physical connections into one single thing that is treated as a dedicated connection. So you might combine together 410 gig connections. So you have a resulting 40 gig of capacity there, but you treat it as a single connection when you're configuring virtual interfaces, etc. on it. We'll then do flow hashing of the traffic across those connections, and you can configure on the AWS side and your equipment, uh, what is the appropriate point that you would rather shut down that set of connections if you lose capacity versus maintaining it. So you might have 40GB of connectivity and you decide that you really need to always have 20GB available. So if one of those other connections is impacted, you're down to 30 gig, that's fine, keep the lag up. But if we drop down to 20 gig or below, perhaps we then shut it down, and that's configured as the minimum number of interfaces on a lag. So we're in a fairly good place at this point, we've assumed everything's working, but what if it doesn't? And what I thought I'd do is just talk you through a couple of situations that we hear about all the time, and our support engineers end up discussing with customers. So I wanted to just give you maybe a bit of an insight into two things that we hear very regularly. And that other phrase is roll the fiber, or I'm gonna put a loop on that. I see a few people nodding here, maybe you, you've heard that or experienced it. For those of you that have not worked with physical fiber equipment, at the bottom there we've got what's called an SFP, a small form factor pluggable module. And on the right-hand side we have some fiber, uh, duplex fiber with LC connectors on the end of it. And the module at the bottom is what is sitting in those various pieces of network equipment on each end of this connection. And you might be able to see in very small writing on there, it's marked TX and RX. So that's transmit and receive. So what happens there on the transmit side is there is a laser inside that module that is firing the light out of it, and when it gets to the other end, it needs to go into the received side of the other connection. So just to illustrate that point a little bit, this would be just two devices next to each other with a single duplex fiber cable that you would just plug in. This is what would happen. Transmit would be connected to receive and vice versa. We'd all be having a good day, packets would be flowing, no problem. Well, when you put this in the context of a co-location facility, we've now introduced a meet me room. Now there are no actual standards for how to do this kind of cabling. There's some. I guess best practices that have been adopted in terms of where you cross over those pairs. So typically between your rack and the meet me room, the fiber will have been crossed over. And if we take that simple example on the screen there, you've got two sides of a connection here, a single meet me room, the fibers have been crossed on one side, crossed on the other. The patch in the middle is just a simple fiber between those ports. That unravels quite nicely and you end up with transmit to receive and vice versa again. All good. The other variation though is when you start adding in multiple meet me rooms, other providers, other pieces of equipment, and before you know it, you've got a situation where these fibers have been crossed multiple times. So when you hear the phrase roll the fiber, what they literally mean is swap, transmit and receive around. Um, I've lost track of the number of times I've visited racks where I've seen the little clips on an LC fiber connector broken off so that the fibers can be swapped around. It's a very, very common thing. Um, I wish it was totally standardized everywhere, but unfortunately it's not. So that's what that means if you hear that when you're debugging a connection. The other phrase is putting a loop on it. So what I'm showing you here, very simply again, these are just two SFPs, two devices that are connected via a meet me room, and perhaps the connection isn't coming up. And what we wanna do here is identify where's the potential problem? Do we have some broken fiber? What, what's the issue? So what will happen here is you'll hear someone say, I'm gonna put a loop on that connection facing towards AWS or facing towards this carrier. What that means is in that meet me room, they might unplug that fiber, that cross connect that we had, and quite simply they will just loop the two together on one side. So on the AWS side, our laser is firing light out, it gets to that port in the meet me room, it gets turned right back around, sent back to AWS. And now in those cloud watch metrics, you would see light level being received. It's not always true that the connection would come up as such, but you can see that that loop has been made. And even better, you could see the transition where there was no loop at all, no light flowing. You loop it, it's good. So now you know the path from AWS to the meet me room is good. The same could be done on the other side with the carrier, and it could be done at various places all the way down the path um to troubleshoot a problem like this. So they're the two phrases you're likely to hear. Um, I thought I would share it with you because, as I say, our support organization work with customers regularly on these things. Um, and quite often we find customers don't necessarily understand these concepts, which, which I get. Um, so hopefully this clarifies that process. The last thing I wanted to talk about in terms of physical connectivity is Macsec. So Macsec is enabled at the port level, as I mentioned earlier. When you request your port, you check that box at the bottom, and if it's available for that bandwidth at that location, it is now available for you to consume. MaxSec encrypts the traffic between two layer 2 devices. So if you've got a piece of equipment in that co-location facility and you connect them together via the cross connects, no problem. If you're connecting outside that facility to perhaps your data center, as long as your carrier is passing through all the layer 2 traffic, then you can establish a Max Sec connection between those two devices. Once that traffic gets into AWS we encrypt all of the traffic between AWS secured facilities. So that max session is between your device and the Direct Connect device in that location. The keys for this session are generated by you. They're stored inside KMS, uh, sorry, in Secrets Manager. And you can then rotate these if you need to over time. You have a choice when you configure Macsec as well, in terms of what you want to do with the encryption. So you can choose no encryption, maybe that's your starting point. If this was part of a plan that you were gonna enable Macsec later on, you'd set it to no encrypt. There's also then should encrypt, where the two devices will try and establish an encrypted connection between them, your device to ours, but if it fails, the connection will still come up. So that's quite a common stage to go to as you're rolling out Maxet connectivity. You enable it, you said it just should connect. That now effectively lets you test it because if you get it right, the connection will come up and you'll see it encrypted. If it doesn't work, you haven't interrupted the connection. And then the final one is must encrypt, which is exactly what it sounds like. If we can't establish the encryption between the two devices, the connection will stay down and all your virtual interfaces will be down as well. So talking of virtual interfaces, gonna hand over to Josh to talk about those with you. All right, thank you, Stevie. Yeah, so just taking a look at the virtual interfaces here just really quick just to level set, um, Steve kind of alluded to it, but, uh, virtual interface, that's the VLAN and the BGP, right? Um, I know you kind of like talked down about BGP, but I, I like it. So, uh, we have three main types, and I'm gonna go into some details on them, so don't, don't panic, uh, public, private, and transit. So public is for connecting to public AWS uh endpoints, S3, that sort of thing. Private for getting to VPCs, transit for getting to transit gateways and cloud ones, and then to VPCs. And then we also have the concept of a hosted virtual interface, uh, not to be confused with the hosted connection. This is a, uh, virtual interface owned by another accounts connection. They configure all the BGP and all of that stuff, and then you attach it to your VPC essentially. So sometimes that's like an infrastructure account or something like that. So we'll start with public virtual interfaces. I'm not gonna go into super detail on these because I'm kind of hoping you know, at least some level of uh understanding about these, but public virtual interface, these are, as I said, to connect you to any region. Um, these are, you use public IPs for peering. Uh, we have some ability to scope these down. I'll explain that a little later on. Um, but essentially what it is is a, a, your own personal connection to the public side of AWS. To talk about private virtual interfaces we have to kind of go back in time first. We have to, uh, go before 2017, which feels like the Wayback Machine. Um, back then Direct Connect was kind of a regional service, so what you had was, uh, your Direct Connect was in a region and you could connect to your VPCs that were in that region. Um, so in my example here I have US East One, and I have my VPC in US East One and my connection is in US East One. Uh, I can still connect to multiple VPCs, but one VPC per virtual interface, and this is where that, uh, concept of an associated region comes in, which you may have seen if you've used Direct Connect at all, um, there because you can still use this architecture. Then we kind of moved on a little bit, uh, to this architecture using direct connect gateway. So these are still private virtual interfaces, but what these do, uh, what, what Direct Connect Gateway does is allows you to bring all your private virtual interfaces into one Direct Connect gateway. Uh, those can be global from anywhere, and you can then attach your VPCs anywhere as well. So you can go kind of from anywhere to anywhere, uh, I mean from on-prem to VPC, VPC to on-prem. Then we started to get into the sort of the transit gateway cloud one world. Uh, you've probably come across those services, so we introduced transit virtual interfaces, those very similar, uh, similar idea you connect to regionally, you can connect to transit gateways, cloud winds in different regions, uh, add those on. Um, one thing to note there, you cannot mix and match there. You can't add. VGWs and TGWs and you can't add transit VIFs and private VIFs to the same ones, um, just something to keep in mind there. And then just one other thing I wanted to point out here, not necessarily a VIF type, but kind of a setting on a VIF, uh, a private or transit VI at least, is something called Sightlink. This allows you to take the, uh, your, your traffic from one DX location to another DX location, ride the AWS backbone. The nice thing is, and you can see I created a lovely little GIF, uh, you can just click the button and you'll start seeing the route show up on the other side. So you can kind of use it as, as needed, right? You don't even have to keep it on all the time. So taking a quick look at monitoring, um, these are sort of building on the things that Steve talked about before, but, uh, for virtual interfaces we also have, uh, the bits per second ingress egress and packets per second. So just to give you the idea of like what traffic is going over those connections. And then we also have, uh, an offering under CloudWatch called, uh, Cloudwatch Network synthetic monitor that's actually sending real traffic so you configure, uh, an endpoint in your subnets. And you can figure you give us an endpoint on prem and we send ICMP or TCP traffic you choose. And we return round trip time and uh packet loss metrics to you. There's also a, a network health indicator metric that comes back. What that is, it's, it's us looking at all of our internal metrics for everything from the subnet all the way to the direct connect endpoint that you're connected to just to give you kind of a quick look if you're having a network issue to say, oh, that's definitely an AWS problem. I can go yell at them, or I need to go investigate my network. And so to troubleshooting virtual interfaces, so again, um. Layer one. You should be fine because you've been through Steve's presentation, uh, but again that's kind of the first thing if your layer one's not up, you're not gonna get any further, right? Uh, the next thing to check if your VIF's not coming up is, uh, layer two. So making sure your VLAN tags match on both sides. The other thing we see pretty commonly, uh, especially when you start adding in partners and providers, they, they love to use these encapsulation technologies. Again, totally fine, no problem, uh, but we need to make sure once they are facing like the port facing AWS, those are stripped off and it's just the VLAN of your virtual interface. Then once you get up another layer, you're into sort of BGP layer 3 sort of issues, right? So. Um, you can kind of see it goes two different ways. Uh, if you're, if you're seeing in your BGP logs stuff getting stuck in idle connect active, uh, it's probably a network connectivity problem. If you're getting over that, you're getting an open sent, open confirm. It's a BGP parameter problem more than likely. OK, so I wanna talk a little bit about routing because. There's a lot to it, um, first thing I wanted to bring up here just kind of as I'm thinking about it, uh, as I was thinking about this, there are, there are the limits, and some limits are more important than others, and they kind of come in at different places. So on the screen I've got virtual interfaces per connection and transit virtual interfaces per connection. Those are super important, but those only really matter when you're architecting your network, right? The next two routes prepare. Those can take down your network or take down your direct connect if you exceed them at any point. So you really wanna kind of make sure you have a good understanding of your routes and, and are summarizing and making sure you're kind of keeping those under control. So I'll give you some ideas on how you can do that. First of all, here's an example of like a, a, um, route filtering. So here I'm filtering just for a couple of slash 24s, applying those as a route map to my peer, uh, sending those, just those routes to AWS. Another option here is um using summarization. So I'm using this aggregate address command. So basically what it's saying is I've got those 24s, ignore those, send a slash 16, only the summary. And then at the bottom, I'm injecting a default route using default originate. The idea there being, uh, just send a default route to AWS and then use the VPC route tables, TGW route tables, that sort of thing to control exactly which traffic you're sending. OK. How do you configure the routing, the active passive, passive, you know, active active, that sort of thing, right? That's kind of the next step. This is the mnemonic device I was always taught, so I hope some of you have, have used that too. Still don't understand why there's two oranges. I find that super confusing, but I've never used origin or origin type to decide a route, so it's fine. OK, so here's an example. Uh, I've got an Ashburn, Virginia Direct connect to New York Direct Connect. Uh, my VPC is in US East One, my data centers in Virginia. I wanna prefer the, uh, Ashburn. Direct connect. So how can I do that? Well, one way is AS path for pending, right? That's pretty common, uh, in the industry, very common way to do it. Uh, the other way that we could do it with AWS is using local preference communities. Um, so we have this, this set of communities allow you to influence AWS's local preference essentially. Then obviously you wanna also apply the same metric locally onto the routes you're receiving from us just to kind of keep things symmetric. And just so you can kind of see what those routes would look like, the top two routes are the preferred routes, the shorter AS path, and the, uh, the higher local preference community. All right, what if you bought all this bandwidth and you wanna use it all? Why not? You wanna go active, active. I've got two connections now in that same data center. How can I utilize everything? Well, I could just use the same local preference communities on both. Technically could also use the same AS path. I personally like to use the local preference communities because I feel like it, since it's higher up the list of, uh. Uh, like the decision tree, it, it, you know, makes me feel a little more comfortable, um, but you, you could also do this with AS pass for pending, um, but local preference is my choice, um, but that this way we'll ECMP traffic across both, so. Obviously advise you would do the same on your side but that way we're splitting traffic across both connections. So for resiliency purposes maybe now I'm going back to my two data center where I'm adding a second data center. Now I have a data center in New York, um, but my data center is still in Virginia. I probably don't want an ECMP across everything because I'm gonna have some weird latency problems and things are gonna start arriving out of order and that sort of thing, right? So in that case, generally I'm gonna apply my local preference communities on the. The closest, so that would be, well, I would pick one, but I would pick my Ashburn since that's the closest, uh, and then kind of a lower priority on the, the New York data center. Then obviously if things fail we can ECMP on the other one, everything's fine. Now I've never really come across a network that's that super clean. Uh, they're usually a little messier than that. And obviously we only have 3 local preference communities. So what do you do if you have 4 routes or more or 4 different paths and you wanna go 1234 in, in order? Well, for that sort of use case, what I would do, what I recommend, just equal out the local preferences everywhere and then use AS path for pending, so. You can kind of get, you can get super granular granular you could go more than 4 obviously with this, um, but that, that's how I would handle it. OK, just on public vis for a minute, I kind of mentioned these a little bit ago. The, uh, scoping communities that we have, these allow you to, uh, filter the routes from AWS that you receive, the public routes, and only accept routes for either the local region. The local continent or accept everything globally. Likewise, you can tell AWS I only want you to advertise my route. Into the local region, the local continent, or you can do it globally. The other thing to note, um, if you advertise the same route with an ISP and over Direct Connect, uh, we're gonna prefer Direct Connect unless you advertise something more specific or something like that. Uh, we don't apply local preference communities here. Those don't apply. You can use the ASPath for pending as long as you are using a public ASN. So if you use a private ASN, we're just gonna strip it off and use a public one internally. Uh, and then ECMP, uh, it gets a little bit sketchier with public trips, to be honest, um, and I would generally just say within the same location you can do ECMP as long as everything else is the same. And so just a couple things to take a look at. These are what the routes look like coming from AWS. First of all, you'll notice that we apply an ASN. We do a bit of prepending, and we apply the no export. Uh, that's really just to protect us from, you know, if you were to leak the routes out to, to an ISP or something, obviously your ISP should stop you, but just in case they didn't, we've got a little bit of protection. Um, I've seen customers strip off the no export, advertise them internally, that sort of thing, that's totally fine. Uh, it's just kind of a little accidental protection. And then, uh, you'll see at the bottom there the 8100 that's just saying that this route originated from that region, from the region that my direct connect is in. OK. So Uh, a bit of failover testing, right? Um, super important. Once you get your set up going, you're gonna have maintenance, things are gonna happen. Somewhere along that big long complicated chain of partners and providers something's gonna go down so you wanna know that you're good so you can do that any number of ways we do have a little failover testing tool which lets you bring down BGP. You can set a time for that, um, up to 72 hours, which seems like a lot, but you could set it to be down for 72 hours if it all goes wrong, thankfully you can't cancel it. That's good. And then just a note on our SLA as well that we have for direct connect. So, we have 3 models for our SLA. First one is a single connection deployment, pretty much is what it says. You have 1 connection. The next one is a uh high resilient multi-site non-redundant connection. It's a mouthful, but what it means essentially is that you're at two locations, but you only have a single connection at those locations. And then finally we have the maximum resiliency multi-site redundant deployment which is at least 4 connections, 2 at each site and on 2 different devices, 2 different AWS devices. So those are for you like your maximum can't have downtime super workloads. And then just uh expanding on, so Steve mentioned MacSec a little bit ago. There's another option that we see with encryption over Direct Connect, and that's using IPSec. Um, in that case, Direct Connect becomes kind of like the, the transport underneath, and then you apply your IPsec tunnel over the top from VGW to your own firewall or router. Um, you can do this with public or private IPs. It used to be kind of problematic because you'd be limited to the tunnel size of like 1.25 gigs per tunnel. They recently upped that to 5 gigs per tunnel, so that actually really helps. Um, so it becomes a bit more of a viable option. OK. On the subject of performance. Uh, just keep in mind as well, you can send as much bandwidth as your EC2 instance can handle. That's totally fine, but keep in mind if you're doing benchmark testing or something like that, that, uh, a single flow, like if you do an IPerf or something like that, a single flow you can only get 5 gigs. So make sure you're spreading it out a little bit. And then just make sure you make the most of your connections. So if you can support jumbo frames on private and transit BIFs, do that, um, because you'll get the most out of it. Public BIFs, we only support 1500, but. You still get the idea. And a pretty good blog post there. Um, if you take a look at that, some good tips on, on how to improve your performance, make sure you're doing good. OK, Steve. Brilliant. OK, so we've got our connection up and running. We probably want to understand how much this is going to cost. And this is a question that comes up quite regularly in customer discussions that I have. So what I thought I would do is just put together a couple of examples so you can consider the components that are involved when you're working out how much does Direct Connect cost you. So, in our example, we're gonna have. A very simple setup to start with. So we have our EC2 instance running in a VPC. In this example, it's in US West 2. We have a Direct Connect location which I've chosen for it to be in London. And I have my customer location on premises. This is how they're connected together. Obviously this is a, a non-redundant setup. Thinking back to what Josh was telling you about. So what do we need to consider? Well, when you're looking at pricing of anything to do with data transfer inside AWS you need to consider it in both directions. So in the first instance, we're gonna consider data transfer between AWS going towards a customer network. What are the costs that we need to consider in this particular scenario? Well, perhaps the most obvious one is the direct connect port itself. So there is a charge for the direct connect port. It's charged per hour and it's charged from when the connection comes up for the first time or 90 days have elapsed from the point that you ordered the connection. We recognize that when you click order, it's very unlikely that you're gonna be able to plug in immediately and benefit from that. There's gonna be time involved to arrange all those cross connects, those circuits, everything I talked about earlier on. But once that connection comes up and is stable, we'll start billing at an hourly rate for that port. And you'll get that charge now until you completely delete that port. So that's an important thing to remember, and it's consistent through each of the architectures I'm gonna show you. The next piece is the data transfer itself from the EC2 instance, leaving AWS going towards your infrastructure. And when you look at our pricing pages, that's where you see the wording data transfer from AWS region or local zone. And it's charged per gigabyte transferred. The way this works is you go and look at the pricing table, you identify where is the traffic coming from. So in this case from the contiguous US for example, and it's going to Europe, you can then work out how much that's going to cost you per gigabyte transferred. So the table for that is on the Direct Connect pricing page. In fact, that's where you can find all of the answers for, for these examples. So this is, as I say, a simple setup with Direct Connect gateway and a virtual private gateway. What about data transfer into AWS in this architecture? Well, in this case, we still have the Direct Connect port fee. Obviously it's not being charged twice in this situation. Um, but that, that's still a constant. But for data transfer in, in this situation where we're going via a virtual private gateway, we don't charge you for any data transfer inbound in this scenario. Let's look at a variation of that. What about with transit gateway? So we've still got our direct connect gateway, we've now got though the transit gateway on that path, and perhaps you've got many hundreds or thousands of VPCs connected to that transit gateway. So once again, let's look at it from the perspective of data transfer out from AWS to your infrastructure. We have good old port hour charge there, that's still the same. We also have the data transfer charge. That's still the same as well. No difference there, we're, we're moving data um across the AWS infrastructure. But the addition of the transit gateway does mean that we now have to consider a per hour attachment charge, and we've got two attachments, one towards Direct Connect, one towards the VPC. And then we have a data processing charge for the transit gateway. So in this scenario, they're the components you would add together to calculate how much this particular workload would be costing you. Let's look at it from the other perspective, data transfer into AWS with this architecture. Still got the same components, transit gateways sitting there, so our old friend, the Port Hourcharge, still there. Data transfer coming into AWS, there's no charge for that. But we do still have the transit gateway on that path. So what that means is we still have the attachment charge, and again this is not being charged twice, it's the, the same attachments we talked about a moment ago. And there is the data processing charge for the traffic that is moving through that transit gateway. So I mention both of these scenarios because you could have a scenario where it's useful to use the virtual private gateway architecture for certain workloads and perhaps a transit gateway or cloud WAM based architecture for another. Josh mentioned Sitelink, so I wanted to just cover off how we, we bill for that as well. Um, in this situation, I've added another Direct Connect location in. Um, it's here in Las Vegas, and therefore I now have expanded to have a US office for, for this organization. Uh, the EC2 infrastructure's still there. I've grayed it out because the, the billing for that is exactly what I've been talking about so far. But for SiteLink, there's a couple of other things to consider. When you create the virtual interfaces that you're going to use for Sitelink. You're gonna attach those to a direct connect gateway. We've still got the port hour chargers, they're still there. We create the virtual interfaces and we check that box that Josh showed you. At that point, we've now enabled Sitelink, and there is a charge for enabling that capability on each of those virtual interfaces. Once you've done that, the traffic is now able to flow between my UK office location and my US office location, going through the Direct Connect infrastructure. And to work out how much that costs, you need to now go and look up on a table that we have on the Direct Connect website. So for traffic flowing from the UK to the US you would go and look up in the table and identify this traffic is coming from Europe to the US. And then vice versa, traffic the other way, you'd go and look up the table in the other direction. And as you can see in this example, it's actually the same charge here, um, but that's how you calculate the pricing involved for Cylink. OK. Now, there's a few components involved in there, and I wanted to share something that we published a few months back, um, which was the open source networking focused calculator. We have the AWS pricing calculator. I'm sure you've all seen that. Um, but we actually have this tool that we put out there for you to be able to deploy in Use yourselves to help calculate anything to do with networking on AWS. Uh, it pulls from our pricing APIs, and I just wanted to mention it. There's a blog post all about it. So if you're trying to calculate how much these architectures cost in advance, you may want to deploy, um, the, the pricing calculator tool that we've published there. So you may have seen, uh, over the last few days, um, we announced this new capability called Database Interconnect Multi-Cloud, uh, in partnership with Google, uh, in preview. Um, I just wanted to spend a, a quick second on it. Uh, I think it's super cool personally. Um, what, what it does is allows you to kind of create capacity to another cloud, right, to, to GCP in this case. Uh, what we're doing is building in our maximum resiliency model, so the, the four wide connectivity that I was talking about before, it's all pre-cabled, it's all pre-built. All you have to do is go and say I want 1 gig, I want 50 megs, whatever you want. Right, um, and you can, you can get that from us through this, this new offering. Um, so GCP for now, I think Rob Kennedy said in his innovation talk today, first half 26 for Azure, uh, to be added to this as well, um, and there was a talk earlier today, so unfortunately you missed that, but, uh, a deep dive onto this, I think it was net 205 it was, um, so if you wanna go look that up on YouTube probably in the next day or so it'll, it'll pop up there if you wanna get more information on that. Oh. All right. And just to wrap up some things that we want you to take away and remember. So first of all, just going all your way through the layers as you configure and troubleshoot, start layer one and kind of work your way up. Using the right viiff for the right job. A lot of times you can't use the wrong wiff for the wrong job, but it is good to kind of consider that. Getting a good idea of what you're gonna do with BGP, are you gonna need to do some summarization? Do you, what do you need to do with the communities? Like, do you need to configure active, active, active, passive? What are you thinking there? You wanna design for resilience, right? So again, as you're building, are you trying to meet a particular sort of SLA? Uh, is this a high available workload or is it a. I'm just testing and I don't care. Uh, and then obviously test and test and test and make sure everything fails over as it should. Understand how to calculate your costs. I think that, um, solution, the open source solution is a really great way to do that. Or you can go watch this on YouTube and rewind and watch the last 5 minutes again. And then just embracing your capabilities. So if you're using Direct Connect directly to VGW's, try out Direct Connect gateway. It's super easy, doesn't add any cost, doesn't add any latency, and really just kind of expands your portfolio. Try out transit gateways, try out SiteLink. Try out cloud one, try out interconnect, um. Yeah, thank you very much and uh.