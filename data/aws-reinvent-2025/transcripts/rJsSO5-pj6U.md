---
video_id: rJsSO5-pj6U
video_url: https://www.youtube.com/watch?v=rJsSO5-pj6U
is_generated: False
is_translatable: True
---

Well, good morning. Hopefully you're having a good show and starting the conference off right. I'm Scott Pickett, and I'll be speaking with you about enterprise scale modernization, leveraging Agentic AI and Janice Tooling. So what's the problem set? What are the challenges out there? Why do people need to modernize now? Number one, retiring SMEs. They don't teach cobalt in school anymore. There aren't cobalt experts. There aren't for trend experts. There aren't 8 experts, but there's a lot of that code out there. A lot of institutions and companies still rely on it, and they cannot even get SMEs that have a detailed understanding of the application, let alone know how to fix it, run it, and operate. The other issue that enterprises are facing is a growing technical debt. Basically these applications haven't been looked at for years and years and years. They're very, very fragile situations where they can't update regularly. Oftentimes these solutions are updated on an annualized basis at the most. Um, that's a, that's a huge obvious issue, and it's growing and growing each year. It's growing and growing. The other problem out there that people are facing is increasing license fees. Many of the vendors who shall not be named are now taking advantage of the situation and increasing their license costs by upwards of 300%. They know you got you, and they're going to increase and increase and lock you in for another 3 years, and that's another major problem. Got a few people smiling out there. Um, and the other situation you're seeing is business innovation. Population changes, number of users changes. People want to start to leverage web services and add-on services. The legacy solutions aren't cutting it. They can't meet the business needs. TSRI has been in the industry for 30 years. It was founded out of Boeing AI labs. We basically touch every single segment worldwide. Cut its teeth in Y2K, um, really in the, in the, uh, defense and federal sector that was most of uh the business early on. We've since expanded into retail offers. We've done a number of different postal services recently rolled out the United States Postal Service, um, all the financial traction there. We've done the Danish Postal Service, um. Big new momentum happening right now is in insurance companies modernizing several different insurance companies and just completed a nationwide roll out there. Talk a little bit about that. And then also the big one is the financial sector. Some of the largest legacy mainframe solutions right now are in the banking sector and they're modernizing now for the same reasons I just brought up. We're recognized as being a leader in the industry. We're in the top magic quadrant and innovation and solution options. So how does this, how does this all work? So we have a deterministic AI engine called Janus. That's a rule-based engine that gives you a known output that can still be, you can still leverage experts to be able to um write rules to operate on that code base, but you always know the emissions that you're getting. There's no probability in that. There's no guesswork. We've integrated that in with a Gen AI solution. We have extracted out knowledge graphs that can drive that G AI, chunk that down into stuff that are into usable chunks that it can operate on efficiently, because we are talking about millions and millions of lines of code. We're also giving a lot more domain expertise associated with that implementation. Those knowledge graphs are driven into a vector database that's allowing you to do a number of new things in your modernization efforts. First one you gotta do is assess where you're at, where you're at with your code base, what you. Don't know what services you need, what services you don't need that's all done by utilizing our, our, our next generation solution, Juno that's an application agent that leverages our business documentation, our design documentation, the test documentation, and, um, provides proposal feedback, POC feedback, and actually gets you started in your modernization journey. The next step after that is actually doing the code transformation. This is all automated. You'll, it's all, it's all right now available for demonstration at our booth, um, but it's all automated. It's up on AWS. It'll generate transform code using that deterministic IOM-based solution, providing you with code output, providing you with those. Uh, with additional testing output, being able to give you information on, um, uh, database, not information, we do the schema transformation and actually develop the ETL scripts for the data loading so you have a solution there and we also do the screen transformation, migrating people from kind of your legacy green screen situations into a react Angular and blazer type solution. In addition to that, you're operating based on a solution that can be modernized. So you begin to be able to leverage Gen AI to do idiomatic refactorings of the Java RC. And that gets you to a point where you're now a solution that's stable that you know works, that the business logic is maintained, able to start to reimagine your solution, be able to leverage Gen AI to move you forward. You're in a new, you're in a, you're in a a mic, you're in an updated CICD pipeline. You've got unit tests. You have regression tests. You're now able to build on something that you can move forward with. In addition, you, uh, typically as a part of this process, we're injecting rest end points, API interfaces that allow you to be able to integrate in with COT solutions or be able to partition the solution out into different microservices. Let's talk a little bit more about the details associated with the solution. Again, it's all based on a deterministic AI solution as the foundation. This is Jannus. We're lexing and parsing in a traditional way to drive towards an intermediate object model that's basically a representation of the abstract syntax tree. I mean, you go up and down that syntax tree, you can take out nested loops, you can drive in new rest interfaces, um, you can containerize at that point, um. All the, all the syntactical issues are are resolved, uh, the semantics like go to statements are eliminated. You're able to basically get a solid modernized solution that runs and is functionally equivalent. Then you're able to also apply rules and do rules-based refractory, do code quality refractory. We extract out a knowledge graph that'll allow you to start to leverage Gen AI and with the Gen AI solution, you're basically developed a custom prompt engine for your solution that allows you to generate all the details that you need for business documentation, test case generation, metadata that can allow you to actually run the test. We do, we can provide also seed tests and then be able to expand on those seed tests to increase test case coverage, an often forgotten part of modernization. You end up, you need the code, the source code, and we'd have all these artifacts delivered. It's, it's, it's kind of a new world with respect to being able to have a platform that you can take forward in the modern environment. So, This solution right now is operating today over here, but this is a couple of screenshots. They might be hard to see, but go and take a closer look. You'll do the project assessment. You'll get the details of the project assessment, you know, understanding the business logic, having an agent that you can query that solution and get insights into that solution. You can get complete proposals as far as what the costs are going to look like when you're in the AWS environment and what the savings are going to be seen. You'll have strategic recommendations on how to replace external services that you're dependent on around those dirty little assembly programs and those proprietary sort programs. You'll have the details that you need in order to replace them. You'll also be able to have a general understanding of what a project looks like from a cost standpoint. A number of plans are generated as a result of that. Obviously you've got to understand the legacy code. You have to understand, you know, what you don't need. There's a lot of time in the con you know, the concept of deprecation and regimented deprecation on, hey, we really don't need this. We have to use it now. We're going to support it for the next 10 years, but we're gonna eliminate that. That's going to migrate over to something else. 2, we're gonna transfer the whole thing, bring it up live, and then. Kind of use a a strangler approach and eventually carve out the the um external type of interfaces, the onboarding interfaces, the printing and reporting functionalities, and slowly replace. You'll be able to understand what that is like from a project standpoint in a wave of a wave of deliverables, a product increment type of approach. Um, you'll have test plans, transformation plans, external replacement plants, and hosting plants. You also get AI driven documentation. So you'll have English instead of cobalt. You'll be able to understand the details associated with those programs. You'll also have deep understanding of the implementations. And you, and that's based on our new offer called Juno, and this is available now. Literally, you can talk to it, ask it questions, and it gets your information back. So that helps with that replacement of the SMEs that are dwindling in availability. You still have your traditional understanding and visibility of the actual code. We're developing control flow graphs and and um state diagrams, uh, business rules, and again you see on the right hand side there, there's your dialogue. You can ask general questions, you know, what does this batch program do? How do I schedule a room with this batch program? Tell me how the payment gateway works and I'll answer those questions in English. And that this gives you a little bit more visibility. You can ask, you know, how to stand up the database. How what can I use to replace that database? What are the differences between the two databases, meaning the source and the target, the DD DB2 versus Postress? You're able to get detailed information on the legacy. You have insights on the target, and you're able to map your direction on going in between. One of the interesting things is this kind of, this kind of replaces about, you know, 4 or 5 p.m.s. OK, you now have an executive dashboard on what's going on. You, you have visibility in that. Do you have a complete code set? Do you know what the holes are? Do you know what the holes are in your delivery? What, what are, I, I just offended some people. Excuse me, nothing's going to replace PMs that always have a role. Um, you'll be able to get the status on those code deliveries. You'll understand and get summaries, detailed summaries on your code quality, how many, how many rules you're violating, whether or not there's security issues. So this is all at a high level. It's a, it's a pretty detailed, it's a pretty detailed page, but it gives you the insights on the code quality, the sonar crew readings, security flaws at a very, very high level. It also lets you know these dirty little implementations that nobody wants to talk about. There's all sorts of. Frameworks that have to be implemented. There's, there's difference in the way data is typed in cobalt that's not representable in a native Java. So those little dirty secrets are now exposed to you, and you know exactly how you can map between the two, how much of it's been done, how much of it still remains. Same thing with those external functions. There's a lot of different ways you can run sort on a mainframe, a lot of different cards that are used, and, and now you're able to actually see the level of, uh, the level of. The state of the implementations of those and you also get a testing coverage. You'll have testing results. Probably the the coolest thing about this offer is it's a single button transformation. You click what used to take days to set up and an expert, you can now just click the button as long as you have the complete code set. You you you you do require the complete code set. You can go through this process. Well, it'll go through the parsing, lexing. You'll get to the point where you understand what the wraps are. You'll resolve, you'll make sure that you've got a complete solution, do the transfer. Information you'll get the code coming out. You'll see if it compiles. You'll confirm it compiles. You run it through the pipeline. You'll get the unit test information. You get the test coverage information, run through the code quality scans, and run through the actual functional equivalence testings. And I know it sounds, sounds like a miracle, but you could do that with a menu click. We've got the demo up and running. You can see it kick the tires yourself. You also have a real-time live log. The resolution's terrible on this screen. Um, so you, you, but you can see it in the, on the demo. You'll see a live log of what you're parsing, what, what process you're at. So each one of those, as those cycle through, you'll see the actual status in the logs. And then you'll get it. This is, this is another really cool thing. It's not been done. So you tie this in with sonar, you get a sonar report, we bring that back through a LLM recommended refactorings. So you have agentic refactorings. We'll go through and we'll go through and you can single click execute on those different refactorings. You hold those states and you decide if you want to apply them because sometimes when you do those. Factorings you get a more verbose solution your code set increases and you might decide not to do that refactoring. So here's a case where you're actually able to select which refactorings you want to apply, apply those refactorings, view the results again since you have the testing already done and you know it's functionally equivalent, you don't have to worry about that hallucinating and the probability of those being wrong. You have a solid baseline to work from. And that's this is the the testing dashboard. So before I start on the dashboard, we can extract out metadata from the source code. So we get the files that are touched, the tables that are changed, the input parameters that are required. It's basically everything you need for a unit test. We've now developed. Instrumentation on the cobalt that'll collect that information automatically. It'll gather those files. It'll gather those tables and put them in a package and make them available in the modern environment. So you've got everything you need to not only have the test case, but actually run the test, the functional equivalent test in the modern environment. That's huge. That saves like 6 to 9 months. Trying to do this manually is. Well, there's a lot of system integrators doing a great job at it now. So you end up with functional equivalence testing. You've you've got, do it, does it run, crashes, you gotta fix it, right? So but does it run all the way through? Did it have any errors? Did it, did it, did it have, you know, good output? Can you, you have to compare the output and then you get it to pass. So there's like 3 different states you do for that functional equivalence. You have to make sure every single bit in that representation is the same as the legacy, and this is for thousands and thousands and thousands of test cases, literally thousands of batch programs, hundreds and hundreds of screens. You gotta to automate. You also have to be able to do that the system end to end testing level, and this is often done on the on the backside. You do modifications on the scheduler. You could drive it with Python for an orchestrated solution. On the UI side, you could on the UI side you use something like selenium. So we've delivered a number of these solutions and a couple I want to bring up are um uh the United States Air Force. Here they saw a 90% cost reduction with ETS. We got that up and running in literally days and we're able to complete the refactoring in less than 2 months. Um, these are referenceable, um, and the interesting thing about ITS on the application side. is that they took the next step. They replaced, they replaced. In 48 states, 36 plans, 29 mainframes, they had to go through and change, they had to go through and make it so that they could have a multi-tenanting capability to handle all those different plans. So they basically turned their solution into a SaSS model, and it's operational on AWS right now. So how did we do? With respect to retiring SMEs, you now have Juno, an agent that gives you insight into those implementations. You've got it in a modern language where you can hire people to actually work on it. You've got documentation, and you have all the test metadata that's required in order to run it again and again and make sure you didn't break it when you apply your eugenic solutions. How do we do on the growing technical debt? Well, we'll make sure all the sonar cube scores are passed with quadruple A's. That, that's just, you know, we lead the industry in that area, but we'll also be able to provide agentic solutions to get it to be a solution that looks less like cobalt and more like Java, even though it's based on a cobal implementation. What about the increased license fees? It, you, you're going to, you're, you're eliminating your legacy license fees, your legacy IT, I don't wanna say IT group, uh, uh, department, uh, no, I can't say that either. You, you, you basically, you're on, you're on AWS. It's now managed. So you don't have the same type of issues you had with respect to hardware provisioning. It's automatic and it's also included, um, so there's huge savings there. And then as far as being able to to move forward, you're now in an environment where you have experts that can work on it and they can operate and meet your business requirements. Today we're working on extracting out portions of the code out of cobalt that was in cobalt to be able to separate that into a separate application that they can go through and move to a cot solution. Those are, those are examples. Oftentimes this will be done in an MSP type of fashion. We actually commit to a multi-year program that will continue to break out services, break out APIs, and be able to on an ongoing basis, offer the customer new capabilities, remodernization, reimagination, and continuous modernization.