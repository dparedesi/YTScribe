---
video_id: pQOZRvrEy3Y
video_url: https://www.youtube.com/watch?v=pQOZRvrEy3Y
is_generated: False
is_translatable: True
---

Hello everyone. Thank you for joining us here and reinvent. I'm Betty Zheng, a developer at WCAT and AWIS. Um, I'm very happy to be here with my co-speaker Trista Pen. She's AWIS data hero and he's a senior AI engineer from Touch it. Uh, Trista, please introduce yourself to everyone here, please. Yeah, sure. Hello everyone. This is Trista. Uh, so I'm the AID, uh. Double edged the hero because my previous background actually is about the distributed database stuff, but recently year I found that maybe AI agent is a good way to leverage AI capability and the data to create your AI agent. So that's why now I take care of the AI agent stuff at to trade. Yeah, yeah, as just aside, our topic today is building production. Uh, agents one mastering industrial AI. The idea behind the talk is simple. AI has moved beyond the chat. Uh, you know, today AI system can plan, copporate, and fix real countless problems. Uh, just we work with a team of engineers. Yeah, so today we're here to show you how to build them. OK. Uh, here's our agenda for today. First, we will talk about why agents matter, why they are different from normal large language model applications, and why more and more teams are moving to agentic system. Then we will explain how agents work. We will break down the architecture, the workflow, and the key components inside the agent. Next, uh, we will look at safety. You know, production system need clear rule and safe ecution path, and we will show, uh, simple patterns you can use today. By the end of the session, I think you will, uh, have a clear full picture of how to design and, uh, uh, and run agent system in your production environment. OK. Now, let's go into our first topic, why ages matter. Today, uh, you know, AI applications are everywhere in China. We see them in search engines, office tours, social apps, and even in restaurants, uh, I mean, for ordering food or writing reviews, um, some apps even use large language model for virtual telling. And please look at me. I'm wearing uh AI powered glasses. Yes, they can show me uh entire slide, uh, back inside the lenses. Uh, they can help me to improve my spoken English, and I think uh I can stay in connection with all of you better today with it. OK, so yes, uh, application, AI applications are now, uh, everywhere and extremely powerful, uh, I think both in China or globally, but We heard many teams, many, uh, customers told us a single modern core isn't enough for real work, and then agents start to shine in mining production environment. Uh, you know, agents act as a tools for largeological model. It's just an early human discovering better tool, I mean maybe the stone. Uh, so the human's brain, uh, didn't change, but what human could do, uh, changed dramatically. So, uh, Um, agent, uh, make model, plan, take action, and so complex, uh, tasks. So with agent we moving to, uh, agentic AI agent. Um, we engage AI model beyond the chat. We have a team of engineers in the production since then. So just that, I know you work with your team, use agents in production today. So to explain why it is matter, uh, let me hand it over to Chaser. All right, please. Yeah, so, uh, I guess most of the people, uh, before we, uh, saw this image, actually it's from a paper, uh, it's about AI agent. Uh, so today I guess it's a very good point. Uh, we started, get it started. So when we talk AI agent because I don't know, maybe in our audience, we have some beginner, we have some professional one, but when we talk AI agent, uh, I guess most of people will think about the chat GPT. I guess it's a good one because that's the first way we learn about the AI agent stuff, but actually such kind of AI agent just to focus on the content generation, right? So you ask a question and you content your answer, that's it. But gradually we found that maybe AI agent can do more. That's why when you now use TI JBT they can help you do some of the like the web, web search stuff or like Web scripting stuff, so, uh, it's really like this image, uh, we have the AI agent, you can see a chatbot and the user talk with the chatbot and chatbot, uh, will use some of the model, the, uh, like AWS model or open AI model and do some the reasoning and planning stuff and it's really like a person think about how can I answer this question or maybe I take some action to solve such a problem, right? When they have such a plan and then uh they will consider, OK, now I can just give you an answer or I need to take some actions. So uh now we talk about like the IMCP server stuff, actually it's all about like the action. To our work workflow stuff. Therefore, you have found that AI agents now can just uh do some of the generation stuff. They can help like the book your hotel or do more, especially in some industries, uh, for example, uh, one of the most popular AI agents is the customer support, right? So, uh, that's why maybe I can share some of the demo to you, OK. All right. OK, that's fine. Later on, I will share some demo about the AI agents, uh, but now, uh, when we talk about how to create a very decent AI agent, we need an infrastructure, right? So that's why, uh, we have this architecture here. Um, the, on the top one, we have the model. It's like the model as a service. For most of the people they will choose some the The model vendor or you can just pick the one of the popular open source model and deploy it locally. That's fine. So you have a model that means you have a brain, right, agent of the brain that can help you reading or planning stuff and second one about the AI agent building platform. For we need some the scaffold to help us quickly to create your AI agent right so for most of the popular like the long chain or lambda index or like um AWStrat or like some of the uh uh NAN right such kind of platform. Their role is to help us to have such the sky folder framework to create such the AI agent. But for most of the framework, they have the following, the components that are very important for us to create the AI agent. The first one is from engineering. Second. One, it's like MCP server we're plugging stuff and third one is workflow. It's always about your business logic because for different scenarios, actually you have different logic, right? Like the book a hotel or write a paper, they have different workflow, right? And then we have the knowledge base that most people will heard that the rack, right? Retrieval uh generation, right, uh, retrieval, right, a uh augmented generation, right? So I think that the knowledge base, that's the key point because we gradually found if we really want to create a very great AI agent for our customer or any user, our AI agent needed to know more about our company, know more about the business. So if you ask a ChatBT, uh, for example, if, uh, like the, I'm a yoga mat vendor, right? So I asked Chat GBT could you introduce some more about my yoga. Matt you know nothing about me, so they cannot give you an answer. So that's why we need to use rack or knowledge base to let our AI agent have a lot of like the memory or the knowledge about my company. So therefore I can deliver such a good AI agent to my end user or customer, right? Yeah, so now we have a lot of the framework or like the open source framework or SDK can help to do such stuff, right? So that's very important. But actually AI, uh, agent building platform or the model as a service, that's all about how to create or develop AI agent. But once you create an AI agent, the next part about how to operate it. So I guess, I mean before the AI era, we will talk about like the that stuff, right, about the cloud computing. Actually, AI agent is just a kind of software. So if it's software, when we put it on production, then we will consider how to operate it and guarantee availability, do some observability stuff, right? So that's why, I mean, When we create an AI agent, the next topic is about how to operate it. Therefore, we can see it's like an AI agent that op stuff. So, uh, on the right one, it's about the security stuff because from my experience, I did a lot of, I actually, I created a lot of AI for my customer. And gradually I found uh some malicious and you, you don't know, right? They will ask some like the malicious questions about your AI agent and they want to steal some like the prompt stuff or your privacy, right? So that's why when you do some like the access control about our agent, so you can create an AI agent, operate it, guarantee the uh security stuff. Then that means you will have a lot of the enterprise applications or we call AI agent for your business. So that's why I gave this architecture. Uh, when you want to create your AI agent, please give a look at it. It will give you your insights about how to like give more attention to which topics. Yeah. And here, uh, I gave two demos about AI agents. The, the last one, it's a very popular one, it's just the customer support. Let me show. Right, so you can see here, I just, uh, create this the like the one vehicle vendor or reseller web page. So generally, we will have such an AI agent when I ask about, hey, Uh, could you tell me how about the Model Y, because I'm interested in this car, uh, so you have such the car can sell to me, and then this A agent will do some of the semantic search. Also there maybe there's no voice, I don't know. So it will uh show you a lot of the details about my product, right? So you can see here when we tell AI agent now, we just use the test stuff of gradually we found maybe we can use the voice, maybe we use the uh vision to do the AI agent stuff. So that's a very popular case for most of the AI agents and the next one is to treat troubleshooter. So you can see here, um, because why we want to create such the like a troubleshooter AI agent because we found, uh, we deliver our product to customers environment and now we need to guarantee uh the SOW, right? But we found we spend a lot of The human resources, time to help people to locate their question or their problem pinpoint and to fix them. It really costs a lot of time and plus most of our customers, the local customers, they hope that we provide the 24/7 hour support for their environment. So we cannot do such stuff, right, but we hope that they can satisfies our product so. They think, OK, maybe we can just create them the AI agent this troubleshooter. So when our customer, they raise a ticket on the Jira and this AI agent will pull down the content of the Jira ticket and analyze it and to uh or to uh request, do some queries about our uh menu or run book or QA QA stuff, right, QA wrapple. And then they will give some of the solutions to our customer. So, uh, therefore, the customer can quickly get the solutions and to test it, and our next release, we will consider to like this AI agent to connect to some of the MCP server. So that means this AI agents not just to deliver the solution to the customer. And we will help our customer to log in their production environment, right, and to help to fix it, fix it. So you can see here, it's not just about the content generation stuff. They can really do some actions to really fix some issues. It's not just like our customers to copy paste this command and then they ran all the the command on their product and give us the feedback and we will iterate again and again, right? So I guess that will be perfect for the AI agent case. Yeah, so, uh, now we have some of the demo case and we have the architecture about the how to create the AI agent and we will, um, dive into, uh, each part like the problem engineering or the, how to pick up a good framework for most of the people because Actually, AI agents, um, it's not obscure like the topic, right, because it's really like how understand the people's pinpoint and then Leverage AI model capability to create a software or deliver a solution. So, uh, here I give this framework because the first one we need to pick one of the framework, right? So the left one, it's really for some the business people or like the Uh, data, um, analyst or the marketing people because for all that the roles, uh, they have no engineer background, so they don't like the coding stuff. Uh, that's why we recommend such the local platform to help them to create the AI agent. And so you can see here, uh, generally if you like the leftwise uh NAN or other open source projects, there are so many. So, um, for most people, they don't need to do a lot of coding stuff, uh, they can just like um drag draw uh some node. And to uh use the, the connection stuff to uh create your business logic there, right? Uh and um for all that the open source local platform, they have a lot of building capabilities, so we're building nodes, right? So you can see the left one, they have lots of kind of nodes, uh, the LLM nodes or knowledge retrieval nodes or multi-agent nodes or If out that stuff. So therefore you can just uh draw your business logic there and use some of the building capabilities to create your AI agent. Uh, that's a, actually for most of the people, uh, it's a good start here uh if you like, don't like do some coding stuff, um, but from here, uh, there's a question that Um, because we use this platform, we drag draw, we do not do some coding stuff, so that means you can just only pick. Uh, the tools from this platform. So, if your case is very complicated and you need to use some connectors, there's no such connectors. You need to come back to coding stuff because such open source platform they currently they do not provide uh the capabilities that you like, right? So, uh, but, but, but I, I know for some of our, uh, colleagues, they like this because they can just do some of the demo for their customer, right? Because, you know, uh, we, or sometimes we do some. PUC for a customer before they decided to buy, right? So they will use this such open source platform to do some demo. It's very easy, very efficient and don't need to such complicated on production ready solutions. So that's a good one. But actually uh for most of the developers, they will prefer the coding stuff. Currently, uh we have a lot of the open source SDK or framework for you to pick. It gives us the most flexibility. You can do everything here but that means you need to code it, uh, build it. Deploy it, maintain it, right? So it, it's a software, so everything about software, the dev stuff you need to do by your team or by yourself, right? But you can do everything here. You have the most flexibility, right? So, uh, that's the pros and cons of different framework. I mean, you can just based on your cases to pick one of them. Um, yeah. And that one, once you decide which framework or open source project you need, and that's why we need to pick the model, right? So, I guess most people will think, OK, so therefore just to pick one of the most popular model or Free model, right? Uh, even the same model, uh, for different scenarios, you also need to adjust some parameters for your case because, uh, like, like take an example here, um, when you do some like, I hope this AI agent can help me do some the uh paper writing stuff, paper writing stuff, right? So that means everything, the generation stuff need to strict. Everything is based on the facts, right? You cannot do some creativity stuff, right? So, but, but if you ask this AI agent, could you tell me a story or write a poem to me, so that means this AI agents need to be friendly and have a lot of creativity here and give us some uh imaginative like the content, right? So you can see here. Even though it's the same model, but your case is different. That means the parameter when you do some adjudgment, adjust to make it fitting for your case. So, uh, actually, it's a long parameter listed there. I just pick one of them, for example, the temperature or the top K or top E that will decide, like I said before, um, making the content generation more um. Imaginative or keep more coherent, right? Or for example, the max token stuff, you need to control um how long the generation or the answer is or like the um frequency. Penalty, um, you hope your agent to give the answer every time they keep the same like repetitive or no, you hope that every, each time the answer is fresh, fresh. So different to the scenarios may need different parameters, so I just here give some of the cases because we have no enough time to introduce them one by one, right? Yeah, so the next part about the multi-agent system, maybe Betty can introduce more about this part. Yeah. Uh, thank you, Trista. Trista show us how to choose and tuning, uh, large language model in a real project. But, uh, as we know, we often work with more than one models in our production environment because different models have a different strengths like the, uh, twister site, maybe some of them are best and content creation, and other one is, uh, good and the, uh, video or picture generation. So, uh, we need a simple way to call this model or switch between them, uh, and test them and without, uh, writing a lot of boilerplate code. Yes, this is where, uh, I think AWS, uh, student agent, uh, shining and, uh, comes in. Yes, Strat agent is an open source SDK from AWS. It makes the easy way to build agent workflow and multi-agent system with only a few lines of code. Uh, with strength agent, you can call models through, uh, Bro, uh, L LLM or direct API core if you. want full control. Yeah, there are two code examples on the slide. On the left you can see we load a barrock model, um, on the right, uh, you can see we use the light LLM for another model, but both of this code are very short, clean. Yes, so straight agent handle the complexity for you. Uh, you can focus on your logic and sometimes it's because it's open source, so, uh, you can extend it with your own tools and, uh, integrate them into your own system easily. So if you want a a simple and flexible way to with multiple, uh, like language models and build agents faster, I think, uh, strength agents give you a great starting point. OK, um. I know, uh, uh, I think, uh, if you, uh, build this your multiple, uh, strength agents, you can choose another, uh, tools or another, uh, platform, uh, for your, uh, multi-agent system, I think, uh, including Brock itself. You know, Brock is uh AI, uh, Uh, platform to help you build your AI application on it. Um, if you are AWS builder, uh, Brock agent core, uh, I think can give you the easiest way to build a production grade multi-agent system, but for I think for more uh developers we need open source because uh we can use open source uh to integrate our uh different environments, so open source tool like agent can offer more uh flexibility in different uh production environments. Well, um, uh, we have known how to build agents. Now let's look at how to connect multiple agents and to take them together, work together, yeah, so pass to you. Yeah, all right, so, um. Because I know most people now consider, maybe we can use some of the multi-agent to, for your scenarios, but uh from my experience, um my suggestion is that to start from the single agent, agent, um, yeah, because um now um when we talk about workflow or talk the single uh AI agent, actually, uh, we're talking about the second one, it means when we create a workflow, that means You know everything, you know your uh business logic is always follow such kind of workflow. But for some of the cases, actually it's not. For example, um, like Um, we have a company, uh, I'm a director, right? And each time we will, uh, develop a different products for our customer. So that means each of the requests, we will have different workflow for each of the requests. Maybe the first time, uh, I just need the business people to help us, that's it. Or second one, maybe I need The production, product team or test team, developer team. So you can see here, it's the dynamic. You cannot just create your workflow at the beginning, it's the static. So that's why um now we'll consider maybe we can use the object agent. Each request is a dynamic and each of the time, uh, our AI agent first to reason. OK, so maybe this time uh we just need the three departments, uh, the product department, developer department, and the test department for this request. That's it. Or next one it's another story. So, uh, that's why uh we actually have a lot of paper, um, do some of the research about this part. But it's a very complicated because you can see here if you have the different departments, you have the different agents, then you talk with each other. So how do we talk with each other? Uh, generally, first, the model is that I have a router, I'm a director, I'm a router. I will get each of the departments, they just talk to me and listen to my guide and I'm the reasoner. I will do everything about planning stuff. The second model that no, there's no the single direct there. Everyone, they tell each other, right, the interaction stuff. So therefore, um it's a distributed system here, especially for your production environment. So the question now is, it's how to guarantee the cap, I mean the consistency, availability, and partition tolerance, that stuff. It's a distributed system. If the internet this time is broken, so how can I, I guarantee that the message delivery stuff, um, yeah, so that's very complicated, um. But maybe one day we can really make it on the production environment, but, but currently I guess if your case is not so complicated, maybe you can just uh try the workflow or static one. even though for the workflow or static one, you also can use the multi-agent there because it's a workflow for each of the nodes, the node can be an agent or the node can be a LLM. Uh, for example, uh, you remember the first of the customer support that AI agent I showed you before, right? That's a multi-agent workflow. So why is the multi, multi-agent? Because I will consider the end user, they will not just ask about the vehicle's question, they will just do some chatting stuff. Hey, what's the weather? Uh do you know um Can you introduce more about the Las Vegas and stuff, right? So therefore, actually uh that AI agent, I have two AI agents. The first one is for chat, uh random chat, I don't know. The second agent is for professional car recommendation. And I just use the workflow to connect to the different car and do some of the ELLs. If this end user asks about the weather stuff or just want to talk with me, then go the chat agent, but if they ask me about my cars, about my product. Please go to the professional car recommendation agent and then I merge the readouts and give the final readout to my customer. So you can see, uh, it's a static workflow, but it's still a multi AI agent, right? Yeah, so, uh, in order to create the multi AI agent system, actually we need a lot of the tools for our workflow. I guess Betty uh can introduce more about it. Yeah, thank you. Uh, Trista, I will talk more about uh strength agent. Uh, now we, uh, have seen how uh the why multi-agent system works so well. Let's look at uh how agents make this, uh, practical. Um, you know, uh, strength agent support a few ways for agents to work together. Uh, one is orchestra model. Um, that means, uh, one agent, uh, leads, uh, it assign tasks to other agents and collect the feedback from them. Um, second way, uh, you see the swarm model, uh, there is no leader, but agents work together, they share ideas and pass results to each other. Uh, I always saw, uh, graphic-based agent. Uh, you can connect agents like flow. Each agent handle one part of the process. Size, uh, also, um, we, uh, also can see the full workflow or pipelines step by step, uh, multi-agent task. Each stage is handled by, uh, different agents, uh, that all, uh, usually say in our, uh our build the multi-agents work together and strength agents support all of them. But I think besides that, strength agents also give us a full set of tool and ready, uh, from day one. Uh, I know, uh, many developers love them, uh, including me. Um, Yes, you can see I list some tools uh in the uh in the slide, but it's not the full tour list. Uh, this list, uh, maybe uh update per month. Uh, I like this is, uh, for example, the shared tool, you know, agents can run safe system, commands we can run and, uh, call. The code, uh, from the, uh, shell environment. I like the HTTP tool, you, uh, you know, agents can call APIs with authentications and, uh, we can use uh uh AWS native tools. Uh, agents can access services like Amazon S3, AWS EC2, and DanaDB, uh, and, uh, others. Like logging and memory tool, uh, you can track what agents think and what they do. So I think the benefit for these tools, um, because we can use this tool directly, we can integrate them into our own system, uh, and we can build them, we can use them, uh, without build everything uh in AWS. So, um, that is why we love it. OK, uh, we talked about the tools. Now, uh, let's see how agents can live up their, uh, ability with MCP. You know, MCP is a very hot topic. Uh, I think whatever in China or globally. So Tesa, back to you. OK, all right, so, uh, MCP server, um, I mean. It's really a good one because they designed the protocol, uh, we use the tools uh for the AI uh troubleshooter, to treat the AI troubleshooter in this case, you can, like I introduced before, if we have no MCP server, we have no tools. that means my AI agent, my troubleshooter just to generate the solution or tips to the end user. So that means the end user uh gets the solution, they need to copy paste my command to their uh environment and try to fix the issue. So you can see here, my AI agent just uh Give the solution, give the guide, but do nothing, right? So it looks like I'm a human, I need to listen to AI agent and but I need to do everything by myself. So then, but if we have the tools or a lot of MCP server or the Qubative server here, uh. In the uh troubleshooter in this case. So therefore, uh, my AI agents not just generated the solution or just to tell the end user, hey, I don't think that your input is enough, so could you give me more login, help me to analyze your issue, right? So at this time. Our AI agents will not just give such answer, they will help user to log in users' human environment and to pull some login here and to analyze the login and to give the, give the commands and this AI agent will use MCP server to come back to customers environment and copy paste its generated command and to see The, the, the issue is fixed or no, right? So, that's why uh we need this AI agent not just to do some the content generation or give me some tips. They will uh use their tips, their solution to help user fix their issues on the production environment. So, I guess, uh, I mean, MCP server is very good. And about the MCP tag part, uh, I guess Betty, you will have more one. OK, thank you, Trista. Yes, uh, about MCP, yes, thread agent also, uh, works smoothly with, uh, MCP, uh, thread agent supports to MCP server access way and both are very simple for developers. Um, first is, uh, uh, local model. It runs the MCP server as a small uh subprocess of STDIO. It's very fast, easy to debug and grade for local uh deployment. Secondly, the remote model, it runs the MCP server of HTTP. This works better in product. where Tor and data live on remote infrastructure. So on this slide, uh, the code sample show us how easy the remote model, uh, is to use. Uh, at the top, uh, we create, uh, MCP client of streamable HTTP. There is no, uh, you can say. There is no uh network uh requirement and uh transport code required. Uh, in the next block we call function of listed tour sync to fetch all tour available on the remote MCP server. The agent doesn't need to know the tour ahead of time. And at the bottom, uh, we pass this tour directly into our reagent. The agent get for access to everything the MCP server provides. So reagent hide all the complexity, uh, you just choose local or remote model and strength agent does the rest. Uh, this flexibility, uh, I think, uh, lets your, uh, start local, scare to remote, and keep the same agent code. OK, uh, now we have some, uh, seen how st agents make MCP integration simple. Uh, I think whether the MCP server run local or remotely. Next, let's look at how, uh, I just use your enterprise knowledge. You know this is. uh important part because I think, uh, good, uh, high quality data makes our, uh, support, uh, much more effective or much more smart. So, uh, to start over to you, I think as uh AWS data hero, you bring a lot of curious here. Yeah, yeah. So, uh, remember our first image about archi architecture, right? Uh, the most of the part that about the rack stuff, uh, it's about your data, about your, um, Knowledge stuff because I found uh when I create the AI agent, uh, the data actually is the number one question because for most of the companies, uh they have no very um good quality of the, the data. For working at the rack system for your AI agent. So generally, um, because actually we have the two types of data here. The first one is like your PDF, your words, your slide stuff, right? Uh, you don't need to update it. Frequently, right? Uh, for someone like the business or uh trading that data, it's like your database, the database or big data system, right? So, um, they will update your database or your table like the Um, like the TPS or QPS 1000 TPS or QPS stuff. So for two tab the data, actually for most of the customers, they need both working for your rack system. So, how do we handle them to make them fitting for your AI agent or for rack system. Uh, here it's a, it's a workflow for most the enterprise data, the static one and the dynamic one. The The MySQR post square or Mongo DBD stuff, right? And then uh we also need to do some like the first review your data but because for some of the business actually they have no clear metadata or data algistration. In their company, so actually you need to kind of the ETL or mandate registration stuff for your AI agent because for example, you don't care about, about it. You think I have a lot of data, just to put everything into your AI agent, it works? Yeah, it works, but the first one, your context window. It's limited, right? The second one, your AI agent will feel confused about the input, the knowledge. It's really like a person. Today you just teaching me the math, the next day you're teaching me the coding, the, the third one, you teach me the like the English and that stuff. So I don't know like how to fix your issue, they feel confused. So that's why we need to pick. Try our best to pick the correct and simple and clean data for our AI agent. So therefore you can see um it's actually a data algration issue here. So if for your company actually you do good about your data stration in a previous era, that's good, but if you didn't do that stuff then you need to combat this issue. Yeah, so, generally, um, uh, we will use the vector DB, you know, that embedding stuff, you have the document PDF, you chunk it and embedding it, put it in your vector DB, do some semantic search, that's enough. Yeah, so for some of the single cases, it's OK. Words is Good, and especially for some of the static data, but um actually for the enterprise AI agents, they will found some of the data, um, they come from the database or the data is scattered, right? They are scattered. So, in order to give the Accurate answer. You need to acquire data from the different storage or from the different places. So therefore we will use the hybrid search, that means um I will use the ve DB to get some data and then I will use the natural language to SQL to query data from database and then maybe I will use natural language to API or to um domain language to get data from some of the data service and the, and now I have 3 parts of the data, right? And I will use a hybrid search like use some of the re-ranker model to merge uh the stuff, right, because we need, we have 3 parts of data. needed to pick which part. So I will use the re-ranker model or use the hybrid search to guide the final ranking, uh, the results and working for the rack, right? So, that's why um if we on the simple cases, uh, you chunk it, embed it, do some semantic search that's, that's OK. But for some, I guess for most of the companies because their data now is in the database, so you need to use some like the NL2 SQL or uh NL2 uh DSL to do some query but actually uh for such cases, I guess um you can do some of the business intelligence BI stuff because for the BI case. Uh, you hope the answer is exactly 100% correct, but actually now at this point NL2 SQL or NL2 DSL cannot guarantee each each of the time or 100% they will give you the correct answer. So, you need to consider, I mean, the trade-off, the correct or you hope to get the answer. So I guess for most of the cases, they can do some trade-off because not each of the cases about the BI case, about number, uh calculate your like the revenue stuff, right? Yeah, so, I mean, because today our topic is, is the common topic, so I cannot give you specific issues, uh uh answers or the suggestions for your case, but I will, I mean, list everything here, you can just pick for your case. Um, yeah, so, uh, when we handle our data to working as a rag and also, uh, please consider. Uh, your like the security or access control stuff. Uh, first one, it's about your static data, uh, because people will think, oh, it's just a PDF I chunk it, embedded, that's it. Actually, no, for most of the PDF it's very complicated, um, because the PDF they includes images, handings, titles, emails, pictures there. So, how to scan this PDF to recognize such uh static data, it's another question. So that's why now we see a lot of the OCR open source framework or VLM vision model uh to handle the OCR stuff to help you to really correctly to recognize your PDF or other like slides or other images, the static data. And for the um dynamic data, um you also need to consider the first one, the security stuff or the PI privacy stuff because uh I can just give an example before we created um AI agent for um like the cities's uh library, right? We launched the, the AI agent for the uh library, but some people just ask about the question about the The politics, right, about that, the stuff, so some topic is, is prohibited there, but they ask about that question. So no way we can make it right on the production, so we just offline it. So now, so we need to consider about the security. Do your best to control uh the access about your AI agent just to give that the The part of the like the rate or view um the privileges for some certain tables or database, that's enough, that's OK. Yeah, so, and uh for some of the cases, I mean, they will. Uh, try to steal your system prompting through your AI agent, so therefore you need to protect that part. I know, uh, currently, uh, a lot of the startup companies, they focus on this part, like I know that Before, uh, have some like the LLM firewall, such the kind of two-hour service to guarantee that your users will not steal the system promptings through your AI and stuff, yeah, so. That's also the key part. Um, yeah, so the next part, uh, yeah, I can give some the, um, the cases for my demo. You remember the first demo is the customer support, the second demo is to treat the troubleshooter. So for the first one it's very simple because the demo I just use the Excel file that includes everything about my vehicles there and do some chunking stuff and to show that demo, but I put some of the image link there, so therefore my AI agent can not just give you a text, I've got to give your location about my images, so that makes the AI agents more interesting, not just the test the stuff output. And the second one, it's a little bit, a little bit complicated here because I need to use the uh requestor's Jira record to get the content and use some of the jargon wrapple because you know uh For example, your AI agent can not understand the evaluation of your like the OKR stuff, right? So you need to first explain some jargons to your AI agent and then the model can use that explanation to answer a question, right? So that's the second knowledge part and the third one is the QA rebel because we actually have a lot of User questions. I know we can dig it because some of the answers from there, right? So that's the third part of the knowledge and then the RAM book, the menu, and sometimes we found that the user's input is not enough, we will get more logins of the user's case, right? So, uh, when you do the workflow to get the data from. Different where, right? Different places and to give the final gradeout. Yeah, so simple one and a complicated one. There it's like the uh spectrum. Yeah. Uh, thank you, Trista. We talked about how agents use, uh, enterprise data with IG. IG keeps answers grounded in real facts, and it helps agents work more, uh, accurately and reliable, but, uh, good data alone is not enough, I think, uh, it. Action agent also contours our work flow and it uh it uh racked up with the real system so we need a way to keep their behavior safe and uh predictable. So this brings us to the next part, making the multi-agent system safe. And uh one of the uh piece of safety is, uh, Gail, sorry. OK Um, on this slide, you can see what guardrails do. Uh, guardrails are safety measure applied to like language model to reduce harmful outputs and can model behavior aligned with human values. They act as a programmable, uh, rule-based layer that sit between the user and the large language model. So, uh, every request goes through the layer and every response returns through the same layer. Um, it checks input, checks the intent and low, and or, uh, redirect anything that, uh, violates your rule. So that will make sure your agents are not only smart and power, but also safe, controlled, and reliable in real production environment. OK, uh, there are a few, um, main, uh, strategies, I think, for applying guardrail. First, uh, just to say now, if I request to break a safety rule or system, stop, stop it immediately. 2nd, 2nd is, uh, do it with a warning. The agent can continue the task, but it has a clear safety note or disclaimer. Uh, also, we can give a safe summary, uh, summarize instead of returning, uh, risky content. Uh, the agent share a short harmless version that still answer the question and still respond. And last, we can offer another options. The agent can rewrite the request or suggest a safer uh alternative that keep the user's intent without breaking policy. OK. Uh, this strategy help, uh, agents stay useful while staying, uh, still, uh, stay safe. OK, so, uh, how do we actually build this guide rails in product, uh, in product environment or in practice? Um, I think the simple type is rule-based guide rails. They work like a filter. Uh, they look for certain words. Uh, phrases or patterns and block or replace anything that breaks the rule. Uh, this approach are fast, easy to maintain, and great for clear no cases. I mean it's like, uh, removing personal data or blocking unsafe commands. Uh, then we have uh metric-based scaris. Uh, this don't rely on fixed keywords. Instead they use signals like, uh, hallucinations, score or other risky, uh, metrics to judge whether our response look unsafe. Uh, this is, uh, this is more flexible or and help us to catch subtle issue that maybe, uh, rule-based method might missed. OK. The next type of guardrail is large language model based guo. These are more I think advanced uh because uh they use another model to check the request before anything happens. We call it uh helper, uh, helper model, yes. The helper model look at user's intent, uh, if it detect malicious. Maintenance, unsafe infrastructure or anything that break business rule, it stops the request before the main agent even see it. This looks like, uh, this works like a semantic safety, uh, filter. So instead of only checking keywords, the helper model understand what the user is actually trying to do. Uh, if the intense is safe, the request to move on the maintain uh large language model and, uh, other tools. If not, the system block the action and return a safe response. Uh, this adds a deeper layer of protection, uh, especially for accomplished prompts where simple rules are not enough. OK, um, now let's put everything together and work through uh Grio workflow. On the uh on on this slide, uh, you see two color paths. The purple path show what happens without Grio. Uh, the users send prompt, the larger language model process it directly and the output goes straight back to the users. It's very simple, but there's no protection at all. Um, and the blue part shows what happened with Gabriel, uh, I did. This, uh, flow has two safety check, uh, checkpoints, you can see. The first one is input guard, uh, sorry. Uh, it checks the incoming, uh, request for things like, uh, personally, uh, identifier, uh, information and off topic prompts or gene break, uh, attacks. Uh, if something looks unsafe, the block it or rewrite it before it reached the model. Then the large uh language model as you were wrong as uh wrong and uh reason and the response. Before the answer, go back to the user, we have output gap. Uh, it's got look for, uh, hallucinations, uh, profanity, uh, competitive monitors, and other risk content, I think. Uh, if needed, it adjust the response to make it safe. So, the workflow become safe input, agent reasoning, and safe output. We can control input and output uh with uh safety uh models. So this is a story of Gabriel. Um, I would like to see, make Multiple agent system safe is not add-on. I think it's a core part of the architecture. It's what allows agents to operate in real production environment with uh trust, consistency and confidence, so. Um, after the safety story, now let's zoom out and ramp up everything we learned today. So, Trista, I know you have built so many real agents in your production. So, um, what's the key takeaways you want everyone here, uh, to live with? Yeah, yeah. So, so that's our last slides. Yeah, so congratulations. You stay here for the last one, yeah, congratulations. So, uh, for the, can you take, takeaways actually um the 1st, 1st 1 that AI agents is not so or, or everything about your model training stuff. So, for most of the people if you before it's not like the Um, natural language or model trainer stuff, you can consider the AI agent because now we need to use AI to solve people's pinpoint. The second one, because AI agent is solved aware, so that ops that's the serum is also applying for AI agent stuff, uh, don't oversee the operations of your AI agent. And third one about your rack stuff, you can see my case, simple one and Complicated one, but I guess for most people and just from small or from some of the simple one, especially for your single agent and multi-agent stuff. First to try the static or workflow or single agent for your case and then about the complicated one. Yeah, uh, security, uh, it's another big topic. We actually didn't show too much about it, but please don't ignore it. It's very important. Yeah, so that's all about today. Thanks guys.