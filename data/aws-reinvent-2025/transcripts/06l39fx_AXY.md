---
video_id: 06l39fx_AXY
video_url: https://www.youtube.com/watch?v=06l39fx_AXY
is_generated: False
is_translatable: True
---

Hello everyone. Uh, welcome to session DAT 325. We'll talk about uh how you can cut costs and operate more efficiently with RDS for SQL Server and Oracle. My name is Mehul Shah. I'm director at AWS for RDS databases, uh, SQL Server, Oracle DB2, and also Oracle database at AWS. Um, before we get started, I just want to get a pulse of the audience. Uh, can I get a raise of hands of folks who already use Amazon RDS? Most of you. OK. And uh how many of you use SQL Server? About half of the audience, more than 50% of the audience. And how many of you use Oracle? OK. A good number. Good. So I think we have the right audience. Um, let's get started. This is our agenda for today. We're gonna start with a short introduction to RDS, um, then we're gonna deep dive into some improvements that we are making into how you can use storage volumes. Um, there's some recent features that we have launched that give you more flexibility in how you can use storage volumes and operate a little bit more efficiently than what you could before. And then we'll talk about some new service features that help you reduce your costs when you're running SQL Server or Oracle on RDS. So relational databases at AWS. When you look at relational databases, Amazon offers Aurora, which offers a Postca SQL compatible edition, uh MySQL compatible edition, and then we have Aurora DSQL, which is our serverless distributed SQL service. You also have Amazon RDS for open source databases. This includes RDS for PostSpace SQL, RDS for MySQL, and RDS for MariaDB. And then you have RDS for commercial database engines, which includes RDS for Oracle, SQL Server, and DB2. Most of our discussion today is going to focus on ideas for commercial database engines, which include SQL Server and Oracle. Now why do we offer RDS for commercial database engines? First, ease of migration. We know that thousands of customers already use Oracle and SQL Server on-premises. When these customers move to the cloud, move to AWS, the easiest migration is to use the same database and run on AWS because you don't have to change your applications. You don't have to go change your schema and write to a new database schema. You don't have to change your stored procedures. It just works as is. So it becomes an easier migration when you take your applications running on premises on SQL Server, Oracle and run it on the cloud and you have the same database, SQL Server or Oracle. Flexible licensing options. So many customers have long term agreements with Microsoft for SQL Server or with Oracle for using Oracle, which includes licensing and support terms. So those customers often use what we call a bring your own license model where you can take your existing agreements, existing support model, and just run it on AWS as is. But then we also offer license included offering, and this is particularly compelling for many customers for a few reasons. First, the license included offering includes the license along with the software and the server usage, everything combined. And you're effectively paying for both the usage of the server as well as licenses, only for the period that you're using it by the hour. So if your needs change over time, so if you need more licenses, less licenses, more usage, less usage, you're just paying for what you actually need versus signing up for a long-term contract. It also becomes particularly interesting because many customers want to over time change to a different database. For example, your applications may change from using SQL Server to using an open source database, or it may change from using a relational store to a non-relational store. When that happens, you're usually changing things over a period of time and you can't always predict when it's going to happen and how it's going to happen. So having a usage-based model allows you to make sure that you're using as much as you need it, and then you can gradually shift over and that's where the license included model becomes very compelling for many, many customers. Third, RDS gives you a managed service for running these engines, um, operations like software patches, software updates, backups, storing backups in a different region for disaster recovery. All of those operations are automated for you. For example, if you want to do software updates, RDS offers the latest updates. You simply specify your maintenance window, and RDS applies the updates in a maintenance window. You can choose when you want to apply updates, but you can also tell RDS just apply the updates automatically. In fact, we recently released a new feature which allows you to stage your upgrades. So many of you, when you have a test environment, a dev environment, and a production environment, you can just tag your different instances and say, this is my test instance, this is my production instance. When you do that. The software updates are automatically applied to your test instances first and then after a few weeks they get applied to your production instance. What it does is it allows you to give you some time to test it, make sure you don't get surprised because the update showed up in a production instance and suddenly the performance of your application changed or something like that, so you get some time. So all of those are automated for you and you don't have to do any manual work around that. So the managed service gives you a bunch of benefits that frees up your time to do some more application specific stuff. And lastly, you have a lot of options to get high availability. So RDS offers a multi AC configuration and which allows you to. Recover much more easily when you have, let's say a hardware failure or a software failure or a power failure and recover quickly and fail over to your standby instance. These options are configurable, so you simply specify what you want. You can say I want a highly available service in a multi AZ configuration. You can specify you want a red replica, and the installations are automatically handled for you. Let's look into a little bit into what a typical multi AZ configuration looks like. So you have an application. The application talks to an RDS instant endpoint. The instance standpoint talks to an instance, typically your primary instance in an availability zone. Your database instance is backed by an EBS volume, a storage volume, and when you specify you want a multi AZ configuration, RDS automatically sets up a standby instance for you in a different availability zone which protects you against failures that may happen in your instance. Your standby instance has its own storage volume in EBS and then. The data is synchronously replicated from your primary instance to your secondary instance, to your standby instance. It's synchronous, which means as your transactions are written, it's written into both primary and standby before the transactions get committed. Now we work with thousands of customers over the years, and we found a few areas where we could make the service better for our customers. Let me give you some examples. Um, RDS lets you choose the storage size you want, but the size of the volume can go up to 64 terabytes. Now we saw a few customers who have very, very large databases, and they take up more than 64 terabytes. It doesn't happen frequently, but sometimes it happens. Even if it doesn't happen, if you're reaching 40, 50 terabytes, you want to know that the service continues to work and you have a path to scale forward in case your storage sizes grow over time. The ability to scale up and down. In many times you have scenarios where you want a large amount of storage for a short period of time. You may be running some data processing jobs every month, once a month, or you may have a peak season, um, in a month, in a month, in a year where the storage volume grows, or maybe you're restoring a backup in Oracle, so you want to copy your backup to a volume. Restore from the backup, delete the backup file, and then bring your storage size down. So there is a need for many scenarios to be able to increase storage, reduce storage over time. Um, IO2 and GP 3. So EBS offers different volume types. You can choose IO2 storage for your databases, or you can use GP 3 storage for your databases. We recommend IO2 for critical workloads. IO2 offers our highest level of availability, um, durability, and consistent low latency performance, which you would expect in a production, highly transaction workload. We also offer GPT or our general purpose EBS volumes. GP3 volumes tend to be more cost effective. Uh, and in many cases, a GP3 volume is sufficient for running a production workload. When you have a database where a subset of data requires a high performance, high transaction, high durability, low latency all the time, and then there's some data which is not used frequently, it's infrequently accessed. Maybe it's old data, but every now and then it's accessed as part of the same database. Ideally you would want to be able to choose like I want IO2 for this data and I want GP 3 for this data so that you can more efficiently cost optimize and use the right storage volume, the right sets of data, but you have to choose one. So in most cases you end up choosing IO 2 even though you may not need IO 2 for the entire storage that you have for your database. Lastly, when we replicate data from your primary to your standby instance, we have a replication channel. The replication channel has a throughput of about 625 MB per second. When you have large amounts of data that you're writing in a short period of time. Uh, on occasions, you may run into limitations of this throughput in the channel of replication, and when that happens, your transaction rates can go down. So we wanted to look at ways that we could improve this as well. To address this, we added something called the ability to have additional storage volumes. How does this work? This picture shows the same environment, your multi AC configuration with your application instance endpoint, primary, and a standby instance, each backed by an EBS volume. But what you can now do is to have an additional volume. It's a different mount point that you can add to the same instance. And you can add up to 3 additional volumes in addition to your primary volume. What this does is that you now have the ability to have 4 times of storage. So you can now have up to 256 terabytes of storage for your database instances. You also have the ability to add and remove storage volumes over a period of time, so it doesn't mean that when you start it, you need to have all the volumes. So as your data grows, you can add volumes. If you don't need the storage, you can remove a volume, and you can do this without having any application downtime. So this gives you more flexibility to be able to adjust storage based on your needs. And even though the example here shows Oracle, the feature is available for both RDS Oracle and for RDS SQL Server. You can use it the same way in both the database engines. Let's see how we can use it. So in this case, I have a database instance that I just created. The primary instance is using Oracle, it has a single volume. If I want to add more storage. I have a command I call a modified DB instance command. I specify my database instance. In this case it's called Minstance. I specify the volume name that I want to use and refer to my volume mount point. I call it RDSDB data 2, and a specific property like the storage type IO2, and the amount of storage I need and the amount of IOPs I need for my additional volume. When I do that, I get a 2nd volume, and I can reference that volume using the name that I specified. In this case, I'm using RDSTP data too. Now that I've added a volume, you want to be able to use the volume from your database. The easiest way to do it if you're using Oracle is to update the default location that Oracle uses to create new data files. I can do that easily by just updating a parameter, if I'm on RDS. So there's a parameter called DB Create file test that tells you what the default destination for new storage table spaces. And in this case, the default happens to be the primary volume RDSDB data DB. I use an alter session command to change the default location and I change it to RDSDB2DB. And then after I change it, I want to confirm that the change is applied, so I call a show parameter again and as you can see, the default location is now changed to RDSDP.2. Once I do that, if I create new table space files, they get automatically created in my additional volume. So if you're growing storage over time, this may be an easy way that you can start having new table spaces go into your new volume. But there are some more interesting things that you can do with additional storage volumes. Let's say that you want to move a table space from your primary volume to your additional volume that you just added. Maybe that table space has been growing or you expect it to grow quite large for a short period of time. In that case, I just want to move the existing table space from my primary volume to my additional volume that I just created. And maybe I want to allow it to grow for some period of time. It grows, it grows, and maybe after a few weeks, I don't need that storage anymore. The data size goes down, and maybe after a few weeks, I want to bring it back to my primary volume. And then I want to delete my additional volume because you don't want to pay for storage that you're not using. So what this allows you to do is to move it to an additional volume, use it for a short period of time, bring it back to your primary volume, remove the additional volume. How would you do that? To move my table space to my additional volume, I call a select command. In this case, my table space is called my table space. I call the command to get the properties of the table space. I see that the table space has a file ID 6, and the table space resides with my primary volume, RDSDB data, and I have the file name for the table space. Um I then call a command, move data file, and I say that I want to move the data file with file ID 6 to my additional volume called RDSDP data 2. After I execute the command, I call a select command again to say, let me see the properties of the table space, and as you can see, the file for the table space has been moved to my new storage volume that I just added, RDSDB data 2. Now if you can do this without any application downtime, this happens in the background. Let's say I use the table space for a while, it grows, it changes over time, and now it's pretty small again, and I want to bring it back to my primary volume and delete my additional volume. To do that, I want to first clear the additional volume. So I start with, let me look at all table space files which were created in my additional volume. So I call a select command and say show me all the table space files in my additional volume. I again see just one file with file ID 6. I then call and execute command again, move data file to move it back to my primary volume. And then I verify it again to say, is the file name moved to my primary volume. I see it's moved back to RDSDP data, which is my primary volume. And then I call a command to say, is there any more table space files remaining in my additional volume, and I see that there is no more table space files. The volume has been cleaned up. After the volume has been cleaned up, I can now remove the volume. To do that, I delete the storage volume by calling a command modify DB instance again. And I mark it to say set for delete equals true. When I do that, the volume is marked for deletion. And you no longer charge for the volume that you used before. Now, in case there are files being used when you call the command to remove the volume, uh, you will get an error, and so it protects you from accidentally deleting volumes which are actually being used. So as long as you make sure that all the files have been moved away from the volume, you can delete the volume and stop incurring costs for that additional volume. Now there are some more fun things that the volumes can give you. You can now combine IO2 and GP 3 volumes. So in many cases, for example, if you have some old data which is infrequently used, you can move the table space files for those data, data, data tables into your additional volume by creating a GP 3 volume. So now you can mix and match your volumes, and you can mix and match volumes types anyhow you want when you're using RDS. We usually recommend if you're mixing and matching, we usually recommend having IO2 volume for your primary volume. Why is that? When, when you write to a database, databases write to a write-ahead log first. Your write-ahead logs are always in your primary volume. And that's why if you're using a combination of IO2 and GP 3, we recommend that you use IO2 volume for a primary volumes and GP 3 for your additional volumes. You also get benefits in a multi-ey replication scenario. As I mentioned, when you write your transactions, your data gets replicated to two zones before it gets committed. And a single channel of replication in a single volume gives you 625 MB per second. But when you add a second volume, you have a second channel of replication for replicating the second volume. Third volume has its own channel. Fourth volume has its own channel. So now you effectively get more throughput. So if you're writing large amounts of data in a short period of time in certain tables or in case of SQL Server, when you have multiple databases in the same instance, and some databases write a lot of data, it may be beneficial for you to put those databases or those table space files in an additional volume which gets its own dedicated channel to replicate data in a multi AC configuration. So in summary, when you use additional storage volumes, you can use it for multiple benefits. You can use it to get more storage. The feature is available for both SQL Server and for Oracle. You have the ability to add and remove volumes without having any downtime. You can use the additional volume for temporary storage for short term needs. Even in some cases in SQL Server when you create temp files, many applications and workflows and jobs create temp files in SQL Server. You can use additional volumes when you're running those jobs that require a large amount of storage in a temp file while the jobs are running. After the jobs finished running, you can remove the additional storage volumes. You can combine IO2 and GP3 volumes. And when you use RDS and you're setting up a multi- AZ configuration, whenever you add or remove volumes, your changes are automatically replicated in both your primary and the standby instance by RDS behind the covers, so you don't have to do any management tasks or any operational tasks to make sure things are being done consistently. Now, let's talk about some new service features that can help you reduce your costs. Um, SQL Server Developer Edition. So Microsoft offers SQL Server Developer Edition that's now fully supported in Amazon RDS. What that means is that you can now use developer edition of SQL Server with all the features that you normally use with Amazon RDS. Now SQL Server developer Edition is a full-featured version of SQL Server. It has all the features that are available in SQL Server Enterprise, and it is free from licensing costs because it is intended for non-production usage and dev and test usage. When we see most development environments, most developers have a dev environment where they build new applications. You often have a test environment or a pre-production environment where you bring in all your applications and do performance testing, application testing, and then you have production instance where you're running your production workloads. In this case, you can now start to switch to using developer edition for all your development and test environments and test instances and use the instant standard or enterprise only for your production instances. What happens if you were to do that? Let's look at the costs when you start using different editions. Now, this picture just shows you examples of different editions and the costs that you incur per hour when you use different editions of SQL Server. In this case, I just take two instance types, M6 XL and R6 XL, and these are the costs of different editions. And these are just public pricing in the Virginia region, but if you're using it in other regions, pricing is similar and the variations are similar. If I switch from standard edition to developer edition for M6XL instance, my price changes from 0.977 per hour to 0.60 per hour. If you switch from enterprise edition to developer edition, let's say for your pre-production testing, your price changes from 2.501 per hour to 0.74 per hour. So simply by switching all your devon test environments to use developer edition, you're effectively reducing your cost by 74% for all your dev and test environments. And all you have to do is to just start using developer edition for these environments. How do you use them? It's pretty easy. You first download the IOC image for SQL Server edition from the Microsoft website. This is required for licensing compliance. You are informing us that you are using SQL Server edition, download it from the website, and this is the instance you want to use for dev and test purposes and non-production purposes. After you download the ISO image, just upload it to an S3 packet. You can upload it to any S3 bucket you want. In this case, I just use S3CP to upload it, and I upload it to a bucket called My Test bucket, but you can upload it to any bucket you prefer. Once you upload your ISO image, you inform us and you create what we call an RDS custom engine version. Why do we need that? Well, once you have a developer, uh, edition image, you want to be able to use the use the developer edition for multiple dev and test environments, multiple instances. So you build what we call a custom image once, which is a develop edition image based on the ISO image that you give us, and then you can use it for all your instances for dev and test. To do that, use a simple RDS command called create DB engine version. You specify the packet name where you uploaded your ISO image. In this case, it was my test packet. You specify the file name that you uploaded for the ISO image. And then you name your engine version. These are names that you can name so that you can easily remember what is the engine version you're using. So for example, if you're using different versions of SQL Server, we recommend putting the name of the version of SQL Server that you're using so that you can easily remember when you're creating instances. Once you do the custom engine version, you can start creating instances using double edition. To do that, use the same create DB instance command from RDS. It's the same command that you use for creating production instances or development instances. The only variation is you specify the custom engine version that you just created. I created the engine version called My RDS SQL Server 22 Dev. In the previous step, I specified the same engine version. And then I specify my instance name and instance properties. For example, which region do I want to create the instance in, um, and what the configuration of the instance? Is it a single easy instance, a multi-AZ configuration? You can specify all those configurations. That's it. Once you do that. Uh, you now have an RDS instance for SQL Server. It's using SQL Server developer edition, and now it's all the features that are available in RDS are now available to use for your development and test environments. SQL Server web edition. This is also something that Microsoft offers. The web edition is designed for web hosting providers. It's optimized for web hosting. So if you have websites, if you have web services, if you have ASP pages, if you have internal web applications, and if you're using the database to power those web applications, SQL Server web edition is designed for that. It also has lower licensing charges compared to SQL Server Standard Edition or SQL Server Enterprise edition. Now when you have web applications and websites, you want high availability for your website, right? You want to make sure that things are not going down, your web service is not going down, and so you wanna make sure that you have high availability and you can recover from failures in case there is a hardware failure or a power failure. So we looked at high availability features in different SQL Servery editions, and SQL Server uses something called always on availability for high availability. But when we looked at the availability of the feature, it's available for enterprise edition. It's available for standard edition, but it's not available for developer edition. And so we asked ourselves, how can we fix this? Um, we're now launching support in Amazon RDS for high availability for SQL Server web edition. How do we do this? We do it using synchronous block level replication in a multi AZ configuration, very similar to what you saw in the Oracle example earlier. You have an application that talks to an RDS instance endpoint. The instance endpoint talks to a SQL Server primary instance which is backed by an EBS volume, but then we do block level replication from the EBS storage in your primary instance to the EBS storage for your standby instance that happens to be in the 2nd, 2nd availability zone. We also make sure that your licensing is only for one instance at a time, most of the time for your usage, because you're only using one instance, which is your primary instance, and the data is just simply being replicated to your standby instance, not actually being used, so you're not using SQL server in the standby instance. Now, RDS also automatically detects failures. So we have your RDS instant standpoint that routes requests to your primary instance. In case we detect that there's a failure in your primary instance, we automatically detect the failure. We stopped the block level replication that was going from your primary to your standby. We read out requests to your standby instances. In this case, now your standby instance becomes your new primary instance and then we replicate the other way around from your standby or your new primary into the stand previous primary instance and now your previous primary instance now becomes a standby instance. So all of this happens behind the covers, the detection, the switchover, the transfer, creation of a new standby RDS is doing all of that behind the covers so that you have high availability. So what's the benefit? The benefit now is that many applications, web applications that you were previously running with SQL Serveran edition can now start running on web edition. What's the benefit? Let's look at the prices, and again these are prices with public prices for license included in the US Easter Virginia region, but similar prices are applicable for all other regions. In this case, these are prices for a multi AC configuration. So I take two instances, M6 Xcel and R6 XL. If I switch from standard edition to web edition, my price goes down from 2.45 per hour to 1.01 per hour. For R6, if I switch, my price goes from 3.04 per hour to 1.69 per hour. So simply by switching from standard edition to web edition for all your web applications or ESP pages or web services, you can again reduce your cost by up to 58%. For running RDS SQL server. If you only use web edition and you're using it in a single easy configuration, you can now use multi-E configuration for high variability, and doing that is pretty simple. If you want to do it from the console, there's an option called modify DB instance. There there's an attribute called multi-EZ deployment. You simply change the value of the attribute and say, yes, I want a multi easy deployment. And when you apply the change, RDS will create a standby instance for you behind the covers, and that's it. Your applications can keep running. There is no change required in your application. VCPU-based licensing charges. This is also something very interesting. When you use MicroSQL Server, your charging for licenses is based on the number of VCPUs or virtual CPUs that you use in an instance. Now I mean a typical intel. Instance, for each physical CPU core, you have 2 virtual or 2 logical CPUs. Why is that? For a technology called SMT or simultaneous multi-threading. What SFT does is that it allows you to run two parallel threads on each physical CPU core. Now you don't get double the performance because the physical CPU core is just 2. In this example, I just have 2 physical cores, so I don't get the performance of 4 CPUs. I get a performance boost, but it's not 2x the performance for every core. However, the licensing charges that you pay is 2X. So you get a small performance boost, but you're paying 2 weeks licensing charge for each physical CPU code. So we ask ourselves, how can we take advantage of this and become more cost performant. If you, what it turns out is you can turn off SMT. In an instance. When you turn off SMT in the instance, you now have one logical CPU for each physical CPU. But your licensing charges are now for half the number of VCPUs that you were running before. So Let's take some examples. Many, many, many database workloads tend to be memory bound or IO bound, and not CPU bound. In this example, I'm using metrics for a workload on an R7 8 XL machine. As you can see, the available free memory on this workload is about 25%. So it's using about 75% of memory available on the instant, which seemed like good utilization for the machine. Then I look at CPU realization. On the same machine, CPUization is only about 10%. So this is what it would look like if your workload is a memory-bound workload, not a CPU-bound workload. So what happens in this kind of a workload if I turn off SMT? So I tried turning it off. So in this case, when SMT is turned on, my utilization was about 10%, and I was using 32 VCPUs and I was incurring licensing charges for 32 VCPUs. I turn off SMT Now I have 16 VCPUs, same number of physical CPUs. All physical CPUs are available and being used. And my performance is still under 20%. So CPU is still underutilized. But what happened here is my licensing charges switched from licensing for 32 VCPUs to licensing for 16 VCPUs. So what we did in RDS is to take advantage of this into a feature called optimized CPU. Now what we do is for 7 generation instances and for all future instances going forward, we're going to optimize the assembly settings for the instances depending on what the size looks like, what the performance looks like, so that you get better cost performance out of the box in those instances. So, as a result of that, If you simply switch from a previous 6th generation instance to a 7th generation instance, you get a lower price. You get a lower price because it is an optimized CPU setting. So if I was using SQL Server Enterprise with an R62 XL instance, and I simply upgrade to an R72 XL instance with the same number of physical CPU cores, my price goes down from 7.202 per hour to 3.868 per hour. If I'm doing SQL Server Standard, my price goes from 6.080 per hour to 2.848 per hour. This was just like R6 example. If I take an M6 instance and upgrade that to M7, again, I'm taking an M62 XL and upgrading to M72 XL. I have the same number of physical CPU cores, and the price goes from Enterprise from 6.657 to 3.295. For standard goes from 5.096 to 2.275. So as you can see, You get up to a 55% lower cost simply by doing an upgrade to a newer generation instance. You don't change your application. You have the same amount of memory, same amount of physical CPUs. You're simply doing an instance upgrade, and now we have a lower price. This is what you get simply by upgrading, but you can do more. You can fine tune performance even more. In the previous example, you saw that even if I optimized and turned off SMT. I was still utilizing CPU by about 20%, which means that 80% of CPU is still underutilized. In scenarios like those, you can fine tune the CPU settings in the feature called optimize CPU. In this case, it allows you to configure the number of active CPUs, and you can do this by turning on or turning off physical cores in the machine. So in this case, I have an instance, the default number of physical cores is 8. It is using one thread for each physical core, so SMT is turned off, but you can change the value of 8 to a lower value, 7 or 6, to what your application requires. And when you do that. The number of VCPU reduces, and remember, a lower VCPU count equals a lower software licensing charge for you. So you can get a large performance boost by upgrading. And then if you want to fine tune further, you can configure your settings for optimized CPU and fine tune for your applications to get even further cost benefits. For RDS Oracle. We have something called support for easy to bare metal instances. What are easy to bare metal instances? An easy to bare metal instance is an instance that's backed by a full physical server. It bypasses the hypervisor, so there is no hypervisor. Your application software talks directly to the physical hardware because there is no hypervisor. Now, when you have a large instance on a using for a large database that's using a large virtual memory instance, you can switch over to using a bare metal instance which offers the same amount of CPU and the same amount of memory and bypasses the hypervisor. In this case, in this example, I have an M724 Xcel instance with 96 VCPU 384 GB memory. And I can switch over to using a metal instance which offers the same amount of VCPU, same amount of membrane. We have similar metal instances available for R724 XL, different CPU and memory profile, but consistent between a virtual machine and a physical machine. Same for X2 IEDN, a VM, a large VM, and a, and a bare metal instance will have the same amount of memory, same amount of CPU. And all RDS features, all Oracle features work exactly as they were in the virtual instance. There is no change to the application. You get a better performance. But when you switch over from a large virtual machine to a bare metal instance, you get a 25% cost benefit by switching over. So when you have large Oracle databases running on a large VM. In most cases, you will have a cost benefit by switching over to a bare metal instance for the same application performance and a better cost. So in summary, we talked about how RDS helps you and gives you a managed service for running SQL Server and Oracle. We talked about how you can use additional storage volumes to give you more flexibility, to give you more cost efficiency. And we talked about how you can use the RDS, new RDS features to reduce your costs. We talked about how you can use the RDS SQL developer edition for all your dev and test environments. We talked about how you can use RDS SQL Server web edition for your web applications. In many cases, you can downgrade from using SQL Server Standard edition to SQL Server web edition, get the same high availability and lower your costs. We talked about how we can simply upgrade to 7 generation instances for M instances, R instances, other instance types, and get a lower cost out of the box because of optimized CPU. And then if you want to further reduce cost, you can fine tune optimize CPU settings. And then finally we talked about how you can use bare metal instances if you're using RDS Oracle compared to a large VM to reduce your cost by 25% or more. Um, that concludes my talk, uh, but there's still some time to get some swag. Um, so if you go to the Venetian and you go to the expo hall of the Venetian, you can go to the databases booth and you can tell them about the one unique thing you learned from the session. So you can tell them that you learned about how you can upgrade to newer instances to reduce cost. You can tell them how you can use metal instances to upgrade your cost, and you can get your swag. Thank you.