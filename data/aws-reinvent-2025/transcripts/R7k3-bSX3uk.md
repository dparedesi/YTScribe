---
video_id: R7k3-bSX3uk
video_url: https://www.youtube.com/watch?v=R7k3-bSX3uk
is_generated: False
is_translatable: True
---

Morning everyone, and I hope everyone's having a great conference so far. My name is Brad Rumph, and I'm the field CTO at Times. You know, it's a bit crazy to think that I've been in this space and working with different model-driven tools, iPads, API gateways, AIML, and over the last 3 years, that for the last 25, for the last 3 really deep into all things Gen AI, gentech AI, and kind of where we find ourselves with agents today. You know, it's been quite a journey, you know, over this time, and now we're working with systems and platforms that are architected radically different, right? You know, RAG, which is almost a thing of the past, you know, we've got MCP and model context protocol, and even a lot of other protocols that I'm, you know, trying to keep up with and the agent to agent protocol, and even the ACP protocol, which is now being merged into A2A. So today we're gonna cut through all the noise and what we're really gonna focus on is how IT can strategically govern AI driven workflows. And we're gonna explore how to blend uh different types of workflows from fixed deterministic workflows to highly dynamic agentic ones. And we're also gonna touch on kind of where human judgment uh is added and, and where that matters the most. So our focus is gonna be on infrastructure management, uh, using AWS for your infrastructure, and then leveraging Tines for your AI orchestration, and how you can securely, um, but scale, uh, without losing control. So we all know that AI is moving incredibly fast. And IT is being asked to do more than ever. They are doing things in terms of having to scale systems, managing compliance, and now integrating AI into the mix. And so the opportunity, it's huge. But so is the complexity, and how do you manage all these things? So the challenge for IT isn't whether to use AI. About how to deploy it safely, strategically, cost efficiently, in a way that's fully auditable. So gentic workflows, which we define as autonomous systems that are acting across, you know, various different tools, really can unlock faster, smarter decision making and while keeping IT in control. So 86% of IT leaders believe orchestration is critical to scaling AI and this isn't theoretical. Uh, we worked with Forrester, uh, we talked to over 400. Uh, folks in the C-suite, SVPs, um, directors of engineering, all different levels, engineering leaders, and really kind of came up with a bunch of stats, and this was one that really kind of jumped off the page. And so what does a modern IT environment look like? Well, modern IT environments today are defined by 3 core pillars. And these all create a very dynamic ecosystem of complexity, but also opportunity. If we look at the left over here, and I think they gave me a laser, if we look at infrastructure, this is your digital fabric, right? This is all of your systems, your data, your APIs, your tools that you wanna connect to. You know, from AWS to other specialized SAS platforms, or maybe you're a hybrid cloud environment, maybe you're running some things on-prem. And we see that a lot with our customers. And you know, this layer generates millions of different signals and alerts and events every day. Well, ts, we connect to every single one of those. And we can make those events and transform these very raw, high volume types of alarms and events into highly orchestrated audible actions. If we move over to the right, and we look at intelligence. This is what we deem is the cognitive layer. And with the rise of AI, co-pilots, autonomous agents, you know, these systems can reason and act, but they really need to have some boundaries to operate safely. And so we're Ty's here is we are the definitive control plane. And we ensure that every intelligent action is governed, explainable, and inherently safe. If we shift down to the bottom, we look at people, we view this kind of layer as this and pillar as the strategic operator. And here, these are the decision makers, you know, these are the folks who are dealing with strategic priorities, having to make this critical, you know, manage critical exceptions, and really that hold the final accountability. With Tines we embed human judgment into your workflows, and we allow humans to review, approve and intervene, uh, where it makes sense to ensure that the most critical decisions are always informed and timely. So at the intersection and what you see in the middle is Tines, and you know, we're an intelligent workflow platform and we keep IT operations secure, intelligent, and aligned with the business goals. And this is all wrapped again in a layer of control. So if we kind of look at the evolution of workflows, you know, we all rely on highly deterministic workflows. You know, these are, you know, fixed logic. They're predictable results. And these are things for like tasks for like provisioning or deprovisioning, for example. And, you know, but what happens when we look at the context and, and context shifts, or you have to make decisions that are depend on nuance, right? Or type of judgment, that's really where agentic workflows can shine. Interpreting, reasoning, and adapting. And the goal isn't to really replace one with the other, replacing deterministic with agentic. Um, we really think that it's, you know, kind of a combination of all of these. And so I'd like to introduce kind of this concept of. AI agents in Ts. And the definition and requirements can vary in terms of what agents looks like. I mean, you can go to every single booth here and hear, you know, somebody talking about what agents have, what they do. And, and the way that we view it, um, is very much like our workflows that you can create in times. And, you know, we believe that these workflows should belong to the people that own them, and, and those people should be the ones that, you know, create them. And so we're not gonna force our own definition of what an AI agent looks like. We're gonna give you the tools to build your own agents. And so, we know that agents should be part of any workflow process. And there's a massive degree of orchestration that has to happen, especially when you roll these things out company-wide. And when you do that, prescribed approaches, they're just not going to work at scale. But the ability to tailor these agents to the individual business needs will. So there's a lot of different examples of kind of what this looks like, and we offer um pre-built stories out of the box. You can look at those as accelerators, as well as pre-built templates and API integrations. And we allow our customers to take those, tailor their workflows to their needs, and we really provide the same type of ability with building your own agents. Take your standard operating procedures, take your policies, and really focus on building the prompts that differentiate your business from your competitors. And so, you know, we really encourage, you know, and work with our customers to kind of help them through that process. So the core idea is that you can scale execution, uh, without sacrificing any of the oversight. So how do you decide uh what type of, of workflow you're gonna use, right, deterministic or agentic? Well, if risk tolerance, right, if it has to be critical, perfect every time, highly predictable, then you should stick to deterministic. If flexibility, and if the outcomes can vary, then Agentic may offer some speed and adaptability, and really kind of give you that flexibility that you need within your process. So within Tines, we blend both. Uh, you can script the rules, you can layer in reasoning, and you can also insert human checkpoints when and where they're necessary. So, no automation is complete, uh, without human judgment. And we often say humans can handle kind of the gray areas, priorities and exceptions. And we believe that human in the loop, it's not a fail-sy fit, but it's a deliberate design choice. You know, it's something that we all know, hey, somebody should really take a look at something, right? We shouldn't, it really deserves, there are those nuances or maybe the context needs, you know, a human to review it. And so you can choose what runs automatically, uh, what needs review. And so we offer a couple of different flavors of agents within Ts. So chat-based where a human can be in the loop and interact with that, uh, or it can run completely task-based or autonomously. And so, you know, I think, um, here we're gonna kind of tee up, um, kind of a sample use case. Um, I'm gonna show you a story that uh we pulled from our library in Tys. Um, and then we configured it to basically, we're gonna look at some alarms, right, that are gonna be taking place, uh, that are monitoring and, and configured against some of our EC2 instances for, uh, our leading FinTech application, right? And we're really going to focus on, hey, when our CPUs are trending or running hot, uh, where there's really high CPU utilization. And, you know, if, if, if it, if The, the usage and the utilization is normal and, and we're looking at these patterns. Um, you know, we'll make, you know, certain decisions of maybe just to run, you know, a flow that runs autonomously. But if it's unusual or abnormal, and, you know, something doesn't look right, maybe we're running over a certain, you know, CPU uh percentage or threshold, uh, let's say 96%, well, then we might want a human in the loop. We might want to route, uh, a notification to the engineer on call in Slack, right? And have them look at it and decide whether or not they want to approve or disapprove a particular request to upsize or downsize a particular instance. So we look at this as predictive availability and deterministic workflows can handle, you know, routine, you know, types of tasks, um, while humans step in only when something looks off. So we believe that workflows are evolving, and the future is really a thoughtful combination of human-led, deterministic, and agentic approaches. So we don't put you in one box or the other. Uh, we give you the, the full autonomy to choose, um, what makes sense so you can blend all three together within a single workflow or automation. And we believe that intelligent workflows are truly the key to unlocking AI's true potential. So before we hop into this story that I mentioned, and again a story is a workflow and Tyne speak, um, it's worthwhile to note that Tines builds all our AI features with trust front and center. Uh, all our AI runs stateless, private, in region, it's tenant scope, there's no networking, training, storage, or logging of any of your data. And you can use our Tines hosted model. We partner with Anthropic, um, we run on top of AWS Bedrock, or you can bring your own models from OpenAI or Google Gemini, Mistral, Llama. So, we give you, um, a lot of options, uh, but again, out of the box, um, we, we provide anthropic models under the hood. So, your fearless leader, Gavin Belson, he's uh becoming incredibly worried lately that uh Pied Piper is figuring out how to use intelligent workflows and AI agents to really scale and manage their infrastructure, much more efficiently than Huli's. And so he's tasked his engineering team and SRE teams to look into how AI agents can be inserted into workflows and play a much bigger role in helping to manage and maintain Hooli's infrastructure. So what you're gonna see is intelligent workflow automation and orchestration with the human in the loop, AI agents, and cases within times. So we're gonna start off by looking at our Hooley Prod1 instance an EC2. We can see that it's running. Instance type is a T2 large. We're gonna pop over into Tynes. This is a Tynes story, right? So, at the top, we're looking for, you know, alarms that we're getting from AWS Cloudwatch. And what we have is a couple of different triggers. Basically conditionals, go this way or that way, where on the left-hand side, if CPU utilization is 90%, is greater than 90%, but less than 96, we're gonna go down that path. Or if it's greater than 96%, we're gonna go down the path on the right-hand side over here. If we go down the right, we're gonna create a case. We're gonna send it for approval in Slack. If it's approved, we're gonna update the case, and we're gonna update the instant size by upsizing or downsizing it in EC2. And up here you can see that event just came in from Cloud Watch. So an alarm, we get this alarm. We see that in that alarm, when we look at it, it's greater than 96% CPU utilization. We're gonna create a case in Tines. So we're using an AI agent to do that. We have some system instructions. We have a very simple prompt that, hey, all we want to do is create a case in Tines, and we give it some metadata. When I come over and I look at how, what the agent is actually doing, we can look and see exactly the decisions that it's making at runtime. So we can see where it's created a case, it's adding all the metadata for that particular EC2 instance. And when we pop back over into the story, we can see that the case update's been completed, and we've now progressed to sending an approval to the engineer on call in Slack. He can either choose to approve or not approve this request. So we're gonna pop over to Slack. You can see we've got this, you know, channel set up, notification came in, we have an abnormal EC2 instance, over 96% instance name, instance ID, and we have a link to the case details that our AI agent created where you can get additional details. Ask the engineer if you want to approve, he clicks yes. Come back into the story, you can now see that we've progressed here to, hey, determine what the instance size should be and update that particular. Instance accordingly. So, again, we can look at all the events that are flowing through these stories. Um, again, another very simple prompt in terms of what we're instructing, um, the agent to do. Here I was lazy and actually hardcoded the instance ID, but earlier I pulled it in through some metadata. We can look here and see what the instance details are. We can see that it's currently a type T2 large, as we saw in the very beginning of the presentation. What VPC, what subnets. And here we can get the scaling, decision and implementation that the agent, based on our prompt is looking at. Here we get a summary of the actions taken. And you can see that the agent has made the decision to upsize the particular instance from a T2 large to a T2 2 X large. We come back to the story, we're now gonna update the Tyne's case. Again, we can see exactly what's happening, um, while this is running. We scroll down to the bottom, we can see that the agent's thinking. It's gonna give a case update summary. It says what its resolution information is, what the root cause was of why it made the decision that it did. And I think it's very important to note that all of these events, we store them. So you can retrieve them at any given time, hence the audibility capabilities and the governance that we provide within the platform. This case has been done. It's added some tags automatically. Um, the agent, you know, came up with these just based on, uh, what the events look like. Here you can kind of see just kind of a recap. Um, of that particular case, you know, high, high CPU utilization was detected. You know, here's what the previous state was, the configuration, here's the resolution and the recommendations that were made for the upgrade. We'll go back over to EC2, we'll look at our Hooley Prod one instance, and we can see that it's now running and it's been upgraded to a T2 extra large. So what did you just see? What you just saw is how you can seamlessly build deterministic energetic workflows with human in the loop and human oversight added in. Showed you how easy it was to configure an AI agent, uh, within Tines. I think it took me, I don't know, literally a couple of minutes to write the prompt. It needed some tweaking, uh, but we integrated directly with Amazon's Clai, um, to do all the upsizing that you saw. And then in terms of cases, you know, we have really robust case management capabilities within the Tines platform, and that really enables all those on-call engineers or anybody within the organization to collaborate on that particular case, see exactly what happened, right? And with very little instructions within the prompt, you know, we got a lot of detail, auto populated automatically within that case in Ts. So, with Tines acting as the intelligent workflow platform, even Gilfoyle and Dinesh can agree that you don't need to be an expert in Java, Python, or scripting for that matter, to eliminate muck work within your organization. And with Tynes, Gilfoyle knows it's time to truly move on from Anton and make the move to AWS. So this isn't about launching, again, a single AI agent, it's about governing every workflow from end to end. And IT shifts from being a gatekeeper to an orchestrator, secure, intelligent, execution at scale. And so with AWS and Tynes. And your policies, your SOPs, and the prompts that you create, you can gain speed without losing control. And AWS provides the reliability where Tines really provides the control. Your policies and prompts define how it all comes together in the end. So I'm gonna leave you with this question, and I want you to think about. From an infrastructure perspective, you know, what's one process or more, one or more processes that you would leave to run completely ungoverned and completely autonomously? And and what are some processes that you would actually, you know, deem a human should be in the loop to provide that oversight? And that's really where orchestration meets opportunity. So we say the best way to understand Ts is to see tines. So I wanna encourage everyone to come by booth, 1849. Be happy to carry the conversation on or answer any questions that you have. Appreciate you all coming out and I hope you enjoy the rest of the conference. Thank you.