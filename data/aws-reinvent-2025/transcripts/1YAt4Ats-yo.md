---
video_id: 1YAt4Ats-yo
video_url: https://www.youtube.com/watch?v=1YAt4Ats-yo
is_generated: False
is_translatable: True
---

Hello everyone. Can you hear me OK? and welcome to HMC 202 AWS wherever you need it from the cloud to the edge. My name is Spencer Dillard and I lead our EC2 edge businesses. Originally this is going to be a joint talk with Madura Cale who leads the product team for AWBS Outposts. Unfortunately Madura had to miss out, uh, for a family emergency and had to miss reinvent this year. Uh, so you're stuck with me. Uh, I've been at AWBS since 2011. Uh, I've led a number of areas of AWBS ranging from elastic load balancing, uh, private link, Nat Gateway, our BPC networking, uh, Fargate, and today I lead our AC2 Edge businesses. In today's session, OK, uh, we'll cover a lot of ground. Is it good? All right. ABS offers a wide variety of products and solutions that enables you to address the breadth of edge computing needs. So we'll start with an overview of the AWBS Edge computing product portfolio. Then we'll go deeper into 3 areas of interest that we hear most frequently from customers. And specifically we'll cover digital sovereignty, generative AI, and migration and modernization. Let's start with an overview of AWS's Edge product portfolio. And we'll start with how AWS can support you where you need a solution. To meet the extensive breadth of your needs, AWBS delivers a continuum of consistent cloud services to a variety of locations spanning from AWBS regions to far edge locations. Major metropolitan areas and industrial centers are supported with AWS local zones. For large scale complex digital sovereignty requirements, AWBS dedicated local zones operate in a customer specified location. For on-prem and co-location deployments, AWBS outposts extends AWBS infrastructure. And services to these sites. If you want to integrate container environments across AWS and non-AWBS platforms, we offer EKS hybrid nodes. At the far edge, ABS outpost servers extend dual cloud capabilities, extend cloud capabilities to remote locations and a smaller form factor. And for workloads that run on existing hardware. You can use Amazon ECS anywhere or Amazon ETS anywhere. What truly differentiates us is the ability to bridge cloud. And legacy environments using the same AWBS services, APIs, automation, governance policies, and security controls for all of your applications distributed across a variety of locations. To deliver on this promise truly requires a global infrastructure footprint. Bye. ADBS has the largest global infrastructure footprint for distributed hybrid workloads. This footprint is constantly expanding and at a significant rate. Here's a snapshot of our footprint as of today. In addition to 38 regions comprising 120 availability zones, we have 35 metro areas with AWBS local zones and another 10 that we've announced. If you're not located in a country with regions or local zones, we have 78 countries where AWBS outposts can be deployed to bring AWBS compute to you. Or maybe you prefer a visual of this global infrastructure. As you can see, ABS has the most extensive global cloud infrastructure. And there's a good reason for this footprint. Some of the themes that we hear from customers are around applications that many of which could be easily migrated to the cloud, but that you have a lot of applications that require being rearchitected or modernized in some way before they can be moved to the cloud, regardless of whether it's a local zone or a region. Other applications have a need to remain on-prem or in a specific location for various reasons such as low latency, uh, local data processing, or data residency requirements. In addition, what we find is that customers want the same experience across these environments. And customers have consistently told us they wanted a cloud experience, not just a cloud-like experience. The same experience, the same expectations of the infrastructure, including reliability, security, and performance. The same operational consistency using the same services and APIs. The same tools for automation, deployments, and security controls. And of course customers want the same pace of innovation as in the cloud. We agree And our hybrid cloud offerings deliver on this promise and need. We'll start with ADBS local zones and then we'll talk a little about dedicated local zones and other areas, but all of them are designed from the ground up to address these requirements. We've built all of these solutions on top of the ADBS nitro system that powers modern EC2 instances in ADBS regions today. This approach Excuse me, brings the enhanced security and performance benefits of the nitro system to edge locations. This means there's no replatforming or performance validation as you scale your applications to more locations. This full stack consistency is critical in boosting IT efficiency and developer productivity, allowing you to deliver new products and solutions faster. We'll go into each of these a bit more, starting with AWBS local zones. ADS local zones are an extension of the ADBS region. That place select services, select AWBS services in different locations. Local zones provide seamless access to AWBS services that are available in the region. They use AWBS's low latency, high bandwidth, global backbone. And they offer elastic on-demand pay as you go pricing and the same core AWBS services and developer experience. In addition to standard local zones, we also offer dedicated local zones. ABS dedicated local zones. Uh, sorry, our AWBS deployed infrastructure in customer specified data centers. Dedicated local zones offer the same benefits of a local zone but are dedicated to a single customer or a community of customers. And dedicated local zones are operated by local AWBS personnel and also use the AWS backbone to provide the same capabilities as standard local zones. And when you need a solution that can be deployed to your locations, there's AWBS outposts. When an AWS region or AWS local zone isn't close enough to meet your requirements, Alpas may be worthy worthy of your consideration. Outpost is a fully managed service that brings AWBS infrastructure and services to virtually any customer premise or edge location. This consistent hybrid experience offers the same core AWBS services and APIs. Developer experience and controls as AWBS regions and local zones. It's important to understand that outpost shifts the the shared responsibility model and that you manage the connectivity to the ADBS regions, to the parent region. The Alpos family comes in multiple form factors. EPOs racks are 42U deployments and they're ideal, uh, ideal for deployments in customer data centers or colo facilities. Outpost servers are available in 1 and 2U form factors for locations with limited space or power. Such as branch offices, restaurants, clinics, or manufacturing sites. Earlier this year, we announced 2nd generation AWBS outpost racks. This 4th addition to the Alpost family brings 3 key innovations that we're really excited about. First, these support the latest EC2 instances. Second, this new design uses a modular network configuration. That allows you to independently scale your compute and networking needs. Third, you can use an industry-first bare metal EC2 instances that are designed to meet the networking requirements of ultra low latency and high throughput workloads. The new outpost rack delivers the performance needed for a broad range of workloads that you need to run on-prem. Outpost powers some of the most demanding workloads that were once considered impossible to run in the cloud, for example, 5G core, uh, telecom workloads or core trading system of financial institutions. We're really excited about how customers are using these bare metal networking instances today. Well, let's talk about the new bare metal networking instances. These 2 EC2 instances are only available in ADBS outposts. The specialized bare metal nic that is used in these instances opens up new possibilities. Uh, for local networking. The bare metalworking. Experience works in parallel to the AWBS Nitro Amazon VPC Experience. This lets customers get the best of both worlds. And customers with demanding workloads such as financial services and telco industries are using these in production today with applications that support financial exchanges, options markets, real-time market data distribution, and 5G core applications. These enhancements are important examples of how we are continuing to deliver on the pace of innovation that you've come to expect from AWBS. In addition to major enhancements like bare metal networking and the new outpost rack design, we continue to iterate and innovate in our edge solutions. Thanks to feedback and input from customers like you, we've delivered a variety of features and resiliency improvements spanning networking, storage, and ease of use. We've also continued to expand on the locations for AWBS outposts and ADBS local zones with 35 metro metro areas for local zones and 78 countries for ADBS outposts. This continued innovation and customer focus has not gone unnoticed. I'm happy to share that ABS has been named a leader in the recently published 2025 Gardner Magic Quadrant hybrid infrastructure research paper. And has positioned the highest in ability to execute. ADBS ranked number 1 in 3 use cases, including edge computing, container deployment, and AI and G AI workloads. This leadership is also reflected in the many success stories of our customers. And the success of our customers perhaps provides the most important testimony to our product portfolio. Nearly 50% of these successful customers were added in just the last 12 months. And today we'll look at a few of these success stories as well as some reference architectures. Let's start with Ticketmaster, the world's largest ticket marketplace. Ticketmaster delivers superior live event experiences by bringing its online ticket sales and distribution platform closer to fans with AWBS local zones. Ticketmaster overcame technical challenges, reducing latency by a factor of 10 to less than 5 milliseconds for a round trip, all while using the same AWS compute storage. And other services available in this in a local zone. Ticketmaster's implementation sets new standards for distributed cloud, delivering improved end user experiences and further accelerating their innovation. Let's look at another customer who is seeing the benefits of operating in AWBS local zones. Sophos builds, curates, and disseminates real-time threat intelligence to hundreds of millions of endpoints and network devices. Via its Global Sophos Labs Intelix lookup service. To improve user experience and specific geographies, SOFOs use local zones. To reduce lookup latency by bringing threat intelligence closer to end users. The front end lookup tier was deployed globally in local zones. While the back end uh data tier what remained in ADBS regions. To bring these things, these parts together, Sophos used Amazon Route 53 latency-based and geop proximity routing. Combined with high performance caching. To enable faster threat lookup responses. Excuse me. The result has been outstanding. The enhanced threat detection service reduced latency by 69% in Germany. As well as 35% across Europe with similar improvements from other regions. The resiliency and scalability of this architecture was proven out recently when tens of thousands of endpoints went offline as a result of Hurricane Milton and then came back online suddenly. The application scaled using EC2 auto scaling and was able to handle a surge from 146,000 requests per second to nearly 2 million. A surge of more than 1,200%. And we'll look at another example of how AWBS outpost is being used for demanding workloads. The London Stock Exchange Group is modernizing critical financial infrastructure with AWBS outposts. LSEG is transitioning its global price stream FX trading platform using AWS hybrid cloud technology, implementing a sophisticated architecture with ultra low latency. And additionally, LSAG is modernizing its clearing systems, balancing regulatory compliance, operational excellence, and business continuity with strict RPO and RTO requirements. ElSEG's transformation and modernization is enabling exceptional performance while meeting stringent regulatory resiliency and regulatory requirements. And another customer that is relying on ABS outposts for critical workloads is Amazon.com. Amazon.com is using Outpost to orchestrate the movement of tens of thousands of robotic drive units within Amazon's fulfillment centers. In addition to the real-time command and control of robotic drives, Amazon.com runs the automated storage and retrieval system using Alpost, which is deployed in Amazon.com fulfillment centers. With outposts, Amazon maintains fluid operations in the fulfillment centers, which helps enable the customer promise of sub same day and next day delivery during Prime Day 2025. The automated storage and retrieval system at one of the largest Amazon fulfillment centers. Sent more than 524 million commands to over 7000 robots, reaching peak volumes of 8 million commands per hour. This is a 160% increase compared to Prime Day 2024. Empowering applications at the critical core of Amazon.com's business is a testament to the scale and the operational resilience of Apis. We'll now dive a bit deeper into the key challenges that our customers are solving today and how hybrid and edge solutions are helping customers on this journey. First, let's start with digital sovereignty. AWBS provides the most secure infrastructure for your sovereign workloads. But let's break this down a bit because sovereignty is a layered and nuanced topic, and definitions of digital sovereignty will definitely vary. As we have listened to customers and regulators, partners, we've decomposed the core aspects of digital sovereignty into 4 themes. You want to know where all your data is stored. You want to control where that data is, where that data is stored and transferred to at all times. You want to be sure that Neither AWS nor a foreign government can access your data in the cloud. You want to be sure that you can sustain operations despite geopolitical instability and natural disasters and technical failures. And finally, you want to be sure that your data in the cloud meets the operational and security assurance requirements for regulated industries, sectors, or locations. And this topic is critically important to AWS. In this evolving regulatory environment, there's been one concern from customers that has really stood out to us. This concern that customers voice is that they have to make a choice or a fear that they have to make a choice between either the full power of AWBS or an independent sovereign cloud solution that could hamper their innovation. We really don't believe that you should have to make this choice, and that's why we introduced the AWBS digital sovereignty pledge. This pledge represents our commitment to offer all AWBS customers the most advanced set of sovereignty controls and features available in the cloud. With this pledge we commit. To deliver more services. More services and features to protect our customers' data and provide even more fine-grained. Data residency controls, and transparency. Second, We continue to build additional access restrictions. That limit all access to customer data. Unless the customer it's requested specifically by the customer or a trusted party. Third, we continue to innovate and invest in encryption features. And additional controls for sovereignty so that customers can encrypt everything everywhere with encryption keys that are managed inside or outside the cloud. And we continue to enhance our range of sovereign and resilient solutions, allowing customers to sustain operations through disruption or disconnection. Let's start with control over the location of your data. Maybe OK. We will improvise. It's important to understand that data residency is not binary. OK. Instead, it's a spectrum with shades of complexity that vary from one scenario to another. Identifying in scope data is a pivotal step that influences every aspect of your design and investment need. Some of the most common scenarios that our customers run into affect data storage and data transfer. And this is based on geographical boundaries, data classification, and are often industry specific. ADB's hybrid and edge solutions provide a variety of options for local storage and data processing. By working backwards from your country-specific data residency needs, ABS can help identify in scope data. We can recommend infrastructure offerings that meet your specific needs. Whether that's an ADBS region, a local zone, or an outpost. And each of these has a variety of options for that data storage. This can get quite complex. To reduce the complexity, you can set up data residency guard rails to control the location and movement of data. AWS control tower landing zone is a well architected multi-account environment available in AWBS. You can use service control policies or SCPs with ADBS organizations to define data residency requirements for ADBS local zones or ADBS outposts. In this example, the SCP expresses various deny statements for data movement actions. This keeps your data within the specific local zone or outpost that the policy covers. But let's return to the digital sovereignty pledge and cover verifiable control over your data access. For 10 years we have been reinventing the Amazon EC2 virtualization stack and moving virtualization functions to dedicated hardware and firmware. The nitrous system is a result of this continuous and sustained innovation, and it powers all modern EC2 instances available today. By providing a strong physical and logical security boundary, nitro is designed to enforce restrictions so that nobody, including anyone in ABS, can access your workloads on EC2. Access to the EC2 instance APIs which enable ABS personnel to operate the system. Without access to customer content is always logged and always requires authentication and authorization. The global cyber cybersecurity consulting firm NCC Group published an independent report on our security design claims of the nitro system, and this is available on ADBS's website. For the third part of digital sovereignty, let's talk about the ability to encrypt everything everywhere. Continuing with the importance of the ABS nitro system, it's worth a minor detour and let's look at a simple solution to a really difficult problem. And we loved all the innovation in the AWS nitro system, but we wanted an extra layer of security that is particularly important for the edge. Media handling and data centers can be a big challenge, ensuring that data does not leave the data center. Because we encrypt everything at rest in the nitro system using hardware-based encryption. We can centralize the encryption keys key hierarchy into one location and then externalize it. And that's what we do with this nitro security key. Within this little device there's a small chip. And there's a screw that is sitting just above that chip, and this device includes a hex driver. All you do is you turn that screw and you crunch that chip. Crushing that chip will physically destroy the encryption key that is associated with all of the data on the server. This is equivalent to shredding drives, and it helps protect sensitive data from leaving the data center. And the last element in the AWS digital sovereignty pledge is resilience of the cloud. And there are particular challenges in hybrid architectures that are worth discussing when it comes to resiliency. As our CTO Doctor Werner Vogels has said, everything fails all the time. This is especially true in edge locations where you need to not only design for high availability, but also need to consider continued operations through temporary network disconnections. We continue to invest in enhancing the resiliency of our hybrid and edge services. And when architecting for high availability, ADBS's continuity of services and consistency across services and APIs is a foundation that gives you a leg up. You can choose to partition your workloads in a variety of different ways based on your needs, for example, between a local zone and an ADBS region. And keep in mind that each local zone or outpost is parented to an AWBS availability zone in an AWBS region. Depending on your specific needs, an AWBS specialist will be able to guide you through these choices to architect for high availability. With AS outposts, there's also some additional options that you can consider. When you're architecting for high availability for your on-prem applications, another option with outposts is to use intraVPC communication across multiple outposts. This enables local connectivity. Excuse me, between different logical outposts without having to traverse to the parent regions. This pattern allows you to build multi AZ-like architectures for your on-premise applications. Each logical outpost is parented to a different availability zone in the region. The local connectivity enables you to design for failover and HA scenarios. A related topic of disaster recovery is rather important when we're talking about resiliency. And ABS Elastic Disaster Recovery Service provides nearly continuous replication for mission critical workloads. DRS supports many deployment patterns, uh, which are covered here and all their variations. Such as replication from outposts to local zones, DRS provides a native tool for you to simplify disaster recovery of workloads with your specific RTO and RPO objectives. And one of the most common topics that we find with customers when they are designing their edge architecture is the ability to withstand network interruptions. Continued operations in a in a disconnected state is a particularly nuanced topic. With outposts, your EC2 instances can continue to operate for up to 7 days in the event that the network connection to the parent availability zone is interrupted. There are customer choices that can affect how an outpost behaves under a variety of conditions such as power interruptions, extended loss of network connectivity, etc. And for our services that operate on customer managed hardware, you also have the choice of ETS hybrid nodes and ECS anywhere that can support periods of disconnection from ADBS regions. Lastly, EKS anywhere can operate in air gapped environments. And yet another option for improving resiliency with outposts is using satellite connections. Many customers have told us they want the power of AWBS in remote locations. But require last mile networking, resiliency that terrestrial connections don't currently provide in these locations. With satellite resiliency for ADBS outposts, your outpost connects to a low orbit satellites. And if there's a disruption in the terrestrial connection, it uses network routing to route the traffic back to the parent region over a satellite connection. Currently this solution could be used as both primary and backup connectivity for outpost servers and as a backup connectivity for outpost racks. Finally, it's important to look at a customer success story that is specifically addressing digital sovereignty. And AWBS's overall digital sovereignty solution across the four pillars that we covered previously data locality control, verifiable operator access, encryption, and data security, as well as resiliency through disasters has resonated with customers. The Singapore government, Smart Nation, and Digital Government Group. Has partnered with ADBS since the beginning of their ADBS cloud journey. They collaborated with AWS to define and build dedicated local zones that can meet the stringent data isolation and security requirements. That enables Singapore to securely run more sensitive workloads in the cloud. In addition to helping the Singapore government meet its cybersecurity requirements, dedicated local zones enables the Singapore government to offer its agencies a seamless and consistent cloud experience. Let's move on to another interesting case of hybrid and edge computing using generative AI. Generative AI and inference at the edge are areas that we're seeing a lot of innovation from customers today who are using AWS hybrid and edge solutions. One of the challenges that customers face is balancing multiple, often conflicting requirements. And many of the customers we've spoken with have told us about the challenges they face in their Gen AI adoption journey, in particular as it applies to edge and hybrid environments. You want to use your data to better meet the needs of your customers and end users. But you can't compromise on securing and protecting this data. And it must be compliant with data residency rules and regulations. You need solutions that will give you the flexibility to adapt as your needs change. While providing a consistent experience for your builders. Customers across many industries spanning from manufacturing, telecom, and, and others. have been using these hybrid cloud offerings. The case studies and reference architectures that we'll cover momentarily use edge inference for low latency and local data processing. They also include a range of workloads such as object detection, facial recognition, robotic control, and predictive maintenance. So let's start with how ABS's hybrid solutions truly can support the full Gen AI life cycle. This life cycle spends data preparation, model training, model customization, and inference, as well as deploying. With ADBS hybrid cloud offerings, customers can scrub or anonymize data before storing it in ADBS regions for training. With GPU enabled instances from EC2 that are available on AWS hybrid cloud offerings, for example, P5 instances that are available in local zones, ADS supports the initial training, customization, and continuous tuning for customers with data that is subject to data residency requirements. Let's start with an overview of how ABS supports this full continuum. And when people talk about cloud, they often see it as a binary choice. There's public cloud and there's on-prem. But the reality is more nuanced. Enterprises are increasingly finding that they need a continuum of solutions. This continuum encompasses public cloud, on-prem, and edge computing in a way that's seamless and consistent. ABS regions and select local zones provide the most powerful compute options, including ABS ranium. ADBS inferentia and EC2 ultra clusters, as well as the latest GPUs. Meanwhile, ADBS local zones and ADBS outposts enable inference and fine tuning and address the data residency and local low latency requirements that many of our customers have. This continuum provides a consistent experience that gives you the flexibility to adapt as your needs change. And yesterday we announced AWBS AI factories that further expands on this continuum. Many enterprises, especially those in highly regulated industries or public sector, have found it challenging to deploy advanced AI and machine learning technologies. Some of the challenges faced by these customers are strict requirements in areas of security, sovereignty, and compliance. Realizing that it often takes years to design, build, and deploy the infrastructure needed to support advanced AI applications and workloads, we launched AWS AI factories. You can think of these as dedicated, isolated environments. That provide customers with secure access to powerful compute, compute, storage, and AI services that are needed to train and run large scale AI workloads. These AI factories operate exclusively for each customer, ensuring complete separation while maintaining the security, reliability, and capabilities of the AWS cloud of the AWS cloud. Importantly, AWBS AI factories can seamlessly integrate with customers' existing IT investments such as their own Nvidia GPUs and existing, excuse me. Get back. Uh, OK, apologies. And with with customers existing IT investments such as Nvidia GPUs. I'm not, I love. In addition, AWS AI factories also provide access to a broad set of AWBS AI services, including Amazon Bedrock and Amazon Sagemaker. AI factories allow us to meet customers wherever they are on their AI journey. And enable rapid development and deployment of advanced AI applications at scale. You may be wondering how this works. So first, customers provide details about their data center and power infrastructure for an AI factory deployment. This may include using their own GPUs that they've already invested in. Next, AWBS deploys AI factories and customer data centers, providing GPUs, high performance networking, and ADBS AI services. Once deployed, AWBS AI factories look and behave similarly to local zones. And availability zones from a pricing perspective, the pricing for AWBS AI factories depends on various conditions and criteria. For example, whether the where the infrastructure is located, the investments that the customer is bringing to the AI factory, as well as the required services and capabilities needed in the AI factory. With ADBS AI factories, customers can leverage their existing investments in data centers, power, and even GPUs, while AWBS provides expertise in building and maintaining AI infrastructure at scale. By accelerating deployment times by months or even years, customers can focus on innovation with AI instead of infrastructure complexity. And there are a variety of business drivers that we're seeing that are leading to a lot more investment and interest in Gen AI and agentic AI at the edge. With support for the full life cycle and the continuum that we already talked about, customers can drive innovation while balancing constraints and requirements. Customers with data on-prem can remove personally identifiable information. And other sensitive information. In their outpost deployment before storing the data in an ADBS region for training. You can leverage your data using a local and hybrid rag hybrid inference with retrieval automated generation or RAG to improve prompt outcomes. It's amazing to see how customers are using Gen AI along with AWBS's full range of hybrid offerings to solve incredibly challenging problems. These solutions span manufacturing, telecom, public sector, energy, and media and cover a wide range of requirements, including data residency restrictions and low latency applications. Let's look at a real world example of how bringing all these pieces together. Bank Center Credit is a leading bank in Kazakhstan. They provide simple, convenient banking products and services to more than 3 million individuals and business clients. BCC wanted to take advantage of generative AI to deliver innovative banking solutions and improve operational efficiency. But it's subject to stringent country-specific data residency regulations for financial services institutions. With AWS, BCC is now able to process over 1 million minutes of audio per month with cost savings of over $1 million US dollars, and they've reduced AI inference costs by 50% using Amazon Bedrock. But let's go a little bit deeper into the solution that BCC developed and is operating today. BCC worked with AWS to build the first secure and scalable hybrid architecture in Central Asia, which allows them to meet Kazakhstan's strict financial data regulations. BCC anonymized the regulated data. Locally using AWBS outposts before transferring it to Amazon S3. Which is located in the parent region. With the data in Amazon S3, BCC then trained an automatic speech recognition model using Amazon EC2 to process Kazakh- Russian mixed customer service calls. This anonymized data was then used to fine tune audio encoder using Amazon Sage Maker to improve the domain-specific Russian recognition from these calls. And BCC continues to innovate with Gen AI using foundation models on Amazon bedrock to improve business process automation. Again, ABS's full range of solutions and for the hybrid and edge locations provides both flexibility and scale. Let's look at another example, Anthropic, who is one of the most innovative companies in the AI space. And requires massive scale to achieve their vision of solving complex problems that were previously beyond reach. Anthropic uses AWBS local zones and AWBS Tranium too to ensure that millions of end users. Can access Cloud's capability to continue to drive AI innovation. And we'll shift a bit from large language models and talk about small language models. Small language models. Or SLMs are becoming particularly critical for extending applications using local processing. Some examples of these applications. Our chatbots, report generation, and many others, for example, in this reference architecture, users are submitting. A query or taking an action that results in a prompt. Models are selected from the hugging face marketplace, and with SLMs readily available for text to speech, text generation, text to image, and others, you, you can quickly deliver powerful capabilities to end users. The application and SLM are deployed on EC2 instances in ADBS local zones or ADBS outposts. And this architectures resides within the network boundaries of an Amazon VPC. And is able to scale based on demand using application load balancer and auto scaling groups. And SLM SLMs are an important part of a complete solution that takes advantage of the capabilities of a hybrid architecture. As you develop your hybrid solution, G AI adoption and acceleration, it's worth exploring the SLMs that are readily available. But like any software tool, you need to invest in the testing and validation of the SLMs you plan to use. With easy access to these models, they can also become difficult to track and manage, so you may want to consider using an optimization framework. You also need to think carefully about priorities and constraints. For example, optimizing for resource constrained environments will require resolving tensions between speed and accuracy. Now let's look at a real world example that further uses SLMs. Ctrium delivers innovative maritime and new energy solutions, bringing together world-class talent and engineering capabilities to create transformative and sustainable offshore and energy solutions. CRM is building real-time predictive analytics using sensor data from seaports to create an intelligent. Shipyard, excuse me, an intelligent shipyard operations platform. This solution is powered by Gen AI and relies on local processing of sensor data where CRM's AWS outpost deployment hosts the real-time inference that enables these applications and decision support for maintenance, inspection, and workflow automation. The result is subsecond latency with sophisticated real-time decision support using the shipyard operations platform while maintaining compliant with maritime data sovereignty regulations. We've touched on rag here a little bit, retrieval automated generation. Let's go a little bit further into how this is being used. While ADBS outposts and ADBS local zones provide solutions to meet your data residency requirements, this leaves you with the challenge of how to use this data safely and effectively when other systems or parts of your application are running in an AWBS region or AWBS local zone. For RAG to improve the accuracy of prompts, you will need to integrate data sources that reside in these locations. Using Amazon Bedrock agents and ABS Lambda. You can, excuse me, you can define action groups that are accessible to the bedrock agents. These lambda functions can implement business logic as well as additional controls before proxing the request to SLMs and applications that are running in ADBS outposts or local zones. And when you implement a rag solution to improve your prompt responses, you can use a local or hybrid approach. In this example, we'll look at a local rag solution. That uses a local data ingestion process. To ingest files and databases. Once the data is chunked using chunking models or as part of a more complex rag pipeline. You can then use embedding models that are appropriate to the type of data you're ingesting, for example, working with tabular data or content translation. This data is then stored in RDS Postgras SQL using the PG vector extension, and this enables vector similarity searches. And we'll look at how this is actually used in the generation phase to improve your prompt responses. In this example, we'll look at a scalable application that improves the prompt responses. We're using application load balancers and auto scaling groups to scale the front end. When the prompt is received, we create the vector representation of the prompt using an embedding model. And these vectors are then used to query the RDS postgras sequel that we covered previously. The result is passed to an SLM to generate potential responses. The original prompt and chunks are then processed by a re-ranker to filter out low quality or risky responses. The final response is then provided to the end user. And in this example we built an extensible solution. That you can build on supporting additional prompts and data sources over time that you can incorporate in new models and new new ways of extending your applications. And we'll look at how this architecture fits in a broader agentic AI solution. As you develop agentic AI workflows, you're likely to have many applications that reside in a single location, such as AWBS regions and local zones. However, there are many cases where the agent in our interactions will need to span locations. Using Amazon Bedrock Agent Core, you can define and manage the interactions of agents at these various locations while ensuring compliance with various restrictions. Agent Core makes it easy to connect with agents, data, and tools in almost any location and also provides operational capabilities such as dashboards and metrics. Now we've covered how ADBS hybrid solutions can contribute to your AI strategy. We're going to shift a bit to talk about migration and modernization. And ADBS's hybrid and edge solutions are frequently part of a broader strategy and effort to migrate and modernize applications that are running in an on-prem environment. Many of our customers have told us that adopting Gen AI and moving to a hybrid strategy has been slowed because of the difficulty in migrating and modernizing workloads. This is especially difficult to avoid disruption or added latency when applications have on-prem dependencies. Let's look at a few of the challenges in this area. Many workloads can be easily migrated to the cloud, but some need to remain on-prem. You may have dependencies on applications and data that must maintain low latencies or that must remain on-prem. Such as systems for facilities operations. You may be required to keep the data on-prem or within some geographic boundary due to regulatory or other requirements. And many customers are facing an aggressive timeline to lift and shift from an on-prem environment and plan to modernize over time. This may be driven by a strategic plan and a move to the cloud. It may be driven by increased licensing costs, or it may be a result of the need to exit or consolidate data centers. And there are a number of ways that ADBS can support your migration and modernization plans. There's a wide range of approaches that you can use to accelerate your cloud migration, and our hybrid cloud offerings are a critical part of this strategy. The AWBS migration acceleration Program provides tools, training, and expertise to assist you. But let's look at some key considerations that you have to consider in this journey. If you need to keep your data on-prem. Or within a geographic boundary, then you'll want to consider ADBS outposts or ADBS local zones. Then decide what's right for you. Is it rehosting your workloads with Amazon EC2? Uh, in which case pathway number 1, or modernizing by containerizing your applications with Amazon ECS or Amazon EKS pathway number 2. If you want to modernize but plan to continue running on your existing hardware, then you may want to consider ECS anywhere or EKS hybrid nodes, as well as EKS anywhere. For many customers, this migration and modernization effort will lead to identifying workloads that can benefit from refactoring and deploying in a serviceless model as well as using other managed services that are available through AWS. One of the customers who has been through this journey is DraftKings. DraftKings needed to expand its sports betting service across 26 US states while meeting strict regulatory requirements. The Federal Wire Act and state regulations require that customer account and wallet data remains within each state's borders where DraftKings holds a license. Traditional solutions would require building physical data centers in each state, which would create a massive upfront infrastructure and software investment for DraftKings. And it would also require extended deployment timelines. DraftKings also wanted to migrate from a legacy virtual machine architecture in addition to maintaining compliance. DraftKings launched its state by state expansion strategy that uses AWBS local zones to achieve data residency compliance. DraftKings deployed regu regulated betting operations to local zones in each state, while keeping non-regulated services and data in parent ADBS regions. This hybrid approach required only minor modifications to existing infrastructure automation code. DraftKings also worked with Presidio, a premier consulting partner in the ABS partner network, to create guard rails for securing operations across different state jurisdictions. As a result, new entry state entry time has been reduced from 1 week to just days, and the solution has eliminated upfront infrastructure investments for each state launch, saving millions of dollars annually while maintaining up time during peak events like the Super Bowl. And one final customer to look at for AWS outposts and the challenges that they have been have worked through is Rivian. Rivian is an American automotive manufacturer that develops and builds category defining electric vehicles. Rivian's software and services address the entire life cycle of the vehicle, and many of Rivian's manufacturing workloads were previously hosted on a legacy virtual machine architecture, and this was slowing innovation. Vivian wanted to move to a self-service model that allowed them to accelerate innovation, and they also wanted to containerize their applications over time. Differences in the cloud environment versus a legacy on-prem environment were creating silos, and they were really limiting teams' ability to innovate and deliver. And as an added challenge, Rivian's factory operations require maximum uptime. And low latency to ensure a safe and efficient manufacturing site. Vivian is realizing its goals by standardizing on ADBS outposts. For its manufacturing container platform 2.0. This solution provides Rivian with a single low latency infrastructure and container platform across the entire business. Vivian is able to test in the cloud and deploy to factory sites without code changes. As a result, Rivian is reducing operational costs and accelerating new capabilities. And as you develop your cloud migration strategy that's appropriate for you, the less you have to change, the better. And with the ADBS outpost, the third party storage integration that we offer allows you to realize the full potential of your on-prem data and to simplify your migration strategy. This solution lets you combine the compute capabilities of AWBS outposts with storage solutions from leading partners including Dell, HPE, NetApp, and Pure. With third party storage integration, you can attach external blocked data volumes using AWBS APIs and management console. This allows you to make use of the data that is already available on-prem and gives you the flexibility to use as a long term solution or as a step in your migration journey. So we've covered a lot today, and let's recap and cover some of the key takeaways. With AWBS you can leverage the same infrastructure, APIs, and management console automation, governance policies, and security controls across cloud, on-prem, and edge environments. This consistent approach differentiates us from comparable solutions and is what allows you to boost your developer productivity. Improve IT efficiency and deliver innovation innovative solutions faster. Second, AWBS supports. A broad range of on-prem and edge workloads that require low latency, local data processing or data residency requirements, including some workloads that were previously considered impossible to run in the cloud. We bring the ADBS experience on-prem that allows you to accelerate your migration and modernization efforts, including virtual machine migrations that need to remain on-prem. And finally, AWS is committed to continued investment and innovation in our hybrid cloud and edge computing solutions to help you lever leverage AWS wherever you need it. And there are plenty of opportunities this week to go even deeper. I strongly recommend checking the attendee guide to attend one of these sessions live or to view the recorded session after reinvent. All of the customers that were referenced in this talk, uh, are giving some session this week, uh, so check out the attendee guide for more details. There are also a lot of options for you to level up your skills and go even deeper on the services we've talked about today and many others. I highly recommend checking out the AWBS Skill Builder. And finally, let us know how we can help you with your hybrid and edge needs. And with that, thank you and I appreciate your time and attention.