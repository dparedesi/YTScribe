---
video_id: e-AN0kuAW3s
video_url: https://www.youtube.com/watch?v=e-AN0kuAW3s
is_generated: False
is_translatable: True
summary: |
  Anwar Ali and Ray show how generative agentic AI can streamline telecom cybersecurity operations, especially diagnosing blocked user requests across complex, multi-segment networks. Telcos face rising attacks, strict regulation, layered monitoring tools, and fragmented logs (terabytes/day across clouds/on-prem, proprietary formats, inconsistent schemas), making correlation slow and error-prone. The demo focuses on a “network trace expert assistant,” a chatbot for security analysts (and eventually self-service users) that fetches, correlates, and reasons over network/security logs to pinpoint root causes in minutes instead of hours.
  
  Architecture: A Bedrock AgentCore-hosted agent (built with the Strands SDK using Anthropic Claude 3.7 Sonnet) authenticates via AgentCore Identity (JWT validated through Amazon Cognito or other IdPs) and queries tools exposed through AgentCore Gateway as an MCP endpoint. Gateway lists tool schemas, and the agent dynamically selects tools based on base prompts describing each log source’s schema. Tools are implemented as Lambda functions that query logs wherever they live (S3/OpenSearch in the demo, but extendable to other clouds/on-prem); any AgentCore-supported framework (LangChain, LangGraph, CrewAI) could be swapped in. Amazon Security Lake is recommended (not mandatory) to centralize logs in OCSF format, lifecycle-manage storage (Iceberg), and ease analytics by standardizing schemas for regulated telco environments.
  
  Demo scenario: “David Lee” is blocked accessing a billing app from home. The agent authenticates, lists tools, and runs multi-source checks against Zscaler, Check Point, and Illumio segmentation logs. It returns a natural-language report summarizing blocked timestamps, per-source findings, and a final conclusion: ZPA authentication succeeded, initial Elasticsearch connection was allowed by ZPA/Checkpoint, but a subsequent attempt was blocked by Illumio. Because it’s a chat interface, follow-up questions can target individual sources; the agent can also generate specific queries using its knowledge of each schema. Base code requires only four added lines to move a locally built agent to AgentCore Runtime, scale to hundreds of concurrent sessions, and access tools via Gateway with a bearer token.
  
  Benefits: faster incident detection/resolution (hours → minutes), higher SOC productivity, better collaboration between developers and security teams, and potential to offer self-service troubleshooting that reduces ticket volume and context-switching. Users interact in natural language—no need to learn proprietary query languages—while the agent writes and runs the queries. A crawl-walk-run path is suggested: start with SOC chatbot, then self-service portal for blocked users, and ultimately use the same agents to investigate larger security events (e.g., many failed requests indicating a bad actor) and meet compliance SLAs. Security Lake centralization plus AgentCore Gateway flexibility allows adding non-AWS log sources via REST, Lambda, or MCP server targets. Key takeaways: GenAI on AWS can perform undifferentiated heavy lifting in log correlation; Bedrock AgentCore accelerates deployment; and an MCP-enabled gateway future-proofs access to diverse tools and data locations for global telco teams securely.
keywords: telecom security, generative AI, Bedrock AgentCore, log correlation, Security Lake
---

Welcome to the Lightning Talk session, streamlining, uh, telecom cybersecurity operations with Generative AI. I'm Anwar Ali. I will be your host for the session. I will be co-presenting with Ray. We both work as a solution architect at AWS. So this is a broad agenda of what we are going to cover, uh, in this lightning talk. We'll look at, uh, common challenges faced by uh the uh telecoms while analyzing the, uh, the logs. The network security logs and particularly we'll focus on diagnosis of any user or blocked user request if there's any incident, any security event, so how the agenttic AI can help the security analyst to quickly resolve the issues, right? So there is an interesting demo which really will be covering and he will also cover the solution architecture, how we build this agenttic architecture. So telecom and communication service providers are facing the increased number of security attacks. They are constantly facing an increased number of cybersecurity threats, and they are operating under stringent regulatory norms. There is a need for them to constantly evolve the security architecture. And eventually they have added a lot of monitoring and security control tools that has added a lot of complexity in managing these telco networks. So it becomes a challenging task, very time consuming. If there's any security event to diagnose this particular locks and quickly find out the root cause. So here I'm showing a, a representative uh flow where a user is connecting to an internal application. It's a very simple flow. You can look at various network security tools that go through. There are various interconnected network segments. This is a very simple representation of one of the flow, but in a real network there will be millions of such requests. There will be user to application connectivity. There will be application to application connectivities also between different network segments, and in between you can find various network monitoring and security operations tools. And all these tools are emitting the logs, right? So when any security incident happens, it becomes very time consuming and error error prone to diagnose this log. So the agentic solution what we are talking about is going to help in this particular case, right? And there are two use cases. What we are focusing on is the use case where a user, an authentic user is being blocked while accessing the. Uh, the applications over a telco network, but uh, it can even be extended for security analysis diagnosis. So, with that background. Let's look at the common challenges what someone faces while analyzing the log. So it's not the logs are very verbose. There is a lot of information in it. Now, all this security and network tools are emitting the log. It presents in multiple places. It will be on AWS cloud. It will be across the region. It will be on third-party cloud, on-premise, and these logs are not in a standard format. So many of the tools are emitting the log in. The proprietary, uh, uh, format, right, uh, there is no standard convention, uh, that helps you to correlate this particular log. It becomes very time consuming and cumbersome because of this, right? The log volumes are high, so even to store the logs, many large enterprises are emitting the logs in the, uh, in, in terabytes per day. That, that's the kind of volume, even for large enterprises, that's the, uh, volume that we are talking about. So to store this particular log and process this log to query this log in the. Analytics tool, it becomes extremely cost prohibitive. It becomes extremely difficult. And last but not the least, very important is the it's hard to correlate this log. So many of these solutions are providing logs in a proprietary format or even there are specific query tools that are supported, right? So someone as a security analyst needs to learn. And fetch this particular log. So look at the scenario when there is any incident, the user, the end user is blocked for a network request. The developer is blocked. He has raised a ticket with the cybersecurity team. Someone in the cybersecurity team actually goes, the security analyst goes, look at all the logs, try to make sense out of it, and it becomes a very cumbersome and difficult process. So although I was showing one of the flow, there can be like uh many different flows. There can be several flows that's happening in the real network, and as I said, there will be application to application connectivity or interconnected network. There will be user users are accessing the telco network. There will also be various security and network components in between. Now we'll see how Agentic AI and Amazon Security Lake can help you to mitigate this. So the security analyst, what you're seeing on the right can use the network trace expert assistant. It is nothing but a virtual assistant that can help the security analyst to uh to diagnose the log. It's a chatbot in a simple way. Now. At the back end it is having an agent, uh, bedrock gentic AI. It is powered by the agents which are built on bedrock agent core, and this particular agents are functioning are doing two things. One is it is it can help fetch the logs from various sources. Help you to correlate and analyze these particular logs and then the agents, as you know, that are also having a reasoning power so it can help diagnose, find out the root cause of this particular issue. So overall agentic AI can be your friend. It can help you to uh meet uh uh the uh the uh it can help you to diagnose the log, what you can accomplish within the minutes earlier it was not even possible to accomplish within several hours as well. And, uh, one more best practice is to store this particular log in a centralized um Amazon Security lake. So Amazon Security lake will help you to, uh, store this particular log in a central place. It is also supporting the open cybersecurity schema framework. It's a standard format that helps, uh, the AI agent as well as your other analytics tool, uh, the same, same tool to query this particular logs in an efficient. and it also helps to manage the life cycle management policies to store this log in an iceberg in a very efficient way that is easier to query and process. So, uh, although Amazon Security lake is not a prerequisite for this genic architecture to work, but it is a best practice. So we are using it in the combination in the architecture. One more thing is, uh, as, uh, the maturity of this particular tool increases, you can even provide this particular, uh, uh, network trace expert assistant as a self-service, uh, agent to the users. So now I want to uh call Ray to, uh, uh, explain in detail, to give a walkthrough on the architecture of, uh, how we have built this particular agents. Thank you, Anwar. Um, OK, so we're gonna talk a little bit about the architecture. We'll do a quick demo, um, and then we'll talk, uh, about some of the solution benefits. Starting on the left hand side here, you can see the personas, uh, that might interact with this application. Uh, primarily we're listing a security analyst, right? This is someone who might manually go through and look through these logs currently, um, and what they're doing in this case is they're actually interacting with our generative AI agent. This agent is running an Amazon Bedrock agent core runtime, which is a purpose-built runtime environment for uh generative AI agents. Uh, you can bring your own framework and you can bring your own model. So in this case, we built it with the Strands SDK and we're using a model available on Amazon Bedrock, which is uh Cloud 37 sonnet. The agent is of course only as valuable as the tools that it can use to retrieve the information it needs. Um, so we're actually using Amazon Bedrock Agent Core gateway as an MCP gateway to expose those tools to the agent. So when the agent first authenticates to the gateway, it's going to present a JWT, uh, and, and that JWT is gonna be validated by Amazon Bedrock agent core identity against our chosen IDP which in this case is just Amazoncognito, but you could use anything you want there, right? You could use OCTA, Entry ID, uh, you're welcome to swap that out. Now, for the gateway, the first thing that's gonna happen is when the agent initializes, it's actually gonna do a list tool sink call to retrieve the er the current er tool information. This is er the schema for the, the, the various tools that it can call, right, what the parameters it needs to pass in are. And um. Then what's going to happen is the agent is gonna, is gonna rationalize based upon the tools that it has, based upon the base prompting, and based upon the input from the user. So it'll use that model, uh, it'll, it'll decide to call tools, it'll make the calls through Amazon Bedrock Agent Core gateway, right, this is an MCP uh call, and those calls are actually going to a lambda function which actually implements the tool. So in this case, the lambda function is going to be connecting to our various log sources. So you can see we've listed three here for the sake of the demo, right? ZScalar, Checkpoint, and Alumio. But I do want to make it clear, right, wherever you're hosting your logs, whether it's S3 or or somewhere else, even on another cloud potentially, um, you know, that's something that, that, that we can support, right? You can connect, uh, you know, to that log source and use the agent to troubleshoot across, uh, many different sources. So let's take a look at a quick demo here. I just want to walk you through the scenario. So David Lee is an employee of Acme Telecom, and he encounters a security block while accessing a billing app service through an Acme laptop and from his home internet. So here's a quick front end uh that I built here for the sake of this demo. Um, so you can see here that we're gonna put in a natural language query. Just kick it off here. There we go. So we're we're putting in a natural language query that we're passing to the agent. Um, the agent is of course hosted on Amazon Bedrock Agent Corre runtime, and currently the agent is, uh, is troubleshooting that incident, right? So it's going to connect to that Agent core gateway, it's going to authenticate, um, it's going to list its tools and then use those three tools to troubleshoot the incident. What I'll point out about this specific call right here is, uh, we've kind of asked it to do some generic troubleshooting, right? We haven't given it specific instructions, uh, about the, the, the specific, uh, queries it might run or the sources to look at. So it's actually gonna check against all three data sources in this scenario. But because it's a chatbot format, it's actually able to, uh, selectively, right, if I were to ask follow-up questions, go ahead and, and, uh, specifically call on, uh, you know, individual data sources. So you can see it, it produced a report here. Um, there's a summary of the findings, so it did identify some block traffic at this time stamp, and it's giving us a detailed log analysis. First with the checkpoint, then the Illumio segmentation logs, where the blocked traffic was actually found, and then lastly in the Z scalar logs. And then it's uh generating this kind of final conclusion where it's walking us through the full traffic flow. We were successfully able to authenticate to ZPA. We established a connection to ElasticSearch. Uh, the initial connection was allowed by both ZPA and Checkpoint, but that a subsequent attempt to connect to the Elastic Search instance was blocked, uh, by, by, um, uh, our, our, our third and final, uh, uh, uh, network firewall, right? Um, so this is kind of a, a, a quick demo of how the solution works. And I actually wanted to talk a little bit about the code here, er I know that's always um kind of more fun. Um, I know it's a little hard to read, so I, I apologize, you probably can't read the prompting here, but I wanted to include it because I think it's really important. So the prompting here is what tells the agent how it should call these tools. So you'll notice we have on top of the kind of basic, like, you know, you're, you're an analyst and you should, uh, you know, be respectful with the user, we actually have information about the schema for each of the log sources, and this allows for the agent to dynamically write queries that it's going to use to uh to troubleshoot any incident. So. The the scenario that we ran was a little bit basic, right? It was just, uh, you know, troubleshoot this, this incident more generally. But if you asked a follow-up question, right, something that required it to actually formulate a specific query for a specific data source, the agent can use its knowledge of the schema for each of these log sources to formulate those queries and call the appropriate tools. You'll also notice we're accessing that model in Amazon Bedrock, uh, in the upper right corner there of your screen. Um, so this is how we're connecting to cloud 37 Sonnet. Um, and we're connecting to our agent core gateway to, uh, uh, to access our tools, right? So we're establishing an MCP client. This is a streamable HTTP MCP client to our gateway URL which is kind of passed in, it's that, that, uh, blue, uh, uh, uh, variable that we're passing in right there. And we're also passing in a bearer token, that's the JWT that's gonna get validated by, uh, uh, agent core identity when we authenticate to the gateway. Lastly, I wanted to point out, uh, some of the, just these are just two of the lines that you have to add. There's 4 total when you're taking an agent that might be built with strands or, or land graph, lang chain, crew AI, right, any of the frameworks that we support. If you're trying to run them on Agent core runtime, you only have to add 4 lines of code, um, and 2 of them are, are, are shown right here. Uh, just wanting to highlight, uh, really how simple it is to take an agent that you might first run locally and then push it up onto Agent Core and scale it up to, to hundreds of concurrent requests. OK, Anwar, can you tell us a little bit now about the, uh, the, the value of the solution? Yeah, thanks, Ali. So, uh, we found that, uh, the organizations which are adopting this particular solution, uh, they, uh, have a multi, uh, they've. Have multiple benefits. First and foremost is the faster incident detection and resolution time. So as I said that for security ops team, particularly if there is a new team member or the team was pretty much stretched. So with this particular solution they were able to resolve the issues faster. What used to take. Hours it is now within a matter of minutes, so it helps the productivity of the team. Second is some organizations have even rolled it out as more as a self-service agent for the internal users. So with that, the, the information what is present in the ticket, like the end users themselves can query the internal users can. Use this particular tool, identify where is the specific network block. They can diagnose their own issues, and when they raise the support ticket, it will be faster. Then the volume of the ticket has been reduced. It is faster and it is also helping in better collaboration. So the developer team and the security operations team, they can. Communicate in a much better way. Many times developers raised the issue and the security of steam is pretty much spread. They cannot resolve it within within a couple of days' time. So it was also reducing the developer productivity. So with this particular tool, there is the developers there is an increased agility for the development within the organization. And as Raly mentioned that the agents themselves write the queries, so you, you can interact with the chatbot with the national language query, and you don't need to learn sophisticated query and tools, so it's pretty useful in the way that it elevates a lot of these pinpoints. So what are some of the key learnings and takeaway really when you build this solution? Thanks, Oar. So I think a few key takeaways I wanted to highlight from this solution. The first is just the power of generative AI on AWS for this specific use case. Building with the strands SDK, we're able to, able to dramatically reduce the time to resolution for incidents, uh, really from hours just to minutes. Right. Previously the security analysts had to go and kind of comb through the logs to understand and triangulate across various log sources, and now the agent can really er er do some of that undifferentiated heavy lifting for the security analysts to help them find er the the the incident root cause sooner. The second thing I'll point out is that Amazon Bedrock Agent core runtime can really dramatically uh uh cut down the time to put this agent into production, right? So I, I started by just building this locally on my computer, uh, added just 4 lines of code and was able to push the agent onto Agent core runtime, and then scale it up in, in just a few minutes. So I think that's worth highlighting. The third thing is a crawl walk run approach, right? We started with just kind of a, a portal where a security analyst might interact with the agent. I think as part of the, the, the walk step here, you could actually have a self-service portal, right, where individuals could go in, uh, you know, when they hit a network block, they could, uh, interact with the agent, find the root cause, and then maybe they only have to submit a ticket if they want some, uh, you know, some, some policy change that's blocking them currently, right? Um, so that kind of eliminates some of the heavy lifting that the security analyst has to do right now. And then the final uh kind of run aspect of this could even be using the same interface and the same agents to actually investigate uh kind of dangerous security incidents, right? So if you had many failed requests that might indicate, uh, you know, potentially that there was some sort of bad actor that was operating against your system, and there's an opportunity here to use the same system to look at many different timestamps and try and identify, you know, what blocked it, or maybe if it wasn't blocked, what should have blocked it. Um, I'll point out that Amazon Security lake, right, we use that to kind of centralize the security posture around all of our, our, our log sources, um. And uh uh that's a a good practice here. Um, of course, we used S3 with OpenSearch, right, which is obviously um something you can protect, protect with Amazon Security like, but if you're bringing your own uh own um potential logging sources from, from, from other, uh, other places, you can also use Amazon Security like. Um, and I think this actually kind of connects to my last point which I really wanted, wanted to highlight, which is that the power of Amazon Bedrock agent core gateway. Um, so we, we, again, right, we showed just 3 sources that are running on AWS for the logs, but. I know, I don't think it's fair to expect that your log sources are all going to be on AWS, right? You've probably got, uh, logs on prem, for example, you might have logs on other providers. Um, and the power of, of Agent Core Gateway is if you were to host an MCP server that's running where your log, uh, where your logs are accumulated, um, you could then connect to it via Agent Core gateway because it also supports an MCP server target type as well as a REST API type and the, the lambda, uh, target that we were, that we were using for the sake of this demo. Um, and, and you could, uh, then connect it to the gateway, uh, and let your agent, uh, use that MCP server, um, in it's, in its troubleshooting process. So that's what we wanted to talk about today. Uh, we really appreciate your time. Um, also wanted to, uh, throw in this, this slide here, uh, if you wanna kind of level up your skills and get started with SkillBuilder, uh, you can get started today. Uh, I'll hold the QR code here for a minute. Um, we really appreciate your time. Thank you so much. And if you wouldn't mind, uh, inside your, your AWS events app, there's gonna be a session survey. If you could fill that out, it would help us, uh, a lot. Thank you everyone, and we're happy to take questions over here once we get the mics on.
