---
video_id: iMC_Um32UTQ
video_url: https://www.youtube.com/watch?v=iMC_Um32UTQ
is_generated: False
is_translatable: True
---

Good afternoon everyone, and thank you for joining us today. Uh, I am Mark Orrell. I run the AWS Professional Services practice in Hong Kong, and I'm really excited, uh, to be sharing a story with one of my favorite customers, Cathay. Um, we've gone on an incredible journey to transition from a DevOps to a devsecops practice and using Agentic AI. So Matt, Matt stole some of our thunder in our presentation this morning when he talked about the, uh, security agents. Um, so really excited to be here with Naresh Sharma and Tony Leong, uh, to go through. So we're gonna talk about some of the challenges that were faced. Um, you know, what the solution that was there, the journey we went on to, to getting, uh, some benefits and results out, and most importantly, some lessons learned and what's next. So with that, I'd like to introduce Naresh. Thanks, Mike. Thank you. Hello, everyone. May I tell you that close to 78% of vulnerabilities identified by our scanning tools were false positive. Leading to hours and thousands of hours of waste of time for many, and also having some issues with, you know, uh, fixing those vulnerabilities, identifying, and so forth and so on. And it was really slowing, uh, slowing our innovations. So, my name is Naresh Sharma, and here we are from Cathay to share with you an amazing journey that we had by overcoming these challenges and sharing more. So before I go to those details, I would like to share with you that this is Nikki, and Nikki is one of our initial first aircraft in 1946. And it has been, uh, you know, proudly displayed outside Cathay headquarters in Hong Kong. Interestingly, its sister, uh, aircraft called Betsy is actually at the Hong Kong Science Museum. Cathay is more than just an airline. It is the memories for most of us of our first flight. It is also a cultural connection for millions of people in Hong Kong, Asia, and worldwide. And as we reach Our 80 years of services. We have As we reach 80 years of our services. We are now serving close to 100 destinations worldwide with 230 aircraft. And counting. We're also very proud to be the founding member of the One World Alliances. This year we were judged the top 3 airlines, the best airlines in the world. And with our accolades like being the best in the economic class and best in in-flight entertainment. For those who don't know, CATA is a very dynamic and a complex organization. On a daily basis, we fly 70,000 passengers. And help them to reach their destination safely, comfortably, and happily. And behind all these intricate and large operations are thousands of our employees who are working day in and and out to ensure the great customer service. And at the same time, Work with the customers at every touch point. And, uh, while they are doing these activities, IT in this case is actually at the center of everything. With technology, we are, we are facilitating and we are supporting our thousands of employees to ensure that they can give the services they want to give to, to our customers and at the same time, have a seamless, uh, processes and meet their goals and. Their vision IT and digital at Cathay has been the forefront in supporting the vast technologies that we have. We have close to, we support close to 1300 applications, uh, uh, that we are having. With 2500 microservices. Uh, we also have close to 1000 developers that are spread across 7 offshore development centers. And many more Having this large scale IT and by the way, this is just about the application I'm talking about the, the systems behind, uh, that those are having downstream and upstream, east west, north, south, I think we have, we have a lot over there. But as we, uh, as we have progressively innovated all these years and we have uplift our application, there are always, there are technical depth, there are certain challenges will actually impact your go to market. Challenges such as Time to market. I think time to market. I'm sure you must have heard it was in the early 80s and 90s that this word, word was being used a lot, but of late in IT also, it has been used a lot in, in many senses. And the reason being because time to market is. Actually, a differentiation that you can have in your, in your services that you give to the customer that differentiates you from your, from your, uh, uh, from your, uh, competitors, right? But time to market is just a function, and it's a function of all the challenges that I have shown here, functions of false positives. Project timeline impacts, roles and responsibility, if not clear. And then escalating cost. And if you're having multiple tools, of course, you know, not each tool will work with the, uh, with one another, integrate. So, and on top of it is the agility of the business. So time to market does get impacted by all these factors. Before we move to the next, uh, few slides, I would like to share that When you're doing this evaluation, it is very important because at first, we need to understand where we are standing, right? So we have to do certain assessment in the organization to say where we are standing. And how we want to progress from there because you may be having a lot of strengths, you'll be having some area of improvement. There are also the positive, you know, there are, there are promoters to the systems and technologies, and there are detectors to the systems and technologies. So when you do these kind of assessments, it actually identifies the area that you want to address in the next 6. Months, 12 months, and 18 months timeline and so forth and so on. While the degree of these parameters may go up and down depending on what is, what is the maturity of those processes in the organization. There is one more important thing that actually helps you to give the right information in such cases, and that is culture of the organization. Because when you're doing this self-assessment, this self-assessments should be done without any. Impact to see that what will people think about our department, what other department will think. It's very, it is very important that when such assessments are done, they are done with wholehearted information and the right information. Only then we will have the right, uh, you know, steps that you need to do to work on that. So, what, uh, the next few slides that I'll be sharing, I'm pretty sure many of you will resonate, uh, it will resonate to many of you here, and it, maybe the degree of, of the impact would be varying, but definitely these things you must have seen or heard in the organization a lot. False positives, as I earlier mentioned, 78% of the vulnerabilities were actually false positive. What happens when you have false positive vulnerabilities, right? The, the, the team still needs to validate. It's not easy. The, the reason why you come to the conclusion that it's false positive, because that initially, somebody has done a validation and addressed to, to be a false positive. It's a lot of manual resource intensive because lacking automation capabilities means one has to, one has to validate those false positives and also fix the ones which are true positives. So it is very manual, uh, in automation capabilities and the findings that we were having very raw, and it was a lot of excessive hours that we were spending on the assessment of the results. Roles and responsibilities. While every subunit within technology were aware of what they have to do, but when working together, it was quite a challenge when you don't have the right roles and responsibility and accountability in terms of remediation efforts. Otherwise there will be a lot of finger pointing. Time to market. I think we already covered that. I won't go much deeper into that, but yes, it is, uh, it is the factor or it is, uh, it's a function of all the factors that we saw earlier. Other thing which is quite important is one needs to identify, consolidate, and prioritize. There has to be certain process that one must have to identify and understand that what are those vulnerabilities, consolidate them so that it can be fixed in the, in the right, uh, frame. But again, this was one of the challenges that we were having. And multiple tools. Like tools are tools. If there are no right processes, if there are no right, uh, information coming out of them, then they are just sitting as a white elephant and just giving some information. So it was critical for us to identify these things and then go to the next, uh, next, uh, chapter. Where were we in terms of software development life cycle, um, it is quite important that because from the risk perspective we have to mitigate those risks, but how do we mitigate? How do we identify that this is a risk because there are false positives also in that there are other, other situations in that, so it's very difficult to mitigate the risk. Need to ensure security hygiene. Uh, the security when it comes to the later stage of a development, there are only two things which can happen, because if you find a lot of vulnerabilities and true, true positives, it's either you're going to delay your, uh, initiative, or you're going to exempt and exempt, uh, accept those risks and move forward, which in both cases is not the right thing to do. So, having a design, uh, of security team and having the architects thinking of des uh design from the conception stage is very important. And finally, if security team and the, uh, er, and the developers are in a, in a different zone where they are developing at one end, then the, when the output is coming, and then we are doing the security testing, it's definitely going to create a lot of overhead on the organization. So we had to see how to work that in tandem. So this is a typical, uh, DevOps, agile. A lot of, a lot of companies say, OK, we have agility in our DevOps, and, uh, you know, we have all these phases. We ensure that the coding practices and all those are in place. But what happens when we are going to launch? That's when the security team comes into the picture and says, hey, wait, let me do my testing. And then when they are doing the test, we identify. By tons of proved vulnerabilities. And we all know what happens then, right? So, uh, there's a lot of tug of war. The business wants to go, uh, go, uh, to the market as soon as possible. They want to launch their products as soon as possible, but then we have to take a risk-based decision. And sometimes it can be very risky when you are, when you are, uh, you know, launching a product which has, uh, security deficiencies. So when, when into security uh, testing, any vulnerability identified after the development and the UAT and other areas have been completed, a security vulnerability will take at least 18 times the cost to fix. And when we do the launch, if the vulnerabilities are identified at the launch, it'll be close to 64 times the cost of fixing those vulnerabilities. So as you notice that the focus should be how we change the cultural mindset of the organization to have security as, uh, as early as possible in the cycle and, and, uh, go forward from there. So with that, I will hand over to my colleague, Tony Leung, who will take you further on this journey. Tony, over to you. OK. Thank you, Naresh, and good afternoon everyone. So I believe after sharing from Narresh on how impactful the waterfall security scanning was, so you may have some ideas on the pinpoint of ourselves. So we change. We need to migrate from the existing waterfall security testing to something else that can help us to detect and fix the error at an earlier stage. So we have to shift our testing. To the left of our timeline, means we have to have earlier testing. And throughout the whole cycle we have to test on everything as early as possible. So to better improve the quality, efficiency and lower cost and lower risk. So I'm, I think you guys know what I'm going to say. Yes, we have to transform from dev ops to devsetops. And there are some key changes we have to embrace. And first of all, we have to have shift left. Means we have to have embed all the security compliance and practice into our SDLC software development life cycle. Not just at the beginning or the end, we have to do it continuously. And then so that we can detect the error at an early stage and then fix it as early as possible. But you would say that if we shift left all the security testing, some of people will have concerns, questions about how we accomplish this. For example, the testing team, be concerned about the resources because they need to do more testing because continuously. And also, how about application team? They also have concern about do they have a skill set to tackle those security issues or among the uh security uh priority or other application requirement. Which one should they do first? So those questions are actually we are also addressing in in this key chains. I will cover it in the 2nd and the 3rd point. So come to the second point, let's talk about the process. So as I mentioned, uh, shift left. So we need to make sure that all the testing and scanning must be triggered and executed in an automatic way. So luckily we have a DevOps, a very robust CICD pipeline, and we can easily orchestrate all those testing and scanning into our DevOps pipeline. And also, most of our applications are now using that CICD means this is the most natural and easier way for us to integrate. And also we can also maintain the compliance by enable the blocking mode. And blocking mode is a guardrail of our applications to safeguard our deployment. If there are any high and critical vulnerability files, the deployment will stop and the vulnerable release will not be reaching our customer. And last but not least, on the people's side. As mentioned by Naresh, the waterfall security testing always come with some last minute surprise. And the application team and BU didn't understand why our security team always blocking them and the department cannot go to the customer. But actually this, our security team is doing a good job to protect our company from any revenue loss, reputation loss due to the security incidents. And there's some misunderstanding that security is the obstacle of innovation and value creation. So we must change. We must have some culture change to to change our people's mindset, especially for development community. So let me uh uh uh ask a simple question to all of you. So imagine one day you can be a developer for one day, a 1 day developer. There are two options of work you can do. One is new application development. Second is that aging vulnerability effects. So which one you will choose? OK, uh, for those who want to do the aging volatility please roll your, raise your hand. OK. OK. Thank you. Only, I think only a few of us, uh, you would want to do the vulnerability. So it means I assume the rest of you will want to do application development. OK. So this is, uh, expected and this is a normal uh human behavior. Everyone wants to do the new things rather than fixing the old things, right? And last but not least on this people's side talking about the visibility and also the observability. So we, we want to improve the application security posture. At least we want the application owner to know that what is the current application security posture. So a very insightful dashboard is also important. So the application team can have some clear target to aim for day in day out. And also they no more last minute surprise because they all know their application security portion now. So with the help and and less and blessing from our senior management and also support from the ADWS conservative, we have successfully achieved all these key changes. And now we can say that we transform from dev ops to devstop ops. And we can also have some earlier detection of all all those vulnerabilities. So you can see that from this uh different life cycle, we have different activities in embedded in our cycle. For example, we have SAST for the source scanning. We have IAST for the uh interactive testing, SCA for the third party library scanning, and also we have a dashboard to review all those outstanding vulnerability. So now, compared with the previous uh traditional way, the cost of fixing the vulnerabilities is now significantly reduced. And we can say that we successfully transformed to depthsite ops and we can detect the error earlier. However, Do you think Everyone was happy And do you think we are really able to achieve time to market, better quality, better efficiency, lower cost, and lower risk? I think the answer is no. But just one step away from a success. I'm going to share what's this new challenge is holding us. Actually, from different, by different reasons, from the security scanning tools, there are many noises inside the tools, especially for false positive. This is one of the things we need a lot of human effort to review and follow up. So let me explain a little bit more here. So whenever there's a potential false positive, we have to Ask the security expert to review it and then to evaluate whether this is a true false or false positive. Confirm this is false positive, then we ask the tools owner to do the suppression by either updated configuration of the tools or go back to the portal vendor to ask for their fake bug facts on the port side. And also this is for one application, one vulnerability. However, the same vulnerability also can occur in other applications and no way to do the synchronization across different applications for the same tools. Means we have to do it one by one, suppress the false positive one by one. Not just this, Across different tools, also no way to do synchronization. Means we have to repeat all those process for other tools, right? This is a lot of human effort will be induced in this kind of false positive review. In average for our case, talk about 500 exemptions we need to review every month. We also need to spend about 15 main days on viewing those uh those uh vulnerabilities and also the suppression configurations. So this is a huge effort for us and we know that this is also a burden and the bottom left for our development life cycle. So we have to change, otherwise we cannot no longer achieve the time to market objective in the near future. So, we are excited to announce that we have developed an agenda AI to help us on rebuilding those false false positive and then the suppression. So I'm going to go over the high level diagram of this uh H AI and Mark will go over the details in the later of the presentation. So first of all, our developer will go to our application security posture portal and interact with our AI agents. Then they can ask the question about any security recommendation, the existing application posture, and also they can ask for the false positive exemption. And then AI agents will learn from our knowledge base, including all those approve approved that exemptions, all those uh false positive pattern, our company company policy, and also that some patent anti anti-patent. And once the decision is made, the agent AI will then interact with different security tools on the actual suppression and actual configuration to to uh remove those uh false false alarm. So with the help of this agenda AI, uh, we successfully reduced our average time of reviewing false positives from 30 days to 13 days. So it's about like 60% improvement. OK. I think up to now, uh, you guys may want to know the making of of the desktops journey and the making of our HS AI. So let me pass the time to Mark to talk about it. Thank you. Thank you, Tony. So it was a journey, right? You know, going from having 78% of the vulnerabilities being false positive, having to go through the research, it truly was a journey. So there were many milestones that we have completed over the last 223 years along the way. You know, the first thing as Naresh had mentioned, it's, we have a mentality, start small, iterate, cycle through. So the first and biggest thing, right, you know, Cathay was on AWS for 7+ years when we first got engaged. And the request was, hey, we're, we're continuing to grow, we're putting in other areas, we want to up our game from a, a cloud operations and engagement perspective. So we came in, we did a, uh, cloud center of excellence review. That led to a cloud operations assessment, which then led into a Dev DevOps assessment, right? So we, we put some effort in and we, we did that at the end of 2022. With that, that set up, kicking off in 2023. The first part of the engagement, right, which was really to do a deeper dive, following those assessments to get hands on with the application teams to see what is really happening, right? So we, we got engaged and we kicked that off in the 3rd quarter and with that we focused on 3 applications. That had the highest number of critical and high vulnerabilities. And there was a little bit of skepticism within CAA to say, oh, you know, it, it's impossible to get rid of all these critical and high, right? There was a lot of exceptions, right? And it was much easier to get an exception than it was to fix what was wrong. And even part of that was the application teams didn't know how to particularly fix certain vulnerabilities, right? They're developers, they wanted to build cool stuff. They weren't the best um security engineers, right? So they didn't necessarily know how to actually remediate some of those. So we worked with the teams, and for those three, we cleared all the critical and high vulnerabilities to prove it could be done. Right? And that was something that was important, right? So to, for the application teams to say, yes, this is possible. So in 2024, that's when the real heavy lifting started, right? The, the goal was to initially consider remediating the entire set of applications. Um, we rationalize that down to approach and say we're gonna do 50%. Right, to get started. And in conjunction with that remediation of the vulnerabilities we were focusing on, you know, from that first engagement we realized there was a gap in the knowledge, right? So the best positioned teams to fix those vulnerabilities are within the application teams, but they didn't have. The, the skills to do that, right? Not that they were bad developers, it's just their forte was not security development and they didn't know how to do certain things, so we launched a security champions program which I'll talk in a little bit about. With that, we actually sort of even surprised myself at the end of last year, we had hit 120% of the target that had set out. So more than 50% of the applications were remediated to get rid of the critical and high vulnerabilities. And it was a journey, right? And, and in that process, we managed to get 58 security champions certified in the process. This year It became about how do we get more efficient in doing that, because going through 2024, as Naresh and Tony had pointed out, there was a lot of manual labor that was going into this. You saw the metrics, 45 days, I think it was 45 days a month to just sift through the vulnerability exceptions and what was false positives, right? That's not sustainable. Um, so we did a POC. And we also launched our level 2 security champions, and we're really excited that in the 3rd quarter, we launched the 1st MVP of the Devsec Ops Agentic AI capability, which, as mentioned, substantially reduced down the amount of manual efforts to go into it. So when you take a look, right, the light blue circle was sort of where that initial assessment was. We had set out the green line, which was where we wanted to try to get to over time. And right now we're, we're in that orange, orange line, right? So there's definitely been improvements. Right, and I think talking to what Naresh said, having that baseline in the beginning is critical because you want to be able to show that you are making progress against those goals and to have those goals, so you, when you're talking to your leadership, you can say, hey, this is where we were, here's where we're going, and this is how far we've made it along that journey. So there was a lot going on over the last 3 years. In phase one where we were predominantly focused on those 1st 3 applications, we had set out basically 3 swim lanes of activities. You know, one was about looking at the security design, what are the patterns, anti-patterns, and code samples that teams could readily apply to their solutions. The next was how do we enhance and supplement the existing DevOps uh capability to enhance that to be more devsecops oriented. And the last was looking at security test automation, right? Because there was not that much security testing, uh, in an automated fashion. So we dove deep and it was sort of uh ran in parallel. So while we were looking at those three core swim lanes, we dove into those 3 applications to start working with the CA teams to say, how do we make this happen, right? So it would have been really easy. We could have gone in as proserve, fixed everything, handed it back, walked away, and then we'd be getting another call a year or two later, say, hey, we got a lot of vulnerabilities again, come back and help us and do it again and again. So we wanted to really, you know, change that. So in phase two, where it was about the remediation of a bigger set in the portfolio. It was really a parallel effort. While the application teams were working on remediating the vulnerabilities, we also were running the security champions program to help raise the awareness, skills and capabilities of what the team needed to do to be able to fix those vulnerabilities along the way. So it was sort of, you know, I, I would refer to it as book smarts and street smarts, right? The book smarts was the security champions where we were running training sessions and that. And the street smarts was the teams were actually getting hands-on and fixing the vulnerabilities, um, through that process. This year, right, it's the remainder of the portfolio is in focus for getting remediated. But it was really about the, the POC we did with the Agenic AI. To help reduce down the amount of human effort that was required in the process, particularly in classification of false positives and the exception and the review process that was surrounding that. So mentioned Security champions program a few times. So who are the security champions? What's the role that they play? So there's really 3 levels. You know, that first level we worked with CA we went to the application teams, we said we want a named individual from each application to join the security champions program for level one. That was going to be their person in the application team. Who needed to keep an eye on security elements that they were doing. Previously, they did not have that, right? The application team, they would look to the secure like security, that's another team's problem. The security team was like, well, you know, we're, we have these vulnerabilities and somebody else has to fix them, right? So level one was really to get the people aligned to that and support that shift left type of mentality. And it really was intending to drive the fixes and address the security items as early as possible in the life cycle. With level 2, that is the next level up. So the focus there was these are the more senior people, uh, they have a broader, uh, impact within the, the given areas, right? And this is really a, a, a secondary decision, right? So, what you don't necessarily wanna do is have an application, level one, say, oh yep, everything's a false positive. Right? Trust but verify. So the level two was really more of a uh verification process to ensure that what was being done actually was, it was either truly a, a, a false positive. Or did it require Uh, for the remediation. So they were really also supporting that level one in the, uh, decision making process. And that really helped in a shift down of the security capabilities. Level 3, right? You don't need an army of level 3 people. This is your 1 or 2, like within Amazon, we would call them a distinguished engineer, right? It's, it's the guy, right? I have a security problem, that's the guy. I'm super lucky, because on my team in Hong Kong, I have the OWASP chapter lead is actually one of my employees. So when it comes to things in the security field in Hong Kong, I've got one of the best guys on my team, right? And I think Cathay appreciates that, right, with having that type of knowledge and expertise, right? And they helped support the level 2, and we were also helping with level 1, but it's also to, to look and take a, a forward view. On what else is coming, uh, in the security space, right? There's new tools. Hey, security agents all heard about them this morning, right? There's constantly new tools, new capabilities that are coming out, as well as there's new threats all the time that are surfacing, right? And that's where that level 3 champion, it's all about, not as much internal, but what is happening in the market. To bring that knowledge to make sure that internally, that it's going to be best addressed. So in that program, right, we had classroom type of training, and we actually ran a test at the end of the training to see how many people actually comprehended and retained, right? It's not an AWS cert, um, but it was specifically tailored uh for cafe. And we had over 86 people participating in the program, uh, in 15 sessions. We supplemented that, right? So the first one was the, the, the book smarts. The second one was the street smarts, as I mentioned, right? Hands-on labs, right? And in some cases, we didn't do a lab, we actually went into one of the apps that had a problem, and we were using that as a real-time example to fix. Right? So we balanced that, right? So it wasn't just a bunch of presentations, we got people with hands-on keyboard to make it happen. And then AWS helped uh in that level 2 and level 3 mode, um, as well as helping enable that skills transfer across the team. One of the big things that we noticed, right, roles and responsibilities, right? So as you look at moving from a DevOps practice to dev secops, there's something new in there. Somebody's gotta do that sec part in Dev secops. Is it The pipeline team Is it the security team? Is it the app team? Who's gonna do that? And you know, unfortunately, it's not one person. There's different capabilities, different elements that are addressed by different parts of the organization, and that all has to be orchestrated together. And just for people, this is not the exhausted racy, this is a subset just as an example. The detailed racy that we had had 220 activities that were itemized out. So it got pretty comprehensive on what elements were covered by which teams. And Dev secops agents. This, you know, is sort of the, the happy part of the story. How do we get the heavy lifting off of the people and let the computer do that undifferentiated heavy lifting, and let people do more value add bits. So the agents come into play, right? We get a request in, it goes into a, a matching node. Did they say, because the, the capability, it's pretty wide from, you know, a general inquiry to, you know, is this a false positive, right? So it was a pretty complex, uh, you know, system that we helped build out. And we, it relied on a lot of work that we did over the preceding year and a half, where we had developed patterns, anti-patterns, code samples, um, and so we had a, a pretty good, uh, knowledge base to build off of. Right? And so that focused into the Devsecps tooling, and a big part of that was needing to have LLMs help us make heads or tails of it, because it's not just a, oh, I got a sequel injection vulnerability. Is this false positive or not? Yes or no. There's a lot of things that go into actually determining that, right? So what people were having to do, we had to build that out in the agents to be able to fit, factor in. How many different things are we considering, including, has this been reported before? Are there known uh remediations? Are there compensating controls in play? Also, how do you handle a general inquiry, right? To say, um, hey, I don't know exactly what this vulnerability is. So creating a knowledge base to, to say, hey, this is that vulnerability, and here's what it might be about. Then, as part of this. Tony mentioned, there was a hard blocking put in place. So once an application had cleared all of its critical and high vulnerabilities, there was a hard block. You could not go out with a new release with a critical or high vulnerability. It's a great way to make sure that you don't get yourself back into a, a position where you had too many vulnerabilities. So with that hard block. It was integrated in with ServiceNow, so the agents are smart enough if something has been determined as a false positive, it gets registered into ServiceNow as a false positive, which then would allow the pipeline to be able to to continue on. So obviously behind that, right, there's a bunch of AWS services that are out there. Probably the biggest part is leveraging bedrock, right? And how do we, we set up the agents, how do we have the agents coordinated through the life cycle, tapping into this to make all of this come together. So this is a from a, a desensitized screenshot of what the agent would do. Hey, I've got this vulnerability. What is that, right? The agent went out, checked the knowledge base, checked the various sources, and with 95% confidence, this is going to be a false positive, and it gives some of the, the background on that. But then I might have another vulnerability. And You know, for this one, server side code, uh, you know, maybe insecure, but the agent did not have enough information, right? So it's prompting the, uh, the developer. We need a few more details to make a determination on is this a false positive or is there a potential uh vulnerability there, right? So it gets to be a bit more dynamic. And then there's also, you know, the knowledge of saying, hey, what is sequel injection? And it gives an example of, of what that is, um, and so that's what we've sort of have built out, um, you know, and there's been some great benefits. So Naresh, if you wanna. Yeah, thanks, Mark. So the benefit side, uh, well, well this is not exactly for Cathy, this is a market information. Which says that the change management is 3 times more effective when you have devsecops compared to DevOps. The recovery time is very much, is quite fast. If you notice, it's, uh, close to 2600 times faster to restore an incident if you have dese ops. And this is very important when you have thousands of developers, you don't want the people to be burnt out by fixing or going around and trying to identify, uh, false positives and getting burnt out, uh, you know, while fixing those. So it's almost 40% reduction in the burnout. And the change is likely, uh, 7 times less likely to fail if you have DA cops, because what you're doing in this case, you are identifying, you're addressing, you are, uh, you know, uh, fixing those vulnerabilities or those, uh, uh, uh, logic failures or whatever, much ahead in time rather than doing it at the, uh, at the final, uh, touch of the launch. What we found is 50% of the time the remediation costs compared to fixing at the later stage, uh, but obvious because when you want to go, uh, live, and when you're trying to fix something and you have tons of things in and you want to put more, more labor and more, uh, you know, uh, uh, more developers and more staff to actually fix those, uh, items, which is going to increase your cost. 75% of the uh reduction in the, uh, detection and fixed critical high security vulnerabilities, because again, you, uh, upfront, uh, security, uh, uh, is already inbuilt in your coding practices where it is not having critical high vulnerabilities. And 70% increase in security awareness among development team. It's very important. There is one line which most of the which our leaders and all, they keep reiterating in most of the town halls and all security is everyone's responsibility. So it is not just. Security team's responsibility. It is a responsibility of right from the person who's doing the conception to the design, to the development, to the testing, and so forth. So it is not just one team's responsibility. Of course, from the governance side, from accountability, yes, but the responsibility is for everyone. What was the outcome of agentic AI? It was faster decision making, uh, while, uh, we had to, uh, fix and identify whether those are false positives or whether, what are the next steps that we need to do. Agentic AI was quite fast. Shift left, uh, and identification of the correction of the vulnerabilities because we were not in the, you know, at the right side of the, uh, launch cycle, but we're actually at the left where we were, uh, identifying and fixing those. Consistency and accuracy. This is again very critical when you are having so many developments about 131,400 applications to, uh, to manage. It's quite important that you have the consistency in fixing. So in this case, when you are fixing the vulnerability, you are fixing in across the board, you're not just, uh, uh, you know, trying to address one application at a time. And workflow management, again, uh, you know, lift, uh, uh, diff undifferentiated heavy lifting from humans to agenttic AI. Again, humans are always, uh, you know, in terms of, uh, cost effectiveness, if you can do a repetitive job with agentic AI, it's always, uh, it's always good. And there's 11 other item which I probably want to also share is we are always having a belief that culture eats strategies for the breakfast. And this is one of the quote that our leader had once mentioned from a book, and it's a very important quote. So when which of whatever strategies you might be having, they be the best strategies in the world, but if the culture of the organization is not. Adapting to those strategies are not changing, then it's they are going to fail for sure. So, so always, you know, go back and when we are doing the, that's the reason when we're doing these assessments we were coming up with a very clear mindset that this is where we are and this is where, where we want to be. So that's quite, uh, important. And then for the next, I will give it to Tony. OK, thank you, Naish again. So, uh, we have a very fruitful and a very, I got a lot of great achievement in the last two years. So first of all, thank you, uh, AD bus team, especially the Hong Kong team, the Akang team, and also the PEF team, and also our support from my senior management. So for the next year we have a lot, a lot of things to do. But because this is not a PSC, the project steering meeting, so I'm not go over the details. Just uh in a nutshell, there are a few items we want to cover in next year. So first of all about the people, we want to have a more security champion and more advanced skill in our security champion. Secondly, about the tools, we want more security scanning throughout the whole development life cycle and so so that we can detect the error even earlier. And the last one is about the observability or the visibility of the episode security posture. So we want to have more insightful dashboard, more insight from actions can be, can be brought from this kind of dashboard. So next about the lesson learned. So, uh, this is a, it's a big change management as a as a whole. And there are a few items I want to, uh, mention again here. So first of all about the culture. So we know that, uh, culture change takes time, uh, people can be changed overnight. So, so, but, but we still need to set a very clear guidelines for everyone, a very ambitious target, bite the bullet and go for it. And also can, can, can do a spirit. For the second one, it's about the tools. Uh, by default, no twist is perfect without any customization or any, uh, uh, fine tuning of the tools. The twist is only at one of the collections in your showroom. It's not functioning, right? So, in some in some cases we also need to work with the portal vendor, share our feedback to them, ask them to change, to upgrade their version to fix our issue. And last but not least, automation. So AI also help us to do our automation. We try to, try to move from our human in short automation to AI in short automation. This is the key point. And also we, we can help to reduce some of the human effort, especially on the false positive review. So I think it's almost come to our end of presentation. So thanks for your time to hear our story, and we are more than welcome to share experience after the sessions and also we love to hear. Thank you.