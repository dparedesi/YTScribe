---
video_id: qur5VQbavdw
video_url: https://www.youtube.com/watch?v=qur5VQbavdw
is_generated: False
is_translatable: True
---

Thanks everyone for joining. My name is Andrew Sun from Nvidia. I help lead our global business development for the retail and commerce industries. Um, welcome to this session. It's really great to see such a full room after lunch. Uh, and also it says a lot to be at a conference like AWS Reinvent where there's just so many announcements about the latest data, compute, uh, models, and at the same time, so many of you coming to join us to talk about something that is, um, frankly as human as it gets, conversations, um. Voice AI is really evolving quickly. Um, it's no longer just a simple command. Um, today it's rich, it understands the context of the dialogue, it can understand your intent, your emotion, domain-specific language, and all of this is happening in real time. Um, a lot of this breakthrough is happening because of infrastructure with the cloud and AWS, with accelerated computing and GPUs, as well as foundation models, and all of this is becoming so much more tangible for every consumer and every enterprise, um, such that, you know, the everyday tasks that we do, whether that's customer support, whether that's ordering your food, whether that's transcribing a medical note. Um, this is all being, being rapidly transformed with voice. Uh, I'm excited about our panel today because we're gonna explore where voice AI is today in the market. Um, what does it really take to run a voice AI workload, not just in a pilot, but actually scale that into production. And you're gonna be hearing stories, uh, from the people that are building these products, uh, and they're building them at scale. They're tackling all the hard problems, latency, cost, privacy, safety, but ultimately trust of their customers and their, of their employees. So with that, thank you all for coming, and let's get started. I'd love to invite my panelists to please introduce themselves. Cool. Hi, everyone. So my name is Seng, co-founder and CTO of PTI. So Polia is based in London. We do voice agent for enterprise contact centers. We work with some of the largest enterprise, you know, in the world, and including utility companies, financial services, and a lot of hospitality and restaurants and hotels as well. So, yeah, well, glad to be here and then, you know, love to share more with everyone here. Hi, so I'm Cameron Davies. So, uh, I'm the chief data officer for Yum Brands. So for those of you who don't know Yum Brands, we're the world's largest restaurant company. So you've probably heard of Pizza Hut, Taco Bell, KFC, or hopefully have a Burger if you're on the West Coast, um, with about 65,000 units worldwide. So we're using voice in a number of places across the enterprise. We're happy to talk about it in a few minutes. I think you got the most loyal customers in a developer conference, uh, at least Taco Bell, certainly more. Um, I'm Prem. Um, I'm a machine learning engineer and the founding engineer of Heidi Health. And Heidi is an AI care partner. Uh, we use voice-based, ah, we do voice-based clinical documentation and workflow automation for clinicians, so clinicians can spend less time taking notes and more time on their, on their, on their patients. And we're based out of Melbourne, Australia, and, ah, we launched this product a couple of years ago and uh we scaled to supporting like thousands of users worldwide. I'm really looking forward to the chat and, uh, good to meet all of you. Excellent. Well, thanks for joining us today. We're so excited to have this diverse point of view here on this panel for everyone. Let's jump right in. I think in so many times when we're going through a technology paradigm shift, there's always sort of a sprinkling of 1000 seeds to kind of see what blooms. But ultimately what we're really here for is solving real customer problems and pain points. So let's jump right in. Um, can each of you share a real world example of where voice AI is transforming a core business process from what, from your vantage point? Yeah, uh, we deploy a lot of voice agents for different of, uh, different verticals and, and many of our customers, you know, so it's kind of quite hard for me to actually pick one specific case. Uh, I will pick one anyway. So, because we just had a Black Friday, right? So we actually work with one of our retail customers here in the US. We started with launching a voice agent with them first because you know, our, our, uh, primary drive is always driving for voice first and that's kind of our product for the focus since the company was funded. The customer use already work with uh chat vendor as well. So they do like online chat, which is actually a very common thing that you know, Black Friday Friday, they got a lot of traffic. They also got a lot of surg traffic uh during Black Friday Friday. It's about 3X of their normal volume during that week, and typically what they have to do is that they need to staff 3X of the existing contact center people in order to take and digest those volumes. But the problem of that is that they have to staff, like, you know, started hiring a couple of months ago, and then it's always a temporary job because after Black Friday Friday, they are going to scale back the operation. So the training, the hiring, and afterwards letting people go is a very expensive process overall. Uh, they started with chat and then they wanted to do voice, but voice is hard. So they partnered with with us to launch the voice agent. And once we launched the voice agent, you would thought that, you know, people, the business was started to let people go and they reduce workforce. The reality is that they just, they just don't have to handle this kind of seasonalalities. They keep their workforce around, because, you know, there are so many things to do in the contact center anyway. If they are not picking up a call, they, they can totally do something else. So, I think we always thought that AI would take people's job away. It's probably going to be true. We talked a little bit already. But what we are seeing now with a lot of our customer base, it just smooths that demand curve and make it a lot easier for them to manage operationally. This, uh, last week we took over their chat deployments as well. So now we are like the only channel vendor for the, for them. So the customer can actually get in touch with the B2BPs online chat, order something, and then, you know, phone in, and then we would know who they are and when they placed the order. So I think that is to me is a is a very, you know, cool and interesting case study there. That's a great one. I, and I feel like we've heard that in at least in the retail industry a lot in the sense that the, the expectation versus what actually happens is that, you know, the cognitive load on these very retail demanding or business operations where the operations are so intense and they spike, um, no one. In that industry ever feels like they have enough hours in the day just to do their job and so you actually shift that cognitive load and a lot of the times you're hearing customers being able to actually serve customers right and focus on the the actual connection with their end user. Kim, what are you seeing in your business? Yeah, I think our. The most impactful is the one we've been the most vocal about and most public with. We're, we're looking at Voice AI right now in 22 ways, which one is in the drive-thru and the other is in call centers and we've got another of other applications that we haven't really talked about publicly. Those are the two big ones. Uh, in the drive-thru we are live with a voice, um, solution and over 600 Taco Bells sitting here today running live. Um, it's been. A journey of learning What we found is really interesting, you know, we talk about cutting labor that that really wasn't, isn't our key premise off of it. It goes back to what you, you use a term we use that term which is the cognitive load, which is if you've ever, I don't know if anybody worked fast food ever in their like teenage career, a couple of people, if you've ever, you want stress, put on a headset. Go sit at a cash register at a um at a busy Taco Bell that's running. Let's call it 4 or 5 million AUVs, which is a pretty big good size for a Taco Bell, and during a lunch rush and try to take an order, cash out an order, fill a drink, grab a bag, make sure it's right, get it to a customer. They're all really friendly and happy and everybody's rational, right? Like it's, it's, it, it's, it's tough, right? It is tough and it takes. Um, a set of mental, um, toughness to go do it. So our thoughts are if you do this, what we can do is we can take that cognitive load off. We can make it easier for these team members to do their jobs and. In our experiment so far, I call it an experiment, we're scaled at 600 stores. Now that's 600 out of 60,000 across the globe, but still, um, what we're finding is really interesting, which is if you get it right, it can do the job pretty well and in some of our best stores it can be successful somewhere from 70 to 80% of the time that it just takes the order from start to finish. And so it can do and it's just getting better we're finding that consumers are getting more used to dealing with it um as it's getting better in the restaurant we see a couple of interesting things on a direct value perspective like it never forgets to upsell it never forgets to ask about Roundup and so you see some financial advantages there for your franchisees and then for the team members what we see in restaurants that use it and leave it on, we see dramatic decreases in turnover. Which is our key is KPI to say are we making it better to do this job, um, and then if you're a franchisee and you understand what it takes to how much it takes to hire a new person and train them, that's a pretty big financial incentive as well. It's great. Um, for Heidi, I feel like voice AI is like the core of how we operate. Um, you must have all noticed that when you go see a GP in a clinic, you walk in and then you see your GP sitting in front of a computer, um, ready to take notes. Uh, you sit on your bed, the GP's asking like, hey, how's, how's your, let's let's say you have a chest pain. The GP's like how's your chest pain, how do you rate the pain, and every now and then the GP's just between you and the computer, just taking notes, uh, making sure that they're getting everything that you said into the computer, and that just sort of makes you feel like GP's focusing more on the computer than on you, and like there's a, there's a chance that the GPs could be missing out on real details of what you're saying. And what Heidi does is Heidi uses voice AI to take automate all of that, so the GPs gets like full-time spent on you, like you just have like this ambient scribe in the background just listening to the conversation. Just make sure that it picks up on everything that you're saying so the doctors put the full attention on you. And also the, I feel like with what Heidi does is the benefit is twofold. One is that it makes sure that GPs get to spend more time on you and they hear what you're saying. Making sure that um they don't miss out on any information that you say so that everything's accurate and you don't have to really think about them losing or anything. And the second thing is GPs don't have to spend a lot of time after their usual operating hours, making sure that they get all the admin work and everything done. So it's sort of like it takes a lot of cognitive a lot away from the GPs and also makes sure that GP's free up their time to spend more time with the patients. Prem, you used a really interesting word there about um ambient right like that it's constantly there. Talk to us more about kind of what you're seeing there in terms of user adoption and engagement so. Sometimes what we feel more about technology is that um it kind of like hinders the way we do our everyday things. Um, you have a phone, you have a laptop, you also have to spend a lot of time interacting with it, you're typing things into it, you have to take your time away from your normal activities to do things. But with voice AI it can make the technology not feel that pervasive. It's more like a thing that's in the background listening or doing whatever you want it to do. Like it just like it's like a way for you to interact with the platform without actually having to spend a lot of time away from your day to day activities. Like for Scribe, you know, it's just something that's listening in the background, making sure that it takes a lot of the manual labor away, and also it captures the conversation and makes it into a structured way when you connect to an LLM as well. So it's like a really good way for you to interact with the system without actually having to take too much time away. Yeah, thanks for that. I think, I think in many ways that's sort of the future, right? is this technology only gets more personal, more fast, more relevant for the user, um, that ambience and how you interact with it becomes so conversational. It's like we all have an assistant with us at all times, which then kind of begs the question of how do you scale this technology, right? If everyone starts to form the new habit and it really starts to adopt and scale. Um, you know, what are some of those technical considerations that really need to come to mind if you're, uh, building this or partnering this for your enterprise? So let's talk about the technology side. Sean, maybe you can start us off here with, um, you know, what are you seeing is the hardest technical challenge when it comes to scaling a, a voice AI, uh, solution from a pilot into a production? Yeah. Yeah, I think, uh, for, you know, after, you know, ChechiPD got launched, I think the world becomes a very different place because, you know, polia exists, you know, before that, that time. I think the, the LM actually make building of these agents a lot faster and easier. However, you will see that once you try to get into production, you run into a lot of challenges. And I think I usually like to say is like, you know, this technology get you to 70, 80% really fast, you know, basically like a couple of hours of work, you will be there. And you imagine you, you thought that you have already reached that level of production is. And once you get Into production, you realize there are so many different problems, the hallucinations, like, you know, the, you know, the instruction for the following capabilities. These are all getting better as well. But when we bring in voice, there's an additional layer of complexity is like, you know, about the speech recognition errors is that, you know, if the TTS a sound robotic user will not be engaging. And you started to solve the whole business problem. Like I think the technical problem is one layer, but then there's another layer on top of it is like the adoption problem is like, hey, adoption in my thinking is that you need three persona to actually buy into this. One is the enterprise, the B2B business you sell to. They need to feel that they are getting ROI from the solution, right? So that ROI calculation is very important. The second layer is the consumers, like, eventually, the voice agent is going to talk to your customer. Like, does the customer like to talk to the voice agent? Unfortunately, in this country, the answer is no, because you have tried out a lot of these like an automatic phone systems, which is still predominantly the majority of the install base. They are not very good. And so therefore, when, when humans realize when people who realize this is actually an AI, they immediately wanted to hang up on the phone call. That's just like walking. In context center, one of the major issues we are seeing. So the user XPTPP appearance of the first term is very important. You've got to understand very accurately. You're going to say in a very crispy way that people feel like, oh, this agent actually sounds very different from the previous ones I interact with. So that's a tricky one. I think the third one about scaling is about. Prosumer adoption. Like now you heard AI industry, a lot of people doing forward deploy engineering. It's just because the prosumer adoption is not quite there. Enterprise, a lot of them don't know how to adopt this technology and build effective, you know, product around it. So therefore, a lot of startups come in to actually do a lot of these forward deploy uh methods to actually go really deep into the organization. So this is the problem I think that everyone is trying to solve right now, all the big cloud vendors as well, because I think that's the the final piece of the question, because I think we can narrow it down. Uh, the consumer. side, you can also narrow it down as well with a forward deployment model, but the prosumer, real, real challenging, I think. But the prosumer adoption would gradually improve as technology become better. And then we need to shift, you know, create more product layers on top of these foundational models to actually much more easier to learn and interact with. That's super helpful. I think that that gap and closing that last 20%, right, is so fundamental. How do you think about What to prioritize first, you know, when you're trying to close that gap, right? I, we definitely, you know, hear companies talking about speed, right? It is really important so there's not just a very uncomfortable lag in the conversation where it's just to your point, a very inhuman interaction, um, but then at the same time there's probably issues like accuracy, right at the end of the day, like talk to us a little bit about from an engineering perspective how you, how you think about prior. of closing that gap. Yeah, uh, it's a very, very, uh, good question. It's a tough problem. I think one company alone cannot solve those problems. That's why we partnered with Nvidia to actually solve some of the problems like, you know, latency, we shouldn't worry about it because, you know, Nvidia should have the best GPUs and best software knows how to run on those GPUs to solve that problem for us. So, that is just like, you know, something that we. Decided to take that, you know, bet on partnering with some video. And I think accuracy is about collecting the data and then continue to improve your model. So I think that continuous improvement actually matters a lot. But there's also fundamentally the model that you are using, does it actually like, is it sufficient for your problems? So, you know, one very interesting use case is that we have this outbound call where The human picking up a call when when the agent make an outbound human pick up a call, accuracy was perfect. But then once there's a robotic IVR pick up the call, the accuracy is just complete poor. It's just because the model doesn't see this kind of didn't see this kind of data before. So therefore, like, I think that the approach we're taking is that we decided where which areas we want to partner so that we remove those out of our priorities. Then the second piece will be It will, building a very flexible infrastructure, you know, because the good thing is that everyone is trying to solve the problem for you, because AI is like making so much advancements in the past year, so many companies working on it. So you kind of have to need to have a flexible infrastructure ready to take on all these new techs. Technowledge. So I think the second way we are doing is just building a very flexible platform so you can integrate it with the latest technology when they are available. Got it. Flexibility and and option value because yeah, you, you, you could, you said it so well. The ecosystem is just proliferating at a very incredible rate, right? And what you think is not available today. Sometimes it's a matter of just weeks, right? It's no longer months given how fast the market's going and like riff off that for a minute if it's OK, please, like a non-engineering perspective off of it, which is fine. There's nothing wrong it's a good perspective. The way we think about it is there's There's a set of like basics, right? A latency of 4 seconds is not gonna be acceptable. So like there's a set of basics. There's a set of accuracy you've gotta at least be at, right? There's a set of infrastructure things that have to be true and cost structures. That have to be true. Like those are minimum hurdles. Like which one am I gonna prioritize? Like they all need to be true, right? All three of these things, there's a minimum level and you need to decide what those minimum levels of things to be true. There's no prioritization there. They all just have to be true. Once you dec but you need to understand what that is and decide what that is for your use case, right? Once I have that, um, then it starts to be, and this is where like maybe I'm just the product of 20 years at Disney and my experiences there, then it starts to be about the experience. To your point, like, because it doesn't matter how accurate it is if it sucks, right? So do I work? Do I give you 2 more points of accuracy or 5 more points of accuracy, but it's a really bad experience because the latency sucks or the voice doesn't sound right or is off-putting. So I'm a firm believer that once you hit the minimum levels, your number one priority needs to be that experience for that use case because I said like you, we've been there. The reason why I think people are still where they are is because they're so used to like how quickly can I hit zero because I'm used to the NO like the NOPs they're like they're really bad. They can only answer the questions they've been trained on, which is 20 questions in a chatbot. And I just, and they can't do anything but those 5 things and it's just frustrating to just let me talk to a person. So we're in my world, we're still stuck in sort of Apple Newton world of expect of like my experience is this. It we're really moving toward iPhone world, but nobody's tried it enough yet, and we're not all there yet. And unless we get enough people in that space, we're gonna have a hard time moving people along that continuum, just my perspective. Oh, that's super helpful, Kim, because I, I think in many ways what I'm hearing from you is customer trust at the end of the day is everything. And so there's a minimum set of sacred, sacred sort of standards, right, for your brand to make sure, you know, in order to play this game, it's important to provide. Awesome. Bramley, anything you wanna add? Yeah, I agree with what Cameron said on that, so just to get an interesting perspective on that, like, especially when it comes to models, like you always look at models in silos, like how well the models perform in terms of like accuracy or precision or whatever, but you also have to look at it from an entering perspective as well. And you need to look at how the whole customer experience is like you put the model in, OK. It's got good performance, but at the end of the day, like when you go through a whole customer journey, does the model really help the user achieve what they want to achieve and the, the performance, like, and the experience they get out of it, like that's really like it's really important to how it's like when you're using like agents like voice AI. Yeah, I mean, in your world, if, if, if I, but the whole point is. In the medical world, I, I talked to the client and I gotta remember I'm spending over half my time actually just charting versus dealing with care and that's frustrating if you're in the medical. So you're trying to deal with the fact that like I can take the thing about your job you really don't like but it's necessary, move it up in that experience chain, and I can spend more time. But if at the end of the day I go and go back and check and all those things are inaccurate, that I actually made it worse. I would have been better off just to do it myself the first time, right? Exactly. And also like doctors didn't spend 5 years in medical school just to like, you know, sit in front of a computer and take notes. They want to be a doctor. And Haydn really does that really well and voice AI is like, it really enables that to like take it from a point where the doctors don't have to worry too much about what they're saying. But if the model is not really that accurate, then that actually means that it creates a ripple down the line, the notes are really bad and the coding and billing everything, you can't really trust that anymore. Yeah. Thanks gentlemen, um, let's, let's switch to another topic here on, on scaling related to scaling, which is, you know, we're here at AWS Reinvent. I think Amazon in many ways deserves so much credit because they pioneered far field communication with Alexa and Echo and really like took the industry in a new direction. When it comes to voice AI, how are you seeing AI manage kind of nuances specific to voice, you know, whether that's like a regional accent, whether that's noise in the background, you all kind of have a unique perspective given from where you, where you sit. So we'd love to hear, you know, how you're seeing AI manage some of that auditory, um, complexity and nuance. Yeah, uh, I think, uh, from a very technical point of view, and then, you know, after sending several technology iterations in the past is that you, you have a lot of these like, you know, uh, local or regional issues really, like, you know, accent of the particular kind or like, you know, particular kind of understanding problems, you know, uh, I remember in the past nuances used to focus a lot on healthcare space. It's basically tailored vocabulary for those use cases, right? But then if you see the technology evolution, especially in machine learning world, is becoming a more cas, you know, from a cascaded system to be a more, you know, like completely connected large neural networks. I think that's just, I think, when I was like thinking about where to invest in and then where to solve the problem. It's like it's very important to remember that the technology will eventually move there. And I think LM, I remember when previously when we did chatbots is about like intent language understanding and you have some decision making and you're writing some template text and then it's a cascaded pipeline. But then now is a complete end to end training. We have now the speech to speech models as well. It's got, you know, try to join all these modalities. Together. To be frank, I don't think the technology is quite there yet, but I do actually think that this is definitely the future. And so if the technology is going to evolve that way, and you do actually have a problem to solve right now, then you just need to solve the problem, you know, if you can solve it in a nice way, great. But if that problem is only open AI can solve the problem, then then solve the problem, right? Like you can. patch around that problem right now so that you can have a production system that's kind of ready to use, because what you, what you want now is what you want to ship the product now, rather than ship the product, you know, several years later once the technology becomes there. But you always need to keep in mind that technology would eventually catch up. So how do you build up an infrastructure or architecture that factor that in. In the future, I think it's quite important. I think this is like quite, you know, uh, because internally 6 months ago, we have this like review of like, oh, do we continue to invest in cascading systems or N2 systems. And then we did a lot of TED testing with within ourselves and also with the clients. The conclusion is always like, you know, in the future, an end to end system will be the future will be the future. I mean, the technology will continue to change. I'd say the first thing is we should continue to reset the expectation of what the standard is. And what I mean by that is every time we try to do something with AI, we could talk about it like when my head of AI is in the back of the room with forecasting, and they're like, Well, is it 100%? Like, well, you're not 100%, right? So like the standard should be like what is the standard? And right now when we talk about accents like. Has anybody in this room ever had a conversation with someone who had an accent that was different from theirs and you had to ask them to repeat something? Of course you have, right, of course you have. So like the expectation isn't that the AI will perfectly hear every accent. Perfectly and respond to it, the, the, the standard should be how does it adjust when it doesn't, right? with that technology and where do we tune it to specific places to make sure those things that we know and we, we have this we have a joke right now. One of our like our heads on the product side. He went to Oxford and he's got a very proper English accent. Our current like voice ordering hates Ghan's accent. It's hilarious. Everybody else will test it. It'll get like 80, 90%, and Gan will test it. It'll get to 50%. He'll yell at the thing, he'll call me, this thing is shit. I can't believe we're doing this thing. And it's, it's, and it's Gehan's accent like, so like we could tune it to him, but unfortunately across the US that's not the standardized accent that we're going after now when we release in the UK we probably will, but so we'll, and then the others, the voice canceling, the noise canceling, all that stuff will come along. But I think setting the expectation right is the first thing that people tend to set it the wrong way, yeah, yeah, and then fine tuning it for bollocks. Uh, yeah, well, the, the thing is that, I completely agree with you, and then we are expecting AI to be better than human, which is fair because there's a lot of like news, you know, people go on the news and then say that, you know, AGI is, you know, arriving. The reality is I think the expectation has been set to way too high. So yeah. Prem, any, any thoughts on kind of, um, how you think about your decisions of cascading versus composable, right? This whole idea is, is really whether it's the business or the technical side of how do you think about the architecture in a world where you know where the world's going, like how do you think about it technically, I think Sean kind of like mentioned it by making the platform flexible and especially where you are, like when you're a startup, you're really experimenting different things. You don't know what works and you want to make sure. Or that you really set in a way you can quickly adapt to change, so if you're using a composable architecture, it really helps with ah enabling something like that. So when you're using composed architecture, you're just making the components really modular, so it makes it like, it's like hot swappable, like you can like for example, if you look at Heidi, there's a transcription, there's a node generation part, there's billing, and the way we set it up, we make sure that each part is really replaceable with something new. And given the way uh that things operate, like even if like for example, if you're using like, like an agent driven architecture, where you have LLMs interacting with each other, there's like a lot of models coming around all the time, there's like different kinds of tools coming around all the time. So you need to make sure that your platform is flexible enough to like iterate and change based on what was coming out, so that you know like how the flexibilities change, but on the other hand, Cascading is really efficient when you're like working in a place where you know exactly what the system needs to be, like, once you're like ironed out, how you want a certain feature to be, then you can just, you know, like OK, this is the maximum we're gonna go, OK, then at that point we fix certain things and then we set it up, OK, one thing after the other, this is how the flow goes, and it also really helpful when you want like monitoring and different things enabled and also like it will be very fault tolerant as well, because one of the downsides of having a flexible architecture is that it's really hard to know, Like when things go wrong, you have to like, it's it makes it a bit hard to debug when you're like there's a lot of moving parts around, but at the same time it's a price you have to pay to stay flexible. Yeah, I look, I, I think it's a great question. It's when we constantly ask ourselves. I, I've been married to the same woman for 35 years. I have no fear of commitment. I'm not worried about that. What I am worried about is I don't have, I've never had those same kind of feelings for any kind of technology vendor I've ever met, right? So like finding that balance is key and is what we just said like there's pieces of it I'm just gonna need to commit to because I don't know, and that commitment will create a set of stability. Recurrence, trainability on my team and an expectation, realizing that I may be behind and then there's pieces that I know we need to be composable on and so we're constantly reinventing the architecture by the way, but you know we, we just had this conversation it's not just on the technology side we had a whole conversation last night about our entire data infrastructure. And our current set of schemas and the way we've done it, like, you know what, it was really great for a set of reporting and analytics that we're doing. It's not set up the way we need it to be set up to feed some of our upcoming like LLMs and some of the more generative AI. So how do we do that, right? And how do we flex it? I don't regret the money we put in 5 years ago to get a great star schema to do what we needed to do, right? I don't, I'm not, that's fine, right? And I have no problem with the fact that we need to now reinvest and adjust, but there. There are certain elements of models, for example, we were talking about changing our model. Like some of them will get better, some of them won't. And so how, where I can, where I know the composability will be key, how do I architect around that to balance the trade-offs. Super insightful, um. Given, given we have a kind of different perspective both on the enterprise side as the ISV side, sort of different stages of, of maturity in terms of your organizations, talk to us about how do you or your customers make that decision of what to build when it comes to voice in-house, voice in-house versus partnering. So we, we, I, I guess I'm the one non-vendor on the page. So, but you guys, I love your perspective. I, I can say for us we have a, we have a sort of a standardized filter that, um, starts with like IP. Like, is there something we know that we wanna keep to us or something we know that somebody else doesn't, or is there something they know that we don't have and it would be a huge speed to market? I'll use a non-voice example on, um, we use a third party to do, um, email customization. And when we looked at the way they were doing it, you know, Rocky and I set aside like we could probably figure this out over time. It probably takes about 18 months of research to do it. We probably, and at that time the opportunity cost is gone. Let's just sign the contract and go, right, because the IP was already there. And then it's about cost and speed to market, right? And then the third thing for us is integration. Not only are we the world's largest restaurant company, but we are quickly becoming the world's largest restaurant technology company with Bite. And so there is a, a lock in and integration with our technology that we also care about is that we've added as 1/4 filter. That's, that's such a, such a critical point. I think so many times in paradigm shifts people race for speed, right? And then, and then speed is important in a market. It's important to learn and, and rapidly learn, but, but there's always this fundamental strategy question that we see often at the sea level. All around who owns this intelligence, right, and, and, and what is truly sacred, and that's a really thoughtful decision and an important one to kind of navigate your approach on and well, and that's like there we more than ever we'll go like the voice like no matter what. We own those recordings and we own that data. Like, no matter what, and all the customer data, no matter what, we own it. We even own it with our third-party aggregators, by the way. So like we, we're serious about that, and that's a key point for us. Yeah, I think with, with Byte, especially in the investments that Yam has made, uh, you know, I think it was like a billion to date, right? And, in terms of how much they've put in the talent, you can see that it's, it's, it's not just sort of a vocal strategy, right? Like there's real, real technology, there's real talent there. Sean, you were gonna say something. Yeah, uh, I think, uh, in this, so voice agent itself has a really complicated, you know, like modules and technical stack in order to actually make the voice agent works, not just for one use case. But for many, many use cases, like, you know, because that's the industry we are in, right, because it's not just about building a retail use case or financial services, we have to actually sell into a lot of different customers as well. So, in order to do that, the things that we have to build is actually a lot. And so then, you know, deciding what you do and what you not to do become very important. And I think this is always the biggest uh question for startups is like, you know, what's your core value at? And what do you, what, what do you focus on predominantly because you have limited resources. To us is always about delivering that. Voice agent appearances and we are focusing on building up the application for the end customers, either for the consumer or enterprises. So with that in mind, we have been focusing on building the product layer to make it easily configurable for different industries and different purpose, you know, different use cases that they're looking for. So that has been quite fundamental. We also find ourselves because our goal is to deliver the best userPTPP appearance as much as possible because we see that from our conversation with customers, that's the reason they, they come to put the port at the first place. So we will have to invest in areas we think that is needed. That's the reason we started to invest our own speech recognition model because We previously found that, you know, some of the over the shelf speech APIs works perfectly. But for some use cases, you started to see there are limitations there. And without controlling that particular technical stack, You kind of like, you know, limited by what you can do to deliver that best experience experience. And, you know, in the old, old days, speech recognition models is such a big problem because there is not an end to a model yet exactly you have this language model, acoustic model, and then, you know, you have a vocabulary, all these things that need to be, you know, again, a pipeline system, uh. So we have always hesitate to invest in that until we realize, oh, Nvidia started to do their own models and steam steam like this an entire pipeline. And it was just, OK, well, let's take that base model. And then we train our own model, train our own data and tailored to it. And it solved so many of the problems that you know, we will not be able to solve previously. So I guess like, you know, what I'm trying to use these examples to say is that only model is not a goal, is not a strategy, but like be able to deliver a best usage PDPP for our clients is the goal. But then the goal takes us to actually invest in this particular area. So I think you always need to find what is your north star that you are trying to achieve. Say no to the majority of things and then realize, oh, this is like one thing or two I have to invest in. Great. Prem, anything you wanna add to this? I think Cameron and Sean, they covered pretty much everything I wanted to say, but it's more about just how what your business is, how much you want to outsource, it's like, when you're starting off, you want to make sure you get your product to to your users first, and what's the best way to do it. Like if it's something that's business critical, you want to make sure that you dealt with that in-house, but if it's something that can be outstore, if there's like an API or provided. You can use that and it's also you have limited resources, so you prioritize like where do I invest my resources now? Is it something that I can figure out down the line? OK, cool, I'll just use a third party, get it over with and then figure it out later. But if it's really critical to the business, OK, I'm gonna send my resource to research and develop and get, get it up and running and you know like to serve my users. It's just about how you prioritize your your resources. Great, so moving on in terms of enabling this technology, um, you know, clearly the ecosystem matters there's so many different players that are critical. What do you think are the most critical ingredients for a business leader to look for when they are trying to decide on a voice AI platform? I, I, I'll say from our perspective, it's We're, we've, we've already hit on a couple of them, you know, for us it's. For, uh, personally, is it somebody we wanna work with? You say that, but we've all had people like that we've worked with with vendors in the past and like, yeah, I just would prefer never to work with those people ever again. And then there's people we worked with like I still, you still have relationships with today because they were just really good and easy to work with. You can come to win-wins. And so for us that's, that's the number one thing we, we meet. So like, is this somebody that's on the same page as us do they wanna work with? Then it's, it starts to be about the technology piece of it and sometimes I don't want the most cutting edge. Sometimes I want the one that's gonna integrate with my, my peop my technology the easiest people that are gonna work with my people the easiest. Um, and then there's a minimum set, and then it becomes to that lock, right, we, where we talked about commitment, right? How composable is the system? Can you speak? Can you work with my other things? Are you gonna, like, do I have to do the integrations? Do you have like because we die on the integration hill all the time, right? We all see it like we die on the integration hill. So like what's already there, what am I gonna pay for? What are you' gonna pay for, um, and then that composability, right? And, and the firm belief that if you have to lock me in so hard that I have no optionality. Then you obviously don't believe that strongly in your product. That's my theory. Like if you believe in your theory, your product, you, you're not gonna have to lock me in that hard because it's gonna be so good. I'm never gonna wanna leave it, and you need to put the faith in the product. That's a great point, and it kind of segues nicely in terms of, you know, this decision that a lot of businesses have to come up with of when to use open source versus when to use a more proprietary model. Curious if gentlemen can talk a little bit about, you know, that decision framework for your company or in, in, in, in customers that you've seen. Yeah, uh, I would say from my perspective, always start with the easiest to start with because. You wanted to first prove that this technology brings you ROI. You wanted to prove that this technology is actually helping you a business in the way that you want them to. And so I think that invest too early on in the open source is probably not the right strategy. I think that you should give it a try on the latest closed, you know, those APIs, the easiest you can integrate it to. Try to build something with your workflow, and if that. Works well, and you prove that it's an ROI and you realize it is not sufficient and then open source can actually solve that problem for you, then you should go to go that way. That's how we did with our ASR models. That's how we did with our in-house ALM models as well. It's only, you know, when 2 GP came along, we just throw all the APIs, you know, to them, you know, just like try to build iterate on the product faster. And then over time, you realize, oh, like there are problems with this and that and that and you don't want it to be bounded by a particular road map of a of a company. Then there's a way that I think that you know, investing in your own like model would actually make sense. But I think that it needs to be a very deliberate calculation, because you don't want it to invest in technology that you don't actually need eventually. Yeah, it's the same, I'm a firm believer in open source like I believe like of most of the things that's built on technology or software, it's all built on open source, but having said that, I agree with what Sean said, like when you're, Entering a market, you're trying to prove a concept and your resources are limited, you want to invest too much in open source, and also the quality of the open source models is not up to par with the foundation models yet. I feel like it might take like maybe 2 or 3 iterations of open source model to catch up to what the foundation wants, but, You want to prove a concept, so the fastest way is is like you use one of the APIs or wrappers and make sure that you get, OK, I've got a product that works and I've got enough customer bases, I've got enough resources and now OK it's time to like invest into an open source or like invest in my own department and start R&D. And once you get to that point and you can, there's a lot you can do, like you have the flexibility because a lot of the reasons why people move away from foundation or frontier models from different products and calls is everything's behind an API like you don't know what's happening there, everything's abstracted away from an API. But you get to a point where you want to own a lot of those components, like different things, how you want to do it, and then once you attain a certain point, you'll be tired of like just having to call a random API like, To get one thing done you might have to call like 3 different APIs and you can just get like some open source models host them yourself and do a much better job than they can do cause what what this um foundation models, what they do is they give you a generic use case, but based on your business needs, it might be a bit different, but, and they may not be flexible enough to, Um, integrate that into your future and then you get to a point where, OK, this is where I start investing in my own R&D and get my product to a place where these services can no longer support me. Right. Kim, you mentioned earlier a lot of the business outcomes you're seeing and the measurement of it. I'm, I'm curious if other folks on the panel can talk a little bit about tangible business outcomes and potentially, you know, to the extent you can share like business measurement that you're seeing out of your customers, right, in terms of impacts to their business. When they, when it comes to integrating voice, obviously. I'm sorry, can you repeat that again? Yeah, just in terms of, are there any examples of business outcomes, um, from integrating voice that you're seeing in, in, in health, for example, um, and similarly, Sean, you serve multiple, multiple industries, um, talk to us a little bit about that. Um, in terms of health, you know, like, one thing we've noticed that, um, clinicians are very hesitant to change. Like when you're trying to introduce a new software, they'll, even if it's very helpful, they'd rather stick to whatever they have up and running cause they're not that tech savvy like an engineers would be, and they have something that's set out and that works and they don't wanna break it. And what we've observed that when you have a software that's built on top of our voice, it kind of makes it easier for clinicians to interact with your product. Like they don't even have to know it's there, you know, it's just something that's running in the background, no one's gonna notice it's there, you know. Like the only, you only know it when you interact with it, like you start recording and then you stop recording, that's pretty much all you have to do. And also the downstream tasks as well, like you can automate a lot of that as well, like the billing, numerical coding and integrations and things like that. Like, what the beauty of Heidi is it has integration with a lot of EHRs, so the notes are not just sitting there in a, in a standalone software or something. Like once you've done a consultation, you have the notes and then it moves into an EHR it's just there ready to go, and you can also take care of your downstream workflows as well, and all of that is being made possible with voice AI. So like, I feel like there's a, there's a big wave of change coming and voice AI is gonna play a big role in it. Sean, anything in terms of your cross industry view around business? Yeah, uh, so I think it's very interesting that because when we started working on the context center, uh, industry overall, we thought that cost is the primary thing and then a lot of people thought that, you know, we're just trying to use AI to replace humans. and we see a lot of the reality is that once you deploy this voice agent in various different industries, you kind of started to realize that different industries actually care about different things. And they are, they are seeking our eyes in different ways. So, uh, the retail example I just mentioned is about smooth that demand curve. So then, You know, they can, they can actually, they don't have to overhire that many people and train them up and then let them go later. So that workforce management is a very important piece to the to them. That's for retail because they have seasonality. For restaurants we work with, they actually, you know, we do a lot of reservations and bookings for for them. And it's actually very funny that on average, in restaurants actually mixing about 20% to 30% of their calls, because just about the cognitive law that is happening inside a restaurant. People running around, especially at the peak hours, to actually pick up the call and then, you know, sometimes if there's Availability one hour later, they don't even negotiate that availability, so the, the coverage will not will not feel, for example. So and then we just found that you know, restaurants, we usually find that they are for large enterprises. They found the value in, you know, not just about the company in the law, but also be able to pick up some of those revenues as well. So I think we are. You know, helping them to increase maybe a 4%, 5% of the revenue once deployed a voice agent, which is the kind of ROI we would not expect to begin with, right? So I think there are a lot of these different aspects I think different industries are different. So you kind of have to deploy something and learn with with the clients on that journey. Yeah, that's, that's the retail examples it hits home obviously, um, just because to your point, the expectation versus the discovery was, was, was quite opposite, right? And, and, and in retail. Uh, customer service, you know, typically, especially as things move more digitally, you have last mile shipping costs, and then when you can serve a customer well, you avoid the return additional last mile shipping cost, right, that recovery cost, um, and so when you serve your customers well, it, it, it can improve not only customer life and value but the actual order economics, right, yeah, exactly. You were seeing, you know, it's interesting that that because you imagine a world where right now you call and you're put on hold to deal with something because the IVR can't handle what you needed to do and you have a choice like stay on hold for 45 minutes, give me your number and I'll call you back. I think we're moving toward a 3rd world, 3rd option, which is or just talk to the virtual agent, which most of us like, well if they can handle it, like why wouldn't I of those 3 options and then what you see is in the restaurant use case on the reservations and I've talked to a lot of like folks in our space we don't do that obviously, but like the ones that do, um. That idea of like nobody's ever on hold. Somebody's always gonna pick up the phone and so what that does to their top line demand driver like it was there but they were in revenue management world we called it an unable like you lost the business you had no idea you lost the business because of availability or. Nobody picked up the call, right? And so as that goes away, I think it's gonna be an interesting is in your world as that business case continues to flow, um, because it's a very I'm booking a reservation for this time, right? It's very clean, it's very contained, and yet somebody can I'd rather do that than not. That's a, that's a great example, Cam, and we see that in voice adjacent with vision like in retail often, you know, retail companies will come in and they'll start using computer vision to detect and automate and smooth out self checkout at a store. And as they can use more accelerated computing, they realize that there's a lot more workloads that they can actually run on that same GPU and so the detection of the use case they didn't even realize they had, right? It's suddenly they're looking at movement patterns of their customers and how long they're waiting in line, not just to check out, but at the deli and so this is a, you know, a great example is Kohl's in Australia. They realized if customers wait more than 45 seconds at a deli, then they're gonna leave that line and so now they can actually perceive it, understand it, alert the customers, and, and it's incremental revenue, yeah, and, and we're talking voice like Lowe's isn't here, but we all know those folks and the way they're starting to do it, the old CEO, I, I don't see it in your bag. Right, the way this is just a terrible experience. Now the computer vision is watching what comes out of the cart and goes into the bag and say, hey, I think you may have missed something. Like I counted 14 items. It's less intrusive, right? It's, and it's a lot smoother, but what it's doing for them on shrinkage is really interesting. Yeah, it's all about reducing the friction and making it really convenient. Alright, let's, um, let's kind of move to kind of the final group of questions here which is really about guidance, you know, you, you are all are unique leaders in your, in your respective industries, um. For an organization that's just starting in Voice AI. What are the top what's the top lesson or lessons that you wish you had known from the outset? Yeah, yeah, I, I'd say that that if I was gonna give anybody advice on this, and this is just not just voice, this is anything, one of the hardest things to do is know when to let go. And we talk about failing fast. Is like, no, no, no, you need to fail cheap because you fail, fail fast and expensive, that's still not good. You need to fail cheap. But one of the things, and you know, we, we, if I go back the last 5 years at Yum and just used as an example, I can name 6 things right now that we have now stopped doing. Right, we tried it, we tried it, it didn't work, and every one of those projects had somebody who was really passionate about it that really believed in it and if we just gave it another try, we could make it work, right? And one of the hardest things to do is say, you know what? This isn't working. It's not worth the effort right now, or maybe the time is not right. Maybe the technology is not there, and I know we've invested in it, but I've literally met people that will let a spouse or a relative go before they'll let that project go, right, um, and so getting that like learning and putting the rules in place and the stage gates in place up front. They put it up front and say, hey, these are what the stage gates are. Here's what success are. When will we call it? What needs to be true by this point, or we're just gonna put it away for the time being, um, and there are projects that we let go on too long because we didn't do that up front. And not only was it a a net co-cost, there was opportunity cost things we should have been working on. We could've been working on that we weren't. Um, and that's the, I think is people come in, the best advice I give them right now. Let's set that up front every project. Let's set the stage gates and understand it now. So when the time comes we're gonna call it, right? We're gonna put a motion aside. We've already made the agreement and unless something's changed, that's what we're gonna do. Yeah, uh, I totally agree with that, because I think uh what I want to add on top of that is because I think voice aging, despite that there's a lot, we have made a lot of progress there. Technically, the technology still has a lot to go, to be honest. I think that, I think, you know, if you done it right, it's completely possible to actually solve your problem already. But it's very likely that you are going to end up with a lot of spending a lot of resources and not going anywhere. So, because of that, you know, setting up those milestones are very important. Also, finding a partner that, you know, are willing to actually go really deep and really far with you is very important as well. That's why like, you know, there's a lot of like, you know, startups out there doing. FDDDE models, we are also doing that as well. And if they are doing the FDE models, you know, try them out, you know, let them build things for the, for you. Maybe, you know, it's actually, you know, it's a cheaper way for you to actually payment and there's a lot of competition now in voice agent companies. So, you know, you can negotiate the deals, you know, good for you, and then, you know, to just give it a. Right. And I think that is probably a way that you should go as well, rather than, you know, also thinking about putting all these big technology boxes together, because that's actually a lot you have to do as well. So find a way, a cheaper way to exp and finding a partner that you can lean on and trust to work on, I think would be my suggestion. My advice is from an engineering perspective and I think it's not just for voice AI's for any project that you start working on, it's always good to start small, like you can think of um building something piece by piece like putting Lego pieces together. Um, making sure that you stay flexible on the way, like you have, you want, you have a feature or a product you wanna build. You wanna try and, um, have a proof of concept build and you start really small, you use whatever resources you have, APIs, open source, whatever you think is best to start with that, and then you, once you get some validation, you start building on top of it, like, You have some components there, OK. Earlier I used a third party or a vendor, maybe the latency's not that great, you swap it out, you put a different piece on, and then brick by brick, piece by piece, you start building it, and then you get to a pro and then you get to a place where your, your product is very flexible, cause, like Sean said, um, the technology that we have, These days, everyday there's like a new model coming out and you want to make sure, if you want to stay relevant and make sure the model's performing at its best, you want to make sure that you're leaning in, you're making sure that you're using the best out there, and, and having them build piece by piece by piece really make sure that you stay flexible and you can adapt to change as quickly as possible. Great. Sean, Cam, Prem, thank you so much for spending time with us today. We hope you all found today's session interesting and learn something new as you go on your voice journey. Uh, and Amazon, obviously, thank you for having us here today.